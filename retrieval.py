import argparse, os
from loguru import logger
from src.datasets.dataset import get_task_datasets
from evaluator import StageEvaluator
from src.llms import Mock

from src.tasks.retrieval import RetrievalTask
from src.retrievers import CustomBM25Retriever, CustomBGEM3Retriever
from src.embeddings.base import HuggingfaceEmbeddings

parser = argparse.ArgumentParser()

# Model related options
parser.add_argument('--model_name', default='qwen7b', help="Name of the model to use")
parser.add_argument('--temperature', type=float, default=0.1, help="Controls the randomness of the model's text generation")
parser.add_argument('--max_new_tokens', type=int, default=1280, help="Maximum number of new tokens to be generated by the model")

# Dataset related options
parser.add_argument('--data_path', default='data/crud_split/split_merged.json', help="Path to the dataset")
parser.add_argument('--shuffle', type=bool, default=True, help="Whether to shuffle the dataset")
parser.add_argument('--ocr_type', type=str, default="MinerU")
parser.add_argument('--doc_type', type=str, default="paper")
parser.add_argument('--output_path', type=str, default="./output/retrieval")

# Retriever related options
parser.add_argument('--retriever', type=str, default="bge-m3")
parser.add_argument('--retrieve_top_k', type=int, default=1)
parser.add_argument('--docs_path', type=str)

# Evaluation related options
parser.add_argument('--task', default='event_summary', help="Task to perform")
parser.add_argument('--num_threads', type=int, default=1, help="Number of threads")
parser.add_argument('--show_progress_bar', action='store', default=True, type=bool, help="Whether to show a progress bar")
parser.add_argument('--contain_original_data', action='store_true', help="Whether to contain original data")

args = parser.parse_args()
logger.info(args)

def setup_seed(seed):
    import torch
    import numpy as np
    import random
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    random.seed(seed)
    torch.backends.cudnn.deterministic = True

setup_seed(0)

llm = Mock()

if args.retriever == "bge-m3":
    embed_model = HuggingfaceEmbeddings(model_name="BAAI/bge-m3")
    retriever = CustomBGEM3Retriever(
        args.docs_path, embed_model=embed_model, embed_dim=1024,
        chunk_size=1024, chunk_overlap=0, similarity_top_k=args.retrieve_top_k
    )
elif args.retriever == "bm25":
    retriever = CustomBM25Retriever(
        args.docs_path, chunk_size=1024, chunk_overlap=0, similarity_top_k=args.retrieve_top_k
    )
else:
    raise NotImplementedError()

task_mapping = {
    'Retrieval': [RetrievalTask],
}

if args.task not in task_mapping:
    raise ValueError(f"Unknown task: {args.task}")

tasks = [task() for task in task_mapping[args.task]]

datasets = get_task_datasets(args.data_path, args.task)

for task, dataset in zip(tasks, datasets):
    evaluator = StageEvaluator(task, llm, retriever, dataset, 
                               output_dir=os.path.join(args.output_path, args.ocr_type),
                               output_name=args.doc_type,
                               num_threads=args.num_threads, stage="retrieval")
    results = evaluator.run(show_progress_bar=args.show_progress_bar, contain_original_data=args.contain_original_data)
