[
    {
        "doc_name": "textbook/socialsci-15334.pdf_180",
        "ID": "00073cc2-c801-467c-9039-fca63c78c6a9",
        "questions": "What was unique about the print edition of TV Guide\u2019s 'TV's Top 50 Families' story published in March 2010?",
        "answers": "The print edition included only the top 20 families, and readers needed to go online to discover the rest of the list.",
        "context": "# 5.7: Influence of the Internet on the Magazine Industry  \n\n![](images/e4f7242276ea282af422f817e1301f87563cd775c13edc721efdc9eb33578346.jpg)  \n\n# Learning Objectives  \n\nDescribe how print magazines have adapted to an online market. Indicate a unique benefit of print magazines archiving back issues on their websites.  \n\nIn March of 2010, Consumerist published a story titled \u201cPrint edition of TV Guide tells me to go online to read most of cover story.\u201d According to the article, TV Guide printed a story listing \u201cTV's Top 50 Families,\u201d but shocked readers by including only the top 20 families in its print version. To discover the rest of the list, readers needed to go online. Phil Villarreal, \u201cPrint Edition of TV Guide Tells Me to Go Online to Read Most of Cover Story,\u201d Consumerist (blog), March 30, 2010, http://consumerist.com/2010/03/print.ver-story.html. As dismayed as some readers were, this story reflects an ongoing trend in magazine journalism: the move toward online reporting.  \n\nJust like their newspaper cousins, magazines have been greatly affected by the influence of the Internet. With so much information available online, advertisers and readers are accessing content on the Internet, causing declines in both revenue and readership. These changes are forcing magazines to adapt to an increasingly online market.  \n\n# Online-Only Magazines  \n\nIn 1995, Salon launched the first major online-only magazine at http://www.salon.com. Salon, the award-winning online news and entertainment website, combines original investigative stories, breaking news, provocative personal essays, and highly respected criticism along with popular staff-written blogs about politics, technology, and culture. Salon, \u201cSalon Fact Sheet,\u201d www.salon.com/press/fact/. Like many print magazines, the site divides content into sections including entertainment, books, comics, life, news, and politics, and technology and business. With an average of 5.8 million monthly unique visitors, this online magazine demonstrates the potential successes of Internet-based publications. Salon, \u201cSalon Fact Sheet,\u201d www.salon.com/press/fact/.  \n\nOther online-only magazines include Slate and PC Magazine. All three magazines, like most online publications, support themselves in part through ads that appear alongside articles and other content. Founded in 1996, Slate is a \u201cgeneral interest publication offering analysis and commentary about politics, news, and culture.\u201d Slate, \u201cAbout Us: Everything you need to know about Slate,\u201d http://www.slate.com/id/2147070/. Considering itself \u201ca daily magazine on the Web,\u201d Slate offers its readers information on news and politics, arts, life, business, technology, and science via online articles, podcasts, and blogs. Slate, \u201cAbout Us: Everything you need to know about Slate,\u201d http://www.slate.com/id/2147070/. The successful magazine has been recognized with numerous awards for its contributions to journalism.  \n\nPC Magazine differs somewhat from Slate or Salon in that it was originally a print publication. First published in 1982, the computer magazine published hard-copy issues for over 15 years before announcing in 2008 that its January 2009 issue would be its last printed edition. In an open letter to its readers, PC Magazine discussed the transition.  \n\nStarting in February 2009, PC Magazine will become a 100-percent digital publication. So, in addition to our popular network of Websites... we'll offer PC Magazine Digital Edition to all of our print subscribers. The PC Magazine Digital Edition has actually been available since 2002. So for thousands of you, the benefits of this unique medium are already clear. And those benefits will continue to multiply in the coming months, as we work hard to enhance your digital experience. Lance Ulanoff, \u201cPC Magazine Goes  $100\\%$ Digital,\u201d (2008), PC Magazine, http://www.pcmag.com/article2/0,2817,2335009,00.asp.  \n\nWhile it is perhaps fitting that this computer-focused publication is one of the first print magazines to move to an entirely online form, its reasons for the transition were financial rather than creative. In describing the decision, Jason Young, chief executive of Ziff Davis Media, said, \u201c[t]he viability for us to continue to publish in print just isn't there anymore.\u201d Stephanie Clifford, \u201cPC Magazine, a Flagship for Ziff Davis, Will Cease Printing a Paper Version,\u201d New York Times, November 19, 2008, http://www.nytimes.com/2008/11/20/business/media/20mag.html. Unfortunately for the magazine industry, Young's sentiment reflects a trend that has been building for some time. Several other publications have followed in PC Magazine's footsteps, making the move from print to online-only. Journals such as ElleGirl and Teen People that were once available in print can now be viewed only via the Internet. As printing costs rise and advertising and subscription revenues decrease, more magazines will likely be making similar shifts.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "TV Guide printed a story listing \u201cTV's Top 50 Families,\u201d but shocked readers by including only the top 20 families in its print version. To discover the rest of the list, readers needed to go online.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/socialsci-15334.pdf_180",
        "ID": "000b6710-f8b4-4dd4-9913-90c7d424fccf",
        "questions": "What was the average number of monthly unique visitors for the online magazine Salon in 1995?",
        "answers": "5.8 million",
        "context": "# 5.7: Influence of the Internet on the Magazine Industry  \n\n![](images/e4f7242276ea282af422f817e1301f87563cd775c13edc721efdc9eb33578346.jpg)  \n\n# Learning Objectives  \n\nDescribe how print magazines have adapted to an online market. Indicate a unique benefit of print magazines archiving back issues on their websites.  \n\nIn March of 2010, Consumerist published a story titled \u201cPrint edition of TV Guide tells me to go online to read most of cover story.\u201d According to the article, TV Guide printed a story listing \u201cTV's Top 50 Families,\u201d but shocked readers by including only the top 20 families in its print version. To discover the rest of the list, readers needed to go online. Phil Villarreal, \u201cPrint Edition of TV Guide Tells Me to Go Online to Read Most of Cover Story,\u201d Consumerist (blog), March 30, 2010, http://consumerist.com/2010/03/print.ver-story.html. As dismayed as some readers were, this story reflects an ongoing trend in magazine journalism: the move toward online reporting.  \n\nJust like their newspaper cousins, magazines have been greatly affected by the influence of the Internet. With so much information available online, advertisers and readers are accessing content on the Internet, causing declines in both revenue and readership. These changes are forcing magazines to adapt to an increasingly online market.  \n\n# Online-Only Magazines  \n\nIn 1995, Salon launched the first major online-only magazine at http://www.salon.com. Salon, the award-winning online news and entertainment website, combines original investigative stories, breaking news, provocative personal essays, and highly respected criticism along with popular staff-written blogs about politics, technology, and culture. Salon, \u201cSalon Fact Sheet,\u201d www.salon.com/press/fact/. Like many print magazines, the site divides content into sections including entertainment, books, comics, life, news, and politics, and technology and business. With an average of 5.8 million monthly unique visitors, this online magazine demonstrates the potential successes of Internet-based publications. Salon, \u201cSalon Fact Sheet,\u201d www.salon.com/press/fact/.  \n\nOther online-only magazines include Slate and PC Magazine. All three magazines, like most online publications, support themselves in part through ads that appear alongside articles and other content. Founded in 1996, Slate is a \u201cgeneral interest publication offering analysis and commentary about politics, news, and culture.\u201d Slate, \u201cAbout Us: Everything you need to know about Slate,\u201d http://www.slate.com/id/2147070/. Considering itself \u201ca daily magazine on the Web,\u201d Slate offers its readers information on news and politics, arts, life, business, technology, and science via online articles, podcasts, and blogs. Slate, \u201cAbout Us: Everything you need to know about Slate,\u201d http://www.slate.com/id/2147070/. The successful magazine has been recognized with numerous awards for its contributions to journalism.  \n\nPC Magazine differs somewhat from Slate or Salon in that it was originally a print publication. First published in 1982, the computer magazine published hard-copy issues for over 15 years before announcing in 2008 that its January 2009 issue would be its last printed edition. In an open letter to its readers, PC Magazine discussed the transition.  \n\nStarting in February 2009, PC Magazine will become a 100-percent digital publication. So, in addition to our popular network of Websites... we'll offer PC Magazine Digital Edition to all of our print subscribers. The PC Magazine Digital Edition has actually been available since 2002. So for thousands of you, the benefits of this unique medium are already clear. And those benefits will continue to multiply in the coming months, as we work hard to enhance your digital experience. Lance Ulanoff, \u201cPC Magazine Goes  $100\\%$ Digital,\u201d (2008), PC Magazine, http://www.pcmag.com/article2/0,2817,2335009,00.asp.  \n\nWhile it is perhaps fitting that this computer-focused publication is one of the first print magazines to move to an entirely online form, its reasons for the transition were financial rather than creative. In describing the decision, Jason Young, chief executive of Ziff Davis Media, said, \u201c[t]he viability for us to continue to publish in print just isn't there anymore.\u201d Stephanie Clifford, \u201cPC Magazine, a Flagship for Ziff Davis, Will Cease Printing a Paper Version,\u201d New York Times, November 19, 2008, http://www.nytimes.com/2008/11/20/business/media/20mag.html. Unfortunately for the magazine industry, Young's sentiment reflects a trend that has been building for some time. Several other publications have followed in PC Magazine's footsteps, making the move from print to online-only. Journals such as ElleGirl and Teen People that were once available in print can now be viewed only via the Internet. As printing costs rise and advertising and subscription revenues decrease, more magazines will likely be making similar shifts.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Numeric",
        "evidence_source": "text",
        "evidence_context": "With an average of 5.8 million monthly unique visitors, this online magazine demonstrates the potential successes of Internet-based publications.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/socialsci-15334.pdf_180",
        "ID": "00183cfe-ceb0-4220-b984-f33f61c61ae4",
        "questions": "What financial reason did Jason Young cite for PC Magazine's transition to an entirely online form?",
        "answers": "The viability for us to continue to publish in print just isn't there anymore.",
        "context": "# 5.7: Influence of the Internet on the Magazine Industry  \n\n![](images/e4f7242276ea282af422f817e1301f87563cd775c13edc721efdc9eb33578346.jpg)  \n\n# Learning Objectives  \n\nDescribe how print magazines have adapted to an online market. Indicate a unique benefit of print magazines archiving back issues on their websites.  \n\nIn March of 2010, Consumerist published a story titled \u201cPrint edition of TV Guide tells me to go online to read most of cover story.\u201d According to the article, TV Guide printed a story listing \u201cTV's Top 50 Families,\u201d but shocked readers by including only the top 20 families in its print version. To discover the rest of the list, readers needed to go online. Phil Villarreal, \u201cPrint Edition of TV Guide Tells Me to Go Online to Read Most of Cover Story,\u201d Consumerist (blog), March 30, 2010, http://consumerist.com/2010/03/print.ver-story.html. As dismayed as some readers were, this story reflects an ongoing trend in magazine journalism: the move toward online reporting.  \n\nJust like their newspaper cousins, magazines have been greatly affected by the influence of the Internet. With so much information available online, advertisers and readers are accessing content on the Internet, causing declines in both revenue and readership. These changes are forcing magazines to adapt to an increasingly online market.  \n\n# Online-Only Magazines  \n\nIn 1995, Salon launched the first major online-only magazine at http://www.salon.com. Salon, the award-winning online news and entertainment website, combines original investigative stories, breaking news, provocative personal essays, and highly respected criticism along with popular staff-written blogs about politics, technology, and culture. Salon, \u201cSalon Fact Sheet,\u201d www.salon.com/press/fact/. Like many print magazines, the site divides content into sections including entertainment, books, comics, life, news, and politics, and technology and business. With an average of 5.8 million monthly unique visitors, this online magazine demonstrates the potential successes of Internet-based publications. Salon, \u201cSalon Fact Sheet,\u201d www.salon.com/press/fact/.  \n\nOther online-only magazines include Slate and PC Magazine. All three magazines, like most online publications, support themselves in part through ads that appear alongside articles and other content. Founded in 1996, Slate is a \u201cgeneral interest publication offering analysis and commentary about politics, news, and culture.\u201d Slate, \u201cAbout Us: Everything you need to know about Slate,\u201d http://www.slate.com/id/2147070/. Considering itself \u201ca daily magazine on the Web,\u201d Slate offers its readers information on news and politics, arts, life, business, technology, and science via online articles, podcasts, and blogs. Slate, \u201cAbout Us: Everything you need to know about Slate,\u201d http://www.slate.com/id/2147070/. The successful magazine has been recognized with numerous awards for its contributions to journalism.  \n\nPC Magazine differs somewhat from Slate or Salon in that it was originally a print publication. First published in 1982, the computer magazine published hard-copy issues for over 15 years before announcing in 2008 that its January 2009 issue would be its last printed edition. In an open letter to its readers, PC Magazine discussed the transition.  \n\nStarting in February 2009, PC Magazine will become a 100-percent digital publication. So, in addition to our popular network of Websites... we'll offer PC Magazine Digital Edition to all of our print subscribers. The PC Magazine Digital Edition has actually been available since 2002. So for thousands of you, the benefits of this unique medium are already clear. And those benefits will continue to multiply in the coming months, as we work hard to enhance your digital experience. Lance Ulanoff, \u201cPC Magazine Goes  $100\\%$ Digital,\u201d (2008), PC Magazine, http://www.pcmag.com/article2/0,2817,2335009,00.asp.  \n\nWhile it is perhaps fitting that this computer-focused publication is one of the first print magazines to move to an entirely online form, its reasons for the transition were financial rather than creative. In describing the decision, Jason Young, chief executive of Ziff Davis Media, said, \u201c[t]he viability for us to continue to publish in print just isn't there anymore.\u201d Stephanie Clifford, \u201cPC Magazine, a Flagship for Ziff Davis, Will Cease Printing a Paper Version,\u201d New York Times, November 19, 2008, http://www.nytimes.com/2008/11/20/business/media/20mag.html. Unfortunately for the magazine industry, Young's sentiment reflects a trend that has been building for some time. Several other publications have followed in PC Magazine's footsteps, making the move from print to online-only. Journals such as ElleGirl and Teen People that were once available in print can now be viewed only via the Internet. As printing costs rise and advertising and subscription revenues decrease, more magazines will likely be making similar shifts.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "In describing the decision, Jason Young, chief executive of Ziff Davis Media, said, \u201c[t]he viability for us to continue to publish in print just isn't there anymore.\u201d",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/(Springer_Monographs_in_Mathematics)_Kazuyuki_SaitA\u0303\u00b4,_J._D._Maitland_Wright_-_Monotone_Complete_C_-algebras_and_Generic_Dynamics-Springer_(2015).pdf_122",
        "ID": "001b10c4-0ec1-48c9-a059-0a44159119bd",
        "questions": "Who does the Loomis-Sikorski theorem apply to when specialized in Theorem 5.4.5?",
        "answers": "commutative algebras",
        "context": "It follows that $(d_{n})$ is a sequence in $\\mathcal{N}$ which converges in the weak operator topology to $\\operatorname*{lim}w_{n}-\\operatorname*{lim}c_{n}$. Since $\\mathcal{N}$ is sequentially closed in the weak operator topology and $\\operatorname{lim}c_{n}$ is in $W$, it follows that $\\operatorname*{lim}w_{n}$ is in $W$. So $W$ is $\\sigma$ -closed in $A^{\\prime\\prime}$. Also, by Lemma 5.4.3,\n\n$$\nk(\\operatorname*{lim}w_{n})=k(\\operatorname*{lim}c_{n})=c=\\bigvee_{n\\geq1}c_{n}=\\bigvee_{n\\geq1}k(w_{n}).\n$$\n\nWe now come to the representation theorem for monotone $\\sigma$-complete $C^{*}$-algebras.\n\nTheorem 5.4.5 Let $A$ be monotone $\\sigma$-complete. There exists a $\\sigma$-homomorphism $q$ from $A^{\\infty}$ onto $A$ such that $q(a)=a$ for each $a\\in A$. Then $A^{\\infty}\\cap\\mathcal{N}$ is a $\\sigma$-ideal of $A^{\\infty}$ and is the kernel of $q$. So $A$ is isomorphic to $A^{\\infty}/(A^{\\infty}\\cap\\mathcal{N})$.\n\nProof The smallest $\\sigma$-closed subspace of $A_{s a}^{\\prime\\prime}$ which contains $A_{s a}$ is $A_{s a}^{\\infty}$. So $A^{\\infty}\\subset W$. Let $q$ be the restriction of $k$ to $A^{\\infty}$. The result follows from Corollary 5.4.4.\n\nWe recall that the algebra $\\mathcal{N}$ is the complex linear span of $\\mathcal{M}^{+}$. We shall see from the results of Sect. 5.6, that in Theorem 5.6.5, we may replace $A^{\\infty}\\cap\\mathcal{N}$ by $A^{\\infty}\\cap\\mathcal{M}$.\n\nWhen specialized to commutative algebras, Theorem 5.4.5 corresponds to the Loomis-Sikorski theorem for Boolean $\\sigma$ -algebras [153].\n\nBy applying results of Birkhoff-Ulam for complete Boolean algebras, see Theorem 4.1.3, every commutative monotone complete $C^{*}$ -algebra can be represented as follows. Let $S$ be the spectrum of a commutative monotone complete $C^{*}$-algebra, then $C(S)$ is isomorphic to the quotient of the algebra of bounded Borel measurable functions on $S$ modulo the ideal of meagre Borel functions. This may be thought of as a special case, for commutative algebras, of the following representation theorem. See Theorem 4.2.9.\n\nTheorem 5.4.6 Let $A$ be monotone complete. There exists a $\\sigma$ -homomorphism $q$ from $A^{b}$ onto $A$ such that $q(a)=a$ for each $a\\in A$. Then $A^{b}\\cap{\\mathcal{N}}$ is a $\\sigma$-ideal of $A^{b}$ and is the kernel of $q$. So $A$ is isomorphic to $A^{b}/(A^{b}\\cap\\mathcal{N})$. Let $\\left(c_{\\lambda}\\right)$ be a norm bounded increasing net in $A_{s a}$ with least upper bound $c$ in $A_{s a}$. Let $\\operatorname*{lim}c_{\\lambda}$ be its strong (and so weak) operator limit in $A^{\\prime\\prime}$ (and so is in $A^{b}$), then\n\n$$\nq(\\operatorname*{lim}c_{\\lambda})=c.\n$$\n\nFurthermore, given $f\\in A_{s a}^{b}$, $q(f)\\leq0$ if and only if $f\\le0$ a.e. So $q(f)=0$ if, and only if, $f=0$ a.e.\n\nProof Let $\\left(c_{\\lambda}\\right)$ be a norm-bounded, upward directed net in $A_{s a}$. Then $\\operatorname*{lim}c_{\\lambda}$ is in $A^{b}$. By Lemma 5.4.3, $\\operatorname*{lim}c_{\\lambda}$ is also in $W$. By definition, $A_{s a}^{b}$ is the smallest $\\sigma$-closed subspace of $A^{\\prime\\prime}_{s a}$ which contains all $x$ that correspond to lower semi-continuous affine functions on $K$. So $A^{b}\\subset W$. Let $q$ be the restriction of $k$ to $A^{b}$.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "When specialized to commutative algebras, Theorem 5.4.5 corresponds to the Loomis-Sikorski theorem for Boolean $\\sigma$ -algebras [153].",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/(Springer_Monographs_in_Mathematics)_Kazuyuki_SaitA\u0303\u00b4,_J._D._Maitland_Wright_-_Monotone_Complete_C_-algebras_and_Generic_Dynamics-Springer_(2015).pdf_122",
        "ID": "001cfd71-1996-4ffe-9382-4e7cd476ef88",
        "questions": "What is the outcome when applying the $\\sigma$-homomorphism q in Theorem 5.4.6 on a monotone complete C*-algebra A, particularly regarding the kernel?",
        "answers": "A is isomorphic to $A^{b}/(A^{b}\\cap\\mathcal{N})$",
        "context": "It follows that $(d_{n})$ is a sequence in $\\mathcal{N}$ which converges in the weak operator topology to $\\operatorname*{lim}w_{n}-\\operatorname*{lim}c_{n}$. Since $\\mathcal{N}$ is sequentially closed in the weak operator topology and $\\operatorname{lim}c_{n}$ is in $W$, it follows that $\\operatorname*{lim}w_{n}$ is in $W$. So $W$ is $\\sigma$ -closed in $A^{\\prime\\prime}$. Also, by Lemma 5.4.3,\n\n$$\nk(\\operatorname*{lim}w_{n})=k(\\operatorname*{lim}c_{n})=c=\\bigvee_{n\\geq1}c_{n}=\\bigvee_{n\\geq1}k(w_{n}).\n$$\n\nWe now come to the representation theorem for monotone $\\sigma$-complete $C^{*}$-algebras.\n\nTheorem 5.4.5 Let $A$ be monotone $\\sigma$-complete. There exists a $\\sigma$-homomorphism $q$ from $A^{\\infty}$ onto $A$ such that $q(a)=a$ for each $a\\in A$. Then $A^{\\infty}\\cap\\mathcal{N}$ is a $\\sigma$-ideal of $A^{\\infty}$ and is the kernel of $q$. So $A$ is isomorphic to $A^{\\infty}/(A^{\\infty}\\cap\\mathcal{N})$.\n\nProof The smallest $\\sigma$-closed subspace of $A_{s a}^{\\prime\\prime}$ which contains $A_{s a}$ is $A_{s a}^{\\infty}$. So $A^{\\infty}\\subset W$. Let $q$ be the restriction of $k$ to $A^{\\infty}$. The result follows from Corollary 5.4.4.\n\nWe recall that the algebra $\\mathcal{N}$ is the complex linear span of $\\mathcal{M}^{+}$. We shall see from the results of Sect. 5.6, that in Theorem 5.6.5, we may replace $A^{\\infty}\\cap\\mathcal{N}$ by $A^{\\infty}\\cap\\mathcal{M}$.\n\nWhen specialized to commutative algebras, Theorem 5.4.5 corresponds to the Loomis-Sikorski theorem for Boolean $\\sigma$ -algebras [153].\n\nBy applying results of Birkhoff-Ulam for complete Boolean algebras, see Theorem 4.1.3, every commutative monotone complete $C^{*}$ -algebra can be represented as follows. Let $S$ be the spectrum of a commutative monotone complete $C^{*}$-algebra, then $C(S)$ is isomorphic to the quotient of the algebra of bounded Borel measurable functions on $S$ modulo the ideal of meagre Borel functions. This may be thought of as a special case, for commutative algebras, of the following representation theorem. See Theorem 4.2.9.\n\nTheorem 5.4.6 Let $A$ be monotone complete. There exists a $\\sigma$ -homomorphism $q$ from $A^{b}$ onto $A$ such that $q(a)=a$ for each $a\\in A$. Then $A^{b}\\cap{\\mathcal{N}}$ is a $\\sigma$-ideal of $A^{b}$ and is the kernel of $q$. So $A$ is isomorphic to $A^{b}/(A^{b}\\cap\\mathcal{N})$. Let $\\left(c_{\\lambda}\\right)$ be a norm bounded increasing net in $A_{s a}$ with least upper bound $c$ in $A_{s a}$. Let $\\operatorname*{lim}c_{\\lambda}$ be its strong (and so weak) operator limit in $A^{\\prime\\prime}$ (and so is in $A^{b}$), then\n\n$$\nq(\\operatorname*{lim}c_{\\lambda})=c.\n$$\n\nFurthermore, given $f\\in A_{s a}^{b}$, $q(f)\\leq0$ if and only if $f\\le0$ a.e. So $q(f)=0$ if, and only if, $f=0$ a.e.\n\nProof Let $\\left(c_{\\lambda}\\right)$ be a norm-bounded, upward directed net in $A_{s a}$. Then $\\operatorname*{lim}c_{\\lambda}$ is in $A^{b}$. By Lemma 5.4.3, $\\operatorname*{lim}c_{\\lambda}$ is also in $W$. By definition, $A_{s a}^{b}$ is the smallest $\\sigma$-closed subspace of $A^{\\prime\\prime}_{s a}$ which contains all $x$ that correspond to lower semi-continuous affine functions on $K$. So $A^{b}\\subset W$. Let $q$ be the restriction of $k$ to $A^{b}$.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Theorem 5.4.6 Let $A$ be monotone complete. There exists a $\\sigma$ -homomorphism $q$ from $A^{b}$ onto $A$ such that $q(a)=a$ for each $a\\in A$. Then $A^{b}\\cap{\\mathcal{N}}$ is a $\\sigma$-ideal of $A^{b}$ and is the kernel of $q$. So $A$ is isomorphic to $A^{b}/(A^{b}\\cap\\mathcal{N})$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/(Springer_Monographs_in_Mathematics)_Kazuyuki_SaitA\u0303\u00b4,_J._D._Maitland_Wright_-_Monotone_Complete_C_-algebras_and_Generic_Dynamics-Springer_(2015).pdf_122",
        "ID": "0021b632-3246-47d9-bb29-66398e4a295d",
        "questions": "In the context of Theorem 5.4.5, which algebra is the complex linear span of another set, and what is that set?",
        "answers": "The algebra $\\mathcal{N}$ is the complex linear span of $\\mathcal{M}^{+}$.",
        "context": "It follows that $(d_{n})$ is a sequence in $\\mathcal{N}$ which converges in the weak operator topology to $\\operatorname*{lim}w_{n}-\\operatorname*{lim}c_{n}$. Since $\\mathcal{N}$ is sequentially closed in the weak operator topology and $\\operatorname{lim}c_{n}$ is in $W$, it follows that $\\operatorname*{lim}w_{n}$ is in $W$. So $W$ is $\\sigma$ -closed in $A^{\\prime\\prime}$. Also, by Lemma 5.4.3,\n\n$$\nk(\\operatorname*{lim}w_{n})=k(\\operatorname*{lim}c_{n})=c=\\bigvee_{n\\geq1}c_{n}=\\bigvee_{n\\geq1}k(w_{n}).\n$$\n\nWe now come to the representation theorem for monotone $\\sigma$-complete $C^{*}$-algebras.\n\nTheorem 5.4.5 Let $A$ be monotone $\\sigma$-complete. There exists a $\\sigma$-homomorphism $q$ from $A^{\\infty}$ onto $A$ such that $q(a)=a$ for each $a\\in A$. Then $A^{\\infty}\\cap\\mathcal{N}$ is a $\\sigma$-ideal of $A^{\\infty}$ and is the kernel of $q$. So $A$ is isomorphic to $A^{\\infty}/(A^{\\infty}\\cap\\mathcal{N})$.\n\nProof The smallest $\\sigma$-closed subspace of $A_{s a}^{\\prime\\prime}$ which contains $A_{s a}$ is $A_{s a}^{\\infty}$. So $A^{\\infty}\\subset W$. Let $q$ be the restriction of $k$ to $A^{\\infty}$. The result follows from Corollary 5.4.4.\n\nWe recall that the algebra $\\mathcal{N}$ is the complex linear span of $\\mathcal{M}^{+}$. We shall see from the results of Sect. 5.6, that in Theorem 5.6.5, we may replace $A^{\\infty}\\cap\\mathcal{N}$ by $A^{\\infty}\\cap\\mathcal{M}$.\n\nWhen specialized to commutative algebras, Theorem 5.4.5 corresponds to the Loomis-Sikorski theorem for Boolean $\\sigma$ -algebras [153].\n\nBy applying results of Birkhoff-Ulam for complete Boolean algebras, see Theorem 4.1.3, every commutative monotone complete $C^{*}$ -algebra can be represented as follows. Let $S$ be the spectrum of a commutative monotone complete $C^{*}$-algebra, then $C(S)$ is isomorphic to the quotient of the algebra of bounded Borel measurable functions on $S$ modulo the ideal of meagre Borel functions. This may be thought of as a special case, for commutative algebras, of the following representation theorem. See Theorem 4.2.9.\n\nTheorem 5.4.6 Let $A$ be monotone complete. There exists a $\\sigma$ -homomorphism $q$ from $A^{b}$ onto $A$ such that $q(a)=a$ for each $a\\in A$. Then $A^{b}\\cap{\\mathcal{N}}$ is a $\\sigma$-ideal of $A^{b}$ and is the kernel of $q$. So $A$ is isomorphic to $A^{b}/(A^{b}\\cap\\mathcal{N})$. Let $\\left(c_{\\lambda}\\right)$ be a norm bounded increasing net in $A_{s a}$ with least upper bound $c$ in $A_{s a}$. Let $\\operatorname*{lim}c_{\\lambda}$ be its strong (and so weak) operator limit in $A^{\\prime\\prime}$ (and so is in $A^{b}$), then\n\n$$\nq(\\operatorname*{lim}c_{\\lambda})=c.\n$$\n\nFurthermore, given $f\\in A_{s a}^{b}$, $q(f)\\leq0$ if and only if $f\\le0$ a.e. So $q(f)=0$ if, and only if, $f=0$ a.e.\n\nProof Let $\\left(c_{\\lambda}\\right)$ be a norm-bounded, upward directed net in $A_{s a}$. Then $\\operatorname*{lim}c_{\\lambda}$ is in $A^{b}$. By Lemma 5.4.3, $\\operatorname*{lim}c_{\\lambda}$ is also in $W$. By definition, $A_{s a}^{b}$ is the smallest $\\sigma$-closed subspace of $A^{\\prime\\prime}_{s a}$ which contains all $x$ that correspond to lower semi-continuous affine functions on $K$. So $A^{b}\\subset W$. Let $q$ be the restriction of $k$ to $A^{b}$.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "We recall that the algebra $\\mathcal{N}$ is the complex linear span of $\\mathcal{M}^{+}$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/(Springer_Monographs_in_Mathematics)_Kazuyuki_SaitA\u0303\u00b4,_J._D._Maitland_Wright_-_Monotone_Complete_C_-algebras_and_Generic_Dynamics-Springer_(2015).pdf_122",
        "ID": "002b2f92-8dc5-4bd9-a689-ef79f8c3c461",
        "questions": "What is the expression for the value of $k$ at the limit $\\operatorname*{lim}w_{n}$ in terms of $c_{n}$ when $\\operatorname*{lim}c_{n}$ is in $W$?",
        "answers": "$k(\\operatorname*{lim}w_{n})=c=\\bigvee_{n\\geq1}c_{n}=\\bigvee_{n\\geq1}k(w_{n})$",
        "context": "It follows that $(d_{n})$ is a sequence in $\\mathcal{N}$ which converges in the weak operator topology to $\\operatorname*{lim}w_{n}-\\operatorname*{lim}c_{n}$. Since $\\mathcal{N}$ is sequentially closed in the weak operator topology and $\\operatorname{lim}c_{n}$ is in $W$, it follows that $\\operatorname*{lim}w_{n}$ is in $W$. So $W$ is $\\sigma$ -closed in $A^{\\prime\\prime}$. Also, by Lemma 5.4.3,\n\n$$\nk(\\operatorname*{lim}w_{n})=k(\\operatorname*{lim}c_{n})=c=\\bigvee_{n\\geq1}c_{n}=\\bigvee_{n\\geq1}k(w_{n}).\n$$\n\nWe now come to the representation theorem for monotone $\\sigma$-complete $C^{*}$-algebras.\n\nTheorem 5.4.5 Let $A$ be monotone $\\sigma$-complete. There exists a $\\sigma$-homomorphism $q$ from $A^{\\infty}$ onto $A$ such that $q(a)=a$ for each $a\\in A$. Then $A^{\\infty}\\cap\\mathcal{N}$ is a $\\sigma$-ideal of $A^{\\infty}$ and is the kernel of $q$. So $A$ is isomorphic to $A^{\\infty}/(A^{\\infty}\\cap\\mathcal{N})$.\n\nProof The smallest $\\sigma$-closed subspace of $A_{s a}^{\\prime\\prime}$ which contains $A_{s a}$ is $A_{s a}^{\\infty}$. So $A^{\\infty}\\subset W$. Let $q$ be the restriction of $k$ to $A^{\\infty}$. The result follows from Corollary 5.4.4.\n\nWe recall that the algebra $\\mathcal{N}$ is the complex linear span of $\\mathcal{M}^{+}$. We shall see from the results of Sect. 5.6, that in Theorem 5.6.5, we may replace $A^{\\infty}\\cap\\mathcal{N}$ by $A^{\\infty}\\cap\\mathcal{M}$.\n\nWhen specialized to commutative algebras, Theorem 5.4.5 corresponds to the Loomis-Sikorski theorem for Boolean $\\sigma$ -algebras [153].\n\nBy applying results of Birkhoff-Ulam for complete Boolean algebras, see Theorem 4.1.3, every commutative monotone complete $C^{*}$ -algebra can be represented as follows. Let $S$ be the spectrum of a commutative monotone complete $C^{*}$-algebra, then $C(S)$ is isomorphic to the quotient of the algebra of bounded Borel measurable functions on $S$ modulo the ideal of meagre Borel functions. This may be thought of as a special case, for commutative algebras, of the following representation theorem. See Theorem 4.2.9.\n\nTheorem 5.4.6 Let $A$ be monotone complete. There exists a $\\sigma$ -homomorphism $q$ from $A^{b}$ onto $A$ such that $q(a)=a$ for each $a\\in A$. Then $A^{b}\\cap{\\mathcal{N}}$ is a $\\sigma$-ideal of $A^{b}$ and is the kernel of $q$. So $A$ is isomorphic to $A^{b}/(A^{b}\\cap\\mathcal{N})$. Let $\\left(c_{\\lambda}\\right)$ be a norm bounded increasing net in $A_{s a}$ with least upper bound $c$ in $A_{s a}$. Let $\\operatorname*{lim}c_{\\lambda}$ be its strong (and so weak) operator limit in $A^{\\prime\\prime}$ (and so is in $A^{b}$), then\n\n$$\nq(\\operatorname*{lim}c_{\\lambda})=c.\n$$\n\nFurthermore, given $f\\in A_{s a}^{b}$, $q(f)\\leq0$ if and only if $f\\le0$ a.e. So $q(f)=0$ if, and only if, $f=0$ a.e.\n\nProof Let $\\left(c_{\\lambda}\\right)$ be a norm-bounded, upward directed net in $A_{s a}$. Then $\\operatorname*{lim}c_{\\lambda}$ is in $A^{b}$. By Lemma 5.4.3, $\\operatorname*{lim}c_{\\lambda}$ is also in $W$. By definition, $A_{s a}^{b}$ is the smallest $\\sigma$-closed subspace of $A^{\\prime\\prime}_{s a}$ which contains all $x$ that correspond to lower semi-continuous affine functions on $K$. So $A^{b}\\subset W$. Let $q$ be the restriction of $k$ to $A^{b}$.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$k(\\operatorname*{lim}w_{n})=k(\\operatorname*{lim}c_{n})=c=\\bigvee_{n\\geq1}c_{n}=\\bigvee_{n\\geq1}k(w_{n}).$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/(Springer_Monographs_in_Mathematics)_Kazuyuki_SaitA\u0303\u00b4,_J._D._Maitland_Wright_-_Monotone_Complete_C_-algebras_and_Generic_Dynamics-Springer_(2015).pdf_122",
        "ID": "002f9cc4-096b-4aff-b5b7-751f497e28aa",
        "questions": "If $A$ is a monotone complete $C^{*}$-algebra, how is the operator limit $\\operatorname*{lim}c_{\\lambda}$ of a norm bounded increasing net $(c_{\\lambda})$ in $A_{s a}$ related to $c$ in $A_{s a}$?",
        "answers": "$q(\\operatorname*{lim}c_{\\lambda})=c$",
        "context": "It follows that $(d_{n})$ is a sequence in $\\mathcal{N}$ which converges in the weak operator topology to $\\operatorname*{lim}w_{n}-\\operatorname*{lim}c_{n}$. Since $\\mathcal{N}$ is sequentially closed in the weak operator topology and $\\operatorname{lim}c_{n}$ is in $W$, it follows that $\\operatorname*{lim}w_{n}$ is in $W$. So $W$ is $\\sigma$ -closed in $A^{\\prime\\prime}$. Also, by Lemma 5.4.3,\n\n$$\nk(\\operatorname*{lim}w_{n})=k(\\operatorname*{lim}c_{n})=c=\\bigvee_{n\\geq1}c_{n}=\\bigvee_{n\\geq1}k(w_{n}).\n$$\n\nWe now come to the representation theorem for monotone $\\sigma$-complete $C^{*}$-algebras.\n\nTheorem 5.4.5 Let $A$ be monotone $\\sigma$-complete. There exists a $\\sigma$-homomorphism $q$ from $A^{\\infty}$ onto $A$ such that $q(a)=a$ for each $a\\in A$. Then $A^{\\infty}\\cap\\mathcal{N}$ is a $\\sigma$-ideal of $A^{\\infty}$ and is the kernel of $q$. So $A$ is isomorphic to $A^{\\infty}/(A^{\\infty}\\cap\\mathcal{N})$.\n\nProof The smallest $\\sigma$-closed subspace of $A_{s a}^{\\prime\\prime}$ which contains $A_{s a}$ is $A_{s a}^{\\infty}$. So $A^{\\infty}\\subset W$. Let $q$ be the restriction of $k$ to $A^{\\infty}$. The result follows from Corollary 5.4.4.\n\nWe recall that the algebra $\\mathcal{N}$ is the complex linear span of $\\mathcal{M}^{+}$. We shall see from the results of Sect. 5.6, that in Theorem 5.6.5, we may replace $A^{\\infty}\\cap\\mathcal{N}$ by $A^{\\infty}\\cap\\mathcal{M}$.\n\nWhen specialized to commutative algebras, Theorem 5.4.5 corresponds to the Loomis-Sikorski theorem for Boolean $\\sigma$ -algebras [153].\n\nBy applying results of Birkhoff-Ulam for complete Boolean algebras, see Theorem 4.1.3, every commutative monotone complete $C^{*}$ -algebra can be represented as follows. Let $S$ be the spectrum of a commutative monotone complete $C^{*}$-algebra, then $C(S)$ is isomorphic to the quotient of the algebra of bounded Borel measurable functions on $S$ modulo the ideal of meagre Borel functions. This may be thought of as a special case, for commutative algebras, of the following representation theorem. See Theorem 4.2.9.\n\nTheorem 5.4.6 Let $A$ be monotone complete. There exists a $\\sigma$ -homomorphism $q$ from $A^{b}$ onto $A$ such that $q(a)=a$ for each $a\\in A$. Then $A^{b}\\cap{\\mathcal{N}}$ is a $\\sigma$-ideal of $A^{b}$ and is the kernel of $q$. So $A$ is isomorphic to $A^{b}/(A^{b}\\cap\\mathcal{N})$. Let $\\left(c_{\\lambda}\\right)$ be a norm bounded increasing net in $A_{s a}$ with least upper bound $c$ in $A_{s a}$. Let $\\operatorname*{lim}c_{\\lambda}$ be its strong (and so weak) operator limit in $A^{\\prime\\prime}$ (and so is in $A^{b}$), then\n\n$$\nq(\\operatorname*{lim}c_{\\lambda})=c.\n$$\n\nFurthermore, given $f\\in A_{s a}^{b}$, $q(f)\\leq0$ if and only if $f\\le0$ a.e. So $q(f)=0$ if, and only if, $f=0$ a.e.\n\nProof Let $\\left(c_{\\lambda}\\right)$ be a norm-bounded, upward directed net in $A_{s a}$. Then $\\operatorname*{lim}c_{\\lambda}$ is in $A^{b}$. By Lemma 5.4.3, $\\operatorname*{lim}c_{\\lambda}$ is also in $W$. By definition, $A_{s a}^{b}$ is the smallest $\\sigma$-closed subspace of $A^{\\prime\\prime}_{s a}$ which contains all $x$ that correspond to lower semi-continuous affine functions on $K$. So $A^{b}\\subset W$. Let $q$ be the restriction of $k$ to $A^{b}$.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Let $\\left(c_{\\lambda}\\right)$ be a norm bounded increasing net in $A_{s a}$ with least upper bound $c$ in $A_{s a}$. Let $\\operatorname*{lim}c_{\\lambda}$ be its strong (and so weak) operator limit in $A^{\\prime\\prime}$ (and so is in $A^{b}$), then  $q(\\operatorname*{lim}c_{\\lambda})=c.$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/(Springer_Monographs_in_Mathematics)_Kazuyuki_SaitA\u0303\u00b4,_J._D._Maitland_Wright_-_Monotone_Complete_C_-algebras_and_Generic_Dynamics-Springer_(2015).pdf_122",
        "ID": "0030f3fb-01f7-4027-955c-7e9f7a793d3e",
        "questions": "In the representation theorem for monotone complete $C^{*}$-algebras, under what condition is $q(f)=0$ for $f$ in $A_{s a}^{b}$?",
        "answers": "$f=0$ a.e.",
        "context": "It follows that $(d_{n})$ is a sequence in $\\mathcal{N}$ which converges in the weak operator topology to $\\operatorname*{lim}w_{n}-\\operatorname*{lim}c_{n}$. Since $\\mathcal{N}$ is sequentially closed in the weak operator topology and $\\operatorname{lim}c_{n}$ is in $W$, it follows that $\\operatorname*{lim}w_{n}$ is in $W$. So $W$ is $\\sigma$ -closed in $A^{\\prime\\prime}$. Also, by Lemma 5.4.3,\n\n$$\nk(\\operatorname*{lim}w_{n})=k(\\operatorname*{lim}c_{n})=c=\\bigvee_{n\\geq1}c_{n}=\\bigvee_{n\\geq1}k(w_{n}).\n$$\n\nWe now come to the representation theorem for monotone $\\sigma$-complete $C^{*}$-algebras.\n\nTheorem 5.4.5 Let $A$ be monotone $\\sigma$-complete. There exists a $\\sigma$-homomorphism $q$ from $A^{\\infty}$ onto $A$ such that $q(a)=a$ for each $a\\in A$. Then $A^{\\infty}\\cap\\mathcal{N}$ is a $\\sigma$-ideal of $A^{\\infty}$ and is the kernel of $q$. So $A$ is isomorphic to $A^{\\infty}/(A^{\\infty}\\cap\\mathcal{N})$.\n\nProof The smallest $\\sigma$-closed subspace of $A_{s a}^{\\prime\\prime}$ which contains $A_{s a}$ is $A_{s a}^{\\infty}$. So $A^{\\infty}\\subset W$. Let $q$ be the restriction of $k$ to $A^{\\infty}$. The result follows from Corollary 5.4.4.\n\nWe recall that the algebra $\\mathcal{N}$ is the complex linear span of $\\mathcal{M}^{+}$. We shall see from the results of Sect. 5.6, that in Theorem 5.6.5, we may replace $A^{\\infty}\\cap\\mathcal{N}$ by $A^{\\infty}\\cap\\mathcal{M}$.\n\nWhen specialized to commutative algebras, Theorem 5.4.5 corresponds to the Loomis-Sikorski theorem for Boolean $\\sigma$ -algebras [153].\n\nBy applying results of Birkhoff-Ulam for complete Boolean algebras, see Theorem 4.1.3, every commutative monotone complete $C^{*}$ -algebra can be represented as follows. Let $S$ be the spectrum of a commutative monotone complete $C^{*}$-algebra, then $C(S)$ is isomorphic to the quotient of the algebra of bounded Borel measurable functions on $S$ modulo the ideal of meagre Borel functions. This may be thought of as a special case, for commutative algebras, of the following representation theorem. See Theorem 4.2.9.\n\nTheorem 5.4.6 Let $A$ be monotone complete. There exists a $\\sigma$ -homomorphism $q$ from $A^{b}$ onto $A$ such that $q(a)=a$ for each $a\\in A$. Then $A^{b}\\cap{\\mathcal{N}}$ is a $\\sigma$-ideal of $A^{b}$ and is the kernel of $q$. So $A$ is isomorphic to $A^{b}/(A^{b}\\cap\\mathcal{N})$. Let $\\left(c_{\\lambda}\\right)$ be a norm bounded increasing net in $A_{s a}$ with least upper bound $c$ in $A_{s a}$. Let $\\operatorname*{lim}c_{\\lambda}$ be its strong (and so weak) operator limit in $A^{\\prime\\prime}$ (and so is in $A^{b}$), then\n\n$$\nq(\\operatorname*{lim}c_{\\lambda})=c.\n$$\n\nFurthermore, given $f\\in A_{s a}^{b}$, $q(f)\\leq0$ if and only if $f\\le0$ a.e. So $q(f)=0$ if, and only if, $f=0$ a.e.\n\nProof Let $\\left(c_{\\lambda}\\right)$ be a norm-bounded, upward directed net in $A_{s a}$. Then $\\operatorname*{lim}c_{\\lambda}$ is in $A^{b}$. By Lemma 5.4.3, $\\operatorname*{lim}c_{\\lambda}$ is also in $W$. By definition, $A_{s a}^{b}$ is the smallest $\\sigma$-closed subspace of $A^{\\prime\\prime}_{s a}$ which contains all $x$ that correspond to lower semi-continuous affine functions on $K$. So $A^{b}\\subset W$. Let $q$ be the restriction of $k$ to $A^{b}$.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$q(f)=0$ if, and only if, $f=0$ a.e.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/geo-12644.pdf_353",
        "ID": "003c6ab8-2d19-4cf0-8d43-8259815f9e34",
        "questions": "What causes Neptune's blue color?",
        "answers": "Frozen methane",
        "context": "Neptune's composition is that of a gas giant: (1) upper atmosphere, (2) atmosphere composed of hydrogen, helium, and methane gas, (3) mantle of water, ammonia, and methane ice, (4) core of rock and ice.\n\n# Extremes of Cold and Wind\n\nNeptune's blue color is mostly because of frozen methane $\\mathrm{(CH_{4})}$. When Voyager 2 visited Neptune in 1986, there was a large dark blue spot that scientists named the Great Dark Spot, south of the equator. When the Hubble Space Telescope took pictures of Neptune in 1994, the Great Dark Spot had disappeared but another dark spot had appeared north of the equator. Astronomers think that both of these spots represent gaps in the methane clouds on Neptune.\n\nThe changing appearance of Neptune is caused by its turbulent atmosphere. The winds on Neptune are stronger than on any other planet in the solar system, reaching speeds of $1{,}100\\ \\mathrm{km/h}$ $(700\\ \\mathrm{mi/h})$, close to the speed of sound. This extreme weather surprised astronomers, since the planet receives little energy from the Sun to power weather systems. Neptune is also one of the coldest places in the solar system. Temperatures at the top of the clouds are about $-218^{\\circ}\\mathrm{C}$ $(-360^{\\circ}\\mathrm{F})$.\n\n# Neptune's Rings and Moons\n\nNeptune has faint rings of ice and dust that may change or disappear in fairly short time frames.\n\nNeptune has 13 known moons. Triton, shown in Figure below, is the only one of them that has enough mass to be spherical in shape. Triton orbits in the direction opposite to the orbit of Neptune. Scientists think Triton did not form around Neptune, but instead was captured by Neptune's gravity as it passed by.\n\n![](images/660d642906a91322ae91fab30302c3497e27db226515392f1ed278df671b7311.jpg)\n\nThis image of Triton, Neptune's largest moon, was taken by Voyager 2 in 1989.\n\nFly by Neptune's moon Triton by watching this video: http://www.space.com/common/media/video/player.php?videoRef=mm32_SunDeath#playerTop.\n\n# Lesson Summary\n\n- The four outer planets are all gas giants made primarily of hydrogen and helium. They have thick gaseous outer layers and liquid interiors.\n\n- The outer planets have numerous moons, as well as planetary rings.\n\n- Jupiter, by far the largest planet in the solar system, has bands of different colored clouds, and a long-lasting storm called the Great Red Spot.\n\n- Jupiter has more than 60 moons including the four largest, the Galilean moons.\n\n- Europa has an ocean of liquid water under a layer of ice where life may have formed.\n\n- Saturn is smaller than Jupiter but has a large system of beautiful rings.\n\n- Titan's atmosphere is similar to early Earth's and the moon could harbor primitive life.\n\n- Uranus and Neptune were discovered relatively recently since they are so far away.\n\n- Uranus is tilted on its side, probably because of a past collision with a large object.\n\n- Neptune is very cold and has strong winds. Its dark spots are storms in Neptune's atmosphere.\n\n# Review Questions\n\n1. Name the outer planets a) in order from the Sun outward, b) from largest to smallest by mass, and c) from largest to smallest by size.\n\n2. Why are the outer planets called gas giants?\n\n3. How do the Great Red Spot and Great Dark Spot differ?\n\n4. Name the Galilean moons, and explain why they have that name.\n\n5. Why might Europa be a likely place to find extraterrestrial life?",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Neptune's blue color is mostly because of frozen methane $(\\mathrm{CH_{4}})$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/geo-12644.pdf_353",
        "ID": "0042d740-0c34-439f-ad44-e0f06a9e72f8",
        "questions": "How many moons does Neptune have, and which moon is massive enough to be spherical in shape?",
        "answers": "Neptune has 13 known moons; Triton is the only one massive enough to be spherical in shape.",
        "context": "Neptune's composition is that of a gas giant: (1) upper atmosphere, (2) atmosphere composed of hydrogen, helium, and methane gas, (3) mantle of water, ammonia, and methane ice, (4) core of rock and ice.\n\n# Extremes of Cold and Wind\n\nNeptune's blue color is mostly because of frozen methane $\\mathrm{(CH_{4})}$. When Voyager 2 visited Neptune in 1986, there was a large dark blue spot that scientists named the Great Dark Spot, south of the equator. When the Hubble Space Telescope took pictures of Neptune in 1994, the Great Dark Spot had disappeared but another dark spot had appeared north of the equator. Astronomers think that both of these spots represent gaps in the methane clouds on Neptune.\n\nThe changing appearance of Neptune is caused by its turbulent atmosphere. The winds on Neptune are stronger than on any other planet in the solar system, reaching speeds of $1{,}100\\ \\mathrm{km/h}$ $(700\\ \\mathrm{mi/h})$, close to the speed of sound. This extreme weather surprised astronomers, since the planet receives little energy from the Sun to power weather systems. Neptune is also one of the coldest places in the solar system. Temperatures at the top of the clouds are about $-218^{\\circ}\\mathrm{C}$ $(-360^{\\circ}\\mathrm{F})$.\n\n# Neptune's Rings and Moons\n\nNeptune has faint rings of ice and dust that may change or disappear in fairly short time frames.\n\nNeptune has 13 known moons. Triton, shown in Figure below, is the only one of them that has enough mass to be spherical in shape. Triton orbits in the direction opposite to the orbit of Neptune. Scientists think Triton did not form around Neptune, but instead was captured by Neptune's gravity as it passed by.\n\n![](images/660d642906a91322ae91fab30302c3497e27db226515392f1ed278df671b7311.jpg)\n\nThis image of Triton, Neptune's largest moon, was taken by Voyager 2 in 1989.\n\nFly by Neptune's moon Triton by watching this video: http://www.space.com/common/media/video/player.php?videoRef=mm32_SunDeath#playerTop.\n\n# Lesson Summary\n\n- The four outer planets are all gas giants made primarily of hydrogen and helium. They have thick gaseous outer layers and liquid interiors.\n\n- The outer planets have numerous moons, as well as planetary rings.\n\n- Jupiter, by far the largest planet in the solar system, has bands of different colored clouds, and a long-lasting storm called the Great Red Spot.\n\n- Jupiter has more than 60 moons including the four largest, the Galilean moons.\n\n- Europa has an ocean of liquid water under a layer of ice where life may have formed.\n\n- Saturn is smaller than Jupiter but has a large system of beautiful rings.\n\n- Titan's atmosphere is similar to early Earth's and the moon could harbor primitive life.\n\n- Uranus and Neptune were discovered relatively recently since they are so far away.\n\n- Uranus is tilted on its side, probably because of a past collision with a large object.\n\n- Neptune is very cold and has strong winds. Its dark spots are storms in Neptune's atmosphere.\n\n# Review Questions\n\n1. Name the outer planets a) in order from the Sun outward, b) from largest to smallest by mass, and c) from largest to smallest by size.\n\n2. Why are the outer planets called gas giants?\n\n3. How do the Great Red Spot and Great Dark Spot differ?\n\n4. Name the Galilean moons, and explain why they have that name.\n\n5. Why might Europa be a likely place to find extraterrestrial life?",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Neptune has 13 known moons. Triton, shown in Figure below, is the only one of them that has enough mass to be spherical in shape.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/geo-12644.pdf_353",
        "ID": "004cdaf0-0ed9-4a32-8f0f-a9db4b6a3fea",
        "questions": "What was the speed of the winds observed on Neptune, and why did this phenomenon surprise astronomers?",
        "answers": "The winds on Neptune reached speeds of $1{,}100\\ \\mathrm{km/h}$ $(700\\ \\mathrm{mi/h})$, surprising astronomers because the planet receives little energy from the Sun to power weather systems.",
        "context": "Neptune's composition is that of a gas giant: (1) upper atmosphere, (2) atmosphere composed of hydrogen, helium, and methane gas, (3) mantle of water, ammonia, and methane ice, (4) core of rock and ice.\n\n# Extremes of Cold and Wind\n\nNeptune's blue color is mostly because of frozen methane $\\mathrm{(CH_{4})}$. When Voyager 2 visited Neptune in 1986, there was a large dark blue spot that scientists named the Great Dark Spot, south of the equator. When the Hubble Space Telescope took pictures of Neptune in 1994, the Great Dark Spot had disappeared but another dark spot had appeared north of the equator. Astronomers think that both of these spots represent gaps in the methane clouds on Neptune.\n\nThe changing appearance of Neptune is caused by its turbulent atmosphere. The winds on Neptune are stronger than on any other planet in the solar system, reaching speeds of $1{,}100\\ \\mathrm{km/h}$ $(700\\ \\mathrm{mi/h})$, close to the speed of sound. This extreme weather surprised astronomers, since the planet receives little energy from the Sun to power weather systems. Neptune is also one of the coldest places in the solar system. Temperatures at the top of the clouds are about $-218^{\\circ}\\mathrm{C}$ $(-360^{\\circ}\\mathrm{F})$.\n\n# Neptune's Rings and Moons\n\nNeptune has faint rings of ice and dust that may change or disappear in fairly short time frames.\n\nNeptune has 13 known moons. Triton, shown in Figure below, is the only one of them that has enough mass to be spherical in shape. Triton orbits in the direction opposite to the orbit of Neptune. Scientists think Triton did not form around Neptune, but instead was captured by Neptune's gravity as it passed by.\n\n![](images/660d642906a91322ae91fab30302c3497e27db226515392f1ed278df671b7311.jpg)\n\nThis image of Triton, Neptune's largest moon, was taken by Voyager 2 in 1989.\n\nFly by Neptune's moon Triton by watching this video: http://www.space.com/common/media/video/player.php?videoRef=mm32_SunDeath#playerTop.\n\n# Lesson Summary\n\n- The four outer planets are all gas giants made primarily of hydrogen and helium. They have thick gaseous outer layers and liquid interiors.\n\n- The outer planets have numerous moons, as well as planetary rings.\n\n- Jupiter, by far the largest planet in the solar system, has bands of different colored clouds, and a long-lasting storm called the Great Red Spot.\n\n- Jupiter has more than 60 moons including the four largest, the Galilean moons.\n\n- Europa has an ocean of liquid water under a layer of ice where life may have formed.\n\n- Saturn is smaller than Jupiter but has a large system of beautiful rings.\n\n- Titan's atmosphere is similar to early Earth's and the moon could harbor primitive life.\n\n- Uranus and Neptune were discovered relatively recently since they are so far away.\n\n- Uranus is tilted on its side, probably because of a past collision with a large object.\n\n- Neptune is very cold and has strong winds. Its dark spots are storms in Neptune's atmosphere.\n\n# Review Questions\n\n1. Name the outer planets a) in order from the Sun outward, b) from largest to smallest by mass, and c) from largest to smallest by size.\n\n2. Why are the outer planets called gas giants?\n\n3. How do the Great Red Spot and Great Dark Spot differ?\n\n4. Name the Galilean moons, and explain why they have that name.\n\n5. Why might Europa be a likely place to find extraterrestrial life?",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "The winds on Neptune are stronger than on any other planet in the solar system, reaching speeds of $1{,}100\\ \\mathrm{km/h}$ $(700\\ \\mathrm{mi/h})$, close to the speed of sound. This extreme weather surprised astronomers, since the planet receives little energy from the Sun to power weather systems.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/c04_874768_mt.pdf_6",
        "ID": "00513063-020a-4a12-855d-fed45fa7cb00",
        "questions": "What are some important questions to consider when faced with an ethical decision, particularly regarding the legality and impact on others?",
        "answers": "[\"Is it against the law?\", \"Does it violate company or professional policies?\", \"Even if everyone is doing it, how would I feel if someone did this to me?\", \"Am I sacrificing long-term benefits for short-term gains?\"]",
        "context": "# As You Read  \n\nConsider a conflict of interest you have encountered in your life. How did you resolve it?  \n\n# Ethical Questions  \n\nWhen you encounter an ethical decision and must choose a course of action, ask yourself these important questions:  \n\n- Is it against the law? Does it violate company or professional policies? \n- Even if everyone is doing it, how would I feel if someone did this to me? \n- Am I sacrificing long-term benefits for short-term gains?  \n\n# The Ethical Decision-Making Process  \n\nHere are some steps to take if you find yourself in an ethical dilemma:  \n\n1. Identify the ethical dilemma. \n2. Discover alternative actions.\n3. Decide who might be affected. \n4. List the probable effects of the alternatives.\n5. Select the best alternative.  \n\nUsing this process will enable you to make a more informed ethical choice. Making an ethical decision involves more people than just you.  \n\n# Section 4.1  \n\n# After You Read  \n\n# Review Key Concepts  \n\n1. What is the difference between personal and business ethics?\n2. Describe some of the ways that unethical business practices can affect a business.\n3. What is the relationship between illegal behaviors of business and unethical behaviors of business?  \n\n# Academic Skills  \n\n4.1 Mathematics A large company decided $\\frac{1}{8}$ of its profits to charity. If the amount given was spread equally among five different charities, what fraction of the company's profits was given to each? What percent of the company's profits is this?  \n\n# CONCEPT  \n\nNumber and Operations: Dividing Fractions To divide a fraction, invert the divisor and multiply  \n\n![](images/f5998b24806bcd5d268d24d6c3a34f6363ef315bae2249873147339baf2842a7.jpg)  \n\nFor math help, go to the Math Appendix.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "When you encounter an ethical decision and must choose a course of action, ask yourself these important questions: Is it against the law? Does it violate company or professional policies? Even if everyone is doing it, how would I feel if someone did this to me? Am I sacrificing long-term benefits for short-term gains?",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/c04_874768_mt.pdf_6",
        "ID": "005476c7-d8f9-49cc-bed6-1fd50aeaebe2",
        "questions": "What fraction and percent of profits does a large company allocate to each of five charities if $\frac{1}{8}$ of its profits is distributed equally among them?",
        "answers": "The company gives $\frac{1}{40}$ of its profits to each charity, which is 2.5% of the company's profits.",
        "context": "# As You Read  \n\nConsider a conflict of interest you have encountered in your life. How did you resolve it?  \n\n# Ethical Questions  \n\nWhen you encounter an ethical decision and must choose a course of action, ask yourself these important questions:  \n\n- Is it against the law? Does it violate company or professional policies? \n- Even if everyone is doing it, how would I feel if someone did this to me? \n- Am I sacrificing long-term benefits for short-term gains?  \n\n# The Ethical Decision-Making Process  \n\nHere are some steps to take if you find yourself in an ethical dilemma:  \n\n1. Identify the ethical dilemma. \n2. Discover alternative actions.\n3. Decide who might be affected. \n4. List the probable effects of the alternatives.\n5. Select the best alternative.  \n\nUsing this process will enable you to make a more informed ethical choice. Making an ethical decision involves more people than just you.  \n\n# Section 4.1  \n\n# After You Read  \n\n# Review Key Concepts  \n\n1. What is the difference between personal and business ethics?\n2. Describe some of the ways that unethical business practices can affect a business.\n3. What is the relationship between illegal behaviors of business and unethical behaviors of business?  \n\n# Academic Skills  \n\n4.1 Mathematics A large company decided $\\frac{1}{8}$ of its profits to charity. If the amount given was spread equally among five different charities, what fraction of the company's profits was given to each? What percent of the company's profits is this?  \n\n# CONCEPT  \n\nNumber and Operations: Dividing Fractions To divide a fraction, invert the divisor and multiply  \n\n![](images/f5998b24806bcd5d268d24d6c3a34f6363ef315bae2249873147339baf2842a7.jpg)  \n\nFor math help, go to the Math Appendix.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Numeric",
        "evidence_source": "text",
        "evidence_context": "4.1 Mathematics A large company decided $\frac{1}{8}$ of its profits to charity. If the amount given was spread equally among five different charities, what fraction of the company's profits was given to each? What percent of the company's profits is this?",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/c04_874768_mt.pdf_6",
        "ID": "00650544-7a10-4917-ab53-0a1536681492",
        "questions": "In the ethical decision-making process, what are the essential steps to follow when you find yourself facing an ethical dilemma?",
        "answers": "[\"Identify the ethical dilemma.\",\"Discover alternative actions.\",\"Decide who might be affected.\",\"List the probable effects of the alternatives.\",\"Select the best alternative.\"]",
        "context": "# As You Read  \n\nConsider a conflict of interest you have encountered in your life. How did you resolve it?  \n\n# Ethical Questions  \n\nWhen you encounter an ethical decision and must choose a course of action, ask yourself these important questions:  \n\n- Is it against the law? Does it violate company or professional policies? \n- Even if everyone is doing it, how would I feel if someone did this to me? \n- Am I sacrificing long-term benefits for short-term gains?  \n\n# The Ethical Decision-Making Process  \n\nHere are some steps to take if you find yourself in an ethical dilemma:  \n\n1. Identify the ethical dilemma. \n2. Discover alternative actions.\n3. Decide who might be affected. \n4. List the probable effects of the alternatives.\n5. Select the best alternative.  \n\nUsing this process will enable you to make a more informed ethical choice. Making an ethical decision involves more people than just you.  \n\n# Section 4.1  \n\n# After You Read  \n\n# Review Key Concepts  \n\n1. What is the difference between personal and business ethics?\n2. Describe some of the ways that unethical business practices can affect a business.\n3. What is the relationship between illegal behaviors of business and unethical behaviors of business?  \n\n# Academic Skills  \n\n4.1 Mathematics A large company decided $\\frac{1}{8}$ of its profits to charity. If the amount given was spread equally among five different charities, what fraction of the company's profits was given to each? What percent of the company's profits is this?  \n\n# CONCEPT  \n\nNumber and Operations: Dividing Fractions To divide a fraction, invert the divisor and multiply  \n\n![](images/f5998b24806bcd5d268d24d6c3a34f6363ef315bae2249873147339baf2842a7.jpg)  \n\nFor math help, go to the Math Appendix.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Here are some steps to take if you find yourself in an ethical dilemma: Identify the ethical dilemma. Discover alternative actions. Decide who might be affected. List the probable effects of the alternatives. Select the best alternative.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/med-67540.pdf_21",
        "ID": "006baa01-fdbc-46e7-8734-baefc2e4866f",
        "questions": "What educational qualifications are typically necessary for a medical social worker to practice?",
        "answers": "A medical social worker typically requires at least a bachelor's degree, licensed within the state they practice, with clinical social workers needing a master's degree and two years post-masters supervised clinical experience.",
        "context": "# Registered Dietician I (RD)  \n\nA registered dietician evaluates a patient's nutritional intake and orders special diets for the patient to follow. They provide education to patients and families about special diets to manage their illness and to improve their nutrition. RDs must have completed a bachelor's degree and often have a master's degree. Most states require certification or license to practice.  \n\n# Medical Social Worker (MSW)  \n\nA medical social worker works with the patient and family to help them get support services such as counseling, financial assistance, and community services. An MSW provides emotional support to the family and works as an advocate to help meet the patient's needs. Social workers typically have at least a bachelor's degree. Clinical social workers must have a master's degree and two years post-masters supervised clinical experience. MSWs must be licensed within the state they practice.  \n\n# Home Health Aide (HHA)  \n\nUnder the supervision of a nurse, a HHA provides supportive care to patients within their homes. They work to increase or maintain independence, health, and well-being of the patient. HHAs provide or assist with self-care activities such as bathing, dressing, grooming, toileting, feeding, skin care, use of medical supplies and equipment such as walkers and wheelchairs, and assisting with light housework, laundry, and home safety. Depending on the state in which they live and if they work in a certified home health agency, home health aides (HHAs) must be certified and complete training programs.  \n\n# Personal Care Aide (PCA)  \n\nUnder the supervision of a nurse, a PCA provides self-care and companionship to a patient. They assist with self-care activities such as bathing, dressing, grooming, toileting, feeding, skin care, and use of assistive devices such as walkers and wheelchairs. They also assist with housekeeping tasks such as laundry, changing bed linens, washing dishes, and preparing meals. Personal care aides may not perform any type of medical service or task, as a Home Health Aide may. A PCA may not take vital signs or glucose meter readings. Personal Care Aides are usually trained on the job. There are no educational requirements to become a PCA, but most PCAs have a high school diploma.  \n\n# Patient/Family  \n\nThe patient and their family are the most important parts of the health care team. Patients have the right to make decisions about their healthcare. They have a right to be informed about treatments and the care they receive. They have a right to refuse treatments, medications, and services. All patients and their families are unique and have various needs, desires, cultures, and traditions. It is important that the healthcare team respect these individual differences and work to meet each patient's needs. Without the patient, there can be no healthcare team.  \n\n# Self Check Activity  \n\nMatch the team member with the role they play:  \n\n\\begin{tabular}{|l|l|}\n \nTeam Member           & Role                                                                                                               \\\\  \n1. Home Health Aide            & g. Under supervision, provides and assists patients with self-care such as bathing, dressing, and feeding, and performs household tasks. They may not perform medically related tasks. \\\\  \n2. Registered Nurse            & e. Under supervision of an RN, administers medications, performs dressing changes, and monitors vital signs.                  \\\\  \n3. Occupational Therapist      & d. Teaches a patient to use assistive or adaptive devices so they may perform activities of daily living.                     \\\\  \n4. Medical Social Worker       & b. Most important team member, has the right to be involved in care and refuse treatments.                                    \\\\  \n5. Registered Dietician        & c. Assesses a patient\u2019s nutritional status and suggests special diets.                                                       \\\\  \n6. Physician                   & a. Oversees care, makes diagnoses, and prescribes medications.                                                               \\\\  \n7. Patient                     & f. Helps restore mobility and prevent injury by working with patients to perform exercises and use special equipment such as wheelchairs. \\\\  \n\\end{tabular}",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Social workers typically have at least a bachelor's degree. Clinical social workers must have a master's degree and two years post-masters supervised clinical experience. MSWs must be licensed within the state they practice.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/med-67540.pdf_21",
        "ID": "007b0a78-f278-4163-9312-8e5cbea3351d",
        "questions": "Can a personal care aide (PCA) perform medical services such as taking vital signs?",
        "answers": "No",
        "context": "# Registered Dietician I (RD)  \n\nA registered dietician evaluates a patient's nutritional intake and orders special diets for the patient to follow. They provide education to patients and families about special diets to manage their illness and to improve their nutrition. RDs must have completed a bachelor's degree and often have a master's degree. Most states require certification or license to practice.  \n\n# Medical Social Worker (MSW)  \n\nA medical social worker works with the patient and family to help them get support services such as counseling, financial assistance, and community services. An MSW provides emotional support to the family and works as an advocate to help meet the patient's needs. Social workers typically have at least a bachelor's degree. Clinical social workers must have a master's degree and two years post-masters supervised clinical experience. MSWs must be licensed within the state they practice.  \n\n# Home Health Aide (HHA)  \n\nUnder the supervision of a nurse, a HHA provides supportive care to patients within their homes. They work to increase or maintain independence, health, and well-being of the patient. HHAs provide or assist with self-care activities such as bathing, dressing, grooming, toileting, feeding, skin care, use of medical supplies and equipment such as walkers and wheelchairs, and assisting with light housework, laundry, and home safety. Depending on the state in which they live and if they work in a certified home health agency, home health aides (HHAs) must be certified and complete training programs.  \n\n# Personal Care Aide (PCA)  \n\nUnder the supervision of a nurse, a PCA provides self-care and companionship to a patient. They assist with self-care activities such as bathing, dressing, grooming, toileting, feeding, skin care, and use of assistive devices such as walkers and wheelchairs. They also assist with housekeeping tasks such as laundry, changing bed linens, washing dishes, and preparing meals. Personal care aides may not perform any type of medical service or task, as a Home Health Aide may. A PCA may not take vital signs or glucose meter readings. Personal Care Aides are usually trained on the job. There are no educational requirements to become a PCA, but most PCAs have a high school diploma.  \n\n# Patient/Family  \n\nThe patient and their family are the most important parts of the health care team. Patients have the right to make decisions about their healthcare. They have a right to be informed about treatments and the care they receive. They have a right to refuse treatments, medications, and services. All patients and their families are unique and have various needs, desires, cultures, and traditions. It is important that the healthcare team respect these individual differences and work to meet each patient's needs. Without the patient, there can be no healthcare team.  \n\n# Self Check Activity  \n\nMatch the team member with the role they play:  \n\n\\begin{tabular}{|l|l|}\n \nTeam Member           & Role                                                                                                               \\\\  \n1. Home Health Aide            & g. Under supervision, provides and assists patients with self-care such as bathing, dressing, and feeding, and performs household tasks. They may not perform medically related tasks. \\\\  \n2. Registered Nurse            & e. Under supervision of an RN, administers medications, performs dressing changes, and monitors vital signs.                  \\\\  \n3. Occupational Therapist      & d. Teaches a patient to use assistive or adaptive devices so they may perform activities of daily living.                     \\\\  \n4. Medical Social Worker       & b. Most important team member, has the right to be involved in care and refuse treatments.                                    \\\\  \n5. Registered Dietician        & c. Assesses a patient\u2019s nutritional status and suggests special diets.                                                       \\\\  \n6. Physician                   & a. Oversees care, makes diagnoses, and prescribes medications.                                                               \\\\  \n7. Patient                     & f. Helps restore mobility and prevent injury by working with patients to perform exercises and use special equipment such as wheelchairs. \\\\  \n\\end{tabular}",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Yes/No",
        "evidence_source": "text",
        "evidence_context": "Personal care aides may not perform any type of medical service or task, as a Home Health Aide may. A PCA may not take vital signs or glucose meter readings.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/med-67540.pdf_21",
        "ID": "0097c49a-5570-4dc0-8805-fb35cba9748d",
        "questions": "According to the self-check activity table, what role is assigned to an occupational therapist?",
        "answers": "Teaches a patient to use assistive or adaptive devices so they may perform activities of daily living.",
        "context": "# Registered Dietician I (RD)  \n\nA registered dietician evaluates a patient's nutritional intake and orders special diets for the patient to follow. They provide education to patients and families about special diets to manage their illness and to improve their nutrition. RDs must have completed a bachelor's degree and often have a master's degree. Most states require certification or license to practice.  \n\n# Medical Social Worker (MSW)  \n\nA medical social worker works with the patient and family to help them get support services such as counseling, financial assistance, and community services. An MSW provides emotional support to the family and works as an advocate to help meet the patient's needs. Social workers typically have at least a bachelor's degree. Clinical social workers must have a master's degree and two years post-masters supervised clinical experience. MSWs must be licensed within the state they practice.  \n\n# Home Health Aide (HHA)  \n\nUnder the supervision of a nurse, a HHA provides supportive care to patients within their homes. They work to increase or maintain independence, health, and well-being of the patient. HHAs provide or assist with self-care activities such as bathing, dressing, grooming, toileting, feeding, skin care, use of medical supplies and equipment such as walkers and wheelchairs, and assisting with light housework, laundry, and home safety. Depending on the state in which they live and if they work in a certified home health agency, home health aides (HHAs) must be certified and complete training programs.  \n\n# Personal Care Aide (PCA)  \n\nUnder the supervision of a nurse, a PCA provides self-care and companionship to a patient. They assist with self-care activities such as bathing, dressing, grooming, toileting, feeding, skin care, and use of assistive devices such as walkers and wheelchairs. They also assist with housekeeping tasks such as laundry, changing bed linens, washing dishes, and preparing meals. Personal care aides may not perform any type of medical service or task, as a Home Health Aide may. A PCA may not take vital signs or glucose meter readings. Personal Care Aides are usually trained on the job. There are no educational requirements to become a PCA, but most PCAs have a high school diploma.  \n\n# Patient/Family  \n\nThe patient and their family are the most important parts of the health care team. Patients have the right to make decisions about their healthcare. They have a right to be informed about treatments and the care they receive. They have a right to refuse treatments, medications, and services. All patients and their families are unique and have various needs, desires, cultures, and traditions. It is important that the healthcare team respect these individual differences and work to meet each patient's needs. Without the patient, there can be no healthcare team.  \n\n# Self Check Activity  \n\nMatch the team member with the role they play:  \n\n\\begin{tabular}{|l|l|}\n \nTeam Member           & Role                                                                                                               \\\\  \n1. Home Health Aide            & g. Under supervision, provides and assists patients with self-care such as bathing, dressing, and feeding, and performs household tasks. They may not perform medically related tasks. \\\\  \n2. Registered Nurse            & e. Under supervision of an RN, administers medications, performs dressing changes, and monitors vital signs.                  \\\\  \n3. Occupational Therapist      & d. Teaches a patient to use assistive or adaptive devices so they may perform activities of daily living.                     \\\\  \n4. Medical Social Worker       & b. Most important team member, has the right to be involved in care and refuse treatments.                                    \\\\  \n5. Registered Dietician        & c. Assesses a patient\u2019s nutritional status and suggests special diets.                                                       \\\\  \n6. Physician                   & a. Oversees care, makes diagnoses, and prescribes medications.                                                               \\\\  \n7. Patient                     & f. Helps restore mobility and prevent injury by working with patients to perform exercises and use special equipment such as wheelchairs. \\\\  \n\\end{tabular}",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "table",
        "evidence_context": "3. Occupational Therapist      & d. Teaches a patient to use assistive or adaptive devices so they may perform activities of daily living.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/biz-96816.pdf_48",
        "ID": "00a1402e-57e7-4f7b-8486-10cfd21276c2",
        "questions": "What is meant by the term 'issue spot' in a legal context, and why is it important for exams?",
        "answers": "Issue spotting is the process of identifying the 'issues' or questions to solve in a hypothetical story. It helps determine what legal problems need to be addressed.",
        "context": "NOT outline. Think about how you want to organize your essay. Are all issues created equally? What is your plan to address all issues?\n\nA good way to outline is to organize your facts as we discussed above. For example, think back to that table:\n\n$\n\\begin{tabular}{|l|p{4cm}|p{4cm}|p{3cm}|}\n \nRule Element & Facts For & Facts Against & Resolution \\\\\n \nSelf-propelled & Motor scooters have an engine and can move without \u201cmanpower\u201d & Can also move with only manpower, meaning the rider can use their feet to get it to move & Which is the predominant use? \\\\\n \nNot running on rails & No rails on a motor scooter &  &  \\\\\n \nRuns over land & Can't fly &  &  \\\\\n \n\\end{tabular}\n$\n\nYou might notice that there isn't much to talk about with \u201cruns over land.\u201d I mean, a motorized scooter certainly doesn't fly in the air, so this feels obvious. But \u201cself-propelled\u201d seems to have more to discuss! So that means you will likely want to spend more time on the issue of whether a motor scooter is self-propelled than whether it runs over land.\n\nIf there are multiple issues, you can also use this type of chart to determine which issue requires the most time.\n\nSpeaking of issues, outlining will help you issue spot. You will hear this as a buzzword all around: that you need to \u201cspot the issues\u201d or \u201cissue spot.\u201d But what does that mean? Remember that a hypothetical is essentially a story. So your job is to read the story and determine the \u201cissues\u201d or questions to solve. A professor may ask you a very directed question, such as \u201cDid Defendant commit murder?\u201d, in which case, your issue-spotting just got much easier! However, it is more than likely that the professor will end the hypothetical story with \u201cWhat are the rights of the parties?\u201d or \u201cWhat crimes can Bob be charged with?\u201d\n\nThis means that a large part of earning points on your exam is figuring out what issues, or legal problems, to solve. Everyone tackles this in a slightly different way. However, I suggest taking one of the two methods described below and making it your own.\n\n# ISSue Spotting Method 1: The Checklist\n\nIn doing the outlining that I mentioned above, you can create a mini-outline or \u201cattack outline,\u201d which is what I just call a checklist. Essentially, it should be a one-page list of the types of law you covered. For example, in a torts class, you are going to cover various types of torts. Therefore, your checklist might look something like this:\n\n1. Intentional Torts\n\na. Assault b. Battery c. False Imprisonment d. Trespass e. Trespass to Chattels f. Conversion Negligence\n\nNote that this is an incomplete checklist, and the complete version will look different depending on your professor and class. The idea is that if I have this memorized, I can quickly go through the fact pattern to see if any of the torts show up. Part of your checklist might also be to add in \u201cactivating facts.\u201d What I mean by that is, if you are looking for an assault, or a battery, what are you looking for?\n\nFor example, for battery, I might know that I need a person in the fact pattern to touch another person, so I'm indicating that in my checklist. I can go through the story and think, \u201cAlright, is anyone touching someone else? If so, could that be a battery? Similarly, trespass requires land or entering the land of another. Is that showing up in the facts?\u201d Adding these types of \u201cactivating facts\u201d to our checklist might look like this:\n\n1. Intentional Torts \n\na. Assault",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Speaking of issues, outlining will help you issue spot. You will hear this as a buzzword all around: that you need to \u201cspot the issues\u201d or \u201cissue spot.\u201d But what does that mean? Remember that a hypothetical is essentially a story. So your job is to read the story and determine the 'issues' or questions to solve. A professor may ask you a very directed question, such as 'Did Defendant commit murder?', in which case, your issue-spotting just got much easier! However, it is more than likely that the professor will end the hypothetical story with 'What are the rights of the parties?' or 'What crimes can Bob be charged with?'",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/biz-96816.pdf_48",
        "ID": "00a594c2-0d4e-4d06-8c16-4ccabbfcc661",
        "questions": "What example is given in the document to demonstrate a scenario where multiple facts need to be considered for determining whether an entity is self-propelled?",
        "answers": "Motor scooters have an engine and can move without 'manpower' & Can also move with only manpower, meaning the rider can use their feet to get it to move.",
        "context": "NOT outline. Think about how you want to organize your essay. Are all issues created equally? What is your plan to address all issues?\n\nA good way to outline is to organize your facts as we discussed above. For example, think back to that table:\n\n$\n\\begin{tabular}{|l|p{4cm}|p{4cm}|p{3cm}|}\n \nRule Element & Facts For & Facts Against & Resolution \\\\\n \nSelf-propelled & Motor scooters have an engine and can move without \u201cmanpower\u201d & Can also move with only manpower, meaning the rider can use their feet to get it to move & Which is the predominant use? \\\\\n \nNot running on rails & No rails on a motor scooter &  &  \\\\\n \nRuns over land & Can't fly &  &  \\\\\n \n\\end{tabular}\n$\n\nYou might notice that there isn't much to talk about with \u201cruns over land.\u201d I mean, a motorized scooter certainly doesn't fly in the air, so this feels obvious. But \u201cself-propelled\u201d seems to have more to discuss! So that means you will likely want to spend more time on the issue of whether a motor scooter is self-propelled than whether it runs over land.\n\nIf there are multiple issues, you can also use this type of chart to determine which issue requires the most time.\n\nSpeaking of issues, outlining will help you issue spot. You will hear this as a buzzword all around: that you need to \u201cspot the issues\u201d or \u201cissue spot.\u201d But what does that mean? Remember that a hypothetical is essentially a story. So your job is to read the story and determine the \u201cissues\u201d or questions to solve. A professor may ask you a very directed question, such as \u201cDid Defendant commit murder?\u201d, in which case, your issue-spotting just got much easier! However, it is more than likely that the professor will end the hypothetical story with \u201cWhat are the rights of the parties?\u201d or \u201cWhat crimes can Bob be charged with?\u201d\n\nThis means that a large part of earning points on your exam is figuring out what issues, or legal problems, to solve. Everyone tackles this in a slightly different way. However, I suggest taking one of the two methods described below and making it your own.\n\n# ISSue Spotting Method 1: The Checklist\n\nIn doing the outlining that I mentioned above, you can create a mini-outline or \u201cattack outline,\u201d which is what I just call a checklist. Essentially, it should be a one-page list of the types of law you covered. For example, in a torts class, you are going to cover various types of torts. Therefore, your checklist might look something like this:\n\n1. Intentional Torts\n\na. Assault b. Battery c. False Imprisonment d. Trespass e. Trespass to Chattels f. Conversion Negligence\n\nNote that this is an incomplete checklist, and the complete version will look different depending on your professor and class. The idea is that if I have this memorized, I can quickly go through the fact pattern to see if any of the torts show up. Part of your checklist might also be to add in \u201cactivating facts.\u201d What I mean by that is, if you are looking for an assault, or a battery, what are you looking for?\n\nFor example, for battery, I might know that I need a person in the fact pattern to touch another person, so I'm indicating that in my checklist. I can go through the story and think, \u201cAlright, is anyone touching someone else? If so, could that be a battery? Similarly, trespass requires land or entering the land of another. Is that showing up in the facts?\u201d Adding these types of \u201cactivating facts\u201d to our checklist might look like this:\n\n1. Intentional Torts \n\na. Assault",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "table",
        "evidence_context": "Self-propelled: Motor scooters have an engine and can move without 'manpower' & Can also move with only manpower, meaning the rider can use their feet to get it to move & Which is the predominant use?",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/biz-96816.pdf_48",
        "ID": "00a89d2b-e1f4-4a00-a5ca-92bd745dc319",
        "questions": "How does the 'Checklist' method help in issue spotting during exams, according to the document, and provide an example given for torts?",
        "answers": "The 'Checklist' method helps by creating a mini-outline of the types of law covered. For example, in a torts class, the checklist might include items like Assault, Battery, False Imprisonment, Trespass, Trespass to Chattels, and Conversion Negligence.",
        "context": "NOT outline. Think about how you want to organize your essay. Are all issues created equally? What is your plan to address all issues?\n\nA good way to outline is to organize your facts as we discussed above. For example, think back to that table:\n\n$\n\\begin{tabular}{|l|p{4cm}|p{4cm}|p{3cm}|}\n \nRule Element & Facts For & Facts Against & Resolution \\\\\n \nSelf-propelled & Motor scooters have an engine and can move without \u201cmanpower\u201d & Can also move with only manpower, meaning the rider can use their feet to get it to move & Which is the predominant use? \\\\\n \nNot running on rails & No rails on a motor scooter &  &  \\\\\n \nRuns over land & Can't fly &  &  \\\\\n \n\\end{tabular}\n$\n\nYou might notice that there isn't much to talk about with \u201cruns over land.\u201d I mean, a motorized scooter certainly doesn't fly in the air, so this feels obvious. But \u201cself-propelled\u201d seems to have more to discuss! So that means you will likely want to spend more time on the issue of whether a motor scooter is self-propelled than whether it runs over land.\n\nIf there are multiple issues, you can also use this type of chart to determine which issue requires the most time.\n\nSpeaking of issues, outlining will help you issue spot. You will hear this as a buzzword all around: that you need to \u201cspot the issues\u201d or \u201cissue spot.\u201d But what does that mean? Remember that a hypothetical is essentially a story. So your job is to read the story and determine the \u201cissues\u201d or questions to solve. A professor may ask you a very directed question, such as \u201cDid Defendant commit murder?\u201d, in which case, your issue-spotting just got much easier! However, it is more than likely that the professor will end the hypothetical story with \u201cWhat are the rights of the parties?\u201d or \u201cWhat crimes can Bob be charged with?\u201d\n\nThis means that a large part of earning points on your exam is figuring out what issues, or legal problems, to solve. Everyone tackles this in a slightly different way. However, I suggest taking one of the two methods described below and making it your own.\n\n# ISSue Spotting Method 1: The Checklist\n\nIn doing the outlining that I mentioned above, you can create a mini-outline or \u201cattack outline,\u201d which is what I just call a checklist. Essentially, it should be a one-page list of the types of law you covered. For example, in a torts class, you are going to cover various types of torts. Therefore, your checklist might look something like this:\n\n1. Intentional Torts\n\na. Assault b. Battery c. False Imprisonment d. Trespass e. Trespass to Chattels f. Conversion Negligence\n\nNote that this is an incomplete checklist, and the complete version will look different depending on your professor and class. The idea is that if I have this memorized, I can quickly go through the fact pattern to see if any of the torts show up. Part of your checklist might also be to add in \u201cactivating facts.\u201d What I mean by that is, if you are looking for an assault, or a battery, what are you looking for?\n\nFor example, for battery, I might know that I need a person in the fact pattern to touch another person, so I'm indicating that in my checklist. I can go through the story and think, \u201cAlright, is anyone touching someone else? If so, could that be a battery? Similarly, trespass requires land or entering the land of another. Is that showing up in the facts?\u201d Adding these types of \u201cactivating facts\u201d to our checklist might look like this:\n\n1. Intentional Torts \n\na. Assault",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "In doing the outlining that I mentioned above, you can create a mini-outline or 'attack outline,' which is what I just call a checklist. Essentially, it should be a one-page list of the types of law you covered. For example, in a torts class, you are going to cover various types of torts. Therefore, your checklist might look something like this: 1. Intentional Torts a. Assault b. Battery c. False Imprisonment d. Trespass e. Trespass to Chattels f. Conversion Negligence",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Derivatives_In_Financial_Markets_With_Stochas.pdf_14",
        "ID": "00ac317a-dd82-4b3e-a868-5bdd02c81d11",
        "questions": "What is the definition of a Radon-Nikodym process for any 0 \u2264 s \u2264 t \u2264 T?",
        "answers": "The process $(\\xi_{t}^{\\theta})_{0 \\leq t \\leq T}$ is called the Radon-Nikodym process.",
        "context": "For any $0 \\leq s \\leq t \\leq T$, the process $(\\xi_{t}^{\\theta})_{0 \\leq t \\leq T}$ is called the Radon-Nikodym process.\n\nThe main result of this section asserts that the process $(W_{t}^{\\star})$ given by (1.45) is a standard Brownian motion under the probability $I\\!\\!P^{\\star}$: This result in its full generality (when $\\theta$ is an adapted stochastic process) is known as Girsanov's theorem. In our simple case ($\\theta$ constant), it is easily derived by using the characterization (1.3) and formula (1.49) as follows:\n\n$$\n\\begin{array}{r l}&{{I\\!\\!E}^{*}\\{e^{i u(W_{t}^{*}-W_{s}^{*})}\\mid\\mathcal F_{s}\\}=\\frac1{\\xi_{s}^{\\theta}}{I\\!\\!E}\\{\\xi_{t}^{\\theta}e^{i u(W_{t}^{*}-W_{s}^{*})}\\mid\\mathcal F_{s}\\}}\\\\ &{\\qquad\\qquad\\qquad=e^{\\theta W_{s}+\\theta^{2}s/2}{I\\!\\!E}\\{e^{-\\theta W_{t}-\\theta^{2}t/2}e^{i u(W_{t}-W_{s}+\\theta(t-s))}\\mid\\mathcal F_{s}\\}}\\\\ &{\\qquad\\qquad\\qquad=e^{(-\\theta^{2}/2+i u\\theta)(t-s)}{I\\!\\!E}\\{e^{i(u+i\\theta)(W_{t}-W_{s})}\\mid\\mathcal F_{s}\\}}\\\\ &{\\qquad\\qquad\\qquad=e^{(-\\theta^{2}/2+i u\\theta)(t-s)}e^{-(u+i\\theta)^{2}(t-s)/2}}\\\\ &{\\qquad\\qquad\\qquad=e^{-u^{2}(t-s)/2}.}\\end{array}\n$$\n\n# 1.4.2 Self-Financing Portfolios\n\nAs in Section 1.3.1, a portfolio comprises $a_{t}$ units of stock and $b_{t}$ in bonds; we denote by $V_{t}$ its value at time $t$\n\n$$\nV_{t}=a_{t}X_{t}+b_{t}e^{r t}.\n$$\n\nThe self-financing property (1.28), namely $d V_{t} = a_{t} d X_{t} + r b_{t} e^{r t} d t$, implies that the discounted value of the portfolio, $\\widetilde{V}_{t} = e^{-r t} V_{t}$, is a martingale under the risk-neutral probability $I\\!\\!P^{\\star}$. This important property of self-financing portfolios is obtained as follows:\n\n$$\n\\begin{array}{r l}&{d\\widetilde{V}_{t}=-r e^{-r t}V_{t}\\,d t+e^{-r t}\\,d V_{t}}\\\\ &{\\quad=-r e^{-r t}(a_{t}\\,X_{t}+b_{t}e^{r t})\\,d t+e^{-r t}(a_{t}\\,d X_{t}+r b_{t}e^{r t}\\,d t)}\\\\ &{\\quad=-r e^{-r t}a_{t}\\,X_{t}\\,d t+e^{-r t}a_{t}\\,d X_{t}}\\\\ &{\\quad=a_{t}\\,d(e^{-r t}X_{t})}\\\\ &{\\quad=a_{t}\\,d\\widetilde{X}_{t}}\\\\ &{\\quad=\\sigma a_{t}\\widetilde{X}_{t}\\,d W_{t}^{\\star}\\quad(\\mathrm{by~(1.46)}),}\\end{array}\n$$\n\nwhich shows that $(\\widetilde{V}_{t})$ is a martingale under $I\\!\\!P^{\\star}$ as a stochastic integral with respect to the Brownian motion $(\\boldsymbol{W}_{t}^{\\star})$. Indeed, the same computation shows that if a portfolio satisfies $d\\widetilde{V}_{t} = a_{t} d\\widetilde{X}_{t}$ then it is self-financing.\n\nA simple calculation demonstrates the connection between martingales and no arbitrage. Suppose that $(a_{t}, b_{t})_{0 \\leq t \\leq T}$ is a self-financing arbitrage strategy; that is,\n\n$$\nV_{T} \\geq e^{r T} V_{0} \\quad (I\\!\\!P\\mathrm{-a.s.}),\n$$\n\nwith\n\n$$\nI\\!\\!P\\{V_{T} > e^{r T} V_{0}\\} > 0,\n$$\n\nso that the strategy never makes less than money in the bank and there is some chance of making more. But\n\n$$\nI\\!\\!E^{\\star}\\{V_{T}\\} = e^{r T} V_{0}\n$$\n\nby the martingale property, so (1.51) and (1.52) cannot hold. This is because $I\\!\\!P$ and $I\\!\\!P^{\\star}$ are equivalent and so (1.51) and (1.52) also hold with $I\\!\\!P$ replaced by $I\\!\\!P^{\\star}$.\n\n# 1.4.3 Risk-Neutral Valuation\n\nAssume that $(a_{t}, b_{t})$ is a self-financing portfolio satisfying the same integrability conditions of Section 1.3.1 and replicating the European-style derivative with non-negative payoff $H$\n\n$$\na_{T} X_{T} + b_{T} e^{r T} = H,\n$$\n\nwhere we assume that $H$ is a square-integrable $\\mathcal{F}_{T}$-adapted random variable. This includes European calls and puts or more general standard European derivatives for which $H = h(X_{T})$, as well as other European-style exotic derivatives presented in Section 1.2.3.\n\nOn one hand, a no-arbitrage argument shows that the price at time $t$ of this derivative should be the value $V_{t}$ of this portfolio. On the other hand, as shown in Section 1.4.2, the discounted values $(\\widetilde{V}_{t})$ of this portfolio form a martingale under the risk-neutral probability $I\\!\\!\\!P^{\\star}$ and consequently\n\n$$\n\\widetilde{V}_{t} = I\\!\\!E^{\\star}\\{\\widetilde{V_{T}} \\mid \\mathcal{F}_{t}\\},\n$$\n\nwhich gives\n\n$$\nV_{t} = I\\!\\!E^{\\star}\\{e^{-r(T-t)} H \\mid \\mathcal{F}_{t}\\}\n$$\n\nafter reintroducing the discounting factor and using the replicating property (1.53). Alternatively, given the risk-neutral valuation formula (1.54), we can find a self-financing replicating portfolio for the payoff $H$. The existence of such a portfolio is guaranteed by an application of the martingale representation theorem: for $0 \\leq t \\leq T$\n\n$$\nM_{t} = I\\!E^{\\star}\\{e^{-r T} H \\mid \\mathcal{F}_{t}\\}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "For any $0 \\leq s \\leq t \\leq T$, the process $(\\xi_{t}^{\\theta})_{0 \\leq t \\leq T}$ is called the Radon-Nikodym process.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Derivatives_In_Financial_Markets_With_Stochas.pdf_14",
        "ID": "00afecfa-6ea0-41cc-9ec7-d2715034e9ff",
        "questions": "According to Girsanov's theorem, what property does the process $(W_{t}^{\\star})$ exhibit under the probability $I\\!\\!P^{\\star}$?",
        "answers": "The process $(W_{t}^{\\star})$ is a standard Brownian motion under the probability $I\\!\\!P^{\\star}$.",
        "context": "For any $0 \\leq s \\leq t \\leq T$, the process $(\\xi_{t}^{\\theta})_{0 \\leq t \\leq T}$ is called the Radon-Nikodym process.\n\nThe main result of this section asserts that the process $(W_{t}^{\\star})$ given by (1.45) is a standard Brownian motion under the probability $I\\!\\!P^{\\star}$: This result in its full generality (when $\\theta$ is an adapted stochastic process) is known as Girsanov's theorem. In our simple case ($\\theta$ constant), it is easily derived by using the characterization (1.3) and formula (1.49) as follows:\n\n$$\n\\begin{array}{r l}&{{I\\!\\!E}^{*}\\{e^{i u(W_{t}^{*}-W_{s}^{*})}\\mid\\mathcal F_{s}\\}=\\frac1{\\xi_{s}^{\\theta}}{I\\!\\!E}\\{\\xi_{t}^{\\theta}e^{i u(W_{t}^{*}-W_{s}^{*})}\\mid\\mathcal F_{s}\\}}\\\\ &{\\qquad\\qquad\\qquad=e^{\\theta W_{s}+\\theta^{2}s/2}{I\\!\\!E}\\{e^{-\\theta W_{t}-\\theta^{2}t/2}e^{i u(W_{t}-W_{s}+\\theta(t-s))}\\mid\\mathcal F_{s}\\}}\\\\ &{\\qquad\\qquad\\qquad=e^{(-\\theta^{2}/2+i u\\theta)(t-s)}{I\\!\\!E}\\{e^{i(u+i\\theta)(W_{t}-W_{s})}\\mid\\mathcal F_{s}\\}}\\\\ &{\\qquad\\qquad\\qquad=e^{(-\\theta^{2}/2+i u\\theta)(t-s)}e^{-(u+i\\theta)^{2}(t-s)/2}}\\\\ &{\\qquad\\qquad\\qquad=e^{-u^{2}(t-s)/2}.}\\end{array}\n$$\n\n# 1.4.2 Self-Financing Portfolios\n\nAs in Section 1.3.1, a portfolio comprises $a_{t}$ units of stock and $b_{t}$ in bonds; we denote by $V_{t}$ its value at time $t$\n\n$$\nV_{t}=a_{t}X_{t}+b_{t}e^{r t}.\n$$\n\nThe self-financing property (1.28), namely $d V_{t} = a_{t} d X_{t} + r b_{t} e^{r t} d t$, implies that the discounted value of the portfolio, $\\widetilde{V}_{t} = e^{-r t} V_{t}$, is a martingale under the risk-neutral probability $I\\!\\!P^{\\star}$. This important property of self-financing portfolios is obtained as follows:\n\n$$\n\\begin{array}{r l}&{d\\widetilde{V}_{t}=-r e^{-r t}V_{t}\\,d t+e^{-r t}\\,d V_{t}}\\\\ &{\\quad=-r e^{-r t}(a_{t}\\,X_{t}+b_{t}e^{r t})\\,d t+e^{-r t}(a_{t}\\,d X_{t}+r b_{t}e^{r t}\\,d t)}\\\\ &{\\quad=-r e^{-r t}a_{t}\\,X_{t}\\,d t+e^{-r t}a_{t}\\,d X_{t}}\\\\ &{\\quad=a_{t}\\,d(e^{-r t}X_{t})}\\\\ &{\\quad=a_{t}\\,d\\widetilde{X}_{t}}\\\\ &{\\quad=\\sigma a_{t}\\widetilde{X}_{t}\\,d W_{t}^{\\star}\\quad(\\mathrm{by~(1.46)}),}\\end{array}\n$$\n\nwhich shows that $(\\widetilde{V}_{t})$ is a martingale under $I\\!\\!P^{\\star}$ as a stochastic integral with respect to the Brownian motion $(\\boldsymbol{W}_{t}^{\\star})$. Indeed, the same computation shows that if a portfolio satisfies $d\\widetilde{V}_{t} = a_{t} d\\widetilde{X}_{t}$ then it is self-financing.\n\nA simple calculation demonstrates the connection between martingales and no arbitrage. Suppose that $(a_{t}, b_{t})_{0 \\leq t \\leq T}$ is a self-financing arbitrage strategy; that is,\n\n$$\nV_{T} \\geq e^{r T} V_{0} \\quad (I\\!\\!P\\mathrm{-a.s.}),\n$$\n\nwith\n\n$$\nI\\!\\!P\\{V_{T} > e^{r T} V_{0}\\} > 0,\n$$\n\nso that the strategy never makes less than money in the bank and there is some chance of making more. But\n\n$$\nI\\!\\!E^{\\star}\\{V_{T}\\} = e^{r T} V_{0}\n$$\n\nby the martingale property, so (1.51) and (1.52) cannot hold. This is because $I\\!\\!P$ and $I\\!\\!P^{\\star}$ are equivalent and so (1.51) and (1.52) also hold with $I\\!\\!P$ replaced by $I\\!\\!P^{\\star}$.\n\n# 1.4.3 Risk-Neutral Valuation\n\nAssume that $(a_{t}, b_{t})$ is a self-financing portfolio satisfying the same integrability conditions of Section 1.3.1 and replicating the European-style derivative with non-negative payoff $H$\n\n$$\na_{T} X_{T} + b_{T} e^{r T} = H,\n$$\n\nwhere we assume that $H$ is a square-integrable $\\mathcal{F}_{T}$-adapted random variable. This includes European calls and puts or more general standard European derivatives for which $H = h(X_{T})$, as well as other European-style exotic derivatives presented in Section 1.2.3.\n\nOn one hand, a no-arbitrage argument shows that the price at time $t$ of this derivative should be the value $V_{t}$ of this portfolio. On the other hand, as shown in Section 1.4.2, the discounted values $(\\widetilde{V}_{t})$ of this portfolio form a martingale under the risk-neutral probability $I\\!\\!\\!P^{\\star}$ and consequently\n\n$$\n\\widetilde{V}_{t} = I\\!\\!E^{\\star}\\{\\widetilde{V_{T}} \\mid \\mathcal{F}_{t}\\},\n$$\n\nwhich gives\n\n$$\nV_{t} = I\\!\\!E^{\\star}\\{e^{-r(T-t)} H \\mid \\mathcal{F}_{t}\\}\n$$\n\nafter reintroducing the discounting factor and using the replicating property (1.53). Alternatively, given the risk-neutral valuation formula (1.54), we can find a self-financing replicating portfolio for the payoff $H$. The existence of such a portfolio is guaranteed by an application of the martingale representation theorem: for $0 \\leq t \\leq T$\n\n$$\nM_{t} = I\\!E^{\\star}\\{e^{-r T} H \\mid \\mathcal{F}_{t}\\}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "The main result of this section asserts that the process $(W_{t}^{\\star})$ given by (1.45) is a standard Brownian motion under the probability $I\\!\\!P^{\\star}$: This result in its full generality (when $\\theta$ is an adapted stochastic process) is known as Girsanov's theorem.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Derivatives_In_Financial_Markets_With_Stochas.pdf_14",
        "ID": "00b425aa-e7eb-433c-ba08-79fbdc7843b3",
        "questions": "What is implied by the self-financing property in the context of portfolio management, in terms of the discounted value of the portfolio and the risk-neutral probability?",
        "answers": "The self-financing property implies that the discounted value of the portfolio, $\\widetilde{V}_{t} = e^{-r t} V_{t}$, is a martingale under the risk-neutral probability $I\\!\\!P^{\\star}$.",
        "context": "For any $0 \\leq s \\leq t \\leq T$, the process $(\\xi_{t}^{\\theta})_{0 \\leq t \\leq T}$ is called the Radon-Nikodym process.\n\nThe main result of this section asserts that the process $(W_{t}^{\\star})$ given by (1.45) is a standard Brownian motion under the probability $I\\!\\!P^{\\star}$: This result in its full generality (when $\\theta$ is an adapted stochastic process) is known as Girsanov's theorem. In our simple case ($\\theta$ constant), it is easily derived by using the characterization (1.3) and formula (1.49) as follows:\n\n$$\n\\begin{array}{r l}&{{I\\!\\!E}^{*}\\{e^{i u(W_{t}^{*}-W_{s}^{*})}\\mid\\mathcal F_{s}\\}=\\frac1{\\xi_{s}^{\\theta}}{I\\!\\!E}\\{\\xi_{t}^{\\theta}e^{i u(W_{t}^{*}-W_{s}^{*})}\\mid\\mathcal F_{s}\\}}\\\\ &{\\qquad\\qquad\\qquad=e^{\\theta W_{s}+\\theta^{2}s/2}{I\\!\\!E}\\{e^{-\\theta W_{t}-\\theta^{2}t/2}e^{i u(W_{t}-W_{s}+\\theta(t-s))}\\mid\\mathcal F_{s}\\}}\\\\ &{\\qquad\\qquad\\qquad=e^{(-\\theta^{2}/2+i u\\theta)(t-s)}{I\\!\\!E}\\{e^{i(u+i\\theta)(W_{t}-W_{s})}\\mid\\mathcal F_{s}\\}}\\\\ &{\\qquad\\qquad\\qquad=e^{(-\\theta^{2}/2+i u\\theta)(t-s)}e^{-(u+i\\theta)^{2}(t-s)/2}}\\\\ &{\\qquad\\qquad\\qquad=e^{-u^{2}(t-s)/2}.}\\end{array}\n$$\n\n# 1.4.2 Self-Financing Portfolios\n\nAs in Section 1.3.1, a portfolio comprises $a_{t}$ units of stock and $b_{t}$ in bonds; we denote by $V_{t}$ its value at time $t$\n\n$$\nV_{t}=a_{t}X_{t}+b_{t}e^{r t}.\n$$\n\nThe self-financing property (1.28), namely $d V_{t} = a_{t} d X_{t} + r b_{t} e^{r t} d t$, implies that the discounted value of the portfolio, $\\widetilde{V}_{t} = e^{-r t} V_{t}$, is a martingale under the risk-neutral probability $I\\!\\!P^{\\star}$. This important property of self-financing portfolios is obtained as follows:\n\n$$\n\\begin{array}{r l}&{d\\widetilde{V}_{t}=-r e^{-r t}V_{t}\\,d t+e^{-r t}\\,d V_{t}}\\\\ &{\\quad=-r e^{-r t}(a_{t}\\,X_{t}+b_{t}e^{r t})\\,d t+e^{-r t}(a_{t}\\,d X_{t}+r b_{t}e^{r t}\\,d t)}\\\\ &{\\quad=-r e^{-r t}a_{t}\\,X_{t}\\,d t+e^{-r t}a_{t}\\,d X_{t}}\\\\ &{\\quad=a_{t}\\,d(e^{-r t}X_{t})}\\\\ &{\\quad=a_{t}\\,d\\widetilde{X}_{t}}\\\\ &{\\quad=\\sigma a_{t}\\widetilde{X}_{t}\\,d W_{t}^{\\star}\\quad(\\mathrm{by~(1.46)}),}\\end{array}\n$$\n\nwhich shows that $(\\widetilde{V}_{t})$ is a martingale under $I\\!\\!P^{\\star}$ as a stochastic integral with respect to the Brownian motion $(\\boldsymbol{W}_{t}^{\\star})$. Indeed, the same computation shows that if a portfolio satisfies $d\\widetilde{V}_{t} = a_{t} d\\widetilde{X}_{t}$ then it is self-financing.\n\nA simple calculation demonstrates the connection between martingales and no arbitrage. Suppose that $(a_{t}, b_{t})_{0 \\leq t \\leq T}$ is a self-financing arbitrage strategy; that is,\n\n$$\nV_{T} \\geq e^{r T} V_{0} \\quad (I\\!\\!P\\mathrm{-a.s.}),\n$$\n\nwith\n\n$$\nI\\!\\!P\\{V_{T} > e^{r T} V_{0}\\} > 0,\n$$\n\nso that the strategy never makes less than money in the bank and there is some chance of making more. But\n\n$$\nI\\!\\!E^{\\star}\\{V_{T}\\} = e^{r T} V_{0}\n$$\n\nby the martingale property, so (1.51) and (1.52) cannot hold. This is because $I\\!\\!P$ and $I\\!\\!P^{\\star}$ are equivalent and so (1.51) and (1.52) also hold with $I\\!\\!P$ replaced by $I\\!\\!P^{\\star}$.\n\n# 1.4.3 Risk-Neutral Valuation\n\nAssume that $(a_{t}, b_{t})$ is a self-financing portfolio satisfying the same integrability conditions of Section 1.3.1 and replicating the European-style derivative with non-negative payoff $H$\n\n$$\na_{T} X_{T} + b_{T} e^{r T} = H,\n$$\n\nwhere we assume that $H$ is a square-integrable $\\mathcal{F}_{T}$-adapted random variable. This includes European calls and puts or more general standard European derivatives for which $H = h(X_{T})$, as well as other European-style exotic derivatives presented in Section 1.2.3.\n\nOn one hand, a no-arbitrage argument shows that the price at time $t$ of this derivative should be the value $V_{t}$ of this portfolio. On the other hand, as shown in Section 1.4.2, the discounted values $(\\widetilde{V}_{t})$ of this portfolio form a martingale under the risk-neutral probability $I\\!\\!\\!P^{\\star}$ and consequently\n\n$$\n\\widetilde{V}_{t} = I\\!\\!E^{\\star}\\{\\widetilde{V_{T}} \\mid \\mathcal{F}_{t}\\},\n$$\n\nwhich gives\n\n$$\nV_{t} = I\\!\\!E^{\\star}\\{e^{-r(T-t)} H \\mid \\mathcal{F}_{t}\\}\n$$\n\nafter reintroducing the discounting factor and using the replicating property (1.53). Alternatively, given the risk-neutral valuation formula (1.54), we can find a self-financing replicating portfolio for the payoff $H$. The existence of such a portfolio is guaranteed by an application of the martingale representation theorem: for $0 \\leq t \\leq T$\n\n$$\nM_{t} = I\\!E^{\\star}\\{e^{-r T} H \\mid \\mathcal{F}_{t}\\}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "The self-financing property (1.28), namely $d V_{t} = a_{t} d X_{t} + r b_{t} e^{r t} d t$, implies that the discounted value of the portfolio, $\\widetilde{V}_{t} = e^{-r t} V_{t}$, is a martingale under the risk-neutral probability $I\\!\\!P^{\\star}$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Derivatives_In_Financial_Markets_With_Stochas.pdf_14",
        "ID": "00b5888d-5f7c-441a-abf5-5e065ae88bd8",
        "questions": "What is the formula for the discounted value of a self-financing portfolio, given its undiscounted value and interest rate?",
        "answers": "$\\widetilde{V}_{t} = e^{-r t} V_{t}$",
        "context": "For any $0 \\leq s \\leq t \\leq T$, the process $(\\xi_{t}^{\\theta})_{0 \\leq t \\leq T}$ is called the Radon-Nikodym process.\n\nThe main result of this section asserts that the process $(W_{t}^{\\star})$ given by (1.45) is a standard Brownian motion under the probability $I\\!\\!P^{\\star}$: This result in its full generality (when $\\theta$ is an adapted stochastic process) is known as Girsanov's theorem. In our simple case ($\\theta$ constant), it is easily derived by using the characterization (1.3) and formula (1.49) as follows:\n\n$$\n\\begin{array}{r l}&{{I\\!\\!E}^{*}\\{e^{i u(W_{t}^{*}-W_{s}^{*})}\\mid\\mathcal F_{s}\\}=\\frac1{\\xi_{s}^{\\theta}}{I\\!\\!E}\\{\\xi_{t}^{\\theta}e^{i u(W_{t}^{*}-W_{s}^{*})}\\mid\\mathcal F_{s}\\}}\\\\ &{\\qquad\\qquad\\qquad=e^{\\theta W_{s}+\\theta^{2}s/2}{I\\!\\!E}\\{e^{-\\theta W_{t}-\\theta^{2}t/2}e^{i u(W_{t}-W_{s}+\\theta(t-s))}\\mid\\mathcal F_{s}\\}}\\\\ &{\\qquad\\qquad\\qquad=e^{(-\\theta^{2}/2+i u\\theta)(t-s)}{I\\!\\!E}\\{e^{i(u+i\\theta)(W_{t}-W_{s})}\\mid\\mathcal F_{s}\\}}\\\\ &{\\qquad\\qquad\\qquad=e^{(-\\theta^{2}/2+i u\\theta)(t-s)}e^{-(u+i\\theta)^{2}(t-s)/2}}\\\\ &{\\qquad\\qquad\\qquad=e^{-u^{2}(t-s)/2}.}\\end{array}\n$$\n\n# 1.4.2 Self-Financing Portfolios\n\nAs in Section 1.3.1, a portfolio comprises $a_{t}$ units of stock and $b_{t}$ in bonds; we denote by $V_{t}$ its value at time $t$\n\n$$\nV_{t}=a_{t}X_{t}+b_{t}e^{r t}.\n$$\n\nThe self-financing property (1.28), namely $d V_{t} = a_{t} d X_{t} + r b_{t} e^{r t} d t$, implies that the discounted value of the portfolio, $\\widetilde{V}_{t} = e^{-r t} V_{t}$, is a martingale under the risk-neutral probability $I\\!\\!P^{\\star}$. This important property of self-financing portfolios is obtained as follows:\n\n$$\n\\begin{array}{r l}&{d\\widetilde{V}_{t}=-r e^{-r t}V_{t}\\,d t+e^{-r t}\\,d V_{t}}\\\\ &{\\quad=-r e^{-r t}(a_{t}\\,X_{t}+b_{t}e^{r t})\\,d t+e^{-r t}(a_{t}\\,d X_{t}+r b_{t}e^{r t}\\,d t)}\\\\ &{\\quad=-r e^{-r t}a_{t}\\,X_{t}\\,d t+e^{-r t}a_{t}\\,d X_{t}}\\\\ &{\\quad=a_{t}\\,d(e^{-r t}X_{t})}\\\\ &{\\quad=a_{t}\\,d\\widetilde{X}_{t}}\\\\ &{\\quad=\\sigma a_{t}\\widetilde{X}_{t}\\,d W_{t}^{\\star}\\quad(\\mathrm{by~(1.46)}),}\\end{array}\n$$\n\nwhich shows that $(\\widetilde{V}_{t})$ is a martingale under $I\\!\\!P^{\\star}$ as a stochastic integral with respect to the Brownian motion $(\\boldsymbol{W}_{t}^{\\star})$. Indeed, the same computation shows that if a portfolio satisfies $d\\widetilde{V}_{t} = a_{t} d\\widetilde{X}_{t}$ then it is self-financing.\n\nA simple calculation demonstrates the connection between martingales and no arbitrage. Suppose that $(a_{t}, b_{t})_{0 \\leq t \\leq T}$ is a self-financing arbitrage strategy; that is,\n\n$$\nV_{T} \\geq e^{r T} V_{0} \\quad (I\\!\\!P\\mathrm{-a.s.}),\n$$\n\nwith\n\n$$\nI\\!\\!P\\{V_{T} > e^{r T} V_{0}\\} > 0,\n$$\n\nso that the strategy never makes less than money in the bank and there is some chance of making more. But\n\n$$\nI\\!\\!E^{\\star}\\{V_{T}\\} = e^{r T} V_{0}\n$$\n\nby the martingale property, so (1.51) and (1.52) cannot hold. This is because $I\\!\\!P$ and $I\\!\\!P^{\\star}$ are equivalent and so (1.51) and (1.52) also hold with $I\\!\\!P$ replaced by $I\\!\\!P^{\\star}$.\n\n# 1.4.3 Risk-Neutral Valuation\n\nAssume that $(a_{t}, b_{t})$ is a self-financing portfolio satisfying the same integrability conditions of Section 1.3.1 and replicating the European-style derivative with non-negative payoff $H$\n\n$$\na_{T} X_{T} + b_{T} e^{r T} = H,\n$$\n\nwhere we assume that $H$ is a square-integrable $\\mathcal{F}_{T}$-adapted random variable. This includes European calls and puts or more general standard European derivatives for which $H = h(X_{T})$, as well as other European-style exotic derivatives presented in Section 1.2.3.\n\nOn one hand, a no-arbitrage argument shows that the price at time $t$ of this derivative should be the value $V_{t}$ of this portfolio. On the other hand, as shown in Section 1.4.2, the discounted values $(\\widetilde{V}_{t})$ of this portfolio form a martingale under the risk-neutral probability $I\\!\\!\\!P^{\\star}$ and consequently\n\n$$\n\\widetilde{V}_{t} = I\\!\\!E^{\\star}\\{\\widetilde{V_{T}} \\mid \\mathcal{F}_{t}\\},\n$$\n\nwhich gives\n\n$$\nV_{t} = I\\!\\!E^{\\star}\\{e^{-r(T-t)} H \\mid \\mathcal{F}_{t}\\}\n$$\n\nafter reintroducing the discounting factor and using the replicating property (1.53). Alternatively, given the risk-neutral valuation formula (1.54), we can find a self-financing replicating portfolio for the payoff $H$. The existence of such a portfolio is guaranteed by an application of the martingale representation theorem: for $0 \\leq t \\leq T$\n\n$$\nM_{t} = I\\!E^{\\star}\\{e^{-r T} H \\mid \\mathcal{F}_{t}\\}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "The self-financing property (1.28), namely $d V_{t} = a_{t} d X_{t} + r b_{t} e^{r t} d t$, implies that the discounted value of the portfolio, $\\widetilde{V}_{t} = e^{-r t} V_{t}$, is a martingale under the risk-neutral probability $I\\!\\!P^{\\star}$.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/Derivatives_In_Financial_Markets_With_Stochas.pdf_14",
        "ID": "00c08143-c5a4-48c6-995f-908dbd9695c9",
        "questions": "What is the equation that demonstrates the connection between a self-financing arbitrage strategy and the notion that this strategy never makes less than the money in the bank, given the condition that the probability of ending with more money is positive?",
        "answers": "$V_{T} \\geq e^{r T} V_{0}$ with $I\\!\\!P\\{V_{T} > e^{r T} V_{0}\\} > 0$",
        "context": "For any $0 \\leq s \\leq t \\leq T$, the process $(\\xi_{t}^{\\theta})_{0 \\leq t \\leq T}$ is called the Radon-Nikodym process.\n\nThe main result of this section asserts that the process $(W_{t}^{\\star})$ given by (1.45) is a standard Brownian motion under the probability $I\\!\\!P^{\\star}$: This result in its full generality (when $\\theta$ is an adapted stochastic process) is known as Girsanov's theorem. In our simple case ($\\theta$ constant), it is easily derived by using the characterization (1.3) and formula (1.49) as follows:\n\n$$\n\\begin{array}{r l}&{{I\\!\\!E}^{*}\\{e^{i u(W_{t}^{*}-W_{s}^{*})}\\mid\\mathcal F_{s}\\}=\\frac1{\\xi_{s}^{\\theta}}{I\\!\\!E}\\{\\xi_{t}^{\\theta}e^{i u(W_{t}^{*}-W_{s}^{*})}\\mid\\mathcal F_{s}\\}}\\\\ &{\\qquad\\qquad\\qquad=e^{\\theta W_{s}+\\theta^{2}s/2}{I\\!\\!E}\\{e^{-\\theta W_{t}-\\theta^{2}t/2}e^{i u(W_{t}-W_{s}+\\theta(t-s))}\\mid\\mathcal F_{s}\\}}\\\\ &{\\qquad\\qquad\\qquad=e^{(-\\theta^{2}/2+i u\\theta)(t-s)}{I\\!\\!E}\\{e^{i(u+i\\theta)(W_{t}-W_{s})}\\mid\\mathcal F_{s}\\}}\\\\ &{\\qquad\\qquad\\qquad=e^{(-\\theta^{2}/2+i u\\theta)(t-s)}e^{-(u+i\\theta)^{2}(t-s)/2}}\\\\ &{\\qquad\\qquad\\qquad=e^{-u^{2}(t-s)/2}.}\\end{array}\n$$\n\n# 1.4.2 Self-Financing Portfolios\n\nAs in Section 1.3.1, a portfolio comprises $a_{t}$ units of stock and $b_{t}$ in bonds; we denote by $V_{t}$ its value at time $t$\n\n$$\nV_{t}=a_{t}X_{t}+b_{t}e^{r t}.\n$$\n\nThe self-financing property (1.28), namely $d V_{t} = a_{t} d X_{t} + r b_{t} e^{r t} d t$, implies that the discounted value of the portfolio, $\\widetilde{V}_{t} = e^{-r t} V_{t}$, is a martingale under the risk-neutral probability $I\\!\\!P^{\\star}$. This important property of self-financing portfolios is obtained as follows:\n\n$$\n\\begin{array}{r l}&{d\\widetilde{V}_{t}=-r e^{-r t}V_{t}\\,d t+e^{-r t}\\,d V_{t}}\\\\ &{\\quad=-r e^{-r t}(a_{t}\\,X_{t}+b_{t}e^{r t})\\,d t+e^{-r t}(a_{t}\\,d X_{t}+r b_{t}e^{r t}\\,d t)}\\\\ &{\\quad=-r e^{-r t}a_{t}\\,X_{t}\\,d t+e^{-r t}a_{t}\\,d X_{t}}\\\\ &{\\quad=a_{t}\\,d(e^{-r t}X_{t})}\\\\ &{\\quad=a_{t}\\,d\\widetilde{X}_{t}}\\\\ &{\\quad=\\sigma a_{t}\\widetilde{X}_{t}\\,d W_{t}^{\\star}\\quad(\\mathrm{by~(1.46)}),}\\end{array}\n$$\n\nwhich shows that $(\\widetilde{V}_{t})$ is a martingale under $I\\!\\!P^{\\star}$ as a stochastic integral with respect to the Brownian motion $(\\boldsymbol{W}_{t}^{\\star})$. Indeed, the same computation shows that if a portfolio satisfies $d\\widetilde{V}_{t} = a_{t} d\\widetilde{X}_{t}$ then it is self-financing.\n\nA simple calculation demonstrates the connection between martingales and no arbitrage. Suppose that $(a_{t}, b_{t})_{0 \\leq t \\leq T}$ is a self-financing arbitrage strategy; that is,\n\n$$\nV_{T} \\geq e^{r T} V_{0} \\quad (I\\!\\!P\\mathrm{-a.s.}),\n$$\n\nwith\n\n$$\nI\\!\\!P\\{V_{T} > e^{r T} V_{0}\\} > 0,\n$$\n\nso that the strategy never makes less than money in the bank and there is some chance of making more. But\n\n$$\nI\\!\\!E^{\\star}\\{V_{T}\\} = e^{r T} V_{0}\n$$\n\nby the martingale property, so (1.51) and (1.52) cannot hold. This is because $I\\!\\!P$ and $I\\!\\!P^{\\star}$ are equivalent and so (1.51) and (1.52) also hold with $I\\!\\!P$ replaced by $I\\!\\!P^{\\star}$.\n\n# 1.4.3 Risk-Neutral Valuation\n\nAssume that $(a_{t}, b_{t})$ is a self-financing portfolio satisfying the same integrability conditions of Section 1.3.1 and replicating the European-style derivative with non-negative payoff $H$\n\n$$\na_{T} X_{T} + b_{T} e^{r T} = H,\n$$\n\nwhere we assume that $H$ is a square-integrable $\\mathcal{F}_{T}$-adapted random variable. This includes European calls and puts or more general standard European derivatives for which $H = h(X_{T})$, as well as other European-style exotic derivatives presented in Section 1.2.3.\n\nOn one hand, a no-arbitrage argument shows that the price at time $t$ of this derivative should be the value $V_{t}$ of this portfolio. On the other hand, as shown in Section 1.4.2, the discounted values $(\\widetilde{V}_{t})$ of this portfolio form a martingale under the risk-neutral probability $I\\!\\!\\!P^{\\star}$ and consequently\n\n$$\n\\widetilde{V}_{t} = I\\!\\!E^{\\star}\\{\\widetilde{V_{T}} \\mid \\mathcal{F}_{t}\\},\n$$\n\nwhich gives\n\n$$\nV_{t} = I\\!\\!E^{\\star}\\{e^{-r(T-t)} H \\mid \\mathcal{F}_{t}\\}\n$$\n\nafter reintroducing the discounting factor and using the replicating property (1.53). Alternatively, given the risk-neutral valuation formula (1.54), we can find a self-financing replicating portfolio for the payoff $H$. The existence of such a portfolio is guaranteed by an application of the martingale representation theorem: for $0 \\leq t \\leq T$\n\n$$\nM_{t} = I\\!E^{\\star}\\{e^{-r T} H \\mid \\mathcal{F}_{t}\\}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "A simple calculation demonstrates the connection between martingales and no arbitrage. Suppose that $(a_{t}, b_{t})_{0 \\leq t \\leq T}$ is a self-financing arbitrage strategy; that is, $V_{T} \\geq e^{r T} V_{0} \\quad (I\\!\\!P\\mathrm{-a.s.}),$ with $I\\!\\!P\\{V_{T} > e^{r T} V_{0}\\} > 0,$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/Derivatives_In_Financial_Markets_With_Stochas.pdf_14",
        "ID": "00c99f27-6e4d-442f-b306-f416b09b8163",
        "questions": "Using the Girsanov's theorem context, what is the expectation of a process with respect to the risk-neutral probability $I\\!\\!P^{\\star}$ when expressed in terms of complex exponentials and given no change in filtration?",
        "answers": "$I\\!\\!E^{*}\\{e^{i u(W_{t}^{*}-W_{s}^{*})}\\mid\\mathcal F_{s}\\}=e^{-u^{2}(t-s)/2}$",
        "context": "For any $0 \\leq s \\leq t \\leq T$, the process $(\\xi_{t}^{\\theta})_{0 \\leq t \\leq T}$ is called the Radon-Nikodym process.\n\nThe main result of this section asserts that the process $(W_{t}^{\\star})$ given by (1.45) is a standard Brownian motion under the probability $I\\!\\!P^{\\star}$: This result in its full generality (when $\\theta$ is an adapted stochastic process) is known as Girsanov's theorem. In our simple case ($\\theta$ constant), it is easily derived by using the characterization (1.3) and formula (1.49) as follows:\n\n$$\n\\begin{array}{r l}&{{I\\!\\!E}^{*}\\{e^{i u(W_{t}^{*}-W_{s}^{*})}\\mid\\mathcal F_{s}\\}=\\frac1{\\xi_{s}^{\\theta}}{I\\!\\!E}\\{\\xi_{t}^{\\theta}e^{i u(W_{t}^{*}-W_{s}^{*})}\\mid\\mathcal F_{s}\\}}\\\\ &{\\qquad\\qquad\\qquad=e^{\\theta W_{s}+\\theta^{2}s/2}{I\\!\\!E}\\{e^{-\\theta W_{t}-\\theta^{2}t/2}e^{i u(W_{t}-W_{s}+\\theta(t-s))}\\mid\\mathcal F_{s}\\}}\\\\ &{\\qquad\\qquad\\qquad=e^{(-\\theta^{2}/2+i u\\theta)(t-s)}{I\\!\\!E}\\{e^{i(u+i\\theta)(W_{t}-W_{s})}\\mid\\mathcal F_{s}\\}}\\\\ &{\\qquad\\qquad\\qquad=e^{(-\\theta^{2}/2+i u\\theta)(t-s)}e^{-(u+i\\theta)^{2}(t-s)/2}}\\\\ &{\\qquad\\qquad\\qquad=e^{-u^{2}(t-s)/2}.}\\end{array}\n$$\n\n# 1.4.2 Self-Financing Portfolios\n\nAs in Section 1.3.1, a portfolio comprises $a_{t}$ units of stock and $b_{t}$ in bonds; we denote by $V_{t}$ its value at time $t$\n\n$$\nV_{t}=a_{t}X_{t}+b_{t}e^{r t}.\n$$\n\nThe self-financing property (1.28), namely $d V_{t} = a_{t} d X_{t} + r b_{t} e^{r t} d t$, implies that the discounted value of the portfolio, $\\widetilde{V}_{t} = e^{-r t} V_{t}$, is a martingale under the risk-neutral probability $I\\!\\!P^{\\star}$. This important property of self-financing portfolios is obtained as follows:\n\n$$\n\\begin{array}{r l}&{d\\widetilde{V}_{t}=-r e^{-r t}V_{t}\\,d t+e^{-r t}\\,d V_{t}}\\\\ &{\\quad=-r e^{-r t}(a_{t}\\,X_{t}+b_{t}e^{r t})\\,d t+e^{-r t}(a_{t}\\,d X_{t}+r b_{t}e^{r t}\\,d t)}\\\\ &{\\quad=-r e^{-r t}a_{t}\\,X_{t}\\,d t+e^{-r t}a_{t}\\,d X_{t}}\\\\ &{\\quad=a_{t}\\,d(e^{-r t}X_{t})}\\\\ &{\\quad=a_{t}\\,d\\widetilde{X}_{t}}\\\\ &{\\quad=\\sigma a_{t}\\widetilde{X}_{t}\\,d W_{t}^{\\star}\\quad(\\mathrm{by~(1.46)}),}\\end{array}\n$$\n\nwhich shows that $(\\widetilde{V}_{t})$ is a martingale under $I\\!\\!P^{\\star}$ as a stochastic integral with respect to the Brownian motion $(\\boldsymbol{W}_{t}^{\\star})$. Indeed, the same computation shows that if a portfolio satisfies $d\\widetilde{V}_{t} = a_{t} d\\widetilde{X}_{t}$ then it is self-financing.\n\nA simple calculation demonstrates the connection between martingales and no arbitrage. Suppose that $(a_{t}, b_{t})_{0 \\leq t \\leq T}$ is a self-financing arbitrage strategy; that is,\n\n$$\nV_{T} \\geq e^{r T} V_{0} \\quad (I\\!\\!P\\mathrm{-a.s.}),\n$$\n\nwith\n\n$$\nI\\!\\!P\\{V_{T} > e^{r T} V_{0}\\} > 0,\n$$\n\nso that the strategy never makes less than money in the bank and there is some chance of making more. But\n\n$$\nI\\!\\!E^{\\star}\\{V_{T}\\} = e^{r T} V_{0}\n$$\n\nby the martingale property, so (1.51) and (1.52) cannot hold. This is because $I\\!\\!P$ and $I\\!\\!P^{\\star}$ are equivalent and so (1.51) and (1.52) also hold with $I\\!\\!P$ replaced by $I\\!\\!P^{\\star}$.\n\n# 1.4.3 Risk-Neutral Valuation\n\nAssume that $(a_{t}, b_{t})$ is a self-financing portfolio satisfying the same integrability conditions of Section 1.3.1 and replicating the European-style derivative with non-negative payoff $H$\n\n$$\na_{T} X_{T} + b_{T} e^{r T} = H,\n$$\n\nwhere we assume that $H$ is a square-integrable $\\mathcal{F}_{T}$-adapted random variable. This includes European calls and puts or more general standard European derivatives for which $H = h(X_{T})$, as well as other European-style exotic derivatives presented in Section 1.2.3.\n\nOn one hand, a no-arbitrage argument shows that the price at time $t$ of this derivative should be the value $V_{t}$ of this portfolio. On the other hand, as shown in Section 1.4.2, the discounted values $(\\widetilde{V}_{t})$ of this portfolio form a martingale under the risk-neutral probability $I\\!\\!\\!P^{\\star}$ and consequently\n\n$$\n\\widetilde{V}_{t} = I\\!\\!E^{\\star}\\{\\widetilde{V_{T}} \\mid \\mathcal{F}_{t}\\},\n$$\n\nwhich gives\n\n$$\nV_{t} = I\\!\\!E^{\\star}\\{e^{-r(T-t)} H \\mid \\mathcal{F}_{t}\\}\n$$\n\nafter reintroducing the discounting factor and using the replicating property (1.53). Alternatively, given the risk-neutral valuation formula (1.54), we can find a self-financing replicating portfolio for the payoff $H$. The existence of such a portfolio is guaranteed by an application of the martingale representation theorem: for $0 \\leq t \\leq T$\n\n$$\nM_{t} = I\\!E^{\\star}\\{e^{-r T} H \\mid \\mathcal{F}_{t}\\}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Numeric",
        "evidence_source": "equation",
        "evidence_context": "$I\\!\\!E^{*}\\{e^{i u(W_{t}^{*}-W_{s}^{*})}\\mid\\mathcal F_{s}\\}=e^{-u^{2}(t-s)/2}.$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/chem-431931.pdf_11",
        "ID": "00cbcbf6-71b5-451b-93df-c7bf5966aa79",
        "questions": "What is the equation for calculating the Relative Standard Deviation?",
        "answers": "R S D=100\times\\frac{\\sigma}{\\bar{x}}",
        "context": "$$\nR S D=100\\times\\frac{\\sigma}{\\bar{x}}\n$$  \n\n# Confidence Interval  \n\nWith a finite number of data points, it is not possible to find the true mean or the true standard deviation, as a small sample size will not cover the entirety of the normal distribution of data. What we calculated in the earlier sections is the sample mean and the sample standard deviation. The confidence interval is an expression that states that the true mean is likely to lie within a certain distance from the measured and reported mean, $\\bar{{x}}$. The confidence interval is given by:  \n\n$$\n\\mu=\\bar{x}\\pm\\frac{t\\sigma}{\\sqrt{n}}\n$$  \n\nwhere $\\mu$ is the interval, and $t$ is the student's $t$ which can be looked up in the student's $t$ table (available in many textbooks or online). The value of $t$ for a $95\\%$ confidence interval can be found in Table 1:\n\n$\n\\caption{Table 1: Student $t$ table for a $95\\%$ confidence interval.}\n\\begin{tabular}{|c|c|}\n \ndegrees of freedom (n - 1) & 95\\% Confidence Interval t Value \\\\\n \n1 & 12.706 \\\\\n \n2 & 4.303 \\\\\n \n3 & 3.182 \\\\\n \n4 & 2.776 \\\\\n \n5 & 2.571 \\\\\n \n6 & 2.447 \\\\\n \n7 & 2.365 \\\\\n \n8 & 2.306 \\\\\n \n9 & 2.262 \\\\\n \n10 & 2.228 \\\\\n \n15 & 2.131 \\\\\n \n20 & 2.086 \\\\\n \n25 & 2.060 \\\\\n \n30 & 2.042 \\\\\n \n40 & 2.021 \\\\\n \n60 & 2.000 \\\\\n \n120 & 1.980 \\\\\n \n$\\infty$ & 1.960 \\\\\n \n\\end{tabular}\n$\n\n# Discarding Data  \n\nYou should always be cautious of discarding data. Just because a data point is an outlier does not mean it is wrong; that may turn out to be your most accurate measurement. Two methods are generally accepted when deciding to reject data. The first is rejecting data that you know to be low quality due to the procedure of measuring it. You can do this by adding notes in your lab notebook, such as any issue in the lab, extra solvent added, a little bit of spilled powder, or instrument malfunctions, leading to problematic data collected. If you know you did something wrong, you can discard that data as bad data.  \n\nThe other method for rejecting a single outlier (you can only perform this procedure once on a dataset) is called the q-test. For $3\\leq n\\leq10$, where $n$ is the number of measurements of the same quantity, calculate:  \n\n$$\nQ={\\frac{|{\\mathrm{subject~value}}-{\\mathrm{value~closed~to~it}}|}{\\mathrm{highest~value}-{\\mathrm{lowest~value}}}}\n$$  \n\nCompare the value of $Q$ with $Q_{c}$ from Table 2. If $Q>Q_{c}$, you can reject the suspect value.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "R S D=100\times\\frac{\\sigma}{\\bar{x}}",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/chem-431931.pdf_11",
        "ID": "00ce4721-4ff0-494d-b15f-efa4d84c1087",
        "questions": "How is the value for the confidence interval expressed and what does each variable represent?",
        "answers": "The confidence interval is given by: \\(\\mu = \\bar{x} \\pm \\frac{t\\sigma}{\\sqrt{n}}\\) where \\(\\mu\\) is the interval, and \\(t\\) is the student's t.",
        "context": "$$\nR S D=100\\times\\frac{\\sigma}{\\bar{x}}\n$$  \n\n# Confidence Interval  \n\nWith a finite number of data points, it is not possible to find the true mean or the true standard deviation, as a small sample size will not cover the entirety of the normal distribution of data. What we calculated in the earlier sections is the sample mean and the sample standard deviation. The confidence interval is an expression that states that the true mean is likely to lie within a certain distance from the measured and reported mean, $\\bar{{x}}$. The confidence interval is given by:  \n\n$$\n\\mu=\\bar{x}\\pm\\frac{t\\sigma}{\\sqrt{n}}\n$$  \n\nwhere $\\mu$ is the interval, and $t$ is the student's $t$ which can be looked up in the student's $t$ table (available in many textbooks or online). The value of $t$ for a $95\\%$ confidence interval can be found in Table 1:\n\n$\n\\caption{Table 1: Student $t$ table for a $95\\%$ confidence interval.}\n\\begin{tabular}{|c|c|}\n \ndegrees of freedom (n - 1) & 95\\% Confidence Interval t Value \\\\\n \n1 & 12.706 \\\\\n \n2 & 4.303 \\\\\n \n3 & 3.182 \\\\\n \n4 & 2.776 \\\\\n \n5 & 2.571 \\\\\n \n6 & 2.447 \\\\\n \n7 & 2.365 \\\\\n \n8 & 2.306 \\\\\n \n9 & 2.262 \\\\\n \n10 & 2.228 \\\\\n \n15 & 2.131 \\\\\n \n20 & 2.086 \\\\\n \n25 & 2.060 \\\\\n \n30 & 2.042 \\\\\n \n40 & 2.021 \\\\\n \n60 & 2.000 \\\\\n \n120 & 1.980 \\\\\n \n$\\infty$ & 1.960 \\\\\n \n\\end{tabular}\n$\n\n# Discarding Data  \n\nYou should always be cautious of discarding data. Just because a data point is an outlier does not mean it is wrong; that may turn out to be your most accurate measurement. Two methods are generally accepted when deciding to reject data. The first is rejecting data that you know to be low quality due to the procedure of measuring it. You can do this by adding notes in your lab notebook, such as any issue in the lab, extra solvent added, a little bit of spilled powder, or instrument malfunctions, leading to problematic data collected. If you know you did something wrong, you can discard that data as bad data.  \n\nThe other method for rejecting a single outlier (you can only perform this procedure once on a dataset) is called the q-test. For $3\\leq n\\leq10$, where $n$ is the number of measurements of the same quantity, calculate:  \n\n$$\nQ={\\frac{|{\\mathrm{subject~value}}-{\\mathrm{value~closed~to~it}}|}{\\mathrm{highest~value}-{\\mathrm{lowest~value}}}}\n$$  \n\nCompare the value of $Q$ with $Q_{c}$ from Table 2. If $Q>Q_{c}$, you can reject the suspect value.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "The confidence interval is given by: \\(\\mu = \\bar{x} \\pm \\frac{t\\sigma}{\\sqrt{n}}\\) where \\(\\mu\\) is the interval, and \\(t\\) is the student's t which can be looked up in the student's t table (available in many textbooks or online).",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/chem-431931.pdf_11",
        "ID": "00d1e139-b8cd-469b-8e7e-6db1ef4c618d",
        "questions": "According to the Student's t table, what is the t value for a 95% confidence interval when the degrees of freedom are 6?",
        "answers": "2.447",
        "context": "$$\nR S D=100\\times\\frac{\\sigma}{\\bar{x}}\n$$  \n\n# Confidence Interval  \n\nWith a finite number of data points, it is not possible to find the true mean or the true standard deviation, as a small sample size will not cover the entirety of the normal distribution of data. What we calculated in the earlier sections is the sample mean and the sample standard deviation. The confidence interval is an expression that states that the true mean is likely to lie within a certain distance from the measured and reported mean, $\\bar{{x}}$. The confidence interval is given by:  \n\n$$\n\\mu=\\bar{x}\\pm\\frac{t\\sigma}{\\sqrt{n}}\n$$  \n\nwhere $\\mu$ is the interval, and $t$ is the student's $t$ which can be looked up in the student's $t$ table (available in many textbooks or online). The value of $t$ for a $95\\%$ confidence interval can be found in Table 1:\n\n$\n\\caption{Table 1: Student $t$ table for a $95\\%$ confidence interval.}\n\\begin{tabular}{|c|c|}\n \ndegrees of freedom (n - 1) & 95\\% Confidence Interval t Value \\\\\n \n1 & 12.706 \\\\\n \n2 & 4.303 \\\\\n \n3 & 3.182 \\\\\n \n4 & 2.776 \\\\\n \n5 & 2.571 \\\\\n \n6 & 2.447 \\\\\n \n7 & 2.365 \\\\\n \n8 & 2.306 \\\\\n \n9 & 2.262 \\\\\n \n10 & 2.228 \\\\\n \n15 & 2.131 \\\\\n \n20 & 2.086 \\\\\n \n25 & 2.060 \\\\\n \n30 & 2.042 \\\\\n \n40 & 2.021 \\\\\n \n60 & 2.000 \\\\\n \n120 & 1.980 \\\\\n \n$\\infty$ & 1.960 \\\\\n \n\\end{tabular}\n$\n\n# Discarding Data  \n\nYou should always be cautious of discarding data. Just because a data point is an outlier does not mean it is wrong; that may turn out to be your most accurate measurement. Two methods are generally accepted when deciding to reject data. The first is rejecting data that you know to be low quality due to the procedure of measuring it. You can do this by adding notes in your lab notebook, such as any issue in the lab, extra solvent added, a little bit of spilled powder, or instrument malfunctions, leading to problematic data collected. If you know you did something wrong, you can discard that data as bad data.  \n\nThe other method for rejecting a single outlier (you can only perform this procedure once on a dataset) is called the q-test. For $3\\leq n\\leq10$, where $n$ is the number of measurements of the same quantity, calculate:  \n\n$$\nQ={\\frac{|{\\mathrm{subject~value}}-{\\mathrm{value~closed~to~it}}|}{\\mathrm{highest~value}-{\\mathrm{lowest~value}}}}\n$$  \n\nCompare the value of $Q$ with $Q_{c}$ from Table 2. If $Q>Q_{c}$, you can reject the suspect value.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Numeric",
        "evidence_source": "table",
        "evidence_context": "6 & 2.447",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/chem-431931.pdf_11",
        "ID": "00d2870b-4b5c-41ed-b2bb-ccfc34ff496a",
        "questions": "How is the relative standard deviation (RSD) calculated using the standard deviation and sample mean?",
        "answers": "R S D=100\\times\\frac{\\sigma}{\\bar{x}}",
        "context": "$$\nR S D=100\\times\\frac{\\sigma}{\\bar{x}}\n$$  \n\n# Confidence Interval  \n\nWith a finite number of data points, it is not possible to find the true mean or the true standard deviation, as a small sample size will not cover the entirety of the normal distribution of data. What we calculated in the earlier sections is the sample mean and the sample standard deviation. The confidence interval is an expression that states that the true mean is likely to lie within a certain distance from the measured and reported mean, $\\bar{{x}}$. The confidence interval is given by:  \n\n$$\n\\mu=\\bar{x}\\pm\\frac{t\\sigma}{\\sqrt{n}}\n$$  \n\nwhere $\\mu$ is the interval, and $t$ is the student's $t$ which can be looked up in the student's $t$ table (available in many textbooks or online). The value of $t$ for a $95\\%$ confidence interval can be found in Table 1:\n\n$\n\\caption{Table 1: Student $t$ table for a $95\\%$ confidence interval.}\n\\begin{tabular}{|c|c|}\n \ndegrees of freedom (n - 1) & 95\\% Confidence Interval t Value \\\\\n \n1 & 12.706 \\\\\n \n2 & 4.303 \\\\\n \n3 & 3.182 \\\\\n \n4 & 2.776 \\\\\n \n5 & 2.571 \\\\\n \n6 & 2.447 \\\\\n \n7 & 2.365 \\\\\n \n8 & 2.306 \\\\\n \n9 & 2.262 \\\\\n \n10 & 2.228 \\\\\n \n15 & 2.131 \\\\\n \n20 & 2.086 \\\\\n \n25 & 2.060 \\\\\n \n30 & 2.042 \\\\\n \n40 & 2.021 \\\\\n \n60 & 2.000 \\\\\n \n120 & 1.980 \\\\\n \n$\\infty$ & 1.960 \\\\\n \n\\end{tabular}\n$\n\n# Discarding Data  \n\nYou should always be cautious of discarding data. Just because a data point is an outlier does not mean it is wrong; that may turn out to be your most accurate measurement. Two methods are generally accepted when deciding to reject data. The first is rejecting data that you know to be low quality due to the procedure of measuring it. You can do this by adding notes in your lab notebook, such as any issue in the lab, extra solvent added, a little bit of spilled powder, or instrument malfunctions, leading to problematic data collected. If you know you did something wrong, you can discard that data as bad data.  \n\nThe other method for rejecting a single outlier (you can only perform this procedure once on a dataset) is called the q-test. For $3\\leq n\\leq10$, where $n$ is the number of measurements of the same quantity, calculate:  \n\n$$\nQ={\\frac{|{\\mathrm{subject~value}}-{\\mathrm{value~closed~to~it}}|}{\\mathrm{highest~value}-{\\mathrm{lowest~value}}}}\n$$  \n\nCompare the value of $Q$ with $Q_{c}$ from Table 2. If $Q>Q_{c}$, you can reject the suspect value.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$$R S D=100\\times\\frac{\\sigma}{\\bar{x}}$$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/chem-431931.pdf_11",
        "ID": "00d3470f-abed-43b1-89e6-6c0421125186",
        "questions": "What is the formula for the confidence interval for the true mean using the student's t-distribution?",
        "answers": "\\mu=\\bar{x}\\pm\\frac{t\\sigma}{\\sqrt{n}}",
        "context": "$$\nR S D=100\\times\\frac{\\sigma}{\\bar{x}}\n$$  \n\n# Confidence Interval  \n\nWith a finite number of data points, it is not possible to find the true mean or the true standard deviation, as a small sample size will not cover the entirety of the normal distribution of data. What we calculated in the earlier sections is the sample mean and the sample standard deviation. The confidence interval is an expression that states that the true mean is likely to lie within a certain distance from the measured and reported mean, $\\bar{{x}}$. The confidence interval is given by:  \n\n$$\n\\mu=\\bar{x}\\pm\\frac{t\\sigma}{\\sqrt{n}}\n$$  \n\nwhere $\\mu$ is the interval, and $t$ is the student's $t$ which can be looked up in the student's $t$ table (available in many textbooks or online). The value of $t$ for a $95\\%$ confidence interval can be found in Table 1:\n\n$\n\\caption{Table 1: Student $t$ table for a $95\\%$ confidence interval.}\n\\begin{tabular}{|c|c|}\n \ndegrees of freedom (n - 1) & 95\\% Confidence Interval t Value \\\\\n \n1 & 12.706 \\\\\n \n2 & 4.303 \\\\\n \n3 & 3.182 \\\\\n \n4 & 2.776 \\\\\n \n5 & 2.571 \\\\\n \n6 & 2.447 \\\\\n \n7 & 2.365 \\\\\n \n8 & 2.306 \\\\\n \n9 & 2.262 \\\\\n \n10 & 2.228 \\\\\n \n15 & 2.131 \\\\\n \n20 & 2.086 \\\\\n \n25 & 2.060 \\\\\n \n30 & 2.042 \\\\\n \n40 & 2.021 \\\\\n \n60 & 2.000 \\\\\n \n120 & 1.980 \\\\\n \n$\\infty$ & 1.960 \\\\\n \n\\end{tabular}\n$\n\n# Discarding Data  \n\nYou should always be cautious of discarding data. Just because a data point is an outlier does not mean it is wrong; that may turn out to be your most accurate measurement. Two methods are generally accepted when deciding to reject data. The first is rejecting data that you know to be low quality due to the procedure of measuring it. You can do this by adding notes in your lab notebook, such as any issue in the lab, extra solvent added, a little bit of spilled powder, or instrument malfunctions, leading to problematic data collected. If you know you did something wrong, you can discard that data as bad data.  \n\nThe other method for rejecting a single outlier (you can only perform this procedure once on a dataset) is called the q-test. For $3\\leq n\\leq10$, where $n$ is the number of measurements of the same quantity, calculate:  \n\n$$\nQ={\\frac{|{\\mathrm{subject~value}}-{\\mathrm{value~closed~to~it}}|}{\\mathrm{highest~value}-{\\mathrm{lowest~value}}}}\n$$  \n\nCompare the value of $Q$ with $Q_{c}$ from Table 2. If $Q>Q_{c}$, you can reject the suspect value.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$$\\mu=\\bar{x}\\pm\\frac{t\\sigma}{\\sqrt{n}}$$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/chem-431931.pdf_11",
        "ID": "00d3d1af-353e-4c86-a4ae-ba79e4b82987",
        "questions": "How do you calculate the Q value used in the q-test for rejecting an outlier in a dataset with 3 to 10 measurements?",
        "answers": "Q={\\frac{|{\\mathrm{subject~value}}-{\\mathrm{value~closed~to~it}}|}{\\mathrm{highest~value}-{\\mathrm{lowest~value}}}}",
        "context": "$$\nR S D=100\\times\\frac{\\sigma}{\\bar{x}}\n$$  \n\n# Confidence Interval  \n\nWith a finite number of data points, it is not possible to find the true mean or the true standard deviation, as a small sample size will not cover the entirety of the normal distribution of data. What we calculated in the earlier sections is the sample mean and the sample standard deviation. The confidence interval is an expression that states that the true mean is likely to lie within a certain distance from the measured and reported mean, $\\bar{{x}}$. The confidence interval is given by:  \n\n$$\n\\mu=\\bar{x}\\pm\\frac{t\\sigma}{\\sqrt{n}}\n$$  \n\nwhere $\\mu$ is the interval, and $t$ is the student's $t$ which can be looked up in the student's $t$ table (available in many textbooks or online). The value of $t$ for a $95\\%$ confidence interval can be found in Table 1:\n\n$\n\\caption{Table 1: Student $t$ table for a $95\\%$ confidence interval.}\n\\begin{tabular}{|c|c|}\n \ndegrees of freedom (n - 1) & 95\\% Confidence Interval t Value \\\\\n \n1 & 12.706 \\\\\n \n2 & 4.303 \\\\\n \n3 & 3.182 \\\\\n \n4 & 2.776 \\\\\n \n5 & 2.571 \\\\\n \n6 & 2.447 \\\\\n \n7 & 2.365 \\\\\n \n8 & 2.306 \\\\\n \n9 & 2.262 \\\\\n \n10 & 2.228 \\\\\n \n15 & 2.131 \\\\\n \n20 & 2.086 \\\\\n \n25 & 2.060 \\\\\n \n30 & 2.042 \\\\\n \n40 & 2.021 \\\\\n \n60 & 2.000 \\\\\n \n120 & 1.980 \\\\\n \n$\\infty$ & 1.960 \\\\\n \n\\end{tabular}\n$\n\n# Discarding Data  \n\nYou should always be cautious of discarding data. Just because a data point is an outlier does not mean it is wrong; that may turn out to be your most accurate measurement. Two methods are generally accepted when deciding to reject data. The first is rejecting data that you know to be low quality due to the procedure of measuring it. You can do this by adding notes in your lab notebook, such as any issue in the lab, extra solvent added, a little bit of spilled powder, or instrument malfunctions, leading to problematic data collected. If you know you did something wrong, you can discard that data as bad data.  \n\nThe other method for rejecting a single outlier (you can only perform this procedure once on a dataset) is called the q-test. For $3\\leq n\\leq10$, where $n$ is the number of measurements of the same quantity, calculate:  \n\n$$\nQ={\\frac{|{\\mathrm{subject~value}}-{\\mathrm{value~closed~to~it}}|}{\\mathrm{highest~value}-{\\mathrm{lowest~value}}}}\n$$  \n\nCompare the value of $Q$ with $Q_{c}$ from Table 2. If $Q>Q_{c}$, you can reject the suspect value.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$$Q={\\frac{|{\\mathrm{subject~value}}-{\\mathrm{value~closed~to~it}}|}{\\mathrm{highest~value}-{\\mathrm{lowest~value}}}}$$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/0aa598c735f77296910c9b61658e9411d38061dc817b9e35b5ea4867d83f7603.pdf_5",
        "ID": "00e1e415-040b-4601-823a-0864be1b885c",
        "questions": "What is the test-retest reliability for the function mentioned in the studies by Borgmeier, 2003, and McIntosh, Borgmeier, et al., 2008?",
        "answers": "0.92",
        "context": "To possess evidence of sufficient validity, reliability, and treatment utility when administered by trained graduate students (as in this study). Two research studies provide the following technical adequacy data: test-retest reliability for function of .92 and agreement on function with direct observation results in 96% of cases (Borgmeier, 2003; McIntosh, Borgmeier, et al., 2008).\n\nProblem behavior ratings. Levels of behavior were measured through the Behavior Assessment Scale for Children 2 (BASC-2; Reynolds & Kamphaus, 2004). The BASC-2 is a standardized, norm-referenced behavior rating scale for assessing levels of problem behavior in school-aged students. The BASC-2 was selected because of its recent revision, its psychometric properties, and its updated, representative normative group. The measure also contains four validity indices to control for biased responding. The form used in this study was the BASC-2 Teacher Report Scale-Child Form, designed to rate the behavior of students aged 6 to 11 years. Composite scales for the BASC-2 are reported as T scores, with a mean of 50 and a standard deviation of 10. To measure level of problem behavior, the authors used the Behavioral Symptoms Index (BSI), a composite scale made up of the following subscales: hyperactivity, aggression, depression, attention problems, atypicality, and withdrawal. The BASC-2 test manual reports the following technical adequacy means for this composite scale: alpha reliability .97; test-retest reliability, .94; and inter-rater reliability, .64.\n\nProsocial behavior ratings. To measure level of prosocial behavior, the authors used the BASC-2 Teacher Report Scale-Child Form Adaptive Scale, a composite scale made up of the following subscales: adaptability, social skills, leadership, study skills, and functional communication. The BASC-2 test manual reports the following technical adequacy means for this composite scale: alpha reliability, .97; test-retest reliability, .89; and inter-rater reliability, .61.\n\nOffice discipline referrals. Office discipline referrals (ODRs) are school-based forms designed to document serious behavioral incidents and track individual student behavior (Sugai, Sprague, Horner, & Walker, 2000). School staff issue ODRs to students for serious behavioral violations, including fighting, vandalism, harassment, or noncompliance. ODRs have been shown to possess sufficient construct validity as a behavioral measure (Irvin, Tobin, Sprague, Sugai, & Vincent, 2004) and adequate concurrent validity with standardized behavior rating scales (McIntosh, Campbell, Carter, & Zumbo, 2008; B. Walker, Cheney, Stage, & Blum, 2005), and ODRs have been moderately correlated with other indirect measures of problem behavior, such as student self-report of delinquent behavior (Gottfredson & Gottfredson, 1999). In addition, the number and type of ODRs received significantly predict a range of future outcomes, including violent events in school and dropout (Tobin & Sugai, 1999). Predictive validity from one year to the next for middle and high school students has been documented at .54 (Gottfredson & Gottfredson, 1999), within the reported range of some standardized behavior rating scales.\n\nWhen incidents of problem behavior occur in the participating district, school personnel complete ODR forms, which are entered into the School-Wide Information System (SWIS; May et al., 2002), a Web-based ODR data system, to tally total ODRs per year. To increase the reliability of ODR data, the district conducts regular trainings on discriminating between behaviors that do and do not warrant a referral, based on definitions used in the SWIS.\n\n# Procedures\n\nThe Check-In/Check-Out intervention was implemented as described in the manual (Crone et al., 2003), with the school's tier one expectations used as the student behaviors to be rated (e.g., Safe, Respectful, Responsible) and no modification or individualization of goals or incentives. Before program implementation, the authors provided two 2-hour training sessions for school personnel and then provided monthly follow-up training sessions that stressed the critical features of the intervention and mechanisms of behavior improvement. The authors advised school administrators to identify school personnel with time at the start and finish of each day to serve as Check-In/Check-Out coordinators and mentors. In four of the schools, the school counselor served as the program coordinator and mentor for the participants. In one school, the special education teacher was the coordinator/mentor, and in the final school, an educational aide was the coordinator/mentor.\n\nStudents were referred to participate in the Check-In/Check-Out intervention by their classroom teachers through their usual school's request for assistance and behavior assistance team process. Prior to beginning the intervention, each student received a brief training session conducted by school personnel that (a) taught the daily routines of the Check-In/Check-Out program, (b) provided examples and non-examples of appropriate behavior in school, and (c) provided the student opportunities to practice the daily routines of the program. After training, the student began the program.\n\nMeasurement. Upon referral for behavior support and parent consent, the school notified the researchers and an",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Numeric",
        "evidence_source": "text",
        "evidence_context": "Two research studies provide the following technical adequacy data: test-retest reliability for function of .92 and agreement on function with direct observation results in 96% of cases (Borgmeier, 2003; McIntosh, Borgmeier, et al., 2008).",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/0aa598c735f77296910c9b61658e9411d38061dc817b9e35b5ea4867d83f7603.pdf_5",
        "ID": "00e954f6-f574-48f9-bd16-b04f2cf6c298",
        "questions": "Which individual served as the Check-In/Check-Out coordinator and mentor in one of the schools according to the procedures described in the intervention manual by Crone et al., 2003?",
        "answers": "In one school, the special education teacher was the coordinator/mentor.",
        "context": "To possess evidence of sufficient validity, reliability, and treatment utility when administered by trained graduate students (as in this study). Two research studies provide the following technical adequacy data: test-retest reliability for function of .92 and agreement on function with direct observation results in 96% of cases (Borgmeier, 2003; McIntosh, Borgmeier, et al., 2008).\n\nProblem behavior ratings. Levels of behavior were measured through the Behavior Assessment Scale for Children 2 (BASC-2; Reynolds & Kamphaus, 2004). The BASC-2 is a standardized, norm-referenced behavior rating scale for assessing levels of problem behavior in school-aged students. The BASC-2 was selected because of its recent revision, its psychometric properties, and its updated, representative normative group. The measure also contains four validity indices to control for biased responding. The form used in this study was the BASC-2 Teacher Report Scale-Child Form, designed to rate the behavior of students aged 6 to 11 years. Composite scales for the BASC-2 are reported as T scores, with a mean of 50 and a standard deviation of 10. To measure level of problem behavior, the authors used the Behavioral Symptoms Index (BSI), a composite scale made up of the following subscales: hyperactivity, aggression, depression, attention problems, atypicality, and withdrawal. The BASC-2 test manual reports the following technical adequacy means for this composite scale: alpha reliability .97; test-retest reliability, .94; and inter-rater reliability, .64.\n\nProsocial behavior ratings. To measure level of prosocial behavior, the authors used the BASC-2 Teacher Report Scale-Child Form Adaptive Scale, a composite scale made up of the following subscales: adaptability, social skills, leadership, study skills, and functional communication. The BASC-2 test manual reports the following technical adequacy means for this composite scale: alpha reliability, .97; test-retest reliability, .89; and inter-rater reliability, .61.\n\nOffice discipline referrals. Office discipline referrals (ODRs) are school-based forms designed to document serious behavioral incidents and track individual student behavior (Sugai, Sprague, Horner, & Walker, 2000). School staff issue ODRs to students for serious behavioral violations, including fighting, vandalism, harassment, or noncompliance. ODRs have been shown to possess sufficient construct validity as a behavioral measure (Irvin, Tobin, Sprague, Sugai, & Vincent, 2004) and adequate concurrent validity with standardized behavior rating scales (McIntosh, Campbell, Carter, & Zumbo, 2008; B. Walker, Cheney, Stage, & Blum, 2005), and ODRs have been moderately correlated with other indirect measures of problem behavior, such as student self-report of delinquent behavior (Gottfredson & Gottfredson, 1999). In addition, the number and type of ODRs received significantly predict a range of future outcomes, including violent events in school and dropout (Tobin & Sugai, 1999). Predictive validity from one year to the next for middle and high school students has been documented at .54 (Gottfredson & Gottfredson, 1999), within the reported range of some standardized behavior rating scales.\n\nWhen incidents of problem behavior occur in the participating district, school personnel complete ODR forms, which are entered into the School-Wide Information System (SWIS; May et al., 2002), a Web-based ODR data system, to tally total ODRs per year. To increase the reliability of ODR data, the district conducts regular trainings on discriminating between behaviors that do and do not warrant a referral, based on definitions used in the SWIS.\n\n# Procedures\n\nThe Check-In/Check-Out intervention was implemented as described in the manual (Crone et al., 2003), with the school's tier one expectations used as the student behaviors to be rated (e.g., Safe, Respectful, Responsible) and no modification or individualization of goals or incentives. Before program implementation, the authors provided two 2-hour training sessions for school personnel and then provided monthly follow-up training sessions that stressed the critical features of the intervention and mechanisms of behavior improvement. The authors advised school administrators to identify school personnel with time at the start and finish of each day to serve as Check-In/Check-Out coordinators and mentors. In four of the schools, the school counselor served as the program coordinator and mentor for the participants. In one school, the special education teacher was the coordinator/mentor, and in the final school, an educational aide was the coordinator/mentor.\n\nStudents were referred to participate in the Check-In/Check-Out intervention by their classroom teachers through their usual school's request for assistance and behavior assistance team process. Prior to beginning the intervention, each student received a brief training session conducted by school personnel that (a) taught the daily routines of the Check-In/Check-Out program, (b) provided examples and non-examples of appropriate behavior in school, and (c) provided the student opportunities to practice the daily routines of the program. After training, the student began the program.\n\nMeasurement. Upon referral for behavior support and parent consent, the school notified the researchers and an",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "In one school, the special education teacher was the coordinator/mentor, and in the final school, an educational aide was the coordinator/mentor.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/0aa598c735f77296910c9b61658e9411d38061dc817b9e35b5ea4867d83f7603.pdf_5",
        "ID": "00f24603-8295-4fe0-92c5-53b5d2f74429",
        "questions": "Does the BASC-2 Teacher Report Scale-Child Form Adaptive Scale have higher alpha reliability compared to its inter-rater reliability?",
        "answers": "Yes",
        "context": "To possess evidence of sufficient validity, reliability, and treatment utility when administered by trained graduate students (as in this study). Two research studies provide the following technical adequacy data: test-retest reliability for function of .92 and agreement on function with direct observation results in 96% of cases (Borgmeier, 2003; McIntosh, Borgmeier, et al., 2008).\n\nProblem behavior ratings. Levels of behavior were measured through the Behavior Assessment Scale for Children 2 (BASC-2; Reynolds & Kamphaus, 2004). The BASC-2 is a standardized, norm-referenced behavior rating scale for assessing levels of problem behavior in school-aged students. The BASC-2 was selected because of its recent revision, its psychometric properties, and its updated, representative normative group. The measure also contains four validity indices to control for biased responding. The form used in this study was the BASC-2 Teacher Report Scale-Child Form, designed to rate the behavior of students aged 6 to 11 years. Composite scales for the BASC-2 are reported as T scores, with a mean of 50 and a standard deviation of 10. To measure level of problem behavior, the authors used the Behavioral Symptoms Index (BSI), a composite scale made up of the following subscales: hyperactivity, aggression, depression, attention problems, atypicality, and withdrawal. The BASC-2 test manual reports the following technical adequacy means for this composite scale: alpha reliability .97; test-retest reliability, .94; and inter-rater reliability, .64.\n\nProsocial behavior ratings. To measure level of prosocial behavior, the authors used the BASC-2 Teacher Report Scale-Child Form Adaptive Scale, a composite scale made up of the following subscales: adaptability, social skills, leadership, study skills, and functional communication. The BASC-2 test manual reports the following technical adequacy means for this composite scale: alpha reliability, .97; test-retest reliability, .89; and inter-rater reliability, .61.\n\nOffice discipline referrals. Office discipline referrals (ODRs) are school-based forms designed to document serious behavioral incidents and track individual student behavior (Sugai, Sprague, Horner, & Walker, 2000). School staff issue ODRs to students for serious behavioral violations, including fighting, vandalism, harassment, or noncompliance. ODRs have been shown to possess sufficient construct validity as a behavioral measure (Irvin, Tobin, Sprague, Sugai, & Vincent, 2004) and adequate concurrent validity with standardized behavior rating scales (McIntosh, Campbell, Carter, & Zumbo, 2008; B. Walker, Cheney, Stage, & Blum, 2005), and ODRs have been moderately correlated with other indirect measures of problem behavior, such as student self-report of delinquent behavior (Gottfredson & Gottfredson, 1999). In addition, the number and type of ODRs received significantly predict a range of future outcomes, including violent events in school and dropout (Tobin & Sugai, 1999). Predictive validity from one year to the next for middle and high school students has been documented at .54 (Gottfredson & Gottfredson, 1999), within the reported range of some standardized behavior rating scales.\n\nWhen incidents of problem behavior occur in the participating district, school personnel complete ODR forms, which are entered into the School-Wide Information System (SWIS; May et al., 2002), a Web-based ODR data system, to tally total ODRs per year. To increase the reliability of ODR data, the district conducts regular trainings on discriminating between behaviors that do and do not warrant a referral, based on definitions used in the SWIS.\n\n# Procedures\n\nThe Check-In/Check-Out intervention was implemented as described in the manual (Crone et al., 2003), with the school's tier one expectations used as the student behaviors to be rated (e.g., Safe, Respectful, Responsible) and no modification or individualization of goals or incentives. Before program implementation, the authors provided two 2-hour training sessions for school personnel and then provided monthly follow-up training sessions that stressed the critical features of the intervention and mechanisms of behavior improvement. The authors advised school administrators to identify school personnel with time at the start and finish of each day to serve as Check-In/Check-Out coordinators and mentors. In four of the schools, the school counselor served as the program coordinator and mentor for the participants. In one school, the special education teacher was the coordinator/mentor, and in the final school, an educational aide was the coordinator/mentor.\n\nStudents were referred to participate in the Check-In/Check-Out intervention by their classroom teachers through their usual school's request for assistance and behavior assistance team process. Prior to beginning the intervention, each student received a brief training session conducted by school personnel that (a) taught the daily routines of the Check-In/Check-Out program, (b) provided examples and non-examples of appropriate behavior in school, and (c) provided the student opportunities to practice the daily routines of the program. After training, the student began the program.\n\nMeasurement. Upon referral for behavior support and parent consent, the school notified the researchers and an",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Yes/No",
        "evidence_source": "text",
        "evidence_context": "The BASC-2 test manual reports the following technical adequacy means for this composite scale: alpha reliability, .97; test-retest reliability, .89; and inter-rater reliability, .61.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTX_-_Graphs_and_Matrices,_Second_Edition.pdf_116",
        "ID": "00f276c9-41cf-41a1-bdc5-515ab78331b9",
        "questions": "What theorem provides a representation for the second smallest eigenvalue of a symmetric matrix?",
        "answers": "spectral theorem",
        "context": "Further, the vertices in any component of $T\\setminus\\{k\\}$ are either all positive, all negative, or all zero. It follows that the subgraph of $T$ induced by the zero vertices is connected. The proof of the second part is similar to the one given for (i).\n\n# 8.4 Bounds for Algebraic Connectivity\n\nThe following representation for the second smallest eigenvalue of a symmetric matrix will be used. It is easily derived from the spectral theorem.\n\nLemma 8.15 Let A be a symmetric $n\\times n$ matrix with eigenvalues $\\lambda_{1} \\geq \\cdot\\cdot\\cdot \\geq \\lambda_{n-1} \\geq \\lambda_{n}$. Let u be an eigenvector of $A$ corresponding to $\\lambda_{n}$. Then\n\n$$\n\\lambda_{n-1}=\\operatorname*{min}\\left\\{{\\frac{x^{\\prime}A x}{x^{\\prime}x}}\\right\\},\n$$\n\nwhere the minimum is taken over all nonzero vectors $x$, orthogonal to $u$.\n\nWe introduce some notation. Let $G$ be a connected graph with $V(G)=\\{1,.\\,.\\,.\\,,n\\}$. If $i,j\\in V(G)$, then as usual the distance between $i$ and $j$, denoted $d(i,j)$, is defined to be the length (that is, the number of edges) in the shortest $(i j)$-path. We set $d(i,i)=0, i=1,.\\,.\\,.\\,,n$. If $V_{1}$, $V_{2}\\subset V(G)$ are nonempty sets, then define\n\n$$\nd(V_{1},V_{2})=\\operatorname*{min}\\{d(i,j):i\\in V_{1},\\,j\\in V_{2}\\}.\n$$\n\nIf $V_{1}=\\{i\\}$, we write $d(V_{1},V_{2})$ as $d(i,V_{2})$.\n\nTheorem 8.16 Let $G$ be a connected graph with $V(G)=\\{1,.\\,.\\,.\\,,n\\}$. Let $V_{1}$ and $V_{2}$ be nonempty disjoint subsets of $V(G)$, and let $G_{1}$ and $G_{2}$ be the subgraphs induced by $V_{1}$ and $V_{2}$, respectively. Let $L$ be the Laplacian of $G$ and $\\mu$ the algebraic connectivity. Then\n\n$$\n\\mu\\leq\\frac{1}{d(V_{1},V_{2})^{2}}\\left(\\frac{1}{|V_{1}|}+\\frac{1}{|V_{2}|}\\right)(|E(G)|-|E(G_{1})|-|E(G_{2})|).\n$$\n\nProof Let\n\n$$\ng(i)=\\frac{1}{|V_{1}|}-\\frac{1}{d(V_{1},V_{2})}\\left(\\frac{1}{|V_{1}|}+\\frac{1}{|V_{2}|}\\right)\\operatorname*{min}\\{d(i,V_{1}),d(V_{1},V_{2})\\},\n$$\n\n$i=1,\\dots,n$, $i\\in V_{1}$, $\\begin{array}{r}{g(i)=\\frac{1}{|V_{1}|}}\\end{array}$, $i\\in V_{2}$, $g(i)=-\\frac{1}{|V_{2}|}$. Also, if $i\\sim j$, then $|d(i,V_{1})-d(j,V_{2})|\\leq1$ and hence\n\n$$\n|g(i)-g(j)|\\leq{\\frac{1}{d(V_{1},\\,V_{2})}}\\,\\bigg({\\frac{1}{|V_{1}|}}+{\\frac{1}{|V_{2}|}}\\bigg).\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "The following representation for the second smallest eigenvalue of a symmetric matrix will be used. It is easily derived from the spectral theorem.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTX_-_Graphs_and_Matrices,_Second_Edition.pdf_116",
        "ID": "00f520f4-9ef1-4846-9dbc-24fd0a8aa1e4",
        "questions": "How is the minimum value of the second smallest eigenvalue expression determined according to Lemma 8.15?",
        "answers": "over all nonzero vectors x, orthogonal to u",
        "context": "Further, the vertices in any component of $T\\setminus\\{k\\}$ are either all positive, all negative, or all zero. It follows that the subgraph of $T$ induced by the zero vertices is connected. The proof of the second part is similar to the one given for (i).\n\n# 8.4 Bounds for Algebraic Connectivity\n\nThe following representation for the second smallest eigenvalue of a symmetric matrix will be used. It is easily derived from the spectral theorem.\n\nLemma 8.15 Let A be a symmetric $n\\times n$ matrix with eigenvalues $\\lambda_{1} \\geq \\cdot\\cdot\\cdot \\geq \\lambda_{n-1} \\geq \\lambda_{n}$. Let u be an eigenvector of $A$ corresponding to $\\lambda_{n}$. Then\n\n$$\n\\lambda_{n-1}=\\operatorname*{min}\\left\\{{\\frac{x^{\\prime}A x}{x^{\\prime}x}}\\right\\},\n$$\n\nwhere the minimum is taken over all nonzero vectors $x$, orthogonal to $u$.\n\nWe introduce some notation. Let $G$ be a connected graph with $V(G)=\\{1,.\\,.\\,.\\,,n\\}$. If $i,j\\in V(G)$, then as usual the distance between $i$ and $j$, denoted $d(i,j)$, is defined to be the length (that is, the number of edges) in the shortest $(i j)$-path. We set $d(i,i)=0, i=1,.\\,.\\,.\\,,n$. If $V_{1}$, $V_{2}\\subset V(G)$ are nonempty sets, then define\n\n$$\nd(V_{1},V_{2})=\\operatorname*{min}\\{d(i,j):i\\in V_{1},\\,j\\in V_{2}\\}.\n$$\n\nIf $V_{1}=\\{i\\}$, we write $d(V_{1},V_{2})$ as $d(i,V_{2})$.\n\nTheorem 8.16 Let $G$ be a connected graph with $V(G)=\\{1,.\\,.\\,.\\,,n\\}$. Let $V_{1}$ and $V_{2}$ be nonempty disjoint subsets of $V(G)$, and let $G_{1}$ and $G_{2}$ be the subgraphs induced by $V_{1}$ and $V_{2}$, respectively. Let $L$ be the Laplacian of $G$ and $\\mu$ the algebraic connectivity. Then\n\n$$\n\\mu\\leq\\frac{1}{d(V_{1},V_{2})^{2}}\\left(\\frac{1}{|V_{1}|}+\\frac{1}{|V_{2}|}\\right)(|E(G)|-|E(G_{1})|-|E(G_{2})|).\n$$\n\nProof Let\n\n$$\ng(i)=\\frac{1}{|V_{1}|}-\\frac{1}{d(V_{1},V_{2})}\\left(\\frac{1}{|V_{1}|}+\\frac{1}{|V_{2}|}\\right)\\operatorname*{min}\\{d(i,V_{1}),d(V_{1},V_{2})\\},\n$$\n\n$i=1,\\dots,n$, $i\\in V_{1}$, $\\begin{array}{r}{g(i)=\\frac{1}{|V_{1}|}}\\end{array}$, $i\\in V_{2}$, $g(i)=-\\frac{1}{|V_{2}|}$. Also, if $i\\sim j$, then $|d(i,V_{1})-d(j,V_{2})|\\leq1$ and hence\n\n$$\n|g(i)-g(j)|\\leq{\\frac{1}{d(V_{1},\\,V_{2})}}\\,\\bigg({\\frac{1}{|V_{1}|}}+{\\frac{1}{|V_{2}|}}\\bigg).\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Lemma 8.15 Let A be a symmetric $n\times n$ matrix with eigenvalues $\\lambda_{1} \\geq \\cdot\\cdot\\cdot \\geq \\lambda_{n-1} \\geq \\lambda_{n}$. Let u be an eigenvector of $A$ corresponding to $\\lambda_{n}$. Then \n$$\\lambda_{n-1}=\\operatorname*{min}\\left\\{{\frac{x^{\\prime}A x}{x^{\\prime}x}}\right\\},$$\nwhere the minimum is taken over all nonzero vectors $x$, orthogonal to $u$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTX_-_Graphs_and_Matrices,_Second_Edition.pdf_116",
        "ID": "01055b03-085b-4b3e-ab19-3fd25bbdb887",
        "questions": "What function is used in Theorem 8.16 to bound the algebraic connectivity of a connected graph?",
        "answers": "$\\mu\\leq\\frac{1}{d(V_{1},V_{2})^{2}}\\left(\\frac{1}{|V_{1}|} + \\frac{1}{|V_{2}|}\\right)(|E(G)|-|E(G_{1})|-|E(G_{2})|)$",
        "context": "Further, the vertices in any component of $T\\setminus\\{k\\}$ are either all positive, all negative, or all zero. It follows that the subgraph of $T$ induced by the zero vertices is connected. The proof of the second part is similar to the one given for (i).\n\n# 8.4 Bounds for Algebraic Connectivity\n\nThe following representation for the second smallest eigenvalue of a symmetric matrix will be used. It is easily derived from the spectral theorem.\n\nLemma 8.15 Let A be a symmetric $n\\times n$ matrix with eigenvalues $\\lambda_{1} \\geq \\cdot\\cdot\\cdot \\geq \\lambda_{n-1} \\geq \\lambda_{n}$. Let u be an eigenvector of $A$ corresponding to $\\lambda_{n}$. Then\n\n$$\n\\lambda_{n-1}=\\operatorname*{min}\\left\\{{\\frac{x^{\\prime}A x}{x^{\\prime}x}}\\right\\},\n$$\n\nwhere the minimum is taken over all nonzero vectors $x$, orthogonal to $u$.\n\nWe introduce some notation. Let $G$ be a connected graph with $V(G)=\\{1,.\\,.\\,.\\,,n\\}$. If $i,j\\in V(G)$, then as usual the distance between $i$ and $j$, denoted $d(i,j)$, is defined to be the length (that is, the number of edges) in the shortest $(i j)$-path. We set $d(i,i)=0, i=1,.\\,.\\,.\\,,n$. If $V_{1}$, $V_{2}\\subset V(G)$ are nonempty sets, then define\n\n$$\nd(V_{1},V_{2})=\\operatorname*{min}\\{d(i,j):i\\in V_{1},\\,j\\in V_{2}\\}.\n$$\n\nIf $V_{1}=\\{i\\}$, we write $d(V_{1},V_{2})$ as $d(i,V_{2})$.\n\nTheorem 8.16 Let $G$ be a connected graph with $V(G)=\\{1,.\\,.\\,.\\,,n\\}$. Let $V_{1}$ and $V_{2}$ be nonempty disjoint subsets of $V(G)$, and let $G_{1}$ and $G_{2}$ be the subgraphs induced by $V_{1}$ and $V_{2}$, respectively. Let $L$ be the Laplacian of $G$ and $\\mu$ the algebraic connectivity. Then\n\n$$\n\\mu\\leq\\frac{1}{d(V_{1},V_{2})^{2}}\\left(\\frac{1}{|V_{1}|}+\\frac{1}{|V_{2}|}\\right)(|E(G)|-|E(G_{1})|-|E(G_{2})|).\n$$\n\nProof Let\n\n$$\ng(i)=\\frac{1}{|V_{1}|}-\\frac{1}{d(V_{1},V_{2})}\\left(\\frac{1}{|V_{1}|}+\\frac{1}{|V_{2}|}\\right)\\operatorname*{min}\\{d(i,V_{1}),d(V_{1},V_{2})\\},\n$$\n\n$i=1,\\dots,n$, $i\\in V_{1}$, $\\begin{array}{r}{g(i)=\\frac{1}{|V_{1}|}}\\end{array}$, $i\\in V_{2}$, $g(i)=-\\frac{1}{|V_{2}|}$. Also, if $i\\sim j$, then $|d(i,V_{1})-d(j,V_{2})|\\leq1$ and hence\n\n$$\n|g(i)-g(j)|\\leq{\\frac{1}{d(V_{1},\\,V_{2})}}\\,\\bigg({\\frac{1}{|V_{1}|}}+{\\frac{1}{|V_{2}|}}\\bigg).\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Equation",
        "evidence_source": "text",
        "evidence_context": "Theorem 8.16 Let $G$ be a connected graph with $V(G)=\\{1,.\\,.\\,.\\,,n\\}$. Let $V_{1}$ and $V_{2}$ be nonempty disjoint subsets of $V(G)$, and let $G_{1}$ and $G_{2}$ be the subgraphs induced by $V_{1}$ and $V_{2}$, respectively. Let $L$ be the Laplacian of $G$ and $\\mu$ the algebraic connectivity. Then \n$$\\mu\\leq\\frac{1}{d(V_{1},V_{2})^{2}}\\left(\\frac{1}{|V_{1}|} + \\frac{1}{|V_{2}|}\\right)(|E(G)|-|E(G_{1})|-|E(G_{2})|).$$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTX_-_Graphs_and_Matrices,_Second_Edition.pdf_116",
        "ID": "010bd4fe-5789-4404-b84b-f63b4f3ef6b2",
        "questions": "What is the expression for the second smallest eigenvalue of a symmetric matrix \\( A \\) in terms of a nonzero vector \\( x \\) orthogonal to the eigenvector corresponding to the smallest eigenvalue?",
        "answers": "\\(\\lambda_{n-1}=\\operatorname*{min}\\left\\{\frac{x^{\\prime}A x}{x^{\\prime}x}\right\\}\\)",
        "context": "Further, the vertices in any component of $T\\setminus\\{k\\}$ are either all positive, all negative, or all zero. It follows that the subgraph of $T$ induced by the zero vertices is connected. The proof of the second part is similar to the one given for (i).\n\n# 8.4 Bounds for Algebraic Connectivity\n\nThe following representation for the second smallest eigenvalue of a symmetric matrix will be used. It is easily derived from the spectral theorem.\n\nLemma 8.15 Let A be a symmetric $n\\times n$ matrix with eigenvalues $\\lambda_{1} \\geq \\cdot\\cdot\\cdot \\geq \\lambda_{n-1} \\geq \\lambda_{n}$. Let u be an eigenvector of $A$ corresponding to $\\lambda_{n}$. Then\n\n$$\n\\lambda_{n-1}=\\operatorname*{min}\\left\\{{\\frac{x^{\\prime}A x}{x^{\\prime}x}}\\right\\},\n$$\n\nwhere the minimum is taken over all nonzero vectors $x$, orthogonal to $u$.\n\nWe introduce some notation. Let $G$ be a connected graph with $V(G)=\\{1,.\\,.\\,.\\,,n\\}$. If $i,j\\in V(G)$, then as usual the distance between $i$ and $j$, denoted $d(i,j)$, is defined to be the length (that is, the number of edges) in the shortest $(i j)$-path. We set $d(i,i)=0, i=1,.\\,.\\,.\\,,n$. If $V_{1}$, $V_{2}\\subset V(G)$ are nonempty sets, then define\n\n$$\nd(V_{1},V_{2})=\\operatorname*{min}\\{d(i,j):i\\in V_{1},\\,j\\in V_{2}\\}.\n$$\n\nIf $V_{1}=\\{i\\}$, we write $d(V_{1},V_{2})$ as $d(i,V_{2})$.\n\nTheorem 8.16 Let $G$ be a connected graph with $V(G)=\\{1,.\\,.\\,.\\,,n\\}$. Let $V_{1}$ and $V_{2}$ be nonempty disjoint subsets of $V(G)$, and let $G_{1}$ and $G_{2}$ be the subgraphs induced by $V_{1}$ and $V_{2}$, respectively. Let $L$ be the Laplacian of $G$ and $\\mu$ the algebraic connectivity. Then\n\n$$\n\\mu\\leq\\frac{1}{d(V_{1},V_{2})^{2}}\\left(\\frac{1}{|V_{1}|}+\\frac{1}{|V_{2}|}\\right)(|E(G)|-|E(G_{1})|-|E(G_{2})|).\n$$\n\nProof Let\n\n$$\ng(i)=\\frac{1}{|V_{1}|}-\\frac{1}{d(V_{1},V_{2})}\\left(\\frac{1}{|V_{1}|}+\\frac{1}{|V_{2}|}\\right)\\operatorname*{min}\\{d(i,V_{1}),d(V_{1},V_{2})\\},\n$$\n\n$i=1,\\dots,n$, $i\\in V_{1}$, $\\begin{array}{r}{g(i)=\\frac{1}{|V_{1}|}}\\end{array}$, $i\\in V_{2}$, $g(i)=-\\frac{1}{|V_{2}|}$. Also, if $i\\sim j$, then $|d(i,V_{1})-d(j,V_{2})|\\leq1$ and hence\n\n$$\n|g(i)-g(j)|\\leq{\\frac{1}{d(V_{1},\\,V_{2})}}\\,\\bigg({\\frac{1}{|V_{1}|}}+{\\frac{1}{|V_{2}|}}\\bigg).\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Then $$ \\lambda_{n-1}=\\operatorname*{min}\\left\\{{\frac{x^{\\prime}A x}{x^{\\prime}x}}\right\\}, $$ where the minimum is taken over all nonzero vectors \\( x \\), orthogonal to \\( u \\).",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/UTX_-_Graphs_and_Matrices,_Second_Edition.pdf_116",
        "ID": "0111aca2-9949-47f1-a83d-53d5bce4588e",
        "questions": "For a connected graph \\( G \\) with vertex set \\( V(G) = \\{1, 2, ..., n\\} \\) and Laplacian \\( L \\), how is the algebraic connectivity \\( \\mu \\) bounded above in terms of the distance between two nonempty disjoint subsets \\( V_1 \\) and \\( V_2 \\) of \\( V(G) \\)?",
        "answers": "\\(\\mu \\leq \frac{1}{d(V_{1},V_{2})^{2}}\\left(\frac{1}{|V_{1}|}+\frac{1}{|V_{2}|}\right)(|E(G)|-|E(G_{1})|-|E(G_{2})|) \\)",
        "context": "Further, the vertices in any component of $T\\setminus\\{k\\}$ are either all positive, all negative, or all zero. It follows that the subgraph of $T$ induced by the zero vertices is connected. The proof of the second part is similar to the one given for (i).\n\n# 8.4 Bounds for Algebraic Connectivity\n\nThe following representation for the second smallest eigenvalue of a symmetric matrix will be used. It is easily derived from the spectral theorem.\n\nLemma 8.15 Let A be a symmetric $n\\times n$ matrix with eigenvalues $\\lambda_{1} \\geq \\cdot\\cdot\\cdot \\geq \\lambda_{n-1} \\geq \\lambda_{n}$. Let u be an eigenvector of $A$ corresponding to $\\lambda_{n}$. Then\n\n$$\n\\lambda_{n-1}=\\operatorname*{min}\\left\\{{\\frac{x^{\\prime}A x}{x^{\\prime}x}}\\right\\},\n$$\n\nwhere the minimum is taken over all nonzero vectors $x$, orthogonal to $u$.\n\nWe introduce some notation. Let $G$ be a connected graph with $V(G)=\\{1,.\\,.\\,.\\,,n\\}$. If $i,j\\in V(G)$, then as usual the distance between $i$ and $j$, denoted $d(i,j)$, is defined to be the length (that is, the number of edges) in the shortest $(i j)$-path. We set $d(i,i)=0, i=1,.\\,.\\,.\\,,n$. If $V_{1}$, $V_{2}\\subset V(G)$ are nonempty sets, then define\n\n$$\nd(V_{1},V_{2})=\\operatorname*{min}\\{d(i,j):i\\in V_{1},\\,j\\in V_{2}\\}.\n$$\n\nIf $V_{1}=\\{i\\}$, we write $d(V_{1},V_{2})$ as $d(i,V_{2})$.\n\nTheorem 8.16 Let $G$ be a connected graph with $V(G)=\\{1,.\\,.\\,.\\,,n\\}$. Let $V_{1}$ and $V_{2}$ be nonempty disjoint subsets of $V(G)$, and let $G_{1}$ and $G_{2}$ be the subgraphs induced by $V_{1}$ and $V_{2}$, respectively. Let $L$ be the Laplacian of $G$ and $\\mu$ the algebraic connectivity. Then\n\n$$\n\\mu\\leq\\frac{1}{d(V_{1},V_{2})^{2}}\\left(\\frac{1}{|V_{1}|}+\\frac{1}{|V_{2}|}\\right)(|E(G)|-|E(G_{1})|-|E(G_{2})|).\n$$\n\nProof Let\n\n$$\ng(i)=\\frac{1}{|V_{1}|}-\\frac{1}{d(V_{1},V_{2})}\\left(\\frac{1}{|V_{1}|}+\\frac{1}{|V_{2}|}\\right)\\operatorname*{min}\\{d(i,V_{1}),d(V_{1},V_{2})\\},\n$$\n\n$i=1,\\dots,n$, $i\\in V_{1}$, $\\begin{array}{r}{g(i)=\\frac{1}{|V_{1}|}}\\end{array}$, $i\\in V_{2}$, $g(i)=-\\frac{1}{|V_{2}|}$. Also, if $i\\sim j$, then $|d(i,V_{1})-d(j,V_{2})|\\leq1$ and hence\n\n$$\n|g(i)-g(j)|\\leq{\\frac{1}{d(V_{1},\\,V_{2})}}\\,\\bigg({\\frac{1}{|V_{1}|}}+{\\frac{1}{|V_{2}|}}\\bigg).\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Then $$ \\mu\\leq\frac{1}{d(V_{1},V_{2})^{2}}\\left(\frac{1}{|V_{1}|}+\frac{1}{|V_{2}|}\right)(|E(G)|-|E(G_{1})|-|E(G_{2})|).$$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/UTX_-_Graphs_and_Matrices,_Second_Edition.pdf_116",
        "ID": "01364fc5-1a6e-497f-83cd-7bab667b94c9",
        "questions": "In Theorem 8.16, when \\( i \\in V_1 \\), how is the function \\( g(i) \\) defined?",
        "answers": "\\[ g(i)=\frac{1}{|V_{1}|}-\frac{1}{d(V_{1},V_{2})}\\left(\frac{1}{|V_{1}|}+\frac{1}{|V_{2}|}\right)\\operatorname*{min}\\{d(i,V_{1}),d(V_{1},V_{2})\\}\\]",
        "context": "Further, the vertices in any component of $T\\setminus\\{k\\}$ are either all positive, all negative, or all zero. It follows that the subgraph of $T$ induced by the zero vertices is connected. The proof of the second part is similar to the one given for (i).\n\n# 8.4 Bounds for Algebraic Connectivity\n\nThe following representation for the second smallest eigenvalue of a symmetric matrix will be used. It is easily derived from the spectral theorem.\n\nLemma 8.15 Let A be a symmetric $n\\times n$ matrix with eigenvalues $\\lambda_{1} \\geq \\cdot\\cdot\\cdot \\geq \\lambda_{n-1} \\geq \\lambda_{n}$. Let u be an eigenvector of $A$ corresponding to $\\lambda_{n}$. Then\n\n$$\n\\lambda_{n-1}=\\operatorname*{min}\\left\\{{\\frac{x^{\\prime}A x}{x^{\\prime}x}}\\right\\},\n$$\n\nwhere the minimum is taken over all nonzero vectors $x$, orthogonal to $u$.\n\nWe introduce some notation. Let $G$ be a connected graph with $V(G)=\\{1,.\\,.\\,.\\,,n\\}$. If $i,j\\in V(G)$, then as usual the distance between $i$ and $j$, denoted $d(i,j)$, is defined to be the length (that is, the number of edges) in the shortest $(i j)$-path. We set $d(i,i)=0, i=1,.\\,.\\,.\\,,n$. If $V_{1}$, $V_{2}\\subset V(G)$ are nonempty sets, then define\n\n$$\nd(V_{1},V_{2})=\\operatorname*{min}\\{d(i,j):i\\in V_{1},\\,j\\in V_{2}\\}.\n$$\n\nIf $V_{1}=\\{i\\}$, we write $d(V_{1},V_{2})$ as $d(i,V_{2})$.\n\nTheorem 8.16 Let $G$ be a connected graph with $V(G)=\\{1,.\\,.\\,.\\,,n\\}$. Let $V_{1}$ and $V_{2}$ be nonempty disjoint subsets of $V(G)$, and let $G_{1}$ and $G_{2}$ be the subgraphs induced by $V_{1}$ and $V_{2}$, respectively. Let $L$ be the Laplacian of $G$ and $\\mu$ the algebraic connectivity. Then\n\n$$\n\\mu\\leq\\frac{1}{d(V_{1},V_{2})^{2}}\\left(\\frac{1}{|V_{1}|}+\\frac{1}{|V_{2}|}\\right)(|E(G)|-|E(G_{1})|-|E(G_{2})|).\n$$\n\nProof Let\n\n$$\ng(i)=\\frac{1}{|V_{1}|}-\\frac{1}{d(V_{1},V_{2})}\\left(\\frac{1}{|V_{1}|}+\\frac{1}{|V_{2}|}\\right)\\operatorname*{min}\\{d(i,V_{1}),d(V_{1},V_{2})\\},\n$$\n\n$i=1,\\dots,n$, $i\\in V_{1}$, $\\begin{array}{r}{g(i)=\\frac{1}{|V_{1}|}}\\end{array}$, $i\\in V_{2}$, $g(i)=-\\frac{1}{|V_{2}|}$. Also, if $i\\sim j$, then $|d(i,V_{1})-d(j,V_{2})|\\leq1$ and hence\n\n$$\n|g(i)-g(j)|\\leq{\\frac{1}{d(V_{1},\\,V_{2})}}\\,\\bigg({\\frac{1}{|V_{1}|}}+{\\frac{1}{|V_{2}|}}\\bigg).\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Proof Let $$ g(i)=\frac{1}{|V_{1}|}-\frac{1}{d(V_{1},V_{2})}\\left(\frac{1}{|V_{1}|}+\frac{1}{|V_{2}|}\right)\\operatorname*{min}\\{d(i,V_{1}),d(V_{1},V_{2})\\}, $$ i=1,\\dots,n, i \\in V_{1} ",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/c22e1a4acbd2d996ff19a852585f9434883c30124f6b118eb9152fe4e5ee7994.pdf_38",
        "ID": "013a3cfa-d2b2-4882-bb2d-32d0a65c2fea",
        "questions": "What is the decrease in IkB after EPA treatment indicative of according to the time course experiment?",
        "answers": "EPA stimulated an inflammatory response.",
        "context": "bEnd.3 cells as the responses to the FFAR4 agonist EPA were similar to AH-7614. Alternatively, AH-7614 and EPA may be stimulating a receptor other than FFAR4 to mediate these anti-inflammatory effects (although there is no evidence for this in the literature).  \n\nAfter evaluating the data, it became apparent that the change in protein expression did not align with our original hypothesis. For the time course experiment, the decrease in IkB after 24 hours of EPA treatment suggests EPA stimulated an inflammatory response and should have increased VCAM-1. However, there was no change in VCAM-1 expression. Previous work in this laboratory evaluated the impact of EPA on Cx43 expression and only observed a decrease in CX43 after 48 hours. As Cx43 expression is increased by inflammation through the NF-$\\kappa$B pathway, the decrease in Cx43 suggests the reduction in inflammation to EPA might have occurred at a later time than we evaluated (i.e., 48 hours). However, AH-7614 and EPA decreased VCAM-1 after 24 hours in later experiments (figure 8). The issue with our initial data (figure 5) may be the challenges associated with time course experiments. This likely increased the variability in the data along with the degradation in samples, making it difficult to find significance.  \n\nThe majority of this discussion has revolved around the decreased inflammatory response after 24 hours. However, we also observed an increased inflammatory response after 1.5 hours (figure 7). This observation is not consistent with the reported anti-inflammatory effects of the FFAR4. However, previous studies evaluating FFAR4 responses used later times (6-48 hours), with the earliest evaluated pERK showing a rapid peak after 2.5 minutes, which would precede any changes in IrB and/or plKK as phosphorylation of ERK activates the NF-$\\kappa$B pathway (figure 3). Responses to FFAR4 (a $\\mathrm{G}\\alpha_{\\mathrm{q}}$ receptor) may initially activate the NF-$\\kappa$B pathway enough to",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "For the time course experiment, the decrease in IkB after 24 hours of EPA treatment suggests EPA stimulated an inflammatory response and should have increased VCAM-1.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/c22e1a4acbd2d996ff19a852585f9434883c30124f6b118eb9152fe4e5ee7994.pdf_38",
        "ID": "0140a718-b50a-4a65-aca3-6771c7ef28e7",
        "questions": "In the experiment, which protein's expression was not changed despite EPA treatment for 24 hours?",
        "answers": "VCAM-1",
        "context": "bEnd.3 cells as the responses to the FFAR4 agonist EPA were similar to AH-7614. Alternatively, AH-7614 and EPA may be stimulating a receptor other than FFAR4 to mediate these anti-inflammatory effects (although there is no evidence for this in the literature).  \n\nAfter evaluating the data, it became apparent that the change in protein expression did not align with our original hypothesis. For the time course experiment, the decrease in IkB after 24 hours of EPA treatment suggests EPA stimulated an inflammatory response and should have increased VCAM-1. However, there was no change in VCAM-1 expression. Previous work in this laboratory evaluated the impact of EPA on Cx43 expression and only observed a decrease in CX43 after 48 hours. As Cx43 expression is increased by inflammation through the NF-$\\kappa$B pathway, the decrease in Cx43 suggests the reduction in inflammation to EPA might have occurred at a later time than we evaluated (i.e., 48 hours). However, AH-7614 and EPA decreased VCAM-1 after 24 hours in later experiments (figure 8). The issue with our initial data (figure 5) may be the challenges associated with time course experiments. This likely increased the variability in the data along with the degradation in samples, making it difficult to find significance.  \n\nThe majority of this discussion has revolved around the decreased inflammatory response after 24 hours. However, we also observed an increased inflammatory response after 1.5 hours (figure 7). This observation is not consistent with the reported anti-inflammatory effects of the FFAR4. However, previous studies evaluating FFAR4 responses used later times (6-48 hours), with the earliest evaluated pERK showing a rapid peak after 2.5 minutes, which would precede any changes in IrB and/or plKK as phosphorylation of ERK activates the NF-$\\kappa$B pathway (figure 3). Responses to FFAR4 (a $\\mathrm{G}\\alpha_{\\mathrm{q}}$ receptor) may initially activate the NF-$\\kappa$B pathway enough to",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "For the time course experiment, the decrease in IkB after 24 hours of EPA treatment suggests EPA stimulated an inflammatory response and should have increased VCAM-1. However, there was no change in VCAM-1 expression.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/c22e1a4acbd2d996ff19a852585f9434883c30124f6b118eb9152fe4e5ee7994.pdf_38",
        "ID": "0156f13c-8098-4b3e-8734-627f1c3726f5",
        "questions": "What does the data from figure 8 suggest about the effect of AH-7614 and EPA after 24 hours?",
        "answers": "AH-7614 and EPA decreased VCAM-1 after 24 hours in later experiments.",
        "context": "bEnd.3 cells as the responses to the FFAR4 agonist EPA were similar to AH-7614. Alternatively, AH-7614 and EPA may be stimulating a receptor other than FFAR4 to mediate these anti-inflammatory effects (although there is no evidence for this in the literature).  \n\nAfter evaluating the data, it became apparent that the change in protein expression did not align with our original hypothesis. For the time course experiment, the decrease in IkB after 24 hours of EPA treatment suggests EPA stimulated an inflammatory response and should have increased VCAM-1. However, there was no change in VCAM-1 expression. Previous work in this laboratory evaluated the impact of EPA on Cx43 expression and only observed a decrease in CX43 after 48 hours. As Cx43 expression is increased by inflammation through the NF-$\\kappa$B pathway, the decrease in Cx43 suggests the reduction in inflammation to EPA might have occurred at a later time than we evaluated (i.e., 48 hours). However, AH-7614 and EPA decreased VCAM-1 after 24 hours in later experiments (figure 8). The issue with our initial data (figure 5) may be the challenges associated with time course experiments. This likely increased the variability in the data along with the degradation in samples, making it difficult to find significance.  \n\nThe majority of this discussion has revolved around the decreased inflammatory response after 24 hours. However, we also observed an increased inflammatory response after 1.5 hours (figure 7). This observation is not consistent with the reported anti-inflammatory effects of the FFAR4. However, previous studies evaluating FFAR4 responses used later times (6-48 hours), with the earliest evaluated pERK showing a rapid peak after 2.5 minutes, which would precede any changes in IrB and/or plKK as phosphorylation of ERK activates the NF-$\\kappa$B pathway (figure 3). Responses to FFAR4 (a $\\mathrm{G}\\alpha_{\\mathrm{q}}$ receptor) may initially activate the NF-$\\kappa$B pathway enough to",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "However, AH-7614 and EPA decreased VCAM-1 after 24 hours in later experiments (figure 8).",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Goursat_E._-_A_course_in_mathematical_analysis._-_part.1_Variation_Of_Solutions_;Partial_Differential_Equations_Of_The_Second_Order._Vol.3-Ginn_(1916).pdf_304",
        "ID": "015a50ba-86d3-4bfe-9de4-5628ad100cbf",
        "questions": "What is the relation between the parameters a and b for the integral $e^{a x + b y}$?",
        "answers": "$b=a^{2}$",
        "context": "(III, 41) which here is  \n\n$$\n\\mathcal{G}(v)=\\frac{\\partial^{2}v}{\\partial x^{2}}+\\frac{\\partial v}{\\partial y}=0.\n$$  \n\nThese two equations have a single family of characteristics, which consists of parallels to the $x$-axis. We shall say that one of these functions, $u(x,y)$ or $v(x,y)$, is regular in a domain $D$ if it is continuous and has continuous first partial derivatives in this domain. It will even be sufficient to say that the derivative with respect to $y$ is continuous; for if $\\partial u/\\partial y$ for example, is a continuous function, equation (1) proves that the same is true of $\\partial^{2}u/\\partial x^{2}$ and, consequently, of $\\hat{c}u/\\hat{c}x$.\n\nSince equation (1) has constant coefficients, it possesses particular integrals of the form $e^{a x + b y}$ (III, 27); the relation between $a$ and $b$ is, in this case, $b=a^{2}$. From the integral $e^{a x + a^{2}y}$ thus obtained we can derive any infinity of others by taking its successive derivatives with respect to the parameter $a$, or, what amounts to the same thing, by taking the successive coefficients of the expansion of this integral, in powers of $a$. Let us write this expansion in the form  \n\n$$\ne^{\\alpha x+a^{2}y}=1\\,+\\sum_{n=1}^{+\\infty}\\frac{n^{n}}{n!}\\,V_{n}(x,\\,y)\\,;\n$$  \n\n$V_{n}(x,y)$ is a polynomial of degree $n$ in $x, y$ homogeneous in $x$ and $\\sqrt{y}$.\n\n$$\nV_{n}(x,y)\\,=\\,x^{n}\\,+\\,n(n-1)\\,x^{n-2}y\\,+\\ldots+\\frac{n(n-1)\\ldots(n-2p+1)}{p!}x^{n-2p}y^p+\\ldots\n$$  \n\nwhich is terminated by a term in $y^{\\frac{1}{2}n}$ if $n$ is even and by a term in $x y^{\\frac{1}{2}(n-1)}$, if $\\pi$ is odd. These polynomials $V_{n}$ are integrals of equation (1), from their very definition. We can easily verify this by observing that equation (3), differentiated with respect to $x$ and to $y$, gives the relations  \n\n$$\n\\frac{\\partial\\,V_{n}}{\\partial x}\\,=\\,n\\,V_{n-1},\\qquad\\frac{\\partial\\,V_{n}}{\\partial y}\\,=\\,n(n\\,-\\,1)\\,\\,V_{n-2},\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Since equation (1) has constant coefficients, it possesses particular integrals of the form $e^{a x + b y}$ (III, 27); the relation between $a$ and $b$ is, in this case, $b=a^{2}$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Goursat_E._-_A_course_in_mathematical_analysis._-_part.1_Variation_Of_Solutions_;Partial_Differential_Equations_Of_The_Second_Order._Vol.3-Ginn_(1916).pdf_304",
        "ID": "015cd1e7-2bc7-4ba4-b0c6-319ca891e09a",
        "questions": "What is the formula for the polynomial $V_n(x, y)$ as it appears in the expansion of the integral $e^{\u0007lpha x+a^{2}y}$?",
        "answers": "$V_{n}(x,y)\\,=\\,x^{n}\\,+\\,n(n-1)\\,x^{n-2}y\\,+\\ldots$",
        "context": "(III, 41) which here is  \n\n$$\n\\mathcal{G}(v)=\\frac{\\partial^{2}v}{\\partial x^{2}}+\\frac{\\partial v}{\\partial y}=0.\n$$  \n\nThese two equations have a single family of characteristics, which consists of parallels to the $x$-axis. We shall say that one of these functions, $u(x,y)$ or $v(x,y)$, is regular in a domain $D$ if it is continuous and has continuous first partial derivatives in this domain. It will even be sufficient to say that the derivative with respect to $y$ is continuous; for if $\\partial u/\\partial y$ for example, is a continuous function, equation (1) proves that the same is true of $\\partial^{2}u/\\partial x^{2}$ and, consequently, of $\\hat{c}u/\\hat{c}x$.\n\nSince equation (1) has constant coefficients, it possesses particular integrals of the form $e^{a x + b y}$ (III, 27); the relation between $a$ and $b$ is, in this case, $b=a^{2}$. From the integral $e^{a x + a^{2}y}$ thus obtained we can derive any infinity of others by taking its successive derivatives with respect to the parameter $a$, or, what amounts to the same thing, by taking the successive coefficients of the expansion of this integral, in powers of $a$. Let us write this expansion in the form  \n\n$$\ne^{\\alpha x+a^{2}y}=1\\,+\\sum_{n=1}^{+\\infty}\\frac{n^{n}}{n!}\\,V_{n}(x,\\,y)\\,;\n$$  \n\n$V_{n}(x,y)$ is a polynomial of degree $n$ in $x, y$ homogeneous in $x$ and $\\sqrt{y}$.\n\n$$\nV_{n}(x,y)\\,=\\,x^{n}\\,+\\,n(n-1)\\,x^{n-2}y\\,+\\ldots+\\frac{n(n-1)\\ldots(n-2p+1)}{p!}x^{n-2p}y^p+\\ldots\n$$  \n\nwhich is terminated by a term in $y^{\\frac{1}{2}n}$ if $n$ is even and by a term in $x y^{\\frac{1}{2}(n-1)}$, if $\\pi$ is odd. These polynomials $V_{n}$ are integrals of equation (1), from their very definition. We can easily verify this by observing that equation (3), differentiated with respect to $x$ and to $y$, gives the relations  \n\n$$\n\\frac{\\partial\\,V_{n}}{\\partial x}\\,=\\,n\\,V_{n-1},\\qquad\\frac{\\partial\\,V_{n}}{\\partial y}\\,=\\,n(n\\,-\\,1)\\,\\,V_{n-2},\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$V_{n}(x,y)\\,=\\,x^{n}\\,+\\,n(n-1)\\,x^{n-2}y\\,+\\ldots+\frac{n(n-1)\\ldots(n-2p+1)}{p!}x^{n-2p}y^p+\\ldots",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Goursat_E._-_A_course_in_mathematical_analysis._-_part.1_Variation_Of_Solutions_;Partial_Differential_Equations_Of_The_Second_Order._Vol.3-Ginn_(1916).pdf_304",
        "ID": "01650350-67db-4350-b368-89013bc3411c",
        "questions": "Is the derivative of $V_n(x, y)$ with respect to $x$ equal to $n \\cdot V_{n-1}(x, y)$?",
        "answers": "Yes",
        "context": "(III, 41) which here is  \n\n$$\n\\mathcal{G}(v)=\\frac{\\partial^{2}v}{\\partial x^{2}}+\\frac{\\partial v}{\\partial y}=0.\n$$  \n\nThese two equations have a single family of characteristics, which consists of parallels to the $x$-axis. We shall say that one of these functions, $u(x,y)$ or $v(x,y)$, is regular in a domain $D$ if it is continuous and has continuous first partial derivatives in this domain. It will even be sufficient to say that the derivative with respect to $y$ is continuous; for if $\\partial u/\\partial y$ for example, is a continuous function, equation (1) proves that the same is true of $\\partial^{2}u/\\partial x^{2}$ and, consequently, of $\\hat{c}u/\\hat{c}x$.\n\nSince equation (1) has constant coefficients, it possesses particular integrals of the form $e^{a x + b y}$ (III, 27); the relation between $a$ and $b$ is, in this case, $b=a^{2}$. From the integral $e^{a x + a^{2}y}$ thus obtained we can derive any infinity of others by taking its successive derivatives with respect to the parameter $a$, or, what amounts to the same thing, by taking the successive coefficients of the expansion of this integral, in powers of $a$. Let us write this expansion in the form  \n\n$$\ne^{\\alpha x+a^{2}y}=1\\,+\\sum_{n=1}^{+\\infty}\\frac{n^{n}}{n!}\\,V_{n}(x,\\,y)\\,;\n$$  \n\n$V_{n}(x,y)$ is a polynomial of degree $n$ in $x, y$ homogeneous in $x$ and $\\sqrt{y}$.\n\n$$\nV_{n}(x,y)\\,=\\,x^{n}\\,+\\,n(n-1)\\,x^{n-2}y\\,+\\ldots+\\frac{n(n-1)\\ldots(n-2p+1)}{p!}x^{n-2p}y^p+\\ldots\n$$  \n\nwhich is terminated by a term in $y^{\\frac{1}{2}n}$ if $n$ is even and by a term in $x y^{\\frac{1}{2}(n-1)}$, if $\\pi$ is odd. These polynomials $V_{n}$ are integrals of equation (1), from their very definition. We can easily verify this by observing that equation (3), differentiated with respect to $x$ and to $y$, gives the relations  \n\n$$\n\\frac{\\partial\\,V_{n}}{\\partial x}\\,=\\,n\\,V_{n-1},\\qquad\\frac{\\partial\\,V_{n}}{\\partial y}\\,=\\,n(n\\,-\\,1)\\,\\,V_{n-2},\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Yes/No",
        "evidence_source": "equation",
        "evidence_context": "$\\frac{\\partial\\,V_{n}}{\\partial x}\\,=\\,n\\,V_{n-1},\\qquad\\frac{\\partial\\,V_{n}}{\\partial y}\\,=\\,n(n\\,-\\,1)\\,\\,V_{n-2},$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Goursat_E._-_A_course_in_mathematical_analysis._-_part.1_Variation_Of_Solutions_;Partial_Differential_Equations_Of_The_Second_Order._Vol.3-Ginn_(1916).pdf_304",
        "ID": "01668796-e975-406b-8043-af980dc44252",
        "questions": "What is the specific form of the function $\\mathcal{G}(v)$?",
        "answers": "$\\mathcal{G}(v)=\\frac{\\partial^{2}v}{\\partial x^{2}}+\\frac{\\partial v}{\\partial y}=0.$",
        "context": "(III, 41) which here is  \n\n$$\n\\mathcal{G}(v)=\\frac{\\partial^{2}v}{\\partial x^{2}}+\\frac{\\partial v}{\\partial y}=0.\n$$  \n\nThese two equations have a single family of characteristics, which consists of parallels to the $x$-axis. We shall say that one of these functions, $u(x,y)$ or $v(x,y)$, is regular in a domain $D$ if it is continuous and has continuous first partial derivatives in this domain. It will even be sufficient to say that the derivative with respect to $y$ is continuous; for if $\\partial u/\\partial y$ for example, is a continuous function, equation (1) proves that the same is true of $\\partial^{2}u/\\partial x^{2}$ and, consequently, of $\\hat{c}u/\\hat{c}x$.\n\nSince equation (1) has constant coefficients, it possesses particular integrals of the form $e^{a x + b y}$ (III, 27); the relation between $a$ and $b$ is, in this case, $b=a^{2}$. From the integral $e^{a x + a^{2}y}$ thus obtained we can derive any infinity of others by taking its successive derivatives with respect to the parameter $a$, or, what amounts to the same thing, by taking the successive coefficients of the expansion of this integral, in powers of $a$. Let us write this expansion in the form  \n\n$$\ne^{\\alpha x+a^{2}y}=1\\,+\\sum_{n=1}^{+\\infty}\\frac{n^{n}}{n!}\\,V_{n}(x,\\,y)\\,;\n$$  \n\n$V_{n}(x,y)$ is a polynomial of degree $n$ in $x, y$ homogeneous in $x$ and $\\sqrt{y}$.\n\n$$\nV_{n}(x,y)\\,=\\,x^{n}\\,+\\,n(n-1)\\,x^{n-2}y\\,+\\ldots+\\frac{n(n-1)\\ldots(n-2p+1)}{p!}x^{n-2p}y^p+\\ldots\n$$  \n\nwhich is terminated by a term in $y^{\\frac{1}{2}n}$ if $n$ is even and by a term in $x y^{\\frac{1}{2}(n-1)}$, if $\\pi$ is odd. These polynomials $V_{n}$ are integrals of equation (1), from their very definition. We can easily verify this by observing that equation (3), differentiated with respect to $x$ and to $y$, gives the relations  \n\n$$\n\\frac{\\partial\\,V_{n}}{\\partial x}\\,=\\,n\\,V_{n-1},\\qquad\\frac{\\partial\\,V_{n}}{\\partial y}\\,=\\,n(n\\,-\\,1)\\,\\,V_{n-2},\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$$\n\\mathcal{G}(v)=\\frac{\\partial^{2}v}{\\partial x^{2}}+\\frac{\\partial v}{\\partial y}=0.\n$$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/Goursat_E._-_A_course_in_mathematical_analysis._-_part.1_Variation_Of_Solutions_;Partial_Differential_Equations_Of_The_Second_Order._Vol.3-Ginn_(1916).pdf_304",
        "ID": "017b49cf-249c-4be0-a967-2134dfdd8e2d",
        "questions": "What is the relation between $a$ and $b$ for the particular integrals of the form $e^{a x + b y}$?",
        "answers": "$b=a^{2}$",
        "context": "(III, 41) which here is  \n\n$$\n\\mathcal{G}(v)=\\frac{\\partial^{2}v}{\\partial x^{2}}+\\frac{\\partial v}{\\partial y}=0.\n$$  \n\nThese two equations have a single family of characteristics, which consists of parallels to the $x$-axis. We shall say that one of these functions, $u(x,y)$ or $v(x,y)$, is regular in a domain $D$ if it is continuous and has continuous first partial derivatives in this domain. It will even be sufficient to say that the derivative with respect to $y$ is continuous; for if $\\partial u/\\partial y$ for example, is a continuous function, equation (1) proves that the same is true of $\\partial^{2}u/\\partial x^{2}$ and, consequently, of $\\hat{c}u/\\hat{c}x$.\n\nSince equation (1) has constant coefficients, it possesses particular integrals of the form $e^{a x + b y}$ (III, 27); the relation between $a$ and $b$ is, in this case, $b=a^{2}$. From the integral $e^{a x + a^{2}y}$ thus obtained we can derive any infinity of others by taking its successive derivatives with respect to the parameter $a$, or, what amounts to the same thing, by taking the successive coefficients of the expansion of this integral, in powers of $a$. Let us write this expansion in the form  \n\n$$\ne^{\\alpha x+a^{2}y}=1\\,+\\sum_{n=1}^{+\\infty}\\frac{n^{n}}{n!}\\,V_{n}(x,\\,y)\\,;\n$$  \n\n$V_{n}(x,y)$ is a polynomial of degree $n$ in $x, y$ homogeneous in $x$ and $\\sqrt{y}$.\n\n$$\nV_{n}(x,y)\\,=\\,x^{n}\\,+\\,n(n-1)\\,x^{n-2}y\\,+\\ldots+\\frac{n(n-1)\\ldots(n-2p+1)}{p!}x^{n-2p}y^p+\\ldots\n$$  \n\nwhich is terminated by a term in $y^{\\frac{1}{2}n}$ if $n$ is even and by a term in $x y^{\\frac{1}{2}(n-1)}$, if $\\pi$ is odd. These polynomials $V_{n}$ are integrals of equation (1), from their very definition. We can easily verify this by observing that equation (3), differentiated with respect to $x$ and to $y$, gives the relations  \n\n$$\n\\frac{\\partial\\,V_{n}}{\\partial x}\\,=\\,n\\,V_{n-1},\\qquad\\frac{\\partial\\,V_{n}}{\\partial y}\\,=\\,n(n\\,-\\,1)\\,\\,V_{n-2},\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "the relation between $a$ and $b$ is, in this case, $b=a^{2}$.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/Goursat_E._-_A_course_in_mathematical_analysis._-_part.1_Variation_Of_Solutions_;Partial_Differential_Equations_Of_The_Second_Order._Vol.3-Ginn_(1916).pdf_304",
        "ID": "01847803-d840-4ccb-a446-eceecaa0a679",
        "questions": "What are the formulas for the derivatives of $V_n(x, y)$ with respect to $x$ and $y$?",
        "answers": "$\\frac{\\partial\\,V_{n}}{\\partial x}\\,=\\,n\\,V_{n-1},\\qquad\\frac{\\partial\\,V_{n}}{\\partial y}\\,=\\,n(n\\,-\\,1)\\,\\,V_{n-2},$",
        "context": "(III, 41) which here is  \n\n$$\n\\mathcal{G}(v)=\\frac{\\partial^{2}v}{\\partial x^{2}}+\\frac{\\partial v}{\\partial y}=0.\n$$  \n\nThese two equations have a single family of characteristics, which consists of parallels to the $x$-axis. We shall say that one of these functions, $u(x,y)$ or $v(x,y)$, is regular in a domain $D$ if it is continuous and has continuous first partial derivatives in this domain. It will even be sufficient to say that the derivative with respect to $y$ is continuous; for if $\\partial u/\\partial y$ for example, is a continuous function, equation (1) proves that the same is true of $\\partial^{2}u/\\partial x^{2}$ and, consequently, of $\\hat{c}u/\\hat{c}x$.\n\nSince equation (1) has constant coefficients, it possesses particular integrals of the form $e^{a x + b y}$ (III, 27); the relation between $a$ and $b$ is, in this case, $b=a^{2}$. From the integral $e^{a x + a^{2}y}$ thus obtained we can derive any infinity of others by taking its successive derivatives with respect to the parameter $a$, or, what amounts to the same thing, by taking the successive coefficients of the expansion of this integral, in powers of $a$. Let us write this expansion in the form  \n\n$$\ne^{\\alpha x+a^{2}y}=1\\,+\\sum_{n=1}^{+\\infty}\\frac{n^{n}}{n!}\\,V_{n}(x,\\,y)\\,;\n$$  \n\n$V_{n}(x,y)$ is a polynomial of degree $n$ in $x, y$ homogeneous in $x$ and $\\sqrt{y}$.\n\n$$\nV_{n}(x,y)\\,=\\,x^{n}\\,+\\,n(n-1)\\,x^{n-2}y\\,+\\ldots+\\frac{n(n-1)\\ldots(n-2p+1)}{p!}x^{n-2p}y^p+\\ldots\n$$  \n\nwhich is terminated by a term in $y^{\\frac{1}{2}n}$ if $n$ is even and by a term in $x y^{\\frac{1}{2}(n-1)}$, if $\\pi$ is odd. These polynomials $V_{n}$ are integrals of equation (1), from their very definition. We can easily verify this by observing that equation (3), differentiated with respect to $x$ and to $y$, gives the relations  \n\n$$\n\\frac{\\partial\\,V_{n}}{\\partial x}\\,=\\,n\\,V_{n-1},\\qquad\\frac{\\partial\\,V_{n}}{\\partial y}\\,=\\,n(n\\,-\\,1)\\,\\,V_{n-2},\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$$\n\\frac{\\partial\\,V_{n}}{\\partial x}\\,=\\,n\\,V_{n-1},\\qquad\\frac{\\partial\\,V_{n}}{\\partial y}\\,=\\,n(n\\,-\\,1)\\,\\,V_{n-2},\n$$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/Essential_Statistical_Inference_Theory_and_Methods.pdf_163",
        "ID": "019fa768-7836-41c3-a258-e52ce068ce92",
        "questions": "What are the given variance and sample sizes in the context of the $P$-values reported in Table 3.3?",
        "answers": "The given variance is 14 and the sample sizes are $n_1=n_2=n_3=5$.",
        "context": "$\n\\caption{Table 3.3 $P$ -values for three samples. $n_1=n_2=n_3=5$, $\\sigma^2=14$}\n\\begin{tabular}{|c|c|c|c|c|c|}\n \n$\\bar{Y}_1$ & $\\bar{Y}_2$ & $\\bar{Y}_3$ & ANOVA & ISO & Reg \\\\\n \n2 & 6 & 6 & 0.149 & 0.050 & 0.045 \\\\\n \n2 & 6 & 7 & 0.082 & 0.026 & 0.017 \\\\\n \n2 & 6 & 8 & 0.036 & 0.011 & 0.006 \\\\\n \n\\end{tabular}\n$\n\nrelative ease of using regression is probably why isotonic regression is not used more.  \n\nFinally, although the $p$ -values reported in Table 3.3 are for the known-variance case, qualitatively similar results are obtained for the more complicated case of $\\sigma$ unknown.\n\nThere is a large literature on order-restricted inference. For testing for ordered alternatives, there has been more emphasis on $T_{\\mathrm{LR}}$ than on $T_{\\mathrm{{W}}}$ and $T_{S}$. The classic references are Barlow et al. (1972) and Robertson et al. (1988), whereas a more recent account is Silva pull e and Sen (2005).  \n\n# 3.6.2 Null Hypotheses on the Boundary of the Parameter Space  \n\nWhen a null hypothesis value, say $\\pmb{\\theta}_{0}$ lies on the boundary of the parameter space, then maximum likelihood estimators are often truncated at that boundary because by definition $\\widehat{\\pmb{\\theta}}_{\\mathrm{MLE}}$ must lie in the parameter space of $\\theta$. Thus, $\\widehat{\\pmb{\\theta}}_{\\mathrm{MLE}}$ is equal to the boundary value $\\pmb{\\theta}_{0}$ with positive probability and correspondingly $T_{\\mathrm{LR}}$ is zero for those cases. The result is that the limiting distribution of $T_{\\mathrm{LR}}$ is a mixture of a point mass at zero and a chi-squared distribution. We illustrate first with an artificial example and then consider the one-way random effects model.  \n\n# 3.6.2 a Normal Mean with Restricted Parameter Space  \n\nSuppose that $Y_{1}, .\\,.\\,.\\,, Y_{n} \\sim N(\\mu, 1)$. Usually, $\\widehat{\\mu}_{\\mathrm{MLE}} = \\overline{{Y}}$, but suppose that we restrict the parameter space for $\\mu$ to be $[\\mu_{0}, \\infty)$ where $\\mu_{0}$ is some given constant, instead of $(-\\infty, \\infty)$. Then $\\widehat{\\mu}_{\\mathrm{MLE}} = \\overline{{Y}}$ if $\\overline{{Y}} \\geq \\mu_{0}$ and $\\widehat{\\mu}_{\\mathrm{MLE}} = \\mu_{0}$ if $\\overline{{Y}} < \\mu_{0}$. Now suppose that the null hypothesis is $H_{0}: \\mu = \\mu_{0}$. We first consider the three likelihood-based test statistics, showing that only the score statistic has a limiting $\\chi_{1}^{2}$ distribution. Then we provide a simple solution to this testing problem.  \n\nUnder $H_{0}$, the Wald statistic is $T_{\\mathrm{W}} = n(\\widehat{\\mu}_{\\mathrm{MLE}} - \\mu_{0})^{2}$, which is thus $T_{\\mathrm{W}} = 0$ if $\\widehat{\\mu}_{\\mathrm{MLE}} = \\mu_{0}$ and $T_{\\mathrm{W}} = n(\\overline{{Y}} - \\mu_{0})^{2}$ if $Y \\geq \\mu_{0}$. The score statistic is $T_{\\mathrm{S}} = n(Y - \\mu_{0})^{2}$ and the likelihood ratio statistic is the same as the Wald statistic. Thus, only the score statistic converges to a $\\chi_{1}^{2}$ distribution under $H_{0}$. The Wald and the likelihood ratio statistics converge to a distribution that is an equal mixture of a point mass at 0 and a $\\chi_{1}^{2}$ distribution, the same distribution as in (3.23) for $k = 2$. In fact, the",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "$\\caption{Table 3.3 $P$ -values for three samples. $n_1=n_2=n_3=5$, $\\sigma^2=14$}$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Essential_Statistical_Inference_Theory_and_Methods.pdf_163",
        "ID": "01a02c0d-1161-4db0-b0d0-f5cb084ada1c",
        "questions": "What is the $P$-value for ANOVA when the sample means are $2, 6,$ and $8$?",
        "answers": "0.036",
        "context": "$\n\\caption{Table 3.3 $P$ -values for three samples. $n_1=n_2=n_3=5$, $\\sigma^2=14$}\n\\begin{tabular}{|c|c|c|c|c|c|}\n \n$\\bar{Y}_1$ & $\\bar{Y}_2$ & $\\bar{Y}_3$ & ANOVA & ISO & Reg \\\\\n \n2 & 6 & 6 & 0.149 & 0.050 & 0.045 \\\\\n \n2 & 6 & 7 & 0.082 & 0.026 & 0.017 \\\\\n \n2 & 6 & 8 & 0.036 & 0.011 & 0.006 \\\\\n \n\\end{tabular}\n$\n\nrelative ease of using regression is probably why isotonic regression is not used more.  \n\nFinally, although the $p$ -values reported in Table 3.3 are for the known-variance case, qualitatively similar results are obtained for the more complicated case of $\\sigma$ unknown.\n\nThere is a large literature on order-restricted inference. For testing for ordered alternatives, there has been more emphasis on $T_{\\mathrm{LR}}$ than on $T_{\\mathrm{{W}}}$ and $T_{S}$. The classic references are Barlow et al. (1972) and Robertson et al. (1988), whereas a more recent account is Silva pull e and Sen (2005).  \n\n# 3.6.2 Null Hypotheses on the Boundary of the Parameter Space  \n\nWhen a null hypothesis value, say $\\pmb{\\theta}_{0}$ lies on the boundary of the parameter space, then maximum likelihood estimators are often truncated at that boundary because by definition $\\widehat{\\pmb{\\theta}}_{\\mathrm{MLE}}$ must lie in the parameter space of $\\theta$. Thus, $\\widehat{\\pmb{\\theta}}_{\\mathrm{MLE}}$ is equal to the boundary value $\\pmb{\\theta}_{0}$ with positive probability and correspondingly $T_{\\mathrm{LR}}$ is zero for those cases. The result is that the limiting distribution of $T_{\\mathrm{LR}}$ is a mixture of a point mass at zero and a chi-squared distribution. We illustrate first with an artificial example and then consider the one-way random effects model.  \n\n# 3.6.2 a Normal Mean with Restricted Parameter Space  \n\nSuppose that $Y_{1}, .\\,.\\,.\\,, Y_{n} \\sim N(\\mu, 1)$. Usually, $\\widehat{\\mu}_{\\mathrm{MLE}} = \\overline{{Y}}$, but suppose that we restrict the parameter space for $\\mu$ to be $[\\mu_{0}, \\infty)$ where $\\mu_{0}$ is some given constant, instead of $(-\\infty, \\infty)$. Then $\\widehat{\\mu}_{\\mathrm{MLE}} = \\overline{{Y}}$ if $\\overline{{Y}} \\geq \\mu_{0}$ and $\\widehat{\\mu}_{\\mathrm{MLE}} = \\mu_{0}$ if $\\overline{{Y}} < \\mu_{0}$. Now suppose that the null hypothesis is $H_{0}: \\mu = \\mu_{0}$. We first consider the three likelihood-based test statistics, showing that only the score statistic has a limiting $\\chi_{1}^{2}$ distribution. Then we provide a simple solution to this testing problem.  \n\nUnder $H_{0}$, the Wald statistic is $T_{\\mathrm{W}} = n(\\widehat{\\mu}_{\\mathrm{MLE}} - \\mu_{0})^{2}$, which is thus $T_{\\mathrm{W}} = 0$ if $\\widehat{\\mu}_{\\mathrm{MLE}} = \\mu_{0}$ and $T_{\\mathrm{W}} = n(\\overline{{Y}} - \\mu_{0})^{2}$ if $Y \\geq \\mu_{0}$. The score statistic is $T_{\\mathrm{S}} = n(Y - \\mu_{0})^{2}$ and the likelihood ratio statistic is the same as the Wald statistic. Thus, only the score statistic converges to a $\\chi_{1}^{2}$ distribution under $H_{0}$. The Wald and the likelihood ratio statistics converge to a distribution that is an equal mixture of a point mass at 0 and a $\\chi_{1}^{2}$ distribution, the same distribution as in (3.23) for $k = 2$. In fact, the",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Numeric",
        "evidence_source": "table",
        "evidence_context": "$\\begin{tabular}{|c|c|c|c|c|c|}$\\hline $\\bar{Y}_1$ & $\\bar{Y}_2$ & $\\bar{Y}_3$ & ANOVA & ISO & Reg \\ \\hline 2 & 6 & 8 & 0.036 & 0.011 & 0.006 \\ \\hline$\\end{tabular}$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Essential_Statistical_Inference_Theory_and_Methods.pdf_163",
        "ID": "01a08af9-6bd5-4636-a472-af5aea70aed1",
        "questions": "Under what condition is the maximum likelihood estimate $\\widehat{\\mu}_{\\mathrm{MLE}}$ truncated to $\\mu_{0}$, when $Y$ follows a normal distribution with mean $\\mu$ and variance 1?",
        "answers": "$\\widehat{\\mu}_{\\mathrm{MLE}} = \\mu_{0}$ if $\\overline{{Y}} < \\mu_{0}$",
        "context": "$\n\\caption{Table 3.3 $P$ -values for three samples. $n_1=n_2=n_3=5$, $\\sigma^2=14$}\n\\begin{tabular}{|c|c|c|c|c|c|}\n \n$\\bar{Y}_1$ & $\\bar{Y}_2$ & $\\bar{Y}_3$ & ANOVA & ISO & Reg \\\\\n \n2 & 6 & 6 & 0.149 & 0.050 & 0.045 \\\\\n \n2 & 6 & 7 & 0.082 & 0.026 & 0.017 \\\\\n \n2 & 6 & 8 & 0.036 & 0.011 & 0.006 \\\\\n \n\\end{tabular}\n$\n\nrelative ease of using regression is probably why isotonic regression is not used more.  \n\nFinally, although the $p$ -values reported in Table 3.3 are for the known-variance case, qualitatively similar results are obtained for the more complicated case of $\\sigma$ unknown.\n\nThere is a large literature on order-restricted inference. For testing for ordered alternatives, there has been more emphasis on $T_{\\mathrm{LR}}$ than on $T_{\\mathrm{{W}}}$ and $T_{S}$. The classic references are Barlow et al. (1972) and Robertson et al. (1988), whereas a more recent account is Silva pull e and Sen (2005).  \n\n# 3.6.2 Null Hypotheses on the Boundary of the Parameter Space  \n\nWhen a null hypothesis value, say $\\pmb{\\theta}_{0}$ lies on the boundary of the parameter space, then maximum likelihood estimators are often truncated at that boundary because by definition $\\widehat{\\pmb{\\theta}}_{\\mathrm{MLE}}$ must lie in the parameter space of $\\theta$. Thus, $\\widehat{\\pmb{\\theta}}_{\\mathrm{MLE}}$ is equal to the boundary value $\\pmb{\\theta}_{0}$ with positive probability and correspondingly $T_{\\mathrm{LR}}$ is zero for those cases. The result is that the limiting distribution of $T_{\\mathrm{LR}}$ is a mixture of a point mass at zero and a chi-squared distribution. We illustrate first with an artificial example and then consider the one-way random effects model.  \n\n# 3.6.2 a Normal Mean with Restricted Parameter Space  \n\nSuppose that $Y_{1}, .\\,.\\,.\\,, Y_{n} \\sim N(\\mu, 1)$. Usually, $\\widehat{\\mu}_{\\mathrm{MLE}} = \\overline{{Y}}$, but suppose that we restrict the parameter space for $\\mu$ to be $[\\mu_{0}, \\infty)$ where $\\mu_{0}$ is some given constant, instead of $(-\\infty, \\infty)$. Then $\\widehat{\\mu}_{\\mathrm{MLE}} = \\overline{{Y}}$ if $\\overline{{Y}} \\geq \\mu_{0}$ and $\\widehat{\\mu}_{\\mathrm{MLE}} = \\mu_{0}$ if $\\overline{{Y}} < \\mu_{0}$. Now suppose that the null hypothesis is $H_{0}: \\mu = \\mu_{0}$. We first consider the three likelihood-based test statistics, showing that only the score statistic has a limiting $\\chi_{1}^{2}$ distribution. Then we provide a simple solution to this testing problem.  \n\nUnder $H_{0}$, the Wald statistic is $T_{\\mathrm{W}} = n(\\widehat{\\mu}_{\\mathrm{MLE}} - \\mu_{0})^{2}$, which is thus $T_{\\mathrm{W}} = 0$ if $\\widehat{\\mu}_{\\mathrm{MLE}} = \\mu_{0}$ and $T_{\\mathrm{W}} = n(\\overline{{Y}} - \\mu_{0})^{2}$ if $Y \\geq \\mu_{0}$. The score statistic is $T_{\\mathrm{S}} = n(Y - \\mu_{0})^{2}$ and the likelihood ratio statistic is the same as the Wald statistic. Thus, only the score statistic converges to a $\\chi_{1}^{2}$ distribution under $H_{0}$. The Wald and the likelihood ratio statistics converge to a distribution that is an equal mixture of a point mass at 0 and a $\\chi_{1}^{2}$ distribution, the same distribution as in (3.23) for $k = 2$. In fact, the",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Then $\\widehat{\\mu}_{\\mathrm{MLE}} = \\overline{{Y}}$ if $\\overline{{Y}} \\geq \\mu_{0}$ and $\\widehat{\\mu}_{\\mathrm{MLE}} = \\mu_{0}$ if $\\overline{{Y}} < \\mu_{0}$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Essential_Statistical_Inference_Theory_and_Methods.pdf_163",
        "ID": "01a39f80-6333-41ec-8c85-ca141ef02a90",
        "questions": "What are the ANOVA $P$-values for samples with means 2, 6, and 8 in the given table?",
        "answers": "0.036",
        "context": "$\n\\caption{Table 3.3 $P$ -values for three samples. $n_1=n_2=n_3=5$, $\\sigma^2=14$}\n\\begin{tabular}{|c|c|c|c|c|c|}\n \n$\\bar{Y}_1$ & $\\bar{Y}_2$ & $\\bar{Y}_3$ & ANOVA & ISO & Reg \\\\\n \n2 & 6 & 6 & 0.149 & 0.050 & 0.045 \\\\\n \n2 & 6 & 7 & 0.082 & 0.026 & 0.017 \\\\\n \n2 & 6 & 8 & 0.036 & 0.011 & 0.006 \\\\\n \n\\end{tabular}\n$\n\nrelative ease of using regression is probably why isotonic regression is not used more.  \n\nFinally, although the $p$ -values reported in Table 3.3 are for the known-variance case, qualitatively similar results are obtained for the more complicated case of $\\sigma$ unknown.\n\nThere is a large literature on order-restricted inference. For testing for ordered alternatives, there has been more emphasis on $T_{\\mathrm{LR}}$ than on $T_{\\mathrm{{W}}}$ and $T_{S}$. The classic references are Barlow et al. (1972) and Robertson et al. (1988), whereas a more recent account is Silva pull e and Sen (2005).  \n\n# 3.6.2 Null Hypotheses on the Boundary of the Parameter Space  \n\nWhen a null hypothesis value, say $\\pmb{\\theta}_{0}$ lies on the boundary of the parameter space, then maximum likelihood estimators are often truncated at that boundary because by definition $\\widehat{\\pmb{\\theta}}_{\\mathrm{MLE}}$ must lie in the parameter space of $\\theta$. Thus, $\\widehat{\\pmb{\\theta}}_{\\mathrm{MLE}}$ is equal to the boundary value $\\pmb{\\theta}_{0}$ with positive probability and correspondingly $T_{\\mathrm{LR}}$ is zero for those cases. The result is that the limiting distribution of $T_{\\mathrm{LR}}$ is a mixture of a point mass at zero and a chi-squared distribution. We illustrate first with an artificial example and then consider the one-way random effects model.  \n\n# 3.6.2 a Normal Mean with Restricted Parameter Space  \n\nSuppose that $Y_{1}, .\\,.\\,.\\,, Y_{n} \\sim N(\\mu, 1)$. Usually, $\\widehat{\\mu}_{\\mathrm{MLE}} = \\overline{{Y}}$, but suppose that we restrict the parameter space for $\\mu$ to be $[\\mu_{0}, \\infty)$ where $\\mu_{0}$ is some given constant, instead of $(-\\infty, \\infty)$. Then $\\widehat{\\mu}_{\\mathrm{MLE}} = \\overline{{Y}}$ if $\\overline{{Y}} \\geq \\mu_{0}$ and $\\widehat{\\mu}_{\\mathrm{MLE}} = \\mu_{0}$ if $\\overline{{Y}} < \\mu_{0}$. Now suppose that the null hypothesis is $H_{0}: \\mu = \\mu_{0}$. We first consider the three likelihood-based test statistics, showing that only the score statistic has a limiting $\\chi_{1}^{2}$ distribution. Then we provide a simple solution to this testing problem.  \n\nUnder $H_{0}$, the Wald statistic is $T_{\\mathrm{W}} = n(\\widehat{\\mu}_{\\mathrm{MLE}} - \\mu_{0})^{2}$, which is thus $T_{\\mathrm{W}} = 0$ if $\\widehat{\\mu}_{\\mathrm{MLE}} = \\mu_{0}$ and $T_{\\mathrm{W}} = n(\\overline{{Y}} - \\mu_{0})^{2}$ if $Y \\geq \\mu_{0}$. The score statistic is $T_{\\mathrm{S}} = n(Y - \\mu_{0})^{2}$ and the likelihood ratio statistic is the same as the Wald statistic. Thus, only the score statistic converges to a $\\chi_{1}^{2}$ distribution under $H_{0}$. The Wald and the likelihood ratio statistics converge to a distribution that is an equal mixture of a point mass at 0 and a $\\chi_{1}^{2}$ distribution, the same distribution as in (3.23) for $k = 2$. In fact, the",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Numeric",
        "evidence_source": "equation",
        "evidence_context": "2 & 6 & 8 & 0.036 & 0.011 & 0.006",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/Essential_Statistical_Inference_Theory_and_Methods.pdf_163",
        "ID": "01cf7f93-5e6c-49e4-9768-599decffd101",
        "questions": "What is the regression $P$-value when the sample means are 2, 6, and 7 in Table 3.3?",
        "answers": "0.017",
        "context": "$\n\\caption{Table 3.3 $P$ -values for three samples. $n_1=n_2=n_3=5$, $\\sigma^2=14$}\n\\begin{tabular}{|c|c|c|c|c|c|}\n \n$\\bar{Y}_1$ & $\\bar{Y}_2$ & $\\bar{Y}_3$ & ANOVA & ISO & Reg \\\\\n \n2 & 6 & 6 & 0.149 & 0.050 & 0.045 \\\\\n \n2 & 6 & 7 & 0.082 & 0.026 & 0.017 \\\\\n \n2 & 6 & 8 & 0.036 & 0.011 & 0.006 \\\\\n \n\\end{tabular}\n$\n\nrelative ease of using regression is probably why isotonic regression is not used more.  \n\nFinally, although the $p$ -values reported in Table 3.3 are for the known-variance case, qualitatively similar results are obtained for the more complicated case of $\\sigma$ unknown.\n\nThere is a large literature on order-restricted inference. For testing for ordered alternatives, there has been more emphasis on $T_{\\mathrm{LR}}$ than on $T_{\\mathrm{{W}}}$ and $T_{S}$. The classic references are Barlow et al. (1972) and Robertson et al. (1988), whereas a more recent account is Silva pull e and Sen (2005).  \n\n# 3.6.2 Null Hypotheses on the Boundary of the Parameter Space  \n\nWhen a null hypothesis value, say $\\pmb{\\theta}_{0}$ lies on the boundary of the parameter space, then maximum likelihood estimators are often truncated at that boundary because by definition $\\widehat{\\pmb{\\theta}}_{\\mathrm{MLE}}$ must lie in the parameter space of $\\theta$. Thus, $\\widehat{\\pmb{\\theta}}_{\\mathrm{MLE}}$ is equal to the boundary value $\\pmb{\\theta}_{0}$ with positive probability and correspondingly $T_{\\mathrm{LR}}$ is zero for those cases. The result is that the limiting distribution of $T_{\\mathrm{LR}}$ is a mixture of a point mass at zero and a chi-squared distribution. We illustrate first with an artificial example and then consider the one-way random effects model.  \n\n# 3.6.2 a Normal Mean with Restricted Parameter Space  \n\nSuppose that $Y_{1}, .\\,.\\,.\\,, Y_{n} \\sim N(\\mu, 1)$. Usually, $\\widehat{\\mu}_{\\mathrm{MLE}} = \\overline{{Y}}$, but suppose that we restrict the parameter space for $\\mu$ to be $[\\mu_{0}, \\infty)$ where $\\mu_{0}$ is some given constant, instead of $(-\\infty, \\infty)$. Then $\\widehat{\\mu}_{\\mathrm{MLE}} = \\overline{{Y}}$ if $\\overline{{Y}} \\geq \\mu_{0}$ and $\\widehat{\\mu}_{\\mathrm{MLE}} = \\mu_{0}$ if $\\overline{{Y}} < \\mu_{0}$. Now suppose that the null hypothesis is $H_{0}: \\mu = \\mu_{0}$. We first consider the three likelihood-based test statistics, showing that only the score statistic has a limiting $\\chi_{1}^{2}$ distribution. Then we provide a simple solution to this testing problem.  \n\nUnder $H_{0}$, the Wald statistic is $T_{\\mathrm{W}} = n(\\widehat{\\mu}_{\\mathrm{MLE}} - \\mu_{0})^{2}$, which is thus $T_{\\mathrm{W}} = 0$ if $\\widehat{\\mu}_{\\mathrm{MLE}} = \\mu_{0}$ and $T_{\\mathrm{W}} = n(\\overline{{Y}} - \\mu_{0})^{2}$ if $Y \\geq \\mu_{0}$. The score statistic is $T_{\\mathrm{S}} = n(Y - \\mu_{0})^{2}$ and the likelihood ratio statistic is the same as the Wald statistic. Thus, only the score statistic converges to a $\\chi_{1}^{2}$ distribution under $H_{0}$. The Wald and the likelihood ratio statistics converge to a distribution that is an equal mixture of a point mass at 0 and a $\\chi_{1}^{2}$ distribution, the same distribution as in (3.23) for $k = 2$. In fact, the",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Numeric",
        "evidence_source": "equation",
        "evidence_context": "2 & 6 & 7 & 0.082 & 0.026 & 0.017",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/Essential_Statistical_Inference_Theory_and_Methods.pdf_163",
        "ID": "01de1868-8827-4859-bd02-5676d187bbae",
        "questions": "When comparing the ANOVA $P$-values in Table 3.3, which row has the lowest $P$-value and what is the $P$-value?",
        "answers": "Third row; 0.036",
        "context": "$\n\\caption{Table 3.3 $P$ -values for three samples. $n_1=n_2=n_3=5$, $\\sigma^2=14$}\n\\begin{tabular}{|c|c|c|c|c|c|}\n \n$\\bar{Y}_1$ & $\\bar{Y}_2$ & $\\bar{Y}_3$ & ANOVA & ISO & Reg \\\\\n \n2 & 6 & 6 & 0.149 & 0.050 & 0.045 \\\\\n \n2 & 6 & 7 & 0.082 & 0.026 & 0.017 \\\\\n \n2 & 6 & 8 & 0.036 & 0.011 & 0.006 \\\\\n \n\\end{tabular}\n$\n\nrelative ease of using regression is probably why isotonic regression is not used more.  \n\nFinally, although the $p$ -values reported in Table 3.3 are for the known-variance case, qualitatively similar results are obtained for the more complicated case of $\\sigma$ unknown.\n\nThere is a large literature on order-restricted inference. For testing for ordered alternatives, there has been more emphasis on $T_{\\mathrm{LR}}$ than on $T_{\\mathrm{{W}}}$ and $T_{S}$. The classic references are Barlow et al. (1972) and Robertson et al. (1988), whereas a more recent account is Silva pull e and Sen (2005).  \n\n# 3.6.2 Null Hypotheses on the Boundary of the Parameter Space  \n\nWhen a null hypothesis value, say $\\pmb{\\theta}_{0}$ lies on the boundary of the parameter space, then maximum likelihood estimators are often truncated at that boundary because by definition $\\widehat{\\pmb{\\theta}}_{\\mathrm{MLE}}$ must lie in the parameter space of $\\theta$. Thus, $\\widehat{\\pmb{\\theta}}_{\\mathrm{MLE}}$ is equal to the boundary value $\\pmb{\\theta}_{0}$ with positive probability and correspondingly $T_{\\mathrm{LR}}$ is zero for those cases. The result is that the limiting distribution of $T_{\\mathrm{LR}}$ is a mixture of a point mass at zero and a chi-squared distribution. We illustrate first with an artificial example and then consider the one-way random effects model.  \n\n# 3.6.2 a Normal Mean with Restricted Parameter Space  \n\nSuppose that $Y_{1}, .\\,.\\,.\\,, Y_{n} \\sim N(\\mu, 1)$. Usually, $\\widehat{\\mu}_{\\mathrm{MLE}} = \\overline{{Y}}$, but suppose that we restrict the parameter space for $\\mu$ to be $[\\mu_{0}, \\infty)$ where $\\mu_{0}$ is some given constant, instead of $(-\\infty, \\infty)$. Then $\\widehat{\\mu}_{\\mathrm{MLE}} = \\overline{{Y}}$ if $\\overline{{Y}} \\geq \\mu_{0}$ and $\\widehat{\\mu}_{\\mathrm{MLE}} = \\mu_{0}$ if $\\overline{{Y}} < \\mu_{0}$. Now suppose that the null hypothesis is $H_{0}: \\mu = \\mu_{0}$. We first consider the three likelihood-based test statistics, showing that only the score statistic has a limiting $\\chi_{1}^{2}$ distribution. Then we provide a simple solution to this testing problem.  \n\nUnder $H_{0}$, the Wald statistic is $T_{\\mathrm{W}} = n(\\widehat{\\mu}_{\\mathrm{MLE}} - \\mu_{0})^{2}$, which is thus $T_{\\mathrm{W}} = 0$ if $\\widehat{\\mu}_{\\mathrm{MLE}} = \\mu_{0}$ and $T_{\\mathrm{W}} = n(\\overline{{Y}} - \\mu_{0})^{2}$ if $Y \\geq \\mu_{0}$. The score statistic is $T_{\\mathrm{S}} = n(Y - \\mu_{0})^{2}$ and the likelihood ratio statistic is the same as the Wald statistic. Thus, only the score statistic converges to a $\\chi_{1}^{2}$ distribution under $H_{0}$. The Wald and the likelihood ratio statistics converge to a distribution that is an equal mixture of a point mass at 0 and a $\\chi_{1}^{2}$ distribution, the same distribution as in (3.23) for $k = 2$. In fact, the",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "2 & 6 & 8 & 0.036 & 0.011 & 0.006",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/(Springer_Monographs_in_Mathematics)_Ivan_Penkov,_Crystal_Hoyt_-_Classical_Lie_Algebras_at_Infinity_(Springer_Monographs_in_Mathematics).pdf_199",
        "ID": "01dee1a1-9a01-4709-acf8-5508e1d49a09",
        "questions": "Which group of matrices is used to denote the Borel subgroup B in the context of upper-triangular matrices in GL(V) for V = \ud835\udc9e\u207f?",
        "answers": "The Borel subgroup of upper-triangular matrices in GL(V)",
        "context": "corresponds to the character det: $P\\;\\rightarrow\\;\\mathbb{C}^{\\times}$ which extends to a character of $G$ (check this!). That's why (10.5) is the pull-back on $G/P$ of a $G$-linearized bundle on $G/G$, and is hence trivial as a line bundle. The corresponding $G$-linearized bundle on $G/G$ is not trivial as a $G$-bundle (since det: $G\\to\\mathbb{C}^{\\times}$ does not equal the trivial homomorphism), and (10.5) is also not trivial as a $G$-bundle on $G/P$.\n\nNow consider in more detail the case when $m\\;=\\;n\\;-1$ and $P~=~B$ is the Borel subgroup of upper-triangular matrices in $G L(V)$ for $V\\ =\\ \\mathbb{C}^{n}$. Here the correspondence from Proposition 10.2 has the following explicit form. Order the basis of $\\mathbb{C}^{n}$ as $e_{1},\\,.\\,.\\,,e_{n}$. Then the group of characters $\\operatorname{Hom}(B,\\mathbb{C}^{\\times})$ is identified with $\\mathbb{Z}^{n}$. The $G$-linearized line bundle corresponding to $(\\lambda_{1},\\,.\\,.\\,,\\,\\lambda_{n})\\in\\mathbb{Z}^{n}$ is simply\n\n$$\nS_{1}^{\\lambda_{1}}\\otimes(S_{2}/S_{1})^{\\lambda_{2}}\\otimes\\cdot\\cdot\\otimes(\\tilde{\\mathbb{C}}^{n}/S_{n-1})^{\\lambda_{n}}.\n$$\n\nVerifying this is a non-difficult but essential computation. The simplest case is $n=2$: here one needs to check that the $B$-character in the fiber of bundle $S_{1}^{\\lambda_{1}}\\otimes$ $(\\tilde{\\mathbb{C}}^{2}/S_{1})^{\\lambda_{2}}$ at the point $B\\,\\in\\,G/B$ is precisely the character $(\\lambda_{1},\\lambda_{2})\\in\\mathbb{Z}^{2}$. We hope that the reader will verify this explicitly.\n\nFor a general connected reductive group $G$ and a Borel subgroup $B\\,\\subset\\,G$, we denote by $O(\\lambda)$ the $G$-linearized line bundle on $G/B$ corresponding to a character $\\lambda:B\\to\\mathbb{C}^{\\times}$, i.e., such that $B$ acts via $\\curlywedge$ in the fiber of $O(\\lambda)$ at the point $B\\,\\in\\,G/B$. If we choose $G$ to be $S L(V)$, then every line bundle on $G/B$ admits a unique $G$ linearization and the bijection of Proposition 10.2 induces an equality Pic $G/B\\,=$ $\\operatorname{Hom}(B,\\mathbb{C}^{\\times})$, where $B$ is now a Borel subgroup of $S L(V)$.\n\nThe isomorphisms (10.3) enable us to compute explicitly the cohomology of any $G L(2)$-linearized line bundle on $G L(2)/P=\\mathbb{P}(V)$ for $V=\\mathbb{C}^{2}$. Indeed, notice that in this case\n\n$$\n{\\cal O}(\\lambda)=S_{1}^{\\lambda_{1}}\\otimes(\\tilde{V}/S_{1})^{\\lambda_{2}}=S_{1}^{\\lambda_{1}-\\lambda_{2}}\\otimes(\\Lambda^{2}(\\tilde{V}))^{\\otimes\\lambda_{2}},\n$$\n\nwhere $(\\Lambda^{2}(\\tilde{V}))^{\\otimes\\lambda_{2}}$ is a trivial bundle on $\\mathbb{P}(V)$ with a nontrivial $G$-linearization. Hence (10.3) implies for $\\lambda_{2}-\\lambda_{1}\\geq0$\n\n$$\n\\begin{array}{r l}&{H^{0}({\\mathbb{P}}(V),S_{1}^{\\lambda_{1}}\\otimes(\\tilde{V}/S_{1})^{\\lambda_{2}})=S^{\\lambda_{2}-\\lambda_{1}}(V^{*})\\otimes(\\Lambda^{2}(V))^{\\otimes\\lambda_{2}},}\\\\ &{H^{1}({\\mathbb{P}}(V),S_{1}^{\\lambda_{1}}\\otimes(\\tilde{V}/S_{1})^{\\lambda_{2}})=0;}\\end{array}\n$$\n\nfor $\\lambda_{2}-\\lambda_{1}\\leq-2,$\n\n$$\n\\begin{array}{r l}&{H^{0}({\\mathbb{P}}(V),S_{1}^{\\lambda_{1}}\\otimes(\\tilde{V}/S_{1})^{\\lambda_{2}})=0,}\\\\ &{H^{1}({\\mathbb{P}}(V),S_{1}^{\\lambda_{1}}\\otimes(\\tilde{V}/S_{1})^{\\lambda_{2}})=S^{\\lambda_{1}-\\lambda_{2}-2}(V)\\otimes(\\Lambda^{2}(V))^{\\otimes\\lambda_{2}+1};}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Now consider in more detail the case when $m\\;=\\;n\\;-1$ and $P~=~B$ is the Borel subgroup of upper-triangular matrices in $G L(V)$ for $V\\ =\\ \\mathbb{C}^{n}$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/(Springer_Monographs_in_Mathematics)_Ivan_Penkov,_Crystal_Hoyt_-_Classical_Lie_Algebras_at_Infinity_(Springer_Monographs_in_Mathematics).pdf_199",
        "ID": "01e50dde-46ca-4ca5-90da-4776dbf9c505",
        "questions": "What is the identification of the group of characters Hom(B, \ud835\udc9e \u00d7) when the basis of \ud835\udc9e\u207f is ordered as e\u2081, \u2026, e\u2099?",
        "answers": "The group of characters Hom(B, \ud835\udc9e \u00d7) is identified with \u2124\u207f.",
        "context": "corresponds to the character det: $P\\;\\rightarrow\\;\\mathbb{C}^{\\times}$ which extends to a character of $G$ (check this!). That's why (10.5) is the pull-back on $G/P$ of a $G$-linearized bundle on $G/G$, and is hence trivial as a line bundle. The corresponding $G$-linearized bundle on $G/G$ is not trivial as a $G$-bundle (since det: $G\\to\\mathbb{C}^{\\times}$ does not equal the trivial homomorphism), and (10.5) is also not trivial as a $G$-bundle on $G/P$.\n\nNow consider in more detail the case when $m\\;=\\;n\\;-1$ and $P~=~B$ is the Borel subgroup of upper-triangular matrices in $G L(V)$ for $V\\ =\\ \\mathbb{C}^{n}$. Here the correspondence from Proposition 10.2 has the following explicit form. Order the basis of $\\mathbb{C}^{n}$ as $e_{1},\\,.\\,.\\,,e_{n}$. Then the group of characters $\\operatorname{Hom}(B,\\mathbb{C}^{\\times})$ is identified with $\\mathbb{Z}^{n}$. The $G$-linearized line bundle corresponding to $(\\lambda_{1},\\,.\\,.\\,,\\,\\lambda_{n})\\in\\mathbb{Z}^{n}$ is simply\n\n$$\nS_{1}^{\\lambda_{1}}\\otimes(S_{2}/S_{1})^{\\lambda_{2}}\\otimes\\cdot\\cdot\\otimes(\\tilde{\\mathbb{C}}^{n}/S_{n-1})^{\\lambda_{n}}.\n$$\n\nVerifying this is a non-difficult but essential computation. The simplest case is $n=2$: here one needs to check that the $B$-character in the fiber of bundle $S_{1}^{\\lambda_{1}}\\otimes$ $(\\tilde{\\mathbb{C}}^{2}/S_{1})^{\\lambda_{2}}$ at the point $B\\,\\in\\,G/B$ is precisely the character $(\\lambda_{1},\\lambda_{2})\\in\\mathbb{Z}^{2}$. We hope that the reader will verify this explicitly.\n\nFor a general connected reductive group $G$ and a Borel subgroup $B\\,\\subset\\,G$, we denote by $O(\\lambda)$ the $G$-linearized line bundle on $G/B$ corresponding to a character $\\lambda:B\\to\\mathbb{C}^{\\times}$, i.e., such that $B$ acts via $\\curlywedge$ in the fiber of $O(\\lambda)$ at the point $B\\,\\in\\,G/B$. If we choose $G$ to be $S L(V)$, then every line bundle on $G/B$ admits a unique $G$ linearization and the bijection of Proposition 10.2 induces an equality Pic $G/B\\,=$ $\\operatorname{Hom}(B,\\mathbb{C}^{\\times})$, where $B$ is now a Borel subgroup of $S L(V)$.\n\nThe isomorphisms (10.3) enable us to compute explicitly the cohomology of any $G L(2)$-linearized line bundle on $G L(2)/P=\\mathbb{P}(V)$ for $V=\\mathbb{C}^{2}$. Indeed, notice that in this case\n\n$$\n{\\cal O}(\\lambda)=S_{1}^{\\lambda_{1}}\\otimes(\\tilde{V}/S_{1})^{\\lambda_{2}}=S_{1}^{\\lambda_{1}-\\lambda_{2}}\\otimes(\\Lambda^{2}(\\tilde{V}))^{\\otimes\\lambda_{2}},\n$$\n\nwhere $(\\Lambda^{2}(\\tilde{V}))^{\\otimes\\lambda_{2}}$ is a trivial bundle on $\\mathbb{P}(V)$ with a nontrivial $G$-linearization. Hence (10.3) implies for $\\lambda_{2}-\\lambda_{1}\\geq0$\n\n$$\n\\begin{array}{r l}&{H^{0}({\\mathbb{P}}(V),S_{1}^{\\lambda_{1}}\\otimes(\\tilde{V}/S_{1})^{\\lambda_{2}})=S^{\\lambda_{2}-\\lambda_{1}}(V^{*})\\otimes(\\Lambda^{2}(V))^{\\otimes\\lambda_{2}},}\\\\ &{H^{1}({\\mathbb{P}}(V),S_{1}^{\\lambda_{1}}\\otimes(\\tilde{V}/S_{1})^{\\lambda_{2}})=0;}\\end{array}\n$$\n\nfor $\\lambda_{2}-\\lambda_{1}\\leq-2,$\n\n$$\n\\begin{array}{r l}&{H^{0}({\\mathbb{P}}(V),S_{1}^{\\lambda_{1}}\\otimes(\\tilde{V}/S_{1})^{\\lambda_{2}})=0,}\\\\ &{H^{1}({\\mathbb{P}}(V),S_{1}^{\\lambda_{1}}\\otimes(\\tilde{V}/S_{1})^{\\lambda_{2}})=S^{\\lambda_{1}-\\lambda_{2}-2}(V)\\otimes(\\Lambda^{2}(V))^{\\otimes\\lambda_{2}+1};}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Order the basis of $\\mathbb{C}^{n}$ as $e_{1},\\,.\\,.\\,,e_{n}$. Then the group of characters $\\operatorname{Hom}(B,\\mathbb{C}^{\times})$ is identified with $\\mathbb{Z}^{n}$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/(Springer_Monographs_in_Mathematics)_Ivan_Penkov,_Crystal_Hoyt_-_Classical_Lie_Algebras_at_Infinity_(Springer_Monographs_in_Mathematics).pdf_199",
        "ID": "01f3fa0f-c501-4c5b-a7bf-d28e8664a162",
        "questions": "What are the sections H\u2070 and H\u00b9 of O(\u03bb\u2081, \u03bb\u2082) on \ud835\udcab(V) when \u03bb\u2082 - \u03bb\u2081 \u2264 -2?",
        "answers": "For \u03bb\u2082 - \u03bb\u2081 \u2264 -2, H\u2070(\ud835\udcab(V), S\u2081^{\u03bb\u2081} \u2297 (V/S\u2081)^{\u03bb\u2082}) = 0, and H\u00b9(\ud835\udcab(V), S\u2081^{\u03bb\u2081} \u2297 (V/S\u2081)^{\u03bb\u2082}) = S^{\u03bb\u2081 - \u03bb\u2082 - 2}(V) \u2297 (\u039b\u00b2(V))^{\u2297\u03bb\u2082 + 1}.",
        "context": "corresponds to the character det: $P\\;\\rightarrow\\;\\mathbb{C}^{\\times}$ which extends to a character of $G$ (check this!). That's why (10.5) is the pull-back on $G/P$ of a $G$-linearized bundle on $G/G$, and is hence trivial as a line bundle. The corresponding $G$-linearized bundle on $G/G$ is not trivial as a $G$-bundle (since det: $G\\to\\mathbb{C}^{\\times}$ does not equal the trivial homomorphism), and (10.5) is also not trivial as a $G$-bundle on $G/P$.\n\nNow consider in more detail the case when $m\\;=\\;n\\;-1$ and $P~=~B$ is the Borel subgroup of upper-triangular matrices in $G L(V)$ for $V\\ =\\ \\mathbb{C}^{n}$. Here the correspondence from Proposition 10.2 has the following explicit form. Order the basis of $\\mathbb{C}^{n}$ as $e_{1},\\,.\\,.\\,,e_{n}$. Then the group of characters $\\operatorname{Hom}(B,\\mathbb{C}^{\\times})$ is identified with $\\mathbb{Z}^{n}$. The $G$-linearized line bundle corresponding to $(\\lambda_{1},\\,.\\,.\\,,\\,\\lambda_{n})\\in\\mathbb{Z}^{n}$ is simply\n\n$$\nS_{1}^{\\lambda_{1}}\\otimes(S_{2}/S_{1})^{\\lambda_{2}}\\otimes\\cdot\\cdot\\otimes(\\tilde{\\mathbb{C}}^{n}/S_{n-1})^{\\lambda_{n}}.\n$$\n\nVerifying this is a non-difficult but essential computation. The simplest case is $n=2$: here one needs to check that the $B$-character in the fiber of bundle $S_{1}^{\\lambda_{1}}\\otimes$ $(\\tilde{\\mathbb{C}}^{2}/S_{1})^{\\lambda_{2}}$ at the point $B\\,\\in\\,G/B$ is precisely the character $(\\lambda_{1},\\lambda_{2})\\in\\mathbb{Z}^{2}$. We hope that the reader will verify this explicitly.\n\nFor a general connected reductive group $G$ and a Borel subgroup $B\\,\\subset\\,G$, we denote by $O(\\lambda)$ the $G$-linearized line bundle on $G/B$ corresponding to a character $\\lambda:B\\to\\mathbb{C}^{\\times}$, i.e., such that $B$ acts via $\\curlywedge$ in the fiber of $O(\\lambda)$ at the point $B\\,\\in\\,G/B$. If we choose $G$ to be $S L(V)$, then every line bundle on $G/B$ admits a unique $G$ linearization and the bijection of Proposition 10.2 induces an equality Pic $G/B\\,=$ $\\operatorname{Hom}(B,\\mathbb{C}^{\\times})$, where $B$ is now a Borel subgroup of $S L(V)$.\n\nThe isomorphisms (10.3) enable us to compute explicitly the cohomology of any $G L(2)$-linearized line bundle on $G L(2)/P=\\mathbb{P}(V)$ for $V=\\mathbb{C}^{2}$. Indeed, notice that in this case\n\n$$\n{\\cal O}(\\lambda)=S_{1}^{\\lambda_{1}}\\otimes(\\tilde{V}/S_{1})^{\\lambda_{2}}=S_{1}^{\\lambda_{1}-\\lambda_{2}}\\otimes(\\Lambda^{2}(\\tilde{V}))^{\\otimes\\lambda_{2}},\n$$\n\nwhere $(\\Lambda^{2}(\\tilde{V}))^{\\otimes\\lambda_{2}}$ is a trivial bundle on $\\mathbb{P}(V)$ with a nontrivial $G$-linearization. Hence (10.3) implies for $\\lambda_{2}-\\lambda_{1}\\geq0$\n\n$$\n\\begin{array}{r l}&{H^{0}({\\mathbb{P}}(V),S_{1}^{\\lambda_{1}}\\otimes(\\tilde{V}/S_{1})^{\\lambda_{2}})=S^{\\lambda_{2}-\\lambda_{1}}(V^{*})\\otimes(\\Lambda^{2}(V))^{\\otimes\\lambda_{2}},}\\\\ &{H^{1}({\\mathbb{P}}(V),S_{1}^{\\lambda_{1}}\\otimes(\\tilde{V}/S_{1})^{\\lambda_{2}})=0;}\\end{array}\n$$\n\nfor $\\lambda_{2}-\\lambda_{1}\\leq-2,$\n\n$$\n\\begin{array}{r l}&{H^{0}({\\mathbb{P}}(V),S_{1}^{\\lambda_{1}}\\otimes(\\tilde{V}/S_{1})^{\\lambda_{2}})=0,}\\\\ &{H^{1}({\\mathbb{P}}(V),S_{1}^{\\lambda_{1}}\\otimes(\\tilde{V}/S_{1})^{\\lambda_{2}})=S^{\\lambda_{1}-\\lambda_{2}-2}(V)\\otimes(\\Lambda^{2}(V))^{\\otimes\\lambda_{2}+1};}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "for $\\lambda_{2}-\\lambda_{1}\\leq-2,$\n$$\begin{array}{r l}&{H^{0}({\\mathbb{P}}(V),S_{1}^{\\lambda_{1}}\\otimes(\tilde{V}/S_{1})^{\\lambda_{2}})=0,}\\ &{H^{1}({\\mathbb{P}}(V),S_{1}^{\\lambda_{1}}\\otimes(\tilde{V}/S_{1})^{\\lambda_{2}})=S^{\\lambda_{1}-\\lambda_{2}-2}(V)\\otimes(\\Lambda^{2}(V))^{\\otimes\\lambda_{2}+1};}\\end{array}$$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/(Springer_Monographs_in_Mathematics)_Ivan_Penkov,_Crystal_Hoyt_-_Classical_Lie_Algebras_at_Infinity_(Springer_Monographs_in_Mathematics).pdf_199",
        "ID": "01f5b716-4b50-4821-a6b6-31e03ae688c0",
        "questions": "What is the cohomology $H^0$ of the bundle $S_1^{\\lambda_1} \\otimes (\tilde{V}/S_1)^{\\lambda_2}$ on $\\mathbb{P}(V)$ when $\\lambda_2 - \\lambda_1 \\geq 0$ for $V = \\mathbb{C}^2$?",
        "answers": "$H^{0}({\\mathbb{P}}(V),S_{1}^{\\lambda_{1}}\\otimes(\tilde{V}/S_{1})^{\\lambda_{2}})=S^{\\lambda_{2}-\\lambda_{1}}(V^{*})\\otimes(\\Lambda^{2}(V))^{\\otimes\\lambda_{2}}$",
        "context": "corresponds to the character det: $P\\;\\rightarrow\\;\\mathbb{C}^{\\times}$ which extends to a character of $G$ (check this!). That's why (10.5) is the pull-back on $G/P$ of a $G$-linearized bundle on $G/G$, and is hence trivial as a line bundle. The corresponding $G$-linearized bundle on $G/G$ is not trivial as a $G$-bundle (since det: $G\\to\\mathbb{C}^{\\times}$ does not equal the trivial homomorphism), and (10.5) is also not trivial as a $G$-bundle on $G/P$.\n\nNow consider in more detail the case when $m\\;=\\;n\\;-1$ and $P~=~B$ is the Borel subgroup of upper-triangular matrices in $G L(V)$ for $V\\ =\\ \\mathbb{C}^{n}$. Here the correspondence from Proposition 10.2 has the following explicit form. Order the basis of $\\mathbb{C}^{n}$ as $e_{1},\\,.\\,.\\,,e_{n}$. Then the group of characters $\\operatorname{Hom}(B,\\mathbb{C}^{\\times})$ is identified with $\\mathbb{Z}^{n}$. The $G$-linearized line bundle corresponding to $(\\lambda_{1},\\,.\\,.\\,,\\,\\lambda_{n})\\in\\mathbb{Z}^{n}$ is simply\n\n$$\nS_{1}^{\\lambda_{1}}\\otimes(S_{2}/S_{1})^{\\lambda_{2}}\\otimes\\cdot\\cdot\\otimes(\\tilde{\\mathbb{C}}^{n}/S_{n-1})^{\\lambda_{n}}.\n$$\n\nVerifying this is a non-difficult but essential computation. The simplest case is $n=2$: here one needs to check that the $B$-character in the fiber of bundle $S_{1}^{\\lambda_{1}}\\otimes$ $(\\tilde{\\mathbb{C}}^{2}/S_{1})^{\\lambda_{2}}$ at the point $B\\,\\in\\,G/B$ is precisely the character $(\\lambda_{1},\\lambda_{2})\\in\\mathbb{Z}^{2}$. We hope that the reader will verify this explicitly.\n\nFor a general connected reductive group $G$ and a Borel subgroup $B\\,\\subset\\,G$, we denote by $O(\\lambda)$ the $G$-linearized line bundle on $G/B$ corresponding to a character $\\lambda:B\\to\\mathbb{C}^{\\times}$, i.e., such that $B$ acts via $\\curlywedge$ in the fiber of $O(\\lambda)$ at the point $B\\,\\in\\,G/B$. If we choose $G$ to be $S L(V)$, then every line bundle on $G/B$ admits a unique $G$ linearization and the bijection of Proposition 10.2 induces an equality Pic $G/B\\,=$ $\\operatorname{Hom}(B,\\mathbb{C}^{\\times})$, where $B$ is now a Borel subgroup of $S L(V)$.\n\nThe isomorphisms (10.3) enable us to compute explicitly the cohomology of any $G L(2)$-linearized line bundle on $G L(2)/P=\\mathbb{P}(V)$ for $V=\\mathbb{C}^{2}$. Indeed, notice that in this case\n\n$$\n{\\cal O}(\\lambda)=S_{1}^{\\lambda_{1}}\\otimes(\\tilde{V}/S_{1})^{\\lambda_{2}}=S_{1}^{\\lambda_{1}-\\lambda_{2}}\\otimes(\\Lambda^{2}(\\tilde{V}))^{\\otimes\\lambda_{2}},\n$$\n\nwhere $(\\Lambda^{2}(\\tilde{V}))^{\\otimes\\lambda_{2}}$ is a trivial bundle on $\\mathbb{P}(V)$ with a nontrivial $G$-linearization. Hence (10.3) implies for $\\lambda_{2}-\\lambda_{1}\\geq0$\n\n$$\n\\begin{array}{r l}&{H^{0}({\\mathbb{P}}(V),S_{1}^{\\lambda_{1}}\\otimes(\\tilde{V}/S_{1})^{\\lambda_{2}})=S^{\\lambda_{2}-\\lambda_{1}}(V^{*})\\otimes(\\Lambda^{2}(V))^{\\otimes\\lambda_{2}},}\\\\ &{H^{1}({\\mathbb{P}}(V),S_{1}^{\\lambda_{1}}\\otimes(\\tilde{V}/S_{1})^{\\lambda_{2}})=0;}\\end{array}\n$$\n\nfor $\\lambda_{2}-\\lambda_{1}\\leq-2,$\n\n$$\n\\begin{array}{r l}&{H^{0}({\\mathbb{P}}(V),S_{1}^{\\lambda_{1}}\\otimes(\\tilde{V}/S_{1})^{\\lambda_{2}})=0,}\\\\ &{H^{1}({\\mathbb{P}}(V),S_{1}^{\\lambda_{1}}\\otimes(\\tilde{V}/S_{1})^{\\lambda_{2}})=S^{\\lambda_{1}-\\lambda_{2}-2}(V)\\otimes(\\Lambda^{2}(V))^{\\otimes\\lambda_{2}+1};}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$H^{0}({\\mathbb{P}}(V),S_{1}^{\\lambda_{1}}\\otimes(\tilde{V}/S_{1})^{\\lambda_{2}})=S^{\\lambda_{2}-\\lambda_{1}}(V^{*})\\otimes(\\Lambda^{2}(V))^{\\otimes\\lambda_{2}},$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/(Springer_Monographs_in_Mathematics)_Ivan_Penkov,_Crystal_Hoyt_-_Classical_Lie_Algebras_at_Infinity_(Springer_Monographs_in_Mathematics).pdf_199",
        "ID": "01fcbf68-8e89-454b-81f8-c72f148106b5",
        "questions": "What is the first cohomology group $H^1$ for the line bundle $S_1^{\\lambda_1} \\otimes (\tilde{V}/S_1)^{\\lambda_2}$ on $\\mathbb{P}(V)$ when $\\lambda_2 - \\lambda_1 \\leq -2$ for $V = \\mathbb{C}^2$?",
        "answers": "$H^{1}({\\mathbb{P}}(V),S_{1}^{\\lambda_{1}}\\otimes(\tilde{V}/S_{1})^{\\lambda_{2}})=S^{\\lambda_{1}-\\lambda_{2}-2}(V)\\otimes(\\Lambda^{2}(V))^{\\otimes\\lambda_{2}+1}$",
        "context": "corresponds to the character det: $P\\;\\rightarrow\\;\\mathbb{C}^{\\times}$ which extends to a character of $G$ (check this!). That's why (10.5) is the pull-back on $G/P$ of a $G$-linearized bundle on $G/G$, and is hence trivial as a line bundle. The corresponding $G$-linearized bundle on $G/G$ is not trivial as a $G$-bundle (since det: $G\\to\\mathbb{C}^{\\times}$ does not equal the trivial homomorphism), and (10.5) is also not trivial as a $G$-bundle on $G/P$.\n\nNow consider in more detail the case when $m\\;=\\;n\\;-1$ and $P~=~B$ is the Borel subgroup of upper-triangular matrices in $G L(V)$ for $V\\ =\\ \\mathbb{C}^{n}$. Here the correspondence from Proposition 10.2 has the following explicit form. Order the basis of $\\mathbb{C}^{n}$ as $e_{1},\\,.\\,.\\,,e_{n}$. Then the group of characters $\\operatorname{Hom}(B,\\mathbb{C}^{\\times})$ is identified with $\\mathbb{Z}^{n}$. The $G$-linearized line bundle corresponding to $(\\lambda_{1},\\,.\\,.\\,,\\,\\lambda_{n})\\in\\mathbb{Z}^{n}$ is simply\n\n$$\nS_{1}^{\\lambda_{1}}\\otimes(S_{2}/S_{1})^{\\lambda_{2}}\\otimes\\cdot\\cdot\\otimes(\\tilde{\\mathbb{C}}^{n}/S_{n-1})^{\\lambda_{n}}.\n$$\n\nVerifying this is a non-difficult but essential computation. The simplest case is $n=2$: here one needs to check that the $B$-character in the fiber of bundle $S_{1}^{\\lambda_{1}}\\otimes$ $(\\tilde{\\mathbb{C}}^{2}/S_{1})^{\\lambda_{2}}$ at the point $B\\,\\in\\,G/B$ is precisely the character $(\\lambda_{1},\\lambda_{2})\\in\\mathbb{Z}^{2}$. We hope that the reader will verify this explicitly.\n\nFor a general connected reductive group $G$ and a Borel subgroup $B\\,\\subset\\,G$, we denote by $O(\\lambda)$ the $G$-linearized line bundle on $G/B$ corresponding to a character $\\lambda:B\\to\\mathbb{C}^{\\times}$, i.e., such that $B$ acts via $\\curlywedge$ in the fiber of $O(\\lambda)$ at the point $B\\,\\in\\,G/B$. If we choose $G$ to be $S L(V)$, then every line bundle on $G/B$ admits a unique $G$ linearization and the bijection of Proposition 10.2 induces an equality Pic $G/B\\,=$ $\\operatorname{Hom}(B,\\mathbb{C}^{\\times})$, where $B$ is now a Borel subgroup of $S L(V)$.\n\nThe isomorphisms (10.3) enable us to compute explicitly the cohomology of any $G L(2)$-linearized line bundle on $G L(2)/P=\\mathbb{P}(V)$ for $V=\\mathbb{C}^{2}$. Indeed, notice that in this case\n\n$$\n{\\cal O}(\\lambda)=S_{1}^{\\lambda_{1}}\\otimes(\\tilde{V}/S_{1})^{\\lambda_{2}}=S_{1}^{\\lambda_{1}-\\lambda_{2}}\\otimes(\\Lambda^{2}(\\tilde{V}))^{\\otimes\\lambda_{2}},\n$$\n\nwhere $(\\Lambda^{2}(\\tilde{V}))^{\\otimes\\lambda_{2}}$ is a trivial bundle on $\\mathbb{P}(V)$ with a nontrivial $G$-linearization. Hence (10.3) implies for $\\lambda_{2}-\\lambda_{1}\\geq0$\n\n$$\n\\begin{array}{r l}&{H^{0}({\\mathbb{P}}(V),S_{1}^{\\lambda_{1}}\\otimes(\\tilde{V}/S_{1})^{\\lambda_{2}})=S^{\\lambda_{2}-\\lambda_{1}}(V^{*})\\otimes(\\Lambda^{2}(V))^{\\otimes\\lambda_{2}},}\\\\ &{H^{1}({\\mathbb{P}}(V),S_{1}^{\\lambda_{1}}\\otimes(\\tilde{V}/S_{1})^{\\lambda_{2}})=0;}\\end{array}\n$$\n\nfor $\\lambda_{2}-\\lambda_{1}\\leq-2,$\n\n$$\n\\begin{array}{r l}&{H^{0}({\\mathbb{P}}(V),S_{1}^{\\lambda_{1}}\\otimes(\\tilde{V}/S_{1})^{\\lambda_{2}})=0,}\\\\ &{H^{1}({\\mathbb{P}}(V),S_{1}^{\\lambda_{1}}\\otimes(\\tilde{V}/S_{1})^{\\lambda_{2}})=S^{\\lambda_{1}-\\lambda_{2}-2}(V)\\otimes(\\Lambda^{2}(V))^{\\otimes\\lambda_{2}+1};}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$H^{1}({\\mathbb{P}}(V),S_{1}^{\\lambda_{1}}\\otimes(\tilde{V}/S_{1})^{\\lambda_{2}})=S^{\\lambda_{1}-\\lambda_{2}-2}(V)\\otimes(\\Lambda^{2}(V))^{\\otimes\\lambda_{2}+1};$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/(Springer_Monographs_in_Mathematics)_Ivan_Penkov,_Crystal_Hoyt_-_Classical_Lie_Algebras_at_Infinity_(Springer_Monographs_in_Mathematics).pdf_199",
        "ID": "0203d17e-40d9-46b5-b5af-e2bdb377281f",
        "questions": "What condition is required on $\\lambda_1$ and $\\lambda_2$ for the triviality of the cohomology group $H^1$ of the bundle $S_1^{\\lambda_1} \\otimes (\tilde{V}/S_1)^{\\lambda_2}$ on $\\mathbb{P}(V)$ for $V = \\mathbb{C}^2$?",
        "answers": "$H^{1}({\\mathbb{P}}(V),S_{1}^{\\lambda_{1}}\\otimes(\tilde{V}/S_{1})^{\\lambda_{2}})=0;",
        "context": "corresponds to the character det: $P\\;\\rightarrow\\;\\mathbb{C}^{\\times}$ which extends to a character of $G$ (check this!). That's why (10.5) is the pull-back on $G/P$ of a $G$-linearized bundle on $G/G$, and is hence trivial as a line bundle. The corresponding $G$-linearized bundle on $G/G$ is not trivial as a $G$-bundle (since det: $G\\to\\mathbb{C}^{\\times}$ does not equal the trivial homomorphism), and (10.5) is also not trivial as a $G$-bundle on $G/P$.\n\nNow consider in more detail the case when $m\\;=\\;n\\;-1$ and $P~=~B$ is the Borel subgroup of upper-triangular matrices in $G L(V)$ for $V\\ =\\ \\mathbb{C}^{n}$. Here the correspondence from Proposition 10.2 has the following explicit form. Order the basis of $\\mathbb{C}^{n}$ as $e_{1},\\,.\\,.\\,,e_{n}$. Then the group of characters $\\operatorname{Hom}(B,\\mathbb{C}^{\\times})$ is identified with $\\mathbb{Z}^{n}$. The $G$-linearized line bundle corresponding to $(\\lambda_{1},\\,.\\,.\\,,\\,\\lambda_{n})\\in\\mathbb{Z}^{n}$ is simply\n\n$$\nS_{1}^{\\lambda_{1}}\\otimes(S_{2}/S_{1})^{\\lambda_{2}}\\otimes\\cdot\\cdot\\otimes(\\tilde{\\mathbb{C}}^{n}/S_{n-1})^{\\lambda_{n}}.\n$$\n\nVerifying this is a non-difficult but essential computation. The simplest case is $n=2$: here one needs to check that the $B$-character in the fiber of bundle $S_{1}^{\\lambda_{1}}\\otimes$ $(\\tilde{\\mathbb{C}}^{2}/S_{1})^{\\lambda_{2}}$ at the point $B\\,\\in\\,G/B$ is precisely the character $(\\lambda_{1},\\lambda_{2})\\in\\mathbb{Z}^{2}$. We hope that the reader will verify this explicitly.\n\nFor a general connected reductive group $G$ and a Borel subgroup $B\\,\\subset\\,G$, we denote by $O(\\lambda)$ the $G$-linearized line bundle on $G/B$ corresponding to a character $\\lambda:B\\to\\mathbb{C}^{\\times}$, i.e., such that $B$ acts via $\\curlywedge$ in the fiber of $O(\\lambda)$ at the point $B\\,\\in\\,G/B$. If we choose $G$ to be $S L(V)$, then every line bundle on $G/B$ admits a unique $G$ linearization and the bijection of Proposition 10.2 induces an equality Pic $G/B\\,=$ $\\operatorname{Hom}(B,\\mathbb{C}^{\\times})$, where $B$ is now a Borel subgroup of $S L(V)$.\n\nThe isomorphisms (10.3) enable us to compute explicitly the cohomology of any $G L(2)$-linearized line bundle on $G L(2)/P=\\mathbb{P}(V)$ for $V=\\mathbb{C}^{2}$. Indeed, notice that in this case\n\n$$\n{\\cal O}(\\lambda)=S_{1}^{\\lambda_{1}}\\otimes(\\tilde{V}/S_{1})^{\\lambda_{2}}=S_{1}^{\\lambda_{1}-\\lambda_{2}}\\otimes(\\Lambda^{2}(\\tilde{V}))^{\\otimes\\lambda_{2}},\n$$\n\nwhere $(\\Lambda^{2}(\\tilde{V}))^{\\otimes\\lambda_{2}}$ is a trivial bundle on $\\mathbb{P}(V)$ with a nontrivial $G$-linearization. Hence (10.3) implies for $\\lambda_{2}-\\lambda_{1}\\geq0$\n\n$$\n\\begin{array}{r l}&{H^{0}({\\mathbb{P}}(V),S_{1}^{\\lambda_{1}}\\otimes(\\tilde{V}/S_{1})^{\\lambda_{2}})=S^{\\lambda_{2}-\\lambda_{1}}(V^{*})\\otimes(\\Lambda^{2}(V))^{\\otimes\\lambda_{2}},}\\\\ &{H^{1}({\\mathbb{P}}(V),S_{1}^{\\lambda_{1}}\\otimes(\\tilde{V}/S_{1})^{\\lambda_{2}})=0;}\\end{array}\n$$\n\nfor $\\lambda_{2}-\\lambda_{1}\\leq-2,$\n\n$$\n\\begin{array}{r l}&{H^{0}({\\mathbb{P}}(V),S_{1}^{\\lambda_{1}}\\otimes(\\tilde{V}/S_{1})^{\\lambda_{2}})=0,}\\\\ &{H^{1}({\\mathbb{P}}(V),S_{1}^{\\lambda_{1}}\\otimes(\\tilde{V}/S_{1})^{\\lambda_{2}})=S^{\\lambda_{1}-\\lambda_{2}-2}(V)\\otimes(\\Lambda^{2}(V))^{\\otimes\\lambda_{2}+1};}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$H^{1}({\\mathbb{P}}(V),S_{1}^{\\lambda_{1}}\\otimes(\tilde{V}/S_{1})^{\\lambda_{2}})=0;$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/(Graduate_Studies_in_Mathematics,146)_Aaron_N._Siegel_-_Combinatorial_Game_Theory-American_Mathematical_Society_(2013).pdf_318",
        "ID": "020f1ec9-c5e4-49b6-b98e-2916ff3603f7",
        "questions": "What new type of simplification can strengthen similarity to isomorphism for a stopper with equivalent sub-positions?",
        "answers": "Fusion",
        "context": "![](images/fb44059b16cd8e71e20dfb0d0a8981fe0fdd0ed692d20bc0a6f7bcaa5f2c98ea.jpg)  \nFigure 3.1. Fusion simplifies sover  \n\n# Fusion  \n\nWe've now established that for every stopper $G$, there is a $K=G$ with no dominated or reversible options, and this $K$ is unique up to similarity. But similarity is not quite isomorphism, as shown in Figure 2.1 on page 292. Different forms of over (for example) might have different numbers of sub-positions, even though no sub-positions of either form have any dominated or reversible options. (The theory of Chapter II shows that this situation isn't possible for short games.)  \n\nSimilarity can be strengthened to isomorphism with the help of a new type of simplification: fusion of equivalent sub-positions. Figure 3.1 shows how over might be condensed in two stages. First, the two terminal positions (which are obviously equal) are fused into a single vertex; then the two positions of value over are fused in a separate step. Fusion can be seen as a loopy analogue of the Replacement Lemma (Lemma II.2.2 on page 64).  \n\nTheorem 3.5 (Fusion Lemma). Let $G$ be a stopper, and assume that no sub-position of $G$ has any dominated or reversible options. Suppose there are distinct sub-positions $H$ and $J$ of $G$ with $H=J$. Let $G^{\\prime}$ be obtained from $G$ by replacing all moves to $J$ (throughout all sub-positions of $G$) with moves to $H$. Then $G^{\\prime}$ is also a stopper and $G^{\\prime}=G$.  \n\nProof. Step 1: We first show that $G^{\\prime}$ is a stopper. Suppose (for contradiction) that there is an infinite alternating run  \n\n$$\nX_{0}^{\\prime},X_{1}^{\\prime},X_{2}^{\\prime},\\ldots.\n$$  \n\nstarting from some sub-position $X_{0}^{\\prime}$ of $G^{\\prime}$. Let  \n\n$$\nX_{0},X_{1},X_{2},\\dots\n$$  \n\nbe the corresponding sequence of sub-positions of $G$. To obtain a contradiction, we'll construct an alternating run  \n\n$$\nY_{0},Y_{1},Y_{2},\\ldots\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Similarity can be strengthened to isomorphism with the help of a new type of simplification: fusion of equivalent sub-positions.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/(Graduate_Studies_in_Mathematics,146)_Aaron_N._Siegel_-_Combinatorial_Game_Theory-American_Mathematical_Society_(2013).pdf_318",
        "ID": "02114533-d9d1-4b49-9391-e92479cbdc6c",
        "questions": "What is the assumption about sub-positions in Theorem 3.5 known as the Fusion Lemma?",
        "answers": "no sub-position of $G$ has any dominated or reversible options",
        "context": "![](images/fb44059b16cd8e71e20dfb0d0a8981fe0fdd0ed692d20bc0a6f7bcaa5f2c98ea.jpg)  \nFigure 3.1. Fusion simplifies sover  \n\n# Fusion  \n\nWe've now established that for every stopper $G$, there is a $K=G$ with no dominated or reversible options, and this $K$ is unique up to similarity. But similarity is not quite isomorphism, as shown in Figure 2.1 on page 292. Different forms of over (for example) might have different numbers of sub-positions, even though no sub-positions of either form have any dominated or reversible options. (The theory of Chapter II shows that this situation isn't possible for short games.)  \n\nSimilarity can be strengthened to isomorphism with the help of a new type of simplification: fusion of equivalent sub-positions. Figure 3.1 shows how over might be condensed in two stages. First, the two terminal positions (which are obviously equal) are fused into a single vertex; then the two positions of value over are fused in a separate step. Fusion can be seen as a loopy analogue of the Replacement Lemma (Lemma II.2.2 on page 64).  \n\nTheorem 3.5 (Fusion Lemma). Let $G$ be a stopper, and assume that no sub-position of $G$ has any dominated or reversible options. Suppose there are distinct sub-positions $H$ and $J$ of $G$ with $H=J$. Let $G^{\\prime}$ be obtained from $G$ by replacing all moves to $J$ (throughout all sub-positions of $G$) with moves to $H$. Then $G^{\\prime}$ is also a stopper and $G^{\\prime}=G$.  \n\nProof. Step 1: We first show that $G^{\\prime}$ is a stopper. Suppose (for contradiction) that there is an infinite alternating run  \n\n$$\nX_{0}^{\\prime},X_{1}^{\\prime},X_{2}^{\\prime},\\ldots.\n$$  \n\nstarting from some sub-position $X_{0}^{\\prime}$ of $G^{\\prime}$. Let  \n\n$$\nX_{0},X_{1},X_{2},\\dots\n$$  \n\nbe the corresponding sequence of sub-positions of $G$. To obtain a contradiction, we'll construct an alternating run  \n\n$$\nY_{0},Y_{1},Y_{2},\\ldots\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Theorem 3.5 (Fusion Lemma). Let $G$ be a stopper, and assume that no sub-position of $G$ has any dominated or reversible options.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/(Graduate_Studies_in_Mathematics,146)_Aaron_N._Siegel_-_Combinatorial_Game_Theory-American_Mathematical_Society_(2013).pdf_318",
        "ID": "02143e2e-79a0-4008-8043-feeedac826fc",
        "questions": "Does the fusion process described in the Fusion Lemma change the status of $G$ being a stopper?",
        "answers": "No",
        "context": "![](images/fb44059b16cd8e71e20dfb0d0a8981fe0fdd0ed692d20bc0a6f7bcaa5f2c98ea.jpg)  \nFigure 3.1. Fusion simplifies sover  \n\n# Fusion  \n\nWe've now established that for every stopper $G$, there is a $K=G$ with no dominated or reversible options, and this $K$ is unique up to similarity. But similarity is not quite isomorphism, as shown in Figure 2.1 on page 292. Different forms of over (for example) might have different numbers of sub-positions, even though no sub-positions of either form have any dominated or reversible options. (The theory of Chapter II shows that this situation isn't possible for short games.)  \n\nSimilarity can be strengthened to isomorphism with the help of a new type of simplification: fusion of equivalent sub-positions. Figure 3.1 shows how over might be condensed in two stages. First, the two terminal positions (which are obviously equal) are fused into a single vertex; then the two positions of value over are fused in a separate step. Fusion can be seen as a loopy analogue of the Replacement Lemma (Lemma II.2.2 on page 64).  \n\nTheorem 3.5 (Fusion Lemma). Let $G$ be a stopper, and assume that no sub-position of $G$ has any dominated or reversible options. Suppose there are distinct sub-positions $H$ and $J$ of $G$ with $H=J$. Let $G^{\\prime}$ be obtained from $G$ by replacing all moves to $J$ (throughout all sub-positions of $G$) with moves to $H$. Then $G^{\\prime}$ is also a stopper and $G^{\\prime}=G$.  \n\nProof. Step 1: We first show that $G^{\\prime}$ is a stopper. Suppose (for contradiction) that there is an infinite alternating run  \n\n$$\nX_{0}^{\\prime},X_{1}^{\\prime},X_{2}^{\\prime},\\ldots.\n$$  \n\nstarting from some sub-position $X_{0}^{\\prime}$ of $G^{\\prime}$. Let  \n\n$$\nX_{0},X_{1},X_{2},\\dots\n$$  \n\nbe the corresponding sequence of sub-positions of $G$. To obtain a contradiction, we'll construct an alternating run  \n\n$$\nY_{0},Y_{1},Y_{2},\\ldots\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Yes/No",
        "evidence_source": "text",
        "evidence_context": "Then $G^{\\prime}$ is also a stopper and $G^{\\prime}=G.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/(Graduate_Studies_in_Mathematics,146)_Aaron_N._Siegel_-_Combinatorial_Game_Theory-American_Mathematical_Society_(2013).pdf_318",
        "ID": "02160910-abe5-40ec-9fe1-59cdca54e759",
        "questions": "What does the sequence $X_{0}^{\\prime},X_{1}^{\\prime},X_{2}^{\\prime},\\ldots$ represent when proving Theorem 3.5 for a stopper $G$?",
        "answers": "An infinite alternating run.",
        "context": "![](images/fb44059b16cd8e71e20dfb0d0a8981fe0fdd0ed692d20bc0a6f7bcaa5f2c98ea.jpg)  \nFigure 3.1. Fusion simplifies sover  \n\n# Fusion  \n\nWe've now established that for every stopper $G$, there is a $K=G$ with no dominated or reversible options, and this $K$ is unique up to similarity. But similarity is not quite isomorphism, as shown in Figure 2.1 on page 292. Different forms of over (for example) might have different numbers of sub-positions, even though no sub-positions of either form have any dominated or reversible options. (The theory of Chapter II shows that this situation isn't possible for short games.)  \n\nSimilarity can be strengthened to isomorphism with the help of a new type of simplification: fusion of equivalent sub-positions. Figure 3.1 shows how over might be condensed in two stages. First, the two terminal positions (which are obviously equal) are fused into a single vertex; then the two positions of value over are fused in a separate step. Fusion can be seen as a loopy analogue of the Replacement Lemma (Lemma II.2.2 on page 64).  \n\nTheorem 3.5 (Fusion Lemma). Let $G$ be a stopper, and assume that no sub-position of $G$ has any dominated or reversible options. Suppose there are distinct sub-positions $H$ and $J$ of $G$ with $H=J$. Let $G^{\\prime}$ be obtained from $G$ by replacing all moves to $J$ (throughout all sub-positions of $G$) with moves to $H$. Then $G^{\\prime}$ is also a stopper and $G^{\\prime}=G$.  \n\nProof. Step 1: We first show that $G^{\\prime}$ is a stopper. Suppose (for contradiction) that there is an infinite alternating run  \n\n$$\nX_{0}^{\\prime},X_{1}^{\\prime},X_{2}^{\\prime},\\ldots.\n$$  \n\nstarting from some sub-position $X_{0}^{\\prime}$ of $G^{\\prime}$. Let  \n\n$$\nX_{0},X_{1},X_{2},\\dots\n$$  \n\nbe the corresponding sequence of sub-positions of $G$. To obtain a contradiction, we'll construct an alternating run  \n\n$$\nY_{0},Y_{1},Y_{2},\\ldots\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Suppose (for contradiction) that there is an infinite alternating run  $$ X_{0}^{\\prime},X_{1}^{\\prime},X_{2}^{\\prime},\\ldots.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/(Graduate_Studies_in_Mathematics,146)_Aaron_N._Siegel_-_Combinatorial_Game_Theory-American_Mathematical_Society_(2013).pdf_318",
        "ID": "022031dc-a078-445d-b528-a651e7ce276d",
        "questions": "How are the sequences $X_{0}^{\\prime},X_{1}^{\\prime},X_{2}^{\\prime},\\ldots$ and $X_{0},X_{1},X_{2},\\dots$ related in the proof of the Fusion Lemma for stopper $G$?",
        "answers": "The sequence $X_{0}^{\\prime},X_{1}^{\\prime},X_{2}^{\\prime},\\ldots$ corresponds to the sequence $X_{0},X_{1},X_{2},\\dots$ of sub-positions of $G$.",
        "context": "![](images/fb44059b16cd8e71e20dfb0d0a8981fe0fdd0ed692d20bc0a6f7bcaa5f2c98ea.jpg)  \nFigure 3.1. Fusion simplifies sover  \n\n# Fusion  \n\nWe've now established that for every stopper $G$, there is a $K=G$ with no dominated or reversible options, and this $K$ is unique up to similarity. But similarity is not quite isomorphism, as shown in Figure 2.1 on page 292. Different forms of over (for example) might have different numbers of sub-positions, even though no sub-positions of either form have any dominated or reversible options. (The theory of Chapter II shows that this situation isn't possible for short games.)  \n\nSimilarity can be strengthened to isomorphism with the help of a new type of simplification: fusion of equivalent sub-positions. Figure 3.1 shows how over might be condensed in two stages. First, the two terminal positions (which are obviously equal) are fused into a single vertex; then the two positions of value over are fused in a separate step. Fusion can be seen as a loopy analogue of the Replacement Lemma (Lemma II.2.2 on page 64).  \n\nTheorem 3.5 (Fusion Lemma). Let $G$ be a stopper, and assume that no sub-position of $G$ has any dominated or reversible options. Suppose there are distinct sub-positions $H$ and $J$ of $G$ with $H=J$. Let $G^{\\prime}$ be obtained from $G$ by replacing all moves to $J$ (throughout all sub-positions of $G$) with moves to $H$. Then $G^{\\prime}$ is also a stopper and $G^{\\prime}=G$.  \n\nProof. Step 1: We first show that $G^{\\prime}$ is a stopper. Suppose (for contradiction) that there is an infinite alternating run  \n\n$$\nX_{0}^{\\prime},X_{1}^{\\prime},X_{2}^{\\prime},\\ldots.\n$$  \n\nstarting from some sub-position $X_{0}^{\\prime}$ of $G^{\\prime}$. Let  \n\n$$\nX_{0},X_{1},X_{2},\\dots\n$$  \n\nbe the corresponding sequence of sub-positions of $G$. To obtain a contradiction, we'll construct an alternating run  \n\n$$\nY_{0},Y_{1},Y_{2},\\ldots\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Let  $$ X_{0},X_{1},X_{2},\\dots $$  be the corresponding sequence of sub-positions of $G$.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/(Graduate_Studies_in_Mathematics,146)_Aaron_N._Siegel_-_Combinatorial_Game_Theory-American_Mathematical_Society_(2013).pdf_318",
        "ID": "022fe37d-c8a7-4ea0-86eb-b89d6099ee1f",
        "questions": "In proving the Fusion Lemma for a stopper $G$, what sequence is constructed to obtain a contradiction to the assumption of an alternating run?",
        "answers": "An alternating run $Y_{0},Y_{1},Y_{2},\\ldots$ is constructed.",
        "context": "![](images/fb44059b16cd8e71e20dfb0d0a8981fe0fdd0ed692d20bc0a6f7bcaa5f2c98ea.jpg)  \nFigure 3.1. Fusion simplifies sover  \n\n# Fusion  \n\nWe've now established that for every stopper $G$, there is a $K=G$ with no dominated or reversible options, and this $K$ is unique up to similarity. But similarity is not quite isomorphism, as shown in Figure 2.1 on page 292. Different forms of over (for example) might have different numbers of sub-positions, even though no sub-positions of either form have any dominated or reversible options. (The theory of Chapter II shows that this situation isn't possible for short games.)  \n\nSimilarity can be strengthened to isomorphism with the help of a new type of simplification: fusion of equivalent sub-positions. Figure 3.1 shows how over might be condensed in two stages. First, the two terminal positions (which are obviously equal) are fused into a single vertex; then the two positions of value over are fused in a separate step. Fusion can be seen as a loopy analogue of the Replacement Lemma (Lemma II.2.2 on page 64).  \n\nTheorem 3.5 (Fusion Lemma). Let $G$ be a stopper, and assume that no sub-position of $G$ has any dominated or reversible options. Suppose there are distinct sub-positions $H$ and $J$ of $G$ with $H=J$. Let $G^{\\prime}$ be obtained from $G$ by replacing all moves to $J$ (throughout all sub-positions of $G$) with moves to $H$. Then $G^{\\prime}$ is also a stopper and $G^{\\prime}=G$.  \n\nProof. Step 1: We first show that $G^{\\prime}$ is a stopper. Suppose (for contradiction) that there is an infinite alternating run  \n\n$$\nX_{0}^{\\prime},X_{1}^{\\prime},X_{2}^{\\prime},\\ldots.\n$$  \n\nstarting from some sub-position $X_{0}^{\\prime}$ of $G^{\\prime}$. Let  \n\n$$\nX_{0},X_{1},X_{2},\\dots\n$$  \n\nbe the corresponding sequence of sub-positions of $G$. To obtain a contradiction, we'll construct an alternating run  \n\n$$\nY_{0},Y_{1},Y_{2},\\ldots\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "To obtain a contradiction, we'll construct an alternating run  $$ Y_{0},Y_{1},Y_{2},\\ldots.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/Measure_Theory_And_Integration(Barra).pdf_212",
        "ID": "02300212-e7a7-45ae-bd09-91eb04d36829",
        "questions": "What inequality is verified by integrating explicitly and using the series sum of 1/n^2?",
        "answers": "Minkowski's inequality",
        "context": "$$\n\\int_0^1 \\psi \\circ f \\, dx = l \\psi(a) + m \\psi(\\lambda a + \\mu b) + n \\psi(b) \\\\\n= \\psi(\\lambda a + \\mu b) - \\frac{l}{\\lambda} (\\psi(\\lambda a + \\mu b) - \\lambda \\psi(a) - \\mu \\psi(b)) \\\\\n< \\psi(\\lambda a + \\mu b).\n$$\n\nSo $ \\int_0^1 \\psi \\circ f \\, dx < \\psi \\left( \\int_0^1 f \\, dx \\right) $ a contradiction.\n  \n\n11.(i) If $a_{i}\\!\\geqslant\\!0,b_{i}\\!\\geqslant\\!0,i\\!=1,2,\\ldots,n$ and $p>1,1/p+1/q=1$ , then  \n (ii) $ \\quad \\text{If } p \\geq 1, \\left( \\sum_{i=1}^{n} |a_i + b_i|^p \\right)^{1/p} \\leq \\left( \\sum_{i=1}^{n} |a_i    |^p \\right)^{1/p} + \\left( \\sum_{i=1}^{n} |b_i|^p \\right)^{1/p}. $\n(ii)  $\\mathrm{If}\\;a_{i}\\geqslant0,b_{i}\\geqslant0,i=1,\\;.\\;.\\;.\\;,n,\\sum_{i=1}^{n}a_{i}b_{i}\\leqslant\\left(\\sum_{i=1}^{n}a_{i}\\right)\\operatorname*{max}_{1\\leqslant i\\leqslant n}\\;b_{i}$  . The proof of (i), for example, is obtained by taking  $\\begin{array}{r}{X=\\left[1,\\ldots,n\\right],a(i)=a_{i},\\mu([i])\\approx}\\end{array}$  1 so that  $\\sum_{i=1}^{n}a_{i}=\\int a\\ \\mathrm{d}\\mu.$  , and applying Holder's inequality.  \n\n12.They imply  $\\left\\|\\sin x-\\cos x\\right\\|_{2}=\\left\\|(f-\\sin x)-(f-\\cos x)\\right\\|_{2}\\leqslant\\left\\|f-\\sin x\\right\\|_{2}$   $+\\left\\|f-\\cos x\\right\\|_{2}\\leqslant1$  . But the first term is  $\\surd\\pi$  \n\n13.Apply the Schwarz inequality.  \n\n14.(i) is a special case of (i). Write  $|f|^{p}=F,|g|^{q}=G,\\alpha=1/p,\\beta=1/q$  , then  $F\\!\\in\\!L^{\\alpha}(\\mu)$   $G\\in L^{\\beta}(\\mu)$  , so by Theorem 7,  $F G\\in{\\pmb{L}}^{1}(\\mu)$  \n\n15.(i) Minkowski's inequality gives  $ |\\left\\|f\\right\\|_{2}-\\left\\|f_{n}\\right\\|_{2}|\\leqslant\\left\\|f\\!-\\!f_{n}\\right\\|_{2}$  \n(ii)  $\\left|\\int_{a}^{t}f\\;\\mathrm{d}x-\\int_{a}^{t}f_{n}\\;\\mathrm{d}x\\right|=\\left|\\int_{a}^{b}\\,\\chi_{(a,t)}\\;(f-f_{n})\\;\\mathrm{d}x\\right|\\leqslant\\sqrt{(t-a)\\,\\|f-f_{n}\\|_{2}}\\,,$  by Holders inequality.  \n\n(iii) To verify (i), integrate explicitly and use  $\\sum_{n=1}^{\\infty}\\,1/n^{2}\\ =\\ \\pi^{2}/6,$  To verify (ii), integrate and use the standard Fourier Series for  $t^{2}$  \n\n16.By Minkowski's inequality  $|\\left\\|f_{n}\\right\\|_{p}-\\left\\|f\\right\\|_{p}|\\leqslant\\left\\|f_{n}-f\\right\\|_{p}\\to0.$  \n\n17.By Example 20, p. 67, we can find  $\\psi$  such that  $\\psi({\\dot{t}})t^{p-1}\\;f^{p}\\in L^{1},\\;\\psi\\geqslant1$  on [0,1] ,  $\\psi(0+)=\\infty,$  . Then \n\n$$\nF(x) = \\int_x^1 f \\, dt = \\int_x^1 \\frac{1}{\\psi^{1/p} t^{(p-1)/p}} \\psi^{1/p} t^{(p-1)/p} f \\, dt \\\\\n\\leq \\left( \\int_x^1 \\psi^{-q/p} t^{-1} \\, dt \\right)^{1/q} \\left( \\int_x^1 t^{p-1} \\psi f^p \\, dt \\right)^{1/p}\n$$\n\nby Holder's inequality,  $\\pmb{p}$  and  $\\pmb q$  being conjugate indices. So",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "(iii) To verify (i), integrate explicitly and use $\\sum_{n=1}^{\\infty}\\,1/n^{2}\\ =\\ \\pi^{2}/6,$ To verify (ii), integrate and use the standard Fourier Series for $t^{2}$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Measure_Theory_And_Integration(Barra).pdf_212",
        "ID": "02352cfc-43d3-41cd-8443-6c48cfbb5634",
        "questions": "According to Example 20 on page 67, how is the function $\\psi$ defined on the interval [0,1]?",
        "answers": "$\\psi\\geqslant1$ on [0,1] ,  $\\psi(0+)=\\infty,$",
        "context": "$$\n\\int_0^1 \\psi \\circ f \\, dx = l \\psi(a) + m \\psi(\\lambda a + \\mu b) + n \\psi(b) \\\\\n= \\psi(\\lambda a + \\mu b) - \\frac{l}{\\lambda} (\\psi(\\lambda a + \\mu b) - \\lambda \\psi(a) - \\mu \\psi(b)) \\\\\n< \\psi(\\lambda a + \\mu b).\n$$\n\nSo $ \\int_0^1 \\psi \\circ f \\, dx < \\psi \\left( \\int_0^1 f \\, dx \\right) $ a contradiction.\n  \n\n11.(i) If $a_{i}\\!\\geqslant\\!0,b_{i}\\!\\geqslant\\!0,i\\!=1,2,\\ldots,n$ and $p>1,1/p+1/q=1$ , then  \n (ii) $ \\quad \\text{If } p \\geq 1, \\left( \\sum_{i=1}^{n} |a_i + b_i|^p \\right)^{1/p} \\leq \\left( \\sum_{i=1}^{n} |a_i    |^p \\right)^{1/p} + \\left( \\sum_{i=1}^{n} |b_i|^p \\right)^{1/p}. $\n(ii)  $\\mathrm{If}\\;a_{i}\\geqslant0,b_{i}\\geqslant0,i=1,\\;.\\;.\\;.\\;,n,\\sum_{i=1}^{n}a_{i}b_{i}\\leqslant\\left(\\sum_{i=1}^{n}a_{i}\\right)\\operatorname*{max}_{1\\leqslant i\\leqslant n}\\;b_{i}$  . The proof of (i), for example, is obtained by taking  $\\begin{array}{r}{X=\\left[1,\\ldots,n\\right],a(i)=a_{i},\\mu([i])\\approx}\\end{array}$  1 so that  $\\sum_{i=1}^{n}a_{i}=\\int a\\ \\mathrm{d}\\mu.$  , and applying Holder's inequality.  \n\n12.They imply  $\\left\\|\\sin x-\\cos x\\right\\|_{2}=\\left\\|(f-\\sin x)-(f-\\cos x)\\right\\|_{2}\\leqslant\\left\\|f-\\sin x\\right\\|_{2}$   $+\\left\\|f-\\cos x\\right\\|_{2}\\leqslant1$  . But the first term is  $\\surd\\pi$  \n\n13.Apply the Schwarz inequality.  \n\n14.(i) is a special case of (i). Write  $|f|^{p}=F,|g|^{q}=G,\\alpha=1/p,\\beta=1/q$  , then  $F\\!\\in\\!L^{\\alpha}(\\mu)$   $G\\in L^{\\beta}(\\mu)$  , so by Theorem 7,  $F G\\in{\\pmb{L}}^{1}(\\mu)$  \n\n15.(i) Minkowski's inequality gives  $ |\\left\\|f\\right\\|_{2}-\\left\\|f_{n}\\right\\|_{2}|\\leqslant\\left\\|f\\!-\\!f_{n}\\right\\|_{2}$  \n(ii)  $\\left|\\int_{a}^{t}f\\;\\mathrm{d}x-\\int_{a}^{t}f_{n}\\;\\mathrm{d}x\\right|=\\left|\\int_{a}^{b}\\,\\chi_{(a,t)}\\;(f-f_{n})\\;\\mathrm{d}x\\right|\\leqslant\\sqrt{(t-a)\\,\\|f-f_{n}\\|_{2}}\\,,$  by Holders inequality.  \n\n(iii) To verify (i), integrate explicitly and use  $\\sum_{n=1}^{\\infty}\\,1/n^{2}\\ =\\ \\pi^{2}/6,$  To verify (ii), integrate and use the standard Fourier Series for  $t^{2}$  \n\n16.By Minkowski's inequality  $|\\left\\|f_{n}\\right\\|_{p}-\\left\\|f\\right\\|_{p}|\\leqslant\\left\\|f_{n}-f\\right\\|_{p}\\to0.$  \n\n17.By Example 20, p. 67, we can find  $\\psi$  such that  $\\psi({\\dot{t}})t^{p-1}\\;f^{p}\\in L^{1},\\;\\psi\\geqslant1$  on [0,1] ,  $\\psi(0+)=\\infty,$  . Then \n\n$$\nF(x) = \\int_x^1 f \\, dt = \\int_x^1 \\frac{1}{\\psi^{1/p} t^{(p-1)/p}} \\psi^{1/p} t^{(p-1)/p} f \\, dt \\\\\n\\leq \\left( \\int_x^1 \\psi^{-q/p} t^{-1} \\, dt \\right)^{1/q} \\left( \\int_x^1 t^{p-1} \\psi f^p \\, dt \\right)^{1/p}\n$$\n\nby Holder's inequality,  $\\pmb{p}$  and  $\\pmb q$  being conjugate indices. So",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "By Example 20, p. 67, we can find $\\psi$ such that $\\psi({\\dot{t}})t^{p-1}\\;f^{p}\\in L^{1},\\;\\psi\\geqslant1$ on [0,1] ,  $\\psi(0+)=\\infty,$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Measure_Theory_And_Integration(Barra).pdf_212",
        "ID": "023f3852-0af8-4933-9f99-697f70ef6d2b",
        "questions": "Does applying the Schwarz inequality imply that $\\left\\|\\sin x-\\cos x\right\\|_{2}\\leqslant1$?",
        "answers": "Yes",
        "context": "$$\n\\int_0^1 \\psi \\circ f \\, dx = l \\psi(a) + m \\psi(\\lambda a + \\mu b) + n \\psi(b) \\\\\n= \\psi(\\lambda a + \\mu b) - \\frac{l}{\\lambda} (\\psi(\\lambda a + \\mu b) - \\lambda \\psi(a) - \\mu \\psi(b)) \\\\\n< \\psi(\\lambda a + \\mu b).\n$$\n\nSo $ \\int_0^1 \\psi \\circ f \\, dx < \\psi \\left( \\int_0^1 f \\, dx \\right) $ a contradiction.\n  \n\n11.(i) If $a_{i}\\!\\geqslant\\!0,b_{i}\\!\\geqslant\\!0,i\\!=1,2,\\ldots,n$ and $p>1,1/p+1/q=1$ , then  \n (ii) $ \\quad \\text{If } p \\geq 1, \\left( \\sum_{i=1}^{n} |a_i + b_i|^p \\right)^{1/p} \\leq \\left( \\sum_{i=1}^{n} |a_i    |^p \\right)^{1/p} + \\left( \\sum_{i=1}^{n} |b_i|^p \\right)^{1/p}. $\n(ii)  $\\mathrm{If}\\;a_{i}\\geqslant0,b_{i}\\geqslant0,i=1,\\;.\\;.\\;.\\;,n,\\sum_{i=1}^{n}a_{i}b_{i}\\leqslant\\left(\\sum_{i=1}^{n}a_{i}\\right)\\operatorname*{max}_{1\\leqslant i\\leqslant n}\\;b_{i}$  . The proof of (i), for example, is obtained by taking  $\\begin{array}{r}{X=\\left[1,\\ldots,n\\right],a(i)=a_{i},\\mu([i])\\approx}\\end{array}$  1 so that  $\\sum_{i=1}^{n}a_{i}=\\int a\\ \\mathrm{d}\\mu.$  , and applying Holder's inequality.  \n\n12.They imply  $\\left\\|\\sin x-\\cos x\\right\\|_{2}=\\left\\|(f-\\sin x)-(f-\\cos x)\\right\\|_{2}\\leqslant\\left\\|f-\\sin x\\right\\|_{2}$   $+\\left\\|f-\\cos x\\right\\|_{2}\\leqslant1$  . But the first term is  $\\surd\\pi$  \n\n13.Apply the Schwarz inequality.  \n\n14.(i) is a special case of (i). Write  $|f|^{p}=F,|g|^{q}=G,\\alpha=1/p,\\beta=1/q$  , then  $F\\!\\in\\!L^{\\alpha}(\\mu)$   $G\\in L^{\\beta}(\\mu)$  , so by Theorem 7,  $F G\\in{\\pmb{L}}^{1}(\\mu)$  \n\n15.(i) Minkowski's inequality gives  $ |\\left\\|f\\right\\|_{2}-\\left\\|f_{n}\\right\\|_{2}|\\leqslant\\left\\|f\\!-\\!f_{n}\\right\\|_{2}$  \n(ii)  $\\left|\\int_{a}^{t}f\\;\\mathrm{d}x-\\int_{a}^{t}f_{n}\\;\\mathrm{d}x\\right|=\\left|\\int_{a}^{b}\\,\\chi_{(a,t)}\\;(f-f_{n})\\;\\mathrm{d}x\\right|\\leqslant\\sqrt{(t-a)\\,\\|f-f_{n}\\|_{2}}\\,,$  by Holders inequality.  \n\n(iii) To verify (i), integrate explicitly and use  $\\sum_{n=1}^{\\infty}\\,1/n^{2}\\ =\\ \\pi^{2}/6,$  To verify (ii), integrate and use the standard Fourier Series for  $t^{2}$  \n\n16.By Minkowski's inequality  $|\\left\\|f_{n}\\right\\|_{p}-\\left\\|f\\right\\|_{p}|\\leqslant\\left\\|f_{n}-f\\right\\|_{p}\\to0.$  \n\n17.By Example 20, p. 67, we can find  $\\psi$  such that  $\\psi({\\dot{t}})t^{p-1}\\;f^{p}\\in L^{1},\\;\\psi\\geqslant1$  on [0,1] ,  $\\psi(0+)=\\infty,$  . Then \n\n$$\nF(x) = \\int_x^1 f \\, dt = \\int_x^1 \\frac{1}{\\psi^{1/p} t^{(p-1)/p}} \\psi^{1/p} t^{(p-1)/p} f \\, dt \\\\\n\\leq \\left( \\int_x^1 \\psi^{-q/p} t^{-1} \\, dt \\right)^{1/q} \\left( \\int_x^1 t^{p-1} \\psi f^p \\, dt \\right)^{1/p}\n$$\n\nby Holder's inequality,  $\\pmb{p}$  and  $\\pmb q$  being conjugate indices. So",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Yes/No",
        "evidence_source": "text",
        "evidence_context": "They imply $\\left\\|\\sin x-\\cos x\right\\|_{2}=\\left\\|(f-\\sin x)-(f-\\cos x)\right\\|_{2}\\leqslant\\left\\|f-\\sin x\right\\|_{2}$ $+\\left\\|f-\\cos x\right\\|_{2}\\leqslant1$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Measure_Theory_And_Integration(Barra).pdf_212",
        "ID": "024d4ab1-0f79-4c69-9380-d67510935b1e",
        "questions": "What does the Minkowski's inequality imply about the norms of functions f and f_n?",
        "answers": "Minkowski's inequality gives $ |\\left\\|f\\right\\|_{2}-\\left\\|f_{n}\\right\\|_{2}|\\leqslant\\left\\|f\\!-\\!f_{n}\\right\\|_{2}$",
        "context": "$$\n\\int_0^1 \\psi \\circ f \\, dx = l \\psi(a) + m \\psi(\\lambda a + \\mu b) + n \\psi(b) \\\\\n= \\psi(\\lambda a + \\mu b) - \\frac{l}{\\lambda} (\\psi(\\lambda a + \\mu b) - \\lambda \\psi(a) - \\mu \\psi(b)) \\\\\n< \\psi(\\lambda a + \\mu b).\n$$\n\nSo $ \\int_0^1 \\psi \\circ f \\, dx < \\psi \\left( \\int_0^1 f \\, dx \\right) $ a contradiction.\n  \n\n11.(i) If $a_{i}\\!\\geqslant\\!0,b_{i}\\!\\geqslant\\!0,i\\!=1,2,\\ldots,n$ and $p>1,1/p+1/q=1$ , then  \n (ii) $ \\quad \\text{If } p \\geq 1, \\left( \\sum_{i=1}^{n} |a_i + b_i|^p \\right)^{1/p} \\leq \\left( \\sum_{i=1}^{n} |a_i    |^p \\right)^{1/p} + \\left( \\sum_{i=1}^{n} |b_i|^p \\right)^{1/p}. $\n(ii)  $\\mathrm{If}\\;a_{i}\\geqslant0,b_{i}\\geqslant0,i=1,\\;.\\;.\\;.\\;,n,\\sum_{i=1}^{n}a_{i}b_{i}\\leqslant\\left(\\sum_{i=1}^{n}a_{i}\\right)\\operatorname*{max}_{1\\leqslant i\\leqslant n}\\;b_{i}$  . The proof of (i), for example, is obtained by taking  $\\begin{array}{r}{X=\\left[1,\\ldots,n\\right],a(i)=a_{i},\\mu([i])\\approx}\\end{array}$  1 so that  $\\sum_{i=1}^{n}a_{i}=\\int a\\ \\mathrm{d}\\mu.$  , and applying Holder's inequality.  \n\n12.They imply  $\\left\\|\\sin x-\\cos x\\right\\|_{2}=\\left\\|(f-\\sin x)-(f-\\cos x)\\right\\|_{2}\\leqslant\\left\\|f-\\sin x\\right\\|_{2}$   $+\\left\\|f-\\cos x\\right\\|_{2}\\leqslant1$  . But the first term is  $\\surd\\pi$  \n\n13.Apply the Schwarz inequality.  \n\n14.(i) is a special case of (i). Write  $|f|^{p}=F,|g|^{q}=G,\\alpha=1/p,\\beta=1/q$  , then  $F\\!\\in\\!L^{\\alpha}(\\mu)$   $G\\in L^{\\beta}(\\mu)$  , so by Theorem 7,  $F G\\in{\\pmb{L}}^{1}(\\mu)$  \n\n15.(i) Minkowski's inequality gives  $ |\\left\\|f\\right\\|_{2}-\\left\\|f_{n}\\right\\|_{2}|\\leqslant\\left\\|f\\!-\\!f_{n}\\right\\|_{2}$  \n(ii)  $\\left|\\int_{a}^{t}f\\;\\mathrm{d}x-\\int_{a}^{t}f_{n}\\;\\mathrm{d}x\\right|=\\left|\\int_{a}^{b}\\,\\chi_{(a,t)}\\;(f-f_{n})\\;\\mathrm{d}x\\right|\\leqslant\\sqrt{(t-a)\\,\\|f-f_{n}\\|_{2}}\\,,$  by Holders inequality.  \n\n(iii) To verify (i), integrate explicitly and use  $\\sum_{n=1}^{\\infty}\\,1/n^{2}\\ =\\ \\pi^{2}/6,$  To verify (ii), integrate and use the standard Fourier Series for  $t^{2}$  \n\n16.By Minkowski's inequality  $|\\left\\|f_{n}\\right\\|_{p}-\\left\\|f\\right\\|_{p}|\\leqslant\\left\\|f_{n}-f\\right\\|_{p}\\to0.$  \n\n17.By Example 20, p. 67, we can find  $\\psi$  such that  $\\psi({\\dot{t}})t^{p-1}\\;f^{p}\\in L^{1},\\;\\psi\\geqslant1$  on [0,1] ,  $\\psi(0+)=\\infty,$  . Then \n\n$$\nF(x) = \\int_x^1 f \\, dt = \\int_x^1 \\frac{1}{\\psi^{1/p} t^{(p-1)/p}} \\psi^{1/p} t^{(p-1)/p} f \\, dt \\\\\n\\leq \\left( \\int_x^1 \\psi^{-q/p} t^{-1} \\, dt \\right)^{1/q} \\left( \\int_x^1 t^{p-1} \\psi f^p \\, dt \\right)^{1/p}\n$$\n\nby Holder's inequality,  $\\pmb{p}$  and  $\\pmb q$  being conjugate indices. So",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$ |\\left\\|f\\right\\|_{2}-\\left\\|f_{n}\\right\\|_{2}|\\leqslant\\left\\|f\\!-\\!f_{n}\\right\\|_{2}$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/Measure_Theory_And_Integration(Barra).pdf_212",
        "ID": "0250457f-c4d9-4d9e-9a97-a7d2392cb140",
        "questions": "How does the Holder's inequality relate to the integrals of f and fn over the interval from a to t?",
        "answers": "$\\left|\\int_{a}^{t}f\\;\\mathrm{d}x-\\int_{a}^{t}f_{n}\\;\\mathrm{d}x\\right|=\\left|\\int_{a}^{b}\\,\\chi_{(a,t)}\\;(f-f_{n})\\;\\mathrm{d}x\\right|\\leqslant\\sqrt{(t-a)\\,\\|f-f_{n}\\|_{2}}\\,$",
        "context": "$$\n\\int_0^1 \\psi \\circ f \\, dx = l \\psi(a) + m \\psi(\\lambda a + \\mu b) + n \\psi(b) \\\\\n= \\psi(\\lambda a + \\mu b) - \\frac{l}{\\lambda} (\\psi(\\lambda a + \\mu b) - \\lambda \\psi(a) - \\mu \\psi(b)) \\\\\n< \\psi(\\lambda a + \\mu b).\n$$\n\nSo $ \\int_0^1 \\psi \\circ f \\, dx < \\psi \\left( \\int_0^1 f \\, dx \\right) $ a contradiction.\n  \n\n11.(i) If $a_{i}\\!\\geqslant\\!0,b_{i}\\!\\geqslant\\!0,i\\!=1,2,\\ldots,n$ and $p>1,1/p+1/q=1$ , then  \n (ii) $ \\quad \\text{If } p \\geq 1, \\left( \\sum_{i=1}^{n} |a_i + b_i|^p \\right)^{1/p} \\leq \\left( \\sum_{i=1}^{n} |a_i    |^p \\right)^{1/p} + \\left( \\sum_{i=1}^{n} |b_i|^p \\right)^{1/p}. $\n(ii)  $\\mathrm{If}\\;a_{i}\\geqslant0,b_{i}\\geqslant0,i=1,\\;.\\;.\\;.\\;,n,\\sum_{i=1}^{n}a_{i}b_{i}\\leqslant\\left(\\sum_{i=1}^{n}a_{i}\\right)\\operatorname*{max}_{1\\leqslant i\\leqslant n}\\;b_{i}$  . The proof of (i), for example, is obtained by taking  $\\begin{array}{r}{X=\\left[1,\\ldots,n\\right],a(i)=a_{i},\\mu([i])\\approx}\\end{array}$  1 so that  $\\sum_{i=1}^{n}a_{i}=\\int a\\ \\mathrm{d}\\mu.$  , and applying Holder's inequality.  \n\n12.They imply  $\\left\\|\\sin x-\\cos x\\right\\|_{2}=\\left\\|(f-\\sin x)-(f-\\cos x)\\right\\|_{2}\\leqslant\\left\\|f-\\sin x\\right\\|_{2}$   $+\\left\\|f-\\cos x\\right\\|_{2}\\leqslant1$  . But the first term is  $\\surd\\pi$  \n\n13.Apply the Schwarz inequality.  \n\n14.(i) is a special case of (i). Write  $|f|^{p}=F,|g|^{q}=G,\\alpha=1/p,\\beta=1/q$  , then  $F\\!\\in\\!L^{\\alpha}(\\mu)$   $G\\in L^{\\beta}(\\mu)$  , so by Theorem 7,  $F G\\in{\\pmb{L}}^{1}(\\mu)$  \n\n15.(i) Minkowski's inequality gives  $ |\\left\\|f\\right\\|_{2}-\\left\\|f_{n}\\right\\|_{2}|\\leqslant\\left\\|f\\!-\\!f_{n}\\right\\|_{2}$  \n(ii)  $\\left|\\int_{a}^{t}f\\;\\mathrm{d}x-\\int_{a}^{t}f_{n}\\;\\mathrm{d}x\\right|=\\left|\\int_{a}^{b}\\,\\chi_{(a,t)}\\;(f-f_{n})\\;\\mathrm{d}x\\right|\\leqslant\\sqrt{(t-a)\\,\\|f-f_{n}\\|_{2}}\\,,$  by Holders inequality.  \n\n(iii) To verify (i), integrate explicitly and use  $\\sum_{n=1}^{\\infty}\\,1/n^{2}\\ =\\ \\pi^{2}/6,$  To verify (ii), integrate and use the standard Fourier Series for  $t^{2}$  \n\n16.By Minkowski's inequality  $|\\left\\|f_{n}\\right\\|_{p}-\\left\\|f\\right\\|_{p}|\\leqslant\\left\\|f_{n}-f\\right\\|_{p}\\to0.$  \n\n17.By Example 20, p. 67, we can find  $\\psi$  such that  $\\psi({\\dot{t}})t^{p-1}\\;f^{p}\\in L^{1},\\;\\psi\\geqslant1$  on [0,1] ,  $\\psi(0+)=\\infty,$  . Then \n\n$$\nF(x) = \\int_x^1 f \\, dt = \\int_x^1 \\frac{1}{\\psi^{1/p} t^{(p-1)/p}} \\psi^{1/p} t^{(p-1)/p} f \\, dt \\\\\n\\leq \\left( \\int_x^1 \\psi^{-q/p} t^{-1} \\, dt \\right)^{1/q} \\left( \\int_x^1 t^{p-1} \\psi f^p \\, dt \\right)^{1/p}\n$$\n\nby Holder's inequality,  $\\pmb{p}$  and  $\\pmb q$  being conjugate indices. So",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$\\left|\\int_{a}^{t}f\\;\\mathrm{d}x-\\int_{a}^{t}f_{n}\\;\\mathrm{d}x\\right|=\\left|\\int_{a}^{b}\\,\\chi_{(a,t)}\\;(f-f_{n})\\;\\mathrm{d}x\\right|\\leqslant\\sqrt{(t-a)\\,\\|f-f_{n}\\|_{2}}\\,$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/Measure_Theory_And_Integration(Barra).pdf_212",
        "ID": "02540d49-db1f-4aad-ac19-80beac065dcf",
        "questions": "What inequality involving a function psi and integrals does Holder's inequality lead to in the context of conjugate indices p and q?",
        "answers": "$F(x) = \\int_x^1 f \\, dt = \\int_x^1 \\frac{1}{\\psi^{1/p} t^{(p-1)/p}} \\psi^{1/p} t^{(p-1)/p} f \\, dt \\leq \\left( \\int_x^1 \\psi^{-q/p} t^{-1} \\, dt \\right)^{1/q} \\left( \\int_x^1 t^{p-1} \\psi f^p \\, dt \\right)^{1/p}$",
        "context": "$$\n\\int_0^1 \\psi \\circ f \\, dx = l \\psi(a) + m \\psi(\\lambda a + \\mu b) + n \\psi(b) \\\\\n= \\psi(\\lambda a + \\mu b) - \\frac{l}{\\lambda} (\\psi(\\lambda a + \\mu b) - \\lambda \\psi(a) - \\mu \\psi(b)) \\\\\n< \\psi(\\lambda a + \\mu b).\n$$\n\nSo $ \\int_0^1 \\psi \\circ f \\, dx < \\psi \\left( \\int_0^1 f \\, dx \\right) $ a contradiction.\n  \n\n11.(i) If $a_{i}\\!\\geqslant\\!0,b_{i}\\!\\geqslant\\!0,i\\!=1,2,\\ldots,n$ and $p>1,1/p+1/q=1$ , then  \n (ii) $ \\quad \\text{If } p \\geq 1, \\left( \\sum_{i=1}^{n} |a_i + b_i|^p \\right)^{1/p} \\leq \\left( \\sum_{i=1}^{n} |a_i    |^p \\right)^{1/p} + \\left( \\sum_{i=1}^{n} |b_i|^p \\right)^{1/p}. $\n(ii)  $\\mathrm{If}\\;a_{i}\\geqslant0,b_{i}\\geqslant0,i=1,\\;.\\;.\\;.\\;,n,\\sum_{i=1}^{n}a_{i}b_{i}\\leqslant\\left(\\sum_{i=1}^{n}a_{i}\\right)\\operatorname*{max}_{1\\leqslant i\\leqslant n}\\;b_{i}$  . The proof of (i), for example, is obtained by taking  $\\begin{array}{r}{X=\\left[1,\\ldots,n\\right],a(i)=a_{i},\\mu([i])\\approx}\\end{array}$  1 so that  $\\sum_{i=1}^{n}a_{i}=\\int a\\ \\mathrm{d}\\mu.$  , and applying Holder's inequality.  \n\n12.They imply  $\\left\\|\\sin x-\\cos x\\right\\|_{2}=\\left\\|(f-\\sin x)-(f-\\cos x)\\right\\|_{2}\\leqslant\\left\\|f-\\sin x\\right\\|_{2}$   $+\\left\\|f-\\cos x\\right\\|_{2}\\leqslant1$  . But the first term is  $\\surd\\pi$  \n\n13.Apply the Schwarz inequality.  \n\n14.(i) is a special case of (i). Write  $|f|^{p}=F,|g|^{q}=G,\\alpha=1/p,\\beta=1/q$  , then  $F\\!\\in\\!L^{\\alpha}(\\mu)$   $G\\in L^{\\beta}(\\mu)$  , so by Theorem 7,  $F G\\in{\\pmb{L}}^{1}(\\mu)$  \n\n15.(i) Minkowski's inequality gives  $ |\\left\\|f\\right\\|_{2}-\\left\\|f_{n}\\right\\|_{2}|\\leqslant\\left\\|f\\!-\\!f_{n}\\right\\|_{2}$  \n(ii)  $\\left|\\int_{a}^{t}f\\;\\mathrm{d}x-\\int_{a}^{t}f_{n}\\;\\mathrm{d}x\\right|=\\left|\\int_{a}^{b}\\,\\chi_{(a,t)}\\;(f-f_{n})\\;\\mathrm{d}x\\right|\\leqslant\\sqrt{(t-a)\\,\\|f-f_{n}\\|_{2}}\\,,$  by Holders inequality.  \n\n(iii) To verify (i), integrate explicitly and use  $\\sum_{n=1}^{\\infty}\\,1/n^{2}\\ =\\ \\pi^{2}/6,$  To verify (ii), integrate and use the standard Fourier Series for  $t^{2}$  \n\n16.By Minkowski's inequality  $|\\left\\|f_{n}\\right\\|_{p}-\\left\\|f\\right\\|_{p}|\\leqslant\\left\\|f_{n}-f\\right\\|_{p}\\to0.$  \n\n17.By Example 20, p. 67, we can find  $\\psi$  such that  $\\psi({\\dot{t}})t^{p-1}\\;f^{p}\\in L^{1},\\;\\psi\\geqslant1$  on [0,1] ,  $\\psi(0+)=\\infty,$  . Then \n\n$$\nF(x) = \\int_x^1 f \\, dt = \\int_x^1 \\frac{1}{\\psi^{1/p} t^{(p-1)/p}} \\psi^{1/p} t^{(p-1)/p} f \\, dt \\\\\n\\leq \\left( \\int_x^1 \\psi^{-q/p} t^{-1} \\, dt \\right)^{1/q} \\left( \\int_x^1 t^{p-1} \\psi f^p \\, dt \\right)^{1/p}\n$$\n\nby Holder's inequality,  $\\pmb{p}$  and  $\\pmb q$  being conjugate indices. So",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$F(x) = \\int_x^1 f \\, dt = \\int_x^1 \\frac{1}{\\psi^{1/p} t^{(p-1)/p}} \\psi^{1/p} t^{(p-1)/p} f \\, dt \\leq \\left( \\int_x^1 \\psi^{-q/p} t^{-1} \\, dt \\right)^{1/q} \\left( \\int_x^1 t^{p-1} \\psi f^p \\, dt \\right)^{1/p}$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/unit2t03.pdf_63",
        "ID": "02567d2b-898c-47ae-ba29-667531a09fb4",
        "questions": "Where did Nathaniel Hawthorne serve as a U.S. consul during Franklin Pierce's presidency?",
        "answers": "Liverpool, England",
        "context": "The Minister's Black Veil    \n\n# Meet Nathaniel Hawthorne  \n\n![](images/3762c6e10a0e181c319f91df844a0951185fc2abee10e02d11ecbbfee8bee11e.jpg)  \n\n\u201cI don't want to be a doctor, and live by men's diseases; nor a minister to live by their sins; nor a lawyer to live by their quarrels. So I don't see there's anything left for me but to be an author. \u201d \u2014\u2014 Hawthorne  \n\nThus, some may say, Nathaniel Hawthorne became one of the United States' great writers by default.  \nHawthorne was born in the port town of Salem, Massachusetts. When Hawthorne was only four, his father, a sea captain, died of yellow fever in South America. Raised by his eccentric, reclusive mother, young Hawthorne became an avid reader of poetry and exotic adventure stories.  \nAt age seventeen, Hawthorne began his four years at Bowdoin College in Maine. His friends there included a future president and a future poet: Franklin Pierce and Henry Wadsworth Longfellow.  \nIn 1853, when his friend Franklin Pierce became president of the United States, Hawthorne was awarded the position of U.S. consul to the city of Liverpool, England. He held that position for four years. Then he toured Italy and returned to England to write his last complete novel, The Marble Faun. By 1860, he returned to the United States\u2014in ill health, struggling to continue writing and despondent. Four years later, while traveling with Franklin Pierce, Hawthorne died in his sleep.  \nAfter graduating from Bowdoin, Hawthorne sought seclusion in Salem, where he spent twelve years studying Puritan history and developing his writing skills. Out of those twelve years came two books, a novel called Fanshawe and a collection of short stories called Twice-Told Tales. Fanshawe was never popular. Hawthorne himself destroyed all the copies he could find\u2014but reviewers praised Twice-Told Tales, and the book enjoyed a modest success with the public. \nIn his writing, Hawthorne explored issues of moral and social responsibility in Puritan New England. He hated intolerance, hypocrisy, and any other sentiment that separated one from the rest of humanity. Hawthorne explored these issues in tales he called \u201callegories of the heart\u201d\u2014stories that teach a moral principle.  \nIn fact, Hawthorne's own deep family roots in Puritan Salem haunted the writer throughout his life. Hawthorne's ancestors included a man who had persecuted Quakers and one of the judges who had condemned the Salem \u201cwitches\u201d in 1692. Hawthorne himself was keenly aware of issues of sin and guilt. At the age of thirty-eight, Hawthorne married Sophia.\nPeabody and moved to the Old Manse, the house in Concord, Massachusetts, where writer Ralph Waldo Emerson had lived. However, unable to support his family as a writer, Hawthorne returned to Salem. There he served as Surveyor of the Port but lost the job when the political administration changed. Hawthorne then began writing The Scarlet Letter. This novel, published when Hawthorne was forty-six, was a sensation. He followed up the success with another novel, The House of the Seven Gables.  \n \n\u201cMr. Hawthorne's distinctive trait is invention, creation, imagination.\u201d\u2014\u2014Edgar Allan Poe  \n\n\u201cWhat other dungeon is so dark as one's own heart! What jailer so inexorable as one's self!\u201c \u2014\u2014 Hawthorne  \n\nNathaniel Hawthorne was born in 1804 and died in 1864.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "In 1853, when his friend Franklin Pierce became president of the United States, Hawthorne was awarded the position of U.S. consul to the city of Liverpool, England.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/unit2t03.pdf_63",
        "ID": "02581491-4b4e-427d-910a-7f56ee305bfc",
        "questions": "In which town was Nathaniel Hawthorne born, and what notable historical trials were associated with his ancestors?",
        "answers": "Salem, Massachusetts; Salem 'witches' trials",
        "context": "The Minister's Black Veil    \n\n# Meet Nathaniel Hawthorne  \n\n![](images/3762c6e10a0e181c319f91df844a0951185fc2abee10e02d11ecbbfee8bee11e.jpg)  \n\n\u201cI don't want to be a doctor, and live by men's diseases; nor a minister to live by their sins; nor a lawyer to live by their quarrels. So I don't see there's anything left for me but to be an author. \u201d \u2014\u2014 Hawthorne  \n\nThus, some may say, Nathaniel Hawthorne became one of the United States' great writers by default.  \nHawthorne was born in the port town of Salem, Massachusetts. When Hawthorne was only four, his father, a sea captain, died of yellow fever in South America. Raised by his eccentric, reclusive mother, young Hawthorne became an avid reader of poetry and exotic adventure stories.  \nAt age seventeen, Hawthorne began his four years at Bowdoin College in Maine. His friends there included a future president and a future poet: Franklin Pierce and Henry Wadsworth Longfellow.  \nIn 1853, when his friend Franklin Pierce became president of the United States, Hawthorne was awarded the position of U.S. consul to the city of Liverpool, England. He held that position for four years. Then he toured Italy and returned to England to write his last complete novel, The Marble Faun. By 1860, he returned to the United States\u2014in ill health, struggling to continue writing and despondent. Four years later, while traveling with Franklin Pierce, Hawthorne died in his sleep.  \nAfter graduating from Bowdoin, Hawthorne sought seclusion in Salem, where he spent twelve years studying Puritan history and developing his writing skills. Out of those twelve years came two books, a novel called Fanshawe and a collection of short stories called Twice-Told Tales. Fanshawe was never popular. Hawthorne himself destroyed all the copies he could find\u2014but reviewers praised Twice-Told Tales, and the book enjoyed a modest success with the public. \nIn his writing, Hawthorne explored issues of moral and social responsibility in Puritan New England. He hated intolerance, hypocrisy, and any other sentiment that separated one from the rest of humanity. Hawthorne explored these issues in tales he called \u201callegories of the heart\u201d\u2014stories that teach a moral principle.  \nIn fact, Hawthorne's own deep family roots in Puritan Salem haunted the writer throughout his life. Hawthorne's ancestors included a man who had persecuted Quakers and one of the judges who had condemned the Salem \u201cwitches\u201d in 1692. Hawthorne himself was keenly aware of issues of sin and guilt. At the age of thirty-eight, Hawthorne married Sophia.\nPeabody and moved to the Old Manse, the house in Concord, Massachusetts, where writer Ralph Waldo Emerson had lived. However, unable to support his family as a writer, Hawthorne returned to Salem. There he served as Surveyor of the Port but lost the job when the political administration changed. Hawthorne then began writing The Scarlet Letter. This novel, published when Hawthorne was forty-six, was a sensation. He followed up the success with another novel, The House of the Seven Gables.  \n \n\u201cMr. Hawthorne's distinctive trait is invention, creation, imagination.\u201d\u2014\u2014Edgar Allan Poe  \n\n\u201cWhat other dungeon is so dark as one's own heart! What jailer so inexorable as one's self!\u201c \u2014\u2014 Hawthorne  \n\nNathaniel Hawthorne was born in 1804 and died in 1864.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Hawthorne was born in the port town of Salem, Massachusetts. Hawthorne's ancestors included a man who had persecuted Quakers and one of the judges who had condemned the Salem 'witches' in 1692.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/unit2t03.pdf_63",
        "ID": "025b7c5f-1284-49d7-8d4e-2753ef26a5b7",
        "questions": "How many years did Nathaniel Hawthorne spend in seclusion studying Puritan history in Salem after graduating from Bowdoin, and what literary works emerged from that period?",
        "answers": "Twelve years; Fanshawe and Twice-Told Tales",
        "context": "The Minister's Black Veil    \n\n# Meet Nathaniel Hawthorne  \n\n![](images/3762c6e10a0e181c319f91df844a0951185fc2abee10e02d11ecbbfee8bee11e.jpg)  \n\n\u201cI don't want to be a doctor, and live by men's diseases; nor a minister to live by their sins; nor a lawyer to live by their quarrels. So I don't see there's anything left for me but to be an author. \u201d \u2014\u2014 Hawthorne  \n\nThus, some may say, Nathaniel Hawthorne became one of the United States' great writers by default.  \nHawthorne was born in the port town of Salem, Massachusetts. When Hawthorne was only four, his father, a sea captain, died of yellow fever in South America. Raised by his eccentric, reclusive mother, young Hawthorne became an avid reader of poetry and exotic adventure stories.  \nAt age seventeen, Hawthorne began his four years at Bowdoin College in Maine. His friends there included a future president and a future poet: Franklin Pierce and Henry Wadsworth Longfellow.  \nIn 1853, when his friend Franklin Pierce became president of the United States, Hawthorne was awarded the position of U.S. consul to the city of Liverpool, England. He held that position for four years. Then he toured Italy and returned to England to write his last complete novel, The Marble Faun. By 1860, he returned to the United States\u2014in ill health, struggling to continue writing and despondent. Four years later, while traveling with Franklin Pierce, Hawthorne died in his sleep.  \nAfter graduating from Bowdoin, Hawthorne sought seclusion in Salem, where he spent twelve years studying Puritan history and developing his writing skills. Out of those twelve years came two books, a novel called Fanshawe and a collection of short stories called Twice-Told Tales. Fanshawe was never popular. Hawthorne himself destroyed all the copies he could find\u2014but reviewers praised Twice-Told Tales, and the book enjoyed a modest success with the public. \nIn his writing, Hawthorne explored issues of moral and social responsibility in Puritan New England. He hated intolerance, hypocrisy, and any other sentiment that separated one from the rest of humanity. Hawthorne explored these issues in tales he called \u201callegories of the heart\u201d\u2014stories that teach a moral principle.  \nIn fact, Hawthorne's own deep family roots in Puritan Salem haunted the writer throughout his life. Hawthorne's ancestors included a man who had persecuted Quakers and one of the judges who had condemned the Salem \u201cwitches\u201d in 1692. Hawthorne himself was keenly aware of issues of sin and guilt. At the age of thirty-eight, Hawthorne married Sophia.\nPeabody and moved to the Old Manse, the house in Concord, Massachusetts, where writer Ralph Waldo Emerson had lived. However, unable to support his family as a writer, Hawthorne returned to Salem. There he served as Surveyor of the Port but lost the job when the political administration changed. Hawthorne then began writing The Scarlet Letter. This novel, published when Hawthorne was forty-six, was a sensation. He followed up the success with another novel, The House of the Seven Gables.  \n \n\u201cMr. Hawthorne's distinctive trait is invention, creation, imagination.\u201d\u2014\u2014Edgar Allan Poe  \n\n\u201cWhat other dungeon is so dark as one's own heart! What jailer so inexorable as one's self!\u201c \u2014\u2014 Hawthorne  \n\nNathaniel Hawthorne was born in 1804 and died in 1864.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "After graduating from Bowdoin, Hawthorne sought seclusion in Salem, where he spent twelve years studying Puritan history and developing his writing skills. Out of those twelve years came two books, a novel called Fanshawe and a collection of short stories called Twice-Told Tales.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/stats-4394.pdf_43",
        "ID": "025f1f28-e4d9-48f5-9aa0-fe016a66817e",
        "questions": "How many unique values were recorded for the 'clock' column with a count of 50?",
        "answers": "3",
        "context": "Notice that every predictor but clock has N A for every entry. Furthermore, we see a line that says that fourteen coefficients were \u201cnot defined because of singularities.\u201d This statement means that R could not compute a value for those coefficients because of some anomalies in the data. (More technically, it could not invert the matrix used in the least-squares minimization process.)\n\nThe first step toward resolving this problem is to notice that 72 observations were deleted due to \u201cmissingness,\u201d leaving only four degrees of freedom. We use the function n row(int92.dat) to determine that there are 78 total rows in this data frame. These 78 separate observations sum up to the two predictors used in the model, plus four degrees of freedom, plus 72 deleted rows. When we tried to develop the model using lm(), however, some of our data remained unused.\n\nTo determine why these rows were excluded, we must do a bit of sanity checking to see what data anomalies may be causing the problem. The function table() provides a quick way to summarize a data vector, to see if anything looks obviously out of place. Executing this function on the clock column, we obtain the following:\n\n<td><table  border=\"1\"><thead><tr><td><b>></b></td><td><b>table(clock)</b></td><td><b>table(clock)</b></td><td><b>66</b></td><td><b>70</b></td><td><b>350</b></td><td><b>77</b></td><td><b>80</b></td><td><b>80</b></td><td><b>1</b></td><td><b>90</b></td><td><b>96</b></td><td><b>99</b></td><td><b>101</b></td><td><b>101 110</b></td><td></td><td></td><td></td><td></td><td></td></tr></thead><tbody><tr><td>48</td><td>50 118</td><td>120 60 291</td><td>125 64 300</td><td>133</td><td>150</td><td>350</td><td>75 166</td><td>175</td><td>180</td><td>85 190</td><td>90 200</td><td>96 225</td><td>99 231</td><td>100 233</td><td>250</td><td>266</td><td></td><td></td><td></td><td></td></tr><tr><td>1</td><td>3</td><td>4 4</td><td>1 4</td><td>3 5</td><td>2 1</td><td>2 4</td><td>1</td><td>1</td><td>1 2</td><td>1 4</td><td>2 1</td><td>1 1</td><td>2 2</td><td>10 2</td><td>1</td><td>1 1</td><td></td><td>1</td><td></td><td></td></tr><tr><td>1</td><td>3</td><td>3</td><td>3</td><td>333</td><td>350</td><td>350</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td></td><td></td><td>2</td><td></td><td></td><td></td><td></td><td></td></tr></tbody></table></td>\n\nThe top line shows the unique values that appear in the column. The list of numbers directly below that line is the count of how many times that particular value appeared in the column. For example, 48 appeared once, while 50 appeared three times and 60 appeared four times. We see a reasonable range of values with minimum (48) and maximum (350) values that are not unexpected. Some of the values occur only once; the most frequent value occurs ten times, which again does not seem unreasonable. In short, we do not see anything obviously amiss with these results. We conclude that the problem likely is with a different data column.\n\nExecuting the table() function on the next column in the data frame threads produces this output:\n\n<td><table  border=\"1\"><thead><tr><td><b>> table(threads)</b></td></tr></thead><tbody><tr><td>threads</td></tr><tr></tr><tr></tr></tbody></table></td>",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Numeric",
        "evidence_source": "table",
        "evidence_context": "The top line shows the unique values that appear in the column. The list of numbers directly below that line is the count of how many times that particular value appeared in the column. For example, 48 appeared once, while 50 appeared three times and 60 appeared four times.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/stats-4394.pdf_43",
        "ID": "0262a5aa-edec-41ef-9762-762620379089",
        "questions": "What was the maximum value found in the 'clock' predictor column?",
        "answers": "350",
        "context": "Notice that every predictor but clock has N A for every entry. Furthermore, we see a line that says that fourteen coefficients were \u201cnot defined because of singularities.\u201d This statement means that R could not compute a value for those coefficients because of some anomalies in the data. (More technically, it could not invert the matrix used in the least-squares minimization process.)\n\nThe first step toward resolving this problem is to notice that 72 observations were deleted due to \u201cmissingness,\u201d leaving only four degrees of freedom. We use the function n row(int92.dat) to determine that there are 78 total rows in this data frame. These 78 separate observations sum up to the two predictors used in the model, plus four degrees of freedom, plus 72 deleted rows. When we tried to develop the model using lm(), however, some of our data remained unused.\n\nTo determine why these rows were excluded, we must do a bit of sanity checking to see what data anomalies may be causing the problem. The function table() provides a quick way to summarize a data vector, to see if anything looks obviously out of place. Executing this function on the clock column, we obtain the following:\n\n<td><table  border=\"1\"><thead><tr><td><b>></b></td><td><b>table(clock)</b></td><td><b>table(clock)</b></td><td><b>66</b></td><td><b>70</b></td><td><b>350</b></td><td><b>77</b></td><td><b>80</b></td><td><b>80</b></td><td><b>1</b></td><td><b>90</b></td><td><b>96</b></td><td><b>99</b></td><td><b>101</b></td><td><b>101 110</b></td><td></td><td></td><td></td><td></td><td></td></tr></thead><tbody><tr><td>48</td><td>50 118</td><td>120 60 291</td><td>125 64 300</td><td>133</td><td>150</td><td>350</td><td>75 166</td><td>175</td><td>180</td><td>85 190</td><td>90 200</td><td>96 225</td><td>99 231</td><td>100 233</td><td>250</td><td>266</td><td></td><td></td><td></td><td></td></tr><tr><td>1</td><td>3</td><td>4 4</td><td>1 4</td><td>3 5</td><td>2 1</td><td>2 4</td><td>1</td><td>1</td><td>1 2</td><td>1 4</td><td>2 1</td><td>1 1</td><td>2 2</td><td>10 2</td><td>1</td><td>1 1</td><td></td><td>1</td><td></td><td></td></tr><tr><td>1</td><td>3</td><td>3</td><td>3</td><td>333</td><td>350</td><td>350</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td></td><td></td><td>2</td><td></td><td></td><td></td><td></td><td></td></tr></tbody></table></td>\n\nThe top line shows the unique values that appear in the column. The list of numbers directly below that line is the count of how many times that particular value appeared in the column. For example, 48 appeared once, while 50 appeared three times and 60 appeared four times. We see a reasonable range of values with minimum (48) and maximum (350) values that are not unexpected. Some of the values occur only once; the most frequent value occurs ten times, which again does not seem unreasonable. In short, we do not see anything obviously amiss with these results. We conclude that the problem likely is with a different data column.\n\nExecuting the table() function on the next column in the data frame threads produces this output:\n\n<td><table  border=\"1\"><thead><tr><td><b>> table(threads)</b></td></tr></thead><tbody><tr><td>threads</td></tr><tr></tr><tr></tr></tbody></table></td>",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Numeric",
        "evidence_source": "text",
        "evidence_context": "We see a reasonable range of values with minimum (48) and maximum (350) values that are not unexpected.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/stats-4394.pdf_43",
        "ID": "026e7549-fd37-429e-86be-49572e1a901c",
        "questions": "What step did the document suggest to use to identify anomalies in the 'clock' data according to the analysis?",
        "answers": "Executing the table() function on the clock column.",
        "context": "Notice that every predictor but clock has N A for every entry. Furthermore, we see a line that says that fourteen coefficients were \u201cnot defined because of singularities.\u201d This statement means that R could not compute a value for those coefficients because of some anomalies in the data. (More technically, it could not invert the matrix used in the least-squares minimization process.)\n\nThe first step toward resolving this problem is to notice that 72 observations were deleted due to \u201cmissingness,\u201d leaving only four degrees of freedom. We use the function n row(int92.dat) to determine that there are 78 total rows in this data frame. These 78 separate observations sum up to the two predictors used in the model, plus four degrees of freedom, plus 72 deleted rows. When we tried to develop the model using lm(), however, some of our data remained unused.\n\nTo determine why these rows were excluded, we must do a bit of sanity checking to see what data anomalies may be causing the problem. The function table() provides a quick way to summarize a data vector, to see if anything looks obviously out of place. Executing this function on the clock column, we obtain the following:\n\n<td><table  border=\"1\"><thead><tr><td><b>></b></td><td><b>table(clock)</b></td><td><b>table(clock)</b></td><td><b>66</b></td><td><b>70</b></td><td><b>350</b></td><td><b>77</b></td><td><b>80</b></td><td><b>80</b></td><td><b>1</b></td><td><b>90</b></td><td><b>96</b></td><td><b>99</b></td><td><b>101</b></td><td><b>101 110</b></td><td></td><td></td><td></td><td></td><td></td></tr></thead><tbody><tr><td>48</td><td>50 118</td><td>120 60 291</td><td>125 64 300</td><td>133</td><td>150</td><td>350</td><td>75 166</td><td>175</td><td>180</td><td>85 190</td><td>90 200</td><td>96 225</td><td>99 231</td><td>100 233</td><td>250</td><td>266</td><td></td><td></td><td></td><td></td></tr><tr><td>1</td><td>3</td><td>4 4</td><td>1 4</td><td>3 5</td><td>2 1</td><td>2 4</td><td>1</td><td>1</td><td>1 2</td><td>1 4</td><td>2 1</td><td>1 1</td><td>2 2</td><td>10 2</td><td>1</td><td>1 1</td><td></td><td>1</td><td></td><td></td></tr><tr><td>1</td><td>3</td><td>3</td><td>3</td><td>333</td><td>350</td><td>350</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td></td><td></td><td>2</td><td></td><td></td><td></td><td></td><td></td></tr></tbody></table></td>\n\nThe top line shows the unique values that appear in the column. The list of numbers directly below that line is the count of how many times that particular value appeared in the column. For example, 48 appeared once, while 50 appeared three times and 60 appeared four times. We see a reasonable range of values with minimum (48) and maximum (350) values that are not unexpected. Some of the values occur only once; the most frequent value occurs ten times, which again does not seem unreasonable. In short, we do not see anything obviously amiss with these results. We conclude that the problem likely is with a different data column.\n\nExecuting the table() function on the next column in the data frame threads produces this output:\n\n<td><table  border=\"1\"><thead><tr><td><b>> table(threads)</b></td></tr></thead><tbody><tr><td>threads</td></tr><tr></tr><tr></tr></tbody></table></td>",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "The function table() provides a quick way to summarize a data vector, to see if anything looks obviously out of place. Executing this function on the clock column, we obtain the following:",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTM21-Transformation_Geometry.An_Introduction_to_Symmetry1982.pdf_173",
        "ID": "027752fe-61f6-4c6e-a89c-0559bf4fa4a3",
        "questions": "Which two mathematicians showed that the circumcircle of the Euler triangle coincides with the other two circumcircles, and also gave main contributions to projective geometry?",
        "answers": "Charles-Julian Brianchon and Jean-Victor Poncelet",
        "context": "Charles-Julian Brianchon (1785-1864) and Jean-Victor Poncelet (1788-1867) showed that the circumcircle of the Euler triangle coincides with the other two circumcircles. Therefore, as you would expect and as we shall prove next, the nine-point circle does pass through nine noteworthy points. Poncelet was introduced briefly in the last section. He gave the main impetus to the revival of projective geometry, having laid the foundations of modern projective geometry while a prisoner of the Russians in the Napoleonic Wars. Brianchon is most famous for the theorem of projective geometry he proved as a student. The theorem is known as Brianchon's Theorem: The three diagonals of a hexagon circumscribed about a conic are concurrent.\n\nWe have defined the nine-point circle of $\\triangle A B C$ to be the circumcircle of the medial triangle $\\triangle A^{\\prime}B^{\\prime}C^{\\prime}$. We first wish to show this circle, which has center $N$, also passes through the feet of the altitudes. Let $F_{a}$ be the foot of the altitude through A. So $F_{a}$ and $A^{\\prime}$ are both on $\\overleftrightarrow{B C}$. We wish to show $N F_{a}=N A^{\\prime}$. We suppose $F_{a}\\neq A^{\\prime}$. See Figure 14.17. Now, points $H$ and $F_{a}$ are on the perpendicular to $\\overleftrightarrow{B C}$ at $F_{a}$, and points $o$ and $A^{\\prime}$ are on the perpendicular to $\\overleftrightarrow{B C}$ at $A^{\\prime}$. Then, since $N$ is the midpoint of $H$ and $o$, point $N$ must be on the perpendicular bisector of segment $\\overline{{F_{a}A^{\\prime}}}$. So $N F_{a}=N A^{\\prime}$, as desired. Likewise, $N F_{b}=N B^{\\prime}$ and $N F_{c}=N C^{\\prime}$, where $F_{b}$ and $F_{c}$ are the feet of the altitudes from $B$ and $C$ respectively. Therefore, the vertices of the orthic triangle are on the nine-point circle.\n\nNow let $E_{a}, E_{b}, E_{c}$ be the midpoints between $H$ and $A, B, C$, respectively. See Figure 14.17. We wish to show these Euler points are also on the nine-point circle of $\\triangle A B C$. Since the product $\\delta_{G,\\mathrm{~-~}1/2}\\,\\delta_{H,\\,2}$ has dilation ratio $^{-1}$ and fixes point $N$, then the product is $\\sigma_{N}$. So $\\sigma_{N}(E_{a})=A^{\\prime}$, $\\sigma_{N}(E_{b})=B^{\\prime}$, and $\\sigma_{N}(E_{c})=C^{\\prime}$. Hence, $N E_{a}=N A^{\\prime}$, $N E_{b}=N B^{\\prime}$, and $N E_{c}=N C^{\\prime}$, as desired. We have proved the Nine-point Circle Theorem of Brianchon and Poncelet.\n\n![](images/a6bfbeb15a58ac5a7a855d0f914e649931aa7635e69dd97de52cca6936ffa61b.jpg)  \nNine-point circle",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Charles-Julian Brianchon (1785-1864) and Jean-Victor Poncelet (1788-1867) showed that the circumcircle of the Euler triangle coincides with the other two circumcircles.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTM21-Transformation_Geometry.An_Introduction_to_Symmetry1982.pdf_173",
        "ID": "027c013f-3801-4399-ae6a-8e2f9c19ed34",
        "questions": "What is the name of the geometric figure whose circumcircle passes through the feet of the altitudes from the vertices of triangle ABC?",
        "answers": "Nine-point circle",
        "context": "Charles-Julian Brianchon (1785-1864) and Jean-Victor Poncelet (1788-1867) showed that the circumcircle of the Euler triangle coincides with the other two circumcircles. Therefore, as you would expect and as we shall prove next, the nine-point circle does pass through nine noteworthy points. Poncelet was introduced briefly in the last section. He gave the main impetus to the revival of projective geometry, having laid the foundations of modern projective geometry while a prisoner of the Russians in the Napoleonic Wars. Brianchon is most famous for the theorem of projective geometry he proved as a student. The theorem is known as Brianchon's Theorem: The three diagonals of a hexagon circumscribed about a conic are concurrent.\n\nWe have defined the nine-point circle of $\\triangle A B C$ to be the circumcircle of the medial triangle $\\triangle A^{\\prime}B^{\\prime}C^{\\prime}$. We first wish to show this circle, which has center $N$, also passes through the feet of the altitudes. Let $F_{a}$ be the foot of the altitude through A. So $F_{a}$ and $A^{\\prime}$ are both on $\\overleftrightarrow{B C}$. We wish to show $N F_{a}=N A^{\\prime}$. We suppose $F_{a}\\neq A^{\\prime}$. See Figure 14.17. Now, points $H$ and $F_{a}$ are on the perpendicular to $\\overleftrightarrow{B C}$ at $F_{a}$, and points $o$ and $A^{\\prime}$ are on the perpendicular to $\\overleftrightarrow{B C}$ at $A^{\\prime}$. Then, since $N$ is the midpoint of $H$ and $o$, point $N$ must be on the perpendicular bisector of segment $\\overline{{F_{a}A^{\\prime}}}$. So $N F_{a}=N A^{\\prime}$, as desired. Likewise, $N F_{b}=N B^{\\prime}$ and $N F_{c}=N C^{\\prime}$, where $F_{b}$ and $F_{c}$ are the feet of the altitudes from $B$ and $C$ respectively. Therefore, the vertices of the orthic triangle are on the nine-point circle.\n\nNow let $E_{a}, E_{b}, E_{c}$ be the midpoints between $H$ and $A, B, C$, respectively. See Figure 14.17. We wish to show these Euler points are also on the nine-point circle of $\\triangle A B C$. Since the product $\\delta_{G,\\mathrm{~-~}1/2}\\,\\delta_{H,\\,2}$ has dilation ratio $^{-1}$ and fixes point $N$, then the product is $\\sigma_{N}$. So $\\sigma_{N}(E_{a})=A^{\\prime}$, $\\sigma_{N}(E_{b})=B^{\\prime}$, and $\\sigma_{N}(E_{c})=C^{\\prime}$. Hence, $N E_{a}=N A^{\\prime}$, $N E_{b}=N B^{\\prime}$, and $N E_{c}=N C^{\\prime}$, as desired. We have proved the Nine-point Circle Theorem of Brianchon and Poncelet.\n\n![](images/a6bfbeb15a58ac5a7a855d0f914e649931aa7635e69dd97de52cca6936ffa61b.jpg)  \nNine-point circle",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Therefore, as you would expect and as we shall prove next, the nine-point circle does pass through nine noteworthy points.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTM21-Transformation_Geometry.An_Introduction_to_Symmetry1982.pdf_173",
        "ID": "027dc8dd-d8bb-40a9-9fcf-f5af80fc9ce2",
        "questions": "When Charles-Julian Brianchon was a student, he proved a theorem in projective geometry involving the diagonals of a hexagon and a conic. What is the name of this theorem?",
        "answers": "Brianchon's Theorem",
        "context": "Charles-Julian Brianchon (1785-1864) and Jean-Victor Poncelet (1788-1867) showed that the circumcircle of the Euler triangle coincides with the other two circumcircles. Therefore, as you would expect and as we shall prove next, the nine-point circle does pass through nine noteworthy points. Poncelet was introduced briefly in the last section. He gave the main impetus to the revival of projective geometry, having laid the foundations of modern projective geometry while a prisoner of the Russians in the Napoleonic Wars. Brianchon is most famous for the theorem of projective geometry he proved as a student. The theorem is known as Brianchon's Theorem: The three diagonals of a hexagon circumscribed about a conic are concurrent.\n\nWe have defined the nine-point circle of $\\triangle A B C$ to be the circumcircle of the medial triangle $\\triangle A^{\\prime}B^{\\prime}C^{\\prime}$. We first wish to show this circle, which has center $N$, also passes through the feet of the altitudes. Let $F_{a}$ be the foot of the altitude through A. So $F_{a}$ and $A^{\\prime}$ are both on $\\overleftrightarrow{B C}$. We wish to show $N F_{a}=N A^{\\prime}$. We suppose $F_{a}\\neq A^{\\prime}$. See Figure 14.17. Now, points $H$ and $F_{a}$ are on the perpendicular to $\\overleftrightarrow{B C}$ at $F_{a}$, and points $o$ and $A^{\\prime}$ are on the perpendicular to $\\overleftrightarrow{B C}$ at $A^{\\prime}$. Then, since $N$ is the midpoint of $H$ and $o$, point $N$ must be on the perpendicular bisector of segment $\\overline{{F_{a}A^{\\prime}}}$. So $N F_{a}=N A^{\\prime}$, as desired. Likewise, $N F_{b}=N B^{\\prime}$ and $N F_{c}=N C^{\\prime}$, where $F_{b}$ and $F_{c}$ are the feet of the altitudes from $B$ and $C$ respectively. Therefore, the vertices of the orthic triangle are on the nine-point circle.\n\nNow let $E_{a}, E_{b}, E_{c}$ be the midpoints between $H$ and $A, B, C$, respectively. See Figure 14.17. We wish to show these Euler points are also on the nine-point circle of $\\triangle A B C$. Since the product $\\delta_{G,\\mathrm{~-~}1/2}\\,\\delta_{H,\\,2}$ has dilation ratio $^{-1}$ and fixes point $N$, then the product is $\\sigma_{N}$. So $\\sigma_{N}(E_{a})=A^{\\prime}$, $\\sigma_{N}(E_{b})=B^{\\prime}$, and $\\sigma_{N}(E_{c})=C^{\\prime}$. Hence, $N E_{a}=N A^{\\prime}$, $N E_{b}=N B^{\\prime}$, and $N E_{c}=N C^{\\prime}$, as desired. We have proved the Nine-point Circle Theorem of Brianchon and Poncelet.\n\n![](images/a6bfbeb15a58ac5a7a855d0f914e649931aa7635e69dd97de52cca6936ffa61b.jpg)  \nNine-point circle",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Brianchon is most famous for the theorem of projective geometry he proved as a student. The theorem is known as Brianchon's Theorem: The three diagonals of a hexagon circumscribed about a conic are concurrent.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/textbook_needrop_en_1249",
        "ID": "028990e6-2dd2-48eb-bd57-7ceaa623c278",
        "questions": "How many HIV carriers were reported in China by the end of 2009, according to the document?",
        "answers": "35.74 million",
        "context": "There are over 30 million people living with HIV worldwide. According to the World Health Organization (WHO), more than 4 million children have died of Aids, and more than 15 million children have lost their parents to Aids. Something must be done to stop this disease.  \n\nChina has also been affected by Aids. By the end of 2009, there were about 35.74 million HIV carriers in China, among whom about 105,000 were Aids patients. In a bid to control the problem, the government has opened labs to monitor the disease, and in 2003 it also started providing free drugs for Aids patients.  \n\nInternational help has also been very important in fighting Aids in China. Dr. David Ho, a Chinese-American Aids expert, has devoted himself to bringing up-to-date technology and international attention to China's Aids problem. Since 2001, organizations such as the United Nations have also been supporting Aids education and medicine programmes in China.  \n\nThe United Nations has been very active in fighting Aids and HIV around the world. UNAIDS, an organization within the United Nations, was founded in 1996 with the agenda of helping prevent the spread of Aids. UNAIDS provides people with HIV testing and HIV or Aids medical care. It also teaches young people how to prevent Aids, and sets up treatment centres where mothers with HIV can receive medicine to help keep them from passing HIV on to their children.  \n\nThe work of international organizations is even more important when you consider how much more severe the situation could become. Between 2000 and 2020, over 68 million people will die of Aids. The number of children losing both parents to Aids is also expected to rise.  \n\nWhile losing one's parents to this disease seems terrible and unfair, Ajani and his sister are fortunate. Their grandfather is now caring for them, and because their mother had access to prescription Aids medicines when she was pregnant, they did not get HIV from her. Ajani now wants to be a doctor when he grows up. He believes that education as well as medical treatment is the key to stopping the disease in the future.  \n\n# Reading strategy: identifying links between paragraphs  \n\nWhen reading a text, one should be able to follow the thoughts of the author from one paragraph to the next. Sometimes, the last sentence of a paragraph introduces the topic of the next paragraph. This allows a smooth flow of ideas and makes sure that readers do not lose the focus of the text. The sixth paragraph of the TV news transcript ends with, \u2018Since 2001, organizations such as the United Nations have also been supporting Aids education and medicine programmes in China.\u2019 This introduces the topic of the next paragraph: \u2018The United Nations has been very active in fighting Aids and HIV around the world.\u2019 By identifying these links between paragraphs, readers can follow the logic of the text.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Numeric",
        "evidence_source": "text",
        "evidence_context": "By the end of 2009, there were about 35.74 million HIV carriers in China, among whom about 105,000 were Aids patients.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/textbook_needrop_en_1249",
        "ID": "028b4601-c928-4b58-8b24-de88a308406d",
        "questions": "What is the name of the organization within the United Nations that was founded in 1996 to help combat Aids?",
        "answers": "UNAIDS",
        "context": "There are over 30 million people living with HIV worldwide. According to the World Health Organization (WHO), more than 4 million children have died of Aids, and more than 15 million children have lost their parents to Aids. Something must be done to stop this disease.  \n\nChina has also been affected by Aids. By the end of 2009, there were about 35.74 million HIV carriers in China, among whom about 105,000 were Aids patients. In a bid to control the problem, the government has opened labs to monitor the disease, and in 2003 it also started providing free drugs for Aids patients.  \n\nInternational help has also been very important in fighting Aids in China. Dr. David Ho, a Chinese-American Aids expert, has devoted himself to bringing up-to-date technology and international attention to China's Aids problem. Since 2001, organizations such as the United Nations have also been supporting Aids education and medicine programmes in China.  \n\nThe United Nations has been very active in fighting Aids and HIV around the world. UNAIDS, an organization within the United Nations, was founded in 1996 with the agenda of helping prevent the spread of Aids. UNAIDS provides people with HIV testing and HIV or Aids medical care. It also teaches young people how to prevent Aids, and sets up treatment centres where mothers with HIV can receive medicine to help keep them from passing HIV on to their children.  \n\nThe work of international organizations is even more important when you consider how much more severe the situation could become. Between 2000 and 2020, over 68 million people will die of Aids. The number of children losing both parents to Aids is also expected to rise.  \n\nWhile losing one's parents to this disease seems terrible and unfair, Ajani and his sister are fortunate. Their grandfather is now caring for them, and because their mother had access to prescription Aids medicines when she was pregnant, they did not get HIV from her. Ajani now wants to be a doctor when he grows up. He believes that education as well as medical treatment is the key to stopping the disease in the future.  \n\n# Reading strategy: identifying links between paragraphs  \n\nWhen reading a text, one should be able to follow the thoughts of the author from one paragraph to the next. Sometimes, the last sentence of a paragraph introduces the topic of the next paragraph. This allows a smooth flow of ideas and makes sure that readers do not lose the focus of the text. The sixth paragraph of the TV news transcript ends with, \u2018Since 2001, organizations such as the United Nations have also been supporting Aids education and medicine programmes in China.\u2019 This introduces the topic of the next paragraph: \u2018The United Nations has been very active in fighting Aids and HIV around the world.\u2019 By identifying these links between paragraphs, readers can follow the logic of the text.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "UNAIDS, an organization within the United Nations, was founded in 1996 with the agenda of helping prevent the spread of Aids.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/textbook_needrop_en_1249",
        "ID": "029f8bac-07ee-45ad-a63f-da295877696a",
        "questions": "What specific action did Ajani's mother's access to aids medicines prevent?",
        "answers": "It helped keep them from passing HIV on to their children.",
        "context": "There are over 30 million people living with HIV worldwide. According to the World Health Organization (WHO), more than 4 million children have died of Aids, and more than 15 million children have lost their parents to Aids. Something must be done to stop this disease.  \n\nChina has also been affected by Aids. By the end of 2009, there were about 35.74 million HIV carriers in China, among whom about 105,000 were Aids patients. In a bid to control the problem, the government has opened labs to monitor the disease, and in 2003 it also started providing free drugs for Aids patients.  \n\nInternational help has also been very important in fighting Aids in China. Dr. David Ho, a Chinese-American Aids expert, has devoted himself to bringing up-to-date technology and international attention to China's Aids problem. Since 2001, organizations such as the United Nations have also been supporting Aids education and medicine programmes in China.  \n\nThe United Nations has been very active in fighting Aids and HIV around the world. UNAIDS, an organization within the United Nations, was founded in 1996 with the agenda of helping prevent the spread of Aids. UNAIDS provides people with HIV testing and HIV or Aids medical care. It also teaches young people how to prevent Aids, and sets up treatment centres where mothers with HIV can receive medicine to help keep them from passing HIV on to their children.  \n\nThe work of international organizations is even more important when you consider how much more severe the situation could become. Between 2000 and 2020, over 68 million people will die of Aids. The number of children losing both parents to Aids is also expected to rise.  \n\nWhile losing one's parents to this disease seems terrible and unfair, Ajani and his sister are fortunate. Their grandfather is now caring for them, and because their mother had access to prescription Aids medicines when she was pregnant, they did not get HIV from her. Ajani now wants to be a doctor when he grows up. He believes that education as well as medical treatment is the key to stopping the disease in the future.  \n\n# Reading strategy: identifying links between paragraphs  \n\nWhen reading a text, one should be able to follow the thoughts of the author from one paragraph to the next. Sometimes, the last sentence of a paragraph introduces the topic of the next paragraph. This allows a smooth flow of ideas and makes sure that readers do not lose the focus of the text. The sixth paragraph of the TV news transcript ends with, \u2018Since 2001, organizations such as the United Nations have also been supporting Aids education and medicine programmes in China.\u2019 This introduces the topic of the next paragraph: \u2018The United Nations has been very active in fighting Aids and HIV around the world.\u2019 By identifying these links between paragraphs, readers can follow the logic of the text.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Yes/No",
        "evidence_source": "text",
        "evidence_context": "Their grandfather is now caring for them, and because their mother had access to prescription Aids medicines when she was pregnant, they did not get HIV from her.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/eng-24223.pdf_184",
        "ID": "02a8c33b-0af1-44ed-8a44-36bc8224a1c8",
        "questions": "What is the meaning of the sensitivity function \\( S \\) in control systems design?",
        "answers": "The sensitivity function \\( S \\) is the transfer function mapping disturbances to the output",
        "context": "# 18.3: Algebraic Constraints  \n\nIn general, we would like to design feedback controllers to attenuate both noise and disturbances at the output. We have examined SISO and MIMO conditions that guarantee rejection of low frequency disturbances as well as similar conditions for the rejection of high frequency noise. However, one might wonder if we can  \n\n1. minimize the influence of either noise or disturbances over all frequencies, and/or 2. minimize the influence of both noise and disturbances at the same frequency  \n\nLet us begin this discussion by recalling the following  \n\n- $S=(I+P K)^{-1}$  is the transfer function mapping disturbances to the output\n- $T=P K(I+P K)^{-1}$  is the transfer function mapping noise to the output.  \n\nAs mentioned earlier, in a control design it is usually desirable to make both  $S$  and  $T$  small. However, because of algebraic constraints, both goals are not simultaneously achievable at the same frequency. These constraints are as follows.  \n\n# General Limitations  \n\n$S+T=I$  for all complex (Laplace domain) frequencies  $s$  . This is easily verified, since  \n\n$$\n\\begin{array}{r l}&{S+T\\,=\\left(I+P K\\right)^{-1}+P K(I+P K)^{-1}}\\\\ &{\\quad\\quad\\quad=(I+P K)(I+P K)^{-1}}\\\\ &{\\quad\\quad\\quad=I}\\end{array}\n$$  \n\nThis result implies that if  $\\sigma_{\\mathrm{max}}[S(j\\omega)]$  is small in some frequency range,  $\\sigma_{\\mathrm{max}}[T(j\\omega)]\\sim1$  . The converse is also true.  \n\nFortunately, we rarely need to make both of these functions small in the same frequency region  \n\n# Limitations Due to RHP Zeros and Poles  \n\nBefore we discuss these limitations, we quote the following fact from complex analysis  \n\nLet  $H(s)$  be a stable, causal, linear time-invariant continuous-time system. The maximum modulus principle implies that  \n\n$$\n\\sigma_{\\operatorname*{max}}[H(s)]\\leq\\operatorname*{sup}_{\\omega}\\sigma\\operatorname*{max}[H(j\\omega)]=\\|H\\|_{\\infty}\\quad\\forall s\\in\\mathrm{RHP}\n$$  \n\nIn other words, a stable function, which is analytic in the RHP, achieves its maximum value over the RHP when evaluated on the imaginary axis.  \n\nUsing this result, we can arrive at relationships between poles and zeros of the plant  $P$  located in the RHP and limitations on performance (e.g., disturbance and noise rejection)  \n\n# SISO Systems: Disturbance Rejection  \n\nConsider the stable sensitivity function  $S=(1+P K)^{-1}$  for any stabilizing controller,  $K$; then,  \n\n$$\n\\begin{array}{r l}{S\\left(z_{i}\\right)=\\left(1+P\\left(z_{i}\\right)K\\left(z_{i}\\right)\\right)^{-1}=1}&{{}{\\mathrm{~for~all~RHP~zeros~}}z_{i}{\\mathrm{~of~}}P}\\\\ {S\\left(p_{i}\\right)=\\left(1+P\\left(p_{i}\\right)K\\left(p_{i}\\right)\\right)^{-1}=0}&{{}{\\mathrm{~for~all~RHP~poles~}}p_{i}{\\mathrm{~of~}}P}\\end{array}\n$$  \n\nSince the  $\\mathcal{H}_{\\infty}$  norm bounds the gain of a system over all frequencies  \n\n$$\n1=|S\\left(z_{i}\\right)|\\leq||S||_{\\infty}\n$$  \n\nThis means that we cannot uniformly attenuate disturbances over the entire frequency range if there are zeros in the RHP  \n\n# SISO Systems: Noise Rejection  \n\nSince the transfer function relating a noise input to the output is  $T=P K(1+P K)^{-1}$  , an argument for  $T$  similar to  $S$  can be made, but with the roles of poles and zeros interchanged. In this case, RHP poles of the plant restrict us from uniformly attenuating noise over the entire frequency range.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "- $S=(I+P K)^{-1}$  is the transfer function mapping disturbances to the output",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/eng-24223.pdf_184",
        "ID": "02aa4b88-4451-41f9-a853-40f381abda59",
        "questions": "Can the functions \\( S \\) and \\( T \\) be made small simultaneously at the same frequency in a control design?",
        "answers": "No",
        "context": "# 18.3: Algebraic Constraints  \n\nIn general, we would like to design feedback controllers to attenuate both noise and disturbances at the output. We have examined SISO and MIMO conditions that guarantee rejection of low frequency disturbances as well as similar conditions for the rejection of high frequency noise. However, one might wonder if we can  \n\n1. minimize the influence of either noise or disturbances over all frequencies, and/or 2. minimize the influence of both noise and disturbances at the same frequency  \n\nLet us begin this discussion by recalling the following  \n\n- $S=(I+P K)^{-1}$  is the transfer function mapping disturbances to the output\n- $T=P K(I+P K)^{-1}$  is the transfer function mapping noise to the output.  \n\nAs mentioned earlier, in a control design it is usually desirable to make both  $S$  and  $T$  small. However, because of algebraic constraints, both goals are not simultaneously achievable at the same frequency. These constraints are as follows.  \n\n# General Limitations  \n\n$S+T=I$  for all complex (Laplace domain) frequencies  $s$  . This is easily verified, since  \n\n$$\n\\begin{array}{r l}&{S+T\\,=\\left(I+P K\\right)^{-1}+P K(I+P K)^{-1}}\\\\ &{\\quad\\quad\\quad=(I+P K)(I+P K)^{-1}}\\\\ &{\\quad\\quad\\quad=I}\\end{array}\n$$  \n\nThis result implies that if  $\\sigma_{\\mathrm{max}}[S(j\\omega)]$  is small in some frequency range,  $\\sigma_{\\mathrm{max}}[T(j\\omega)]\\sim1$  . The converse is also true.  \n\nFortunately, we rarely need to make both of these functions small in the same frequency region  \n\n# Limitations Due to RHP Zeros and Poles  \n\nBefore we discuss these limitations, we quote the following fact from complex analysis  \n\nLet  $H(s)$  be a stable, causal, linear time-invariant continuous-time system. The maximum modulus principle implies that  \n\n$$\n\\sigma_{\\operatorname*{max}}[H(s)]\\leq\\operatorname*{sup}_{\\omega}\\sigma\\operatorname*{max}[H(j\\omega)]=\\|H\\|_{\\infty}\\quad\\forall s\\in\\mathrm{RHP}\n$$  \n\nIn other words, a stable function, which is analytic in the RHP, achieves its maximum value over the RHP when evaluated on the imaginary axis.  \n\nUsing this result, we can arrive at relationships between poles and zeros of the plant  $P$  located in the RHP and limitations on performance (e.g., disturbance and noise rejection)  \n\n# SISO Systems: Disturbance Rejection  \n\nConsider the stable sensitivity function  $S=(1+P K)^{-1}$  for any stabilizing controller,  $K$; then,  \n\n$$\n\\begin{array}{r l}{S\\left(z_{i}\\right)=\\left(1+P\\left(z_{i}\\right)K\\left(z_{i}\\right)\\right)^{-1}=1}&{{}{\\mathrm{~for~all~RHP~zeros~}}z_{i}{\\mathrm{~of~}}P}\\\\ {S\\left(p_{i}\\right)=\\left(1+P\\left(p_{i}\\right)K\\left(p_{i}\\right)\\right)^{-1}=0}&{{}{\\mathrm{~for~all~RHP~poles~}}p_{i}{\\mathrm{~of~}}P}\\end{array}\n$$  \n\nSince the  $\\mathcal{H}_{\\infty}$  norm bounds the gain of a system over all frequencies  \n\n$$\n1=|S\\left(z_{i}\\right)|\\leq||S||_{\\infty}\n$$  \n\nThis means that we cannot uniformly attenuate disturbances over the entire frequency range if there are zeros in the RHP  \n\n# SISO Systems: Noise Rejection  \n\nSince the transfer function relating a noise input to the output is  $T=P K(1+P K)^{-1}$  , an argument for  $T$  similar to  $S$  can be made, but with the roles of poles and zeros interchanged. In this case, RHP poles of the plant restrict us from uniformly attenuating noise over the entire frequency range.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Yes/No",
        "evidence_source": "text",
        "evidence_context": "However, because of algebraic constraints, both goals are not simultaneously achievable at the same frequency.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/eng-24223.pdf_184",
        "ID": "02ae7872-9c3e-4bc8-b715-cf06aaae38c4",
        "questions": "What implication does the maximum modulus principle have for a stable function that is analytic in the right half-plane (RHP)?",
        "answers": "A stable function, which is analytic in the RHP, achieves its maximum value over the RHP when evaluated on the imaginary axis.",
        "context": "# 18.3: Algebraic Constraints  \n\nIn general, we would like to design feedback controllers to attenuate both noise and disturbances at the output. We have examined SISO and MIMO conditions that guarantee rejection of low frequency disturbances as well as similar conditions for the rejection of high frequency noise. However, one might wonder if we can  \n\n1. minimize the influence of either noise or disturbances over all frequencies, and/or 2. minimize the influence of both noise and disturbances at the same frequency  \n\nLet us begin this discussion by recalling the following  \n\n- $S=(I+P K)^{-1}$  is the transfer function mapping disturbances to the output\n- $T=P K(I+P K)^{-1}$  is the transfer function mapping noise to the output.  \n\nAs mentioned earlier, in a control design it is usually desirable to make both  $S$  and  $T$  small. However, because of algebraic constraints, both goals are not simultaneously achievable at the same frequency. These constraints are as follows.  \n\n# General Limitations  \n\n$S+T=I$  for all complex (Laplace domain) frequencies  $s$  . This is easily verified, since  \n\n$$\n\\begin{array}{r l}&{S+T\\,=\\left(I+P K\\right)^{-1}+P K(I+P K)^{-1}}\\\\ &{\\quad\\quad\\quad=(I+P K)(I+P K)^{-1}}\\\\ &{\\quad\\quad\\quad=I}\\end{array}\n$$  \n\nThis result implies that if  $\\sigma_{\\mathrm{max}}[S(j\\omega)]$  is small in some frequency range,  $\\sigma_{\\mathrm{max}}[T(j\\omega)]\\sim1$  . The converse is also true.  \n\nFortunately, we rarely need to make both of these functions small in the same frequency region  \n\n# Limitations Due to RHP Zeros and Poles  \n\nBefore we discuss these limitations, we quote the following fact from complex analysis  \n\nLet  $H(s)$  be a stable, causal, linear time-invariant continuous-time system. The maximum modulus principle implies that  \n\n$$\n\\sigma_{\\operatorname*{max}}[H(s)]\\leq\\operatorname*{sup}_{\\omega}\\sigma\\operatorname*{max}[H(j\\omega)]=\\|H\\|_{\\infty}\\quad\\forall s\\in\\mathrm{RHP}\n$$  \n\nIn other words, a stable function, which is analytic in the RHP, achieves its maximum value over the RHP when evaluated on the imaginary axis.  \n\nUsing this result, we can arrive at relationships between poles and zeros of the plant  $P$  located in the RHP and limitations on performance (e.g., disturbance and noise rejection)  \n\n# SISO Systems: Disturbance Rejection  \n\nConsider the stable sensitivity function  $S=(1+P K)^{-1}$  for any stabilizing controller,  $K$; then,  \n\n$$\n\\begin{array}{r l}{S\\left(z_{i}\\right)=\\left(1+P\\left(z_{i}\\right)K\\left(z_{i}\\right)\\right)^{-1}=1}&{{}{\\mathrm{~for~all~RHP~zeros~}}z_{i}{\\mathrm{~of~}}P}\\\\ {S\\left(p_{i}\\right)=\\left(1+P\\left(p_{i}\\right)K\\left(p_{i}\\right)\\right)^{-1}=0}&{{}{\\mathrm{~for~all~RHP~poles~}}p_{i}{\\mathrm{~of~}}P}\\end{array}\n$$  \n\nSince the  $\\mathcal{H}_{\\infty}$  norm bounds the gain of a system over all frequencies  \n\n$$\n1=|S\\left(z_{i}\\right)|\\leq||S||_{\\infty}\n$$  \n\nThis means that we cannot uniformly attenuate disturbances over the entire frequency range if there are zeros in the RHP  \n\n# SISO Systems: Noise Rejection  \n\nSince the transfer function relating a noise input to the output is  $T=P K(1+P K)^{-1}$  , an argument for  $T$  similar to  $S$  can be made, but with the roles of poles and zeros interchanged. In this case, RHP poles of the plant restrict us from uniformly attenuating noise over the entire frequency range.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "The maximum modulus principle implies that...In other words, a stable function, which is analytic in the RHP, achieves its maximum value over the RHP when evaluated on the imaginary axis.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/eng-24223.pdf_184",
        "ID": "02bc47b9-753d-447a-ad5a-c28cf8c6c01f",
        "questions": "What is the resulting expression when summing the transfer functions $S$ and $T$ over all complex (Laplace domain) frequencies $s$?",
        "answers": "$S+T=I$",
        "context": "# 18.3: Algebraic Constraints  \n\nIn general, we would like to design feedback controllers to attenuate both noise and disturbances at the output. We have examined SISO and MIMO conditions that guarantee rejection of low frequency disturbances as well as similar conditions for the rejection of high frequency noise. However, one might wonder if we can  \n\n1. minimize the influence of either noise or disturbances over all frequencies, and/or 2. minimize the influence of both noise and disturbances at the same frequency  \n\nLet us begin this discussion by recalling the following  \n\n- $S=(I+P K)^{-1}$  is the transfer function mapping disturbances to the output\n- $T=P K(I+P K)^{-1}$  is the transfer function mapping noise to the output.  \n\nAs mentioned earlier, in a control design it is usually desirable to make both  $S$  and  $T$  small. However, because of algebraic constraints, both goals are not simultaneously achievable at the same frequency. These constraints are as follows.  \n\n# General Limitations  \n\n$S+T=I$  for all complex (Laplace domain) frequencies  $s$  . This is easily verified, since  \n\n$$\n\\begin{array}{r l}&{S+T\\,=\\left(I+P K\\right)^{-1}+P K(I+P K)^{-1}}\\\\ &{\\quad\\quad\\quad=(I+P K)(I+P K)^{-1}}\\\\ &{\\quad\\quad\\quad=I}\\end{array}\n$$  \n\nThis result implies that if  $\\sigma_{\\mathrm{max}}[S(j\\omega)]$  is small in some frequency range,  $\\sigma_{\\mathrm{max}}[T(j\\omega)]\\sim1$  . The converse is also true.  \n\nFortunately, we rarely need to make both of these functions small in the same frequency region  \n\n# Limitations Due to RHP Zeros and Poles  \n\nBefore we discuss these limitations, we quote the following fact from complex analysis  \n\nLet  $H(s)$  be a stable, causal, linear time-invariant continuous-time system. The maximum modulus principle implies that  \n\n$$\n\\sigma_{\\operatorname*{max}}[H(s)]\\leq\\operatorname*{sup}_{\\omega}\\sigma\\operatorname*{max}[H(j\\omega)]=\\|H\\|_{\\infty}\\quad\\forall s\\in\\mathrm{RHP}\n$$  \n\nIn other words, a stable function, which is analytic in the RHP, achieves its maximum value over the RHP when evaluated on the imaginary axis.  \n\nUsing this result, we can arrive at relationships between poles and zeros of the plant  $P$  located in the RHP and limitations on performance (e.g., disturbance and noise rejection)  \n\n# SISO Systems: Disturbance Rejection  \n\nConsider the stable sensitivity function  $S=(1+P K)^{-1}$  for any stabilizing controller,  $K$; then,  \n\n$$\n\\begin{array}{r l}{S\\left(z_{i}\\right)=\\left(1+P\\left(z_{i}\\right)K\\left(z_{i}\\right)\\right)^{-1}=1}&{{}{\\mathrm{~for~all~RHP~zeros~}}z_{i}{\\mathrm{~of~}}P}\\\\ {S\\left(p_{i}\\right)=\\left(1+P\\left(p_{i}\\right)K\\left(p_{i}\\right)\\right)^{-1}=0}&{{}{\\mathrm{~for~all~RHP~poles~}}p_{i}{\\mathrm{~of~}}P}\\end{array}\n$$  \n\nSince the  $\\mathcal{H}_{\\infty}$  norm bounds the gain of a system over all frequencies  \n\n$$\n1=|S\\left(z_{i}\\right)|\\leq||S||_{\\infty}\n$$  \n\nThis means that we cannot uniformly attenuate disturbances over the entire frequency range if there are zeros in the RHP  \n\n# SISO Systems: Noise Rejection  \n\nSince the transfer function relating a noise input to the output is  $T=P K(1+P K)^{-1}$  , an argument for  $T$  similar to  $S$  can be made, but with the roles of poles and zeros interchanged. In this case, RHP poles of the plant restrict us from uniformly attenuating noise over the entire frequency range.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$S+T=I$  for all complex (Laplace domain) frequencies  $s$  . This is easily verified, since",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/eng-24223.pdf_184",
        "ID": "02c336a0-64b3-491b-9929-12440dc513b6",
        "questions": "For a stable sensitivity function $S=(1+PK)^{-1}$ with a stabilizing controller $K$, what is the value of $S(z_i)$ for all RHP zeros $z_i$ of the plant $P$?",
        "answers": "$S(z_i) = 1$",
        "context": "# 18.3: Algebraic Constraints  \n\nIn general, we would like to design feedback controllers to attenuate both noise and disturbances at the output. We have examined SISO and MIMO conditions that guarantee rejection of low frequency disturbances as well as similar conditions for the rejection of high frequency noise. However, one might wonder if we can  \n\n1. minimize the influence of either noise or disturbances over all frequencies, and/or 2. minimize the influence of both noise and disturbances at the same frequency  \n\nLet us begin this discussion by recalling the following  \n\n- $S=(I+P K)^{-1}$  is the transfer function mapping disturbances to the output\n- $T=P K(I+P K)^{-1}$  is the transfer function mapping noise to the output.  \n\nAs mentioned earlier, in a control design it is usually desirable to make both  $S$  and  $T$  small. However, because of algebraic constraints, both goals are not simultaneously achievable at the same frequency. These constraints are as follows.  \n\n# General Limitations  \n\n$S+T=I$  for all complex (Laplace domain) frequencies  $s$  . This is easily verified, since  \n\n$$\n\\begin{array}{r l}&{S+T\\,=\\left(I+P K\\right)^{-1}+P K(I+P K)^{-1}}\\\\ &{\\quad\\quad\\quad=(I+P K)(I+P K)^{-1}}\\\\ &{\\quad\\quad\\quad=I}\\end{array}\n$$  \n\nThis result implies that if  $\\sigma_{\\mathrm{max}}[S(j\\omega)]$  is small in some frequency range,  $\\sigma_{\\mathrm{max}}[T(j\\omega)]\\sim1$  . The converse is also true.  \n\nFortunately, we rarely need to make both of these functions small in the same frequency region  \n\n# Limitations Due to RHP Zeros and Poles  \n\nBefore we discuss these limitations, we quote the following fact from complex analysis  \n\nLet  $H(s)$  be a stable, causal, linear time-invariant continuous-time system. The maximum modulus principle implies that  \n\n$$\n\\sigma_{\\operatorname*{max}}[H(s)]\\leq\\operatorname*{sup}_{\\omega}\\sigma\\operatorname*{max}[H(j\\omega)]=\\|H\\|_{\\infty}\\quad\\forall s\\in\\mathrm{RHP}\n$$  \n\nIn other words, a stable function, which is analytic in the RHP, achieves its maximum value over the RHP when evaluated on the imaginary axis.  \n\nUsing this result, we can arrive at relationships between poles and zeros of the plant  $P$  located in the RHP and limitations on performance (e.g., disturbance and noise rejection)  \n\n# SISO Systems: Disturbance Rejection  \n\nConsider the stable sensitivity function  $S=(1+P K)^{-1}$  for any stabilizing controller,  $K$; then,  \n\n$$\n\\begin{array}{r l}{S\\left(z_{i}\\right)=\\left(1+P\\left(z_{i}\\right)K\\left(z_{i}\\right)\\right)^{-1}=1}&{{}{\\mathrm{~for~all~RHP~zeros~}}z_{i}{\\mathrm{~of~}}P}\\\\ {S\\left(p_{i}\\right)=\\left(1+P\\left(p_{i}\\right)K\\left(p_{i}\\right)\\right)^{-1}=0}&{{}{\\mathrm{~for~all~RHP~poles~}}p_{i}{\\mathrm{~of~}}P}\\end{array}\n$$  \n\nSince the  $\\mathcal{H}_{\\infty}$  norm bounds the gain of a system over all frequencies  \n\n$$\n1=|S\\left(z_{i}\\right)|\\leq||S||_{\\infty}\n$$  \n\nThis means that we cannot uniformly attenuate disturbances over the entire frequency range if there are zeros in the RHP  \n\n# SISO Systems: Noise Rejection  \n\nSince the transfer function relating a noise input to the output is  $T=P K(1+P K)^{-1}$  , an argument for  $T$  similar to  $S$  can be made, but with the roles of poles and zeros interchanged. In this case, RHP poles of the plant restrict us from uniformly attenuating noise over the entire frequency range.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$S(z_i) = (1 + P(z_i)K(z_i))^{-1} = 1$ for all RHP zeros $z_{i}$ of $P$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/eng-24223.pdf_184",
        "ID": "02c3a5fd-79f5-478f-816c-03df3e333680",
        "questions": "Explain the implication of the Maximum Modulus Principle on a stable function $H(s)$. What does this principle tell us about the maximum value of $H(s)$?",
        "answers": "$\\sigma_{\\operatorname{max}}[H(s)] \\leq \\operatorname{sup}_{\\omega}\\sigma_{\\operatorname{max}}[H(j\\omega)] = \\|H\\|_{\\infty}$",
        "context": "# 18.3: Algebraic Constraints  \n\nIn general, we would like to design feedback controllers to attenuate both noise and disturbances at the output. We have examined SISO and MIMO conditions that guarantee rejection of low frequency disturbances as well as similar conditions for the rejection of high frequency noise. However, one might wonder if we can  \n\n1. minimize the influence of either noise or disturbances over all frequencies, and/or 2. minimize the influence of both noise and disturbances at the same frequency  \n\nLet us begin this discussion by recalling the following  \n\n- $S=(I+P K)^{-1}$  is the transfer function mapping disturbances to the output\n- $T=P K(I+P K)^{-1}$  is the transfer function mapping noise to the output.  \n\nAs mentioned earlier, in a control design it is usually desirable to make both  $S$  and  $T$  small. However, because of algebraic constraints, both goals are not simultaneously achievable at the same frequency. These constraints are as follows.  \n\n# General Limitations  \n\n$S+T=I$  for all complex (Laplace domain) frequencies  $s$  . This is easily verified, since  \n\n$$\n\\begin{array}{r l}&{S+T\\,=\\left(I+P K\\right)^{-1}+P K(I+P K)^{-1}}\\\\ &{\\quad\\quad\\quad=(I+P K)(I+P K)^{-1}}\\\\ &{\\quad\\quad\\quad=I}\\end{array}\n$$  \n\nThis result implies that if  $\\sigma_{\\mathrm{max}}[S(j\\omega)]$  is small in some frequency range,  $\\sigma_{\\mathrm{max}}[T(j\\omega)]\\sim1$  . The converse is also true.  \n\nFortunately, we rarely need to make both of these functions small in the same frequency region  \n\n# Limitations Due to RHP Zeros and Poles  \n\nBefore we discuss these limitations, we quote the following fact from complex analysis  \n\nLet  $H(s)$  be a stable, causal, linear time-invariant continuous-time system. The maximum modulus principle implies that  \n\n$$\n\\sigma_{\\operatorname*{max}}[H(s)]\\leq\\operatorname*{sup}_{\\omega}\\sigma\\operatorname*{max}[H(j\\omega)]=\\|H\\|_{\\infty}\\quad\\forall s\\in\\mathrm{RHP}\n$$  \n\nIn other words, a stable function, which is analytic in the RHP, achieves its maximum value over the RHP when evaluated on the imaginary axis.  \n\nUsing this result, we can arrive at relationships between poles and zeros of the plant  $P$  located in the RHP and limitations on performance (e.g., disturbance and noise rejection)  \n\n# SISO Systems: Disturbance Rejection  \n\nConsider the stable sensitivity function  $S=(1+P K)^{-1}$  for any stabilizing controller,  $K$; then,  \n\n$$\n\\begin{array}{r l}{S\\left(z_{i}\\right)=\\left(1+P\\left(z_{i}\\right)K\\left(z_{i}\\right)\\right)^{-1}=1}&{{}{\\mathrm{~for~all~RHP~zeros~}}z_{i}{\\mathrm{~of~}}P}\\\\ {S\\left(p_{i}\\right)=\\left(1+P\\left(p_{i}\\right)K\\left(p_{i}\\right)\\right)^{-1}=0}&{{}{\\mathrm{~for~all~RHP~poles~}}p_{i}{\\mathrm{~of~}}P}\\end{array}\n$$  \n\nSince the  $\\mathcal{H}_{\\infty}$  norm bounds the gain of a system over all frequencies  \n\n$$\n1=|S\\left(z_{i}\\right)|\\leq||S||_{\\infty}\n$$  \n\nThis means that we cannot uniformly attenuate disturbances over the entire frequency range if there are zeros in the RHP  \n\n# SISO Systems: Noise Rejection  \n\nSince the transfer function relating a noise input to the output is  $T=P K(1+P K)^{-1}$  , an argument for  $T$  similar to  $S$  can be made, but with the roles of poles and zeros interchanged. In this case, RHP poles of the plant restrict us from uniformly attenuating noise over the entire frequency range.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$\\sigma_{\\operatorname{max}}[H(s)]\\leq\\operatorname{sup}_{\\omega} \\sigma \\operatorname{max}[H(j\\omega)] = \\|H\\|_{\\infty} \\quad \forall s \\in \\mathrm{RHP}$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/(Solution_Manual)_Discrete.pdf_86",
        "ID": "02cbc304-90d0-4d0f-8fe2-45b6cc4e0460",
        "questions": "How is the sequence of elements $a_{i j}$ systematically arranged according to the given context?",
        "answers": "We do this by listing first all the elements $a_{i j}$ in which $i+j=2$ (there is only one such pair, $(1,1)$), then all the elements in which $i+j=3$ (there are only two such pairs, $(1,2)$ and $(2,1)$), and so on.",
        "context": "infinite sequence. Now we just need a systematic way to put all the elements $a_{i j}$ into a sequence. We do this by listing first all the elements $a_{i j}$ in which $i+j=2$ (there is only one such pair, $(1,1)$), then all the elements in which $i+j=3$ (there are only two such pairs, $(1,2)$ and $(2,1)$), and so on; except that we do not list any element that we have already listed. So, assuming that these elements are distinct, our list starts $a_{11}$, $a_{12}$, $a_{21}$, $a_{13}$, $a_{22}$, $a_{31}$, $a_{14}$, .... (If any of these terms duplicates a previous term, then it is simply omitted.) The result of this process will be either an infinite sequence or a finite sequence containing all the elements of the union of the sets $A_{\\imath}$. Thus, that union is countable.\n\n29. There are only a finite number of bit strings of each finite length, so we can list all the bit strings by listing first those of length 0, then those of length 1, etc. The listing might be $\\lambda, 0, 1, 00, 01, 10, 11, 000, 001, \\ldots.$ (Recall that $\\lambda$ denotes the empty string.) Actually, this is a special case of Exercise 27: the set of all bit strings is the union of a countable number of countable (actually finite) sets, namely the sets of bit strings of length $n$ for $n=0, 1, 2, \\ldots$\n\n30. A little experimentation with this function shows the pattern:\n\nf(1,1) = 1 f(2,1) = 3 f(3,1) = 6 f(4,1) = 10 f(5,1) = 15 f(6,1) = 21 f(1,2) = 2 f(2,2) = 5 f(3,2) = 9 f(4,2) = 14 f(5,2) = 20 f(6,2) = 27 f(1,3) = 4 f(2,3) = 8 f(3,3) = 13 f(4,3) = 19 f(5,3) = 26 f(1,4) = 7 f(2,4) = 12 f(3,4) = 18 f(4,4) = 25 f(1,5) = 11 f(2,5) = 17 f(3,5) = 24 f(1,6) = 16 f(2,6) = 23 f(1,7) = 22\n\nWe see by looking at the diagonals of this table that the function takes on successive values as $m+n$ increases. When $m+n=2$, $f(m,n)=1$. When $m+n=3$, $f(m,n)$ takes on the values 2 and 3. When $m+n=4$, $f(m,n)$ takes on the values 4, 5, and 6. And so on. It is clear from the formula that the range of values the $m+n$ $m+n=x$ $\\textstyle{\\frac{(x-2)(x-1)}{2}}+1$ $\\textstyle{\\frac{(x-2)(x-1)}{2}}+(x-1)$ since $m$ can assume the values $1, 2, 3, \\ldots, (x-1)$ under these conditions, and the first term in the formula is a fixed positive integer when $m+n$ is fixed. To show that this function is one-to-one and onto, we merely need to show that the range of values for $x+1$ picks up precisely where the range of values for $\\mathbf{x}$ left off, i.e., that $f(x-1,1)+1=f(1,x)$. We compute:\n\n$$\nf(x-1,1)+1={\\frac{(x-2)(x-1)}{2}}+(x-1)+1={\\frac{x^{2}-x+2}{2}}={\\frac{(x-1)x}{2}}+1=f(1,x)\n$$\n\n33. It suffices to find one-to-one functions $f:(0,1)\\to[0,1]$ and $g:[0,1]\\,\\longrightarrow\\,(0,1)$. We can obviously use the function $f(x)=x$ in the first case. For the second, we can just compress $[0, 1]$ into, say, $[\\frac{1}{3},\\,\\frac{2}{3}]$; the increasing linear function $g(x)\\,=\\,(x+1)/3$ will do that. It then follows from the Schroder-Bernstein theorem that $|(0,1)|=|[0,1]|$.\n\n34. We can follow the hint or argue as follows, which really amounts to the same thing. (See the answer key for a proof using bit strings.) Suppose there were such a one-to-one correspondence $f$ from $\\mathbf{Z}^{+}$ to the power set of $\\mathbf{Z}^{+}$ (the set of all subsets of $\\mathbf{Z}^{+}$). Thus, for each $x\\in\\mathbf{Z}^{+}$, $f(x)$ is a subset of $\\mathbf{Z}^{+}$. We will derive a contradiction by showing that $f$ is not onto; we do this by finding an element not in its range. To this end, let $A\\,=\\,\\{\\,x\\,\\mid\\,x\\,\\not\\in\\,f(x)\\,\\}\\,,$ We claim that $A$ is not in the range of $f$. If it were, then $A\\,=\\,f(x_{0})$ for some $x_{0}\\in\\mathbf{Z}^{+}$. Let us look at whether $x_{0}\\in A$ or not. On the one hand, if $x_{0}\\in A$, then by the definition of $A$ it must be true that $x_{0}\\notin f(x_{0})$, which means that $x_{0}\\notin A$; that is a contradiction. On the other hand, if $x_{0}\\notin A$, then by the definition of $A$, it must be true that $x_{0}\\in f(x_{0})$, which means that $x_{0}\\in A$, again a contradiction. Therefore, no such one-to-one correspondence exists.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "We do this by listing first all the elements $a_{i j}$ in which $i+j=2$ (there is only one such pair, $(1,1)$), then all the elements in which $i+j=3$ (there are only two such pairs, $(1,2)$ and $(2,1)$), and so on; except that we do not list any element that we have already listed.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/(Solution_Manual)_Discrete.pdf_86",
        "ID": "02cce923-4f11-4e20-af45-d25c4468f3b1",
        "questions": "What is the result of computing $f(x-1,1)+1$ in the formula provided for $f(x,y)$?",
        "answers": "${\frac{(x-1)x}{2}}+1=f(1,x)$",
        "context": "infinite sequence. Now we just need a systematic way to put all the elements $a_{i j}$ into a sequence. We do this by listing first all the elements $a_{i j}$ in which $i+j=2$ (there is only one such pair, $(1,1)$), then all the elements in which $i+j=3$ (there are only two such pairs, $(1,2)$ and $(2,1)$), and so on; except that we do not list any element that we have already listed. So, assuming that these elements are distinct, our list starts $a_{11}$, $a_{12}$, $a_{21}$, $a_{13}$, $a_{22}$, $a_{31}$, $a_{14}$, .... (If any of these terms duplicates a previous term, then it is simply omitted.) The result of this process will be either an infinite sequence or a finite sequence containing all the elements of the union of the sets $A_{\\imath}$. Thus, that union is countable.\n\n29. There are only a finite number of bit strings of each finite length, so we can list all the bit strings by listing first those of length 0, then those of length 1, etc. The listing might be $\\lambda, 0, 1, 00, 01, 10, 11, 000, 001, \\ldots.$ (Recall that $\\lambda$ denotes the empty string.) Actually, this is a special case of Exercise 27: the set of all bit strings is the union of a countable number of countable (actually finite) sets, namely the sets of bit strings of length $n$ for $n=0, 1, 2, \\ldots$\n\n30. A little experimentation with this function shows the pattern:\n\nf(1,1) = 1 f(2,1) = 3 f(3,1) = 6 f(4,1) = 10 f(5,1) = 15 f(6,1) = 21 f(1,2) = 2 f(2,2) = 5 f(3,2) = 9 f(4,2) = 14 f(5,2) = 20 f(6,2) = 27 f(1,3) = 4 f(2,3) = 8 f(3,3) = 13 f(4,3) = 19 f(5,3) = 26 f(1,4) = 7 f(2,4) = 12 f(3,4) = 18 f(4,4) = 25 f(1,5) = 11 f(2,5) = 17 f(3,5) = 24 f(1,6) = 16 f(2,6) = 23 f(1,7) = 22\n\nWe see by looking at the diagonals of this table that the function takes on successive values as $m+n$ increases. When $m+n=2$, $f(m,n)=1$. When $m+n=3$, $f(m,n)$ takes on the values 2 and 3. When $m+n=4$, $f(m,n)$ takes on the values 4, 5, and 6. And so on. It is clear from the formula that the range of values the $m+n$ $m+n=x$ $\\textstyle{\\frac{(x-2)(x-1)}{2}}+1$ $\\textstyle{\\frac{(x-2)(x-1)}{2}}+(x-1)$ since $m$ can assume the values $1, 2, 3, \\ldots, (x-1)$ under these conditions, and the first term in the formula is a fixed positive integer when $m+n$ is fixed. To show that this function is one-to-one and onto, we merely need to show that the range of values for $x+1$ picks up precisely where the range of values for $\\mathbf{x}$ left off, i.e., that $f(x-1,1)+1=f(1,x)$. We compute:\n\n$$\nf(x-1,1)+1={\\frac{(x-2)(x-1)}{2}}+(x-1)+1={\\frac{x^{2}-x+2}{2}}={\\frac{(x-1)x}{2}}+1=f(1,x)\n$$\n\n33. It suffices to find one-to-one functions $f:(0,1)\\to[0,1]$ and $g:[0,1]\\,\\longrightarrow\\,(0,1)$. We can obviously use the function $f(x)=x$ in the first case. For the second, we can just compress $[0, 1]$ into, say, $[\\frac{1}{3},\\,\\frac{2}{3}]$; the increasing linear function $g(x)\\,=\\,(x+1)/3$ will do that. It then follows from the Schroder-Bernstein theorem that $|(0,1)|=|[0,1]|$.\n\n34. We can follow the hint or argue as follows, which really amounts to the same thing. (See the answer key for a proof using bit strings.) Suppose there were such a one-to-one correspondence $f$ from $\\mathbf{Z}^{+}$ to the power set of $\\mathbf{Z}^{+}$ (the set of all subsets of $\\mathbf{Z}^{+}$). Thus, for each $x\\in\\mathbf{Z}^{+}$, $f(x)$ is a subset of $\\mathbf{Z}^{+}$. We will derive a contradiction by showing that $f$ is not onto; we do this by finding an element not in its range. To this end, let $A\\,=\\,\\{\\,x\\,\\mid\\,x\\,\\not\\in\\,f(x)\\,\\}\\,,$ We claim that $A$ is not in the range of $f$. If it were, then $A\\,=\\,f(x_{0})$ for some $x_{0}\\in\\mathbf{Z}^{+}$. Let us look at whether $x_{0}\\in A$ or not. On the one hand, if $x_{0}\\in A$, then by the definition of $A$ it must be true that $x_{0}\\notin f(x_{0})$, which means that $x_{0}\\notin A$; that is a contradiction. On the other hand, if $x_{0}\\notin A$, then by the definition of $A$, it must be true that $x_{0}\\in f(x_{0})$, which means that $x_{0}\\in A$, again a contradiction. Therefore, no such one-to-one correspondence exists.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Equation",
        "evidence_source": "equation",
        "evidence_context": "$$ f(x-1,1)+1={\frac{(x-2)(x-1)}{2}}+(x-1)+1={\frac{x^{2}-x+2}{2}}={\frac{(x-1)x}{2}}+1=f(1,x) $$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/(Solution_Manual)_Discrete.pdf_86",
        "ID": "02ce965d-352c-48a4-82b2-a2ae2b950753",
        "questions": "According to the proof using a set $A$, why does no one-to-one correspondence exist between $\\mathbf{Z}^{+}$ and the power set of $\\mathbf{Z}^{+}$?",
        "answers": "If $x_{0}\\in A$, then by the definition of $A$ it must be true that $x_{0}\\notin f(x_{0})$, which means that $x_{0}\\notin A$; that is a contradiction.",
        "context": "infinite sequence. Now we just need a systematic way to put all the elements $a_{i j}$ into a sequence. We do this by listing first all the elements $a_{i j}$ in which $i+j=2$ (there is only one such pair, $(1,1)$), then all the elements in which $i+j=3$ (there are only two such pairs, $(1,2)$ and $(2,1)$), and so on; except that we do not list any element that we have already listed. So, assuming that these elements are distinct, our list starts $a_{11}$, $a_{12}$, $a_{21}$, $a_{13}$, $a_{22}$, $a_{31}$, $a_{14}$, .... (If any of these terms duplicates a previous term, then it is simply omitted.) The result of this process will be either an infinite sequence or a finite sequence containing all the elements of the union of the sets $A_{\\imath}$. Thus, that union is countable.\n\n29. There are only a finite number of bit strings of each finite length, so we can list all the bit strings by listing first those of length 0, then those of length 1, etc. The listing might be $\\lambda, 0, 1, 00, 01, 10, 11, 000, 001, \\ldots.$ (Recall that $\\lambda$ denotes the empty string.) Actually, this is a special case of Exercise 27: the set of all bit strings is the union of a countable number of countable (actually finite) sets, namely the sets of bit strings of length $n$ for $n=0, 1, 2, \\ldots$\n\n30. A little experimentation with this function shows the pattern:\n\nf(1,1) = 1 f(2,1) = 3 f(3,1) = 6 f(4,1) = 10 f(5,1) = 15 f(6,1) = 21 f(1,2) = 2 f(2,2) = 5 f(3,2) = 9 f(4,2) = 14 f(5,2) = 20 f(6,2) = 27 f(1,3) = 4 f(2,3) = 8 f(3,3) = 13 f(4,3) = 19 f(5,3) = 26 f(1,4) = 7 f(2,4) = 12 f(3,4) = 18 f(4,4) = 25 f(1,5) = 11 f(2,5) = 17 f(3,5) = 24 f(1,6) = 16 f(2,6) = 23 f(1,7) = 22\n\nWe see by looking at the diagonals of this table that the function takes on successive values as $m+n$ increases. When $m+n=2$, $f(m,n)=1$. When $m+n=3$, $f(m,n)$ takes on the values 2 and 3. When $m+n=4$, $f(m,n)$ takes on the values 4, 5, and 6. And so on. It is clear from the formula that the range of values the $m+n$ $m+n=x$ $\\textstyle{\\frac{(x-2)(x-1)}{2}}+1$ $\\textstyle{\\frac{(x-2)(x-1)}{2}}+(x-1)$ since $m$ can assume the values $1, 2, 3, \\ldots, (x-1)$ under these conditions, and the first term in the formula is a fixed positive integer when $m+n$ is fixed. To show that this function is one-to-one and onto, we merely need to show that the range of values for $x+1$ picks up precisely where the range of values for $\\mathbf{x}$ left off, i.e., that $f(x-1,1)+1=f(1,x)$. We compute:\n\n$$\nf(x-1,1)+1={\\frac{(x-2)(x-1)}{2}}+(x-1)+1={\\frac{x^{2}-x+2}{2}}={\\frac{(x-1)x}{2}}+1=f(1,x)\n$$\n\n33. It suffices to find one-to-one functions $f:(0,1)\\to[0,1]$ and $g:[0,1]\\,\\longrightarrow\\,(0,1)$. We can obviously use the function $f(x)=x$ in the first case. For the second, we can just compress $[0, 1]$ into, say, $[\\frac{1}{3},\\,\\frac{2}{3}]$; the increasing linear function $g(x)\\,=\\,(x+1)/3$ will do that. It then follows from the Schroder-Bernstein theorem that $|(0,1)|=|[0,1]|$.\n\n34. We can follow the hint or argue as follows, which really amounts to the same thing. (See the answer key for a proof using bit strings.) Suppose there were such a one-to-one correspondence $f$ from $\\mathbf{Z}^{+}$ to the power set of $\\mathbf{Z}^{+}$ (the set of all subsets of $\\mathbf{Z}^{+}$). Thus, for each $x\\in\\mathbf{Z}^{+}$, $f(x)$ is a subset of $\\mathbf{Z}^{+}$. We will derive a contradiction by showing that $f$ is not onto; we do this by finding an element not in its range. To this end, let $A\\,=\\,\\{\\,x\\,\\mid\\,x\\,\\not\\in\\,f(x)\\,\\}\\,,$ We claim that $A$ is not in the range of $f$. If it were, then $A\\,=\\,f(x_{0})$ for some $x_{0}\\in\\mathbf{Z}^{+}$. Let us look at whether $x_{0}\\in A$ or not. On the one hand, if $x_{0}\\in A$, then by the definition of $A$ it must be true that $x_{0}\\notin f(x_{0})$, which means that $x_{0}\\notin A$; that is a contradiction. On the other hand, if $x_{0}\\notin A$, then by the definition of $A$, it must be true that $x_{0}\\in f(x_{0})$, which means that $x_{0}\\in A$, again a contradiction. Therefore, no such one-to-one correspondence exists.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Text Explanation",
        "evidence_source": "text",
        "evidence_context": "On the one hand, if $x_{0}\\in A$, then by the definition of $A$ it must be true that $x_{0}\\notin f(x_{0})$, which means that $x_{0}\\notin A$; that is a contradiction.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/(Solution_Manual)_Discrete.pdf_86",
        "ID": "02e1030c-791d-469f-913e-8c9792a75c02",
        "questions": "What is the value of f(2, 3) based on the given function f(m, n)?",
        "answers": "8",
        "context": "infinite sequence. Now we just need a systematic way to put all the elements $a_{i j}$ into a sequence. We do this by listing first all the elements $a_{i j}$ in which $i+j=2$ (there is only one such pair, $(1,1)$), then all the elements in which $i+j=3$ (there are only two such pairs, $(1,2)$ and $(2,1)$), and so on; except that we do not list any element that we have already listed. So, assuming that these elements are distinct, our list starts $a_{11}$, $a_{12}$, $a_{21}$, $a_{13}$, $a_{22}$, $a_{31}$, $a_{14}$, .... (If any of these terms duplicates a previous term, then it is simply omitted.) The result of this process will be either an infinite sequence or a finite sequence containing all the elements of the union of the sets $A_{\\imath}$. Thus, that union is countable.\n\n29. There are only a finite number of bit strings of each finite length, so we can list all the bit strings by listing first those of length 0, then those of length 1, etc. The listing might be $\\lambda, 0, 1, 00, 01, 10, 11, 000, 001, \\ldots.$ (Recall that $\\lambda$ denotes the empty string.) Actually, this is a special case of Exercise 27: the set of all bit strings is the union of a countable number of countable (actually finite) sets, namely the sets of bit strings of length $n$ for $n=0, 1, 2, \\ldots$\n\n30. A little experimentation with this function shows the pattern:\n\nf(1,1) = 1 f(2,1) = 3 f(3,1) = 6 f(4,1) = 10 f(5,1) = 15 f(6,1) = 21 f(1,2) = 2 f(2,2) = 5 f(3,2) = 9 f(4,2) = 14 f(5,2) = 20 f(6,2) = 27 f(1,3) = 4 f(2,3) = 8 f(3,3) = 13 f(4,3) = 19 f(5,3) = 26 f(1,4) = 7 f(2,4) = 12 f(3,4) = 18 f(4,4) = 25 f(1,5) = 11 f(2,5) = 17 f(3,5) = 24 f(1,6) = 16 f(2,6) = 23 f(1,7) = 22\n\nWe see by looking at the diagonals of this table that the function takes on successive values as $m+n$ increases. When $m+n=2$, $f(m,n)=1$. When $m+n=3$, $f(m,n)$ takes on the values 2 and 3. When $m+n=4$, $f(m,n)$ takes on the values 4, 5, and 6. And so on. It is clear from the formula that the range of values the $m+n$ $m+n=x$ $\\textstyle{\\frac{(x-2)(x-1)}{2}}+1$ $\\textstyle{\\frac{(x-2)(x-1)}{2}}+(x-1)$ since $m$ can assume the values $1, 2, 3, \\ldots, (x-1)$ under these conditions, and the first term in the formula is a fixed positive integer when $m+n$ is fixed. To show that this function is one-to-one and onto, we merely need to show that the range of values for $x+1$ picks up precisely where the range of values for $\\mathbf{x}$ left off, i.e., that $f(x-1,1)+1=f(1,x)$. We compute:\n\n$$\nf(x-1,1)+1={\\frac{(x-2)(x-1)}{2}}+(x-1)+1={\\frac{x^{2}-x+2}{2}}={\\frac{(x-1)x}{2}}+1=f(1,x)\n$$\n\n33. It suffices to find one-to-one functions $f:(0,1)\\to[0,1]$ and $g:[0,1]\\,\\longrightarrow\\,(0,1)$. We can obviously use the function $f(x)=x$ in the first case. For the second, we can just compress $[0, 1]$ into, say, $[\\frac{1}{3},\\,\\frac{2}{3}]$; the increasing linear function $g(x)\\,=\\,(x+1)/3$ will do that. It then follows from the Schroder-Bernstein theorem that $|(0,1)|=|[0,1]|$.\n\n34. We can follow the hint or argue as follows, which really amounts to the same thing. (See the answer key for a proof using bit strings.) Suppose there were such a one-to-one correspondence $f$ from $\\mathbf{Z}^{+}$ to the power set of $\\mathbf{Z}^{+}$ (the set of all subsets of $\\mathbf{Z}^{+}$). Thus, for each $x\\in\\mathbf{Z}^{+}$, $f(x)$ is a subset of $\\mathbf{Z}^{+}$. We will derive a contradiction by showing that $f$ is not onto; we do this by finding an element not in its range. To this end, let $A\\,=\\,\\{\\,x\\,\\mid\\,x\\,\\not\\in\\,f(x)\\,\\}\\,,$ We claim that $A$ is not in the range of $f$. If it were, then $A\\,=\\,f(x_{0})$ for some $x_{0}\\in\\mathbf{Z}^{+}$. Let us look at whether $x_{0}\\in A$ or not. On the one hand, if $x_{0}\\in A$, then by the definition of $A$ it must be true that $x_{0}\\notin f(x_{0})$, which means that $x_{0}\\notin A$; that is a contradiction. On the other hand, if $x_{0}\\notin A$, then by the definition of $A$, it must be true that $x_{0}\\in f(x_{0})$, which means that $x_{0}\\in A$, again a contradiction. Therefore, no such one-to-one correspondence exists.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Numeric",
        "evidence_source": "equation",
        "evidence_context": "f(2,3) = 8",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/(Solution_Manual)_Discrete.pdf_86",
        "ID": "02f6ef8e-f8a8-470e-80fc-4c999150b640",
        "questions": "According to the pattern described, what is the resulting value when f(x-1, 1) is increased by 1?",
        "answers": "f(x-1, 1) + 1 = f(1, x)",
        "context": "infinite sequence. Now we just need a systematic way to put all the elements $a_{i j}$ into a sequence. We do this by listing first all the elements $a_{i j}$ in which $i+j=2$ (there is only one such pair, $(1,1)$), then all the elements in which $i+j=3$ (there are only two such pairs, $(1,2)$ and $(2,1)$), and so on; except that we do not list any element that we have already listed. So, assuming that these elements are distinct, our list starts $a_{11}$, $a_{12}$, $a_{21}$, $a_{13}$, $a_{22}$, $a_{31}$, $a_{14}$, .... (If any of these terms duplicates a previous term, then it is simply omitted.) The result of this process will be either an infinite sequence or a finite sequence containing all the elements of the union of the sets $A_{\\imath}$. Thus, that union is countable.\n\n29. There are only a finite number of bit strings of each finite length, so we can list all the bit strings by listing first those of length 0, then those of length 1, etc. The listing might be $\\lambda, 0, 1, 00, 01, 10, 11, 000, 001, \\ldots.$ (Recall that $\\lambda$ denotes the empty string.) Actually, this is a special case of Exercise 27: the set of all bit strings is the union of a countable number of countable (actually finite) sets, namely the sets of bit strings of length $n$ for $n=0, 1, 2, \\ldots$\n\n30. A little experimentation with this function shows the pattern:\n\nf(1,1) = 1 f(2,1) = 3 f(3,1) = 6 f(4,1) = 10 f(5,1) = 15 f(6,1) = 21 f(1,2) = 2 f(2,2) = 5 f(3,2) = 9 f(4,2) = 14 f(5,2) = 20 f(6,2) = 27 f(1,3) = 4 f(2,3) = 8 f(3,3) = 13 f(4,3) = 19 f(5,3) = 26 f(1,4) = 7 f(2,4) = 12 f(3,4) = 18 f(4,4) = 25 f(1,5) = 11 f(2,5) = 17 f(3,5) = 24 f(1,6) = 16 f(2,6) = 23 f(1,7) = 22\n\nWe see by looking at the diagonals of this table that the function takes on successive values as $m+n$ increases. When $m+n=2$, $f(m,n)=1$. When $m+n=3$, $f(m,n)$ takes on the values 2 and 3. When $m+n=4$, $f(m,n)$ takes on the values 4, 5, and 6. And so on. It is clear from the formula that the range of values the $m+n$ $m+n=x$ $\\textstyle{\\frac{(x-2)(x-1)}{2}}+1$ $\\textstyle{\\frac{(x-2)(x-1)}{2}}+(x-1)$ since $m$ can assume the values $1, 2, 3, \\ldots, (x-1)$ under these conditions, and the first term in the formula is a fixed positive integer when $m+n$ is fixed. To show that this function is one-to-one and onto, we merely need to show that the range of values for $x+1$ picks up precisely where the range of values for $\\mathbf{x}$ left off, i.e., that $f(x-1,1)+1=f(1,x)$. We compute:\n\n$$\nf(x-1,1)+1={\\frac{(x-2)(x-1)}{2}}+(x-1)+1={\\frac{x^{2}-x+2}{2}}={\\frac{(x-1)x}{2}}+1=f(1,x)\n$$\n\n33. It suffices to find one-to-one functions $f:(0,1)\\to[0,1]$ and $g:[0,1]\\,\\longrightarrow\\,(0,1)$. We can obviously use the function $f(x)=x$ in the first case. For the second, we can just compress $[0, 1]$ into, say, $[\\frac{1}{3},\\,\\frac{2}{3}]$; the increasing linear function $g(x)\\,=\\,(x+1)/3$ will do that. It then follows from the Schroder-Bernstein theorem that $|(0,1)|=|[0,1]|$.\n\n34. We can follow the hint or argue as follows, which really amounts to the same thing. (See the answer key for a proof using bit strings.) Suppose there were such a one-to-one correspondence $f$ from $\\mathbf{Z}^{+}$ to the power set of $\\mathbf{Z}^{+}$ (the set of all subsets of $\\mathbf{Z}^{+}$). Thus, for each $x\\in\\mathbf{Z}^{+}$, $f(x)$ is a subset of $\\mathbf{Z}^{+}$. We will derive a contradiction by showing that $f$ is not onto; we do this by finding an element not in its range. To this end, let $A\\,=\\,\\{\\,x\\,\\mid\\,x\\,\\not\\in\\,f(x)\\,\\}\\,,$ We claim that $A$ is not in the range of $f$. If it were, then $A\\,=\\,f(x_{0})$ for some $x_{0}\\in\\mathbf{Z}^{+}$. Let us look at whether $x_{0}\\in A$ or not. On the one hand, if $x_{0}\\in A$, then by the definition of $A$ it must be true that $x_{0}\\notin f(x_{0})$, which means that $x_{0}\\notin A$; that is a contradiction. On the other hand, if $x_{0}\\notin A$, then by the definition of $A$, it must be true that $x_{0}\\in f(x_{0})$, which means that $x_{0}\\in A$, again a contradiction. Therefore, no such one-to-one correspondence exists.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "We compute: $$f(x-1,1)+1={\\frac{(x-2)(x-1)}{2}}+(x-1)+1={\\frac{x^{2}-x+2}{2}}={\\frac{(x-1)x}{2}}+1=f(1,x)$$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/(Solution_Manual)_Discrete.pdf_86",
        "ID": "0305ba49-8a8c-450c-8290-f61f1616b10d",
        "questions": "When the sum of m and n is 5, what are the values of f(m, n)?",
        "answers": "f(m, n) = 11, 12, or 13",
        "context": "infinite sequence. Now we just need a systematic way to put all the elements $a_{i j}$ into a sequence. We do this by listing first all the elements $a_{i j}$ in which $i+j=2$ (there is only one such pair, $(1,1)$), then all the elements in which $i+j=3$ (there are only two such pairs, $(1,2)$ and $(2,1)$), and so on; except that we do not list any element that we have already listed. So, assuming that these elements are distinct, our list starts $a_{11}$, $a_{12}$, $a_{21}$, $a_{13}$, $a_{22}$, $a_{31}$, $a_{14}$, .... (If any of these terms duplicates a previous term, then it is simply omitted.) The result of this process will be either an infinite sequence or a finite sequence containing all the elements of the union of the sets $A_{\\imath}$. Thus, that union is countable.\n\n29. There are only a finite number of bit strings of each finite length, so we can list all the bit strings by listing first those of length 0, then those of length 1, etc. The listing might be $\\lambda, 0, 1, 00, 01, 10, 11, 000, 001, \\ldots.$ (Recall that $\\lambda$ denotes the empty string.) Actually, this is a special case of Exercise 27: the set of all bit strings is the union of a countable number of countable (actually finite) sets, namely the sets of bit strings of length $n$ for $n=0, 1, 2, \\ldots$\n\n30. A little experimentation with this function shows the pattern:\n\nf(1,1) = 1 f(2,1) = 3 f(3,1) = 6 f(4,1) = 10 f(5,1) = 15 f(6,1) = 21 f(1,2) = 2 f(2,2) = 5 f(3,2) = 9 f(4,2) = 14 f(5,2) = 20 f(6,2) = 27 f(1,3) = 4 f(2,3) = 8 f(3,3) = 13 f(4,3) = 19 f(5,3) = 26 f(1,4) = 7 f(2,4) = 12 f(3,4) = 18 f(4,4) = 25 f(1,5) = 11 f(2,5) = 17 f(3,5) = 24 f(1,6) = 16 f(2,6) = 23 f(1,7) = 22\n\nWe see by looking at the diagonals of this table that the function takes on successive values as $m+n$ increases. When $m+n=2$, $f(m,n)=1$. When $m+n=3$, $f(m,n)$ takes on the values 2 and 3. When $m+n=4$, $f(m,n)$ takes on the values 4, 5, and 6. And so on. It is clear from the formula that the range of values the $m+n$ $m+n=x$ $\\textstyle{\\frac{(x-2)(x-1)}{2}}+1$ $\\textstyle{\\frac{(x-2)(x-1)}{2}}+(x-1)$ since $m$ can assume the values $1, 2, 3, \\ldots, (x-1)$ under these conditions, and the first term in the formula is a fixed positive integer when $m+n$ is fixed. To show that this function is one-to-one and onto, we merely need to show that the range of values for $x+1$ picks up precisely where the range of values for $\\mathbf{x}$ left off, i.e., that $f(x-1,1)+1=f(1,x)$. We compute:\n\n$$\nf(x-1,1)+1={\\frac{(x-2)(x-1)}{2}}+(x-1)+1={\\frac{x^{2}-x+2}{2}}={\\frac{(x-1)x}{2}}+1=f(1,x)\n$$\n\n33. It suffices to find one-to-one functions $f:(0,1)\\to[0,1]$ and $g:[0,1]\\,\\longrightarrow\\,(0,1)$. We can obviously use the function $f(x)=x$ in the first case. For the second, we can just compress $[0, 1]$ into, say, $[\\frac{1}{3},\\,\\frac{2}{3}]$; the increasing linear function $g(x)\\,=\\,(x+1)/3$ will do that. It then follows from the Schroder-Bernstein theorem that $|(0,1)|=|[0,1]|$.\n\n34. We can follow the hint or argue as follows, which really amounts to the same thing. (See the answer key for a proof using bit strings.) Suppose there were such a one-to-one correspondence $f$ from $\\mathbf{Z}^{+}$ to the power set of $\\mathbf{Z}^{+}$ (the set of all subsets of $\\mathbf{Z}^{+}$). Thus, for each $x\\in\\mathbf{Z}^{+}$, $f(x)$ is a subset of $\\mathbf{Z}^{+}$. We will derive a contradiction by showing that $f$ is not onto; we do this by finding an element not in its range. To this end, let $A\\,=\\,\\{\\,x\\,\\mid\\,x\\,\\not\\in\\,f(x)\\,\\}\\,,$ We claim that $A$ is not in the range of $f$. If it were, then $A\\,=\\,f(x_{0})$ for some $x_{0}\\in\\mathbf{Z}^{+}$. Let us look at whether $x_{0}\\in A$ or not. On the one hand, if $x_{0}\\in A$, then by the definition of $A$ it must be true that $x_{0}\\notin f(x_{0})$, which means that $x_{0}\\notin A$; that is a contradiction. On the other hand, if $x_{0}\\notin A$, then by the definition of $A$, it must be true that $x_{0}\\in f(x_{0})$, which means that $x_{0}\\in A$, again a contradiction. Therefore, no such one-to-one correspondence exists.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "When $m+n=4$, $f(m,n)$ takes on the values 4, 5, and 6. And so on. It is clear from the formula that the range of values the $m+n$ $m+n=x$ $\\textstyle{\\frac{(x-2)(x-1)}{2}}+1$ $\\textstyle{\\frac{(x-2)(x-1)}{2}}+(x-1)$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/3.cake-cutting.pdf_7",
        "ID": "0330dbc8-ea7a-4b57-beb4-0c32ade8c244",
        "questions": "What is performed if R' is not empty in the CutMaxInterval(R, H, D_R) procedure?",
        "answers": "Perform shrinking of all X_1, X_2, ..., X_K.",
        "context": "Procedure $\\operatorname{CutCake}(P, D, D_{P})$\n\n- Find all the maximal intervals of minimum density $\\rho_{\\mathrm{min}}$ in the cake-cutting problem with cake $D$, players $P$, and solid valuation intervals $\\mathcal{D}_{P}$. \n- Let $H_{1}=\\left[h_{1}^{\\prime},h_{1}^{\\prime\\prime}\\right)$, $H_{2}=\\left[h_{2}^{\\prime},h_{2}^{\\prime\\prime}\\right)$, ..., $H_{L}=\\left[h_{L}^{\\prime},h_{L}^{\\prime\\prime}\\right)$ be all the maximal intervals of minimum density $\\rho_{\\mathrm{min}}$. $H_{1}, H_{2}, ..., H_{L}$ are mutually disjoint by Corollary 5. \n- For $\\ell=1$ to $L$ do, \n  - cut cake $D$ at both endpoints $h_{\\ell}^{\\prime}, h_{\\ell}^{\\prime\\prime}$ of $H_{\\ell}$;\n  - $R_{\\ell}=\\left\\{k\\in P \\mid D_{k}\\subseteq H_{\\ell}, D_{k}\\in\\mathcal{D}_{P}\\right\\};\\;\\mathcal{D}_{R_{\\ell}}=\\left(D_{k}\\in\\mathcal{D}_{P}: k\\in R_{\\ell}\\right)$;\n  - $\\operatorname{CutMaxInterval}(R_{\\ell}, H_{\\ell}, D_{R_{\\ell}})$. \n- $P^{\\prime}=P; D^{\\prime}=D$; for $\\ell=1$ to $L$ do, $P^{\\prime}=P^{\\prime}\\setminus R_{\\ell}; D^{\\prime}=D^{\\prime}\\setminus H_{\\ell}$. \n- If $P^{\\prime}\\neq\\emptyset$ then // $P^{\\prime}=P\\setminus\\sum_{\\ell=1}^{L}R_{\\ell}$ and $D^{\\prime}=D\\setminus\\sum_{\\ell=1}^{L}H_{\\ell}$. \n  - $\\mathcal{D}_{P^{\\prime}}^{\\prime}=\\emptyset$;\n  - For each $D_{k}\\in\\mathcal{D}_{P}$ with $k\\in P^{\\prime}$ do $D_{k}^{\\prime}=D_{k}\\setminus\\sum_{\\ell=1}^{L}H_{\\ell}; \\mathcal{D}_{P^{\\prime}}^{\\prime}=\\mathcal{D}_{P^{\\prime}}^{\\prime}+\\{D_{k}^{\\prime}\\}$;\n  - Perform shrinking of all $H_{1}, H_{2}, ..., H_{L}$. \n  - Let $D^{(S)}$, $D_{k}^{(S)}\\in\\mathcal{D}_{P^{\\prime}}^{(S)}$, and $\\mathcal{D}_{P^{\\prime}}^{(S)}$ be obtained from $D^{\\prime}$, $D_{k}^{\\prime}\\in\\mathcal{D}_{P^{\\prime}}^{\\prime}$, and $\\mathcal{D}_{P^{\\prime}}^{\\prime}$ by shrinking of all $H_{1}, H_{2}, ..., H_{L}$, respectively; \n  - $\\operatorname{CutCake}(P^{\\prime}, D^{(\\bar{S})}, \\mathcal{D}_{P^{\\prime}}^{(S)})$; Perform inverse shrinking of all $H_{1}, H_{2}, ..., H_{L}$;\n\nNote that, If $P^{\\prime}\\neq\\emptyset$ after the deletion of $H_{1}, H_{2}, ..., H_{L}$ and $\\operatorname{CutCake}(P^{\\prime}, D^{(S)}, \\mathcal{D}_{P^{\\prime}}^{(S)})$ is recursively called, then the minimum density $\\rho_{\\mathrm{min}}^{\\prime}$ in $\\operatorname{CutCake}(P^{\\prime}, D^{(S)}, D_{P^{\\prime}}^{(S)})$ satisfies $\\rho_{\\mathrm{min}}^{\\prime}>\\rho_{\\mathrm{min}}$ by Lemma 6. Next, we give a detailed description of $\\operatorname{CutMaxInterval}\\left(R, H, D_{R}\\right)$ based on Lemma 7 and Procedure $\\operatorname{CutMinInterval}(S, X, T_{S})$.\n\n# Procedure $\\operatorname{CutMaxInterval}(R, H, D_{R})$\n\n- Let $X_{1}=\\left[x_{1}^{\\prime}, x_{1}^{\\prime\\prime}\\right)$, $X_{2}=\\left[x_{2}^{\\prime}, x_{2}^{\\prime\\prime}\\right)$, ..., $X_{K}=\\left[x_{K}^{\\prime}, x_{K}^{\\prime\\prime}\\right]$ be all the minimal intervals of minimum density $\\rho_{\\mathrm{min}}$ in $H$. // $X_{1}, X_{2}, ..., X_{K}$ are mutually disjoint by Corollary 5.\n- For $k=1$ to $K$ do \n  - cut cake $H$ at both endpoints $x_{k}^{\\prime}, x_{k}^{\\prime\\prime}$ of $X_{k}$;\n  - $S_{k}=\\{i\\in R \\mid D_{i}\\subseteq X_{k}, D_{i}\\in\\mathcal{D}_{R}\\}$; $\\mathcal{D}_{S_{k}}=\\left(D_{i}\\in\\mathcal{D}_{R}: i\\in S_{k}\\right)$;\n  - $\\operatorname{CutMinInterval}(S_{k}, X_{k}, D_{S_{k}})$;\n- $R^{\\prime}=R; H^{\\prime}=H$; for $k=1$ to $K$ do $R^{\\prime}=R^{\\prime}\\setminus S_{k}; H^{\\prime}=H^{\\prime}\\setminus X_{k};$;\n- If $R^{\\prime}\\neq\\emptyset$ then // $R^{\\prime}=R\\setminus\\sum_{k=1}^{K}S_{k}$, $H^{\\prime}=H\\setminus\\sum_{k=1}^{K}X_{k}$\n  - $\\mathcal{D}_{R^{\\prime}}^{\\prime}=\\emptyset$;\n  - For each $D_{i}\\in\\mathcal{D}_{R}$ with $i\\in R^{\\prime}$ do, $D_{i}^{\\prime}=D_{i}\\setminus\\sum_{k=1}^{K}X_{k}$, $\\mathcal{D}_{R^{\\prime}}^{\\prime}=\\mathcal{D}_{R^{\\prime}}^{\\prime}+\\{D_{i}^{\\prime}\\}$;\n  - Perform shrinking of all $X_{1}, X_{2}, ..., X_{K}$;\n  - Let $H^{(S)}$, $D_{i}^{(S)}\\in\\mathcal{D}_{R^{\\prime}}^{(S)}$ and $\\mathcal{D}_{R^{\\prime}}^{(S)}$ be obtained from $H^{\\prime}$, $D_{i}^{\\prime}\\in\\mathcal{D}_{R^{\\prime}}^{\\prime}$ and $D_{R^{\\prime}}^{\\prime}$ by shrinking of all $X_{1}, X_{2}, ..., X_{K}$, respectively;\n  - $\\operatorname{CutMaxIntensity}(R^{\\prime}, H^{(S)}, \\mathcal{D}_{R^{\\prime}}^{(S)})$; Perform inverse shrinking of all $X_{1}, X_{2}, ..., X_{K}$.\n\nNote that, if $R^{\\prime}\\neq\\emptyset$, $X_{1}, X_{2}, ..., X_{K}$ and $\\operatorname{CutMaxInterval}(R^{\\prime}, H^{(S)}, \\mathcal{D}_{R^{\\prime}}^{(S)})$ is recursively called, then the minimum density $\\rho_{\\mathrm{min}}^{\\prime}$ in $\\operatorname{CutMaxInterval}(R^{\\prime}, H^{(S)}, \\mathcal{D}_{R^{\\prime}}^{(S)})$ satisfies $\\rho_{\\mathrm{min}}^{\\prime}=\\rho_{\\mathrm{min}}$ by Lemma 7. As mentioned before, Procedure $\\operatorname{CutMinInterval}\\mathrm{l}(S, X, \\mathcal{D}_{S})$ is the core method for solving the cake-cutting problem where cake $X$ is a minimal interval of minimum density in maximal interval $H$ of minimum density $\\rho_{\\mathrm{min}}$, players $S=R(X)=\\{i\\in R \\mid D_{i}\\in\\mathcal{D}_{R}, D_{i}\\subseteq X\\}$ and solid valuation intervals $\\mathcal{D}_{S}=\\mathcal{D}_{R(X)}=(D_{i}\\in\\mathcal{D}_{R}: i\\in S)$.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "- If R^{\\prime}\neq\\emptyset$ then // $R^{\\prime}=R\\setminus\\sum_{k=1}^{K}S_{k}$, $H^{\\prime}=H\\setminus\\sum_{k=1}^{K}X_{k}$\\n - $\\mathcal{D}_{R^{\\prime}}^{\\prime}=\\emptyset$;\\n - For each $D_{i}\\in\\mathcal{D}_{R}$ with $i\\in R^{\\prime}$ do, $D_{i}^{\\prime}=D_{i}\\setminus\\sum_{k=1}^{K}X_{k}$, $\\mathcal{D}_{R^{\\prime}}^{\\prime}=\\mathcal{D}_{R^{\\prime}}^{\\prime}+\\{D_{i}^{\\prime}\\}$;\\n - Perform shrinking of all $X_{1}, X_{2}, ..., $X_{K}$;\\n - Let $H^{(S)}$, $D_{i}^{(S)}\\in\\mathcal{D}_{R^{\\prime}}^{(S)}$ and $\\mathcal{D}_{R^{\\prime}}^{(S)}$ be obtained from $H^{\\prime}$, $D_{i}^{\\prime}\\in\\mathcal{D}_{R^{\\prime}}^{\\prime}$ and $D_{R^{\\prime}}^{\\prime}$ by shrinking of all $X_{1}, X_{2}, ..., $X_{K}$, respectively;\\n - $\\operatorname{CutMaxIntensity}(R^{\\prime}, H^{(S)}, \\mathcal{D}_{R^{\\prime}}^{(S)})$; Perform inverse shrinking of all $X_{1}, X_{2}, ..., $X_{K}$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/3.cake-cutting.pdf_7",
        "ID": "0339d23b-763b-49ea-b9be-64e1b08d0f95",
        "questions": "According to the cut cake algorithm, what happens to the set of players P' after the deletion of all H_1, H_2, ..., H_L?",
        "answers": "P^{\\prime}\\setminus\\sum_{\\ell=1}^{L}R_{\\ell}",
        "context": "Procedure $\\operatorname{CutCake}(P, D, D_{P})$\n\n- Find all the maximal intervals of minimum density $\\rho_{\\mathrm{min}}$ in the cake-cutting problem with cake $D$, players $P$, and solid valuation intervals $\\mathcal{D}_{P}$. \n- Let $H_{1}=\\left[h_{1}^{\\prime},h_{1}^{\\prime\\prime}\\right)$, $H_{2}=\\left[h_{2}^{\\prime},h_{2}^{\\prime\\prime}\\right)$, ..., $H_{L}=\\left[h_{L}^{\\prime},h_{L}^{\\prime\\prime}\\right)$ be all the maximal intervals of minimum density $\\rho_{\\mathrm{min}}$. $H_{1}, H_{2}, ..., H_{L}$ are mutually disjoint by Corollary 5. \n- For $\\ell=1$ to $L$ do, \n  - cut cake $D$ at both endpoints $h_{\\ell}^{\\prime}, h_{\\ell}^{\\prime\\prime}$ of $H_{\\ell}$;\n  - $R_{\\ell}=\\left\\{k\\in P \\mid D_{k}\\subseteq H_{\\ell}, D_{k}\\in\\mathcal{D}_{P}\\right\\};\\;\\mathcal{D}_{R_{\\ell}}=\\left(D_{k}\\in\\mathcal{D}_{P}: k\\in R_{\\ell}\\right)$;\n  - $\\operatorname{CutMaxInterval}(R_{\\ell}, H_{\\ell}, D_{R_{\\ell}})$. \n- $P^{\\prime}=P; D^{\\prime}=D$; for $\\ell=1$ to $L$ do, $P^{\\prime}=P^{\\prime}\\setminus R_{\\ell}; D^{\\prime}=D^{\\prime}\\setminus H_{\\ell}$. \n- If $P^{\\prime}\\neq\\emptyset$ then // $P^{\\prime}=P\\setminus\\sum_{\\ell=1}^{L}R_{\\ell}$ and $D^{\\prime}=D\\setminus\\sum_{\\ell=1}^{L}H_{\\ell}$. \n  - $\\mathcal{D}_{P^{\\prime}}^{\\prime}=\\emptyset$;\n  - For each $D_{k}\\in\\mathcal{D}_{P}$ with $k\\in P^{\\prime}$ do $D_{k}^{\\prime}=D_{k}\\setminus\\sum_{\\ell=1}^{L}H_{\\ell}; \\mathcal{D}_{P^{\\prime}}^{\\prime}=\\mathcal{D}_{P^{\\prime}}^{\\prime}+\\{D_{k}^{\\prime}\\}$;\n  - Perform shrinking of all $H_{1}, H_{2}, ..., H_{L}$. \n  - Let $D^{(S)}$, $D_{k}^{(S)}\\in\\mathcal{D}_{P^{\\prime}}^{(S)}$, and $\\mathcal{D}_{P^{\\prime}}^{(S)}$ be obtained from $D^{\\prime}$, $D_{k}^{\\prime}\\in\\mathcal{D}_{P^{\\prime}}^{\\prime}$, and $\\mathcal{D}_{P^{\\prime}}^{\\prime}$ by shrinking of all $H_{1}, H_{2}, ..., H_{L}$, respectively; \n  - $\\operatorname{CutCake}(P^{\\prime}, D^{(\\bar{S})}, \\mathcal{D}_{P^{\\prime}}^{(S)})$; Perform inverse shrinking of all $H_{1}, H_{2}, ..., H_{L}$;\n\nNote that, If $P^{\\prime}\\neq\\emptyset$ after the deletion of $H_{1}, H_{2}, ..., H_{L}$ and $\\operatorname{CutCake}(P^{\\prime}, D^{(S)}, \\mathcal{D}_{P^{\\prime}}^{(S)})$ is recursively called, then the minimum density $\\rho_{\\mathrm{min}}^{\\prime}$ in $\\operatorname{CutCake}(P^{\\prime}, D^{(S)}, D_{P^{\\prime}}^{(S)})$ satisfies $\\rho_{\\mathrm{min}}^{\\prime}>\\rho_{\\mathrm{min}}$ by Lemma 6. Next, we give a detailed description of $\\operatorname{CutMaxInterval}\\left(R, H, D_{R}\\right)$ based on Lemma 7 and Procedure $\\operatorname{CutMinInterval}(S, X, T_{S})$.\n\n# Procedure $\\operatorname{CutMaxInterval}(R, H, D_{R})$\n\n- Let $X_{1}=\\left[x_{1}^{\\prime}, x_{1}^{\\prime\\prime}\\right)$, $X_{2}=\\left[x_{2}^{\\prime}, x_{2}^{\\prime\\prime}\\right)$, ..., $X_{K}=\\left[x_{K}^{\\prime}, x_{K}^{\\prime\\prime}\\right]$ be all the minimal intervals of minimum density $\\rho_{\\mathrm{min}}$ in $H$. // $X_{1}, X_{2}, ..., X_{K}$ are mutually disjoint by Corollary 5.\n- For $k=1$ to $K$ do \n  - cut cake $H$ at both endpoints $x_{k}^{\\prime}, x_{k}^{\\prime\\prime}$ of $X_{k}$;\n  - $S_{k}=\\{i\\in R \\mid D_{i}\\subseteq X_{k}, D_{i}\\in\\mathcal{D}_{R}\\}$; $\\mathcal{D}_{S_{k}}=\\left(D_{i}\\in\\mathcal{D}_{R}: i\\in S_{k}\\right)$;\n  - $\\operatorname{CutMinInterval}(S_{k}, X_{k}, D_{S_{k}})$;\n- $R^{\\prime}=R; H^{\\prime}=H$; for $k=1$ to $K$ do $R^{\\prime}=R^{\\prime}\\setminus S_{k}; H^{\\prime}=H^{\\prime}\\setminus X_{k};$;\n- If $R^{\\prime}\\neq\\emptyset$ then // $R^{\\prime}=R\\setminus\\sum_{k=1}^{K}S_{k}$, $H^{\\prime}=H\\setminus\\sum_{k=1}^{K}X_{k}$\n  - $\\mathcal{D}_{R^{\\prime}}^{\\prime}=\\emptyset$;\n  - For each $D_{i}\\in\\mathcal{D}_{R}$ with $i\\in R^{\\prime}$ do, $D_{i}^{\\prime}=D_{i}\\setminus\\sum_{k=1}^{K}X_{k}$, $\\mathcal{D}_{R^{\\prime}}^{\\prime}=\\mathcal{D}_{R^{\\prime}}^{\\prime}+\\{D_{i}^{\\prime}\\}$;\n  - Perform shrinking of all $X_{1}, X_{2}, ..., X_{K}$;\n  - Let $H^{(S)}$, $D_{i}^{(S)}\\in\\mathcal{D}_{R^{\\prime}}^{(S)}$ and $\\mathcal{D}_{R^{\\prime}}^{(S)}$ be obtained from $H^{\\prime}$, $D_{i}^{\\prime}\\in\\mathcal{D}_{R^{\\prime}}^{\\prime}$ and $D_{R^{\\prime}}^{\\prime}$ by shrinking of all $X_{1}, X_{2}, ..., X_{K}$, respectively;\n  - $\\operatorname{CutMaxIntensity}(R^{\\prime}, H^{(S)}, \\mathcal{D}_{R^{\\prime}}^{(S)})$; Perform inverse shrinking of all $X_{1}, X_{2}, ..., X_{K}$.\n\nNote that, if $R^{\\prime}\\neq\\emptyset$, $X_{1}, X_{2}, ..., X_{K}$ and $\\operatorname{CutMaxInterval}(R^{\\prime}, H^{(S)}, \\mathcal{D}_{R^{\\prime}}^{(S)})$ is recursively called, then the minimum density $\\rho_{\\mathrm{min}}^{\\prime}$ in $\\operatorname{CutMaxInterval}(R^{\\prime}, H^{(S)}, \\mathcal{D}_{R^{\\prime}}^{(S)})$ satisfies $\\rho_{\\mathrm{min}}^{\\prime}=\\rho_{\\mathrm{min}}$ by Lemma 7. As mentioned before, Procedure $\\operatorname{CutMinInterval}\\mathrm{l}(S, X, \\mathcal{D}_{S})$ is the core method for solving the cake-cutting problem where cake $X$ is a minimal interval of minimum density in maximal interval $H$ of minimum density $\\rho_{\\mathrm{min}}$, players $S=R(X)=\\{i\\in R \\mid D_{i}\\in\\mathcal{D}_{R}, D_{i}\\subseteq X\\}$ and solid valuation intervals $\\mathcal{D}_{S}=\\mathcal{D}_{R(X)}=(D_{i}\\in\\mathcal{D}_{R}: i\\in S)$.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "- If P^{\\prime}\neq{\\emptyset}$ then // $P^{\\prime}=P\\setminus\\sum_{\\ell=1}^{L}R_{\\ell}$ and $D^{\\prime}=D\\setminus\\sum_{\\ell=1}^{L}H_{\\ell}$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/3.cake-cutting.pdf_7",
        "ID": "033f692f-ad9d-41e7-8685-e760530d9dac",
        "questions": "Does the minimum density increase or stay the same if CutCake(P', D, D_P) is recursively called?",
        "answers": "The minimum density $\rho_{\\mathrm{min}}^{\\prime}$ increases.",
        "context": "Procedure $\\operatorname{CutCake}(P, D, D_{P})$\n\n- Find all the maximal intervals of minimum density $\\rho_{\\mathrm{min}}$ in the cake-cutting problem with cake $D$, players $P$, and solid valuation intervals $\\mathcal{D}_{P}$. \n- Let $H_{1}=\\left[h_{1}^{\\prime},h_{1}^{\\prime\\prime}\\right)$, $H_{2}=\\left[h_{2}^{\\prime},h_{2}^{\\prime\\prime}\\right)$, ..., $H_{L}=\\left[h_{L}^{\\prime},h_{L}^{\\prime\\prime}\\right)$ be all the maximal intervals of minimum density $\\rho_{\\mathrm{min}}$. $H_{1}, H_{2}, ..., H_{L}$ are mutually disjoint by Corollary 5. \n- For $\\ell=1$ to $L$ do, \n  - cut cake $D$ at both endpoints $h_{\\ell}^{\\prime}, h_{\\ell}^{\\prime\\prime}$ of $H_{\\ell}$;\n  - $R_{\\ell}=\\left\\{k\\in P \\mid D_{k}\\subseteq H_{\\ell}, D_{k}\\in\\mathcal{D}_{P}\\right\\};\\;\\mathcal{D}_{R_{\\ell}}=\\left(D_{k}\\in\\mathcal{D}_{P}: k\\in R_{\\ell}\\right)$;\n  - $\\operatorname{CutMaxInterval}(R_{\\ell}, H_{\\ell}, D_{R_{\\ell}})$. \n- $P^{\\prime}=P; D^{\\prime}=D$; for $\\ell=1$ to $L$ do, $P^{\\prime}=P^{\\prime}\\setminus R_{\\ell}; D^{\\prime}=D^{\\prime}\\setminus H_{\\ell}$. \n- If $P^{\\prime}\\neq\\emptyset$ then // $P^{\\prime}=P\\setminus\\sum_{\\ell=1}^{L}R_{\\ell}$ and $D^{\\prime}=D\\setminus\\sum_{\\ell=1}^{L}H_{\\ell}$. \n  - $\\mathcal{D}_{P^{\\prime}}^{\\prime}=\\emptyset$;\n  - For each $D_{k}\\in\\mathcal{D}_{P}$ with $k\\in P^{\\prime}$ do $D_{k}^{\\prime}=D_{k}\\setminus\\sum_{\\ell=1}^{L}H_{\\ell}; \\mathcal{D}_{P^{\\prime}}^{\\prime}=\\mathcal{D}_{P^{\\prime}}^{\\prime}+\\{D_{k}^{\\prime}\\}$;\n  - Perform shrinking of all $H_{1}, H_{2}, ..., H_{L}$. \n  - Let $D^{(S)}$, $D_{k}^{(S)}\\in\\mathcal{D}_{P^{\\prime}}^{(S)}$, and $\\mathcal{D}_{P^{\\prime}}^{(S)}$ be obtained from $D^{\\prime}$, $D_{k}^{\\prime}\\in\\mathcal{D}_{P^{\\prime}}^{\\prime}$, and $\\mathcal{D}_{P^{\\prime}}^{\\prime}$ by shrinking of all $H_{1}, H_{2}, ..., H_{L}$, respectively; \n  - $\\operatorname{CutCake}(P^{\\prime}, D^{(\\bar{S})}, \\mathcal{D}_{P^{\\prime}}^{(S)})$; Perform inverse shrinking of all $H_{1}, H_{2}, ..., H_{L}$;\n\nNote that, If $P^{\\prime}\\neq\\emptyset$ after the deletion of $H_{1}, H_{2}, ..., H_{L}$ and $\\operatorname{CutCake}(P^{\\prime}, D^{(S)}, \\mathcal{D}_{P^{\\prime}}^{(S)})$ is recursively called, then the minimum density $\\rho_{\\mathrm{min}}^{\\prime}$ in $\\operatorname{CutCake}(P^{\\prime}, D^{(S)}, D_{P^{\\prime}}^{(S)})$ satisfies $\\rho_{\\mathrm{min}}^{\\prime}>\\rho_{\\mathrm{min}}$ by Lemma 6. Next, we give a detailed description of $\\operatorname{CutMaxInterval}\\left(R, H, D_{R}\\right)$ based on Lemma 7 and Procedure $\\operatorname{CutMinInterval}(S, X, T_{S})$.\n\n# Procedure $\\operatorname{CutMaxInterval}(R, H, D_{R})$\n\n- Let $X_{1}=\\left[x_{1}^{\\prime}, x_{1}^{\\prime\\prime}\\right)$, $X_{2}=\\left[x_{2}^{\\prime}, x_{2}^{\\prime\\prime}\\right)$, ..., $X_{K}=\\left[x_{K}^{\\prime}, x_{K}^{\\prime\\prime}\\right]$ be all the minimal intervals of minimum density $\\rho_{\\mathrm{min}}$ in $H$. // $X_{1}, X_{2}, ..., X_{K}$ are mutually disjoint by Corollary 5.\n- For $k=1$ to $K$ do \n  - cut cake $H$ at both endpoints $x_{k}^{\\prime}, x_{k}^{\\prime\\prime}$ of $X_{k}$;\n  - $S_{k}=\\{i\\in R \\mid D_{i}\\subseteq X_{k}, D_{i}\\in\\mathcal{D}_{R}\\}$; $\\mathcal{D}_{S_{k}}=\\left(D_{i}\\in\\mathcal{D}_{R}: i\\in S_{k}\\right)$;\n  - $\\operatorname{CutMinInterval}(S_{k}, X_{k}, D_{S_{k}})$;\n- $R^{\\prime}=R; H^{\\prime}=H$; for $k=1$ to $K$ do $R^{\\prime}=R^{\\prime}\\setminus S_{k}; H^{\\prime}=H^{\\prime}\\setminus X_{k};$;\n- If $R^{\\prime}\\neq\\emptyset$ then // $R^{\\prime}=R\\setminus\\sum_{k=1}^{K}S_{k}$, $H^{\\prime}=H\\setminus\\sum_{k=1}^{K}X_{k}$\n  - $\\mathcal{D}_{R^{\\prime}}^{\\prime}=\\emptyset$;\n  - For each $D_{i}\\in\\mathcal{D}_{R}$ with $i\\in R^{\\prime}$ do, $D_{i}^{\\prime}=D_{i}\\setminus\\sum_{k=1}^{K}X_{k}$, $\\mathcal{D}_{R^{\\prime}}^{\\prime}=\\mathcal{D}_{R^{\\prime}}^{\\prime}+\\{D_{i}^{\\prime}\\}$;\n  - Perform shrinking of all $X_{1}, X_{2}, ..., X_{K}$;\n  - Let $H^{(S)}$, $D_{i}^{(S)}\\in\\mathcal{D}_{R^{\\prime}}^{(S)}$ and $\\mathcal{D}_{R^{\\prime}}^{(S)}$ be obtained from $H^{\\prime}$, $D_{i}^{\\prime}\\in\\mathcal{D}_{R^{\\prime}}^{\\prime}$ and $D_{R^{\\prime}}^{\\prime}$ by shrinking of all $X_{1}, X_{2}, ..., X_{K}$, respectively;\n  - $\\operatorname{CutMaxIntensity}(R^{\\prime}, H^{(S)}, \\mathcal{D}_{R^{\\prime}}^{(S)})$; Perform inverse shrinking of all $X_{1}, X_{2}, ..., X_{K}$.\n\nNote that, if $R^{\\prime}\\neq\\emptyset$, $X_{1}, X_{2}, ..., X_{K}$ and $\\operatorname{CutMaxInterval}(R^{\\prime}, H^{(S)}, \\mathcal{D}_{R^{\\prime}}^{(S)})$ is recursively called, then the minimum density $\\rho_{\\mathrm{min}}^{\\prime}$ in $\\operatorname{CutMaxInterval}(R^{\\prime}, H^{(S)}, \\mathcal{D}_{R^{\\prime}}^{(S)})$ satisfies $\\rho_{\\mathrm{min}}^{\\prime}=\\rho_{\\mathrm{min}}$ by Lemma 7. As mentioned before, Procedure $\\operatorname{CutMinInterval}\\mathrm{l}(S, X, \\mathcal{D}_{S})$ is the core method for solving the cake-cutting problem where cake $X$ is a minimal interval of minimum density in maximal interval $H$ of minimum density $\\rho_{\\mathrm{min}}$, players $S=R(X)=\\{i\\in R \\mid D_{i}\\in\\mathcal{D}_{R}, D_{i}\\subseteq X\\}$ and solid valuation intervals $\\mathcal{D}_{S}=\\mathcal{D}_{R(X)}=(D_{i}\\in\\mathcal{D}_{R}: i\\in S)$.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Note that, If $P^{\\prime}\neq\\emptyset$ after the deletion of $H_{1}, H_{2}, ..., H_{L}$ and $\\operatorname{CutCake}(P^{\\prime}, D^{(S)}, \\mathcal{D}_{P^{\\prime}}^{(S)})$ is recursively called, then the minimum density $\rho_{\\mathrm{min}}^{\\prime}$ in $\\operatorname{CutCake}(P^{\\prime}, D^{(S)}, \\mathcal{D}_{P^{\\prime}}^{(S)})$ satisfies $\rho_{\\mathrm{min}}^{\\prime}>\rho_{\\mathrm{min}}$ by Lemma 6.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/3.cake-cutting.pdf_7",
        "ID": "03438da8-aaec-44a2-bb01-84c481d4e46d",
        "questions": "In the CutCake procedure, what is done with the endpoints of maximal intervals of minimum density $H_{\\ell}$? Provide the step as described.",
        "answers": "cut cake $D$ at both endpoints $h_{\\ell}^{\\prime}, h_{\\ell}^{\\prime\\prime}$ of $H_{\\ell}$",
        "context": "Procedure $\\operatorname{CutCake}(P, D, D_{P})$\n\n- Find all the maximal intervals of minimum density $\\rho_{\\mathrm{min}}$ in the cake-cutting problem with cake $D$, players $P$, and solid valuation intervals $\\mathcal{D}_{P}$. \n- Let $H_{1}=\\left[h_{1}^{\\prime},h_{1}^{\\prime\\prime}\\right)$, $H_{2}=\\left[h_{2}^{\\prime},h_{2}^{\\prime\\prime}\\right)$, ..., $H_{L}=\\left[h_{L}^{\\prime},h_{L}^{\\prime\\prime}\\right)$ be all the maximal intervals of minimum density $\\rho_{\\mathrm{min}}$. $H_{1}, H_{2}, ..., H_{L}$ are mutually disjoint by Corollary 5. \n- For $\\ell=1$ to $L$ do, \n  - cut cake $D$ at both endpoints $h_{\\ell}^{\\prime}, h_{\\ell}^{\\prime\\prime}$ of $H_{\\ell}$;\n  - $R_{\\ell}=\\left\\{k\\in P \\mid D_{k}\\subseteq H_{\\ell}, D_{k}\\in\\mathcal{D}_{P}\\right\\};\\;\\mathcal{D}_{R_{\\ell}}=\\left(D_{k}\\in\\mathcal{D}_{P}: k\\in R_{\\ell}\\right)$;\n  - $\\operatorname{CutMaxInterval}(R_{\\ell}, H_{\\ell}, D_{R_{\\ell}})$. \n- $P^{\\prime}=P; D^{\\prime}=D$; for $\\ell=1$ to $L$ do, $P^{\\prime}=P^{\\prime}\\setminus R_{\\ell}; D^{\\prime}=D^{\\prime}\\setminus H_{\\ell}$. \n- If $P^{\\prime}\\neq\\emptyset$ then // $P^{\\prime}=P\\setminus\\sum_{\\ell=1}^{L}R_{\\ell}$ and $D^{\\prime}=D\\setminus\\sum_{\\ell=1}^{L}H_{\\ell}$. \n  - $\\mathcal{D}_{P^{\\prime}}^{\\prime}=\\emptyset$;\n  - For each $D_{k}\\in\\mathcal{D}_{P}$ with $k\\in P^{\\prime}$ do $D_{k}^{\\prime}=D_{k}\\setminus\\sum_{\\ell=1}^{L}H_{\\ell}; \\mathcal{D}_{P^{\\prime}}^{\\prime}=\\mathcal{D}_{P^{\\prime}}^{\\prime}+\\{D_{k}^{\\prime}\\}$;\n  - Perform shrinking of all $H_{1}, H_{2}, ..., H_{L}$. \n  - Let $D^{(S)}$, $D_{k}^{(S)}\\in\\mathcal{D}_{P^{\\prime}}^{(S)}$, and $\\mathcal{D}_{P^{\\prime}}^{(S)}$ be obtained from $D^{\\prime}$, $D_{k}^{\\prime}\\in\\mathcal{D}_{P^{\\prime}}^{\\prime}$, and $\\mathcal{D}_{P^{\\prime}}^{\\prime}$ by shrinking of all $H_{1}, H_{2}, ..., H_{L}$, respectively; \n  - $\\operatorname{CutCake}(P^{\\prime}, D^{(\\bar{S})}, \\mathcal{D}_{P^{\\prime}}^{(S)})$; Perform inverse shrinking of all $H_{1}, H_{2}, ..., H_{L}$;\n\nNote that, If $P^{\\prime}\\neq\\emptyset$ after the deletion of $H_{1}, H_{2}, ..., H_{L}$ and $\\operatorname{CutCake}(P^{\\prime}, D^{(S)}, \\mathcal{D}_{P^{\\prime}}^{(S)})$ is recursively called, then the minimum density $\\rho_{\\mathrm{min}}^{\\prime}$ in $\\operatorname{CutCake}(P^{\\prime}, D^{(S)}, D_{P^{\\prime}}^{(S)})$ satisfies $\\rho_{\\mathrm{min}}^{\\prime}>\\rho_{\\mathrm{min}}$ by Lemma 6. Next, we give a detailed description of $\\operatorname{CutMaxInterval}\\left(R, H, D_{R}\\right)$ based on Lemma 7 and Procedure $\\operatorname{CutMinInterval}(S, X, T_{S})$.\n\n# Procedure $\\operatorname{CutMaxInterval}(R, H, D_{R})$\n\n- Let $X_{1}=\\left[x_{1}^{\\prime}, x_{1}^{\\prime\\prime}\\right)$, $X_{2}=\\left[x_{2}^{\\prime}, x_{2}^{\\prime\\prime}\\right)$, ..., $X_{K}=\\left[x_{K}^{\\prime}, x_{K}^{\\prime\\prime}\\right]$ be all the minimal intervals of minimum density $\\rho_{\\mathrm{min}}$ in $H$. // $X_{1}, X_{2}, ..., X_{K}$ are mutually disjoint by Corollary 5.\n- For $k=1$ to $K$ do \n  - cut cake $H$ at both endpoints $x_{k}^{\\prime}, x_{k}^{\\prime\\prime}$ of $X_{k}$;\n  - $S_{k}=\\{i\\in R \\mid D_{i}\\subseteq X_{k}, D_{i}\\in\\mathcal{D}_{R}\\}$; $\\mathcal{D}_{S_{k}}=\\left(D_{i}\\in\\mathcal{D}_{R}: i\\in S_{k}\\right)$;\n  - $\\operatorname{CutMinInterval}(S_{k}, X_{k}, D_{S_{k}})$;\n- $R^{\\prime}=R; H^{\\prime}=H$; for $k=1$ to $K$ do $R^{\\prime}=R^{\\prime}\\setminus S_{k}; H^{\\prime}=H^{\\prime}\\setminus X_{k};$;\n- If $R^{\\prime}\\neq\\emptyset$ then // $R^{\\prime}=R\\setminus\\sum_{k=1}^{K}S_{k}$, $H^{\\prime}=H\\setminus\\sum_{k=1}^{K}X_{k}$\n  - $\\mathcal{D}_{R^{\\prime}}^{\\prime}=\\emptyset$;\n  - For each $D_{i}\\in\\mathcal{D}_{R}$ with $i\\in R^{\\prime}$ do, $D_{i}^{\\prime}=D_{i}\\setminus\\sum_{k=1}^{K}X_{k}$, $\\mathcal{D}_{R^{\\prime}}^{\\prime}=\\mathcal{D}_{R^{\\prime}}^{\\prime}+\\{D_{i}^{\\prime}\\}$;\n  - Perform shrinking of all $X_{1}, X_{2}, ..., X_{K}$;\n  - Let $H^{(S)}$, $D_{i}^{(S)}\\in\\mathcal{D}_{R^{\\prime}}^{(S)}$ and $\\mathcal{D}_{R^{\\prime}}^{(S)}$ be obtained from $H^{\\prime}$, $D_{i}^{\\prime}\\in\\mathcal{D}_{R^{\\prime}}^{\\prime}$ and $D_{R^{\\prime}}^{\\prime}$ by shrinking of all $X_{1}, X_{2}, ..., X_{K}$, respectively;\n  - $\\operatorname{CutMaxIntensity}(R^{\\prime}, H^{(S)}, \\mathcal{D}_{R^{\\prime}}^{(S)})$; Perform inverse shrinking of all $X_{1}, X_{2}, ..., X_{K}$.\n\nNote that, if $R^{\\prime}\\neq\\emptyset$, $X_{1}, X_{2}, ..., X_{K}$ and $\\operatorname{CutMaxInterval}(R^{\\prime}, H^{(S)}, \\mathcal{D}_{R^{\\prime}}^{(S)})$ is recursively called, then the minimum density $\\rho_{\\mathrm{min}}^{\\prime}$ in $\\operatorname{CutMaxInterval}(R^{\\prime}, H^{(S)}, \\mathcal{D}_{R^{\\prime}}^{(S)})$ satisfies $\\rho_{\\mathrm{min}}^{\\prime}=\\rho_{\\mathrm{min}}$ by Lemma 7. As mentioned before, Procedure $\\operatorname{CutMinInterval}\\mathrm{l}(S, X, \\mathcal{D}_{S})$ is the core method for solving the cake-cutting problem where cake $X$ is a minimal interval of minimum density in maximal interval $H$ of minimum density $\\rho_{\\mathrm{min}}$, players $S=R(X)=\\{i\\in R \\mid D_{i}\\in\\mathcal{D}_{R}, D_{i}\\subseteq X\\}$ and solid valuation intervals $\\mathcal{D}_{S}=\\mathcal{D}_{R(X)}=(D_{i}\\in\\mathcal{D}_{R}: i\\in S)$.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "- For $\\ell=1$ to $L$ do, - cut cake $D$ at both endpoints $h_{\\ell}^{\\prime}, h_{\\ell}^{\\prime\\prime}$ of $H_{\\ell}$;",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/3.cake-cutting.pdf_7",
        "ID": "0344324f-982f-40a9-80d6-216a07bc5630",
        "questions": "What happens to the sets $P^{\\prime}$ and $D^{\\prime}$ after intervals designated as $R_{\\ell}$ and $H_{\\ell}$ are removed in the CutCake procedure?",
        "answers": "$P^{\\prime}=P^{\\prime}\\setminus R_{\\ell}; D^{\\prime}=D^{\\prime}\\setminus H_{\\ell}$",
        "context": "Procedure $\\operatorname{CutCake}(P, D, D_{P})$\n\n- Find all the maximal intervals of minimum density $\\rho_{\\mathrm{min}}$ in the cake-cutting problem with cake $D$, players $P$, and solid valuation intervals $\\mathcal{D}_{P}$. \n- Let $H_{1}=\\left[h_{1}^{\\prime},h_{1}^{\\prime\\prime}\\right)$, $H_{2}=\\left[h_{2}^{\\prime},h_{2}^{\\prime\\prime}\\right)$, ..., $H_{L}=\\left[h_{L}^{\\prime},h_{L}^{\\prime\\prime}\\right)$ be all the maximal intervals of minimum density $\\rho_{\\mathrm{min}}$. $H_{1}, H_{2}, ..., H_{L}$ are mutually disjoint by Corollary 5. \n- For $\\ell=1$ to $L$ do, \n  - cut cake $D$ at both endpoints $h_{\\ell}^{\\prime}, h_{\\ell}^{\\prime\\prime}$ of $H_{\\ell}$;\n  - $R_{\\ell}=\\left\\{k\\in P \\mid D_{k}\\subseteq H_{\\ell}, D_{k}\\in\\mathcal{D}_{P}\\right\\};\\;\\mathcal{D}_{R_{\\ell}}=\\left(D_{k}\\in\\mathcal{D}_{P}: k\\in R_{\\ell}\\right)$;\n  - $\\operatorname{CutMaxInterval}(R_{\\ell}, H_{\\ell}, D_{R_{\\ell}})$. \n- $P^{\\prime}=P; D^{\\prime}=D$; for $\\ell=1$ to $L$ do, $P^{\\prime}=P^{\\prime}\\setminus R_{\\ell}; D^{\\prime}=D^{\\prime}\\setminus H_{\\ell}$. \n- If $P^{\\prime}\\neq\\emptyset$ then // $P^{\\prime}=P\\setminus\\sum_{\\ell=1}^{L}R_{\\ell}$ and $D^{\\prime}=D\\setminus\\sum_{\\ell=1}^{L}H_{\\ell}$. \n  - $\\mathcal{D}_{P^{\\prime}}^{\\prime}=\\emptyset$;\n  - For each $D_{k}\\in\\mathcal{D}_{P}$ with $k\\in P^{\\prime}$ do $D_{k}^{\\prime}=D_{k}\\setminus\\sum_{\\ell=1}^{L}H_{\\ell}; \\mathcal{D}_{P^{\\prime}}^{\\prime}=\\mathcal{D}_{P^{\\prime}}^{\\prime}+\\{D_{k}^{\\prime}\\}$;\n  - Perform shrinking of all $H_{1}, H_{2}, ..., H_{L}$. \n  - Let $D^{(S)}$, $D_{k}^{(S)}\\in\\mathcal{D}_{P^{\\prime}}^{(S)}$, and $\\mathcal{D}_{P^{\\prime}}^{(S)}$ be obtained from $D^{\\prime}$, $D_{k}^{\\prime}\\in\\mathcal{D}_{P^{\\prime}}^{\\prime}$, and $\\mathcal{D}_{P^{\\prime}}^{\\prime}$ by shrinking of all $H_{1}, H_{2}, ..., H_{L}$, respectively; \n  - $\\operatorname{CutCake}(P^{\\prime}, D^{(\\bar{S})}, \\mathcal{D}_{P^{\\prime}}^{(S)})$; Perform inverse shrinking of all $H_{1}, H_{2}, ..., H_{L}$;\n\nNote that, If $P^{\\prime}\\neq\\emptyset$ after the deletion of $H_{1}, H_{2}, ..., H_{L}$ and $\\operatorname{CutCake}(P^{\\prime}, D^{(S)}, \\mathcal{D}_{P^{\\prime}}^{(S)})$ is recursively called, then the minimum density $\\rho_{\\mathrm{min}}^{\\prime}$ in $\\operatorname{CutCake}(P^{\\prime}, D^{(S)}, D_{P^{\\prime}}^{(S)})$ satisfies $\\rho_{\\mathrm{min}}^{\\prime}>\\rho_{\\mathrm{min}}$ by Lemma 6. Next, we give a detailed description of $\\operatorname{CutMaxInterval}\\left(R, H, D_{R}\\right)$ based on Lemma 7 and Procedure $\\operatorname{CutMinInterval}(S, X, T_{S})$.\n\n# Procedure $\\operatorname{CutMaxInterval}(R, H, D_{R})$\n\n- Let $X_{1}=\\left[x_{1}^{\\prime}, x_{1}^{\\prime\\prime}\\right)$, $X_{2}=\\left[x_{2}^{\\prime}, x_{2}^{\\prime\\prime}\\right)$, ..., $X_{K}=\\left[x_{K}^{\\prime}, x_{K}^{\\prime\\prime}\\right]$ be all the minimal intervals of minimum density $\\rho_{\\mathrm{min}}$ in $H$. // $X_{1}, X_{2}, ..., X_{K}$ are mutually disjoint by Corollary 5.\n- For $k=1$ to $K$ do \n  - cut cake $H$ at both endpoints $x_{k}^{\\prime}, x_{k}^{\\prime\\prime}$ of $X_{k}$;\n  - $S_{k}=\\{i\\in R \\mid D_{i}\\subseteq X_{k}, D_{i}\\in\\mathcal{D}_{R}\\}$; $\\mathcal{D}_{S_{k}}=\\left(D_{i}\\in\\mathcal{D}_{R}: i\\in S_{k}\\right)$;\n  - $\\operatorname{CutMinInterval}(S_{k}, X_{k}, D_{S_{k}})$;\n- $R^{\\prime}=R; H^{\\prime}=H$; for $k=1$ to $K$ do $R^{\\prime}=R^{\\prime}\\setminus S_{k}; H^{\\prime}=H^{\\prime}\\setminus X_{k};$;\n- If $R^{\\prime}\\neq\\emptyset$ then // $R^{\\prime}=R\\setminus\\sum_{k=1}^{K}S_{k}$, $H^{\\prime}=H\\setminus\\sum_{k=1}^{K}X_{k}$\n  - $\\mathcal{D}_{R^{\\prime}}^{\\prime}=\\emptyset$;\n  - For each $D_{i}\\in\\mathcal{D}_{R}$ with $i\\in R^{\\prime}$ do, $D_{i}^{\\prime}=D_{i}\\setminus\\sum_{k=1}^{K}X_{k}$, $\\mathcal{D}_{R^{\\prime}}^{\\prime}=\\mathcal{D}_{R^{\\prime}}^{\\prime}+\\{D_{i}^{\\prime}\\}$;\n  - Perform shrinking of all $X_{1}, X_{2}, ..., X_{K}$;\n  - Let $H^{(S)}$, $D_{i}^{(S)}\\in\\mathcal{D}_{R^{\\prime}}^{(S)}$ and $\\mathcal{D}_{R^{\\prime}}^{(S)}$ be obtained from $H^{\\prime}$, $D_{i}^{\\prime}\\in\\mathcal{D}_{R^{\\prime}}^{\\prime}$ and $D_{R^{\\prime}}^{\\prime}$ by shrinking of all $X_{1}, X_{2}, ..., X_{K}$, respectively;\n  - $\\operatorname{CutMaxIntensity}(R^{\\prime}, H^{(S)}, \\mathcal{D}_{R^{\\prime}}^{(S)})$; Perform inverse shrinking of all $X_{1}, X_{2}, ..., X_{K}$.\n\nNote that, if $R^{\\prime}\\neq\\emptyset$, $X_{1}, X_{2}, ..., X_{K}$ and $\\operatorname{CutMaxInterval}(R^{\\prime}, H^{(S)}, \\mathcal{D}_{R^{\\prime}}^{(S)})$ is recursively called, then the minimum density $\\rho_{\\mathrm{min}}^{\\prime}$ in $\\operatorname{CutMaxInterval}(R^{\\prime}, H^{(S)}, \\mathcal{D}_{R^{\\prime}}^{(S)})$ satisfies $\\rho_{\\mathrm{min}}^{\\prime}=\\rho_{\\mathrm{min}}$ by Lemma 7. As mentioned before, Procedure $\\operatorname{CutMinInterval}\\mathrm{l}(S, X, \\mathcal{D}_{S})$ is the core method for solving the cake-cutting problem where cake $X$ is a minimal interval of minimum density in maximal interval $H$ of minimum density $\\rho_{\\mathrm{min}}$, players $S=R(X)=\\{i\\in R \\mid D_{i}\\in\\mathcal{D}_{R}, D_{i}\\subseteq X\\}$ and solid valuation intervals $\\mathcal{D}_{S}=\\mathcal{D}_{R(X)}=(D_{i}\\in\\mathcal{D}_{R}: i\\in S)$.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "for $\\ell=1$ to $L$ do, $P^{\\prime}=P^{\\prime}\\setminus R_{\\ell}; D^{\\prime}=D^{\\prime}\\setminus H_{\\ell}$.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/3.cake-cutting.pdf_7",
        "ID": "034be832-f8c7-450d-b036-bf2cee165adb",
        "questions": "According to the CutMaxInterval procedure, what is the condition for recursively calling the same procedure, and what does Lemma 7 guarantee about the minimum density in such a recursive call?",
        "answers": "if $R^{\\prime}\\neq\\emptyset$, ... then the minimum density $\\rho_{\\mathrm{min}}^{\\prime}$ in $\\operatorname{CutMaxInterval}(R^{\\prime}, H^{(S)}, \\mathcal{D}_{R^{\\prime}}^{(S)})$ satisfies $\\rho_{\\mathrm{min}}^{\\prime}=\\rho_{\\mathrm{min}}$",
        "context": "Procedure $\\operatorname{CutCake}(P, D, D_{P})$\n\n- Find all the maximal intervals of minimum density $\\rho_{\\mathrm{min}}$ in the cake-cutting problem with cake $D$, players $P$, and solid valuation intervals $\\mathcal{D}_{P}$. \n- Let $H_{1}=\\left[h_{1}^{\\prime},h_{1}^{\\prime\\prime}\\right)$, $H_{2}=\\left[h_{2}^{\\prime},h_{2}^{\\prime\\prime}\\right)$, ..., $H_{L}=\\left[h_{L}^{\\prime},h_{L}^{\\prime\\prime}\\right)$ be all the maximal intervals of minimum density $\\rho_{\\mathrm{min}}$. $H_{1}, H_{2}, ..., H_{L}$ are mutually disjoint by Corollary 5. \n- For $\\ell=1$ to $L$ do, \n  - cut cake $D$ at both endpoints $h_{\\ell}^{\\prime}, h_{\\ell}^{\\prime\\prime}$ of $H_{\\ell}$;\n  - $R_{\\ell}=\\left\\{k\\in P \\mid D_{k}\\subseteq H_{\\ell}, D_{k}\\in\\mathcal{D}_{P}\\right\\};\\;\\mathcal{D}_{R_{\\ell}}=\\left(D_{k}\\in\\mathcal{D}_{P}: k\\in R_{\\ell}\\right)$;\n  - $\\operatorname{CutMaxInterval}(R_{\\ell}, H_{\\ell}, D_{R_{\\ell}})$. \n- $P^{\\prime}=P; D^{\\prime}=D$; for $\\ell=1$ to $L$ do, $P^{\\prime}=P^{\\prime}\\setminus R_{\\ell}; D^{\\prime}=D^{\\prime}\\setminus H_{\\ell}$. \n- If $P^{\\prime}\\neq\\emptyset$ then // $P^{\\prime}=P\\setminus\\sum_{\\ell=1}^{L}R_{\\ell}$ and $D^{\\prime}=D\\setminus\\sum_{\\ell=1}^{L}H_{\\ell}$. \n  - $\\mathcal{D}_{P^{\\prime}}^{\\prime}=\\emptyset$;\n  - For each $D_{k}\\in\\mathcal{D}_{P}$ with $k\\in P^{\\prime}$ do $D_{k}^{\\prime}=D_{k}\\setminus\\sum_{\\ell=1}^{L}H_{\\ell}; \\mathcal{D}_{P^{\\prime}}^{\\prime}=\\mathcal{D}_{P^{\\prime}}^{\\prime}+\\{D_{k}^{\\prime}\\}$;\n  - Perform shrinking of all $H_{1}, H_{2}, ..., H_{L}$. \n  - Let $D^{(S)}$, $D_{k}^{(S)}\\in\\mathcal{D}_{P^{\\prime}}^{(S)}$, and $\\mathcal{D}_{P^{\\prime}}^{(S)}$ be obtained from $D^{\\prime}$, $D_{k}^{\\prime}\\in\\mathcal{D}_{P^{\\prime}}^{\\prime}$, and $\\mathcal{D}_{P^{\\prime}}^{\\prime}$ by shrinking of all $H_{1}, H_{2}, ..., H_{L}$, respectively; \n  - $\\operatorname{CutCake}(P^{\\prime}, D^{(\\bar{S})}, \\mathcal{D}_{P^{\\prime}}^{(S)})$; Perform inverse shrinking of all $H_{1}, H_{2}, ..., H_{L}$;\n\nNote that, If $P^{\\prime}\\neq\\emptyset$ after the deletion of $H_{1}, H_{2}, ..., H_{L}$ and $\\operatorname{CutCake}(P^{\\prime}, D^{(S)}, \\mathcal{D}_{P^{\\prime}}^{(S)})$ is recursively called, then the minimum density $\\rho_{\\mathrm{min}}^{\\prime}$ in $\\operatorname{CutCake}(P^{\\prime}, D^{(S)}, D_{P^{\\prime}}^{(S)})$ satisfies $\\rho_{\\mathrm{min}}^{\\prime}>\\rho_{\\mathrm{min}}$ by Lemma 6. Next, we give a detailed description of $\\operatorname{CutMaxInterval}\\left(R, H, D_{R}\\right)$ based on Lemma 7 and Procedure $\\operatorname{CutMinInterval}(S, X, T_{S})$.\n\n# Procedure $\\operatorname{CutMaxInterval}(R, H, D_{R})$\n\n- Let $X_{1}=\\left[x_{1}^{\\prime}, x_{1}^{\\prime\\prime}\\right)$, $X_{2}=\\left[x_{2}^{\\prime}, x_{2}^{\\prime\\prime}\\right)$, ..., $X_{K}=\\left[x_{K}^{\\prime}, x_{K}^{\\prime\\prime}\\right]$ be all the minimal intervals of minimum density $\\rho_{\\mathrm{min}}$ in $H$. // $X_{1}, X_{2}, ..., X_{K}$ are mutually disjoint by Corollary 5.\n- For $k=1$ to $K$ do \n  - cut cake $H$ at both endpoints $x_{k}^{\\prime}, x_{k}^{\\prime\\prime}$ of $X_{k}$;\n  - $S_{k}=\\{i\\in R \\mid D_{i}\\subseteq X_{k}, D_{i}\\in\\mathcal{D}_{R}\\}$; $\\mathcal{D}_{S_{k}}=\\left(D_{i}\\in\\mathcal{D}_{R}: i\\in S_{k}\\right)$;\n  - $\\operatorname{CutMinInterval}(S_{k}, X_{k}, D_{S_{k}})$;\n- $R^{\\prime}=R; H^{\\prime}=H$; for $k=1$ to $K$ do $R^{\\prime}=R^{\\prime}\\setminus S_{k}; H^{\\prime}=H^{\\prime}\\setminus X_{k};$;\n- If $R^{\\prime}\\neq\\emptyset$ then // $R^{\\prime}=R\\setminus\\sum_{k=1}^{K}S_{k}$, $H^{\\prime}=H\\setminus\\sum_{k=1}^{K}X_{k}$\n  - $\\mathcal{D}_{R^{\\prime}}^{\\prime}=\\emptyset$;\n  - For each $D_{i}\\in\\mathcal{D}_{R}$ with $i\\in R^{\\prime}$ do, $D_{i}^{\\prime}=D_{i}\\setminus\\sum_{k=1}^{K}X_{k}$, $\\mathcal{D}_{R^{\\prime}}^{\\prime}=\\mathcal{D}_{R^{\\prime}}^{\\prime}+\\{D_{i}^{\\prime}\\}$;\n  - Perform shrinking of all $X_{1}, X_{2}, ..., X_{K}$;\n  - Let $H^{(S)}$, $D_{i}^{(S)}\\in\\mathcal{D}_{R^{\\prime}}^{(S)}$ and $\\mathcal{D}_{R^{\\prime}}^{(S)}$ be obtained from $H^{\\prime}$, $D_{i}^{\\prime}\\in\\mathcal{D}_{R^{\\prime}}^{\\prime}$ and $D_{R^{\\prime}}^{\\prime}$ by shrinking of all $X_{1}, X_{2}, ..., X_{K}$, respectively;\n  - $\\operatorname{CutMaxIntensity}(R^{\\prime}, H^{(S)}, \\mathcal{D}_{R^{\\prime}}^{(S)})$; Perform inverse shrinking of all $X_{1}, X_{2}, ..., X_{K}$.\n\nNote that, if $R^{\\prime}\\neq\\emptyset$, $X_{1}, X_{2}, ..., X_{K}$ and $\\operatorname{CutMaxInterval}(R^{\\prime}, H^{(S)}, \\mathcal{D}_{R^{\\prime}}^{(S)})$ is recursively called, then the minimum density $\\rho_{\\mathrm{min}}^{\\prime}$ in $\\operatorname{CutMaxInterval}(R^{\\prime}, H^{(S)}, \\mathcal{D}_{R^{\\prime}}^{(S)})$ satisfies $\\rho_{\\mathrm{min}}^{\\prime}=\\rho_{\\mathrm{min}}$ by Lemma 7. As mentioned before, Procedure $\\operatorname{CutMinInterval}\\mathrm{l}(S, X, \\mathcal{D}_{S})$ is the core method for solving the cake-cutting problem where cake $X$ is a minimal interval of minimum density in maximal interval $H$ of minimum density $\\rho_{\\mathrm{min}}$, players $S=R(X)=\\{i\\in R \\mid D_{i}\\in\\mathcal{D}_{R}, D_{i}\\subseteq X\\}$ and solid valuation intervals $\\mathcal{D}_{S}=\\mathcal{D}_{R(X)}=(D_{i}\\in\\mathcal{D}_{R}: i\\in S)$.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Note that, if $R^{\\prime}\\neq\\emptyset$, $X_{1}, X_{2}, ..., X_{K}$ and $\\operatorname{CutMaxInterval}(R^{\\prime}, H^{(S)}, \\mathcal{D}_{R^{\\prime}}^{(S)})$ is recursively called, then the minimum density $\\rho_{\\mathrm{min}}^{\\prime}$ in $\\operatorname{CutMaxInterval}(R^{\\prime}, H^{(S)}, \\mathcal{D}_{R^{\\prime}}^{(S)})$ satisfies $\\rho_{\\mathrm{min}}^{\\prime}=\\rho_{\\mathrm{min}}$ by Lemma 7.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/9d551151d715267077b3a4a41ac5652b5887a82bd8e5ebdd085386a093cd1a89.pdf_11",
        "ID": "035d6ede-a3c9-4e99-b131-aac79f4b6e25",
        "questions": "Which court cases significantly impacted the initiative for Advance Care Planning?",
        "answers": "Karen Ann Quinlan v. State of New Jersey and Nancy Cruzan v. Director, Missouri Department of Health",
        "context": "As they age and their health care needs change. The three stages of the Respecting Choices\u00ae model include First Steps\u00ae, for generally well adults; Next Steps\u00ae, for adults diagnosed with chronic or life-limiting diseases; and Last Steps\u00ae, for those with a life expectancy of less than one year (Hammes & Briggs, 2011). The staged planning process is intended to meet the ongoing needs of the adult with chronic and/or life-limiting diseases (Hammes, et al., 2012; Hickman, et al., 2009).\n\n# Background\n\nThe initiative for ACP started over twenty years ago in the national legislature. The effort was predicated by a number of court cases pleading for a patient's right to choose whether to receive medical treatment (Ulrich, 1999). Two of the more publicized cases were Karen Ann Quinlan v. State of New Jersey and Nancy Cruzan v. Director, Missouri Department of Health (70 N.J. 10 (1976) 355 A.2d 647; 497 U.S. 261, 110 S Ct. 2841, 111 L. Ed. 2d 224, 1990 U.S., respectively). Both cases engendered significant press and publicity that argued over a patient's right to die. Subsequently, the Patient Self-Determination Act of 1990 (PSDA) passed through the United States Legislature and was enacted in 1991 (H.R. Res. ${101}^{\\mathrm{st}}$ Cong. H. R. 4449 (1990). The PSDA provided the legal right for patients to determine which, if any, treatment options they preferred. It also allowed patients to appoint an advocate who would make decisions on their behalves in the event they were unable to do so (Duke, et al., 2009; Ulrich, 1999). The primary intention of the PSDA was to prevent cases similar to Quinlan's or Cruzan's from reoccurring by increasing the availability and utility of AD documents (Ulrich).\n\nUnfortunately, the AD documents that followed were often vague and left the interpretation of the document to the advocate (Andershed & Harstade, 2007; Kirchhoff",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Two of the more publicized cases were Karen Ann Quinlan v. State of New Jersey and Nancy Cruzan v. Director, Missouri Department of Health",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/9d551151d715267077b3a4a41ac5652b5887a82bd8e5ebdd085386a093cd1a89.pdf_11",
        "ID": "035da456-5dbb-4a03-83c2-b7da05dcb25e",
        "questions": "What legislative act provided the legal right for patients to determine their treatment options and appoint an advocate?",
        "answers": "Patient Self-Determination Act of 1990 (PSDA)",
        "context": "As they age and their health care needs change. The three stages of the Respecting Choices\u00ae model include First Steps\u00ae, for generally well adults; Next Steps\u00ae, for adults diagnosed with chronic or life-limiting diseases; and Last Steps\u00ae, for those with a life expectancy of less than one year (Hammes & Briggs, 2011). The staged planning process is intended to meet the ongoing needs of the adult with chronic and/or life-limiting diseases (Hammes, et al., 2012; Hickman, et al., 2009).\n\n# Background\n\nThe initiative for ACP started over twenty years ago in the national legislature. The effort was predicated by a number of court cases pleading for a patient's right to choose whether to receive medical treatment (Ulrich, 1999). Two of the more publicized cases were Karen Ann Quinlan v. State of New Jersey and Nancy Cruzan v. Director, Missouri Department of Health (70 N.J. 10 (1976) 355 A.2d 647; 497 U.S. 261, 110 S Ct. 2841, 111 L. Ed. 2d 224, 1990 U.S., respectively). Both cases engendered significant press and publicity that argued over a patient's right to die. Subsequently, the Patient Self-Determination Act of 1990 (PSDA) passed through the United States Legislature and was enacted in 1991 (H.R. Res. ${101}^{\\mathrm{st}}$ Cong. H. R. 4449 (1990). The PSDA provided the legal right for patients to determine which, if any, treatment options they preferred. It also allowed patients to appoint an advocate who would make decisions on their behalves in the event they were unable to do so (Duke, et al., 2009; Ulrich, 1999). The primary intention of the PSDA was to prevent cases similar to Quinlan's or Cruzan's from reoccurring by increasing the availability and utility of AD documents (Ulrich).\n\nUnfortunately, the AD documents that followed were often vague and left the interpretation of the document to the advocate (Andershed & Harstade, 2007; Kirchhoff",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "The Patient Self-Determination Act of 1990 (PSDA) passed through the United States Legislature and was enacted in 1991.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/9d551151d715267077b3a4a41ac5652b5887a82bd8e5ebdd085386a093cd1a89.pdf_11",
        "ID": "0361194e-41a4-4908-aa86-40178be6aeb4",
        "questions": "What is the name of the model that includes First Steps\u00ae, Next Steps\u00ae, and Last Steps\u00ae for different stages of adults' health care planning?",
        "answers": "Respecting Choices\u00ae model",
        "context": "As they age and their health care needs change. The three stages of the Respecting Choices\u00ae model include First Steps\u00ae, for generally well adults; Next Steps\u00ae, for adults diagnosed with chronic or life-limiting diseases; and Last Steps\u00ae, for those with a life expectancy of less than one year (Hammes & Briggs, 2011). The staged planning process is intended to meet the ongoing needs of the adult with chronic and/or life-limiting diseases (Hammes, et al., 2012; Hickman, et al., 2009).\n\n# Background\n\nThe initiative for ACP started over twenty years ago in the national legislature. The effort was predicated by a number of court cases pleading for a patient's right to choose whether to receive medical treatment (Ulrich, 1999). Two of the more publicized cases were Karen Ann Quinlan v. State of New Jersey and Nancy Cruzan v. Director, Missouri Department of Health (70 N.J. 10 (1976) 355 A.2d 647; 497 U.S. 261, 110 S Ct. 2841, 111 L. Ed. 2d 224, 1990 U.S., respectively). Both cases engendered significant press and publicity that argued over a patient's right to die. Subsequently, the Patient Self-Determination Act of 1990 (PSDA) passed through the United States Legislature and was enacted in 1991 (H.R. Res. ${101}^{\\mathrm{st}}$ Cong. H. R. 4449 (1990). The PSDA provided the legal right for patients to determine which, if any, treatment options they preferred. It also allowed patients to appoint an advocate who would make decisions on their behalves in the event they were unable to do so (Duke, et al., 2009; Ulrich, 1999). The primary intention of the PSDA was to prevent cases similar to Quinlan's or Cruzan's from reoccurring by increasing the availability and utility of AD documents (Ulrich).\n\nUnfortunately, the AD documents that followed were often vague and left the interpretation of the document to the advocate (Andershed & Harstade, 2007; Kirchhoff",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "The three stages of the Respecting Choices\u00ae model include First Steps\u00ae, for generally well adults; Next Steps\u00ae, for adults diagnosed with chronic or life-limiting diseases; and Last Steps\u00ae, for those with a life expectancy of less than one year.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/phys-863.pdf_95",
        "ID": "0361524c-2cc0-4859-aa65-24ab713b7e05",
        "questions": "What phase is observed in hydrated lipid bilayers between the 'gel' phase and the 'fluid' phase?",
        "answers": "The ripple phase $P_{\\beta^{\\prime}}$",
        "context": "# 3.5: The Ripple Phase  \n\nLipids consist of hydrophilic polar head groups attached to hydrocarbon chains and arrange themselves in bilayers to make biological membrane structures. At lower temperatures, the bilayer is in a $L_{\\beta^{\\prime}}$ 'gel' phase and there is a transition to 'fluid' phase, $L_{\\alpha}$ at higher temperatures due to an increase in mobility of individual lipids in the bilayer. As the ripple phase $P_{\\beta^{\\prime}}$ is observed in hydrated lipid bilayers between the $L_{\\beta^{\\prime}}$ and $L_{\\alpha}$ phase. This phase is characterized by corrugations of the membrane surface with well-defined periodicity with an axis parallel to the mean bilayer plane [1]. The molecular origin of ripple-phase formation has traditionally been associated with the lipid headgroup region and hence lipids can be classified into ripple-forming and non-ripple forming lipids based on their headgroups. One of the lipid families belonging to the ripple-forming class is phosphatidyl cholines and has been studied in extensive detail [1].  \n\n![](images/8355e2b178c4a5a10a2369d125a83c599234bbae196b22efdb27023ee1729b61.jpg)  \nScheme above shows different physical states adopted by a lipid bilayer in an aqueous medium [2].  \n\n# Thermodynamics and Existence  \n\nThe existence of the ripple phase at first sight is paradoxical on thermodynamic grounds since it involves an apparent lowering of symmetry (from $L_{\\beta},$ to $P_{\\beta^{\\prime}}$) on increasing the temperature. Some models suggest that ripples exist because of periodic local spontaneous curvature in the lipid bilayers formed due to electrostatic coupling between water molecules and the polar headgroups or coupling between membrane curvature and molecular tilt. It has also been speculated that ripples form to relieve packing frustrations that arise whenever the relationship between head-group cross sectional area and cross-sectional area of the apolar tails exceeds a certain threshold [1]. However, there is not one conclusive theory to explain ripple phase formation.  \n\n# Phase Diagram Depicting Ripple Phase  \n\n![](images/d83e0991b12d29163da1f7c80d0c75798913c78f282681d8dd5eae07d8801d64.jpg)  \nConcentration (% $\\mathsf{H}_{2}\\mathsf{O})$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "As the ripple phase $P_{\\beta^{\\prime}}$ is observed in hydrated lipid bilayers between the $L_{\\beta^{\\prime}}$ and $L_{\\alpha}$ phase.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/phys-863.pdf_95",
        "ID": "03622744-2eb5-47f3-b459-4714a263e403",
        "questions": "What is one of the traditional molecular origins of the ripple phase formation associated with lipid headgroups?",
        "answers": "Periodic local spontaneous curvature in the lipid bilayers formed due to electrostatic coupling between water molecules and the polar headgroups",
        "context": "# 3.5: The Ripple Phase  \n\nLipids consist of hydrophilic polar head groups attached to hydrocarbon chains and arrange themselves in bilayers to make biological membrane structures. At lower temperatures, the bilayer is in a $L_{\\beta^{\\prime}}$ 'gel' phase and there is a transition to 'fluid' phase, $L_{\\alpha}$ at higher temperatures due to an increase in mobility of individual lipids in the bilayer. As the ripple phase $P_{\\beta^{\\prime}}$ is observed in hydrated lipid bilayers between the $L_{\\beta^{\\prime}}$ and $L_{\\alpha}$ phase. This phase is characterized by corrugations of the membrane surface with well-defined periodicity with an axis parallel to the mean bilayer plane [1]. The molecular origin of ripple-phase formation has traditionally been associated with the lipid headgroup region and hence lipids can be classified into ripple-forming and non-ripple forming lipids based on their headgroups. One of the lipid families belonging to the ripple-forming class is phosphatidyl cholines and has been studied in extensive detail [1].  \n\n![](images/8355e2b178c4a5a10a2369d125a83c599234bbae196b22efdb27023ee1729b61.jpg)  \nScheme above shows different physical states adopted by a lipid bilayer in an aqueous medium [2].  \n\n# Thermodynamics and Existence  \n\nThe existence of the ripple phase at first sight is paradoxical on thermodynamic grounds since it involves an apparent lowering of symmetry (from $L_{\\beta},$ to $P_{\\beta^{\\prime}}$) on increasing the temperature. Some models suggest that ripples exist because of periodic local spontaneous curvature in the lipid bilayers formed due to electrostatic coupling between water molecules and the polar headgroups or coupling between membrane curvature and molecular tilt. It has also been speculated that ripples form to relieve packing frustrations that arise whenever the relationship between head-group cross sectional area and cross-sectional area of the apolar tails exceeds a certain threshold [1]. However, there is not one conclusive theory to explain ripple phase formation.  \n\n# Phase Diagram Depicting Ripple Phase  \n\n![](images/d83e0991b12d29163da1f7c80d0c75798913c78f282681d8dd5eae07d8801d64.jpg)  \nConcentration (% $\\mathsf{H}_{2}\\mathsf{O})$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Some models suggest that ripples exist because of periodic local spontaneous curvature in the lipid bilayers formed due to electrostatic coupling between water molecules and the polar headgroups",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/phys-863.pdf_95",
        "ID": "03691338-50f4-443c-bc19-500f2cd8c979",
        "questions": "What is a reason speculated for the formation of ripples to relieve in lipid bilayers according to certain theories?",
        "answers": "Ripples form to relieve packing frustrations that arise whenever the relationship between head-group cross sectional area and cross-sectional area of the apolar tails exceeds a certain threshold.",
        "context": "# 3.5: The Ripple Phase  \n\nLipids consist of hydrophilic polar head groups attached to hydrocarbon chains and arrange themselves in bilayers to make biological membrane structures. At lower temperatures, the bilayer is in a $L_{\\beta^{\\prime}}$ 'gel' phase and there is a transition to 'fluid' phase, $L_{\\alpha}$ at higher temperatures due to an increase in mobility of individual lipids in the bilayer. As the ripple phase $P_{\\beta^{\\prime}}$ is observed in hydrated lipid bilayers between the $L_{\\beta^{\\prime}}$ and $L_{\\alpha}$ phase. This phase is characterized by corrugations of the membrane surface with well-defined periodicity with an axis parallel to the mean bilayer plane [1]. The molecular origin of ripple-phase formation has traditionally been associated with the lipid headgroup region and hence lipids can be classified into ripple-forming and non-ripple forming lipids based on their headgroups. One of the lipid families belonging to the ripple-forming class is phosphatidyl cholines and has been studied in extensive detail [1].  \n\n![](images/8355e2b178c4a5a10a2369d125a83c599234bbae196b22efdb27023ee1729b61.jpg)  \nScheme above shows different physical states adopted by a lipid bilayer in an aqueous medium [2].  \n\n# Thermodynamics and Existence  \n\nThe existence of the ripple phase at first sight is paradoxical on thermodynamic grounds since it involves an apparent lowering of symmetry (from $L_{\\beta},$ to $P_{\\beta^{\\prime}}$) on increasing the temperature. Some models suggest that ripples exist because of periodic local spontaneous curvature in the lipid bilayers formed due to electrostatic coupling between water molecules and the polar headgroups or coupling between membrane curvature and molecular tilt. It has also been speculated that ripples form to relieve packing frustrations that arise whenever the relationship between head-group cross sectional area and cross-sectional area of the apolar tails exceeds a certain threshold [1]. However, there is not one conclusive theory to explain ripple phase formation.  \n\n# Phase Diagram Depicting Ripple Phase  \n\n![](images/d83e0991b12d29163da1f7c80d0c75798913c78f282681d8dd5eae07d8801d64.jpg)  \nConcentration (% $\\mathsf{H}_{2}\\mathsf{O})$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "It has also been speculated that ripples form to relieve packing frustrations that arise whenever the relationship between head-group cross sectional area and cross-sectional area of the apolar tails exceeds a certain threshold.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM92-Sequences_And_Series_In_Banach_Spaces1984.pdf_93",
        "ID": "036d10dd-a39a-48b3-840f-d34e2e004989",
        "questions": "What condition does each sequence $\\mu_{n}^{\\prime}$ satisfy in Phillips's Lemma?",
        "answers": "$\\lim_{n}\\mu_{n}(\\Delta)=0$ for each $\\Delta\\subseteq\\mathsf{N}$",
        "context": "Notice that\n\n$$\n|\\mu_{k_{p}}|\\Big({\\bigcup_{n}}E_{k_{n}}\\Big)+|\\mu_{k_{p}}|\\Big({\\bigcup_{n}}E_{n}{\\setminus}{\\bigcup_{n}}E_{k_{n}}\\Big)=|\\mu_{k_{p}}|\\Big({\\bigcup_{n}}E_{n}\\Big)\\leq1,\n$$\n\nwhich, since\n\n$$\n\\bigcup_{j\\neq k_{p}\\atop j\\in N_{p}}E_{j}\\subseteq\\bigcup_{n}E_{n}\\setminus\\bigcup_{n}E_{k_{n}},\n$$\n\ngives us\n\n$$\n|\\mu_{k_{p}}|\\bigg({\\bigcup_{n}}E_{k_{n}}\\bigg)\\le1-\\varepsilon\n$$\n\nfor all $p$\n\nRepeat the above argument starting this time with the sequences $\\mu_{n}^{\\prime}=\\mu_{k_{n}}$ and $E_{n}^{\\prime}=E_{k_{n}}$; our starting point now will be the inequality\n\n$$\n|\\mu_{n}^{\\prime}|\\left({\\bigcup_{n}E_{n}^{\\prime}}\\right)\\leq1-\\varepsilon.\n$$\n\nProceeding as above, either we arrive immediately at a suitable sub sequence or extract a sub sequence $(j_{k_{n}})$ of $(k_{n})$ for which another can be shaved off the right side of the above inequality making\n\n$$\n|\\mu_{j_{k_{p}}}|\\left({\\bigcup_{n}E_{j_{k_{n}}}}\\right)\\le1-2\\varepsilon\n$$\n\nhold for all $p$.\n\nWhatever the first $n$ is that makes $1-n\\varepsilon<0$, the above procedure must end satisfactorily by $n$ steps or face the possibility that $0\\leq1-n\\varepsilon<0,$\n\nFrom Rosenthal's lemma and the Nikodym-Grothendieck bounded ness theorem we derive another classic convergence theorem pertaining to $l_{\\infty}^{\\ast}$\n\nPhillips's Lemma. Let $\\mu_{n}\\in\\operatorname*{ba}(2^{\\mathsf{N}})$ satisfy $\\lim_{n}\\mu_{n}(\\Delta)=0$ for each $\\Delta\\subseteq\\mathsf{N}$ Then\n\n$$\n\\lim_{n}\\sum_{j}\\left|\\mu_{n}\\left(\\{j\\}\\right)\\right|=0.\n$$\n\nPROOF. The Nikodym-Grothendieck theorem tells us that $\\sup_{n}\\|\\mu_{n}\\|<\\infty$ and so the possibility of applying Rosenthal's lemma arises.\n\nWere the conclusion of Phillips's lemma not to hold, it would be because for some $\\delta>0$ and some subsequence [which we will still refer to as $\\left(\\mu_{n}\\right)]$ of $\\left(\\mu_{n}\\right)$ we have\n\n$$\n\\sum_{j}\\left|\\mu_{n}\\big(\\{j\\}\\big)\\right|\\geq6\\delta\n$$\n\nfor all $n$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Let $\\mu_{n}\\in\\operatorname*{ba}(2^{\\mathsf{N}})$ satisfy $\\lim_{n}\\mu_{n}(\\Delta)=0$ for each $\\Delta\\subseteq\\mathsf{N}$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM92-Sequences_And_Series_In_Banach_Spaces1984.pdf_93",
        "ID": "037d4e96-8504-4d9b-89a2-d95447914603",
        "questions": "What inequality is used as a starting point when repeating the argument with the sequences $\\mu_{n}^{\\prime}=\\mu_{k_{n}}$ and $E_{n}^{\\prime}=E_{k_{n}}$?",
        "answers": "$|\\mu_{n}^{\\prime}|\\left({\bigcup_{n}E_{n}^{\\prime}}\right)\\leq1-\u000barepsilon$",
        "context": "Notice that\n\n$$\n|\\mu_{k_{p}}|\\Big({\\bigcup_{n}}E_{k_{n}}\\Big)+|\\mu_{k_{p}}|\\Big({\\bigcup_{n}}E_{n}{\\setminus}{\\bigcup_{n}}E_{k_{n}}\\Big)=|\\mu_{k_{p}}|\\Big({\\bigcup_{n}}E_{n}\\Big)\\leq1,\n$$\n\nwhich, since\n\n$$\n\\bigcup_{j\\neq k_{p}\\atop j\\in N_{p}}E_{j}\\subseteq\\bigcup_{n}E_{n}\\setminus\\bigcup_{n}E_{k_{n}},\n$$\n\ngives us\n\n$$\n|\\mu_{k_{p}}|\\bigg({\\bigcup_{n}}E_{k_{n}}\\bigg)\\le1-\\varepsilon\n$$\n\nfor all $p$\n\nRepeat the above argument starting this time with the sequences $\\mu_{n}^{\\prime}=\\mu_{k_{n}}$ and $E_{n}^{\\prime}=E_{k_{n}}$; our starting point now will be the inequality\n\n$$\n|\\mu_{n}^{\\prime}|\\left({\\bigcup_{n}E_{n}^{\\prime}}\\right)\\leq1-\\varepsilon.\n$$\n\nProceeding as above, either we arrive immediately at a suitable sub sequence or extract a sub sequence $(j_{k_{n}})$ of $(k_{n})$ for which another can be shaved off the right side of the above inequality making\n\n$$\n|\\mu_{j_{k_{p}}}|\\left({\\bigcup_{n}E_{j_{k_{n}}}}\\right)\\le1-2\\varepsilon\n$$\n\nhold for all $p$.\n\nWhatever the first $n$ is that makes $1-n\\varepsilon<0$, the above procedure must end satisfactorily by $n$ steps or face the possibility that $0\\leq1-n\\varepsilon<0,$\n\nFrom Rosenthal's lemma and the Nikodym-Grothendieck bounded ness theorem we derive another classic convergence theorem pertaining to $l_{\\infty}^{\\ast}$\n\nPhillips's Lemma. Let $\\mu_{n}\\in\\operatorname*{ba}(2^{\\mathsf{N}})$ satisfy $\\lim_{n}\\mu_{n}(\\Delta)=0$ for each $\\Delta\\subseteq\\mathsf{N}$ Then\n\n$$\n\\lim_{n}\\sum_{j}\\left|\\mu_{n}\\left(\\{j\\}\\right)\\right|=0.\n$$\n\nPROOF. The Nikodym-Grothendieck theorem tells us that $\\sup_{n}\\|\\mu_{n}\\|<\\infty$ and so the possibility of applying Rosenthal's lemma arises.\n\nWere the conclusion of Phillips's lemma not to hold, it would be because for some $\\delta>0$ and some subsequence [which we will still refer to as $\\left(\\mu_{n}\\right)]$ of $\\left(\\mu_{n}\\right)$ we have\n\n$$\n\\sum_{j}\\left|\\mu_{n}\\big(\\{j\\}\\big)\\right|\\geq6\\delta\n$$\n\nfor all $n$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Equation",
        "evidence_source": "text",
        "evidence_context": "Repeat the above argument starting this time with the sequences $\\mu_{n}^{\\prime}=\\mu_{k_{n}}$ and $E_{n}^{\\prime}=E_{k_{n}}$; our starting point now will be the inequality $|\\mu_{n}^{\\prime}|\\left({\bigcup_{n}E_{n}^{\\prime}}\right)\\leq1-\u000barepsilon.$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM92-Sequences_And_Series_In_Banach_Spaces1984.pdf_93",
        "ID": "0383178c-6e09-4651-b8e0-882b2079645c",
        "questions": "What classical convergence theorem related to $l_{\\infty}^{\u0007st}$ is derived from Rosenthal's lemma and the Nikodym-Grothendieck boundedness theorem?",
        "answers": "Phillips's Lemma",
        "context": "Notice that\n\n$$\n|\\mu_{k_{p}}|\\Big({\\bigcup_{n}}E_{k_{n}}\\Big)+|\\mu_{k_{p}}|\\Big({\\bigcup_{n}}E_{n}{\\setminus}{\\bigcup_{n}}E_{k_{n}}\\Big)=|\\mu_{k_{p}}|\\Big({\\bigcup_{n}}E_{n}\\Big)\\leq1,\n$$\n\nwhich, since\n\n$$\n\\bigcup_{j\\neq k_{p}\\atop j\\in N_{p}}E_{j}\\subseteq\\bigcup_{n}E_{n}\\setminus\\bigcup_{n}E_{k_{n}},\n$$\n\ngives us\n\n$$\n|\\mu_{k_{p}}|\\bigg({\\bigcup_{n}}E_{k_{n}}\\bigg)\\le1-\\varepsilon\n$$\n\nfor all $p$\n\nRepeat the above argument starting this time with the sequences $\\mu_{n}^{\\prime}=\\mu_{k_{n}}$ and $E_{n}^{\\prime}=E_{k_{n}}$; our starting point now will be the inequality\n\n$$\n|\\mu_{n}^{\\prime}|\\left({\\bigcup_{n}E_{n}^{\\prime}}\\right)\\leq1-\\varepsilon.\n$$\n\nProceeding as above, either we arrive immediately at a suitable sub sequence or extract a sub sequence $(j_{k_{n}})$ of $(k_{n})$ for which another can be shaved off the right side of the above inequality making\n\n$$\n|\\mu_{j_{k_{p}}}|\\left({\\bigcup_{n}E_{j_{k_{n}}}}\\right)\\le1-2\\varepsilon\n$$\n\nhold for all $p$.\n\nWhatever the first $n$ is that makes $1-n\\varepsilon<0$, the above procedure must end satisfactorily by $n$ steps or face the possibility that $0\\leq1-n\\varepsilon<0,$\n\nFrom Rosenthal's lemma and the Nikodym-Grothendieck bounded ness theorem we derive another classic convergence theorem pertaining to $l_{\\infty}^{\\ast}$\n\nPhillips's Lemma. Let $\\mu_{n}\\in\\operatorname*{ba}(2^{\\mathsf{N}})$ satisfy $\\lim_{n}\\mu_{n}(\\Delta)=0$ for each $\\Delta\\subseteq\\mathsf{N}$ Then\n\n$$\n\\lim_{n}\\sum_{j}\\left|\\mu_{n}\\left(\\{j\\}\\right)\\right|=0.\n$$\n\nPROOF. The Nikodym-Grothendieck theorem tells us that $\\sup_{n}\\|\\mu_{n}\\|<\\infty$ and so the possibility of applying Rosenthal's lemma arises.\n\nWere the conclusion of Phillips's lemma not to hold, it would be because for some $\\delta>0$ and some subsequence [which we will still refer to as $\\left(\\mu_{n}\\right)]$ of $\\left(\\mu_{n}\\right)$ we have\n\n$$\n\\sum_{j}\\left|\\mu_{n}\\big(\\{j\\}\\big)\\right|\\geq6\\delta\n$$\n\nfor all $n$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "From Rosenthal's lemma and the Nikodym-Grothendieck bounded ness theorem we derive another classic convergence theorem pertaining to $l_{\\infty}^{\u0007st}$ Phillips's Lemma.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM92-Sequences_And_Series_In_Banach_Spaces1984.pdf_93",
        "ID": "03889405-0e8c-416f-bf76-f7c581f61e9a",
        "questions": "What is the equation that represents the condition on $\\mu_{k_{p}}$ and $\\bigcup_{n} E_{j_{k_{n}}}$ that holds for all $p$?",
        "answers": "$|\\mu_{j_{k_{p}}}|\\left({\\bigcup_{n}E_{j_{k_{n}}}}\\right)\\le1-2\\varepsilon$",
        "context": "Notice that\n\n$$\n|\\mu_{k_{p}}|\\Big({\\bigcup_{n}}E_{k_{n}}\\Big)+|\\mu_{k_{p}}|\\Big({\\bigcup_{n}}E_{n}{\\setminus}{\\bigcup_{n}}E_{k_{n}}\\Big)=|\\mu_{k_{p}}|\\Big({\\bigcup_{n}}E_{n}\\Big)\\leq1,\n$$\n\nwhich, since\n\n$$\n\\bigcup_{j\\neq k_{p}\\atop j\\in N_{p}}E_{j}\\subseteq\\bigcup_{n}E_{n}\\setminus\\bigcup_{n}E_{k_{n}},\n$$\n\ngives us\n\n$$\n|\\mu_{k_{p}}|\\bigg({\\bigcup_{n}}E_{k_{n}}\\bigg)\\le1-\\varepsilon\n$$\n\nfor all $p$\n\nRepeat the above argument starting this time with the sequences $\\mu_{n}^{\\prime}=\\mu_{k_{n}}$ and $E_{n}^{\\prime}=E_{k_{n}}$; our starting point now will be the inequality\n\n$$\n|\\mu_{n}^{\\prime}|\\left({\\bigcup_{n}E_{n}^{\\prime}}\\right)\\leq1-\\varepsilon.\n$$\n\nProceeding as above, either we arrive immediately at a suitable sub sequence or extract a sub sequence $(j_{k_{n}})$ of $(k_{n})$ for which another can be shaved off the right side of the above inequality making\n\n$$\n|\\mu_{j_{k_{p}}}|\\left({\\bigcup_{n}E_{j_{k_{n}}}}\\right)\\le1-2\\varepsilon\n$$\n\nhold for all $p$.\n\nWhatever the first $n$ is that makes $1-n\\varepsilon<0$, the above procedure must end satisfactorily by $n$ steps or face the possibility that $0\\leq1-n\\varepsilon<0,$\n\nFrom Rosenthal's lemma and the Nikodym-Grothendieck bounded ness theorem we derive another classic convergence theorem pertaining to $l_{\\infty}^{\\ast}$\n\nPhillips's Lemma. Let $\\mu_{n}\\in\\operatorname*{ba}(2^{\\mathsf{N}})$ satisfy $\\lim_{n}\\mu_{n}(\\Delta)=0$ for each $\\Delta\\subseteq\\mathsf{N}$ Then\n\n$$\n\\lim_{n}\\sum_{j}\\left|\\mu_{n}\\left(\\{j\\}\\right)\\right|=0.\n$$\n\nPROOF. The Nikodym-Grothendieck theorem tells us that $\\sup_{n}\\|\\mu_{n}\\|<\\infty$ and so the possibility of applying Rosenthal's lemma arises.\n\nWere the conclusion of Phillips's lemma not to hold, it would be because for some $\\delta>0$ and some subsequence [which we will still refer to as $\\left(\\mu_{n}\\right)]$ of $\\left(\\mu_{n}\\right)$ we have\n\n$$\n\\sum_{j}\\left|\\mu_{n}\\big(\\{j\\}\\big)\\right|\\geq6\\delta\n$$\n\nfor all $n$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$|\\mu_{j_{k_{p}}}|\\left({\\bigcup_{n}E_{j_{k_{n}}}}\\right)\\le1-2\\varepsilon$ hold for all $p$.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/GTM92-Sequences_And_Series_In_Banach_Spaces1984.pdf_93",
        "ID": "03927935-8d5f-42c0-83f0-ba7756b8002a",
        "questions": "What inequality is used as the starting point for sequences $\\mu_{n}^{\\prime}$ and $E_{n}^{\\prime}$?",
        "answers": "$|\\mu_{n}^{\\prime}|\\left({\\bigcup_{n}E_{n}^{\\prime}}\\right)\\leq1-\\varepsilon.$",
        "context": "Notice that\n\n$$\n|\\mu_{k_{p}}|\\Big({\\bigcup_{n}}E_{k_{n}}\\Big)+|\\mu_{k_{p}}|\\Big({\\bigcup_{n}}E_{n}{\\setminus}{\\bigcup_{n}}E_{k_{n}}\\Big)=|\\mu_{k_{p}}|\\Big({\\bigcup_{n}}E_{n}\\Big)\\leq1,\n$$\n\nwhich, since\n\n$$\n\\bigcup_{j\\neq k_{p}\\atop j\\in N_{p}}E_{j}\\subseteq\\bigcup_{n}E_{n}\\setminus\\bigcup_{n}E_{k_{n}},\n$$\n\ngives us\n\n$$\n|\\mu_{k_{p}}|\\bigg({\\bigcup_{n}}E_{k_{n}}\\bigg)\\le1-\\varepsilon\n$$\n\nfor all $p$\n\nRepeat the above argument starting this time with the sequences $\\mu_{n}^{\\prime}=\\mu_{k_{n}}$ and $E_{n}^{\\prime}=E_{k_{n}}$; our starting point now will be the inequality\n\n$$\n|\\mu_{n}^{\\prime}|\\left({\\bigcup_{n}E_{n}^{\\prime}}\\right)\\leq1-\\varepsilon.\n$$\n\nProceeding as above, either we arrive immediately at a suitable sub sequence or extract a sub sequence $(j_{k_{n}})$ of $(k_{n})$ for which another can be shaved off the right side of the above inequality making\n\n$$\n|\\mu_{j_{k_{p}}}|\\left({\\bigcup_{n}E_{j_{k_{n}}}}\\right)\\le1-2\\varepsilon\n$$\n\nhold for all $p$.\n\nWhatever the first $n$ is that makes $1-n\\varepsilon<0$, the above procedure must end satisfactorily by $n$ steps or face the possibility that $0\\leq1-n\\varepsilon<0,$\n\nFrom Rosenthal's lemma and the Nikodym-Grothendieck bounded ness theorem we derive another classic convergence theorem pertaining to $l_{\\infty}^{\\ast}$\n\nPhillips's Lemma. Let $\\mu_{n}\\in\\operatorname*{ba}(2^{\\mathsf{N}})$ satisfy $\\lim_{n}\\mu_{n}(\\Delta)=0$ for each $\\Delta\\subseteq\\mathsf{N}$ Then\n\n$$\n\\lim_{n}\\sum_{j}\\left|\\mu_{n}\\left(\\{j\\}\\right)\\right|=0.\n$$\n\nPROOF. The Nikodym-Grothendieck theorem tells us that $\\sup_{n}\\|\\mu_{n}\\|<\\infty$ and so the possibility of applying Rosenthal's lemma arises.\n\nWere the conclusion of Phillips's lemma not to hold, it would be because for some $\\delta>0$ and some subsequence [which we will still refer to as $\\left(\\mu_{n}\\right)]$ of $\\left(\\mu_{n}\\right)$ we have\n\n$$\n\\sum_{j}\\left|\\mu_{n}\\big(\\{j\\}\\big)\\right|\\geq6\\delta\n$$\n\nfor all $n$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "our starting point now will be the inequality $|\\mu_{n}^{\\prime}|\\left({\\bigcup_{n}E_{n}^{\\prime}}\\right)\\leq1-\\varepsilon.$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/GTM92-Sequences_And_Series_In_Banach_Spaces1984.pdf_93",
        "ID": "039d60ba-9c99-4735-95a6-52a708fce7af",
        "questions": "According to Phillips's Lemma, what is the condition on the limit of the sum involving $\\mu_{n}$ over $j$ for each subset $\\Delta$ of $\\mathsf{N}$?",
        "answers": "$\\lim_{n}\\sum_{j}\\left|\\mu_{n}\\left(\\{j\\}\\right)\\right|=0.$",
        "context": "Notice that\n\n$$\n|\\mu_{k_{p}}|\\Big({\\bigcup_{n}}E_{k_{n}}\\Big)+|\\mu_{k_{p}}|\\Big({\\bigcup_{n}}E_{n}{\\setminus}{\\bigcup_{n}}E_{k_{n}}\\Big)=|\\mu_{k_{p}}|\\Big({\\bigcup_{n}}E_{n}\\Big)\\leq1,\n$$\n\nwhich, since\n\n$$\n\\bigcup_{j\\neq k_{p}\\atop j\\in N_{p}}E_{j}\\subseteq\\bigcup_{n}E_{n}\\setminus\\bigcup_{n}E_{k_{n}},\n$$\n\ngives us\n\n$$\n|\\mu_{k_{p}}|\\bigg({\\bigcup_{n}}E_{k_{n}}\\bigg)\\le1-\\varepsilon\n$$\n\nfor all $p$\n\nRepeat the above argument starting this time with the sequences $\\mu_{n}^{\\prime}=\\mu_{k_{n}}$ and $E_{n}^{\\prime}=E_{k_{n}}$; our starting point now will be the inequality\n\n$$\n|\\mu_{n}^{\\prime}|\\left({\\bigcup_{n}E_{n}^{\\prime}}\\right)\\leq1-\\varepsilon.\n$$\n\nProceeding as above, either we arrive immediately at a suitable sub sequence or extract a sub sequence $(j_{k_{n}})$ of $(k_{n})$ for which another can be shaved off the right side of the above inequality making\n\n$$\n|\\mu_{j_{k_{p}}}|\\left({\\bigcup_{n}E_{j_{k_{n}}}}\\right)\\le1-2\\varepsilon\n$$\n\nhold for all $p$.\n\nWhatever the first $n$ is that makes $1-n\\varepsilon<0$, the above procedure must end satisfactorily by $n$ steps or face the possibility that $0\\leq1-n\\varepsilon<0,$\n\nFrom Rosenthal's lemma and the Nikodym-Grothendieck bounded ness theorem we derive another classic convergence theorem pertaining to $l_{\\infty}^{\\ast}$\n\nPhillips's Lemma. Let $\\mu_{n}\\in\\operatorname*{ba}(2^{\\mathsf{N}})$ satisfy $\\lim_{n}\\mu_{n}(\\Delta)=0$ for each $\\Delta\\subseteq\\mathsf{N}$ Then\n\n$$\n\\lim_{n}\\sum_{j}\\left|\\mu_{n}\\left(\\{j\\}\\right)\\right|=0.\n$$\n\nPROOF. The Nikodym-Grothendieck theorem tells us that $\\sup_{n}\\|\\mu_{n}\\|<\\infty$ and so the possibility of applying Rosenthal's lemma arises.\n\nWere the conclusion of Phillips's lemma not to hold, it would be because for some $\\delta>0$ and some subsequence [which we will still refer to as $\\left(\\mu_{n}\\right)]$ of $\\left(\\mu_{n}\\right)$ we have\n\n$$\n\\sum_{j}\\left|\\mu_{n}\\big(\\{j\\}\\big)\\right|\\geq6\\delta\n$$\n\nfor all $n$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Then $\\lim_{n}\\sum_{j}\\left|\\mu_{n}\\left(\\{j\\}\\right)\\right|=0.$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/2021_NEC_Economic_Notes.pdf_23",
        "ID": "03a5fab2-a04d-4ed4-be56-ed9f507de9cf",
        "questions": "What happens to unemployment and price levels during a contraction lasting more than two quarters?",
        "answers": "Unemployment increases and price levels slow and may fall.",
        "context": "Contraction - real GDP begins to fall. If there is a contraction for more than two quarters, there is a recession. Real GDP falls and unemployment increases. Price levels slow and may fall down.  \n\nTrough - cycle's minimum real GDP, end of contraction. Wide spread unemployment followed by expansion (recovery).  \n\nSometimes called economic fluctuations because they are not predictable.  \n\n# #TRENDS  \n\nLong-term growth trend - the straight line that shows how output grows when the fluctuations are removed. The output is known as the potential output.  \n\nUnemployment falls when real GDP grows (expansion). Firms hire more labor and increase quantity of output.  \n\nUnemployment increases when real GDP falls (contraction). Firms cut production and have to fire some workers.  \n\nWhen an economy experiences full employment, there is still a natural rate of unemployment.  \n\nIf actual GDP $>$ potential GDP, unemployment is lower than the natural rate. If potential GDP $>$ actual GDP, unemployment is greater than the natural rate.  \n\nThere is a GDP (output) gap if the actual GDP is above/below the potential GDP.  \n\n# REASONS TO STUDY CYCLE  \n\nReal output growth means that there's a chance to have higher standards of living.  \n\nLarge fluctuations are not desirable, because with expansion, inflation could happen and with a contraction, unemployment increases.  \n\nSome key macroeconomic objectives: rapid economic growth, full employment, and price stability.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Real GDP falls and unemployment increases. Price levels slow and may fall down.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/2021_NEC_Economic_Notes.pdf_23",
        "ID": "03a7590a-b25c-49a3-adbc-59fe47c2e637",
        "questions": "What is the term used to describe the cycle's minimum real GDP?",
        "answers": "Trough",
        "context": "Contraction - real GDP begins to fall. If there is a contraction for more than two quarters, there is a recession. Real GDP falls and unemployment increases. Price levels slow and may fall down.  \n\nTrough - cycle's minimum real GDP, end of contraction. Wide spread unemployment followed by expansion (recovery).  \n\nSometimes called economic fluctuations because they are not predictable.  \n\n# #TRENDS  \n\nLong-term growth trend - the straight line that shows how output grows when the fluctuations are removed. The output is known as the potential output.  \n\nUnemployment falls when real GDP grows (expansion). Firms hire more labor and increase quantity of output.  \n\nUnemployment increases when real GDP falls (contraction). Firms cut production and have to fire some workers.  \n\nWhen an economy experiences full employment, there is still a natural rate of unemployment.  \n\nIf actual GDP $>$ potential GDP, unemployment is lower than the natural rate. If potential GDP $>$ actual GDP, unemployment is greater than the natural rate.  \n\nThere is a GDP (output) gap if the actual GDP is above/below the potential GDP.  \n\n# REASONS TO STUDY CYCLE  \n\nReal output growth means that there's a chance to have higher standards of living.  \n\nLarge fluctuations are not desirable, because with expansion, inflation could happen and with a contraction, unemployment increases.  \n\nSome key macroeconomic objectives: rapid economic growth, full employment, and price stability.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Trough - cycle's minimum real GDP, end of contraction.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/2021_NEC_Economic_Notes.pdf_23",
        "ID": "03a89879-36a9-4d74-80de-59f550f0fc2b",
        "questions": "What results in an unemployment rate lower than the natural rate: actual GDP being higher than potential GDP, or potential GDP being higher than actual GDP?",
        "answers": "Actual GDP being higher than potential GDP.",
        "context": "Contraction - real GDP begins to fall. If there is a contraction for more than two quarters, there is a recession. Real GDP falls and unemployment increases. Price levels slow and may fall down.  \n\nTrough - cycle's minimum real GDP, end of contraction. Wide spread unemployment followed by expansion (recovery).  \n\nSometimes called economic fluctuations because they are not predictable.  \n\n# #TRENDS  \n\nLong-term growth trend - the straight line that shows how output grows when the fluctuations are removed. The output is known as the potential output.  \n\nUnemployment falls when real GDP grows (expansion). Firms hire more labor and increase quantity of output.  \n\nUnemployment increases when real GDP falls (contraction). Firms cut production and have to fire some workers.  \n\nWhen an economy experiences full employment, there is still a natural rate of unemployment.  \n\nIf actual GDP $>$ potential GDP, unemployment is lower than the natural rate. If potential GDP $>$ actual GDP, unemployment is greater than the natural rate.  \n\nThere is a GDP (output) gap if the actual GDP is above/below the potential GDP.  \n\n# REASONS TO STUDY CYCLE  \n\nReal output growth means that there's a chance to have higher standards of living.  \n\nLarge fluctuations are not desirable, because with expansion, inflation could happen and with a contraction, unemployment increases.  \n\nSome key macroeconomic objectives: rapid economic growth, full employment, and price stability.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "If actual GDP $>$ potential GDP, unemployment is lower than the natural rate.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/textbook_needrop_en_1574",
        "ID": "03aa88ef-0678-43d5-9805-3e4845aff4b8",
        "questions": "What does the Grothendieck-Riemann-Roch theorem express the Chern classes of the Hodge bundle as?",
        "answers": "A polynomial (with rational coefficients) in the tautological classes.",
        "context": "which of course is no surprise. Next, we have  \n\n$$\nc_{1}(\\Lambda)=\\mathrm{ch}_{1}(\\Lambda)=\\pi_{*}\\left(\\frac{\\gamma}{2}\\right)=\\frac{\\kappa}{12}\\,,\n$$  \n\nwhere  $\\kappa\\,=\\,\\kappa_{1}$  is the first tautological class. Similarly, to find  $\\mathrm{ch}_{2}(\\Lambda)$  we write  \n\n$$\nc_{2}(\\Lambda)=\\frac{\\mathrm{ch}_{1}(\\Lambda)^{2}}{2}-\\mathrm{ch}_{2}(\\Lambda)=\\frac{\\kappa^{2}}{288}\n$$  \n\nsince  $\\mathrm{ch}_{2}(\\Lambda)=0$  In general, it's clear that the Grothendieck-Riemann-Roch theorem in this case expresses each of the Chern classes of the Hodge bundle as a polynomial (with rational coefficients) in the tautological classes  $\\kappa_{i}$  , and that the polynomial may be worked out explicitly in any given case. Note in particular that, while the  $\\lambda_{i}$  are polynomials in the  $\\kappa_{i}$  , the above examples already show that the converse is not true.  \n\nNext, we consider how this computation\u2014at least in the case of the codimension 1 classes in  $\\overline{{\\mathcal{M}}}_{g}$  \u2014may be extended over all of the stable compactification  $\\overline{{\\mathcal{M}}}_{g}$  . Here we'll see the discussion of Section D used in practice. First of all, to define our terms, we will denote by  $\\omega$  the relative dualizing sheaf of  $\\overline{{\\mathcal{C}}}_{g}$  over  $\\overline{{\\mathcal{M}}}_{g}$  , and call the direct image  $\\pi_{*}\\omega$  on  $\\overline{{\\mathcal{M}}}_{g}$  the Hodge bundle  $\\Lambda$  . Note that the problem we were able to gloss over above has now become more serious: the universal curve now fails to be universal over a codimension 1 locus (all the points  $[C]\\,\\in\\,\\Delta_{1}\\,\\subset\\,{\\overline{{\\mathcal{M}}}}_{g}$  correspond to curves with automorphisms). But now we have an alternative: by Proposition (3.93), in order to derive or prove any relation among divisor classes on the moduli space we simply have to verify the corresponding relation among the associated divisor classes on the base  $B$  of any family  $x{\\xrightarrow{}}B$  of stable curves with smooth, one-dimensional base and smooth general fiber.  \n\nTo do this, let  $\\rho:\\mathcal{X}{\\rightarrow}B$  be any such one-parameter family of stable curves. We will use  $t$  to denote a local coordinate on the base  $B$  of the family. We make one modification: we let  $\\mu:y\\!\\to\\!x$  be a minimal resolution of the singularities of the total space  $x$  , and let  $\\nu=\\rho\\!\\circ\\!\\mu:y{\\rightarrow}B$  be the composition. This has the effect, for each node  $p$  of a fiber of  $x\\!\\to\\!B$  with local coordinates  $x,y,t$  satisfying  $x y=t^{k}$  , of replacing the point  $p$  by a chain of  $k-1$  rational curves. In this way we arrive at a family  $\\nu:\\mathcal{Y}{\\xrightarrow{}}B$  of semi-stable curves, with smooth total space and having  $k$  nodes lying over each node of a fiber of  $x$  with local equation  $x y-t^{k}$  . To relate the invariants of the new family  $\\nu:\\mathcal{Y}\\!\\!\\xrightarrow{}\\!\\!B$  to those of the original, we have the:  \n\nExercise (3.108) 1 Show that the relative dualizing sheaf of the new family is trivial on the exceptional divisor of the map  $\\mu$  , and hence that it's simply the pullback of the relative dualizing sheaf of  $\\rho:\\mathcal{X}\\!\\to\\!B$ ,i.e.,  \n\n$$\n\\begin{array}{r}{\\omega_{Y/B}=\\mu^{*}\\omega_{X/B}.}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "In general, it's clear that the Grothendieck-Riemann-Roch theorem in this case expresses each of the Chern classes of the Hodge bundle as a polynomial (with rational coefficients) in the tautological classes $\\kappa_{i}$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/textbook_needrop_en_1574",
        "ID": "03aca477-4254-4fad-abb7-4d12b350b84b",
        "questions": "In the computation for codimension 1 classes on the stable compactification of the moduli space, what issue arises concerning the universal curve?",
        "answers": "The universal curve now fails to be universal over a codimension 1 locus.",
        "context": "which of course is no surprise. Next, we have  \n\n$$\nc_{1}(\\Lambda)=\\mathrm{ch}_{1}(\\Lambda)=\\pi_{*}\\left(\\frac{\\gamma}{2}\\right)=\\frac{\\kappa}{12}\\,,\n$$  \n\nwhere  $\\kappa\\,=\\,\\kappa_{1}$  is the first tautological class. Similarly, to find  $\\mathrm{ch}_{2}(\\Lambda)$  we write  \n\n$$\nc_{2}(\\Lambda)=\\frac{\\mathrm{ch}_{1}(\\Lambda)^{2}}{2}-\\mathrm{ch}_{2}(\\Lambda)=\\frac{\\kappa^{2}}{288}\n$$  \n\nsince  $\\mathrm{ch}_{2}(\\Lambda)=0$  In general, it's clear that the Grothendieck-Riemann-Roch theorem in this case expresses each of the Chern classes of the Hodge bundle as a polynomial (with rational coefficients) in the tautological classes  $\\kappa_{i}$  , and that the polynomial may be worked out explicitly in any given case. Note in particular that, while the  $\\lambda_{i}$  are polynomials in the  $\\kappa_{i}$  , the above examples already show that the converse is not true.  \n\nNext, we consider how this computation\u2014at least in the case of the codimension 1 classes in  $\\overline{{\\mathcal{M}}}_{g}$  \u2014may be extended over all of the stable compactification  $\\overline{{\\mathcal{M}}}_{g}$  . Here we'll see the discussion of Section D used in practice. First of all, to define our terms, we will denote by  $\\omega$  the relative dualizing sheaf of  $\\overline{{\\mathcal{C}}}_{g}$  over  $\\overline{{\\mathcal{M}}}_{g}$  , and call the direct image  $\\pi_{*}\\omega$  on  $\\overline{{\\mathcal{M}}}_{g}$  the Hodge bundle  $\\Lambda$  . Note that the problem we were able to gloss over above has now become more serious: the universal curve now fails to be universal over a codimension 1 locus (all the points  $[C]\\,\\in\\,\\Delta_{1}\\,\\subset\\,{\\overline{{\\mathcal{M}}}}_{g}$  correspond to curves with automorphisms). But now we have an alternative: by Proposition (3.93), in order to derive or prove any relation among divisor classes on the moduli space we simply have to verify the corresponding relation among the associated divisor classes on the base  $B$  of any family  $x{\\xrightarrow{}}B$  of stable curves with smooth, one-dimensional base and smooth general fiber.  \n\nTo do this, let  $\\rho:\\mathcal{X}{\\rightarrow}B$  be any such one-parameter family of stable curves. We will use  $t$  to denote a local coordinate on the base  $B$  of the family. We make one modification: we let  $\\mu:y\\!\\to\\!x$  be a minimal resolution of the singularities of the total space  $x$  , and let  $\\nu=\\rho\\!\\circ\\!\\mu:y{\\rightarrow}B$  be the composition. This has the effect, for each node  $p$  of a fiber of  $x\\!\\to\\!B$  with local coordinates  $x,y,t$  satisfying  $x y=t^{k}$  , of replacing the point  $p$  by a chain of  $k-1$  rational curves. In this way we arrive at a family  $\\nu:\\mathcal{Y}{\\xrightarrow{}}B$  of semi-stable curves, with smooth total space and having  $k$  nodes lying over each node of a fiber of  $x$  with local equation  $x y-t^{k}$  . To relate the invariants of the new family  $\\nu:\\mathcal{Y}\\!\\!\\xrightarrow{}\\!\\!B$  to those of the original, we have the:  \n\nExercise (3.108) 1 Show that the relative dualizing sheaf of the new family is trivial on the exceptional divisor of the map  $\\mu$  , and hence that it's simply the pullback of the relative dualizing sheaf of  $\\rho:\\mathcal{X}\\!\\to\\!B$ ,i.e.,  \n\n$$\n\\begin{array}{r}{\\omega_{Y/B}=\\mu^{*}\\omega_{X/B}.}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Note that the problem we were able to gloss over above has now become more serious: the universal curve now fails to be universal over a codimension 1 locus.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/textbook_needrop_en_1574",
        "ID": "03b5cdd7-b367-4684-ad76-fa6341761cbe",
        "questions": "According to Exercise (3.108), what is the relationship between the relative dualizing sheaf of the family with the map $\\mu$ and the sheaf of $\rho:\\mathcal{X}\to B$?",
        "answers": "It's simply the pullback of the relative dualizing sheaf of $\rho:\\mathcal{X}\to B$.",
        "context": "which of course is no surprise. Next, we have  \n\n$$\nc_{1}(\\Lambda)=\\mathrm{ch}_{1}(\\Lambda)=\\pi_{*}\\left(\\frac{\\gamma}{2}\\right)=\\frac{\\kappa}{12}\\,,\n$$  \n\nwhere  $\\kappa\\,=\\,\\kappa_{1}$  is the first tautological class. Similarly, to find  $\\mathrm{ch}_{2}(\\Lambda)$  we write  \n\n$$\nc_{2}(\\Lambda)=\\frac{\\mathrm{ch}_{1}(\\Lambda)^{2}}{2}-\\mathrm{ch}_{2}(\\Lambda)=\\frac{\\kappa^{2}}{288}\n$$  \n\nsince  $\\mathrm{ch}_{2}(\\Lambda)=0$  In general, it's clear that the Grothendieck-Riemann-Roch theorem in this case expresses each of the Chern classes of the Hodge bundle as a polynomial (with rational coefficients) in the tautological classes  $\\kappa_{i}$  , and that the polynomial may be worked out explicitly in any given case. Note in particular that, while the  $\\lambda_{i}$  are polynomials in the  $\\kappa_{i}$  , the above examples already show that the converse is not true.  \n\nNext, we consider how this computation\u2014at least in the case of the codimension 1 classes in  $\\overline{{\\mathcal{M}}}_{g}$  \u2014may be extended over all of the stable compactification  $\\overline{{\\mathcal{M}}}_{g}$  . Here we'll see the discussion of Section D used in practice. First of all, to define our terms, we will denote by  $\\omega$  the relative dualizing sheaf of  $\\overline{{\\mathcal{C}}}_{g}$  over  $\\overline{{\\mathcal{M}}}_{g}$  , and call the direct image  $\\pi_{*}\\omega$  on  $\\overline{{\\mathcal{M}}}_{g}$  the Hodge bundle  $\\Lambda$  . Note that the problem we were able to gloss over above has now become more serious: the universal curve now fails to be universal over a codimension 1 locus (all the points  $[C]\\,\\in\\,\\Delta_{1}\\,\\subset\\,{\\overline{{\\mathcal{M}}}}_{g}$  correspond to curves with automorphisms). But now we have an alternative: by Proposition (3.93), in order to derive or prove any relation among divisor classes on the moduli space we simply have to verify the corresponding relation among the associated divisor classes on the base  $B$  of any family  $x{\\xrightarrow{}}B$  of stable curves with smooth, one-dimensional base and smooth general fiber.  \n\nTo do this, let  $\\rho:\\mathcal{X}{\\rightarrow}B$  be any such one-parameter family of stable curves. We will use  $t$  to denote a local coordinate on the base  $B$  of the family. We make one modification: we let  $\\mu:y\\!\\to\\!x$  be a minimal resolution of the singularities of the total space  $x$  , and let  $\\nu=\\rho\\!\\circ\\!\\mu:y{\\rightarrow}B$  be the composition. This has the effect, for each node  $p$  of a fiber of  $x\\!\\to\\!B$  with local coordinates  $x,y,t$  satisfying  $x y=t^{k}$  , of replacing the point  $p$  by a chain of  $k-1$  rational curves. In this way we arrive at a family  $\\nu:\\mathcal{Y}{\\xrightarrow{}}B$  of semi-stable curves, with smooth total space and having  $k$  nodes lying over each node of a fiber of  $x$  with local equation  $x y-t^{k}$  . To relate the invariants of the new family  $\\nu:\\mathcal{Y}\\!\\!\\xrightarrow{}\\!\\!B$  to those of the original, we have the:  \n\nExercise (3.108) 1 Show that the relative dualizing sheaf of the new family is trivial on the exceptional divisor of the map  $\\mu$  , and hence that it's simply the pullback of the relative dualizing sheaf of  $\\rho:\\mathcal{X}\\!\\to\\!B$ ,i.e.,  \n\n$$\n\\begin{array}{r}{\\omega_{Y/B}=\\mu^{*}\\omega_{X/B}.}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Exercise (3.108) 1 Show that the relative dualizing sheaf of the new family is trivial on the exceptional divisor of the map $\\mu$, and hence that it's simply the pullback of the relative dualizing sheaf of $\rho:\\mathcal{X}\to\\!B$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/textbook_needrop_en_1574",
        "ID": "03bfd4bd-07bc-466a-b996-cda3dbc960f6",
        "questions": "What is the expression for the first Chern class $c_{1}(\\Lambda)$ of the Hodge bundle in terms of the tautological class $\\kappa_1$?",
        "answers": "$c_{1}(\\Lambda)=\\\\frac{\\\\kappa}{12}$",
        "context": "which of course is no surprise. Next, we have  \n\n$$\nc_{1}(\\Lambda)=\\mathrm{ch}_{1}(\\Lambda)=\\pi_{*}\\left(\\frac{\\gamma}{2}\\right)=\\frac{\\kappa}{12}\\,,\n$$  \n\nwhere  $\\kappa\\,=\\,\\kappa_{1}$  is the first tautological class. Similarly, to find  $\\mathrm{ch}_{2}(\\Lambda)$  we write  \n\n$$\nc_{2}(\\Lambda)=\\frac{\\mathrm{ch}_{1}(\\Lambda)^{2}}{2}-\\mathrm{ch}_{2}(\\Lambda)=\\frac{\\kappa^{2}}{288}\n$$  \n\nsince  $\\mathrm{ch}_{2}(\\Lambda)=0$  In general, it's clear that the Grothendieck-Riemann-Roch theorem in this case expresses each of the Chern classes of the Hodge bundle as a polynomial (with rational coefficients) in the tautological classes  $\\kappa_{i}$  , and that the polynomial may be worked out explicitly in any given case. Note in particular that, while the  $\\lambda_{i}$  are polynomials in the  $\\kappa_{i}$  , the above examples already show that the converse is not true.  \n\nNext, we consider how this computation\u2014at least in the case of the codimension 1 classes in  $\\overline{{\\mathcal{M}}}_{g}$  \u2014may be extended over all of the stable compactification  $\\overline{{\\mathcal{M}}}_{g}$  . Here we'll see the discussion of Section D used in practice. First of all, to define our terms, we will denote by  $\\omega$  the relative dualizing sheaf of  $\\overline{{\\mathcal{C}}}_{g}$  over  $\\overline{{\\mathcal{M}}}_{g}$  , and call the direct image  $\\pi_{*}\\omega$  on  $\\overline{{\\mathcal{M}}}_{g}$  the Hodge bundle  $\\Lambda$  . Note that the problem we were able to gloss over above has now become more serious: the universal curve now fails to be universal over a codimension 1 locus (all the points  $[C]\\,\\in\\,\\Delta_{1}\\,\\subset\\,{\\overline{{\\mathcal{M}}}}_{g}$  correspond to curves with automorphisms). But now we have an alternative: by Proposition (3.93), in order to derive or prove any relation among divisor classes on the moduli space we simply have to verify the corresponding relation among the associated divisor classes on the base  $B$  of any family  $x{\\xrightarrow{}}B$  of stable curves with smooth, one-dimensional base and smooth general fiber.  \n\nTo do this, let  $\\rho:\\mathcal{X}{\\rightarrow}B$  be any such one-parameter family of stable curves. We will use  $t$  to denote a local coordinate on the base  $B$  of the family. We make one modification: we let  $\\mu:y\\!\\to\\!x$  be a minimal resolution of the singularities of the total space  $x$  , and let  $\\nu=\\rho\\!\\circ\\!\\mu:y{\\rightarrow}B$  be the composition. This has the effect, for each node  $p$  of a fiber of  $x\\!\\to\\!B$  with local coordinates  $x,y,t$  satisfying  $x y=t^{k}$  , of replacing the point  $p$  by a chain of  $k-1$  rational curves. In this way we arrive at a family  $\\nu:\\mathcal{Y}{\\xrightarrow{}}B$  of semi-stable curves, with smooth total space and having  $k$  nodes lying over each node of a fiber of  $x$  with local equation  $x y-t^{k}$  . To relate the invariants of the new family  $\\nu:\\mathcal{Y}\\!\\!\\xrightarrow{}\\!\\!B$  to those of the original, we have the:  \n\nExercise (3.108) 1 Show that the relative dualizing sheaf of the new family is trivial on the exceptional divisor of the map  $\\mu$  , and hence that it's simply the pullback of the relative dualizing sheaf of  $\\rho:\\mathcal{X}\\!\\to\\!B$ ,i.e.,  \n\n$$\n\\begin{array}{r}{\\omega_{Y/B}=\\mu^{*}\\omega_{X/B}.}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$c_{1}(\\\\Lambda)=\\\\mathrm{ch}_{1}(\\\\Lambda)=\\\\pi_{*}\\\\left(\\\\frac{\\\\gamma}{2}\\\\right)=\\\\frac{\\\\kappa}{12}\\\\,,$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/textbook_needrop_en_1574",
        "ID": "03c54c71-fca0-4536-a169-df82b9bdee2d",
        "questions": "What is the relationship between $c_{2}(\\Lambda)$, $\\mathrm{ch}_{1}(\\Lambda)$, and $\\mathrm{ch}_{2}(\\Lambda)$ in terms of the tautological class $\\kappa$?",
        "answers": "$c_{2}(\\\\Lambda)=\\\\frac{\\\\mathrm{ch}_{1}(\\\\Lambda)^{2}}{2}-\\\\mathrm{ch}_{2}(\\\\Lambda)=\\\\frac{\\\\kappa^{2}}{288}$",
        "context": "which of course is no surprise. Next, we have  \n\n$$\nc_{1}(\\Lambda)=\\mathrm{ch}_{1}(\\Lambda)=\\pi_{*}\\left(\\frac{\\gamma}{2}\\right)=\\frac{\\kappa}{12}\\,,\n$$  \n\nwhere  $\\kappa\\,=\\,\\kappa_{1}$  is the first tautological class. Similarly, to find  $\\mathrm{ch}_{2}(\\Lambda)$  we write  \n\n$$\nc_{2}(\\Lambda)=\\frac{\\mathrm{ch}_{1}(\\Lambda)^{2}}{2}-\\mathrm{ch}_{2}(\\Lambda)=\\frac{\\kappa^{2}}{288}\n$$  \n\nsince  $\\mathrm{ch}_{2}(\\Lambda)=0$  In general, it's clear that the Grothendieck-Riemann-Roch theorem in this case expresses each of the Chern classes of the Hodge bundle as a polynomial (with rational coefficients) in the tautological classes  $\\kappa_{i}$  , and that the polynomial may be worked out explicitly in any given case. Note in particular that, while the  $\\lambda_{i}$  are polynomials in the  $\\kappa_{i}$  , the above examples already show that the converse is not true.  \n\nNext, we consider how this computation\u2014at least in the case of the codimension 1 classes in  $\\overline{{\\mathcal{M}}}_{g}$  \u2014may be extended over all of the stable compactification  $\\overline{{\\mathcal{M}}}_{g}$  . Here we'll see the discussion of Section D used in practice. First of all, to define our terms, we will denote by  $\\omega$  the relative dualizing sheaf of  $\\overline{{\\mathcal{C}}}_{g}$  over  $\\overline{{\\mathcal{M}}}_{g}$  , and call the direct image  $\\pi_{*}\\omega$  on  $\\overline{{\\mathcal{M}}}_{g}$  the Hodge bundle  $\\Lambda$  . Note that the problem we were able to gloss over above has now become more serious: the universal curve now fails to be universal over a codimension 1 locus (all the points  $[C]\\,\\in\\,\\Delta_{1}\\,\\subset\\,{\\overline{{\\mathcal{M}}}}_{g}$  correspond to curves with automorphisms). But now we have an alternative: by Proposition (3.93), in order to derive or prove any relation among divisor classes on the moduli space we simply have to verify the corresponding relation among the associated divisor classes on the base  $B$  of any family  $x{\\xrightarrow{}}B$  of stable curves with smooth, one-dimensional base and smooth general fiber.  \n\nTo do this, let  $\\rho:\\mathcal{X}{\\rightarrow}B$  be any such one-parameter family of stable curves. We will use  $t$  to denote a local coordinate on the base  $B$  of the family. We make one modification: we let  $\\mu:y\\!\\to\\!x$  be a minimal resolution of the singularities of the total space  $x$  , and let  $\\nu=\\rho\\!\\circ\\!\\mu:y{\\rightarrow}B$  be the composition. This has the effect, for each node  $p$  of a fiber of  $x\\!\\to\\!B$  with local coordinates  $x,y,t$  satisfying  $x y=t^{k}$  , of replacing the point  $p$  by a chain of  $k-1$  rational curves. In this way we arrive at a family  $\\nu:\\mathcal{Y}{\\xrightarrow{}}B$  of semi-stable curves, with smooth total space and having  $k$  nodes lying over each node of a fiber of  $x$  with local equation  $x y-t^{k}$  . To relate the invariants of the new family  $\\nu:\\mathcal{Y}\\!\\!\\xrightarrow{}\\!\\!B$  to those of the original, we have the:  \n\nExercise (3.108) 1 Show that the relative dualizing sheaf of the new family is trivial on the exceptional divisor of the map  $\\mu$  , and hence that it's simply the pullback of the relative dualizing sheaf of  $\\rho:\\mathcal{X}\\!\\to\\!B$ ,i.e.,  \n\n$$\n\\begin{array}{r}{\\omega_{Y/B}=\\mu^{*}\\omega_{X/B}.}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$c_{2}(\\\\Lambda)=\\\\frac{\\\\mathrm{ch}_{1}(\\\\Lambda)^{2}}{2}-\\\\mathrm{ch}_{2}(\\\\Lambda)=\\\\frac{\\\\kappa^{2}}{288}$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/textbook_needrop_en_1574",
        "ID": "03c6a61a-537c-42e8-9697-9b20517e0427",
        "questions": "What is the expression for the relative dualizing sheaf of the family $\\nu:\\mathcal{Y} \\xrightarrow{} B$ in relation to the map $\\mu$?",
        "answers": "$\\\\omega_{Y/B}=\\\\mu^{*}\\\\omega_{X/B}$",
        "context": "which of course is no surprise. Next, we have  \n\n$$\nc_{1}(\\Lambda)=\\mathrm{ch}_{1}(\\Lambda)=\\pi_{*}\\left(\\frac{\\gamma}{2}\\right)=\\frac{\\kappa}{12}\\,,\n$$  \n\nwhere  $\\kappa\\,=\\,\\kappa_{1}$  is the first tautological class. Similarly, to find  $\\mathrm{ch}_{2}(\\Lambda)$  we write  \n\n$$\nc_{2}(\\Lambda)=\\frac{\\mathrm{ch}_{1}(\\Lambda)^{2}}{2}-\\mathrm{ch}_{2}(\\Lambda)=\\frac{\\kappa^{2}}{288}\n$$  \n\nsince  $\\mathrm{ch}_{2}(\\Lambda)=0$  In general, it's clear that the Grothendieck-Riemann-Roch theorem in this case expresses each of the Chern classes of the Hodge bundle as a polynomial (with rational coefficients) in the tautological classes  $\\kappa_{i}$  , and that the polynomial may be worked out explicitly in any given case. Note in particular that, while the  $\\lambda_{i}$  are polynomials in the  $\\kappa_{i}$  , the above examples already show that the converse is not true.  \n\nNext, we consider how this computation\u2014at least in the case of the codimension 1 classes in  $\\overline{{\\mathcal{M}}}_{g}$  \u2014may be extended over all of the stable compactification  $\\overline{{\\mathcal{M}}}_{g}$  . Here we'll see the discussion of Section D used in practice. First of all, to define our terms, we will denote by  $\\omega$  the relative dualizing sheaf of  $\\overline{{\\mathcal{C}}}_{g}$  over  $\\overline{{\\mathcal{M}}}_{g}$  , and call the direct image  $\\pi_{*}\\omega$  on  $\\overline{{\\mathcal{M}}}_{g}$  the Hodge bundle  $\\Lambda$  . Note that the problem we were able to gloss over above has now become more serious: the universal curve now fails to be universal over a codimension 1 locus (all the points  $[C]\\,\\in\\,\\Delta_{1}\\,\\subset\\,{\\overline{{\\mathcal{M}}}}_{g}$  correspond to curves with automorphisms). But now we have an alternative: by Proposition (3.93), in order to derive or prove any relation among divisor classes on the moduli space we simply have to verify the corresponding relation among the associated divisor classes on the base  $B$  of any family  $x{\\xrightarrow{}}B$  of stable curves with smooth, one-dimensional base and smooth general fiber.  \n\nTo do this, let  $\\rho:\\mathcal{X}{\\rightarrow}B$  be any such one-parameter family of stable curves. We will use  $t$  to denote a local coordinate on the base  $B$  of the family. We make one modification: we let  $\\mu:y\\!\\to\\!x$  be a minimal resolution of the singularities of the total space  $x$  , and let  $\\nu=\\rho\\!\\circ\\!\\mu:y{\\rightarrow}B$  be the composition. This has the effect, for each node  $p$  of a fiber of  $x\\!\\to\\!B$  with local coordinates  $x,y,t$  satisfying  $x y=t^{k}$  , of replacing the point  $p$  by a chain of  $k-1$  rational curves. In this way we arrive at a family  $\\nu:\\mathcal{Y}{\\xrightarrow{}}B$  of semi-stable curves, with smooth total space and having  $k$  nodes lying over each node of a fiber of  $x$  with local equation  $x y-t^{k}$  . To relate the invariants of the new family  $\\nu:\\mathcal{Y}\\!\\!\\xrightarrow{}\\!\\!B$  to those of the original, we have the:  \n\nExercise (3.108) 1 Show that the relative dualizing sheaf of the new family is trivial on the exceptional divisor of the map  $\\mu$  , and hence that it's simply the pullback of the relative dualizing sheaf of  $\\rho:\\mathcal{X}\\!\\to\\!B$ ,i.e.,  \n\n$$\n\\begin{array}{r}{\\omega_{Y/B}=\\mu^{*}\\omega_{X/B}.}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "${\\\\omega_{Y/B}=\\\\mu^{*}\\\\omega_{X/B}.}$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/GTM231-Combinatorics_of_Coxeter_Groups2005.pdf_191",
        "ID": "03ca7fc9-eabb-4e02-b222-c94934301ab4",
        "questions": "What is the defining property of the alternating representation in terms of the Kazhdan-Lusztig basis?",
        "answers": "$K L_{\\{w_{0}\\}}=\\varepsilon,$",
        "context": "and all remaining irreducibles are of degree 2 (see, e.g., [358, pp. 65-66]). However, $I_{2}(m)$ always has exactly four left cells, see Exercise 1.\n\nIt is easy to see that $\\{e\\}$ and $\\{w_{0}\\}$ are left (and right) cells and that they give the trivial representation.\n\n$$\nK L_{\\{e\\}}=1\n$$\n\nand the alternating representation\n\n$$\nK L_{\\{w_{0}\\}}=\\varepsilon,\n$$\n\ndefined by $\\varepsilon(w)=(-1)^{\\ell(w)}$ (cf. Lemma 1.4.1). We will frequently write $\\varepsilon_{w}$ instead of $\\varepsilon(w)$.\n\nThe $w_{0}$ -induced symmetries have the following effect on Kazhdan-Lusztig representations.\n\nProposition 6.3.5 Let $\\mathcal{C}$ be a left cell. Then, the following hold:\n\n(i) $K L_{\\mathcal{C}w_{0}}\\cong\\varepsilon\\,K L_{\\mathcal{C}}$\n\n(ii) $K L_{w_{0}c}\\cong\\varepsilon K L_{\\mathcal{C}}$\n\n(iii) $K L_{w_{0}cw_{0}}\\cong K L_{\\mathcal{C}}$\n\nProof. We begin with part (i). The key fact is that $\\widetilde\\Gamma_{\\mathcal{C}w_{0}}$ is obtained from $\\widetilde\\Gamma_{\\mathcal{C}}$ by reversing the direction of all arrows, keeping their color $s$ and weight $\\overline{{\\mu}}$ except that the $\\pm1$ weights on loops are switched (cf. Proposition 6.2.9(ii)). This implies on the character level that\n\n$$\nK L_{\\mathcal{C}w_{0}}(x)=\\varepsilon_{x}\\,K L_{\\mathcal{C}}(x^{-1}),\n$$\n\nfor all $x\\in W$; namely the trace of $A_{\\mathcal{C}w_{0}}(x)$ is the sum of the weights of all directed circuits in $\\widetilde\\Gamma_{\\mathcal{C}w_{0}}$ beginning and ending in some $y\\in\\mathcal{C}w_{0}$ and whose color sequence is $\\left(s_{1},s_{2},\\ldots,s_{k}\\right)$ for some fixed expression $x\\,=\\,s_{1}s_{2}\\,.\\,.\\,.\\,s_{k}$. Similarly, $K L_{\\mathcal{C}}(x^{-1})$ is the sum of the weights of directed circuits in $\\tilde{\\Gamma}_{\\mathcal{C}}$ whose color sequence is $(s_{k},s_{k-1},.~.~.~,s_{1})$. By the previous remark, these quantities are equal, except possibly for the sign. Whether the sign will change depends on the distribution of the number of $(+1)$-labeled and $(-1)$-labeled loops traversed. However, since $\\widetilde\\Gamma_{(W,S)}$ without its loops is a bipartite graph (edges connect elements of even length with elements of odd length), and hence every circuit with its loops removed is of even length, a change of sign will take place for each individual path if and only if $k$ is odd (i.e., if $\\varepsilon_{x}=-1$).\n\nNow use that\n\n$$\nK L_{\\mathcal{C}}(x^{-1})=\\overline{K L_{\\mathcal{C}}(x)}=K L_{\\mathcal{C}}(x),\n$$\n\nwhere the last equality is true because the matrices, and hence character values, are real. Consequently, the characters agree, and part (i) is proved.\n\nFor part (ii), one observes (using Proposition 6.2.9(i)) that $\\tilde{\\Gamma}_{w_{0}c w_{0}}$ is obtained from $\\tilde{\\Gamma}_{\\mathcal{C}}$ by applying the operator $x\\ \\mapsto\\ w_{0}x w_{0}$ to all nodes.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "and the alternating representation $$K L_{\\{w_{0}\\}}=\\varepsilon,$$ defined by \\varepsilon(w)=(-1)^{\\ell(w)} (cf. Lemma 1.4.1).",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM231-Combinatorics_of_Coxeter_Groups2005.pdf_191",
        "ID": "03cc8bf9-6862-403f-b55d-aee71f2ba3e9",
        "questions": "In the context of Proposition 6.3.5, how is $K L_{\\mathcal{C}w_{0}}$ characteristically related to $K L_{\\mathcal{C}}$?",
        "answers": "K L_{\\mathcal{C}w_{0}}(x)=\\varepsilon_{x}\\,K L_{\\mathcal{C}}(x^{-1}),",
        "context": "and all remaining irreducibles are of degree 2 (see, e.g., [358, pp. 65-66]). However, $I_{2}(m)$ always has exactly four left cells, see Exercise 1.\n\nIt is easy to see that $\\{e\\}$ and $\\{w_{0}\\}$ are left (and right) cells and that they give the trivial representation.\n\n$$\nK L_{\\{e\\}}=1\n$$\n\nand the alternating representation\n\n$$\nK L_{\\{w_{0}\\}}=\\varepsilon,\n$$\n\ndefined by $\\varepsilon(w)=(-1)^{\\ell(w)}$ (cf. Lemma 1.4.1). We will frequently write $\\varepsilon_{w}$ instead of $\\varepsilon(w)$.\n\nThe $w_{0}$ -induced symmetries have the following effect on Kazhdan-Lusztig representations.\n\nProposition 6.3.5 Let $\\mathcal{C}$ be a left cell. Then, the following hold:\n\n(i) $K L_{\\mathcal{C}w_{0}}\\cong\\varepsilon\\,K L_{\\mathcal{C}}$\n\n(ii) $K L_{w_{0}c}\\cong\\varepsilon K L_{\\mathcal{C}}$\n\n(iii) $K L_{w_{0}cw_{0}}\\cong K L_{\\mathcal{C}}$\n\nProof. We begin with part (i). The key fact is that $\\widetilde\\Gamma_{\\mathcal{C}w_{0}}$ is obtained from $\\widetilde\\Gamma_{\\mathcal{C}}$ by reversing the direction of all arrows, keeping their color $s$ and weight $\\overline{{\\mu}}$ except that the $\\pm1$ weights on loops are switched (cf. Proposition 6.2.9(ii)). This implies on the character level that\n\n$$\nK L_{\\mathcal{C}w_{0}}(x)=\\varepsilon_{x}\\,K L_{\\mathcal{C}}(x^{-1}),\n$$\n\nfor all $x\\in W$; namely the trace of $A_{\\mathcal{C}w_{0}}(x)$ is the sum of the weights of all directed circuits in $\\widetilde\\Gamma_{\\mathcal{C}w_{0}}$ beginning and ending in some $y\\in\\mathcal{C}w_{0}$ and whose color sequence is $\\left(s_{1},s_{2},\\ldots,s_{k}\\right)$ for some fixed expression $x\\,=\\,s_{1}s_{2}\\,.\\,.\\,.\\,s_{k}$. Similarly, $K L_{\\mathcal{C}}(x^{-1})$ is the sum of the weights of directed circuits in $\\tilde{\\Gamma}_{\\mathcal{C}}$ whose color sequence is $(s_{k},s_{k-1},.~.~.~,s_{1})$. By the previous remark, these quantities are equal, except possibly for the sign. Whether the sign will change depends on the distribution of the number of $(+1)$-labeled and $(-1)$-labeled loops traversed. However, since $\\widetilde\\Gamma_{(W,S)}$ without its loops is a bipartite graph (edges connect elements of even length with elements of odd length), and hence every circuit with its loops removed is of even length, a change of sign will take place for each individual path if and only if $k$ is odd (i.e., if $\\varepsilon_{x}=-1$).\n\nNow use that\n\n$$\nK L_{\\mathcal{C}}(x^{-1})=\\overline{K L_{\\mathcal{C}}(x)}=K L_{\\mathcal{C}}(x),\n$$\n\nwhere the last equality is true because the matrices, and hence character values, are real. Consequently, the characters agree, and part (i) is proved.\n\nFor part (ii), one observes (using Proposition 6.2.9(i)) that $\\tilde{\\Gamma}_{w_{0}c w_{0}}$ is obtained from $\\tilde{\\Gamma}_{\\mathcal{C}}$ by applying the operator $x\\ \\mapsto\\ w_{0}x w_{0}$ to all nodes.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "This implies on the character level that $$K L_{\\mathcal{C}w_{0}}(x)=\\varepsilon_{x}\\,K L_{\\mathcal{C}}(x^{-1}),$$ for all $x\\in W$;",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM231-Combinatorics_of_Coxeter_Groups2005.pdf_191",
        "ID": "03cd3231-7948-44ae-beb6-533abca281f1",
        "questions": "Does the bipartite nature of the graph $\\widetilde\\Gamma_{(W,S)}$ without loops impact the change of sign in the character expression for Proposition 6.3.5, and under what condition?",
        "answers": "Yes, a change of sign will take place for each individual path if and only if $k$ is odd (i.e., if $\\varepsilon_{x}=-1$).",
        "context": "and all remaining irreducibles are of degree 2 (see, e.g., [358, pp. 65-66]). However, $I_{2}(m)$ always has exactly four left cells, see Exercise 1.\n\nIt is easy to see that $\\{e\\}$ and $\\{w_{0}\\}$ are left (and right) cells and that they give the trivial representation.\n\n$$\nK L_{\\{e\\}}=1\n$$\n\nand the alternating representation\n\n$$\nK L_{\\{w_{0}\\}}=\\varepsilon,\n$$\n\ndefined by $\\varepsilon(w)=(-1)^{\\ell(w)}$ (cf. Lemma 1.4.1). We will frequently write $\\varepsilon_{w}$ instead of $\\varepsilon(w)$.\n\nThe $w_{0}$ -induced symmetries have the following effect on Kazhdan-Lusztig representations.\n\nProposition 6.3.5 Let $\\mathcal{C}$ be a left cell. Then, the following hold:\n\n(i) $K L_{\\mathcal{C}w_{0}}\\cong\\varepsilon\\,K L_{\\mathcal{C}}$\n\n(ii) $K L_{w_{0}c}\\cong\\varepsilon K L_{\\mathcal{C}}$\n\n(iii) $K L_{w_{0}cw_{0}}\\cong K L_{\\mathcal{C}}$\n\nProof. We begin with part (i). The key fact is that $\\widetilde\\Gamma_{\\mathcal{C}w_{0}}$ is obtained from $\\widetilde\\Gamma_{\\mathcal{C}}$ by reversing the direction of all arrows, keeping their color $s$ and weight $\\overline{{\\mu}}$ except that the $\\pm1$ weights on loops are switched (cf. Proposition 6.2.9(ii)). This implies on the character level that\n\n$$\nK L_{\\mathcal{C}w_{0}}(x)=\\varepsilon_{x}\\,K L_{\\mathcal{C}}(x^{-1}),\n$$\n\nfor all $x\\in W$; namely the trace of $A_{\\mathcal{C}w_{0}}(x)$ is the sum of the weights of all directed circuits in $\\widetilde\\Gamma_{\\mathcal{C}w_{0}}$ beginning and ending in some $y\\in\\mathcal{C}w_{0}$ and whose color sequence is $\\left(s_{1},s_{2},\\ldots,s_{k}\\right)$ for some fixed expression $x\\,=\\,s_{1}s_{2}\\,.\\,.\\,.\\,s_{k}$. Similarly, $K L_{\\mathcal{C}}(x^{-1})$ is the sum of the weights of directed circuits in $\\tilde{\\Gamma}_{\\mathcal{C}}$ whose color sequence is $(s_{k},s_{k-1},.~.~.~,s_{1})$. By the previous remark, these quantities are equal, except possibly for the sign. Whether the sign will change depends on the distribution of the number of $(+1)$-labeled and $(-1)$-labeled loops traversed. However, since $\\widetilde\\Gamma_{(W,S)}$ without its loops is a bipartite graph (edges connect elements of even length with elements of odd length), and hence every circuit with its loops removed is of even length, a change of sign will take place for each individual path if and only if $k$ is odd (i.e., if $\\varepsilon_{x}=-1$).\n\nNow use that\n\n$$\nK L_{\\mathcal{C}}(x^{-1})=\\overline{K L_{\\mathcal{C}}(x)}=K L_{\\mathcal{C}}(x),\n$$\n\nwhere the last equality is true because the matrices, and hence character values, are real. Consequently, the characters agree, and part (i) is proved.\n\nFor part (ii), one observes (using Proposition 6.2.9(i)) that $\\tilde{\\Gamma}_{w_{0}c w_{0}}$ is obtained from $\\tilde{\\Gamma}_{\\mathcal{C}}$ by applying the operator $x\\ \\mapsto\\ w_{0}x w_{0}$ to all nodes.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Yes/No",
        "evidence_source": "text",
        "evidence_context": "a change of sign will take place for each individual path if and only if $k$ is odd (i.e., if $\\varepsilon_{x}=-1$).",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM231-Combinatorics_of_Coxeter_Groups2005.pdf_191",
        "ID": "03d03575-54bb-48bd-8e8b-1b517a0cd3b5",
        "questions": "What is the value of $K L_{\\{e\\}}$?",
        "answers": "1",
        "context": "and all remaining irreducibles are of degree 2 (see, e.g., [358, pp. 65-66]). However, $I_{2}(m)$ always has exactly four left cells, see Exercise 1.\n\nIt is easy to see that $\\{e\\}$ and $\\{w_{0}\\}$ are left (and right) cells and that they give the trivial representation.\n\n$$\nK L_{\\{e\\}}=1\n$$\n\nand the alternating representation\n\n$$\nK L_{\\{w_{0}\\}}=\\varepsilon,\n$$\n\ndefined by $\\varepsilon(w)=(-1)^{\\ell(w)}$ (cf. Lemma 1.4.1). We will frequently write $\\varepsilon_{w}$ instead of $\\varepsilon(w)$.\n\nThe $w_{0}$ -induced symmetries have the following effect on Kazhdan-Lusztig representations.\n\nProposition 6.3.5 Let $\\mathcal{C}$ be a left cell. Then, the following hold:\n\n(i) $K L_{\\mathcal{C}w_{0}}\\cong\\varepsilon\\,K L_{\\mathcal{C}}$\n\n(ii) $K L_{w_{0}c}\\cong\\varepsilon K L_{\\mathcal{C}}$\n\n(iii) $K L_{w_{0}cw_{0}}\\cong K L_{\\mathcal{C}}$\n\nProof. We begin with part (i). The key fact is that $\\widetilde\\Gamma_{\\mathcal{C}w_{0}}$ is obtained from $\\widetilde\\Gamma_{\\mathcal{C}}$ by reversing the direction of all arrows, keeping their color $s$ and weight $\\overline{{\\mu}}$ except that the $\\pm1$ weights on loops are switched (cf. Proposition 6.2.9(ii)). This implies on the character level that\n\n$$\nK L_{\\mathcal{C}w_{0}}(x)=\\varepsilon_{x}\\,K L_{\\mathcal{C}}(x^{-1}),\n$$\n\nfor all $x\\in W$; namely the trace of $A_{\\mathcal{C}w_{0}}(x)$ is the sum of the weights of all directed circuits in $\\widetilde\\Gamma_{\\mathcal{C}w_{0}}$ beginning and ending in some $y\\in\\mathcal{C}w_{0}$ and whose color sequence is $\\left(s_{1},s_{2},\\ldots,s_{k}\\right)$ for some fixed expression $x\\,=\\,s_{1}s_{2}\\,.\\,.\\,.\\,s_{k}$. Similarly, $K L_{\\mathcal{C}}(x^{-1})$ is the sum of the weights of directed circuits in $\\tilde{\\Gamma}_{\\mathcal{C}}$ whose color sequence is $(s_{k},s_{k-1},.~.~.~,s_{1})$. By the previous remark, these quantities are equal, except possibly for the sign. Whether the sign will change depends on the distribution of the number of $(+1)$-labeled and $(-1)$-labeled loops traversed. However, since $\\widetilde\\Gamma_{(W,S)}$ without its loops is a bipartite graph (edges connect elements of even length with elements of odd length), and hence every circuit with its loops removed is of even length, a change of sign will take place for each individual path if and only if $k$ is odd (i.e., if $\\varepsilon_{x}=-1$).\n\nNow use that\n\n$$\nK L_{\\mathcal{C}}(x^{-1})=\\overline{K L_{\\mathcal{C}}(x)}=K L_{\\mathcal{C}}(x),\n$$\n\nwhere the last equality is true because the matrices, and hence character values, are real. Consequently, the characters agree, and part (i) is proved.\n\nFor part (ii), one observes (using Proposition 6.2.9(i)) that $\\tilde{\\Gamma}_{w_{0}c w_{0}}$ is obtained from $\\tilde{\\Gamma}_{\\mathcal{C}}$ by applying the operator $x\\ \\mapsto\\ w_{0}x w_{0}$ to all nodes.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Numeric",
        "evidence_source": "equation",
        "evidence_context": "$$ K L_{\\{e\\}}=1 $$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/GTM231-Combinatorics_of_Coxeter_Groups2005.pdf_191",
        "ID": "03d820d3-a3aa-4c06-b050-c7df142fa639",
        "questions": "What is the value of $K L_{\\{w_{0}\\}}$ given $K L_{\\{w_{0}\\}}$ is defined by $\u000barepsilon(w)=(-1)^{\\ell(w)}$?",
        "answers": "$\\varepsilon$",
        "context": "and all remaining irreducibles are of degree 2 (see, e.g., [358, pp. 65-66]). However, $I_{2}(m)$ always has exactly four left cells, see Exercise 1.\n\nIt is easy to see that $\\{e\\}$ and $\\{w_{0}\\}$ are left (and right) cells and that they give the trivial representation.\n\n$$\nK L_{\\{e\\}}=1\n$$\n\nand the alternating representation\n\n$$\nK L_{\\{w_{0}\\}}=\\varepsilon,\n$$\n\ndefined by $\\varepsilon(w)=(-1)^{\\ell(w)}$ (cf. Lemma 1.4.1). We will frequently write $\\varepsilon_{w}$ instead of $\\varepsilon(w)$.\n\nThe $w_{0}$ -induced symmetries have the following effect on Kazhdan-Lusztig representations.\n\nProposition 6.3.5 Let $\\mathcal{C}$ be a left cell. Then, the following hold:\n\n(i) $K L_{\\mathcal{C}w_{0}}\\cong\\varepsilon\\,K L_{\\mathcal{C}}$\n\n(ii) $K L_{w_{0}c}\\cong\\varepsilon K L_{\\mathcal{C}}$\n\n(iii) $K L_{w_{0}cw_{0}}\\cong K L_{\\mathcal{C}}$\n\nProof. We begin with part (i). The key fact is that $\\widetilde\\Gamma_{\\mathcal{C}w_{0}}$ is obtained from $\\widetilde\\Gamma_{\\mathcal{C}}$ by reversing the direction of all arrows, keeping their color $s$ and weight $\\overline{{\\mu}}$ except that the $\\pm1$ weights on loops are switched (cf. Proposition 6.2.9(ii)). This implies on the character level that\n\n$$\nK L_{\\mathcal{C}w_{0}}(x)=\\varepsilon_{x}\\,K L_{\\mathcal{C}}(x^{-1}),\n$$\n\nfor all $x\\in W$; namely the trace of $A_{\\mathcal{C}w_{0}}(x)$ is the sum of the weights of all directed circuits in $\\widetilde\\Gamma_{\\mathcal{C}w_{0}}$ beginning and ending in some $y\\in\\mathcal{C}w_{0}$ and whose color sequence is $\\left(s_{1},s_{2},\\ldots,s_{k}\\right)$ for some fixed expression $x\\,=\\,s_{1}s_{2}\\,.\\,.\\,.\\,s_{k}$. Similarly, $K L_{\\mathcal{C}}(x^{-1})$ is the sum of the weights of directed circuits in $\\tilde{\\Gamma}_{\\mathcal{C}}$ whose color sequence is $(s_{k},s_{k-1},.~.~.~,s_{1})$. By the previous remark, these quantities are equal, except possibly for the sign. Whether the sign will change depends on the distribution of the number of $(+1)$-labeled and $(-1)$-labeled loops traversed. However, since $\\widetilde\\Gamma_{(W,S)}$ without its loops is a bipartite graph (edges connect elements of even length with elements of odd length), and hence every circuit with its loops removed is of even length, a change of sign will take place for each individual path if and only if $k$ is odd (i.e., if $\\varepsilon_{x}=-1$).\n\nNow use that\n\n$$\nK L_{\\mathcal{C}}(x^{-1})=\\overline{K L_{\\mathcal{C}}(x)}=K L_{\\mathcal{C}}(x),\n$$\n\nwhere the last equality is true because the matrices, and hence character values, are real. Consequently, the characters agree, and part (i) is proved.\n\nFor part (ii), one observes (using Proposition 6.2.9(i)) that $\\tilde{\\Gamma}_{w_{0}c w_{0}}$ is obtained from $\\tilde{\\Gamma}_{\\mathcal{C}}$ by applying the operator $x\\ \\mapsto\\ w_{0}x w_{0}$ to all nodes.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$$ K L_{\\{w_{0}\\}}=\\varepsilon, $$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/GTM231-Combinatorics_of_Coxeter_Groups2005.pdf_191",
        "ID": "03e645b9-a24e-45ed-9651-823f1f0e68c0",
        "questions": "According to Proposition 6.3.5, what is the character level effect of $K L_{\\mathcal{C}w_{0}}$ on $\\varepsilon_{x}$ and $K L_{\\mathcal{C}}(x^{-1})$ for all $x \\in W$?",
        "answers": "$K L_{\\mathcal{C}w_{0}}(x)=\\varepsilon_{x}\\,K L_{\\mathcal{C}}(x^{-1})$",
        "context": "and all remaining irreducibles are of degree 2 (see, e.g., [358, pp. 65-66]). However, $I_{2}(m)$ always has exactly four left cells, see Exercise 1.\n\nIt is easy to see that $\\{e\\}$ and $\\{w_{0}\\}$ are left (and right) cells and that they give the trivial representation.\n\n$$\nK L_{\\{e\\}}=1\n$$\n\nand the alternating representation\n\n$$\nK L_{\\{w_{0}\\}}=\\varepsilon,\n$$\n\ndefined by $\\varepsilon(w)=(-1)^{\\ell(w)}$ (cf. Lemma 1.4.1). We will frequently write $\\varepsilon_{w}$ instead of $\\varepsilon(w)$.\n\nThe $w_{0}$ -induced symmetries have the following effect on Kazhdan-Lusztig representations.\n\nProposition 6.3.5 Let $\\mathcal{C}$ be a left cell. Then, the following hold:\n\n(i) $K L_{\\mathcal{C}w_{0}}\\cong\\varepsilon\\,K L_{\\mathcal{C}}$\n\n(ii) $K L_{w_{0}c}\\cong\\varepsilon K L_{\\mathcal{C}}$\n\n(iii) $K L_{w_{0}cw_{0}}\\cong K L_{\\mathcal{C}}$\n\nProof. We begin with part (i). The key fact is that $\\widetilde\\Gamma_{\\mathcal{C}w_{0}}$ is obtained from $\\widetilde\\Gamma_{\\mathcal{C}}$ by reversing the direction of all arrows, keeping their color $s$ and weight $\\overline{{\\mu}}$ except that the $\\pm1$ weights on loops are switched (cf. Proposition 6.2.9(ii)). This implies on the character level that\n\n$$\nK L_{\\mathcal{C}w_{0}}(x)=\\varepsilon_{x}\\,K L_{\\mathcal{C}}(x^{-1}),\n$$\n\nfor all $x\\in W$; namely the trace of $A_{\\mathcal{C}w_{0}}(x)$ is the sum of the weights of all directed circuits in $\\widetilde\\Gamma_{\\mathcal{C}w_{0}}$ beginning and ending in some $y\\in\\mathcal{C}w_{0}$ and whose color sequence is $\\left(s_{1},s_{2},\\ldots,s_{k}\\right)$ for some fixed expression $x\\,=\\,s_{1}s_{2}\\,.\\,.\\,.\\,s_{k}$. Similarly, $K L_{\\mathcal{C}}(x^{-1})$ is the sum of the weights of directed circuits in $\\tilde{\\Gamma}_{\\mathcal{C}}$ whose color sequence is $(s_{k},s_{k-1},.~.~.~,s_{1})$. By the previous remark, these quantities are equal, except possibly for the sign. Whether the sign will change depends on the distribution of the number of $(+1)$-labeled and $(-1)$-labeled loops traversed. However, since $\\widetilde\\Gamma_{(W,S)}$ without its loops is a bipartite graph (edges connect elements of even length with elements of odd length), and hence every circuit with its loops removed is of even length, a change of sign will take place for each individual path if and only if $k$ is odd (i.e., if $\\varepsilon_{x}=-1$).\n\nNow use that\n\n$$\nK L_{\\mathcal{C}}(x^{-1})=\\overline{K L_{\\mathcal{C}}(x)}=K L_{\\mathcal{C}}(x),\n$$\n\nwhere the last equality is true because the matrices, and hence character values, are real. Consequently, the characters agree, and part (i) is proved.\n\nFor part (ii), one observes (using Proposition 6.2.9(i)) that $\\tilde{\\Gamma}_{w_{0}c w_{0}}$ is obtained from $\\tilde{\\Gamma}_{\\mathcal{C}}$ by applying the operator $x\\ \\mapsto\\ w_{0}x w_{0}$ to all nodes.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$$ K L_{\\mathcal{C}w_{0}}(x)=\\varepsilon_{x}\\,K L_{\\mathcal{C}}(x^{-1}), $$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/Groups_And_Symmetry(Armstrong).pdf_74",
        "ID": "03ee36c3-2b3f-419f-bba9-fbb0d8c6827b",
        "questions": "What is the result of conjugating a translation by the vector \u03c4(\u27e8\u27e9) with an orthogonal transformation \u03c6?",
        "answers": "Translation by the vector \u03c6(\u03c4(\u27e8\u27e9)).",
        "context": "![](images/ba5e76bb3bcbf92f754b17d2d674748057b6bae1c954e706ed415add558f9999.jpg)  \nFigure 24.2  \n\n$$\n\\begin{array}{r l}&{\\tau_{1}\\tau_{2}^{-1}(\\mathbf{x})=\\tau_{1}((-\\mathbf{v})+\\mathbf{x})}\\\\ &{\\qquad\\qquad\\qquad=\\mathbf{u}+((-\\mathbf{v})+\\mathbf{x})}\\\\ &{\\qquad\\qquad\\qquad=(\\mathbf{u}-\\mathbf{v})+\\mathbf{x}.}\\end{array}\n$$  \n\nSo $\\tau_{1}\\tau_{2}^{-1}$ is translation by $\\mathbf{u}-\\mathbf{v}$ and therefore belongs to $T$. Let $O$ denote the subgroup of $E_{2}$ which consists of the orthogonal transformations. In other words, the elements of $O$ are rotations about the origin and reflections in lines through the origin. The discussion in the previous paragraph shows that $E_{2}=T O$.\n\nThe intersection of $T$ and $O$ is just the identity transformation because every non-trivial translation moves the origin, whereas every element of $O$ keeps the origin fixed. The usual argument now shows that each isometry can be written in only one way as an orthogonal transformation followed by a translation. For if $g=\\tau f=\\tau^{\\prime}f^{\\prime}$ where $\\tau, \\tau^{\\prime}\\in T$ and $f,f^{\\prime}\\in O$, then $(\\tau^{\\prime})^{-1}\\tau=f^{\\prime}f^{-1}$ lies in $T\\cap O$ and hence $\\tau=\\tau^{\\prime}, f=f^{\\prime}$. If $g=\\tau f$ and if $f$ is a rotation, then $g$ is called a direct isometry. In the other case, when $f$ is a reflection, $g$ is said to be an opposite isometry.\n\nSuppose $f\\in O, \\tau\\in T$ and $\\tau(\\mathbf{0})=\\mathbf{v}$. Then for each $\\mathbf{x}\\in\\mathbb{R}^{2}$ we have  \n\n$$\n\\begin{array}{r l}&{f\\tau f^{-1}(\\mathbf{x})=f(\\mathbf{v}+f^{-1}(\\mathbf{x}))}\\\\ &{\\qquad\\qquad=f(\\mathbf{v})+f(f^{-1}(\\mathbf{x}))\\qquad\\mathrm{because~}f\\mathrm{~is~linear~}}\\\\ &{\\qquad\\qquad=f(\\mathbf{v})+\\mathbf{x}.}\\end{array}\n$$  \n\nTherefore the conjugate $f\\tau f^{-1}$ is translation by the vector $f(\\mathbf{v})$. Since the elements of $T$ and $O$ together generate $E_{2}$, we see (using (15.2)) that $T$ is a normal subgroup of $E_{2}$.\n\nWe can now understand the product structure of our group in terms of the decomposition $E_{2}=T O$. If $g=\\tau f, h=\\tau_{1}f_{1}$ where $\\tau, \\tau_{1}\\in T$ and $f, f_{1}\\in O$, then\n\n$$\ngh=\\tau f\\tau_{1}f_{1}=(\\tau f\\tau_{1}f^{-1})(ff_{1})\n$$  \n\nexpresses $gh$ as an orthogonal transformation followed by a translation. Put another way, the correspondence  \n\n$$\ng\\rightarrow(\\tau,f)\n$$  \n\nis an isomorphism between $E_{2}$ and the semi-direct product $T\\times_{\\varphi}O$ where $\\varphi\\colon O\\to\\mathrm{Aut}(T)$ is given by conjugation.\n\nSpecific calculations are best carried out using rather different notation. Suppose $g=\\tau f$ where $\\tau\\in T$ and $f\\in O$. If $\\mathbf{v}=\\tau(\\mathbf{0})$, and if $M$ is the orthogonal matrix which represents $f$ in the standard basis for $\\mathbb{R}^{2}$, then  \n\n$$\ng(\\mathbf{x})=\\mathbf{v}+f_{M}(\\mathbf{x})=\\mathbf{v}+\\mathbf{x}M^{t}\n$$  \n\nfor all $\\mathbf{x}\\in\\mathbb{R}^{2}$. Conversely, given $\\mathbf{v}\\in\\mathbb{R}^{2}$ and $M\\in O_{2}$, the formula $(*)$ determines an isometry of the plane. We may therefore think of each isometry as an ordered pair $(\\mathbf{v},M)$ in which $\\mathbf{v}\\in\\mathbb{R}^{2}$ and $M\\in O_{2}$, with multiplication given by  \n\n$$\n({\\bf v},M)({\\bf v}_{1},M_{1})=({\\bf v}+f_{M}({\\bf v}_{1}),M M_{1}).\n$$  \n\nIf we are pressed to be very precise, we explain that we have identified $E_{2}$ with the semi-direct product $\\mathbb{R}^{2}\\times_{\\psi}O_{2}$, the homomorphism $\\psi:O_{2}\\to\\mathrm{Aut}(\\mathbb{R}^{2})$ being the usual action of $O_{2}$ on $\\mathbb{R}^{2}$. Notice that $(\\mathbf{v},M)$ is a direct isometry when det $M=+1$ and an opposite isometry when det $M=-1$.\n\nThe \"simplest\" isometries are easily described as ordered pairs. Let  \n\n$$\nA={\\left[\\!\\!\\begin{array}{l l l}{\\cos\\theta}&{}&{-\\sin\\theta}\\\\ {\\sin\\theta}&{}&{\\cos\\theta}\\end{array}\\!\\!\\right]},\\qquad B={\\left[\\!\\!\\begin{array}{l l l}{\\cos\\varphi}&{}&{\\sin\\varphi}\\\\ {\\sin\\varphi}&{}&{-\\cos\\varphi}\\end{array}\\!\\!\\right]}\n$$  \n\nand let $l, m$ be the lines shown in Figure 24.3.\n\n![](images/e55ee17f1fdd570c65059d6754f7488b3426174223d35b91e0be7d71223a487b.jpg)  \nFigure 24.3",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Therefore the conjugate \\( f\tau f^{-1} \\) is translation by the vector \\( f(\\mathbf{v}) \\).",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Groups_And_Symmetry(Armstrong).pdf_74",
        "ID": "03f7ba05-cf4b-4315-a325-4d812bdfb727",
        "questions": "What is the determinant condition for a direct isometry in the isomorphism $E_{2}$ with the semi-direct product $\\mathbb{R}^{2}\times_{\\psi}O_{2}$?",
        "answers": "The determinant of \\( M \\) must be \\( +1 \\).",
        "context": "![](images/ba5e76bb3bcbf92f754b17d2d674748057b6bae1c954e706ed415add558f9999.jpg)  \nFigure 24.2  \n\n$$\n\\begin{array}{r l}&{\\tau_{1}\\tau_{2}^{-1}(\\mathbf{x})=\\tau_{1}((-\\mathbf{v})+\\mathbf{x})}\\\\ &{\\qquad\\qquad\\qquad=\\mathbf{u}+((-\\mathbf{v})+\\mathbf{x})}\\\\ &{\\qquad\\qquad\\qquad=(\\mathbf{u}-\\mathbf{v})+\\mathbf{x}.}\\end{array}\n$$  \n\nSo $\\tau_{1}\\tau_{2}^{-1}$ is translation by $\\mathbf{u}-\\mathbf{v}$ and therefore belongs to $T$. Let $O$ denote the subgroup of $E_{2}$ which consists of the orthogonal transformations. In other words, the elements of $O$ are rotations about the origin and reflections in lines through the origin. The discussion in the previous paragraph shows that $E_{2}=T O$.\n\nThe intersection of $T$ and $O$ is just the identity transformation because every non-trivial translation moves the origin, whereas every element of $O$ keeps the origin fixed. The usual argument now shows that each isometry can be written in only one way as an orthogonal transformation followed by a translation. For if $g=\\tau f=\\tau^{\\prime}f^{\\prime}$ where $\\tau, \\tau^{\\prime}\\in T$ and $f,f^{\\prime}\\in O$, then $(\\tau^{\\prime})^{-1}\\tau=f^{\\prime}f^{-1}$ lies in $T\\cap O$ and hence $\\tau=\\tau^{\\prime}, f=f^{\\prime}$. If $g=\\tau f$ and if $f$ is a rotation, then $g$ is called a direct isometry. In the other case, when $f$ is a reflection, $g$ is said to be an opposite isometry.\n\nSuppose $f\\in O, \\tau\\in T$ and $\\tau(\\mathbf{0})=\\mathbf{v}$. Then for each $\\mathbf{x}\\in\\mathbb{R}^{2}$ we have  \n\n$$\n\\begin{array}{r l}&{f\\tau f^{-1}(\\mathbf{x})=f(\\mathbf{v}+f^{-1}(\\mathbf{x}))}\\\\ &{\\qquad\\qquad=f(\\mathbf{v})+f(f^{-1}(\\mathbf{x}))\\qquad\\mathrm{because~}f\\mathrm{~is~linear~}}\\\\ &{\\qquad\\qquad=f(\\mathbf{v})+\\mathbf{x}.}\\end{array}\n$$  \n\nTherefore the conjugate $f\\tau f^{-1}$ is translation by the vector $f(\\mathbf{v})$. Since the elements of $T$ and $O$ together generate $E_{2}$, we see (using (15.2)) that $T$ is a normal subgroup of $E_{2}$.\n\nWe can now understand the product structure of our group in terms of the decomposition $E_{2}=T O$. If $g=\\tau f, h=\\tau_{1}f_{1}$ where $\\tau, \\tau_{1}\\in T$ and $f, f_{1}\\in O$, then\n\n$$\ngh=\\tau f\\tau_{1}f_{1}=(\\tau f\\tau_{1}f^{-1})(ff_{1})\n$$  \n\nexpresses $gh$ as an orthogonal transformation followed by a translation. Put another way, the correspondence  \n\n$$\ng\\rightarrow(\\tau,f)\n$$  \n\nis an isomorphism between $E_{2}$ and the semi-direct product $T\\times_{\\varphi}O$ where $\\varphi\\colon O\\to\\mathrm{Aut}(T)$ is given by conjugation.\n\nSpecific calculations are best carried out using rather different notation. Suppose $g=\\tau f$ where $\\tau\\in T$ and $f\\in O$. If $\\mathbf{v}=\\tau(\\mathbf{0})$, and if $M$ is the orthogonal matrix which represents $f$ in the standard basis for $\\mathbb{R}^{2}$, then  \n\n$$\ng(\\mathbf{x})=\\mathbf{v}+f_{M}(\\mathbf{x})=\\mathbf{v}+\\mathbf{x}M^{t}\n$$  \n\nfor all $\\mathbf{x}\\in\\mathbb{R}^{2}$. Conversely, given $\\mathbf{v}\\in\\mathbb{R}^{2}$ and $M\\in O_{2}$, the formula $(*)$ determines an isometry of the plane. We may therefore think of each isometry as an ordered pair $(\\mathbf{v},M)$ in which $\\mathbf{v}\\in\\mathbb{R}^{2}$ and $M\\in O_{2}$, with multiplication given by  \n\n$$\n({\\bf v},M)({\\bf v}_{1},M_{1})=({\\bf v}+f_{M}({\\bf v}_{1}),M M_{1}).\n$$  \n\nIf we are pressed to be very precise, we explain that we have identified $E_{2}$ with the semi-direct product $\\mathbb{R}^{2}\\times_{\\psi}O_{2}$, the homomorphism $\\psi:O_{2}\\to\\mathrm{Aut}(\\mathbb{R}^{2})$ being the usual action of $O_{2}$ on $\\mathbb{R}^{2}$. Notice that $(\\mathbf{v},M)$ is a direct isometry when det $M=+1$ and an opposite isometry when det $M=-1$.\n\nThe \"simplest\" isometries are easily described as ordered pairs. Let  \n\n$$\nA={\\left[\\!\\!\\begin{array}{l l l}{\\cos\\theta}&{}&{-\\sin\\theta}\\\\ {\\sin\\theta}&{}&{\\cos\\theta}\\end{array}\\!\\!\\right]},\\qquad B={\\left[\\!\\!\\begin{array}{l l l}{\\cos\\varphi}&{}&{\\sin\\varphi}\\\\ {\\sin\\varphi}&{}&{-\\cos\\varphi}\\end{array}\\!\\!\\right]}\n$$  \n\nand let $l, m$ be the lines shown in Figure 24.3.\n\n![](images/e55ee17f1fdd570c65059d6754f7488b3426174223d35b91e0be7d71223a487b.jpg)  \nFigure 24.3",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Notice that \\((\\mathbf{v},M)\\) is a direct isometry when det \\( M = +1 \\) and an opposite isometry when det \\( M = -1 \\).",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Groups_And_Symmetry(Armstrong).pdf_74",
        "ID": "03f9c3a3-5fb1-40dd-b4fe-f75045709961",
        "questions": "How can each isometry \\( g \\) be represented within the group \\( E_{2} \\) in terms of orthogonal transformations and translations?",
        "answers": "Each isometry \\( g \\) can be represented as an orthogonal transformation followed by a translation with the form \\( g(\\mathbf{x}) = \\mathbf{v} + \\mathbf{x}M^{t} \\).",
        "context": "![](images/ba5e76bb3bcbf92f754b17d2d674748057b6bae1c954e706ed415add558f9999.jpg)  \nFigure 24.2  \n\n$$\n\\begin{array}{r l}&{\\tau_{1}\\tau_{2}^{-1}(\\mathbf{x})=\\tau_{1}((-\\mathbf{v})+\\mathbf{x})}\\\\ &{\\qquad\\qquad\\qquad=\\mathbf{u}+((-\\mathbf{v})+\\mathbf{x})}\\\\ &{\\qquad\\qquad\\qquad=(\\mathbf{u}-\\mathbf{v})+\\mathbf{x}.}\\end{array}\n$$  \n\nSo $\\tau_{1}\\tau_{2}^{-1}$ is translation by $\\mathbf{u}-\\mathbf{v}$ and therefore belongs to $T$. Let $O$ denote the subgroup of $E_{2}$ which consists of the orthogonal transformations. In other words, the elements of $O$ are rotations about the origin and reflections in lines through the origin. The discussion in the previous paragraph shows that $E_{2}=T O$.\n\nThe intersection of $T$ and $O$ is just the identity transformation because every non-trivial translation moves the origin, whereas every element of $O$ keeps the origin fixed. The usual argument now shows that each isometry can be written in only one way as an orthogonal transformation followed by a translation. For if $g=\\tau f=\\tau^{\\prime}f^{\\prime}$ where $\\tau, \\tau^{\\prime}\\in T$ and $f,f^{\\prime}\\in O$, then $(\\tau^{\\prime})^{-1}\\tau=f^{\\prime}f^{-1}$ lies in $T\\cap O$ and hence $\\tau=\\tau^{\\prime}, f=f^{\\prime}$. If $g=\\tau f$ and if $f$ is a rotation, then $g$ is called a direct isometry. In the other case, when $f$ is a reflection, $g$ is said to be an opposite isometry.\n\nSuppose $f\\in O, \\tau\\in T$ and $\\tau(\\mathbf{0})=\\mathbf{v}$. Then for each $\\mathbf{x}\\in\\mathbb{R}^{2}$ we have  \n\n$$\n\\begin{array}{r l}&{f\\tau f^{-1}(\\mathbf{x})=f(\\mathbf{v}+f^{-1}(\\mathbf{x}))}\\\\ &{\\qquad\\qquad=f(\\mathbf{v})+f(f^{-1}(\\mathbf{x}))\\qquad\\mathrm{because~}f\\mathrm{~is~linear~}}\\\\ &{\\qquad\\qquad=f(\\mathbf{v})+\\mathbf{x}.}\\end{array}\n$$  \n\nTherefore the conjugate $f\\tau f^{-1}$ is translation by the vector $f(\\mathbf{v})$. Since the elements of $T$ and $O$ together generate $E_{2}$, we see (using (15.2)) that $T$ is a normal subgroup of $E_{2}$.\n\nWe can now understand the product structure of our group in terms of the decomposition $E_{2}=T O$. If $g=\\tau f, h=\\tau_{1}f_{1}$ where $\\tau, \\tau_{1}\\in T$ and $f, f_{1}\\in O$, then\n\n$$\ngh=\\tau f\\tau_{1}f_{1}=(\\tau f\\tau_{1}f^{-1})(ff_{1})\n$$  \n\nexpresses $gh$ as an orthogonal transformation followed by a translation. Put another way, the correspondence  \n\n$$\ng\\rightarrow(\\tau,f)\n$$  \n\nis an isomorphism between $E_{2}$ and the semi-direct product $T\\times_{\\varphi}O$ where $\\varphi\\colon O\\to\\mathrm{Aut}(T)$ is given by conjugation.\n\nSpecific calculations are best carried out using rather different notation. Suppose $g=\\tau f$ where $\\tau\\in T$ and $f\\in O$. If $\\mathbf{v}=\\tau(\\mathbf{0})$, and if $M$ is the orthogonal matrix which represents $f$ in the standard basis for $\\mathbb{R}^{2}$, then  \n\n$$\ng(\\mathbf{x})=\\mathbf{v}+f_{M}(\\mathbf{x})=\\mathbf{v}+\\mathbf{x}M^{t}\n$$  \n\nfor all $\\mathbf{x}\\in\\mathbb{R}^{2}$. Conversely, given $\\mathbf{v}\\in\\mathbb{R}^{2}$ and $M\\in O_{2}$, the formula $(*)$ determines an isometry of the plane. We may therefore think of each isometry as an ordered pair $(\\mathbf{v},M)$ in which $\\mathbf{v}\\in\\mathbb{R}^{2}$ and $M\\in O_{2}$, with multiplication given by  \n\n$$\n({\\bf v},M)({\\bf v}_{1},M_{1})=({\\bf v}+f_{M}({\\bf v}_{1}),M M_{1}).\n$$  \n\nIf we are pressed to be very precise, we explain that we have identified $E_{2}$ with the semi-direct product $\\mathbb{R}^{2}\\times_{\\psi}O_{2}$, the homomorphism $\\psi:O_{2}\\to\\mathrm{Aut}(\\mathbb{R}^{2})$ being the usual action of $O_{2}$ on $\\mathbb{R}^{2}$. Notice that $(\\mathbf{v},M)$ is a direct isometry when det $M=+1$ and an opposite isometry when det $M=-1$.\n\nThe \"simplest\" isometries are easily described as ordered pairs. Let  \n\n$$\nA={\\left[\\!\\!\\begin{array}{l l l}{\\cos\\theta}&{}&{-\\sin\\theta}\\\\ {\\sin\\theta}&{}&{\\cos\\theta}\\end{array}\\!\\!\\right]},\\qquad B={\\left[\\!\\!\\begin{array}{l l l}{\\cos\\varphi}&{}&{\\sin\\varphi}\\\\ {\\sin\\varphi}&{}&{-\\cos\\varphi}\\end{array}\\!\\!\\right]}\n$$  \n\nand let $l, m$ be the lines shown in Figure 24.3.\n\n![](images/e55ee17f1fdd570c65059d6754f7488b3426174223d35b91e0be7d71223a487b.jpg)  \nFigure 24.3",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "If \\(\\mathbf{v} = \tau(\\mathbf{0})\\), and if \\( M \\) is the orthogonal matrix which represents \\( f \\) in the standard basis for \\( \\mathbb{R}^{2} \\), then \\( g(\\mathbf{x}) = \\mathbf{v} + f_{M}(\\mathbf{x}) = \\mathbf{v} + \\mathbf{x}M^{t} \\) for all \\(\\mathbf{x} \\in \\mathbb{R}^{2} \\).",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Groups_And_Symmetry(Armstrong).pdf_74",
        "ID": "03fa6c59-a9e8-4538-880b-3ff9f4b7d61d",
        "questions": "What operation does the transformation $\tau_{1}\tau_{2}^{-1}$ perform on vector $\\mathbf{u}$ and $\\mathbf{v}$?",
        "answers": "Translation by $\\mathbf{u} - \\mathbf{v}$",
        "context": "![](images/ba5e76bb3bcbf92f754b17d2d674748057b6bae1c954e706ed415add558f9999.jpg)  \nFigure 24.2  \n\n$$\n\\begin{array}{r l}&{\\tau_{1}\\tau_{2}^{-1}(\\mathbf{x})=\\tau_{1}((-\\mathbf{v})+\\mathbf{x})}\\\\ &{\\qquad\\qquad\\qquad=\\mathbf{u}+((-\\mathbf{v})+\\mathbf{x})}\\\\ &{\\qquad\\qquad\\qquad=(\\mathbf{u}-\\mathbf{v})+\\mathbf{x}.}\\end{array}\n$$  \n\nSo $\\tau_{1}\\tau_{2}^{-1}$ is translation by $\\mathbf{u}-\\mathbf{v}$ and therefore belongs to $T$. Let $O$ denote the subgroup of $E_{2}$ which consists of the orthogonal transformations. In other words, the elements of $O$ are rotations about the origin and reflections in lines through the origin. The discussion in the previous paragraph shows that $E_{2}=T O$.\n\nThe intersection of $T$ and $O$ is just the identity transformation because every non-trivial translation moves the origin, whereas every element of $O$ keeps the origin fixed. The usual argument now shows that each isometry can be written in only one way as an orthogonal transformation followed by a translation. For if $g=\\tau f=\\tau^{\\prime}f^{\\prime}$ where $\\tau, \\tau^{\\prime}\\in T$ and $f,f^{\\prime}\\in O$, then $(\\tau^{\\prime})^{-1}\\tau=f^{\\prime}f^{-1}$ lies in $T\\cap O$ and hence $\\tau=\\tau^{\\prime}, f=f^{\\prime}$. If $g=\\tau f$ and if $f$ is a rotation, then $g$ is called a direct isometry. In the other case, when $f$ is a reflection, $g$ is said to be an opposite isometry.\n\nSuppose $f\\in O, \\tau\\in T$ and $\\tau(\\mathbf{0})=\\mathbf{v}$. Then for each $\\mathbf{x}\\in\\mathbb{R}^{2}$ we have  \n\n$$\n\\begin{array}{r l}&{f\\tau f^{-1}(\\mathbf{x})=f(\\mathbf{v}+f^{-1}(\\mathbf{x}))}\\\\ &{\\qquad\\qquad=f(\\mathbf{v})+f(f^{-1}(\\mathbf{x}))\\qquad\\mathrm{because~}f\\mathrm{~is~linear~}}\\\\ &{\\qquad\\qquad=f(\\mathbf{v})+\\mathbf{x}.}\\end{array}\n$$  \n\nTherefore the conjugate $f\\tau f^{-1}$ is translation by the vector $f(\\mathbf{v})$. Since the elements of $T$ and $O$ together generate $E_{2}$, we see (using (15.2)) that $T$ is a normal subgroup of $E_{2}$.\n\nWe can now understand the product structure of our group in terms of the decomposition $E_{2}=T O$. If $g=\\tau f, h=\\tau_{1}f_{1}$ where $\\tau, \\tau_{1}\\in T$ and $f, f_{1}\\in O$, then\n\n$$\ngh=\\tau f\\tau_{1}f_{1}=(\\tau f\\tau_{1}f^{-1})(ff_{1})\n$$  \n\nexpresses $gh$ as an orthogonal transformation followed by a translation. Put another way, the correspondence  \n\n$$\ng\\rightarrow(\\tau,f)\n$$  \n\nis an isomorphism between $E_{2}$ and the semi-direct product $T\\times_{\\varphi}O$ where $\\varphi\\colon O\\to\\mathrm{Aut}(T)$ is given by conjugation.\n\nSpecific calculations are best carried out using rather different notation. Suppose $g=\\tau f$ where $\\tau\\in T$ and $f\\in O$. If $\\mathbf{v}=\\tau(\\mathbf{0})$, and if $M$ is the orthogonal matrix which represents $f$ in the standard basis for $\\mathbb{R}^{2}$, then  \n\n$$\ng(\\mathbf{x})=\\mathbf{v}+f_{M}(\\mathbf{x})=\\mathbf{v}+\\mathbf{x}M^{t}\n$$  \n\nfor all $\\mathbf{x}\\in\\mathbb{R}^{2}$. Conversely, given $\\mathbf{v}\\in\\mathbb{R}^{2}$ and $M\\in O_{2}$, the formula $(*)$ determines an isometry of the plane. We may therefore think of each isometry as an ordered pair $(\\mathbf{v},M)$ in which $\\mathbf{v}\\in\\mathbb{R}^{2}$ and $M\\in O_{2}$, with multiplication given by  \n\n$$\n({\\bf v},M)({\\bf v}_{1},M_{1})=({\\bf v}+f_{M}({\\bf v}_{1}),M M_{1}).\n$$  \n\nIf we are pressed to be very precise, we explain that we have identified $E_{2}$ with the semi-direct product $\\mathbb{R}^{2}\\times_{\\psi}O_{2}$, the homomorphism $\\psi:O_{2}\\to\\mathrm{Aut}(\\mathbb{R}^{2})$ being the usual action of $O_{2}$ on $\\mathbb{R}^{2}$. Notice that $(\\mathbf{v},M)$ is a direct isometry when det $M=+1$ and an opposite isometry when det $M=-1$.\n\nThe \"simplest\" isometries are easily described as ordered pairs. Let  \n\n$$\nA={\\left[\\!\\!\\begin{array}{l l l}{\\cos\\theta}&{}&{-\\sin\\theta}\\\\ {\\sin\\theta}&{}&{\\cos\\theta}\\end{array}\\!\\!\\right]},\\qquad B={\\left[\\!\\!\\begin{array}{l l l}{\\cos\\varphi}&{}&{\\sin\\varphi}\\\\ {\\sin\\varphi}&{}&{-\\cos\\varphi}\\end{array}\\!\\!\\right]}\n$$  \n\nand let $l, m$ be the lines shown in Figure 24.3.\n\n![](images/e55ee17f1fdd570c65059d6754f7488b3426174223d35b91e0be7d71223a487b.jpg)  \nFigure 24.3",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$$\\begin{array}{r l}&{\\tau_{1}\\tau_{2}^{-1}(\\mathbf{x})=\\tau_{1}((-\\mathbf{v})+\\mathbf{x})}\\ &{\\qquad\\qquad\\qquad=\\mathbf{u}+((-\\mathbf{v})+\\mathbf{x})}\\ &{\\qquad\\qquad\\qquad=(\\mathbf{u}-\\mathbf{v})+\\mathbf{x}.}\\end{array}$$ \\text { So } \\tau_{1}\\tau_{2}^{-1} \\text{ is translation by } \\mathbf{u}-\\mathbf{v}",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/Groups_And_Symmetry(Armstrong).pdf_74",
        "ID": "03fd60b3-afbd-47df-8612-154953a08862",
        "questions": "How is the transformation $gh$ expressed in terms of $\tau$, $\tau_1$, $f$, and $f_1$?",
        "answers": "$gh=\\tau f\\tau_{1}f_{1}=(\\tau f\\tau_{1}f^{-1})(ff_{1})$",
        "context": "![](images/ba5e76bb3bcbf92f754b17d2d674748057b6bae1c954e706ed415add558f9999.jpg)  \nFigure 24.2  \n\n$$\n\\begin{array}{r l}&{\\tau_{1}\\tau_{2}^{-1}(\\mathbf{x})=\\tau_{1}((-\\mathbf{v})+\\mathbf{x})}\\\\ &{\\qquad\\qquad\\qquad=\\mathbf{u}+((-\\mathbf{v})+\\mathbf{x})}\\\\ &{\\qquad\\qquad\\qquad=(\\mathbf{u}-\\mathbf{v})+\\mathbf{x}.}\\end{array}\n$$  \n\nSo $\\tau_{1}\\tau_{2}^{-1}$ is translation by $\\mathbf{u}-\\mathbf{v}$ and therefore belongs to $T$. Let $O$ denote the subgroup of $E_{2}$ which consists of the orthogonal transformations. In other words, the elements of $O$ are rotations about the origin and reflections in lines through the origin. The discussion in the previous paragraph shows that $E_{2}=T O$.\n\nThe intersection of $T$ and $O$ is just the identity transformation because every non-trivial translation moves the origin, whereas every element of $O$ keeps the origin fixed. The usual argument now shows that each isometry can be written in only one way as an orthogonal transformation followed by a translation. For if $g=\\tau f=\\tau^{\\prime}f^{\\prime}$ where $\\tau, \\tau^{\\prime}\\in T$ and $f,f^{\\prime}\\in O$, then $(\\tau^{\\prime})^{-1}\\tau=f^{\\prime}f^{-1}$ lies in $T\\cap O$ and hence $\\tau=\\tau^{\\prime}, f=f^{\\prime}$. If $g=\\tau f$ and if $f$ is a rotation, then $g$ is called a direct isometry. In the other case, when $f$ is a reflection, $g$ is said to be an opposite isometry.\n\nSuppose $f\\in O, \\tau\\in T$ and $\\tau(\\mathbf{0})=\\mathbf{v}$. Then for each $\\mathbf{x}\\in\\mathbb{R}^{2}$ we have  \n\n$$\n\\begin{array}{r l}&{f\\tau f^{-1}(\\mathbf{x})=f(\\mathbf{v}+f^{-1}(\\mathbf{x}))}\\\\ &{\\qquad\\qquad=f(\\mathbf{v})+f(f^{-1}(\\mathbf{x}))\\qquad\\mathrm{because~}f\\mathrm{~is~linear~}}\\\\ &{\\qquad\\qquad=f(\\mathbf{v})+\\mathbf{x}.}\\end{array}\n$$  \n\nTherefore the conjugate $f\\tau f^{-1}$ is translation by the vector $f(\\mathbf{v})$. Since the elements of $T$ and $O$ together generate $E_{2}$, we see (using (15.2)) that $T$ is a normal subgroup of $E_{2}$.\n\nWe can now understand the product structure of our group in terms of the decomposition $E_{2}=T O$. If $g=\\tau f, h=\\tau_{1}f_{1}$ where $\\tau, \\tau_{1}\\in T$ and $f, f_{1}\\in O$, then\n\n$$\ngh=\\tau f\\tau_{1}f_{1}=(\\tau f\\tau_{1}f^{-1})(ff_{1})\n$$  \n\nexpresses $gh$ as an orthogonal transformation followed by a translation. Put another way, the correspondence  \n\n$$\ng\\rightarrow(\\tau,f)\n$$  \n\nis an isomorphism between $E_{2}$ and the semi-direct product $T\\times_{\\varphi}O$ where $\\varphi\\colon O\\to\\mathrm{Aut}(T)$ is given by conjugation.\n\nSpecific calculations are best carried out using rather different notation. Suppose $g=\\tau f$ where $\\tau\\in T$ and $f\\in O$. If $\\mathbf{v}=\\tau(\\mathbf{0})$, and if $M$ is the orthogonal matrix which represents $f$ in the standard basis for $\\mathbb{R}^{2}$, then  \n\n$$\ng(\\mathbf{x})=\\mathbf{v}+f_{M}(\\mathbf{x})=\\mathbf{v}+\\mathbf{x}M^{t}\n$$  \n\nfor all $\\mathbf{x}\\in\\mathbb{R}^{2}$. Conversely, given $\\mathbf{v}\\in\\mathbb{R}^{2}$ and $M\\in O_{2}$, the formula $(*)$ determines an isometry of the plane. We may therefore think of each isometry as an ordered pair $(\\mathbf{v},M)$ in which $\\mathbf{v}\\in\\mathbb{R}^{2}$ and $M\\in O_{2}$, with multiplication given by  \n\n$$\n({\\bf v},M)({\\bf v}_{1},M_{1})=({\\bf v}+f_{M}({\\bf v}_{1}),M M_{1}).\n$$  \n\nIf we are pressed to be very precise, we explain that we have identified $E_{2}$ with the semi-direct product $\\mathbb{R}^{2}\\times_{\\psi}O_{2}$, the homomorphism $\\psi:O_{2}\\to\\mathrm{Aut}(\\mathbb{R}^{2})$ being the usual action of $O_{2}$ on $\\mathbb{R}^{2}$. Notice that $(\\mathbf{v},M)$ is a direct isometry when det $M=+1$ and an opposite isometry when det $M=-1$.\n\nThe \"simplest\" isometries are easily described as ordered pairs. Let  \n\n$$\nA={\\left[\\!\\!\\begin{array}{l l l}{\\cos\\theta}&{}&{-\\sin\\theta}\\\\ {\\sin\\theta}&{}&{\\cos\\theta}\\end{array}\\!\\!\\right]},\\qquad B={\\left[\\!\\!\\begin{array}{l l l}{\\cos\\varphi}&{}&{\\sin\\varphi}\\\\ {\\sin\\varphi}&{}&{-\\cos\\varphi}\\end{array}\\!\\!\\right]}\n$$  \n\nand let $l, m$ be the lines shown in Figure 24.3.\n\n![](images/e55ee17f1fdd570c65059d6754f7488b3426174223d35b91e0be7d71223a487b.jpg)  \nFigure 24.3",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$gh=\\tau f\\tau_{1}f_{1}=(\\tau f\\tau_{1}f^{-1})(ff_{1})$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/Groups_And_Symmetry(Armstrong).pdf_74",
        "ID": "0409a997-8408-46d9-a8dc-d8840b0e52d5",
        "questions": "What is the formula for the product of two isometries $(\\mathbf{v}, M)$ and $(\\mathbf{v}_1, M_1)$?",
        "answers": "$({\\bf v},M)({\\bf v}_{1},M_{1})=({\\bf v}+f_{M}({\\bf v}_{1}),M M_{1})$",
        "context": "![](images/ba5e76bb3bcbf92f754b17d2d674748057b6bae1c954e706ed415add558f9999.jpg)  \nFigure 24.2  \n\n$$\n\\begin{array}{r l}&{\\tau_{1}\\tau_{2}^{-1}(\\mathbf{x})=\\tau_{1}((-\\mathbf{v})+\\mathbf{x})}\\\\ &{\\qquad\\qquad\\qquad=\\mathbf{u}+((-\\mathbf{v})+\\mathbf{x})}\\\\ &{\\qquad\\qquad\\qquad=(\\mathbf{u}-\\mathbf{v})+\\mathbf{x}.}\\end{array}\n$$  \n\nSo $\\tau_{1}\\tau_{2}^{-1}$ is translation by $\\mathbf{u}-\\mathbf{v}$ and therefore belongs to $T$. Let $O$ denote the subgroup of $E_{2}$ which consists of the orthogonal transformations. In other words, the elements of $O$ are rotations about the origin and reflections in lines through the origin. The discussion in the previous paragraph shows that $E_{2}=T O$.\n\nThe intersection of $T$ and $O$ is just the identity transformation because every non-trivial translation moves the origin, whereas every element of $O$ keeps the origin fixed. The usual argument now shows that each isometry can be written in only one way as an orthogonal transformation followed by a translation. For if $g=\\tau f=\\tau^{\\prime}f^{\\prime}$ where $\\tau, \\tau^{\\prime}\\in T$ and $f,f^{\\prime}\\in O$, then $(\\tau^{\\prime})^{-1}\\tau=f^{\\prime}f^{-1}$ lies in $T\\cap O$ and hence $\\tau=\\tau^{\\prime}, f=f^{\\prime}$. If $g=\\tau f$ and if $f$ is a rotation, then $g$ is called a direct isometry. In the other case, when $f$ is a reflection, $g$ is said to be an opposite isometry.\n\nSuppose $f\\in O, \\tau\\in T$ and $\\tau(\\mathbf{0})=\\mathbf{v}$. Then for each $\\mathbf{x}\\in\\mathbb{R}^{2}$ we have  \n\n$$\n\\begin{array}{r l}&{f\\tau f^{-1}(\\mathbf{x})=f(\\mathbf{v}+f^{-1}(\\mathbf{x}))}\\\\ &{\\qquad\\qquad=f(\\mathbf{v})+f(f^{-1}(\\mathbf{x}))\\qquad\\mathrm{because~}f\\mathrm{~is~linear~}}\\\\ &{\\qquad\\qquad=f(\\mathbf{v})+\\mathbf{x}.}\\end{array}\n$$  \n\nTherefore the conjugate $f\\tau f^{-1}$ is translation by the vector $f(\\mathbf{v})$. Since the elements of $T$ and $O$ together generate $E_{2}$, we see (using (15.2)) that $T$ is a normal subgroup of $E_{2}$.\n\nWe can now understand the product structure of our group in terms of the decomposition $E_{2}=T O$. If $g=\\tau f, h=\\tau_{1}f_{1}$ where $\\tau, \\tau_{1}\\in T$ and $f, f_{1}\\in O$, then\n\n$$\ngh=\\tau f\\tau_{1}f_{1}=(\\tau f\\tau_{1}f^{-1})(ff_{1})\n$$  \n\nexpresses $gh$ as an orthogonal transformation followed by a translation. Put another way, the correspondence  \n\n$$\ng\\rightarrow(\\tau,f)\n$$  \n\nis an isomorphism between $E_{2}$ and the semi-direct product $T\\times_{\\varphi}O$ where $\\varphi\\colon O\\to\\mathrm{Aut}(T)$ is given by conjugation.\n\nSpecific calculations are best carried out using rather different notation. Suppose $g=\\tau f$ where $\\tau\\in T$ and $f\\in O$. If $\\mathbf{v}=\\tau(\\mathbf{0})$, and if $M$ is the orthogonal matrix which represents $f$ in the standard basis for $\\mathbb{R}^{2}$, then  \n\n$$\ng(\\mathbf{x})=\\mathbf{v}+f_{M}(\\mathbf{x})=\\mathbf{v}+\\mathbf{x}M^{t}\n$$  \n\nfor all $\\mathbf{x}\\in\\mathbb{R}^{2}$. Conversely, given $\\mathbf{v}\\in\\mathbb{R}^{2}$ and $M\\in O_{2}$, the formula $(*)$ determines an isometry of the plane. We may therefore think of each isometry as an ordered pair $(\\mathbf{v},M)$ in which $\\mathbf{v}\\in\\mathbb{R}^{2}$ and $M\\in O_{2}$, with multiplication given by  \n\n$$\n({\\bf v},M)({\\bf v}_{1},M_{1})=({\\bf v}+f_{M}({\\bf v}_{1}),M M_{1}).\n$$  \n\nIf we are pressed to be very precise, we explain that we have identified $E_{2}$ with the semi-direct product $\\mathbb{R}^{2}\\times_{\\psi}O_{2}$, the homomorphism $\\psi:O_{2}\\to\\mathrm{Aut}(\\mathbb{R}^{2})$ being the usual action of $O_{2}$ on $\\mathbb{R}^{2}$. Notice that $(\\mathbf{v},M)$ is a direct isometry when det $M=+1$ and an opposite isometry when det $M=-1$.\n\nThe \"simplest\" isometries are easily described as ordered pairs. Let  \n\n$$\nA={\\left[\\!\\!\\begin{array}{l l l}{\\cos\\theta}&{}&{-\\sin\\theta}\\\\ {\\sin\\theta}&{}&{\\cos\\theta}\\end{array}\\!\\!\\right]},\\qquad B={\\left[\\!\\!\\begin{array}{l l l}{\\cos\\varphi}&{}&{\\sin\\varphi}\\\\ {\\sin\\varphi}&{}&{-\\cos\\varphi}\\end{array}\\!\\!\\right]}\n$$  \n\nand let $l, m$ be the lines shown in Figure 24.3.\n\n![](images/e55ee17f1fdd570c65059d6754f7488b3426174223d35b91e0be7d71223a487b.jpg)  \nFigure 24.3",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$({\\bf v},M)({\\bf v}_{1},M_{1})=({\\bf v}+f_{M}({\\bf v}_{1}),M M_{1})$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/workforce-20780.pdf_23",
        "ID": "040c4d58-954a-4019-a093-e30f1e1eedd9",
        "questions": "What are the two types of intellectual property included in innovation capital?",
        "answers": "patents, trademarks",
        "context": "- Innovation capital includes intellectual property such as patents, trademarks and copyrights, and intangible assets.\n\n- Intellectual properties are protected commercial rights such as patents, trade secrets, copyrights and trademarks. Intangible assets are all of the other talents and theory by which run an organization.\n\nStructural capital is one of the three primary components of intellectual capital, and consists of the supportive infrastructure, processes, and databases of the organization that enable human capital to function. Structural capital is owned by an organization and remains with an organization even when people leave. It includes: capabilities, routines, methods, procedures and methodologies embedded in organization. Structural capital is the supportive non-physical infrastructure that enables human capital to function.\n\nRelational capital, consisting of such elements as customer relationships, supplier relationships, trademarks and trade names (which have value only by virtue of customer relationships), licenses, and franchises. The notion that customer capital is separate from human and structural capital indicates its central importance to an organization's worth. The value of the relationships a business maintains with its customers and suppliers is also referred to as goodwill, but often poorly booked into corporate accounts, because of accounting rules.\n\n# Social Capital Theory - your ability to develop human relationships\n\nWoolcock (2001) defined social capital as the stocks of social trust, norms and networks that people access to solve joint problems. Interrelationships and connectivity between humans are central to the formation of social capital, hence why it is often described as the glue that holds society together (Murphy, 2004). In recent years, driven by fears over fragmentation of communities and a generalized decline in civic engagement (Foley et al., 2011), social capital has moved up the political agenda in democratic societies. It is, however, a complicated and contested concept with differing interpretations of its meaning and usefulness (Quinn 2013).\n\nColeman (1998) defines social capital by its functions and views it as a resource that can be drawn upon collectively. Its presence encourages certain actions, which facilitate the accomplishment of mutually beneficial ends. Moreover, \"social capital in the family and community play a crucial role in creating human capital (defined as individual skills and abilities in the next generation). Like Coleman, Bourdieu (1985) presents a sociological view of social capital, but he views it primarily as a resource for individuals. He defined social capital as 'the aggregate of the actual or potential resources, which are linked to possession of a durable network of more or less institutionalized relationships of mutual acquaintance and recognition' (Bourdieu, 1985, p248).\n\nLike Coleman (1998), Putnam (1995) underlines the collective dimensions of social capital, defining it as features of social organization such as networks, norms and social trust that facilitate co-ordination and cooperation for mutual benefit'. Putnam (1993) argued that the quality of life in societies and their economic sustainability was directly attributable to the features of social organization. He suggested that the hallmarks of a successful society depended upon core attributes of human relationships, the presence or absence of trust, the expectation of reciprocity and the existence of networks. A basic premise underpinning the work of these three theorists, and indeed social capital theory in general, is that investment in social relations is expected to yield a whole series of returns in the marketplace and beyond.\n\n# Bonding and Bridging Capital - internal & external relationships\n\nA distinction between bonding (exclusive) and bridging (inclusive) forms of social capital is widely made in the literature. Putnam (1993) explains that bonding social capital is inward looking and characterized by strong ties that reinforce exclusive identities, promote homogeneity and create strong in-group loyalty; whereas bridging social capital is outward looking, involves weaker ties and promotes links between diverse individuals and groups. Putnam suggests that many groups simultaneously bond across some social dimensions and bridge across others. In general, the dominant sense is that social capital is a force for good. However, Leonard (2004) has problematized the fact that policy-makers, seeing how social capital can potentially be converted into other forms of capital, often consider it as a quick-fix solution to complex, long-term structural problems. Indeed, viewing social capital as a 'quick-fix' and a panacea for all social ills is a noted criticism levelled at social capital theorists. Putnam's work in particular has been criticized for romanticizing 'the world we have lost' and ignoring the downside of community life.\n\nOver time, the growing social capital literature has developed a more critical lens, which acknowledges the inadequacies of the basic framework without abandoning the concept altogether (Muir 2010). For example, in their critique of Putnam's work, Portes and Landolt (1996) discuss how, in some cases, social capital can constrain individuals' actions and choices. This is because while social capital can promote access to resources, it can equally deny or limit such access.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "- Innovation capital includes intellectual property such as patents, trademarks and copyrights, and intangible assets.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/workforce-20780.pdf_23",
        "ID": "042506df-e159-4eab-ab52-f0583a7fe1b3",
        "questions": "How does Putnam (1993) explain the role of bonding social capital?",
        "answers": "Bonding social capital is inward looking and characterized by strong ties that reinforce exclusive identities, promote homogeneity and create strong in-group loyalty.",
        "context": "- Innovation capital includes intellectual property such as patents, trademarks and copyrights, and intangible assets.\n\n- Intellectual properties are protected commercial rights such as patents, trade secrets, copyrights and trademarks. Intangible assets are all of the other talents and theory by which run an organization.\n\nStructural capital is one of the three primary components of intellectual capital, and consists of the supportive infrastructure, processes, and databases of the organization that enable human capital to function. Structural capital is owned by an organization and remains with an organization even when people leave. It includes: capabilities, routines, methods, procedures and methodologies embedded in organization. Structural capital is the supportive non-physical infrastructure that enables human capital to function.\n\nRelational capital, consisting of such elements as customer relationships, supplier relationships, trademarks and trade names (which have value only by virtue of customer relationships), licenses, and franchises. The notion that customer capital is separate from human and structural capital indicates its central importance to an organization's worth. The value of the relationships a business maintains with its customers and suppliers is also referred to as goodwill, but often poorly booked into corporate accounts, because of accounting rules.\n\n# Social Capital Theory - your ability to develop human relationships\n\nWoolcock (2001) defined social capital as the stocks of social trust, norms and networks that people access to solve joint problems. Interrelationships and connectivity between humans are central to the formation of social capital, hence why it is often described as the glue that holds society together (Murphy, 2004). In recent years, driven by fears over fragmentation of communities and a generalized decline in civic engagement (Foley et al., 2011), social capital has moved up the political agenda in democratic societies. It is, however, a complicated and contested concept with differing interpretations of its meaning and usefulness (Quinn 2013).\n\nColeman (1998) defines social capital by its functions and views it as a resource that can be drawn upon collectively. Its presence encourages certain actions, which facilitate the accomplishment of mutually beneficial ends. Moreover, \"social capital in the family and community play a crucial role in creating human capital (defined as individual skills and abilities in the next generation). Like Coleman, Bourdieu (1985) presents a sociological view of social capital, but he views it primarily as a resource for individuals. He defined social capital as 'the aggregate of the actual or potential resources, which are linked to possession of a durable network of more or less institutionalized relationships of mutual acquaintance and recognition' (Bourdieu, 1985, p248).\n\nLike Coleman (1998), Putnam (1995) underlines the collective dimensions of social capital, defining it as features of social organization such as networks, norms and social trust that facilitate co-ordination and cooperation for mutual benefit'. Putnam (1993) argued that the quality of life in societies and their economic sustainability was directly attributable to the features of social organization. He suggested that the hallmarks of a successful society depended upon core attributes of human relationships, the presence or absence of trust, the expectation of reciprocity and the existence of networks. A basic premise underpinning the work of these three theorists, and indeed social capital theory in general, is that investment in social relations is expected to yield a whole series of returns in the marketplace and beyond.\n\n# Bonding and Bridging Capital - internal & external relationships\n\nA distinction between bonding (exclusive) and bridging (inclusive) forms of social capital is widely made in the literature. Putnam (1993) explains that bonding social capital is inward looking and characterized by strong ties that reinforce exclusive identities, promote homogeneity and create strong in-group loyalty; whereas bridging social capital is outward looking, involves weaker ties and promotes links between diverse individuals and groups. Putnam suggests that many groups simultaneously bond across some social dimensions and bridge across others. In general, the dominant sense is that social capital is a force for good. However, Leonard (2004) has problematized the fact that policy-makers, seeing how social capital can potentially be converted into other forms of capital, often consider it as a quick-fix solution to complex, long-term structural problems. Indeed, viewing social capital as a 'quick-fix' and a panacea for all social ills is a noted criticism levelled at social capital theorists. Putnam's work in particular has been criticized for romanticizing 'the world we have lost' and ignoring the downside of community life.\n\nOver time, the growing social capital literature has developed a more critical lens, which acknowledges the inadequacies of the basic framework without abandoning the concept altogether (Muir 2010). For example, in their critique of Putnam's work, Portes and Landolt (1996) discuss how, in some cases, social capital can constrain individuals' actions and choices. This is because while social capital can promote access to resources, it can equally deny or limit such access.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Putnam (1993) explains that bonding social capital is inward looking and characterized by strong ties that reinforce exclusive identities, promote homogeneity and create strong in-group loyalty.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/workforce-20780.pdf_23",
        "ID": "04397e4a-3aff-4da3-9c91-536ba383dfb5",
        "questions": "According to Bourdieu (1985), what is the definition of social capital?",
        "answers": "'the aggregate of the actual or potential resources, which are linked to possession of a durable network of more or less institutionalized relationships of mutual acquaintance and recognition'",
        "context": "- Innovation capital includes intellectual property such as patents, trademarks and copyrights, and intangible assets.\n\n- Intellectual properties are protected commercial rights such as patents, trade secrets, copyrights and trademarks. Intangible assets are all of the other talents and theory by which run an organization.\n\nStructural capital is one of the three primary components of intellectual capital, and consists of the supportive infrastructure, processes, and databases of the organization that enable human capital to function. Structural capital is owned by an organization and remains with an organization even when people leave. It includes: capabilities, routines, methods, procedures and methodologies embedded in organization. Structural capital is the supportive non-physical infrastructure that enables human capital to function.\n\nRelational capital, consisting of such elements as customer relationships, supplier relationships, trademarks and trade names (which have value only by virtue of customer relationships), licenses, and franchises. The notion that customer capital is separate from human and structural capital indicates its central importance to an organization's worth. The value of the relationships a business maintains with its customers and suppliers is also referred to as goodwill, but often poorly booked into corporate accounts, because of accounting rules.\n\n# Social Capital Theory - your ability to develop human relationships\n\nWoolcock (2001) defined social capital as the stocks of social trust, norms and networks that people access to solve joint problems. Interrelationships and connectivity between humans are central to the formation of social capital, hence why it is often described as the glue that holds society together (Murphy, 2004). In recent years, driven by fears over fragmentation of communities and a generalized decline in civic engagement (Foley et al., 2011), social capital has moved up the political agenda in democratic societies. It is, however, a complicated and contested concept with differing interpretations of its meaning and usefulness (Quinn 2013).\n\nColeman (1998) defines social capital by its functions and views it as a resource that can be drawn upon collectively. Its presence encourages certain actions, which facilitate the accomplishment of mutually beneficial ends. Moreover, \"social capital in the family and community play a crucial role in creating human capital (defined as individual skills and abilities in the next generation). Like Coleman, Bourdieu (1985) presents a sociological view of social capital, but he views it primarily as a resource for individuals. He defined social capital as 'the aggregate of the actual or potential resources, which are linked to possession of a durable network of more or less institutionalized relationships of mutual acquaintance and recognition' (Bourdieu, 1985, p248).\n\nLike Coleman (1998), Putnam (1995) underlines the collective dimensions of social capital, defining it as features of social organization such as networks, norms and social trust that facilitate co-ordination and cooperation for mutual benefit'. Putnam (1993) argued that the quality of life in societies and their economic sustainability was directly attributable to the features of social organization. He suggested that the hallmarks of a successful society depended upon core attributes of human relationships, the presence or absence of trust, the expectation of reciprocity and the existence of networks. A basic premise underpinning the work of these three theorists, and indeed social capital theory in general, is that investment in social relations is expected to yield a whole series of returns in the marketplace and beyond.\n\n# Bonding and Bridging Capital - internal & external relationships\n\nA distinction between bonding (exclusive) and bridging (inclusive) forms of social capital is widely made in the literature. Putnam (1993) explains that bonding social capital is inward looking and characterized by strong ties that reinforce exclusive identities, promote homogeneity and create strong in-group loyalty; whereas bridging social capital is outward looking, involves weaker ties and promotes links between diverse individuals and groups. Putnam suggests that many groups simultaneously bond across some social dimensions and bridge across others. In general, the dominant sense is that social capital is a force for good. However, Leonard (2004) has problematized the fact that policy-makers, seeing how social capital can potentially be converted into other forms of capital, often consider it as a quick-fix solution to complex, long-term structural problems. Indeed, viewing social capital as a 'quick-fix' and a panacea for all social ills is a noted criticism levelled at social capital theorists. Putnam's work in particular has been criticized for romanticizing 'the world we have lost' and ignoring the downside of community life.\n\nOver time, the growing social capital literature has developed a more critical lens, which acknowledges the inadequacies of the basic framework without abandoning the concept altogether (Muir 2010). For example, in their critique of Putnam's work, Portes and Landolt (1996) discuss how, in some cases, social capital can constrain individuals' actions and choices. This is because while social capital can promote access to resources, it can equally deny or limit such access.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "He defined social capital as 'the aggregate of the actual or potential resources, which are linked to possession of a durable network of more or less institutionalized relationships of mutual acquaintance and recognition' (Bourdieu, 1985, p248).",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/An_Introduction_To_Stochastic_Partial_Differe.pdf_151",
        "ID": "0439a866-bd97-4c72-8739-c31cdb99e18d",
        "questions": "What type of boundary condition is applied to the function u in the given elliptic equation within a bounded domain D?",
        "answers": "u=0 on the boundary delta D",
        "context": "# CHAPTER NINE  \n\nWe have spent most of our time on parabolic equations: non-parabolic equations have made only token appearances, such as at the beginning of these notes when we took a brief glance at the wave equation, which is hyperbolic. It is fitting to end with a brief glance at a token elliptic, Laplace's equation.  \n\nWe will give one existence and uniqueness theorem for bounded regions and then see how such equations arise as the limits of parabolic equations. In particular, we will look at the limits of the Brownian density process as $t \\to \\infty$  \n\nLet D be a bounded domain in $\\mathtt{R}^{\\mathtt{d}}$ with a smooth boundary. Consider  \n\n$$\n\\left\\{\\begin{array}{r l}{\\Delta u=f}&{\\mathrm{in}\\;\\;D}\\\\ {u=0}&{\\mathrm{on}\\;\\;\\delta D}\\end{array}\\right.\n$$\n\nIf f is bounded and continuous, the solution to (9.1) is  \n\n$$\nu(y)=\\int{K(x,y)\\,f(x)\\,dx}=K(f,y),\n$$  \n\nwhere $K$ is the Green's function for (9.1). Notice that in particular $\\Delta K(f,y)=f(y)$.  \n\nLet $M$ be an $L^{2}$-valued measure on $\\mathtt{R}^{\\mathtt{d}}$ (not a martingale measure, for there is no $t$ in the problem!) Set $Q(A,B)=E\\{M(A)M(B)\\}$ and suppose that there exists a positive definite measure $\\tilde{Q}$ on $\\mathtt{R}^{\\mathtt{d}}\\times\\mathtt{R}^{\\mathtt{d}}$ such that $\\left|Q(A,B)\\right|~\\leq~\\tilde{Q}(A\\times B)$ for all Borel $A, B\\subset\\mathtt{R}^{\\mathtt{d}}$. This assures of a good integration theory. We also assume for convenience that $M(\\delta D)=0$  \n\nLet $T$ be a kth order differential operator on $\\mathtt{R}^{\\mathtt{d}}$ with smooth coefficients $(0\\leq k <\\infty)$ and consider the SPDE  \n\n$$\n\\left\\{\\begin{array}{r l}{\\Delta U=T\\dot{M}}&{\\mathrm{in}\\;\\;D}\\\\ {U=0}&{\\mathrm{in}\\;\\;\\delta D}\\end{array}\\right.\n$$\n\nLet us get the weak form of (9.3). Multiply by a test function $\\phi$ and integrate over $\\mathtt{R}^{\\mathtt{d}}$ pretending $\\dot{M}$ is smooth. Suppose $\\phi=0$ on $\\delta D$. We can then do two integrations by parts to get  \n\n$$\n\\int{U(x)\\,\\Delta\\phi(x)\\,dx}=\\int_{D}T\\dot{M}\\phi(x)dx.\n$$  \n\nLet T\\* be the formal adjoint of T. If $T$ is a zeroth or first order",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Consider  $$ \\left\\{\begin{array}{r l}{\\Delta u=f}&{\\mathrm{in} D}\\ {u=0}&{\\mathrm{on} \\delta D}\\end{array}\right.$$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/An_Introduction_To_Stochastic_Partial_Differe.pdf_151",
        "ID": "043d17e5-2f0e-4937-b4bb-2a5c61cc6889",
        "questions": "What is necessary for the solution to the elliptic equation involving a bounded and continuous function f?",
        "answers": "The solution to (9.1) is  $$u(y)=\\int{K(x,y) f(x) dx}=K(f,y)$$",
        "context": "# CHAPTER NINE  \n\nWe have spent most of our time on parabolic equations: non-parabolic equations have made only token appearances, such as at the beginning of these notes when we took a brief glance at the wave equation, which is hyperbolic. It is fitting to end with a brief glance at a token elliptic, Laplace's equation.  \n\nWe will give one existence and uniqueness theorem for bounded regions and then see how such equations arise as the limits of parabolic equations. In particular, we will look at the limits of the Brownian density process as $t \\to \\infty$  \n\nLet D be a bounded domain in $\\mathtt{R}^{\\mathtt{d}}$ with a smooth boundary. Consider  \n\n$$\n\\left\\{\\begin{array}{r l}{\\Delta u=f}&{\\mathrm{in}\\;\\;D}\\\\ {u=0}&{\\mathrm{on}\\;\\;\\delta D}\\end{array}\\right.\n$$\n\nIf f is bounded and continuous, the solution to (9.1) is  \n\n$$\nu(y)=\\int{K(x,y)\\,f(x)\\,dx}=K(f,y),\n$$  \n\nwhere $K$ is the Green's function for (9.1). Notice that in particular $\\Delta K(f,y)=f(y)$.  \n\nLet $M$ be an $L^{2}$-valued measure on $\\mathtt{R}^{\\mathtt{d}}$ (not a martingale measure, for there is no $t$ in the problem!) Set $Q(A,B)=E\\{M(A)M(B)\\}$ and suppose that there exists a positive definite measure $\\tilde{Q}$ on $\\mathtt{R}^{\\mathtt{d}}\\times\\mathtt{R}^{\\mathtt{d}}$ such that $\\left|Q(A,B)\\right|~\\leq~\\tilde{Q}(A\\times B)$ for all Borel $A, B\\subset\\mathtt{R}^{\\mathtt{d}}$. This assures of a good integration theory. We also assume for convenience that $M(\\delta D)=0$  \n\nLet $T$ be a kth order differential operator on $\\mathtt{R}^{\\mathtt{d}}$ with smooth coefficients $(0\\leq k <\\infty)$ and consider the SPDE  \n\n$$\n\\left\\{\\begin{array}{r l}{\\Delta U=T\\dot{M}}&{\\mathrm{in}\\;\\;D}\\\\ {U=0}&{\\mathrm{in}\\;\\;\\delta D}\\end{array}\\right.\n$$\n\nLet us get the weak form of (9.3). Multiply by a test function $\\phi$ and integrate over $\\mathtt{R}^{\\mathtt{d}}$ pretending $\\dot{M}$ is smooth. Suppose $\\phi=0$ on $\\delta D$. We can then do two integrations by parts to get  \n\n$$\n\\int{U(x)\\,\\Delta\\phi(x)\\,dx}=\\int_{D}T\\dot{M}\\phi(x)dx.\n$$  \n\nLet T\\* be the formal adjoint of T. If $T$ is a zeroth or first order",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "If f is bounded and continuous, the solution to (9.1) is  $$u(y)=\\int{K(x,y) f(x) dx}=K(f,y)$$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/An_Introduction_To_Stochastic_Partial_Differe.pdf_151",
        "ID": "04408df3-2004-45b8-a0d8-336027812704",
        "questions": "What condition must hold for the measure Q(A,B) on the space R^d to ensure good integration theory when dealing with the elliptic equation?",
        "answers": "There must exist a positive definite measure ~tilde{Q} on ~R^{~d}~tilde{Q} on R d times R d such that ~\\left|Q(A,B)\right| ~\\leq~ ~tilde{Q}(A\times B)~stilde{Q}(A times B)~stilde{Q}(A times B)~stilde{Q}(A~subset R d).",
        "context": "# CHAPTER NINE  \n\nWe have spent most of our time on parabolic equations: non-parabolic equations have made only token appearances, such as at the beginning of these notes when we took a brief glance at the wave equation, which is hyperbolic. It is fitting to end with a brief glance at a token elliptic, Laplace's equation.  \n\nWe will give one existence and uniqueness theorem for bounded regions and then see how such equations arise as the limits of parabolic equations. In particular, we will look at the limits of the Brownian density process as $t \\to \\infty$  \n\nLet D be a bounded domain in $\\mathtt{R}^{\\mathtt{d}}$ with a smooth boundary. Consider  \n\n$$\n\\left\\{\\begin{array}{r l}{\\Delta u=f}&{\\mathrm{in}\\;\\;D}\\\\ {u=0}&{\\mathrm{on}\\;\\;\\delta D}\\end{array}\\right.\n$$\n\nIf f is bounded and continuous, the solution to (9.1) is  \n\n$$\nu(y)=\\int{K(x,y)\\,f(x)\\,dx}=K(f,y),\n$$  \n\nwhere $K$ is the Green's function for (9.1). Notice that in particular $\\Delta K(f,y)=f(y)$.  \n\nLet $M$ be an $L^{2}$-valued measure on $\\mathtt{R}^{\\mathtt{d}}$ (not a martingale measure, for there is no $t$ in the problem!) Set $Q(A,B)=E\\{M(A)M(B)\\}$ and suppose that there exists a positive definite measure $\\tilde{Q}$ on $\\mathtt{R}^{\\mathtt{d}}\\times\\mathtt{R}^{\\mathtt{d}}$ such that $\\left|Q(A,B)\\right|~\\leq~\\tilde{Q}(A\\times B)$ for all Borel $A, B\\subset\\mathtt{R}^{\\mathtt{d}}$. This assures of a good integration theory. We also assume for convenience that $M(\\delta D)=0$  \n\nLet $T$ be a kth order differential operator on $\\mathtt{R}^{\\mathtt{d}}$ with smooth coefficients $(0\\leq k <\\infty)$ and consider the SPDE  \n\n$$\n\\left\\{\\begin{array}{r l}{\\Delta U=T\\dot{M}}&{\\mathrm{in}\\;\\;D}\\\\ {U=0}&{\\mathrm{in}\\;\\;\\delta D}\\end{array}\\right.\n$$\n\nLet us get the weak form of (9.3). Multiply by a test function $\\phi$ and integrate over $\\mathtt{R}^{\\mathtt{d}}$ pretending $\\dot{M}$ is smooth. Suppose $\\phi=0$ on $\\delta D$. We can then do two integrations by parts to get  \n\n$$\n\\int{U(x)\\,\\Delta\\phi(x)\\,dx}=\\int_{D}T\\dot{M}\\phi(x)dx.\n$$  \n\nLet T\\* be the formal adjoint of T. If $T$ is a zeroth or first order",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "such that ~tilde{Q}(A\times B)~stilde{Q}(A times B)~stilde{Q}(A times B)~stilde{Q}(A times B)~stilde{Q}(A times times R d times R d)",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/An_Introduction_To_Stochastic_Partial_Differe.pdf_151",
        "ID": "044ed322-8c98-4c49-b540-33b718ac3907",
        "questions": "What are the boundary conditions for the Laplace's equation in a bounded domain D with a smooth boundary?",
        "answers": "$u=0$ on $\\delta D$",
        "context": "# CHAPTER NINE  \n\nWe have spent most of our time on parabolic equations: non-parabolic equations have made only token appearances, such as at the beginning of these notes when we took a brief glance at the wave equation, which is hyperbolic. It is fitting to end with a brief glance at a token elliptic, Laplace's equation.  \n\nWe will give one existence and uniqueness theorem for bounded regions and then see how such equations arise as the limits of parabolic equations. In particular, we will look at the limits of the Brownian density process as $t \\to \\infty$  \n\nLet D be a bounded domain in $\\mathtt{R}^{\\mathtt{d}}$ with a smooth boundary. Consider  \n\n$$\n\\left\\{\\begin{array}{r l}{\\Delta u=f}&{\\mathrm{in}\\;\\;D}\\\\ {u=0}&{\\mathrm{on}\\;\\;\\delta D}\\end{array}\\right.\n$$\n\nIf f is bounded and continuous, the solution to (9.1) is  \n\n$$\nu(y)=\\int{K(x,y)\\,f(x)\\,dx}=K(f,y),\n$$  \n\nwhere $K$ is the Green's function for (9.1). Notice that in particular $\\Delta K(f,y)=f(y)$.  \n\nLet $M$ be an $L^{2}$-valued measure on $\\mathtt{R}^{\\mathtt{d}}$ (not a martingale measure, for there is no $t$ in the problem!) Set $Q(A,B)=E\\{M(A)M(B)\\}$ and suppose that there exists a positive definite measure $\\tilde{Q}$ on $\\mathtt{R}^{\\mathtt{d}}\\times\\mathtt{R}^{\\mathtt{d}}$ such that $\\left|Q(A,B)\\right|~\\leq~\\tilde{Q}(A\\times B)$ for all Borel $A, B\\subset\\mathtt{R}^{\\mathtt{d}}$. This assures of a good integration theory. We also assume for convenience that $M(\\delta D)=0$  \n\nLet $T$ be a kth order differential operator on $\\mathtt{R}^{\\mathtt{d}}$ with smooth coefficients $(0\\leq k <\\infty)$ and consider the SPDE  \n\n$$\n\\left\\{\\begin{array}{r l}{\\Delta U=T\\dot{M}}&{\\mathrm{in}\\;\\;D}\\\\ {U=0}&{\\mathrm{in}\\;\\;\\delta D}\\end{array}\\right.\n$$\n\nLet us get the weak form of (9.3). Multiply by a test function $\\phi$ and integrate over $\\mathtt{R}^{\\mathtt{d}}$ pretending $\\dot{M}$ is smooth. Suppose $\\phi=0$ on $\\delta D$. We can then do two integrations by parts to get  \n\n$$\n\\int{U(x)\\,\\Delta\\phi(x)\\,dx}=\\int_{D}T\\dot{M}\\phi(x)dx.\n$$  \n\nLet T\\* be the formal adjoint of T. If $T$ is a zeroth or first order",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$\\left\\{\\begin{array}{r l}{\\Delta u=f}&{\\mathrm{in}\\;\\;D}\\\\ {u=0}&{\\mathrm{on}\\;\\;\\delta D}\\end{array}\\right.$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/An_Introduction_To_Stochastic_Partial_Differe.pdf_151",
        "ID": "045a1c04-f0ab-4022-b67f-1513d73d4e0c",
        "questions": "According to the integral formula for the solution to a PDE, what is the representation of $u(y)$ when $f$ is bounded and continuous, given the Green's function $K$ for the equation?",
        "answers": "u(y)=\\int{K(x,y)\\,f(x)\\,dx}=K(f,y)",
        "context": "# CHAPTER NINE  \n\nWe have spent most of our time on parabolic equations: non-parabolic equations have made only token appearances, such as at the beginning of these notes when we took a brief glance at the wave equation, which is hyperbolic. It is fitting to end with a brief glance at a token elliptic, Laplace's equation.  \n\nWe will give one existence and uniqueness theorem for bounded regions and then see how such equations arise as the limits of parabolic equations. In particular, we will look at the limits of the Brownian density process as $t \\to \\infty$  \n\nLet D be a bounded domain in $\\mathtt{R}^{\\mathtt{d}}$ with a smooth boundary. Consider  \n\n$$\n\\left\\{\\begin{array}{r l}{\\Delta u=f}&{\\mathrm{in}\\;\\;D}\\\\ {u=0}&{\\mathrm{on}\\;\\;\\delta D}\\end{array}\\right.\n$$\n\nIf f is bounded and continuous, the solution to (9.1) is  \n\n$$\nu(y)=\\int{K(x,y)\\,f(x)\\,dx}=K(f,y),\n$$  \n\nwhere $K$ is the Green's function for (9.1). Notice that in particular $\\Delta K(f,y)=f(y)$.  \n\nLet $M$ be an $L^{2}$-valued measure on $\\mathtt{R}^{\\mathtt{d}}$ (not a martingale measure, for there is no $t$ in the problem!) Set $Q(A,B)=E\\{M(A)M(B)\\}$ and suppose that there exists a positive definite measure $\\tilde{Q}$ on $\\mathtt{R}^{\\mathtt{d}}\\times\\mathtt{R}^{\\mathtt{d}}$ such that $\\left|Q(A,B)\\right|~\\leq~\\tilde{Q}(A\\times B)$ for all Borel $A, B\\subset\\mathtt{R}^{\\mathtt{d}}$. This assures of a good integration theory. We also assume for convenience that $M(\\delta D)=0$  \n\nLet $T$ be a kth order differential operator on $\\mathtt{R}^{\\mathtt{d}}$ with smooth coefficients $(0\\leq k <\\infty)$ and consider the SPDE  \n\n$$\n\\left\\{\\begin{array}{r l}{\\Delta U=T\\dot{M}}&{\\mathrm{in}\\;\\;D}\\\\ {U=0}&{\\mathrm{in}\\;\\;\\delta D}\\end{array}\\right.\n$$\n\nLet us get the weak form of (9.3). Multiply by a test function $\\phi$ and integrate over $\\mathtt{R}^{\\mathtt{d}}$ pretending $\\dot{M}$ is smooth. Suppose $\\phi=0$ on $\\delta D$. We can then do two integrations by parts to get  \n\n$$\n\\int{U(x)\\,\\Delta\\phi(x)\\,dx}=\\int_{D}T\\dot{M}\\phi(x)dx.\n$$  \n\nLet T\\* be the formal adjoint of T. If $T$ is a zeroth or first order",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "u(y)=\\int{K(x,y)\\,f(x)\\,dx}=K(f,y),",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/An_Introduction_To_Stochastic_Partial_Differe.pdf_151",
        "ID": "045abe0c-9f93-432a-9175-198fef88a6fd",
        "questions": "In the weak form of a stochastic partial differential equation, after performing two integrations by parts, which equation relates the function $U(x)$ and the differential operator $T$ applied to a measure $\\dot{M}$?",
        "answers": "\\int{U(x)\\,\\Delta\\phi(x)\\,dx}=\\int_{D}T\\dot{M}\\phi(x)dx.",
        "context": "# CHAPTER NINE  \n\nWe have spent most of our time on parabolic equations: non-parabolic equations have made only token appearances, such as at the beginning of these notes when we took a brief glance at the wave equation, which is hyperbolic. It is fitting to end with a brief glance at a token elliptic, Laplace's equation.  \n\nWe will give one existence and uniqueness theorem for bounded regions and then see how such equations arise as the limits of parabolic equations. In particular, we will look at the limits of the Brownian density process as $t \\to \\infty$  \n\nLet D be a bounded domain in $\\mathtt{R}^{\\mathtt{d}}$ with a smooth boundary. Consider  \n\n$$\n\\left\\{\\begin{array}{r l}{\\Delta u=f}&{\\mathrm{in}\\;\\;D}\\\\ {u=0}&{\\mathrm{on}\\;\\;\\delta D}\\end{array}\\right.\n$$\n\nIf f is bounded and continuous, the solution to (9.1) is  \n\n$$\nu(y)=\\int{K(x,y)\\,f(x)\\,dx}=K(f,y),\n$$  \n\nwhere $K$ is the Green's function for (9.1). Notice that in particular $\\Delta K(f,y)=f(y)$.  \n\nLet $M$ be an $L^{2}$-valued measure on $\\mathtt{R}^{\\mathtt{d}}$ (not a martingale measure, for there is no $t$ in the problem!) Set $Q(A,B)=E\\{M(A)M(B)\\}$ and suppose that there exists a positive definite measure $\\tilde{Q}$ on $\\mathtt{R}^{\\mathtt{d}}\\times\\mathtt{R}^{\\mathtt{d}}$ such that $\\left|Q(A,B)\\right|~\\leq~\\tilde{Q}(A\\times B)$ for all Borel $A, B\\subset\\mathtt{R}^{\\mathtt{d}}$. This assures of a good integration theory. We also assume for convenience that $M(\\delta D)=0$  \n\nLet $T$ be a kth order differential operator on $\\mathtt{R}^{\\mathtt{d}}$ with smooth coefficients $(0\\leq k <\\infty)$ and consider the SPDE  \n\n$$\n\\left\\{\\begin{array}{r l}{\\Delta U=T\\dot{M}}&{\\mathrm{in}\\;\\;D}\\\\ {U=0}&{\\mathrm{in}\\;\\;\\delta D}\\end{array}\\right.\n$$\n\nLet us get the weak form of (9.3). Multiply by a test function $\\phi$ and integrate over $\\mathtt{R}^{\\mathtt{d}}$ pretending $\\dot{M}$ is smooth. Suppose $\\phi=0$ on $\\delta D$. We can then do two integrations by parts to get  \n\n$$\n\\int{U(x)\\,\\Delta\\phi(x)\\,dx}=\\int_{D}T\\dot{M}\\phi(x)dx.\n$$  \n\nLet T\\* be the formal adjoint of T. If $T$ is a zeroth or first order",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Equation",
        "evidence_source": "equation",
        "evidence_context": "\\int{U(x)\\,\\Delta\\phi(x)\\,dx}=\\int_{D}T\\dot{M}\\phi(x)dx.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/textbook_needrop_en_75",
        "ID": "0461d287-dde9-45d2-8dcb-9b62f9a847f5",
        "questions": "According to Theorem 2.2, what is the maximum-norm stability estimate for function u in terms of its boundary values?",
        "answers": "The maximum-norm stability estimate for function u is given by ||u||_C \u2264 max{|u(0)|, |u(1)|} + C||Au||_C.",
        "context": "\uff08ii) If $u \\leq 0$ in $\\pmb{\\mathscr{Q}}$, then (2.7) holds trivially. Otherwise, assume that $\\mathrm{max}_{\\bar{\\varOmega}} u = u\\bigl(x_{0}\\bigr) > 0$ and $x_{0} \\neq 0, 1$. Let $(\\alpha, \\beta)$ be the largest sub interval of $\\varOmega$ containing $\\pmb{x_{0}}$ in which $u > 0$. We now have $\\tilde{\\mathcal{A}}u := \\tilde{\\mathcal{A}}u - c u \\leq 0$ in $(\\alpha, \\beta)$. Part (i), applied with the operator $\\tilde{A}$ in the interval $(\\alpha, \\beta)$, therefore implies $u(x_{0}) = \\operatorname*{max}\\{u(\\alpha), u(\\beta)\\}$. But then $\\pmb{\\alpha}$ and $\\beta$ could not both be interior points of $\\varOmega$, for then neither $u(\\alpha)$ or $\\pmb{u}(\\beta)$ would be positive, and the interval $(\\alpha, \\beta)$ would not be as large as possible with $u > 0$. This implies $u(x_{0}) = \\mathrm{max}\\{u(0), u(1)\\}$ and hence (2.7).\n\nAs a consequence of this theorem, we have the following stability estimate with respect to the maximum-norm, where we use the notation of Sect. 1.2.\n\nTheorem 2.2. Let $A$ be as in (2.1) and (2.2). If $u \\in \\mathcal{C}^{2}$, then\n\n$$\n\\|u\\|_{\\mathcal{C}} \\leq \\operatorname*{max}\\left\\{|u(0)|, |u(1)|\\right\\} + C\\|A u\\|_{\\mathcal{C}}.\n$$\n\nThe constant $C$ depends on the coefficients of $\\pmb{A}$ but not on $\\pmb{u}$.\n\nProof. We shall bound the maxima of $\\pm u$. We set $\\phi(x) = {\\bf e}^{\\lambda} - {\\bf e}^{\\lambda x}$ and define the two functions\n\n$$\nv_{\\pm}(x) = \\pm u(x) - \\|A u\\|c \\, \\phi(x).\n$$\n\nSince $\\phi \\geq 0$ in $\\varOmega$ and $\\begin{array}{r}{A\\phi = c\\mathrm{e}^{\\lambda} + (a\\lambda^{2} + (a^{\\prime} - b)\\lambda - c)\\mathrm{e}^{\\lambda x} \\geq 1}\\end{array}$ in $\\bar{\\varOmega}$, if $\\lambda > 0$ is chosen sufficiently large, we have, with such a choice of $\\lambda$,\n\n$$\n\\pmb{\\mathcal{A}}v_{\\pm} = \\pm\\pmb{\\mathcal{A}}u - \\|\\pmb{\\mathcal{A}}u\\|_{C}\\pmb{\\mathcal{A}}\\phi \\leq \\pm\\pmb{\\mathcal{A}}u - \\|\\pmb{\\mathcal{A}}u\\|_{C} \\leq 0 \\quad \\mathrm{in~} \\Omega.\n$$\n\nTheorem 2.1 (ii) therefore yields\n\n$$\n\\begin{array}{r l}&{\\underset{\\bar{\\Omega}}{\\operatorname*{max}}(v_{\\pm}) \\leq \\operatorname*{max}\\big\\{v_{\\pm}(0), v_{\\pm}(1), 0\\big\\}}\\\\ &{\\qquad\\qquad \\leq \\operatorname*{max}\\big\\{\\pm u(0), \\pm u(1), 0\\big\\} \\leq \\operatorname*{max}\\big\\{|u(0)|, |u(1)|\\big\\},}\\end{array}\n$$\n\nbecause $v_{\\pm}(x) \\leq \\pm u(x)$ for all $\\pmb{x}$. Hence\n\n$$\n\\begin{array}{r l}&{\\underset{\\bar{\\Omega}}{\\operatorname*{max}}(\\pm u) = \\underset{\\bar{\\Omega}}{\\operatorname*{max}}\\left(v_{\\pm} + \\|\\mathcal{A}u\\|_{C} \\, \\phi\\right) \\leq \\underset{\\bar{\\Omega}}{\\operatorname*{max}}(v_{\\pm}) + \\|\\mathcal{A}u\\|_{C}\\|\\phi\\|_{C}}\\\\ &{\\qquad\\qquad \\leq \\operatorname*{max}\\big\\{|u(0)|, |u(1)|\\big\\} + C\\|\\mathcal{A}u\\|_{C}, \\quad \\mathrm{with~} C = \\|\\phi\\|_{C},}\\end{array}\n$$\n\nwhich completes the proof.\n\nFrom Theorem 2.2, we immediately conclude the uniqueness of a solution of (2.1). In fact, if $u$ and $v$ were two solutions, then their difference $w = u - v$ would satisfy $\\mathcal{A}w = 0$ $\\begin{array}{r}{\\pmb{w}(0) = \\pmb{w}(1) = \\mathbf{0}.}\\end{array}$, and hence $\\|w\\|_{\\cal C} = 0$, so that $\\pmb{u} = \\pmb{v}$.\n\nMore generally, if $\\pmb{u}$ and $\\boldsymbol{\\upsilon}$ are two solutions of (2.1) with right hand sides $f$ and $\\pmb{g}$ and boundary values $\\mathbf{\\mathit{u}}_{0}, \\mathbf{\\mathit{u}}_{1}$ and $v_{0}, v_{1}$, respectively, then\n\n$$\n\\|u - v\\|_{C} \\leq \\operatorname*{max}\\left\\{|u_{0} - v_{0}|, |u_{1} - v_{1}|\\right\\} + C\\|f - g\\|_{C}.\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "If $u \\in \\mathcal{C}^{2}$, then $$\\|u\\|_{\\mathcal{C}} \\leq \\operatorname*{max}\\left\\{|u(0)|, |u(1)|\right\\} + C\\|A u\\|_{\\mathcal{C}}.$$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/textbook_needrop_en_75",
        "ID": "04640385-3e14-4555-b323-2c2a52428b6a",
        "questions": "What does the proof conclude about the uniqueness of solutions for equation (2.1) if u and v are two potential solutions?",
        "answers": "The proof concludes that u = v, ensuring uniqueness.",
        "context": "\uff08ii) If $u \\leq 0$ in $\\pmb{\\mathscr{Q}}$, then (2.7) holds trivially. Otherwise, assume that $\\mathrm{max}_{\\bar{\\varOmega}} u = u\\bigl(x_{0}\\bigr) > 0$ and $x_{0} \\neq 0, 1$. Let $(\\alpha, \\beta)$ be the largest sub interval of $\\varOmega$ containing $\\pmb{x_{0}}$ in which $u > 0$. We now have $\\tilde{\\mathcal{A}}u := \\tilde{\\mathcal{A}}u - c u \\leq 0$ in $(\\alpha, \\beta)$. Part (i), applied with the operator $\\tilde{A}$ in the interval $(\\alpha, \\beta)$, therefore implies $u(x_{0}) = \\operatorname*{max}\\{u(\\alpha), u(\\beta)\\}$. But then $\\pmb{\\alpha}$ and $\\beta$ could not both be interior points of $\\varOmega$, for then neither $u(\\alpha)$ or $\\pmb{u}(\\beta)$ would be positive, and the interval $(\\alpha, \\beta)$ would not be as large as possible with $u > 0$. This implies $u(x_{0}) = \\mathrm{max}\\{u(0), u(1)\\}$ and hence (2.7).\n\nAs a consequence of this theorem, we have the following stability estimate with respect to the maximum-norm, where we use the notation of Sect. 1.2.\n\nTheorem 2.2. Let $A$ be as in (2.1) and (2.2). If $u \\in \\mathcal{C}^{2}$, then\n\n$$\n\\|u\\|_{\\mathcal{C}} \\leq \\operatorname*{max}\\left\\{|u(0)|, |u(1)|\\right\\} + C\\|A u\\|_{\\mathcal{C}}.\n$$\n\nThe constant $C$ depends on the coefficients of $\\pmb{A}$ but not on $\\pmb{u}$.\n\nProof. We shall bound the maxima of $\\pm u$. We set $\\phi(x) = {\\bf e}^{\\lambda} - {\\bf e}^{\\lambda x}$ and define the two functions\n\n$$\nv_{\\pm}(x) = \\pm u(x) - \\|A u\\|c \\, \\phi(x).\n$$\n\nSince $\\phi \\geq 0$ in $\\varOmega$ and $\\begin{array}{r}{A\\phi = c\\mathrm{e}^{\\lambda} + (a\\lambda^{2} + (a^{\\prime} - b)\\lambda - c)\\mathrm{e}^{\\lambda x} \\geq 1}\\end{array}$ in $\\bar{\\varOmega}$, if $\\lambda > 0$ is chosen sufficiently large, we have, with such a choice of $\\lambda$,\n\n$$\n\\pmb{\\mathcal{A}}v_{\\pm} = \\pm\\pmb{\\mathcal{A}}u - \\|\\pmb{\\mathcal{A}}u\\|_{C}\\pmb{\\mathcal{A}}\\phi \\leq \\pm\\pmb{\\mathcal{A}}u - \\|\\pmb{\\mathcal{A}}u\\|_{C} \\leq 0 \\quad \\mathrm{in~} \\Omega.\n$$\n\nTheorem 2.1 (ii) therefore yields\n\n$$\n\\begin{array}{r l}&{\\underset{\\bar{\\Omega}}{\\operatorname*{max}}(v_{\\pm}) \\leq \\operatorname*{max}\\big\\{v_{\\pm}(0), v_{\\pm}(1), 0\\big\\}}\\\\ &{\\qquad\\qquad \\leq \\operatorname*{max}\\big\\{\\pm u(0), \\pm u(1), 0\\big\\} \\leq \\operatorname*{max}\\big\\{|u(0)|, |u(1)|\\big\\},}\\end{array}\n$$\n\nbecause $v_{\\pm}(x) \\leq \\pm u(x)$ for all $\\pmb{x}$. Hence\n\n$$\n\\begin{array}{r l}&{\\underset{\\bar{\\Omega}}{\\operatorname*{max}}(\\pm u) = \\underset{\\bar{\\Omega}}{\\operatorname*{max}}\\left(v_{\\pm} + \\|\\mathcal{A}u\\|_{C} \\, \\phi\\right) \\leq \\underset{\\bar{\\Omega}}{\\operatorname*{max}}(v_{\\pm}) + \\|\\mathcal{A}u\\|_{C}\\|\\phi\\|_{C}}\\\\ &{\\qquad\\qquad \\leq \\operatorname*{max}\\big\\{|u(0)|, |u(1)|\\big\\} + C\\|\\mathcal{A}u\\|_{C}, \\quad \\mathrm{with~} C = \\|\\phi\\|_{C},}\\end{array}\n$$\n\nwhich completes the proof.\n\nFrom Theorem 2.2, we immediately conclude the uniqueness of a solution of (2.1). In fact, if $u$ and $v$ were two solutions, then their difference $w = u - v$ would satisfy $\\mathcal{A}w = 0$ $\\begin{array}{r}{\\pmb{w}(0) = \\pmb{w}(1) = \\mathbf{0}.}\\end{array}$, and hence $\\|w\\|_{\\cal C} = 0$, so that $\\pmb{u} = \\pmb{v}$.\n\nMore generally, if $\\pmb{u}$ and $\\boldsymbol{\\upsilon}$ are two solutions of (2.1) with right hand sides $f$ and $\\pmb{g}$ and boundary values $\\mathbf{\\mathit{u}}_{0}, \\mathbf{\\mathit{u}}_{1}$ and $v_{0}, v_{1}$, respectively, then\n\n$$\n\\|u - v\\|_{C} \\leq \\operatorname*{max}\\left\\{|u_{0} - v_{0}|, |u_{1} - v_{1}|\\right\\} + C\\|f - g\\|_{C}.\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "In fact, if $u$ and $v$ were two solutions, then their difference $w = u - v$ would satisfy $\\mathcal{A}w = 0$ $\begin{array}{r}{\\pmb{w}(0) = \\pmb{w}(1) = \\mathbf{0}.}\\end{array}$, and hence $\\|w\\|_{\\cal C} = 0$, so that $\\pmb{u} = \\pmb{v}$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/textbook_needrop_en_75",
        "ID": "046736c5-6cd9-41bb-9db4-50ccff730758",
        "questions": "How is the function \u03c6(x) defined in the document when proving Theorem 2.2?",
        "answers": "The function \u03c6(x) is defined as \u03c6(x) = e^\u03bb - e^{\u03bbx}.",
        "context": "\uff08ii) If $u \\leq 0$ in $\\pmb{\\mathscr{Q}}$, then (2.7) holds trivially. Otherwise, assume that $\\mathrm{max}_{\\bar{\\varOmega}} u = u\\bigl(x_{0}\\bigr) > 0$ and $x_{0} \\neq 0, 1$. Let $(\\alpha, \\beta)$ be the largest sub interval of $\\varOmega$ containing $\\pmb{x_{0}}$ in which $u > 0$. We now have $\\tilde{\\mathcal{A}}u := \\tilde{\\mathcal{A}}u - c u \\leq 0$ in $(\\alpha, \\beta)$. Part (i), applied with the operator $\\tilde{A}$ in the interval $(\\alpha, \\beta)$, therefore implies $u(x_{0}) = \\operatorname*{max}\\{u(\\alpha), u(\\beta)\\}$. But then $\\pmb{\\alpha}$ and $\\beta$ could not both be interior points of $\\varOmega$, for then neither $u(\\alpha)$ or $\\pmb{u}(\\beta)$ would be positive, and the interval $(\\alpha, \\beta)$ would not be as large as possible with $u > 0$. This implies $u(x_{0}) = \\mathrm{max}\\{u(0), u(1)\\}$ and hence (2.7).\n\nAs a consequence of this theorem, we have the following stability estimate with respect to the maximum-norm, where we use the notation of Sect. 1.2.\n\nTheorem 2.2. Let $A$ be as in (2.1) and (2.2). If $u \\in \\mathcal{C}^{2}$, then\n\n$$\n\\|u\\|_{\\mathcal{C}} \\leq \\operatorname*{max}\\left\\{|u(0)|, |u(1)|\\right\\} + C\\|A u\\|_{\\mathcal{C}}.\n$$\n\nThe constant $C$ depends on the coefficients of $\\pmb{A}$ but not on $\\pmb{u}$.\n\nProof. We shall bound the maxima of $\\pm u$. We set $\\phi(x) = {\\bf e}^{\\lambda} - {\\bf e}^{\\lambda x}$ and define the two functions\n\n$$\nv_{\\pm}(x) = \\pm u(x) - \\|A u\\|c \\, \\phi(x).\n$$\n\nSince $\\phi \\geq 0$ in $\\varOmega$ and $\\begin{array}{r}{A\\phi = c\\mathrm{e}^{\\lambda} + (a\\lambda^{2} + (a^{\\prime} - b)\\lambda - c)\\mathrm{e}^{\\lambda x} \\geq 1}\\end{array}$ in $\\bar{\\varOmega}$, if $\\lambda > 0$ is chosen sufficiently large, we have, with such a choice of $\\lambda$,\n\n$$\n\\pmb{\\mathcal{A}}v_{\\pm} = \\pm\\pmb{\\mathcal{A}}u - \\|\\pmb{\\mathcal{A}}u\\|_{C}\\pmb{\\mathcal{A}}\\phi \\leq \\pm\\pmb{\\mathcal{A}}u - \\|\\pmb{\\mathcal{A}}u\\|_{C} \\leq 0 \\quad \\mathrm{in~} \\Omega.\n$$\n\nTheorem 2.1 (ii) therefore yields\n\n$$\n\\begin{array}{r l}&{\\underset{\\bar{\\Omega}}{\\operatorname*{max}}(v_{\\pm}) \\leq \\operatorname*{max}\\big\\{v_{\\pm}(0), v_{\\pm}(1), 0\\big\\}}\\\\ &{\\qquad\\qquad \\leq \\operatorname*{max}\\big\\{\\pm u(0), \\pm u(1), 0\\big\\} \\leq \\operatorname*{max}\\big\\{|u(0)|, |u(1)|\\big\\},}\\end{array}\n$$\n\nbecause $v_{\\pm}(x) \\leq \\pm u(x)$ for all $\\pmb{x}$. Hence\n\n$$\n\\begin{array}{r l}&{\\underset{\\bar{\\Omega}}{\\operatorname*{max}}(\\pm u) = \\underset{\\bar{\\Omega}}{\\operatorname*{max}}\\left(v_{\\pm} + \\|\\mathcal{A}u\\|_{C} \\, \\phi\\right) \\leq \\underset{\\bar{\\Omega}}{\\operatorname*{max}}(v_{\\pm}) + \\|\\mathcal{A}u\\|_{C}\\|\\phi\\|_{C}}\\\\ &{\\qquad\\qquad \\leq \\operatorname*{max}\\big\\{|u(0)|, |u(1)|\\big\\} + C\\|\\mathcal{A}u\\|_{C}, \\quad \\mathrm{with~} C = \\|\\phi\\|_{C},}\\end{array}\n$$\n\nwhich completes the proof.\n\nFrom Theorem 2.2, we immediately conclude the uniqueness of a solution of (2.1). In fact, if $u$ and $v$ were two solutions, then their difference $w = u - v$ would satisfy $\\mathcal{A}w = 0$ $\\begin{array}{r}{\\pmb{w}(0) = \\pmb{w}(1) = \\mathbf{0}.}\\end{array}$, and hence $\\|w\\|_{\\cal C} = 0$, so that $\\pmb{u} = \\pmb{v}$.\n\nMore generally, if $\\pmb{u}$ and $\\boldsymbol{\\upsilon}$ are two solutions of (2.1) with right hand sides $f$ and $\\pmb{g}$ and boundary values $\\mathbf{\\mathit{u}}_{0}, \\mathbf{\\mathit{u}}_{1}$ and $v_{0}, v_{1}$, respectively, then\n\n$$\n\\|u - v\\|_{C} \\leq \\operatorname*{max}\\left\\{|u_{0} - v_{0}|, |u_{1} - v_{1}|\\right\\} + C\\|f - g\\|_{C}.\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "We set $\\phi(x) = {\bf e}^{\\lambda} - {\bf e}^{\\lambda x}$ and define the two functions.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/textbook_needrop_en_75",
        "ID": "047cd56e-fd6c-4364-8191-cbeb175bf448",
        "questions": "What is the upper bound for the maximum norm of a function $u$ given it satisfies $u \\in \\mathcal{C}^{2}$ and is related to the operator $A$?",
        "answers": "$\\|u\\|_{\\mathcal{C}} \\leq \\operatorname*{max}\\left\\{|u(0)|, |u(1)|\\right\\} + C\\|A u\\|_{\\mathcal{C}}.$",
        "context": "\uff08ii) If $u \\leq 0$ in $\\pmb{\\mathscr{Q}}$, then (2.7) holds trivially. Otherwise, assume that $\\mathrm{max}_{\\bar{\\varOmega}} u = u\\bigl(x_{0}\\bigr) > 0$ and $x_{0} \\neq 0, 1$. Let $(\\alpha, \\beta)$ be the largest sub interval of $\\varOmega$ containing $\\pmb{x_{0}}$ in which $u > 0$. We now have $\\tilde{\\mathcal{A}}u := \\tilde{\\mathcal{A}}u - c u \\leq 0$ in $(\\alpha, \\beta)$. Part (i), applied with the operator $\\tilde{A}$ in the interval $(\\alpha, \\beta)$, therefore implies $u(x_{0}) = \\operatorname*{max}\\{u(\\alpha), u(\\beta)\\}$. But then $\\pmb{\\alpha}$ and $\\beta$ could not both be interior points of $\\varOmega$, for then neither $u(\\alpha)$ or $\\pmb{u}(\\beta)$ would be positive, and the interval $(\\alpha, \\beta)$ would not be as large as possible with $u > 0$. This implies $u(x_{0}) = \\mathrm{max}\\{u(0), u(1)\\}$ and hence (2.7).\n\nAs a consequence of this theorem, we have the following stability estimate with respect to the maximum-norm, where we use the notation of Sect. 1.2.\n\nTheorem 2.2. Let $A$ be as in (2.1) and (2.2). If $u \\in \\mathcal{C}^{2}$, then\n\n$$\n\\|u\\|_{\\mathcal{C}} \\leq \\operatorname*{max}\\left\\{|u(0)|, |u(1)|\\right\\} + C\\|A u\\|_{\\mathcal{C}}.\n$$\n\nThe constant $C$ depends on the coefficients of $\\pmb{A}$ but not on $\\pmb{u}$.\n\nProof. We shall bound the maxima of $\\pm u$. We set $\\phi(x) = {\\bf e}^{\\lambda} - {\\bf e}^{\\lambda x}$ and define the two functions\n\n$$\nv_{\\pm}(x) = \\pm u(x) - \\|A u\\|c \\, \\phi(x).\n$$\n\nSince $\\phi \\geq 0$ in $\\varOmega$ and $\\begin{array}{r}{A\\phi = c\\mathrm{e}^{\\lambda} + (a\\lambda^{2} + (a^{\\prime} - b)\\lambda - c)\\mathrm{e}^{\\lambda x} \\geq 1}\\end{array}$ in $\\bar{\\varOmega}$, if $\\lambda > 0$ is chosen sufficiently large, we have, with such a choice of $\\lambda$,\n\n$$\n\\pmb{\\mathcal{A}}v_{\\pm} = \\pm\\pmb{\\mathcal{A}}u - \\|\\pmb{\\mathcal{A}}u\\|_{C}\\pmb{\\mathcal{A}}\\phi \\leq \\pm\\pmb{\\mathcal{A}}u - \\|\\pmb{\\mathcal{A}}u\\|_{C} \\leq 0 \\quad \\mathrm{in~} \\Omega.\n$$\n\nTheorem 2.1 (ii) therefore yields\n\n$$\n\\begin{array}{r l}&{\\underset{\\bar{\\Omega}}{\\operatorname*{max}}(v_{\\pm}) \\leq \\operatorname*{max}\\big\\{v_{\\pm}(0), v_{\\pm}(1), 0\\big\\}}\\\\ &{\\qquad\\qquad \\leq \\operatorname*{max}\\big\\{\\pm u(0), \\pm u(1), 0\\big\\} \\leq \\operatorname*{max}\\big\\{|u(0)|, |u(1)|\\big\\},}\\end{array}\n$$\n\nbecause $v_{\\pm}(x) \\leq \\pm u(x)$ for all $\\pmb{x}$. Hence\n\n$$\n\\begin{array}{r l}&{\\underset{\\bar{\\Omega}}{\\operatorname*{max}}(\\pm u) = \\underset{\\bar{\\Omega}}{\\operatorname*{max}}\\left(v_{\\pm} + \\|\\mathcal{A}u\\|_{C} \\, \\phi\\right) \\leq \\underset{\\bar{\\Omega}}{\\operatorname*{max}}(v_{\\pm}) + \\|\\mathcal{A}u\\|_{C}\\|\\phi\\|_{C}}\\\\ &{\\qquad\\qquad \\leq \\operatorname*{max}\\big\\{|u(0)|, |u(1)|\\big\\} + C\\|\\mathcal{A}u\\|_{C}, \\quad \\mathrm{with~} C = \\|\\phi\\|_{C},}\\end{array}\n$$\n\nwhich completes the proof.\n\nFrom Theorem 2.2, we immediately conclude the uniqueness of a solution of (2.1). In fact, if $u$ and $v$ were two solutions, then their difference $w = u - v$ would satisfy $\\mathcal{A}w = 0$ $\\begin{array}{r}{\\pmb{w}(0) = \\pmb{w}(1) = \\mathbf{0}.}\\end{array}$, and hence $\\|w\\|_{\\cal C} = 0$, so that $\\pmb{u} = \\pmb{v}$.\n\nMore generally, if $\\pmb{u}$ and $\\boldsymbol{\\upsilon}$ are two solutions of (2.1) with right hand sides $f$ and $\\pmb{g}$ and boundary values $\\mathbf{\\mathit{u}}_{0}, \\mathbf{\\mathit{u}}_{1}$ and $v_{0}, v_{1}$, respectively, then\n\n$$\n\\|u - v\\|_{C} \\leq \\operatorname*{max}\\left\\{|u_{0} - v_{0}|, |u_{1} - v_{1}|\\right\\} + C\\|f - g\\|_{C}.\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "If $u \\in \\mathcal{C}^{2}$, then $$ \\|u\\|_{\\mathcal{C}} \\leq \\operatorname*{max}\\left\\{|u(0)|, |u(1)|\\right\\} + C\\|A u\\|_{\\mathcal{C}}.$$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/textbook_needrop_en_75",
        "ID": "0482d7b1-0b5b-4161-9eda-995b78c0aefd",
        "questions": "What inequality must be satisfied by the function $v_{\\pm}$ in relation to the operator $\\pmb{\\mathcal{A}}$?",
        "answers": "$\\pmb{\\mathcal{A}}v_{\\pm} = \\pm\\pmb{\\mathcal{A}}u - \\|\\pmb{\\mathcal{A}}u\\|_{C}\\pmb{\\mathcal{A}}\\phi \\leq \\pm\\pmb{\\mathcal{A}}u - \\|\\pmb{\\mathcal{A}}u\\|_{C} \\leq 0 \\quad \\mathrm{in~} \\Omega.$",
        "context": "\uff08ii) If $u \\leq 0$ in $\\pmb{\\mathscr{Q}}$, then (2.7) holds trivially. Otherwise, assume that $\\mathrm{max}_{\\bar{\\varOmega}} u = u\\bigl(x_{0}\\bigr) > 0$ and $x_{0} \\neq 0, 1$. Let $(\\alpha, \\beta)$ be the largest sub interval of $\\varOmega$ containing $\\pmb{x_{0}}$ in which $u > 0$. We now have $\\tilde{\\mathcal{A}}u := \\tilde{\\mathcal{A}}u - c u \\leq 0$ in $(\\alpha, \\beta)$. Part (i), applied with the operator $\\tilde{A}$ in the interval $(\\alpha, \\beta)$, therefore implies $u(x_{0}) = \\operatorname*{max}\\{u(\\alpha), u(\\beta)\\}$. But then $\\pmb{\\alpha}$ and $\\beta$ could not both be interior points of $\\varOmega$, for then neither $u(\\alpha)$ or $\\pmb{u}(\\beta)$ would be positive, and the interval $(\\alpha, \\beta)$ would not be as large as possible with $u > 0$. This implies $u(x_{0}) = \\mathrm{max}\\{u(0), u(1)\\}$ and hence (2.7).\n\nAs a consequence of this theorem, we have the following stability estimate with respect to the maximum-norm, where we use the notation of Sect. 1.2.\n\nTheorem 2.2. Let $A$ be as in (2.1) and (2.2). If $u \\in \\mathcal{C}^{2}$, then\n\n$$\n\\|u\\|_{\\mathcal{C}} \\leq \\operatorname*{max}\\left\\{|u(0)|, |u(1)|\\right\\} + C\\|A u\\|_{\\mathcal{C}}.\n$$\n\nThe constant $C$ depends on the coefficients of $\\pmb{A}$ but not on $\\pmb{u}$.\n\nProof. We shall bound the maxima of $\\pm u$. We set $\\phi(x) = {\\bf e}^{\\lambda} - {\\bf e}^{\\lambda x}$ and define the two functions\n\n$$\nv_{\\pm}(x) = \\pm u(x) - \\|A u\\|c \\, \\phi(x).\n$$\n\nSince $\\phi \\geq 0$ in $\\varOmega$ and $\\begin{array}{r}{A\\phi = c\\mathrm{e}^{\\lambda} + (a\\lambda^{2} + (a^{\\prime} - b)\\lambda - c)\\mathrm{e}^{\\lambda x} \\geq 1}\\end{array}$ in $\\bar{\\varOmega}$, if $\\lambda > 0$ is chosen sufficiently large, we have, with such a choice of $\\lambda$,\n\n$$\n\\pmb{\\mathcal{A}}v_{\\pm} = \\pm\\pmb{\\mathcal{A}}u - \\|\\pmb{\\mathcal{A}}u\\|_{C}\\pmb{\\mathcal{A}}\\phi \\leq \\pm\\pmb{\\mathcal{A}}u - \\|\\pmb{\\mathcal{A}}u\\|_{C} \\leq 0 \\quad \\mathrm{in~} \\Omega.\n$$\n\nTheorem 2.1 (ii) therefore yields\n\n$$\n\\begin{array}{r l}&{\\underset{\\bar{\\Omega}}{\\operatorname*{max}}(v_{\\pm}) \\leq \\operatorname*{max}\\big\\{v_{\\pm}(0), v_{\\pm}(1), 0\\big\\}}\\\\ &{\\qquad\\qquad \\leq \\operatorname*{max}\\big\\{\\pm u(0), \\pm u(1), 0\\big\\} \\leq \\operatorname*{max}\\big\\{|u(0)|, |u(1)|\\big\\},}\\end{array}\n$$\n\nbecause $v_{\\pm}(x) \\leq \\pm u(x)$ for all $\\pmb{x}$. Hence\n\n$$\n\\begin{array}{r l}&{\\underset{\\bar{\\Omega}}{\\operatorname*{max}}(\\pm u) = \\underset{\\bar{\\Omega}}{\\operatorname*{max}}\\left(v_{\\pm} + \\|\\mathcal{A}u\\|_{C} \\, \\phi\\right) \\leq \\underset{\\bar{\\Omega}}{\\operatorname*{max}}(v_{\\pm}) + \\|\\mathcal{A}u\\|_{C}\\|\\phi\\|_{C}}\\\\ &{\\qquad\\qquad \\leq \\operatorname*{max}\\big\\{|u(0)|, |u(1)|\\big\\} + C\\|\\mathcal{A}u\\|_{C}, \\quad \\mathrm{with~} C = \\|\\phi\\|_{C},}\\end{array}\n$$\n\nwhich completes the proof.\n\nFrom Theorem 2.2, we immediately conclude the uniqueness of a solution of (2.1). In fact, if $u$ and $v$ were two solutions, then their difference $w = u - v$ would satisfy $\\mathcal{A}w = 0$ $\\begin{array}{r}{\\pmb{w}(0) = \\pmb{w}(1) = \\mathbf{0}.}\\end{array}$, and hence $\\|w\\|_{\\cal C} = 0$, so that $\\pmb{u} = \\pmb{v}$.\n\nMore generally, if $\\pmb{u}$ and $\\boldsymbol{\\upsilon}$ are two solutions of (2.1) with right hand sides $f$ and $\\pmb{g}$ and boundary values $\\mathbf{\\mathit{u}}_{0}, \\mathbf{\\mathit{u}}_{1}$ and $v_{0}, v_{1}$, respectively, then\n\n$$\n\\|u - v\\|_{C} \\leq \\operatorname*{max}\\left\\{|u_{0} - v_{0}|, |u_{1} - v_{1}|\\right\\} + C\\|f - g\\|_{C}.\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$\\pmb{\\mathcal{A}}v_{\\pm} = \\pm\\pmb{\\mathcal{A}}u - \\|\\pmb{\\mathcal{A}}u\\|_{C}\\pmb{\\mathcal{A}}\\phi \\leq \\pm\\pmb{\\mathcal{A}}u - \\|\\pmb{\\mathcal{A}}u\\|_{C} \\leq 0 \\quad \\mathrm{in~} \\Omega.$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/textbook_needrop_en_75",
        "ID": "0487ff4a-7967-4ae8-912e-368d633344fb",
        "questions": "Under what condition is the function $\\pmb{u}$ equal to $\\pmb{v}$ considering they are solutions of equation (2.1) and their difference satisfies $\\mathcal{A}w = 0$?",
        "answers": "If $\\|w\\|_{\\cal C} = 0$, then $\\pmb{u} = \\pmb{v}$.",
        "context": "\uff08ii) If $u \\leq 0$ in $\\pmb{\\mathscr{Q}}$, then (2.7) holds trivially. Otherwise, assume that $\\mathrm{max}_{\\bar{\\varOmega}} u = u\\bigl(x_{0}\\bigr) > 0$ and $x_{0} \\neq 0, 1$. Let $(\\alpha, \\beta)$ be the largest sub interval of $\\varOmega$ containing $\\pmb{x_{0}}$ in which $u > 0$. We now have $\\tilde{\\mathcal{A}}u := \\tilde{\\mathcal{A}}u - c u \\leq 0$ in $(\\alpha, \\beta)$. Part (i), applied with the operator $\\tilde{A}$ in the interval $(\\alpha, \\beta)$, therefore implies $u(x_{0}) = \\operatorname*{max}\\{u(\\alpha), u(\\beta)\\}$. But then $\\pmb{\\alpha}$ and $\\beta$ could not both be interior points of $\\varOmega$, for then neither $u(\\alpha)$ or $\\pmb{u}(\\beta)$ would be positive, and the interval $(\\alpha, \\beta)$ would not be as large as possible with $u > 0$. This implies $u(x_{0}) = \\mathrm{max}\\{u(0), u(1)\\}$ and hence (2.7).\n\nAs a consequence of this theorem, we have the following stability estimate with respect to the maximum-norm, where we use the notation of Sect. 1.2.\n\nTheorem 2.2. Let $A$ be as in (2.1) and (2.2). If $u \\in \\mathcal{C}^{2}$, then\n\n$$\n\\|u\\|_{\\mathcal{C}} \\leq \\operatorname*{max}\\left\\{|u(0)|, |u(1)|\\right\\} + C\\|A u\\|_{\\mathcal{C}}.\n$$\n\nThe constant $C$ depends on the coefficients of $\\pmb{A}$ but not on $\\pmb{u}$.\n\nProof. We shall bound the maxima of $\\pm u$. We set $\\phi(x) = {\\bf e}^{\\lambda} - {\\bf e}^{\\lambda x}$ and define the two functions\n\n$$\nv_{\\pm}(x) = \\pm u(x) - \\|A u\\|c \\, \\phi(x).\n$$\n\nSince $\\phi \\geq 0$ in $\\varOmega$ and $\\begin{array}{r}{A\\phi = c\\mathrm{e}^{\\lambda} + (a\\lambda^{2} + (a^{\\prime} - b)\\lambda - c)\\mathrm{e}^{\\lambda x} \\geq 1}\\end{array}$ in $\\bar{\\varOmega}$, if $\\lambda > 0$ is chosen sufficiently large, we have, with such a choice of $\\lambda$,\n\n$$\n\\pmb{\\mathcal{A}}v_{\\pm} = \\pm\\pmb{\\mathcal{A}}u - \\|\\pmb{\\mathcal{A}}u\\|_{C}\\pmb{\\mathcal{A}}\\phi \\leq \\pm\\pmb{\\mathcal{A}}u - \\|\\pmb{\\mathcal{A}}u\\|_{C} \\leq 0 \\quad \\mathrm{in~} \\Omega.\n$$\n\nTheorem 2.1 (ii) therefore yields\n\n$$\n\\begin{array}{r l}&{\\underset{\\bar{\\Omega}}{\\operatorname*{max}}(v_{\\pm}) \\leq \\operatorname*{max}\\big\\{v_{\\pm}(0), v_{\\pm}(1), 0\\big\\}}\\\\ &{\\qquad\\qquad \\leq \\operatorname*{max}\\big\\{\\pm u(0), \\pm u(1), 0\\big\\} \\leq \\operatorname*{max}\\big\\{|u(0)|, |u(1)|\\big\\},}\\end{array}\n$$\n\nbecause $v_{\\pm}(x) \\leq \\pm u(x)$ for all $\\pmb{x}$. Hence\n\n$$\n\\begin{array}{r l}&{\\underset{\\bar{\\Omega}}{\\operatorname*{max}}(\\pm u) = \\underset{\\bar{\\Omega}}{\\operatorname*{max}}\\left(v_{\\pm} + \\|\\mathcal{A}u\\|_{C} \\, \\phi\\right) \\leq \\underset{\\bar{\\Omega}}{\\operatorname*{max}}(v_{\\pm}) + \\|\\mathcal{A}u\\|_{C}\\|\\phi\\|_{C}}\\\\ &{\\qquad\\qquad \\leq \\operatorname*{max}\\big\\{|u(0)|, |u(1)|\\big\\} + C\\|\\mathcal{A}u\\|_{C}, \\quad \\mathrm{with~} C = \\|\\phi\\|_{C},}\\end{array}\n$$\n\nwhich completes the proof.\n\nFrom Theorem 2.2, we immediately conclude the uniqueness of a solution of (2.1). In fact, if $u$ and $v$ were two solutions, then their difference $w = u - v$ would satisfy $\\mathcal{A}w = 0$ $\\begin{array}{r}{\\pmb{w}(0) = \\pmb{w}(1) = \\mathbf{0}.}\\end{array}$, and hence $\\|w\\|_{\\cal C} = 0$, so that $\\pmb{u} = \\pmb{v}$.\n\nMore generally, if $\\pmb{u}$ and $\\boldsymbol{\\upsilon}$ are two solutions of (2.1) with right hand sides $f$ and $\\pmb{g}$ and boundary values $\\mathbf{\\mathit{u}}_{0}, \\mathbf{\\mathit{u}}_{1}$ and $v_{0}, v_{1}$, respectively, then\n\n$$\n\\|u - v\\|_{C} \\leq \\operatorname*{max}\\left\\{|u_{0} - v_{0}|, |u_{1} - v_{1}|\\right\\} + C\\|f - g\\|_{C}.\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "In fact, if $u$ and $v$ were two solutions, then their difference $w = u - v$ would satisfy $\\mathcal{A}w = 0$ $\\begin{array}{r}{\\pmb{w}(0) = \\pmb{w}(1) = \\mathbf{0}.}\\end{array}$, and hence $\\|w\\|_{\\cal C} = 0$, so that $\\pmb{u} = \\pmb{v}$.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/GTM239.Number.Theory.-.Volume.I.Tools.and.Diophantine.Equations,.Cohen,.H.,.(2007,.ISBN.978-0-387-49922-2).pdf_514",
        "ID": "048a07c4-2e08-4509-a5d2-73d0f1e0d225",
        "questions": "If $g(T)$ is not equal to a constant times the square of a rational function and $P$ is in $E_g(K)$, what condition is equivalent to $h(P) = 0$ according to Lemma 7.3.8?",
        "answers": "P = \\mathcal{O} or there exists $u \\in k$ such that $P = (u, 0)$",
        "context": "Lemma 7.3.8. Assume that $g(T)$ is not equal to a constant times the square of a rational function, and let $P \\in E_{g}(K)$. The following are equivalent:\n\n(1) $h(P) = 0$\n\n(2) $P \\in E_{g}(k)$\n\n(3) Either $P = \\mathcal{O}$ or there exists $u \\in k$ such that $P = (u, 0)$\n\n(4) For all $Q \\in E_{g}(K)$ we have $h(P+Q)=h(Q)$; in other words, $B(P,Q) = 0$.\n\nProof. Since the result is trivial when $P = \\mathcal{O}$, assume that this is not the case and write as usual $P = (X_{P}, Y_{P})$. Clearly $h(P) = 0$ if and only if $X_{P} \\in k$, so we can write $X_{P} = u$. We thus have $g(T)Y_{P}^{2} = f(u)$, so that if $f(u) \\neq 0$, $g(T)$ is equal to a constant times the square of the rational function $1/Y_{P}$, contrary to our assumption. Thus $f(u) = 0$, so $Y_{P} = 0$ and $P = (u, 0)$, proving that (1) implies (3), and (3) implies (2) implies (1) is trivial, so that (1), (2), and (3) are equivalent. To prove that (3) implies (4), we note that if $Q = \\pm P$, we have $h(2P) = 4h(P) = 0$ and $h(P-P) = 0$; so (4) is clear, and (4) is also clear if $Q = \\mathcal{O}$. Otherwise, a simple computation using the addition law gives $X_{P+Q} = u + f^{\\prime}(u)/(X_{Q}-u)$, and since $f(u) = 0$ we have $f^{\\prime}(u) \\neq 0$, and this is easily seen to imply that $h(P+Q) = h(Q)$ as desired. Finally, (4) applied to $Q = k P$ for any $k \\in \\mathbb{Z}$ gives $(k+1)^{2}h(P) = h(P+Q) = h(Q) = k^{2}h(P)$; hence $h(P) = 0$, so (4) implies (1).\n\n# 7.3.4 Elliptic Curves over $\\mathbb{F}_{q}$\n\nWe begin with the following very easy lemma.\n\nLemma 7.3.9. Let $q$ be an odd prime power, let $\\rho$ be the unique multiplicative character of order 2 on $\\mathbb{F}_{q}$, and let $y^{2} = f(x)$ be the equation of an elliptic curve over $\\mathbb{F}_{q}$, where $f(X)$ is a polynomial of degree 3. Then $|E(\\mathbb{F}_{q})| = q+1-a_{q}$ with $a_{q} = -\\sum_{x\\in\\mathbb{F}_{q}} \\rho(f(x))$. In particular, if $q = p$ is prime, we have $|E(\\mathbb{F}_{p})| = p+1-a_{p}$ with\n\n$$\na_{p} = -\\sum_{x\\in\\mathbb{F}_{p}}\\left({\\frac{f(x)}{p}}\\right).\n$$\n\nProof. For a given $X \\in \\mathbb{F}_{q}$ it is clear that the number of $y \\in \\mathbb{F}_{q}$ such that $y^{2} = X$ is equal to $1 + \\rho(X)$. Counting the point at infinity separately, it follows that\n\n$$\n|E(\\mathbb{F}_{q})| = 1 + \\sum_{x\\in\\mathbb{F}_{q}}\\left(1 + \\rho(f(x))\\right) = q + 1 + \\sum_{x\\in\\mathbb{F}_{q}}\\rho(f(x)),\n$$\n\nproving the lemma.\n\nThe main result for curves over finite fields is Hasse's theorem giving precise bounds on the cardinality of $E(\\mathbb{F}_{q})$. Considering the importance of",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "The following are equivalent: (1) $h(P) = 0$ ... (3) Either $P = \\mathcal{O}$ or there exists $u \\in k$ such that $P = (u, 0)$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM239.Number.Theory.-.Volume.I.Tools.and.Diophantine.Equations,.Cohen,.H.,.(2007,.ISBN.978-0-387-49922-2).pdf_514",
        "ID": "049167c9-b519-4f8e-85f8-7f5c71347c31",
        "questions": "What is the size of the elliptic curve over the finite field $\\mathbb{F}_{q}$ given $y^{2} = f(x)$ and $f(X)$ is a polynomial of degree 3?",
        "answers": "q+1-a_{q}",
        "context": "Lemma 7.3.8. Assume that $g(T)$ is not equal to a constant times the square of a rational function, and let $P \\in E_{g}(K)$. The following are equivalent:\n\n(1) $h(P) = 0$\n\n(2) $P \\in E_{g}(k)$\n\n(3) Either $P = \\mathcal{O}$ or there exists $u \\in k$ such that $P = (u, 0)$\n\n(4) For all $Q \\in E_{g}(K)$ we have $h(P+Q)=h(Q)$; in other words, $B(P,Q) = 0$.\n\nProof. Since the result is trivial when $P = \\mathcal{O}$, assume that this is not the case and write as usual $P = (X_{P}, Y_{P})$. Clearly $h(P) = 0$ if and only if $X_{P} \\in k$, so we can write $X_{P} = u$. We thus have $g(T)Y_{P}^{2} = f(u)$, so that if $f(u) \\neq 0$, $g(T)$ is equal to a constant times the square of the rational function $1/Y_{P}$, contrary to our assumption. Thus $f(u) = 0$, so $Y_{P} = 0$ and $P = (u, 0)$, proving that (1) implies (3), and (3) implies (2) implies (1) is trivial, so that (1), (2), and (3) are equivalent. To prove that (3) implies (4), we note that if $Q = \\pm P$, we have $h(2P) = 4h(P) = 0$ and $h(P-P) = 0$; so (4) is clear, and (4) is also clear if $Q = \\mathcal{O}$. Otherwise, a simple computation using the addition law gives $X_{P+Q} = u + f^{\\prime}(u)/(X_{Q}-u)$, and since $f(u) = 0$ we have $f^{\\prime}(u) \\neq 0$, and this is easily seen to imply that $h(P+Q) = h(Q)$ as desired. Finally, (4) applied to $Q = k P$ for any $k \\in \\mathbb{Z}$ gives $(k+1)^{2}h(P) = h(P+Q) = h(Q) = k^{2}h(P)$; hence $h(P) = 0$, so (4) implies (1).\n\n# 7.3.4 Elliptic Curves over $\\mathbb{F}_{q}$\n\nWe begin with the following very easy lemma.\n\nLemma 7.3.9. Let $q$ be an odd prime power, let $\\rho$ be the unique multiplicative character of order 2 on $\\mathbb{F}_{q}$, and let $y^{2} = f(x)$ be the equation of an elliptic curve over $\\mathbb{F}_{q}$, where $f(X)$ is a polynomial of degree 3. Then $|E(\\mathbb{F}_{q})| = q+1-a_{q}$ with $a_{q} = -\\sum_{x\\in\\mathbb{F}_{q}} \\rho(f(x))$. In particular, if $q = p$ is prime, we have $|E(\\mathbb{F}_{p})| = p+1-a_{p}$ with\n\n$$\na_{p} = -\\sum_{x\\in\\mathbb{F}_{p}}\\left({\\frac{f(x)}{p}}\\right).\n$$\n\nProof. For a given $X \\in \\mathbb{F}_{q}$ it is clear that the number of $y \\in \\mathbb{F}_{q}$ such that $y^{2} = X$ is equal to $1 + \\rho(X)$. Counting the point at infinity separately, it follows that\n\n$$\n|E(\\mathbb{F}_{q})| = 1 + \\sum_{x\\in\\mathbb{F}_{q}}\\left(1 + \\rho(f(x))\\right) = q + 1 + \\sum_{x\\in\\mathbb{F}_{q}}\\rho(f(x)),\n$$\n\nproving the lemma.\n\nThe main result for curves over finite fields is Hasse's theorem giving precise bounds on the cardinality of $E(\\mathbb{F}_{q})$. Considering the importance of",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Then $|E(\\mathbb{F}_{q})| = q+1-a_{q}$ with $a_{q} = -\\sum_{x\\in\\mathbb{F}_{q}} \\rho(f(x))$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM239.Number.Theory.-.Volume.I.Tools.and.Diophantine.Equations,.Cohen,.H.,.(2007,.ISBN.978-0-387-49922-2).pdf_514",
        "ID": "04937838-ab1d-44e3-86ce-8b0389aca0da",
        "questions": "Does the computation of $|E(\\mathbb{F}_{q})| for an elliptic curve over $\\mathbb{F}_{q}$ involve counting points at infinity?",
        "answers": "Yes",
        "context": "Lemma 7.3.8. Assume that $g(T)$ is not equal to a constant times the square of a rational function, and let $P \\in E_{g}(K)$. The following are equivalent:\n\n(1) $h(P) = 0$\n\n(2) $P \\in E_{g}(k)$\n\n(3) Either $P = \\mathcal{O}$ or there exists $u \\in k$ such that $P = (u, 0)$\n\n(4) For all $Q \\in E_{g}(K)$ we have $h(P+Q)=h(Q)$; in other words, $B(P,Q) = 0$.\n\nProof. Since the result is trivial when $P = \\mathcal{O}$, assume that this is not the case and write as usual $P = (X_{P}, Y_{P})$. Clearly $h(P) = 0$ if and only if $X_{P} \\in k$, so we can write $X_{P} = u$. We thus have $g(T)Y_{P}^{2} = f(u)$, so that if $f(u) \\neq 0$, $g(T)$ is equal to a constant times the square of the rational function $1/Y_{P}$, contrary to our assumption. Thus $f(u) = 0$, so $Y_{P} = 0$ and $P = (u, 0)$, proving that (1) implies (3), and (3) implies (2) implies (1) is trivial, so that (1), (2), and (3) are equivalent. To prove that (3) implies (4), we note that if $Q = \\pm P$, we have $h(2P) = 4h(P) = 0$ and $h(P-P) = 0$; so (4) is clear, and (4) is also clear if $Q = \\mathcal{O}$. Otherwise, a simple computation using the addition law gives $X_{P+Q} = u + f^{\\prime}(u)/(X_{Q}-u)$, and since $f(u) = 0$ we have $f^{\\prime}(u) \\neq 0$, and this is easily seen to imply that $h(P+Q) = h(Q)$ as desired. Finally, (4) applied to $Q = k P$ for any $k \\in \\mathbb{Z}$ gives $(k+1)^{2}h(P) = h(P+Q) = h(Q) = k^{2}h(P)$; hence $h(P) = 0$, so (4) implies (1).\n\n# 7.3.4 Elliptic Curves over $\\mathbb{F}_{q}$\n\nWe begin with the following very easy lemma.\n\nLemma 7.3.9. Let $q$ be an odd prime power, let $\\rho$ be the unique multiplicative character of order 2 on $\\mathbb{F}_{q}$, and let $y^{2} = f(x)$ be the equation of an elliptic curve over $\\mathbb{F}_{q}$, where $f(X)$ is a polynomial of degree 3. Then $|E(\\mathbb{F}_{q})| = q+1-a_{q}$ with $a_{q} = -\\sum_{x\\in\\mathbb{F}_{q}} \\rho(f(x))$. In particular, if $q = p$ is prime, we have $|E(\\mathbb{F}_{p})| = p+1-a_{p}$ with\n\n$$\na_{p} = -\\sum_{x\\in\\mathbb{F}_{p}}\\left({\\frac{f(x)}{p}}\\right).\n$$\n\nProof. For a given $X \\in \\mathbb{F}_{q}$ it is clear that the number of $y \\in \\mathbb{F}_{q}$ such that $y^{2} = X$ is equal to $1 + \\rho(X)$. Counting the point at infinity separately, it follows that\n\n$$\n|E(\\mathbb{F}_{q})| = 1 + \\sum_{x\\in\\mathbb{F}_{q}}\\left(1 + \\rho(f(x))\\right) = q + 1 + \\sum_{x\\in\\mathbb{F}_{q}}\\rho(f(x)),\n$$\n\nproving the lemma.\n\nThe main result for curves over finite fields is Hasse's theorem giving precise bounds on the cardinality of $E(\\mathbb{F}_{q})$. Considering the importance of",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Yes/No",
        "evidence_source": "text",
        "evidence_context": "Counting the point at infinity separately, it follows that $|E(\\mathbb{F}_{q})| = 1 + \\sum_{x\\in\\mathbb{F}_{q}}\\left(1 + \\rho(f(x))\\right) = q + 1 + \\sum_{x\\in\\mathbb{F}_{q}}\\rho(f(x))$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM239.Number.Theory.-.Volume.I.Tools.and.Diophantine.Equations,.Cohen,.H.,.(2007,.ISBN.978-0-387-49922-2).pdf_514",
        "ID": "0495c348-a87c-4e70-8a1f-9e07e8510977",
        "questions": "What is the condition outlined in Lemma 7.3.8 that would make $h(P)$ equal to zero for an elliptic curve $E_{g}(K)$?",
        "answers": "$h(P) = 0$",
        "context": "Lemma 7.3.8. Assume that $g(T)$ is not equal to a constant times the square of a rational function, and let $P \\in E_{g}(K)$. The following are equivalent:\n\n(1) $h(P) = 0$\n\n(2) $P \\in E_{g}(k)$\n\n(3) Either $P = \\mathcal{O}$ or there exists $u \\in k$ such that $P = (u, 0)$\n\n(4) For all $Q \\in E_{g}(K)$ we have $h(P+Q)=h(Q)$; in other words, $B(P,Q) = 0$.\n\nProof. Since the result is trivial when $P = \\mathcal{O}$, assume that this is not the case and write as usual $P = (X_{P}, Y_{P})$. Clearly $h(P) = 0$ if and only if $X_{P} \\in k$, so we can write $X_{P} = u$. We thus have $g(T)Y_{P}^{2} = f(u)$, so that if $f(u) \\neq 0$, $g(T)$ is equal to a constant times the square of the rational function $1/Y_{P}$, contrary to our assumption. Thus $f(u) = 0$, so $Y_{P} = 0$ and $P = (u, 0)$, proving that (1) implies (3), and (3) implies (2) implies (1) is trivial, so that (1), (2), and (3) are equivalent. To prove that (3) implies (4), we note that if $Q = \\pm P$, we have $h(2P) = 4h(P) = 0$ and $h(P-P) = 0$; so (4) is clear, and (4) is also clear if $Q = \\mathcal{O}$. Otherwise, a simple computation using the addition law gives $X_{P+Q} = u + f^{\\prime}(u)/(X_{Q}-u)$, and since $f(u) = 0$ we have $f^{\\prime}(u) \\neq 0$, and this is easily seen to imply that $h(P+Q) = h(Q)$ as desired. Finally, (4) applied to $Q = k P$ for any $k \\in \\mathbb{Z}$ gives $(k+1)^{2}h(P) = h(P+Q) = h(Q) = k^{2}h(P)$; hence $h(P) = 0$, so (4) implies (1).\n\n# 7.3.4 Elliptic Curves over $\\mathbb{F}_{q}$\n\nWe begin with the following very easy lemma.\n\nLemma 7.3.9. Let $q$ be an odd prime power, let $\\rho$ be the unique multiplicative character of order 2 on $\\mathbb{F}_{q}$, and let $y^{2} = f(x)$ be the equation of an elliptic curve over $\\mathbb{F}_{q}$, where $f(X)$ is a polynomial of degree 3. Then $|E(\\mathbb{F}_{q})| = q+1-a_{q}$ with $a_{q} = -\\sum_{x\\in\\mathbb{F}_{q}} \\rho(f(x))$. In particular, if $q = p$ is prime, we have $|E(\\mathbb{F}_{p})| = p+1-a_{p}$ with\n\n$$\na_{p} = -\\sum_{x\\in\\mathbb{F}_{p}}\\left({\\frac{f(x)}{p}}\\right).\n$$\n\nProof. For a given $X \\in \\mathbb{F}_{q}$ it is clear that the number of $y \\in \\mathbb{F}_{q}$ such that $y^{2} = X$ is equal to $1 + \\rho(X)$. Counting the point at infinity separately, it follows that\n\n$$\n|E(\\mathbb{F}_{q})| = 1 + \\sum_{x\\in\\mathbb{F}_{q}}\\left(1 + \\rho(f(x))\\right) = q + 1 + \\sum_{x\\in\\mathbb{F}_{q}}\\rho(f(x)),\n$$\n\nproving the lemma.\n\nThe main result for curves over finite fields is Hasse's theorem giving precise bounds on the cardinality of $E(\\mathbb{F}_{q})$. Considering the importance of",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Lemma 7.3.8. Assume that $g(T)$ is not equal to a constant times the square of a rational function, and let $P \\in E_{g}(K). The following are equivalent: (1) $h(P) = 0$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/GTM239.Number.Theory.-.Volume.I.Tools.and.Diophantine.Equations,.Cohen,.H.,.(2007,.ISBN.978-0-387-49922-2).pdf_514",
        "ID": "04a2c02e-1daa-4afc-b732-85da35ca1135",
        "questions": "According to Lemma 7.3.9, how is $|E(\\mathbb{F}_{q})|$ computed for an elliptic curve over a finite field where $q$ is an odd prime power?",
        "answers": "$|E(\\mathbb{F}_{q})| = q+1-a_{q}$ with $a_{q} = -\\sum_{x\\in\\mathbb{F}_{q}} \\rho(f(x))$",
        "context": "Lemma 7.3.8. Assume that $g(T)$ is not equal to a constant times the square of a rational function, and let $P \\in E_{g}(K)$. The following are equivalent:\n\n(1) $h(P) = 0$\n\n(2) $P \\in E_{g}(k)$\n\n(3) Either $P = \\mathcal{O}$ or there exists $u \\in k$ such that $P = (u, 0)$\n\n(4) For all $Q \\in E_{g}(K)$ we have $h(P+Q)=h(Q)$; in other words, $B(P,Q) = 0$.\n\nProof. Since the result is trivial when $P = \\mathcal{O}$, assume that this is not the case and write as usual $P = (X_{P}, Y_{P})$. Clearly $h(P) = 0$ if and only if $X_{P} \\in k$, so we can write $X_{P} = u$. We thus have $g(T)Y_{P}^{2} = f(u)$, so that if $f(u) \\neq 0$, $g(T)$ is equal to a constant times the square of the rational function $1/Y_{P}$, contrary to our assumption. Thus $f(u) = 0$, so $Y_{P} = 0$ and $P = (u, 0)$, proving that (1) implies (3), and (3) implies (2) implies (1) is trivial, so that (1), (2), and (3) are equivalent. To prove that (3) implies (4), we note that if $Q = \\pm P$, we have $h(2P) = 4h(P) = 0$ and $h(P-P) = 0$; so (4) is clear, and (4) is also clear if $Q = \\mathcal{O}$. Otherwise, a simple computation using the addition law gives $X_{P+Q} = u + f^{\\prime}(u)/(X_{Q}-u)$, and since $f(u) = 0$ we have $f^{\\prime}(u) \\neq 0$, and this is easily seen to imply that $h(P+Q) = h(Q)$ as desired. Finally, (4) applied to $Q = k P$ for any $k \\in \\mathbb{Z}$ gives $(k+1)^{2}h(P) = h(P+Q) = h(Q) = k^{2}h(P)$; hence $h(P) = 0$, so (4) implies (1).\n\n# 7.3.4 Elliptic Curves over $\\mathbb{F}_{q}$\n\nWe begin with the following very easy lemma.\n\nLemma 7.3.9. Let $q$ be an odd prime power, let $\\rho$ be the unique multiplicative character of order 2 on $\\mathbb{F}_{q}$, and let $y^{2} = f(x)$ be the equation of an elliptic curve over $\\mathbb{F}_{q}$, where $f(X)$ is a polynomial of degree 3. Then $|E(\\mathbb{F}_{q})| = q+1-a_{q}$ with $a_{q} = -\\sum_{x\\in\\mathbb{F}_{q}} \\rho(f(x))$. In particular, if $q = p$ is prime, we have $|E(\\mathbb{F}_{p})| = p+1-a_{p}$ with\n\n$$\na_{p} = -\\sum_{x\\in\\mathbb{F}_{p}}\\left({\\frac{f(x)}{p}}\\right).\n$$\n\nProof. For a given $X \\in \\mathbb{F}_{q}$ it is clear that the number of $y \\in \\mathbb{F}_{q}$ such that $y^{2} = X$ is equal to $1 + \\rho(X)$. Counting the point at infinity separately, it follows that\n\n$$\n|E(\\mathbb{F}_{q})| = 1 + \\sum_{x\\in\\mathbb{F}_{q}}\\left(1 + \\rho(f(x))\\right) = q + 1 + \\sum_{x\\in\\mathbb{F}_{q}}\\rho(f(x)),\n$$\n\nproving the lemma.\n\nThe main result for curves over finite fields is Hasse's theorem giving precise bounds on the cardinality of $E(\\mathbb{F}_{q})$. Considering the importance of",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Lemma 7.3.9. Let $q$ be an odd prime power, let $\\rho$ be the unique multiplicative character of order 2 on $\\mathbb{F}_{q}$, and let $y^{2} = f(x)$ be the equation of an elliptic curve over $\\mathbb{F}_{q}$, where $f(X)$ is a polynomial of degree 3. Then $|E(\\mathbb{F}_{q})| = q+1-a_{q}$ with $a_{q} = -\\sum_{x\\in\\mathbb{F}_{q}} \\rho(f(x))$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/GTM239.Number.Theory.-.Volume.I.Tools.and.Diophantine.Equations,.Cohen,.H.,.(2007,.ISBN.978-0-387-49922-2).pdf_514",
        "ID": "04a3e176-2871-468c-a7f2-0af9cbacc159",
        "questions": "If $q$ is a prime number, what is $a_{p}$ for the elliptic curve $y^{2} = f(x)$ over $\\mathbb{F}_{p}$, according to Lemma 7.3.9?",
        "answers": "$a_{p} = -\\sum_{x\\in\\mathbb{F}_{p}}\\left(\\frac{f(x)}{p}\\right)$",
        "context": "Lemma 7.3.8. Assume that $g(T)$ is not equal to a constant times the square of a rational function, and let $P \\in E_{g}(K)$. The following are equivalent:\n\n(1) $h(P) = 0$\n\n(2) $P \\in E_{g}(k)$\n\n(3) Either $P = \\mathcal{O}$ or there exists $u \\in k$ such that $P = (u, 0)$\n\n(4) For all $Q \\in E_{g}(K)$ we have $h(P+Q)=h(Q)$; in other words, $B(P,Q) = 0$.\n\nProof. Since the result is trivial when $P = \\mathcal{O}$, assume that this is not the case and write as usual $P = (X_{P}, Y_{P})$. Clearly $h(P) = 0$ if and only if $X_{P} \\in k$, so we can write $X_{P} = u$. We thus have $g(T)Y_{P}^{2} = f(u)$, so that if $f(u) \\neq 0$, $g(T)$ is equal to a constant times the square of the rational function $1/Y_{P}$, contrary to our assumption. Thus $f(u) = 0$, so $Y_{P} = 0$ and $P = (u, 0)$, proving that (1) implies (3), and (3) implies (2) implies (1) is trivial, so that (1), (2), and (3) are equivalent. To prove that (3) implies (4), we note that if $Q = \\pm P$, we have $h(2P) = 4h(P) = 0$ and $h(P-P) = 0$; so (4) is clear, and (4) is also clear if $Q = \\mathcal{O}$. Otherwise, a simple computation using the addition law gives $X_{P+Q} = u + f^{\\prime}(u)/(X_{Q}-u)$, and since $f(u) = 0$ we have $f^{\\prime}(u) \\neq 0$, and this is easily seen to imply that $h(P+Q) = h(Q)$ as desired. Finally, (4) applied to $Q = k P$ for any $k \\in \\mathbb{Z}$ gives $(k+1)^{2}h(P) = h(P+Q) = h(Q) = k^{2}h(P)$; hence $h(P) = 0$, so (4) implies (1).\n\n# 7.3.4 Elliptic Curves over $\\mathbb{F}_{q}$\n\nWe begin with the following very easy lemma.\n\nLemma 7.3.9. Let $q$ be an odd prime power, let $\\rho$ be the unique multiplicative character of order 2 on $\\mathbb{F}_{q}$, and let $y^{2} = f(x)$ be the equation of an elliptic curve over $\\mathbb{F}_{q}$, where $f(X)$ is a polynomial of degree 3. Then $|E(\\mathbb{F}_{q})| = q+1-a_{q}$ with $a_{q} = -\\sum_{x\\in\\mathbb{F}_{q}} \\rho(f(x))$. In particular, if $q = p$ is prime, we have $|E(\\mathbb{F}_{p})| = p+1-a_{p}$ with\n\n$$\na_{p} = -\\sum_{x\\in\\mathbb{F}_{p}}\\left({\\frac{f(x)}{p}}\\right).\n$$\n\nProof. For a given $X \\in \\mathbb{F}_{q}$ it is clear that the number of $y \\in \\mathbb{F}_{q}$ such that $y^{2} = X$ is equal to $1 + \\rho(X)$. Counting the point at infinity separately, it follows that\n\n$$\n|E(\\mathbb{F}_{q})| = 1 + \\sum_{x\\in\\mathbb{F}_{q}}\\left(1 + \\rho(f(x))\\right) = q + 1 + \\sum_{x\\in\\mathbb{F}_{q}}\\rho(f(x)),\n$$\n\nproving the lemma.\n\nThe main result for curves over finite fields is Hasse's theorem giving precise bounds on the cardinality of $E(\\mathbb{F}_{q})$. Considering the importance of",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "In particular, if $q = p$ is prime, we have $|E(\\mathbb{F}_{p})| = p+1-a_{p}$ with $a_{p} = -\\sum_{x\\in\\mathbb{F}_{p}}\\left({\\frac{f(x)}{p}}\\right)$.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/GTM272-Operator_Theoretic_Aspects_of_Ergodic_Theory2015.pdf_68",
        "ID": "04a4bb91-83d6-45f7-9654-3df09e5b9e4a",
        "questions": "What is the criterion for a compact topological space K to be metrizable according to Theorem 4.7?",
        "answers": "A compact topological space K is metrizable if and only if C(K) is separable.",
        "context": "Proof. For fixed $m \\in \\mathbb{N}$, the balls $B(x, \\frac{1}{m})$ for $x \\in K$ cover $K$, so there is a finite set $F_{m} \\subseteq K$ such that\n\n$$\nK \\subseteq \\bigcup_{x \\in F_{m}} B(x, \\frac{1}{m}).\n$$\n\nThen the set $F := \\bigcup_{m \\in \\mathbb{N}} F_{m}$ is countable and dense in $K$.\n\nTheorem 4.7. A compact topological space $K$ is metrizable if and only if $C(K)$ is separable.\n\nProof. Suppose that $C(K)$ is separable, and let $(f_{n})_{n \\in \\mathbb{N}}$ be a sequence in $C(K)$ such that $\\{f_{n}: n \\in \\mathbb{N}\\}$ is dense in $C(K)$. Define\n\n$$\n\\varPhi: K \\to \\varOmega := \\prod_{n \\in \\mathbb{N}} \\mathbb{C}, \\qquad \\varPhi(x) := (f_{n}(x))_{n \\in \\mathbb{N}},\n$$\n\nwhere $\\varOmega$ carries the usual product topology. Then $\\varPhi$ is continuous and injective by Urysohn's lemma and the density assumption. The topology on $\\varOmega$ is metrizable (see Appendix A.5). Since $K$ is compact, $\\varPhi$ is a homeomorphism from $K$ onto $\\Phi(K)$. Consequently, $K$ is metrizable.\n\nFor the converse, suppose that $d: K \\times K \\rightarrow \\mathbb{R}_{+}$ is a metric that induces the topology of $K$. By Lemma 4.6, there is a countable set $A \\subseteq K$ with $\\bar{A} = K$. Consider the countable(!) set\n\n$$\nD := \\{f\\in CK\\,:\\, f\\,\\mathrm{is\\,a\\,finite\\,product\\,of\\,functions\\,}\\,d(\\cdot,y),y\\in A\\}\\cup\\{\\mathbf{1}\\}\n$$\n\nThen $\\mathrm{lin}(D)$ is a conjugation invariant subalgebra of $C(K)$ containing the constants and separating the points of $K$. By the Stone-Weierstrass theorem, $\\overline{\\lim}(D) = C(K)$ and hence $C(K)$ is separable.\n\n# 4.2 The Space $C(K)$ as a Commutative $C^{\\ast}$ -Algebra\n\nIn this section, we show how the compact space $K$ can be recovered if only the space $C(K)$ is known (see Theorem 4.11 below).\n\nThe main idea is readily formulated. Let $K$ be any compact topological space. To $x \\in K$, we associate the functional\n\n$$\n\\delta_{x}: C(K) \\to \\mathbb{C}, \\qquad \\langle f, \\delta_{x} \\rangle := f(x) \\qquad (f \\in C(K))\n$$\n\ncalled the Dirac or evaluation functional at $x \\in K$. Then $\\delta_{x} \\in \\operatorname{C}(K)^{\\prime}$ with $\\|\\delta_{x}\\| = 1$. By Urysohn's lemma, $\\mathbf{C}(K)$ separates the points of $K$, which means that the map\n\n$$\n\\delta: K \\to \\mathbf{C}(K)^{\\prime}, \\qquad x \\mapsto \\delta_{x}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Theorem 4.7. A compact topological space K is metrizable if and only if C(K) is separable.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM272-Operator_Theoretic_Aspects_of_Ergodic_Theory2015.pdf_68",
        "ID": "04aa72d1-4bc6-4ffd-8610-53ed451b1c8c",
        "questions": "How can the finite set \\( F_m \\) be described in terms of the balls \\( B(x, \frac{1}{m}) \\) and the set K?",
        "answers": "The balls \\( B(x, \frac{1}{m}) \\) for \\( x \\in K \\) cover \\( K \\), so there is a finite set \\( F_{m} \\subseteq K \\) such that \\( K \\subseteq \bigcup_{x \\in F_{m}} B(x, \frac{1}{m}) \\).",
        "context": "Proof. For fixed $m \\in \\mathbb{N}$, the balls $B(x, \\frac{1}{m})$ for $x \\in K$ cover $K$, so there is a finite set $F_{m} \\subseteq K$ such that\n\n$$\nK \\subseteq \\bigcup_{x \\in F_{m}} B(x, \\frac{1}{m}).\n$$\n\nThen the set $F := \\bigcup_{m \\in \\mathbb{N}} F_{m}$ is countable and dense in $K$.\n\nTheorem 4.7. A compact topological space $K$ is metrizable if and only if $C(K)$ is separable.\n\nProof. Suppose that $C(K)$ is separable, and let $(f_{n})_{n \\in \\mathbb{N}}$ be a sequence in $C(K)$ such that $\\{f_{n}: n \\in \\mathbb{N}\\}$ is dense in $C(K)$. Define\n\n$$\n\\varPhi: K \\to \\varOmega := \\prod_{n \\in \\mathbb{N}} \\mathbb{C}, \\qquad \\varPhi(x) := (f_{n}(x))_{n \\in \\mathbb{N}},\n$$\n\nwhere $\\varOmega$ carries the usual product topology. Then $\\varPhi$ is continuous and injective by Urysohn's lemma and the density assumption. The topology on $\\varOmega$ is metrizable (see Appendix A.5). Since $K$ is compact, $\\varPhi$ is a homeomorphism from $K$ onto $\\Phi(K)$. Consequently, $K$ is metrizable.\n\nFor the converse, suppose that $d: K \\times K \\rightarrow \\mathbb{R}_{+}$ is a metric that induces the topology of $K$. By Lemma 4.6, there is a countable set $A \\subseteq K$ with $\\bar{A} = K$. Consider the countable(!) set\n\n$$\nD := \\{f\\in CK\\,:\\, f\\,\\mathrm{is\\,a\\,finite\\,product\\,of\\,functions\\,}\\,d(\\cdot,y),y\\in A\\}\\cup\\{\\mathbf{1}\\}\n$$\n\nThen $\\mathrm{lin}(D)$ is a conjugation invariant subalgebra of $C(K)$ containing the constants and separating the points of $K$. By the Stone-Weierstrass theorem, $\\overline{\\lim}(D) = C(K)$ and hence $C(K)$ is separable.\n\n# 4.2 The Space $C(K)$ as a Commutative $C^{\\ast}$ -Algebra\n\nIn this section, we show how the compact space $K$ can be recovered if only the space $C(K)$ is known (see Theorem 4.11 below).\n\nThe main idea is readily formulated. Let $K$ be any compact topological space. To $x \\in K$, we associate the functional\n\n$$\n\\delta_{x}: C(K) \\to \\mathbb{C}, \\qquad \\langle f, \\delta_{x} \\rangle := f(x) \\qquad (f \\in C(K))\n$$\n\ncalled the Dirac or evaluation functional at $x \\in K$. Then $\\delta_{x} \\in \\operatorname{C}(K)^{\\prime}$ with $\\|\\delta_{x}\\| = 1$. By Urysohn's lemma, $\\mathbf{C}(K)$ separates the points of $K$, which means that the map\n\n$$\n\\delta: K \\to \\mathbf{C}(K)^{\\prime}, \\qquad x \\mapsto \\delta_{x}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "For fixed \\( m \\in \\mathbb{N} \\), the balls \\( B(x, \frac{1}{m}) \\) for \\( x \\in K \\) cover \\( K \\), so there is a finite set \\( F_{m} \\subseteq K \\) such that \\( K \\subseteq \bigcup_{x \\in F_{m}} B(x, \frac{1}{m}) \\).",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM272-Operator_Theoretic_Aspects_of_Ergodic_Theory2015.pdf_68",
        "ID": "04ae5e3e-f0c5-4802-8474-4ac61df73276",
        "questions": "In the proof of Theorem 4.7, how is the map \\( \u000barPhi \\) defined and what are its properties?",
        "answers": "The map \\( \u000barPhi \\) is defined as \\( \u000barPhi: K \to \u000barOmega := \\prod_{n \\in \\mathbb{N}} \\mathbb{C}, \\qquad \u000barPhi(x) := (f_{n}(x))_{n \\in \\mathbb{N}} \\). \\( \u000barPhi \\) is continuous and injective by Urysohn's lemma and the density assumption.",
        "context": "Proof. For fixed $m \\in \\mathbb{N}$, the balls $B(x, \\frac{1}{m})$ for $x \\in K$ cover $K$, so there is a finite set $F_{m} \\subseteq K$ such that\n\n$$\nK \\subseteq \\bigcup_{x \\in F_{m}} B(x, \\frac{1}{m}).\n$$\n\nThen the set $F := \\bigcup_{m \\in \\mathbb{N}} F_{m}$ is countable and dense in $K$.\n\nTheorem 4.7. A compact topological space $K$ is metrizable if and only if $C(K)$ is separable.\n\nProof. Suppose that $C(K)$ is separable, and let $(f_{n})_{n \\in \\mathbb{N}}$ be a sequence in $C(K)$ such that $\\{f_{n}: n \\in \\mathbb{N}\\}$ is dense in $C(K)$. Define\n\n$$\n\\varPhi: K \\to \\varOmega := \\prod_{n \\in \\mathbb{N}} \\mathbb{C}, \\qquad \\varPhi(x) := (f_{n}(x))_{n \\in \\mathbb{N}},\n$$\n\nwhere $\\varOmega$ carries the usual product topology. Then $\\varPhi$ is continuous and injective by Urysohn's lemma and the density assumption. The topology on $\\varOmega$ is metrizable (see Appendix A.5). Since $K$ is compact, $\\varPhi$ is a homeomorphism from $K$ onto $\\Phi(K)$. Consequently, $K$ is metrizable.\n\nFor the converse, suppose that $d: K \\times K \\rightarrow \\mathbb{R}_{+}$ is a metric that induces the topology of $K$. By Lemma 4.6, there is a countable set $A \\subseteq K$ with $\\bar{A} = K$. Consider the countable(!) set\n\n$$\nD := \\{f\\in CK\\,:\\, f\\,\\mathrm{is\\,a\\,finite\\,product\\,of\\,functions\\,}\\,d(\\cdot,y),y\\in A\\}\\cup\\{\\mathbf{1}\\}\n$$\n\nThen $\\mathrm{lin}(D)$ is a conjugation invariant subalgebra of $C(K)$ containing the constants and separating the points of $K$. By the Stone-Weierstrass theorem, $\\overline{\\lim}(D) = C(K)$ and hence $C(K)$ is separable.\n\n# 4.2 The Space $C(K)$ as a Commutative $C^{\\ast}$ -Algebra\n\nIn this section, we show how the compact space $K$ can be recovered if only the space $C(K)$ is known (see Theorem 4.11 below).\n\nThe main idea is readily formulated. Let $K$ be any compact topological space. To $x \\in K$, we associate the functional\n\n$$\n\\delta_{x}: C(K) \\to \\mathbb{C}, \\qquad \\langle f, \\delta_{x} \\rangle := f(x) \\qquad (f \\in C(K))\n$$\n\ncalled the Dirac or evaluation functional at $x \\in K$. Then $\\delta_{x} \\in \\operatorname{C}(K)^{\\prime}$ with $\\|\\delta_{x}\\| = 1$. By Urysohn's lemma, $\\mathbf{C}(K)$ separates the points of $K$, which means that the map\n\n$$\n\\delta: K \\to \\mathbf{C}(K)^{\\prime}, \\qquad x \\mapsto \\delta_{x}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Define\n\n$$\n\u000barPhi: K \to \u000barOmega := \\prod_{n \\in \\mathbb{N}} \\mathbb{C}, \\qquad \u000barPhi(x) := (f_{n}(x))_{n \\in \\mathbb{N}},\n$$\n\nwhere \\( \u000barOmega \\) carries the usual product topology. Then \\( \u000barPhi \\) is continuous and injective by Urysohn's lemma and the density assumption.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM272-Operator_Theoretic_Aspects_of_Ergodic_Theory2015.pdf_68",
        "ID": "04c3743b-d791-4017-b463-619acf7740f3",
        "questions": "For a compact topological space $K$, what is the functional $\\delta_{x}$ associated to any $x$ in $K$ and how is it defined?",
        "answers": "$\\delta_{x}: C(K) \to \\mathbb{C}, \\qquad \\langle f, \\delta_{x} \rangle := f(x) \\qquad (f \\in C(K))$",
        "context": "Proof. For fixed $m \\in \\mathbb{N}$, the balls $B(x, \\frac{1}{m})$ for $x \\in K$ cover $K$, so there is a finite set $F_{m} \\subseteq K$ such that\n\n$$\nK \\subseteq \\bigcup_{x \\in F_{m}} B(x, \\frac{1}{m}).\n$$\n\nThen the set $F := \\bigcup_{m \\in \\mathbb{N}} F_{m}$ is countable and dense in $K$.\n\nTheorem 4.7. A compact topological space $K$ is metrizable if and only if $C(K)$ is separable.\n\nProof. Suppose that $C(K)$ is separable, and let $(f_{n})_{n \\in \\mathbb{N}}$ be a sequence in $C(K)$ such that $\\{f_{n}: n \\in \\mathbb{N}\\}$ is dense in $C(K)$. Define\n\n$$\n\\varPhi: K \\to \\varOmega := \\prod_{n \\in \\mathbb{N}} \\mathbb{C}, \\qquad \\varPhi(x) := (f_{n}(x))_{n \\in \\mathbb{N}},\n$$\n\nwhere $\\varOmega$ carries the usual product topology. Then $\\varPhi$ is continuous and injective by Urysohn's lemma and the density assumption. The topology on $\\varOmega$ is metrizable (see Appendix A.5). Since $K$ is compact, $\\varPhi$ is a homeomorphism from $K$ onto $\\Phi(K)$. Consequently, $K$ is metrizable.\n\nFor the converse, suppose that $d: K \\times K \\rightarrow \\mathbb{R}_{+}$ is a metric that induces the topology of $K$. By Lemma 4.6, there is a countable set $A \\subseteq K$ with $\\bar{A} = K$. Consider the countable(!) set\n\n$$\nD := \\{f\\in CK\\,:\\, f\\,\\mathrm{is\\,a\\,finite\\,product\\,of\\,functions\\,}\\,d(\\cdot,y),y\\in A\\}\\cup\\{\\mathbf{1}\\}\n$$\n\nThen $\\mathrm{lin}(D)$ is a conjugation invariant subalgebra of $C(K)$ containing the constants and separating the points of $K$. By the Stone-Weierstrass theorem, $\\overline{\\lim}(D) = C(K)$ and hence $C(K)$ is separable.\n\n# 4.2 The Space $C(K)$ as a Commutative $C^{\\ast}$ -Algebra\n\nIn this section, we show how the compact space $K$ can be recovered if only the space $C(K)$ is known (see Theorem 4.11 below).\n\nThe main idea is readily formulated. Let $K$ be any compact topological space. To $x \\in K$, we associate the functional\n\n$$\n\\delta_{x}: C(K) \\to \\mathbb{C}, \\qquad \\langle f, \\delta_{x} \\rangle := f(x) \\qquad (f \\in C(K))\n$$\n\ncalled the Dirac or evaluation functional at $x \\in K$. Then $\\delta_{x} \\in \\operatorname{C}(K)^{\\prime}$ with $\\|\\delta_{x}\\| = 1$. By Urysohn's lemma, $\\mathbf{C}(K)$ separates the points of $K$, which means that the map\n\n$$\n\\delta: K \\to \\mathbf{C}(K)^{\\prime}, \\qquad x \\mapsto \\delta_{x}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "To $x \\in K$, we associate the functional $$\\delta_{x}: C(K) \to \\mathbb{C}, \\qquad \\langle f, \\delta_{x} \rangle := f(x) \\qquad (f \\in C(K))$$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/GTM272-Operator_Theoretic_Aspects_of_Ergodic_Theory2015.pdf_68",
        "ID": "04c8ead7-5bf3-4980-bf15-e8a5b5812f88",
        "questions": "How does the set $F_m$ relate to the compact set $K$ given the family of balls $B(x, \frac{1}{m})$?",
        "answers": "$K \\subseteq \bigcup_{x \\in F_{m}} B(x, \frac{1}{m}).$",
        "context": "Proof. For fixed $m \\in \\mathbb{N}$, the balls $B(x, \\frac{1}{m})$ for $x \\in K$ cover $K$, so there is a finite set $F_{m} \\subseteq K$ such that\n\n$$\nK \\subseteq \\bigcup_{x \\in F_{m}} B(x, \\frac{1}{m}).\n$$\n\nThen the set $F := \\bigcup_{m \\in \\mathbb{N}} F_{m}$ is countable and dense in $K$.\n\nTheorem 4.7. A compact topological space $K$ is metrizable if and only if $C(K)$ is separable.\n\nProof. Suppose that $C(K)$ is separable, and let $(f_{n})_{n \\in \\mathbb{N}}$ be a sequence in $C(K)$ such that $\\{f_{n}: n \\in \\mathbb{N}\\}$ is dense in $C(K)$. Define\n\n$$\n\\varPhi: K \\to \\varOmega := \\prod_{n \\in \\mathbb{N}} \\mathbb{C}, \\qquad \\varPhi(x) := (f_{n}(x))_{n \\in \\mathbb{N}},\n$$\n\nwhere $\\varOmega$ carries the usual product topology. Then $\\varPhi$ is continuous and injective by Urysohn's lemma and the density assumption. The topology on $\\varOmega$ is metrizable (see Appendix A.5). Since $K$ is compact, $\\varPhi$ is a homeomorphism from $K$ onto $\\Phi(K)$. Consequently, $K$ is metrizable.\n\nFor the converse, suppose that $d: K \\times K \\rightarrow \\mathbb{R}_{+}$ is a metric that induces the topology of $K$. By Lemma 4.6, there is a countable set $A \\subseteq K$ with $\\bar{A} = K$. Consider the countable(!) set\n\n$$\nD := \\{f\\in CK\\,:\\, f\\,\\mathrm{is\\,a\\,finite\\,product\\,of\\,functions\\,}\\,d(\\cdot,y),y\\in A\\}\\cup\\{\\mathbf{1}\\}\n$$\n\nThen $\\mathrm{lin}(D)$ is a conjugation invariant subalgebra of $C(K)$ containing the constants and separating the points of $K$. By the Stone-Weierstrass theorem, $\\overline{\\lim}(D) = C(K)$ and hence $C(K)$ is separable.\n\n# 4.2 The Space $C(K)$ as a Commutative $C^{\\ast}$ -Algebra\n\nIn this section, we show how the compact space $K$ can be recovered if only the space $C(K)$ is known (see Theorem 4.11 below).\n\nThe main idea is readily formulated. Let $K$ be any compact topological space. To $x \\in K$, we associate the functional\n\n$$\n\\delta_{x}: C(K) \\to \\mathbb{C}, \\qquad \\langle f, \\delta_{x} \\rangle := f(x) \\qquad (f \\in C(K))\n$$\n\ncalled the Dirac or evaluation functional at $x \\in K$. Then $\\delta_{x} \\in \\operatorname{C}(K)^{\\prime}$ with $\\|\\delta_{x}\\| = 1$. By Urysohn's lemma, $\\mathbf{C}(K)$ separates the points of $K$, which means that the map\n\n$$\n\\delta: K \\to \\mathbf{C}(K)^{\\prime}, \\qquad x \\mapsto \\delta_{x}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$K \\subseteq \bigcup_{x \\in F_{m}} B(x, \frac{1}{m}).$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/GTM272-Operator_Theoretic_Aspects_of_Ergodic_Theory2015.pdf_68",
        "ID": "04d35f1f-6d09-4ec0-be51-894d4834bb3a",
        "questions": "According to the theorem on metrizability and separability, under what condition is a compact topological space $K$ metrizable if it is known that $C(K)$ is separable?",
        "answers": "Then the set $F := \\bigcup_{m \\in \\mathbb{N}} F_{m}$ is countable and dense in $K$.",
        "context": "Proof. For fixed $m \\in \\mathbb{N}$, the balls $B(x, \\frac{1}{m})$ for $x \\in K$ cover $K$, so there is a finite set $F_{m} \\subseteq K$ such that\n\n$$\nK \\subseteq \\bigcup_{x \\in F_{m}} B(x, \\frac{1}{m}).\n$$\n\nThen the set $F := \\bigcup_{m \\in \\mathbb{N}} F_{m}$ is countable and dense in $K$.\n\nTheorem 4.7. A compact topological space $K$ is metrizable if and only if $C(K)$ is separable.\n\nProof. Suppose that $C(K)$ is separable, and let $(f_{n})_{n \\in \\mathbb{N}}$ be a sequence in $C(K)$ such that $\\{f_{n}: n \\in \\mathbb{N}\\}$ is dense in $C(K)$. Define\n\n$$\n\\varPhi: K \\to \\varOmega := \\prod_{n \\in \\mathbb{N}} \\mathbb{C}, \\qquad \\varPhi(x) := (f_{n}(x))_{n \\in \\mathbb{N}},\n$$\n\nwhere $\\varOmega$ carries the usual product topology. Then $\\varPhi$ is continuous and injective by Urysohn's lemma and the density assumption. The topology on $\\varOmega$ is metrizable (see Appendix A.5). Since $K$ is compact, $\\varPhi$ is a homeomorphism from $K$ onto $\\Phi(K)$. Consequently, $K$ is metrizable.\n\nFor the converse, suppose that $d: K \\times K \\rightarrow \\mathbb{R}_{+}$ is a metric that induces the topology of $K$. By Lemma 4.6, there is a countable set $A \\subseteq K$ with $\\bar{A} = K$. Consider the countable(!) set\n\n$$\nD := \\{f\\in CK\\,:\\, f\\,\\mathrm{is\\,a\\,finite\\,product\\,of\\,functions\\,}\\,d(\\cdot,y),y\\in A\\}\\cup\\{\\mathbf{1}\\}\n$$\n\nThen $\\mathrm{lin}(D)$ is a conjugation invariant subalgebra of $C(K)$ containing the constants and separating the points of $K$. By the Stone-Weierstrass theorem, $\\overline{\\lim}(D) = C(K)$ and hence $C(K)$ is separable.\n\n# 4.2 The Space $C(K)$ as a Commutative $C^{\\ast}$ -Algebra\n\nIn this section, we show how the compact space $K$ can be recovered if only the space $C(K)$ is known (see Theorem 4.11 below).\n\nThe main idea is readily formulated. Let $K$ be any compact topological space. To $x \\in K$, we associate the functional\n\n$$\n\\delta_{x}: C(K) \\to \\mathbb{C}, \\qquad \\langle f, \\delta_{x} \\rangle := f(x) \\qquad (f \\in C(K))\n$$\n\ncalled the Dirac or evaluation functional at $x \\in K$. Then $\\delta_{x} \\in \\operatorname{C}(K)^{\\prime}$ with $\\|\\delta_{x}\\| = 1$. By Urysohn's lemma, $\\mathbf{C}(K)$ separates the points of $K$, which means that the map\n\n$$\n\\delta: K \\to \\mathbf{C}(K)^{\\prime}, \\qquad x \\mapsto \\delta_{x}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Then the set $F := \\bigcup_{m \\in \\mathbb{N}} F_{m}$ is countable and dense in $K$.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/socialsci-177546.pdf_157",
        "ID": "04d6466e-085c-42f0-b19d-09dd9bb6cafb",
        "questions": "What percentage of males aged 40-49 engaged in vaginal intercourse during the previous year according to the National Survey of Sexual Health and Behavior?",
        "answers": "74%",
        "context": "![](images/9a683aa74a0b86313df7835845914d5c98552ec173579c8a23a27b4a23c7dc68.jpg)  \nFigure 8.14: Medical Check-ups are Important for Men. Source.  \n\nMen during middle adulthood may also experience prostate enlargement, which can interfere with urination, and deficient testosterone levels which decline throughout adulthood, but especially after age 50. If testosterone levels decline significantly, it is referred to as an andropause or late-onset hypogonadism. Identifying whether testosterone levels are low is difficult because individual blood levels vary greatly. Low testosterone is not a concern unless it is accompanied by negative symptoms such as low sex drive, ED, fatigue, loss of muscle, loss of body hair, or breast enlargement. Low testosterone is also associated with medical conditions, such as diabetes, obesity, high blood pressure, and testicular cancer. The effectiveness of supplemental testosterone is mixed, and long-term testosterone replacement therapy for men can increase the risk of prostate cancer, blood clots, heart attack, and stroke (WebMD, 2016). Most men with low testosterone do not have related problems (Berkeley Wellness, 2011).  \n\n# The Climacteric and Sexuality  \n\nSexuality is an important part of people's lives at any age, and many older adults are very interested in staying sexually active (Dimah & Dimah, 2004). According to the National Survey of Sexual Health and Behavior (NSSHB) (Center for Sexual Health Promotion, 2010), 74% of males and 70% of females aged 40-49 engaged in vaginal intercourse during the previous year, while 58% of males and 51% of females aged 50-59 did so.  \n\n![](images/a78c557a8f3c1c13194b7c165ddce44946f09e3e89bb6a65c1245dc6ad165837.jpg)  \nFigure 8.15. Source  \n\nDespite these percentages indicating that middle adults are sexually active, age-related physical changes can affect sexual functioning. For women, decreased sexual desire and pain during vaginal intercourse because of menopausal changes have been identified (Schick et al., 2010). A woman may also notice less vaginal lubrication during arousal, which can affect overall pleasure (Carroll, 2016). Men may require more direct stimulation for an erection, and the erection may be delayed or less firm (Carroll, 2016). As previously discussed, men may experience erectile dysfunction or experience a medical condition (such as diabetes or heart disease) that impacts sexual functioning. Couples can continue to enjoy physical intimacy and may engage in more foreplay, oral sex, and other forms of sexual expression rather than focusing as much on sexual intercourse.  \n\nRisk of pregnancy continues until a woman has been without menstruation for at least 12 months, however, and couples should continue to use contraception. People continue to be at risk of contracting sexually transmitted infections, such as genital herpes, chlamydia, and genital warts. In 2014, 16.7% of the country's new HIV diagnoses (7,391 of 44,071) were among people 50 and older, according to the Centers for Disease Control and Prevention (2014e). This was an increase from 15.4% in 2005. Practicing safe sex is important at any age, but unfortunately, adults over the age of 40 have the lowest rates of condom use (Center for Sexual Health Promotion, 2010). This low rate of condom use suggests the need to enhance education efforts for older individuals regarding STI risks and prevention. Hopefully, when partners understand how aging affects sexual expression, they will be less likely to misinterpret these changes as a lack of sexual interest or displeasure in the partner and more able to continue to have satisfying and safe sexual relationships.\n****\nThis page titled 4.5: Climacteric is shared under a CC BY-NC-SA 3.0 license and was authored, remixed, andor curated by Martha Lally &Suzanne Valentine-French via source content that was edited to the stvle and standards of the LibreTexts platform; a detailed edit history isavailable upon request.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "According to the National Survey of Sexual Health and Behavior (NSSHB) (Center for Sexual Health Promotion, 2010), 74% of males and 70% of females aged 40-49 engaged in vaginal intercourse during the previous year, while 58% of males and 51% of females aged 50-59 did so.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/socialsci-177546.pdf_157",
        "ID": "04da7224-8591-4820-90ac-cfc9ec8dc105",
        "questions": "What are some negative symptoms that accompany low testosterone which would make it a concern for men during middle adulthood?",
        "answers": "Low sex drive, ED, fatigue, loss of muscle, loss of body hair, or breast enlargement",
        "context": "![](images/9a683aa74a0b86313df7835845914d5c98552ec173579c8a23a27b4a23c7dc68.jpg)  \nFigure 8.14: Medical Check-ups are Important for Men. Source.  \n\nMen during middle adulthood may also experience prostate enlargement, which can interfere with urination, and deficient testosterone levels which decline throughout adulthood, but especially after age 50. If testosterone levels decline significantly, it is referred to as an andropause or late-onset hypogonadism. Identifying whether testosterone levels are low is difficult because individual blood levels vary greatly. Low testosterone is not a concern unless it is accompanied by negative symptoms such as low sex drive, ED, fatigue, loss of muscle, loss of body hair, or breast enlargement. Low testosterone is also associated with medical conditions, such as diabetes, obesity, high blood pressure, and testicular cancer. The effectiveness of supplemental testosterone is mixed, and long-term testosterone replacement therapy for men can increase the risk of prostate cancer, blood clots, heart attack, and stroke (WebMD, 2016). Most men with low testosterone do not have related problems (Berkeley Wellness, 2011).  \n\n# The Climacteric and Sexuality  \n\nSexuality is an important part of people's lives at any age, and many older adults are very interested in staying sexually active (Dimah & Dimah, 2004). According to the National Survey of Sexual Health and Behavior (NSSHB) (Center for Sexual Health Promotion, 2010), 74% of males and 70% of females aged 40-49 engaged in vaginal intercourse during the previous year, while 58% of males and 51% of females aged 50-59 did so.  \n\n![](images/a78c557a8f3c1c13194b7c165ddce44946f09e3e89bb6a65c1245dc6ad165837.jpg)  \nFigure 8.15. Source  \n\nDespite these percentages indicating that middle adults are sexually active, age-related physical changes can affect sexual functioning. For women, decreased sexual desire and pain during vaginal intercourse because of menopausal changes have been identified (Schick et al., 2010). A woman may also notice less vaginal lubrication during arousal, which can affect overall pleasure (Carroll, 2016). Men may require more direct stimulation for an erection, and the erection may be delayed or less firm (Carroll, 2016). As previously discussed, men may experience erectile dysfunction or experience a medical condition (such as diabetes or heart disease) that impacts sexual functioning. Couples can continue to enjoy physical intimacy and may engage in more foreplay, oral sex, and other forms of sexual expression rather than focusing as much on sexual intercourse.  \n\nRisk of pregnancy continues until a woman has been without menstruation for at least 12 months, however, and couples should continue to use contraception. People continue to be at risk of contracting sexually transmitted infections, such as genital herpes, chlamydia, and genital warts. In 2014, 16.7% of the country's new HIV diagnoses (7,391 of 44,071) were among people 50 and older, according to the Centers for Disease Control and Prevention (2014e). This was an increase from 15.4% in 2005. Practicing safe sex is important at any age, but unfortunately, adults over the age of 40 have the lowest rates of condom use (Center for Sexual Health Promotion, 2010). This low rate of condom use suggests the need to enhance education efforts for older individuals regarding STI risks and prevention. Hopefully, when partners understand how aging affects sexual expression, they will be less likely to misinterpret these changes as a lack of sexual interest or displeasure in the partner and more able to continue to have satisfying and safe sexual relationships.\n****\nThis page titled 4.5: Climacteric is shared under a CC BY-NC-SA 3.0 license and was authored, remixed, andor curated by Martha Lally &Suzanne Valentine-French via source content that was edited to the stvle and standards of the LibreTexts platform; a detailed edit history isavailable upon request.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Low testosterone is not a concern unless it is accompanied by negative symptoms such as low sex drive, ED, fatigue, loss of muscle, loss of body hair, or breast enlargement.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/socialsci-177546.pdf_157",
        "ID": "04e93690-0b4e-4fdc-8907-68b00530aee3",
        "questions": "How did the percentage of new HIV diagnoses among people aged 50 and older in 2014 compare to that in 2005 according to the Centers for Disease Control and Prevention?",
        "answers": "It increased from 15.4% in 2005 to 16.7% in 2014.",
        "context": "![](images/9a683aa74a0b86313df7835845914d5c98552ec173579c8a23a27b4a23c7dc68.jpg)  \nFigure 8.14: Medical Check-ups are Important for Men. Source.  \n\nMen during middle adulthood may also experience prostate enlargement, which can interfere with urination, and deficient testosterone levels which decline throughout adulthood, but especially after age 50. If testosterone levels decline significantly, it is referred to as an andropause or late-onset hypogonadism. Identifying whether testosterone levels are low is difficult because individual blood levels vary greatly. Low testosterone is not a concern unless it is accompanied by negative symptoms such as low sex drive, ED, fatigue, loss of muscle, loss of body hair, or breast enlargement. Low testosterone is also associated with medical conditions, such as diabetes, obesity, high blood pressure, and testicular cancer. The effectiveness of supplemental testosterone is mixed, and long-term testosterone replacement therapy for men can increase the risk of prostate cancer, blood clots, heart attack, and stroke (WebMD, 2016). Most men with low testosterone do not have related problems (Berkeley Wellness, 2011).  \n\n# The Climacteric and Sexuality  \n\nSexuality is an important part of people's lives at any age, and many older adults are very interested in staying sexually active (Dimah & Dimah, 2004). According to the National Survey of Sexual Health and Behavior (NSSHB) (Center for Sexual Health Promotion, 2010), 74% of males and 70% of females aged 40-49 engaged in vaginal intercourse during the previous year, while 58% of males and 51% of females aged 50-59 did so.  \n\n![](images/a78c557a8f3c1c13194b7c165ddce44946f09e3e89bb6a65c1245dc6ad165837.jpg)  \nFigure 8.15. Source  \n\nDespite these percentages indicating that middle adults are sexually active, age-related physical changes can affect sexual functioning. For women, decreased sexual desire and pain during vaginal intercourse because of menopausal changes have been identified (Schick et al., 2010). A woman may also notice less vaginal lubrication during arousal, which can affect overall pleasure (Carroll, 2016). Men may require more direct stimulation for an erection, and the erection may be delayed or less firm (Carroll, 2016). As previously discussed, men may experience erectile dysfunction or experience a medical condition (such as diabetes or heart disease) that impacts sexual functioning. Couples can continue to enjoy physical intimacy and may engage in more foreplay, oral sex, and other forms of sexual expression rather than focusing as much on sexual intercourse.  \n\nRisk of pregnancy continues until a woman has been without menstruation for at least 12 months, however, and couples should continue to use contraception. People continue to be at risk of contracting sexually transmitted infections, such as genital herpes, chlamydia, and genital warts. In 2014, 16.7% of the country's new HIV diagnoses (7,391 of 44,071) were among people 50 and older, according to the Centers for Disease Control and Prevention (2014e). This was an increase from 15.4% in 2005. Practicing safe sex is important at any age, but unfortunately, adults over the age of 40 have the lowest rates of condom use (Center for Sexual Health Promotion, 2010). This low rate of condom use suggests the need to enhance education efforts for older individuals regarding STI risks and prevention. Hopefully, when partners understand how aging affects sexual expression, they will be less likely to misinterpret these changes as a lack of sexual interest or displeasure in the partner and more able to continue to have satisfying and safe sexual relationships.\n****\nThis page titled 4.5: Climacteric is shared under a CC BY-NC-SA 3.0 license and was authored, remixed, andor curated by Martha Lally &Suzanne Valentine-French via source content that was edited to the stvle and standards of the LibreTexts platform; a detailed edit history isavailable upon request.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "In 2014, 16.7% of the country's new HIV diagnoses (7,391 of 44,071) were among people 50 and older, according to the Centers for Disease Control and Prevention (2014e). This was an increase from 15.4% in 2005.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/team-probability2015.pdf_0",
        "ID": "04eabde4-2257-4ed6-93e7-2b095889c1b9",
        "questions": "What is the probability that the last passenger takes their own seat in a situation where 100 passengers board a plane with 100 seats, and each takes their own seat if available, otherwise a random available seat?",
        "answers": "0.5",
        "context": "# Probability and Statistics Team (5 problems)  \n\nProblem 1. One hundred passengers board a plane with exactly 100 seats. The first passenger takes a seat at random. The second passenger takes his own seat if it is available, otherwise he takes at random a seat among the available ones. The third passenger takes his own seat if it is available, otherwise he takes at random a seat among the available ones. This process continues until all the 100 passengers have boarded the plane. What is the probability that the last passenger takes his own seat?  \n\nProblem 2. Assume a sequence of random variables $X_{n}$ converges in distribution to a random variable $X$. Let $\\{N_{t}, t\\ge0\\}$ be a set of positive integer-valued random variables, which is independent of $\\left(X_{n}\\right)$ and converges in probability to $\\infty$ as $t\\to\\infty$. Prove that $X_{N_{t}}$ converges in distribution to $X$ as $t\\to\\infty$.  \n\nProblem 3. Suppose $T_{1}, T_{2}, .\\,.\\,.\\,, T_{n}$ is a sequence of independent, identically distributed random variables with the exponential distribution of the density function  \n\n$$\np(x) =\n\\begin{cases} \ne^{-x}, & x \\geq 0; \\\\\n0, & x < 0.\n\\end{cases}\n\n$$  \n\nLet $S_{n}=T_{1}+T_{2}+\\cdot\\cdot\\cdot+T_{n}$. Find the distribution of the random vector  \n\n$$\nV_{n}=\\Big\\{\\frac{T_{1}}{S_{n}},\\frac{T_{2}}{S_{n}},\\cdots,\\frac{T_{n}}{S_{n}}\\Big\\}.\n$$  \n\nProblem 4. Suppose that $X$ and $Z$ are jointly normal with mean zero and standard deviation 1. For a strictly monotonic function $f(\\cdot)$, $\\operatorname{cov}(X,Z)\\;=\\;0$ if and only if $\\operatorname{cov}(X,f(Z))\\,=\\,0$, provided the latter covariance exists. Hint: $Z$ can be expressed as $Z=\\rho X+\\varepsilon$ where $X$ and $\\widehat{=}$ are independent and $\\varepsilon\\sim N(0,\\sqrt{1-\\rho^{2}})$.  \n\nProblem 5. Consider the following penalized least-squares problem (Lasso):  \n\n$$\n\\frac{1}{2}\\|\\mathbf{Y}-\\mathbf{X}{\\boldsymbol{\\beta}}\\|^{2}+\\lambda\\|{\\boldsymbol{\\beta}}\\|_{1}\n$$  \n\nLet $\\hat{\\beta}$ be a minimizer and $\\Delta={\\widehat{\\beta}}-\\beta^{*}$ for any given $\\beta^{*}$. If $\\lambda>2\\Vert\\mathbf{X}^{T}(\\mathbf{Y}-\\mathbf{X}\\beta^{\\ast})\\Vert_{\\infty}$, show that  \n\n$\\begin{array}{r}{\\mathsf{l.}\\;\\|\\mathbf{Y}-\\mathbf{X}^{T}\\widehat{\\beta}\\|^{2}-\\|\\mathbf{Y}-\\mathbf{X}^{T}\\beta^{*}\\|^{2}>-\\lambda\\|\\pmb{\\Delta}\\|_{1}.}\\end{array}$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Numeric",
        "evidence_source": "text",
        "evidence_context": "Problem 1. One hundred passengers board a plane with exactly 100 seats. The first passenger takes a seat at random. The second passenger takes his own seat if it is available, otherwise he takes at random a seat among the available ones. This process continues until all the 100 passengers have boarded the plane. What is the probability that the last passenger takes his own seat?",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/team-probability2015.pdf_0",
        "ID": "04eef3ab-854c-4d41-aaee-afbe1840a1ee",
        "questions": "In a penalized least-squares problem known as Lasso, what condition involving lambda is given to show an inequality involving the minimizer \\( \\hat{\\beta} \\) and any given \\( \\beta^{*} \\)?",
        "answers": "\\( \\lambda>2\\Vert\\mathbf{X}^{T}(\\mathbf{Y}-\\mathbf{X}\\beta^{\\ast})\\Vert_{\\infty} \\)",
        "context": "# Probability and Statistics Team (5 problems)  \n\nProblem 1. One hundred passengers board a plane with exactly 100 seats. The first passenger takes a seat at random. The second passenger takes his own seat if it is available, otherwise he takes at random a seat among the available ones. The third passenger takes his own seat if it is available, otherwise he takes at random a seat among the available ones. This process continues until all the 100 passengers have boarded the plane. What is the probability that the last passenger takes his own seat?  \n\nProblem 2. Assume a sequence of random variables $X_{n}$ converges in distribution to a random variable $X$. Let $\\{N_{t}, t\\ge0\\}$ be a set of positive integer-valued random variables, which is independent of $\\left(X_{n}\\right)$ and converges in probability to $\\infty$ as $t\\to\\infty$. Prove that $X_{N_{t}}$ converges in distribution to $X$ as $t\\to\\infty$.  \n\nProblem 3. Suppose $T_{1}, T_{2}, .\\,.\\,.\\,, T_{n}$ is a sequence of independent, identically distributed random variables with the exponential distribution of the density function  \n\n$$\np(x) =\n\\begin{cases} \ne^{-x}, & x \\geq 0; \\\\\n0, & x < 0.\n\\end{cases}\n\n$$  \n\nLet $S_{n}=T_{1}+T_{2}+\\cdot\\cdot\\cdot+T_{n}$. Find the distribution of the random vector  \n\n$$\nV_{n}=\\Big\\{\\frac{T_{1}}{S_{n}},\\frac{T_{2}}{S_{n}},\\cdots,\\frac{T_{n}}{S_{n}}\\Big\\}.\n$$  \n\nProblem 4. Suppose that $X$ and $Z$ are jointly normal with mean zero and standard deviation 1. For a strictly monotonic function $f(\\cdot)$, $\\operatorname{cov}(X,Z)\\;=\\;0$ if and only if $\\operatorname{cov}(X,f(Z))\\,=\\,0$, provided the latter covariance exists. Hint: $Z$ can be expressed as $Z=\\rho X+\\varepsilon$ where $X$ and $\\widehat{=}$ are independent and $\\varepsilon\\sim N(0,\\sqrt{1-\\rho^{2}})$.  \n\nProblem 5. Consider the following penalized least-squares problem (Lasso):  \n\n$$\n\\frac{1}{2}\\|\\mathbf{Y}-\\mathbf{X}{\\boldsymbol{\\beta}}\\|^{2}+\\lambda\\|{\\boldsymbol{\\beta}}\\|_{1}\n$$  \n\nLet $\\hat{\\beta}$ be a minimizer and $\\Delta={\\widehat{\\beta}}-\\beta^{*}$ for any given $\\beta^{*}$. If $\\lambda>2\\Vert\\mathbf{X}^{T}(\\mathbf{Y}-\\mathbf{X}\\beta^{\\ast})\\Vert_{\\infty}$, show that  \n\n$\\begin{array}{r}{\\mathsf{l.}\\;\\|\\mathbf{Y}-\\mathbf{X}^{T}\\widehat{\\beta}\\|^{2}-\\|\\mathbf{Y}-\\mathbf{X}^{T}\\beta^{*}\\|^{2}>-\\lambda\\|\\pmb{\\Delta}\\|_{1}.}\\end{array}$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "If \\( \\lambda>2\\Vert\\mathbf{X}^{T}(\\mathbf{Y}-\\mathbf{X}\\beta^{\\ast})\\Vert_{\\infty} \\), show that... \\( \\|\\mathbf{Y}-\\mathbf{X}^{T}\\widehat{\\beta}\\|^{2}-\\|\\mathbf{Y}-\\mathbf{X}^{T}\\beta^{*}\\|^{2}>-\\lambda\\|\\pmb{\\Delta}\\|_{1} \\)",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/team-probability2015.pdf_0",
        "ID": "04ef5ca7-e196-4f7a-9d67-829c937a8c37",
        "questions": "Using the hint, how can \\( Z \\) be expressed in terms of \\( X \\) if \\( X \\) and \\( Z \\) are jointly normal with zero mean and unit standard deviation, considering \\( \\rho \\) and \\( \\varepsilon \\), where \\( X \\) and \\( \\varepsilon \\) are independent?",
        "answers": "Z=\\rho X+\\varepsilon",
        "context": "# Probability and Statistics Team (5 problems)  \n\nProblem 1. One hundred passengers board a plane with exactly 100 seats. The first passenger takes a seat at random. The second passenger takes his own seat if it is available, otherwise he takes at random a seat among the available ones. The third passenger takes his own seat if it is available, otherwise he takes at random a seat among the available ones. This process continues until all the 100 passengers have boarded the plane. What is the probability that the last passenger takes his own seat?  \n\nProblem 2. Assume a sequence of random variables $X_{n}$ converges in distribution to a random variable $X$. Let $\\{N_{t}, t\\ge0\\}$ be a set of positive integer-valued random variables, which is independent of $\\left(X_{n}\\right)$ and converges in probability to $\\infty$ as $t\\to\\infty$. Prove that $X_{N_{t}}$ converges in distribution to $X$ as $t\\to\\infty$.  \n\nProblem 3. Suppose $T_{1}, T_{2}, .\\,.\\,.\\,, T_{n}$ is a sequence of independent, identically distributed random variables with the exponential distribution of the density function  \n\n$$\np(x) =\n\\begin{cases} \ne^{-x}, & x \\geq 0; \\\\\n0, & x < 0.\n\\end{cases}\n\n$$  \n\nLet $S_{n}=T_{1}+T_{2}+\\cdot\\cdot\\cdot+T_{n}$. Find the distribution of the random vector  \n\n$$\nV_{n}=\\Big\\{\\frac{T_{1}}{S_{n}},\\frac{T_{2}}{S_{n}},\\cdots,\\frac{T_{n}}{S_{n}}\\Big\\}.\n$$  \n\nProblem 4. Suppose that $X$ and $Z$ are jointly normal with mean zero and standard deviation 1. For a strictly monotonic function $f(\\cdot)$, $\\operatorname{cov}(X,Z)\\;=\\;0$ if and only if $\\operatorname{cov}(X,f(Z))\\,=\\,0$, provided the latter covariance exists. Hint: $Z$ can be expressed as $Z=\\rho X+\\varepsilon$ where $X$ and $\\widehat{=}$ are independent and $\\varepsilon\\sim N(0,\\sqrt{1-\\rho^{2}})$.  \n\nProblem 5. Consider the following penalized least-squares problem (Lasso):  \n\n$$\n\\frac{1}{2}\\|\\mathbf{Y}-\\mathbf{X}{\\boldsymbol{\\beta}}\\|^{2}+\\lambda\\|{\\boldsymbol{\\beta}}\\|_{1}\n$$  \n\nLet $\\hat{\\beta}$ be a minimizer and $\\Delta={\\widehat{\\beta}}-\\beta^{*}$ for any given $\\beta^{*}$. If $\\lambda>2\\Vert\\mathbf{X}^{T}(\\mathbf{Y}-\\mathbf{X}\\beta^{\\ast})\\Vert_{\\infty}$, show that  \n\n$\\begin{array}{r}{\\mathsf{l.}\\;\\|\\mathbf{Y}-\\mathbf{X}^{T}\\widehat{\\beta}\\|^{2}-\\|\\mathbf{Y}-\\mathbf{X}^{T}\\beta^{*}\\|^{2}>-\\lambda\\|\\pmb{\\Delta}\\|_{1}.}\\end{array}$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Hint: \\( Z \\) can be expressed as \\( Z=\\rho X+\\varepsilon \\) where \\( X \\) and \\( \\widehat{=} \\) are independent and \\( \\varepsilon\\sim N(0,\\sqrt{1-\\rho^{2}}) \\).",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/team-probability2015.pdf_0",
        "ID": "04f65b19-4e68-4ad2-b5d7-4923c983453c",
        "questions": "What are the conditions of the random variables $T_{1}, T_{2}, ... , T_{n}$ in Problem 3 with exponential distribution?",
        "answers": "$T_{1}, T_{2}, ... , T_{n}$ is a sequence of independent, identically distributed random variables with the exponential distribution of the density function $$p(x) = \\begin{cases} e^{-x}, & x \\geq 0;\\ 0, & x < 0.\\end{cases}$$",
        "context": "# Probability and Statistics Team (5 problems)  \n\nProblem 1. One hundred passengers board a plane with exactly 100 seats. The first passenger takes a seat at random. The second passenger takes his own seat if it is available, otherwise he takes at random a seat among the available ones. The third passenger takes his own seat if it is available, otherwise he takes at random a seat among the available ones. This process continues until all the 100 passengers have boarded the plane. What is the probability that the last passenger takes his own seat?  \n\nProblem 2. Assume a sequence of random variables $X_{n}$ converges in distribution to a random variable $X$. Let $\\{N_{t}, t\\ge0\\}$ be a set of positive integer-valued random variables, which is independent of $\\left(X_{n}\\right)$ and converges in probability to $\\infty$ as $t\\to\\infty$. Prove that $X_{N_{t}}$ converges in distribution to $X$ as $t\\to\\infty$.  \n\nProblem 3. Suppose $T_{1}, T_{2}, .\\,.\\,.\\,, T_{n}$ is a sequence of independent, identically distributed random variables with the exponential distribution of the density function  \n\n$$\np(x) =\n\\begin{cases} \ne^{-x}, & x \\geq 0; \\\\\n0, & x < 0.\n\\end{cases}\n\n$$  \n\nLet $S_{n}=T_{1}+T_{2}+\\cdot\\cdot\\cdot+T_{n}$. Find the distribution of the random vector  \n\n$$\nV_{n}=\\Big\\{\\frac{T_{1}}{S_{n}},\\frac{T_{2}}{S_{n}},\\cdots,\\frac{T_{n}}{S_{n}}\\Big\\}.\n$$  \n\nProblem 4. Suppose that $X$ and $Z$ are jointly normal with mean zero and standard deviation 1. For a strictly monotonic function $f(\\cdot)$, $\\operatorname{cov}(X,Z)\\;=\\;0$ if and only if $\\operatorname{cov}(X,f(Z))\\,=\\,0$, provided the latter covariance exists. Hint: $Z$ can be expressed as $Z=\\rho X+\\varepsilon$ where $X$ and $\\widehat{=}$ are independent and $\\varepsilon\\sim N(0,\\sqrt{1-\\rho^{2}})$.  \n\nProblem 5. Consider the following penalized least-squares problem (Lasso):  \n\n$$\n\\frac{1}{2}\\|\\mathbf{Y}-\\mathbf{X}{\\boldsymbol{\\beta}}\\|^{2}+\\lambda\\|{\\boldsymbol{\\beta}}\\|_{1}\n$$  \n\nLet $\\hat{\\beta}$ be a minimizer and $\\Delta={\\widehat{\\beta}}-\\beta^{*}$ for any given $\\beta^{*}$. If $\\lambda>2\\Vert\\mathbf{X}^{T}(\\mathbf{Y}-\\mathbf{X}\\beta^{\\ast})\\Vert_{\\infty}$, show that  \n\n$\\begin{array}{r}{\\mathsf{l.}\\;\\|\\mathbf{Y}-\\mathbf{X}^{T}\\widehat{\\beta}\\|^{2}-\\|\\mathbf{Y}-\\mathbf{X}^{T}\\beta^{*}\\|^{2}>-\\lambda\\|\\pmb{\\Delta}\\|_{1}.}\\end{array}$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$T_{1}, T_{2}, ... , T_{n}$ is a sequence of independent, identically distributed random variables with the exponential distribution of the density function $$p(x) = \\begin{cases} e^{-x}, & x \\geq 0;\\ 0, & x < 0.\\end{cases}$$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/team-probability2015.pdf_0",
        "ID": "04f980a2-a168-47b0-ae2d-33bdb46c7a54",
        "questions": "What is the condition for $\\lambda$ in the penalized least-squares problem in Problem 5 where the Lasso estimator $\\hat{\beta}$ minimizes the given function?",
        "answers": "$\\lambda > 2\\Vert\\mathbf{X}^{T}(\\mathbf{Y}-\\mathbf{X}\\beta^{\\ast})\\Vert_{\\infty}$",
        "context": "# Probability and Statistics Team (5 problems)  \n\nProblem 1. One hundred passengers board a plane with exactly 100 seats. The first passenger takes a seat at random. The second passenger takes his own seat if it is available, otherwise he takes at random a seat among the available ones. The third passenger takes his own seat if it is available, otherwise he takes at random a seat among the available ones. This process continues until all the 100 passengers have boarded the plane. What is the probability that the last passenger takes his own seat?  \n\nProblem 2. Assume a sequence of random variables $X_{n}$ converges in distribution to a random variable $X$. Let $\\{N_{t}, t\\ge0\\}$ be a set of positive integer-valued random variables, which is independent of $\\left(X_{n}\\right)$ and converges in probability to $\\infty$ as $t\\to\\infty$. Prove that $X_{N_{t}}$ converges in distribution to $X$ as $t\\to\\infty$.  \n\nProblem 3. Suppose $T_{1}, T_{2}, .\\,.\\,.\\,, T_{n}$ is a sequence of independent, identically distributed random variables with the exponential distribution of the density function  \n\n$$\np(x) =\n\\begin{cases} \ne^{-x}, & x \\geq 0; \\\\\n0, & x < 0.\n\\end{cases}\n\n$$  \n\nLet $S_{n}=T_{1}+T_{2}+\\cdot\\cdot\\cdot+T_{n}$. Find the distribution of the random vector  \n\n$$\nV_{n}=\\Big\\{\\frac{T_{1}}{S_{n}},\\frac{T_{2}}{S_{n}},\\cdots,\\frac{T_{n}}{S_{n}}\\Big\\}.\n$$  \n\nProblem 4. Suppose that $X$ and $Z$ are jointly normal with mean zero and standard deviation 1. For a strictly monotonic function $f(\\cdot)$, $\\operatorname{cov}(X,Z)\\;=\\;0$ if and only if $\\operatorname{cov}(X,f(Z))\\,=\\,0$, provided the latter covariance exists. Hint: $Z$ can be expressed as $Z=\\rho X+\\varepsilon$ where $X$ and $\\widehat{=}$ are independent and $\\varepsilon\\sim N(0,\\sqrt{1-\\rho^{2}})$.  \n\nProblem 5. Consider the following penalized least-squares problem (Lasso):  \n\n$$\n\\frac{1}{2}\\|\\mathbf{Y}-\\mathbf{X}{\\boldsymbol{\\beta}}\\|^{2}+\\lambda\\|{\\boldsymbol{\\beta}}\\|_{1}\n$$  \n\nLet $\\hat{\\beta}$ be a minimizer and $\\Delta={\\widehat{\\beta}}-\\beta^{*}$ for any given $\\beta^{*}$. If $\\lambda>2\\Vert\\mathbf{X}^{T}(\\mathbf{Y}-\\mathbf{X}\\beta^{\\ast})\\Vert_{\\infty}$, show that  \n\n$\\begin{array}{r}{\\mathsf{l.}\\;\\|\\mathbf{Y}-\\mathbf{X}^{T}\\widehat{\\beta}\\|^{2}-\\|\\mathbf{Y}-\\mathbf{X}^{T}\\beta^{*}\\|^{2}>-\\lambda\\|\\pmb{\\Delta}\\|_{1}.}\\end{array}$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "If $\\lambda>2\\Vert\\mathbf{X}^{T}(\\mathbf{Y}-\\mathbf{X}\\beta^{\\ast})\\Vert_{\\infty}$, show that",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/team-probability2015.pdf_0",
        "ID": "051266c2-d444-4d7f-995a-f0cfd16a2182",
        "questions": "Regarding the covariance properties in Problem 4, what is $Z$ expressed in terms of $X$ and error variable $\u000barepsilon$?",
        "answers": "$Z=\\rho X+\\varepsilon$ where $X$ and $\\varepsilon$ are independent and $\\varepsilon\\sim N(0,\\sqrt{1-\\rho^{2}})$",
        "context": "# Probability and Statistics Team (5 problems)  \n\nProblem 1. One hundred passengers board a plane with exactly 100 seats. The first passenger takes a seat at random. The second passenger takes his own seat if it is available, otherwise he takes at random a seat among the available ones. The third passenger takes his own seat if it is available, otherwise he takes at random a seat among the available ones. This process continues until all the 100 passengers have boarded the plane. What is the probability that the last passenger takes his own seat?  \n\nProblem 2. Assume a sequence of random variables $X_{n}$ converges in distribution to a random variable $X$. Let $\\{N_{t}, t\\ge0\\}$ be a set of positive integer-valued random variables, which is independent of $\\left(X_{n}\\right)$ and converges in probability to $\\infty$ as $t\\to\\infty$. Prove that $X_{N_{t}}$ converges in distribution to $X$ as $t\\to\\infty$.  \n\nProblem 3. Suppose $T_{1}, T_{2}, .\\,.\\,.\\,, T_{n}$ is a sequence of independent, identically distributed random variables with the exponential distribution of the density function  \n\n$$\np(x) =\n\\begin{cases} \ne^{-x}, & x \\geq 0; \\\\\n0, & x < 0.\n\\end{cases}\n\n$$  \n\nLet $S_{n}=T_{1}+T_{2}+\\cdot\\cdot\\cdot+T_{n}$. Find the distribution of the random vector  \n\n$$\nV_{n}=\\Big\\{\\frac{T_{1}}{S_{n}},\\frac{T_{2}}{S_{n}},\\cdots,\\frac{T_{n}}{S_{n}}\\Big\\}.\n$$  \n\nProblem 4. Suppose that $X$ and $Z$ are jointly normal with mean zero and standard deviation 1. For a strictly monotonic function $f(\\cdot)$, $\\operatorname{cov}(X,Z)\\;=\\;0$ if and only if $\\operatorname{cov}(X,f(Z))\\,=\\,0$, provided the latter covariance exists. Hint: $Z$ can be expressed as $Z=\\rho X+\\varepsilon$ where $X$ and $\\widehat{=}$ are independent and $\\varepsilon\\sim N(0,\\sqrt{1-\\rho^{2}})$.  \n\nProblem 5. Consider the following penalized least-squares problem (Lasso):  \n\n$$\n\\frac{1}{2}\\|\\mathbf{Y}-\\mathbf{X}{\\boldsymbol{\\beta}}\\|^{2}+\\lambda\\|{\\boldsymbol{\\beta}}\\|_{1}\n$$  \n\nLet $\\hat{\\beta}$ be a minimizer and $\\Delta={\\widehat{\\beta}}-\\beta^{*}$ for any given $\\beta^{*}$. If $\\lambda>2\\Vert\\mathbf{X}^{T}(\\mathbf{Y}-\\mathbf{X}\\beta^{\\ast})\\Vert_{\\infty}$, show that  \n\n$\\begin{array}{r}{\\mathsf{l.}\\;\\|\\mathbf{Y}-\\mathbf{X}^{T}\\widehat{\\beta}\\|^{2}-\\|\\mathbf{Y}-\\mathbf{X}^{T}\\beta^{*}\\|^{2}>-\\lambda\\|\\pmb{\\Delta}\\|_{1}.}\\end{array}$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$Z$ can be expressed as $Z=\\rho X+\\varepsilon$ where $X$ and $\\varepsilon$ are independent and $\\varepsilon\\sim N(0,\\sqrt{1-\\rho^{2}})$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/An_Introduction_To_Quantum_Field_Theory(Peski.pdf_437",
        "ID": "05147fea-9644-4c04-bfec-7d978e13c327",
        "questions": "What is the relation between the bare and renormalized field in terms of the renormalization factor Z(M)?",
        "answers": "\u03c6(p) = Z(M)^{-1/2}\u03c6_{0}(p)",
        "context": "First recall that the bare and renormalized field are related by  \n\n$$\n\\phi(p)=Z(M)^{-1/2}\\phi_{0}(p).\n$$  \n\nThis equation expresses the dependence of the field re-scaling on $M$. When $M$ is increased by $\\delta M$, the renormalized field is shifted by  \n\n$$\n\\delta\\eta=\\frac{Z(M+\\delta M)^{-1/2}}{Z(M)^{-1/2}}-1.\n$$  \n\nHence, our original definition (12.39) of $\\gamma$ gives us immediately  \n\n$$\n\\gamma(\\lambda)=\\frac{1}{2}\\frac{M}{Z}\\frac{\\partial}{\\partial M}Z.\n$$  \n\nSince $\\delta_{Z}=Z-1$ (Eq. (10.17)), this formula is in agreement with (12.50) to leading order. Formula (12.63), however, is an exact relation. This expression clarifies the relation of $\\gamma$ to the field strength rescaling. However, it obscures the fact that $\\gamma$ is independent of the cutoff $A$. To understand this aspect of $\\gamma$, we have to go back to the original definition of this function in terms of renormalized Green's functions, whose cutoff independence flows from the renormalizability of the theory.  \n\nSimilarly, we can find an instructive expression for $\\beta$ in terms of the parameters of bare perturbation theory. Our original definition of $\\beta$ in Eq. (12.39) made use of a quantity $\\delta\\lambda$, defined to be the shift of the renormalized coupling $\\lambda$ needed to preserve the values of the bare Green's functions when the renormalization point is shifted infinitesimally. Since the bare Green's functions depend on the bare coupling $\\lambda_{0}$ and the cutoff, this definition can be rewritten as  \n\n$$\n\\beta(\\lambda)=M\\frac{\\partial}{\\partial M}\\lambda\\Big|_{\\lambda_{0},\\Lambda}.\n$$  \n\nThus, the $\\beta$ function is the rate of change of the renormalized coupling at the scale $M$ corresponding to a fixed bare coupling. Recalling our analysis in Section 12.1, it is tempting to associate $\\lambda(M)$ with the coupling constant $\\lambda^{\\prime}$ obtained by integrating out degrees of freedom down to the scale $M$. With this correspondence, the $\\beta$ function is just the rate of the renormalization group flow of the coupling constant $\\lambda$. A positive sign for the $\\beta$ function indicates a renormalized coupling that increases at large momenta and decreases at small momenta. We can see explicitly that this relation works for $\\phi^{4}$ theory, to leading order in $\\lambda$, by comparing Eqs. (12.28) and (12.46). We will justify this correspondence further in the following section.  \n\nThe equality of the exact formula (12.64) with the first-order formula (12.53) again follows from the counterterm definitions (10.17). As with (12.63), it is not obvious that this formula for $\\beta(\\lambda)$ is independent of $\\Lambda$, but that fact again follows from renormalizability. Conversely, it is possible to prove the",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "First recall that the bare and renormalized field are related by \u03c6(p) = Z(M)^{-1/2}\u03c6_{0}(p).",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/An_Introduction_To_Quantum_Field_Theory(Peski.pdf_437",
        "ID": "051dcf24-03f2-4d3e-b8e6-d3bddd298a57",
        "questions": "What does a positive sign for the \u03b2 function indicate about the renormalized coupling \u03bb at different momentum scales in the context of the renormalization group flow?",
        "answers": "A positive sign for the \u03b2 function indicates a renormalized coupling that increases at large momenta and decreases at small momenta.",
        "context": "First recall that the bare and renormalized field are related by  \n\n$$\n\\phi(p)=Z(M)^{-1/2}\\phi_{0}(p).\n$$  \n\nThis equation expresses the dependence of the field re-scaling on $M$. When $M$ is increased by $\\delta M$, the renormalized field is shifted by  \n\n$$\n\\delta\\eta=\\frac{Z(M+\\delta M)^{-1/2}}{Z(M)^{-1/2}}-1.\n$$  \n\nHence, our original definition (12.39) of $\\gamma$ gives us immediately  \n\n$$\n\\gamma(\\lambda)=\\frac{1}{2}\\frac{M}{Z}\\frac{\\partial}{\\partial M}Z.\n$$  \n\nSince $\\delta_{Z}=Z-1$ (Eq. (10.17)), this formula is in agreement with (12.50) to leading order. Formula (12.63), however, is an exact relation. This expression clarifies the relation of $\\gamma$ to the field strength rescaling. However, it obscures the fact that $\\gamma$ is independent of the cutoff $A$. To understand this aspect of $\\gamma$, we have to go back to the original definition of this function in terms of renormalized Green's functions, whose cutoff independence flows from the renormalizability of the theory.  \n\nSimilarly, we can find an instructive expression for $\\beta$ in terms of the parameters of bare perturbation theory. Our original definition of $\\beta$ in Eq. (12.39) made use of a quantity $\\delta\\lambda$, defined to be the shift of the renormalized coupling $\\lambda$ needed to preserve the values of the bare Green's functions when the renormalization point is shifted infinitesimally. Since the bare Green's functions depend on the bare coupling $\\lambda_{0}$ and the cutoff, this definition can be rewritten as  \n\n$$\n\\beta(\\lambda)=M\\frac{\\partial}{\\partial M}\\lambda\\Big|_{\\lambda_{0},\\Lambda}.\n$$  \n\nThus, the $\\beta$ function is the rate of change of the renormalized coupling at the scale $M$ corresponding to a fixed bare coupling. Recalling our analysis in Section 12.1, it is tempting to associate $\\lambda(M)$ with the coupling constant $\\lambda^{\\prime}$ obtained by integrating out degrees of freedom down to the scale $M$. With this correspondence, the $\\beta$ function is just the rate of the renormalization group flow of the coupling constant $\\lambda$. A positive sign for the $\\beta$ function indicates a renormalized coupling that increases at large momenta and decreases at small momenta. We can see explicitly that this relation works for $\\phi^{4}$ theory, to leading order in $\\lambda$, by comparing Eqs. (12.28) and (12.46). We will justify this correspondence further in the following section.  \n\nThe equality of the exact formula (12.64) with the first-order formula (12.53) again follows from the counterterm definitions (10.17). As with (12.63), it is not obvious that this formula for $\\beta(\\lambda)$ is independent of $\\Lambda$, but that fact again follows from renormalizability. Conversely, it is possible to prove the",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "A positive sign for the \u03b2 function indicates a renormalized coupling that increases at large momenta and decreases at small momenta.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/An_Introduction_To_Quantum_Field_Theory(Peski.pdf_437",
        "ID": "052daad3-26c0-4984-8734-bb05788c31f6",
        "questions": "In the context of the given document, how is the \u03b3 function related to the field strength rescaling and its derivative with respect to the scale M?",
        "answers": "\u03b3(\u03bb) = \u00bd (M / Z) (\u2202Z / \u2202M)",
        "context": "First recall that the bare and renormalized field are related by  \n\n$$\n\\phi(p)=Z(M)^{-1/2}\\phi_{0}(p).\n$$  \n\nThis equation expresses the dependence of the field re-scaling on $M$. When $M$ is increased by $\\delta M$, the renormalized field is shifted by  \n\n$$\n\\delta\\eta=\\frac{Z(M+\\delta M)^{-1/2}}{Z(M)^{-1/2}}-1.\n$$  \n\nHence, our original definition (12.39) of $\\gamma$ gives us immediately  \n\n$$\n\\gamma(\\lambda)=\\frac{1}{2}\\frac{M}{Z}\\frac{\\partial}{\\partial M}Z.\n$$  \n\nSince $\\delta_{Z}=Z-1$ (Eq. (10.17)), this formula is in agreement with (12.50) to leading order. Formula (12.63), however, is an exact relation. This expression clarifies the relation of $\\gamma$ to the field strength rescaling. However, it obscures the fact that $\\gamma$ is independent of the cutoff $A$. To understand this aspect of $\\gamma$, we have to go back to the original definition of this function in terms of renormalized Green's functions, whose cutoff independence flows from the renormalizability of the theory.  \n\nSimilarly, we can find an instructive expression for $\\beta$ in terms of the parameters of bare perturbation theory. Our original definition of $\\beta$ in Eq. (12.39) made use of a quantity $\\delta\\lambda$, defined to be the shift of the renormalized coupling $\\lambda$ needed to preserve the values of the bare Green's functions when the renormalization point is shifted infinitesimally. Since the bare Green's functions depend on the bare coupling $\\lambda_{0}$ and the cutoff, this definition can be rewritten as  \n\n$$\n\\beta(\\lambda)=M\\frac{\\partial}{\\partial M}\\lambda\\Big|_{\\lambda_{0},\\Lambda}.\n$$  \n\nThus, the $\\beta$ function is the rate of change of the renormalized coupling at the scale $M$ corresponding to a fixed bare coupling. Recalling our analysis in Section 12.1, it is tempting to associate $\\lambda(M)$ with the coupling constant $\\lambda^{\\prime}$ obtained by integrating out degrees of freedom down to the scale $M$. With this correspondence, the $\\beta$ function is just the rate of the renormalization group flow of the coupling constant $\\lambda$. A positive sign for the $\\beta$ function indicates a renormalized coupling that increases at large momenta and decreases at small momenta. We can see explicitly that this relation works for $\\phi^{4}$ theory, to leading order in $\\lambda$, by comparing Eqs. (12.28) and (12.46). We will justify this correspondence further in the following section.  \n\nThe equality of the exact formula (12.64) with the first-order formula (12.53) again follows from the counterterm definitions (10.17). As with (12.63), it is not obvious that this formula for $\\beta(\\lambda)$ is independent of $\\Lambda$, but that fact again follows from renormalizability. Conversely, it is possible to prove the",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Hence, our original definition (12.39) of \u03b3 gives us immediately \u03b3(\u03bb) = \u00bd (M / Z) (\u2202Z / \u2202M).",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/An_Introduction_To_Quantum_Field_Theory(Peski.pdf_437",
        "ID": "0534a252-a6d3-46c4-b810-c0405cec2965",
        "questions": "What is the relationship between the bare field $\\phi_{0}(p)$ and the renormalized field $\\phi(p)$?",
        "answers": "$$\\phi(p)=Z(M)^{-1/2}\\phi_{0}(p).$$",
        "context": "First recall that the bare and renormalized field are related by  \n\n$$\n\\phi(p)=Z(M)^{-1/2}\\phi_{0}(p).\n$$  \n\nThis equation expresses the dependence of the field re-scaling on $M$. When $M$ is increased by $\\delta M$, the renormalized field is shifted by  \n\n$$\n\\delta\\eta=\\frac{Z(M+\\delta M)^{-1/2}}{Z(M)^{-1/2}}-1.\n$$  \n\nHence, our original definition (12.39) of $\\gamma$ gives us immediately  \n\n$$\n\\gamma(\\lambda)=\\frac{1}{2}\\frac{M}{Z}\\frac{\\partial}{\\partial M}Z.\n$$  \n\nSince $\\delta_{Z}=Z-1$ (Eq. (10.17)), this formula is in agreement with (12.50) to leading order. Formula (12.63), however, is an exact relation. This expression clarifies the relation of $\\gamma$ to the field strength rescaling. However, it obscures the fact that $\\gamma$ is independent of the cutoff $A$. To understand this aspect of $\\gamma$, we have to go back to the original definition of this function in terms of renormalized Green's functions, whose cutoff independence flows from the renormalizability of the theory.  \n\nSimilarly, we can find an instructive expression for $\\beta$ in terms of the parameters of bare perturbation theory. Our original definition of $\\beta$ in Eq. (12.39) made use of a quantity $\\delta\\lambda$, defined to be the shift of the renormalized coupling $\\lambda$ needed to preserve the values of the bare Green's functions when the renormalization point is shifted infinitesimally. Since the bare Green's functions depend on the bare coupling $\\lambda_{0}$ and the cutoff, this definition can be rewritten as  \n\n$$\n\\beta(\\lambda)=M\\frac{\\partial}{\\partial M}\\lambda\\Big|_{\\lambda_{0},\\Lambda}.\n$$  \n\nThus, the $\\beta$ function is the rate of change of the renormalized coupling at the scale $M$ corresponding to a fixed bare coupling. Recalling our analysis in Section 12.1, it is tempting to associate $\\lambda(M)$ with the coupling constant $\\lambda^{\\prime}$ obtained by integrating out degrees of freedom down to the scale $M$. With this correspondence, the $\\beta$ function is just the rate of the renormalization group flow of the coupling constant $\\lambda$. A positive sign for the $\\beta$ function indicates a renormalized coupling that increases at large momenta and decreases at small momenta. We can see explicitly that this relation works for $\\phi^{4}$ theory, to leading order in $\\lambda$, by comparing Eqs. (12.28) and (12.46). We will justify this correspondence further in the following section.  \n\nThe equality of the exact formula (12.64) with the first-order formula (12.53) again follows from the counterterm definitions (10.17). As with (12.63), it is not obvious that this formula for $\\beta(\\lambda)$ is independent of $\\Lambda$, but that fact again follows from renormalizability. Conversely, it is possible to prove the",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$$\\phi(p)=Z(M)^{-1/2}\\phi_{0}(p).$$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/An_Introduction_To_Quantum_Field_Theory(Peski.pdf_437",
        "ID": "054961d6-0438-43d4-a81b-3fe3fda48455",
        "questions": "How is the $\beta$ function expressed in terms of the parameters of bare perturbation theory?",
        "answers": "$$\beta(\\lambda)=M\frac{\\partial}{\\partial M}\\lambda\\Big|_{\\lambda_{0},\\Lambda}.$$",
        "context": "First recall that the bare and renormalized field are related by  \n\n$$\n\\phi(p)=Z(M)^{-1/2}\\phi_{0}(p).\n$$  \n\nThis equation expresses the dependence of the field re-scaling on $M$. When $M$ is increased by $\\delta M$, the renormalized field is shifted by  \n\n$$\n\\delta\\eta=\\frac{Z(M+\\delta M)^{-1/2}}{Z(M)^{-1/2}}-1.\n$$  \n\nHence, our original definition (12.39) of $\\gamma$ gives us immediately  \n\n$$\n\\gamma(\\lambda)=\\frac{1}{2}\\frac{M}{Z}\\frac{\\partial}{\\partial M}Z.\n$$  \n\nSince $\\delta_{Z}=Z-1$ (Eq. (10.17)), this formula is in agreement with (12.50) to leading order. Formula (12.63), however, is an exact relation. This expression clarifies the relation of $\\gamma$ to the field strength rescaling. However, it obscures the fact that $\\gamma$ is independent of the cutoff $A$. To understand this aspect of $\\gamma$, we have to go back to the original definition of this function in terms of renormalized Green's functions, whose cutoff independence flows from the renormalizability of the theory.  \n\nSimilarly, we can find an instructive expression for $\\beta$ in terms of the parameters of bare perturbation theory. Our original definition of $\\beta$ in Eq. (12.39) made use of a quantity $\\delta\\lambda$, defined to be the shift of the renormalized coupling $\\lambda$ needed to preserve the values of the bare Green's functions when the renormalization point is shifted infinitesimally. Since the bare Green's functions depend on the bare coupling $\\lambda_{0}$ and the cutoff, this definition can be rewritten as  \n\n$$\n\\beta(\\lambda)=M\\frac{\\partial}{\\partial M}\\lambda\\Big|_{\\lambda_{0},\\Lambda}.\n$$  \n\nThus, the $\\beta$ function is the rate of change of the renormalized coupling at the scale $M$ corresponding to a fixed bare coupling. Recalling our analysis in Section 12.1, it is tempting to associate $\\lambda(M)$ with the coupling constant $\\lambda^{\\prime}$ obtained by integrating out degrees of freedom down to the scale $M$. With this correspondence, the $\\beta$ function is just the rate of the renormalization group flow of the coupling constant $\\lambda$. A positive sign for the $\\beta$ function indicates a renormalized coupling that increases at large momenta and decreases at small momenta. We can see explicitly that this relation works for $\\phi^{4}$ theory, to leading order in $\\lambda$, by comparing Eqs. (12.28) and (12.46). We will justify this correspondence further in the following section.  \n\nThe equality of the exact formula (12.64) with the first-order formula (12.53) again follows from the counterterm definitions (10.17). As with (12.63), it is not obvious that this formula for $\\beta(\\lambda)$ is independent of $\\Lambda$, but that fact again follows from renormalizability. Conversely, it is possible to prove the",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$$\beta(\\lambda)=M\frac{\\partial}{\\partial M}\\lambda\\Big|_{\\lambda_{0},\\Lambda}.$$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/An_Introduction_To_Quantum_Field_Theory(Peski.pdf_437",
        "ID": "054b34e9-6922-4a46-8dd4-8f958b04fdf2",
        "questions": "What is the expression for the field re-scaling shift when $M$ is increased by $\\delta M$?",
        "answers": "$$\\delta\\eta=\frac{Z(M+\\delta M)^{-1/2}}{Z(M)^{-1/2}}-1.$$",
        "context": "First recall that the bare and renormalized field are related by  \n\n$$\n\\phi(p)=Z(M)^{-1/2}\\phi_{0}(p).\n$$  \n\nThis equation expresses the dependence of the field re-scaling on $M$. When $M$ is increased by $\\delta M$, the renormalized field is shifted by  \n\n$$\n\\delta\\eta=\\frac{Z(M+\\delta M)^{-1/2}}{Z(M)^{-1/2}}-1.\n$$  \n\nHence, our original definition (12.39) of $\\gamma$ gives us immediately  \n\n$$\n\\gamma(\\lambda)=\\frac{1}{2}\\frac{M}{Z}\\frac{\\partial}{\\partial M}Z.\n$$  \n\nSince $\\delta_{Z}=Z-1$ (Eq. (10.17)), this formula is in agreement with (12.50) to leading order. Formula (12.63), however, is an exact relation. This expression clarifies the relation of $\\gamma$ to the field strength rescaling. However, it obscures the fact that $\\gamma$ is independent of the cutoff $A$. To understand this aspect of $\\gamma$, we have to go back to the original definition of this function in terms of renormalized Green's functions, whose cutoff independence flows from the renormalizability of the theory.  \n\nSimilarly, we can find an instructive expression for $\\beta$ in terms of the parameters of bare perturbation theory. Our original definition of $\\beta$ in Eq. (12.39) made use of a quantity $\\delta\\lambda$, defined to be the shift of the renormalized coupling $\\lambda$ needed to preserve the values of the bare Green's functions when the renormalization point is shifted infinitesimally. Since the bare Green's functions depend on the bare coupling $\\lambda_{0}$ and the cutoff, this definition can be rewritten as  \n\n$$\n\\beta(\\lambda)=M\\frac{\\partial}{\\partial M}\\lambda\\Big|_{\\lambda_{0},\\Lambda}.\n$$  \n\nThus, the $\\beta$ function is the rate of change of the renormalized coupling at the scale $M$ corresponding to a fixed bare coupling. Recalling our analysis in Section 12.1, it is tempting to associate $\\lambda(M)$ with the coupling constant $\\lambda^{\\prime}$ obtained by integrating out degrees of freedom down to the scale $M$. With this correspondence, the $\\beta$ function is just the rate of the renormalization group flow of the coupling constant $\\lambda$. A positive sign for the $\\beta$ function indicates a renormalized coupling that increases at large momenta and decreases at small momenta. We can see explicitly that this relation works for $\\phi^{4}$ theory, to leading order in $\\lambda$, by comparing Eqs. (12.28) and (12.46). We will justify this correspondence further in the following section.  \n\nThe equality of the exact formula (12.64) with the first-order formula (12.53) again follows from the counterterm definitions (10.17). As with (12.63), it is not obvious that this formula for $\\beta(\\lambda)$ is independent of $\\Lambda$, but that fact again follows from renormalizability. Conversely, it is possible to prove the",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$$\\delta\\eta=\frac{Z(M+\\delta M)^{-1/2}}{Z(M)^{-1/2}}-1.$$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/[undefined_series_for_scimag_]_-_[10.1007_978-0-387-27236-8]_-_libgen.li.pdf_268",
        "ID": "054e5126-7953-40f7-8a13-93ab39b3c49d",
        "questions": "What are the names of the entities that represent the 'temperatures' in the two phases within the one-dimensional 'container' [0,b]?",
        "answers": "y_{1}, y_{2}",
        "context": "$$\n\\begin{array}{r l}{y_{1,t}(t,x)=\\alpha_{1}y_{1,x x}(t,x),\\quad}&{0<t<T,\\ 0<x<u(t),}\\\\ {y_{2,t}(t,x)=\\alpha_{2}y_{2,x x}(t,x),\\quad}&{0<t<T,\\ u(t)<x<b,}\\\\ {y_{1}(0,x)=\\varphi_{1}(x),\\ x\\in[0,u_{0}],\\quad}&{y_{2}(0,x)=\\varphi_{2}(x),\\ x\\in[u_{0},b],}\\\\ {y_{1}(t,0)=0,\\quad}&{y_{2}(t,b)=0,}\\\\ {y_{1}(t,u(t))=y_{2}(t,u(t))=0,\\quad}&{0\\leq t\\leq T,}\\\\ u_{t}(t)=\\beta_2\\,{y_{2,x}(t,u(t))-\\beta_{1}y_{1,x}(t,u(t)),\\quad}&{0<t\\leq T,}\\\\ {u(0)=u_{0}\\in[0,b]\\,.}\\end{array}\n$$  \n\nHere, $y_{1},\\;y_{2}$ represent the \u201ctemperatures\u201d in the two phases (solid and liquid, say), which coexist in the one-dimensional \"container\" $[0,b]$, separated by an interface located at time $t$ at the space point $x=u(t)$, $0\\leq t\\leq T$. The positive constants $\\alpha_{i},\\ \\beta_{i}$, $i=1,2$, are related to the physics of the problem (thermal conductivity, Stefan condition on the interface), and the initial temperature distributions $\\varphi_{i}$, $i=1,2$, in the phases and the initial location $u(0)$ of the interface are known.  \n\nNow let $v\\in L^{2}(0,T)$ be a \"control\" function. We replace the Stefan condition (5.1.26) and (5.1.27) by  \n\n$$\n\\begin{array}{l}{u^{\\prime}\\!\\left(t\\right)\\:=\\:v(t)\\quad\\mathrm{in~}[0,T],}\\\\ {u(0)\\:=\\:u_{0},}\\end{array}\n$$  \n\nwhere $v$ belongs to a prescribed set $U_{a d}$ that usually is chosen compact in $C[0,T]$. In this way, a class of \u201cadmissible free boundaries\u201d is defined. The original problem may then be reformulated as the optimal shape design problem  \n\n$$\n\\operatorname*{Min}_{v\\in U_{a d}}\\left\\{\\int_{0}^{T}\\left[\\beta_{2}\\,y_{2,x}(t,u(t))-\\beta_{1}\\,y_{1,x}(t,u(t))-v(t)\\right]^{2}d t\\right\\},\n$$  \n\nsubject to the system (5.1.21)-(5.1.25) and (5.1.28), (5.1.29).  \n\nWe remark that here the optimal shape design problem could be stated directly as an optimal control problem, since we considered the one-dimensional case. This is not possible in higher dimensions of space.  \n\nThe above relationship between free boundary problems and shape optimization problems is reflected in the scientific literature by the use of similar methods. A survey along these lines may be found in the work of Hoffmann and Tiba [1995]. Several important techniques will be discussed below in this chapter.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Here, $y_{1},\\;y_{2}$ represent the 'temperatures' in the two phases (solid and liquid, say), which coexist in the one-dimensional 'container' $[0,b]$, separated by an interface located at time $t$ at the space point $x=u(t)$, $0\\leq t\\leq T$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/[undefined_series_for_scimag_]_-_[10.1007_978-0-387-27236-8]_-_libgen.li.pdf_268",
        "ID": "054f0566-bb1a-48e2-90b9-1e51681e5658",
        "questions": "According to the given optimal shape design problem, what is the objective function to minimize when v is in the prescribed set U_ad?",
        "answers": "The objective function to minimize is the integral $\\int_{0}^{T}\\left[\beta_{2}\\,y_{2,x}(t,u(t))-\beta_{1}\\,y_{1,x}(t,u(t))-v(t)\right]^{2}d t$",
        "context": "$$\n\\begin{array}{r l}{y_{1,t}(t,x)=\\alpha_{1}y_{1,x x}(t,x),\\quad}&{0<t<T,\\ 0<x<u(t),}\\\\ {y_{2,t}(t,x)=\\alpha_{2}y_{2,x x}(t,x),\\quad}&{0<t<T,\\ u(t)<x<b,}\\\\ {y_{1}(0,x)=\\varphi_{1}(x),\\ x\\in[0,u_{0}],\\quad}&{y_{2}(0,x)=\\varphi_{2}(x),\\ x\\in[u_{0},b],}\\\\ {y_{1}(t,0)=0,\\quad}&{y_{2}(t,b)=0,}\\\\ {y_{1}(t,u(t))=y_{2}(t,u(t))=0,\\quad}&{0\\leq t\\leq T,}\\\\ u_{t}(t)=\\beta_2\\,{y_{2,x}(t,u(t))-\\beta_{1}y_{1,x}(t,u(t)),\\quad}&{0<t\\leq T,}\\\\ {u(0)=u_{0}\\in[0,b]\\,.}\\end{array}\n$$  \n\nHere, $y_{1},\\;y_{2}$ represent the \u201ctemperatures\u201d in the two phases (solid and liquid, say), which coexist in the one-dimensional \"container\" $[0,b]$, separated by an interface located at time $t$ at the space point $x=u(t)$, $0\\leq t\\leq T$. The positive constants $\\alpha_{i},\\ \\beta_{i}$, $i=1,2$, are related to the physics of the problem (thermal conductivity, Stefan condition on the interface), and the initial temperature distributions $\\varphi_{i}$, $i=1,2$, in the phases and the initial location $u(0)$ of the interface are known.  \n\nNow let $v\\in L^{2}(0,T)$ be a \"control\" function. We replace the Stefan condition (5.1.26) and (5.1.27) by  \n\n$$\n\\begin{array}{l}{u^{\\prime}\\!\\left(t\\right)\\:=\\:v(t)\\quad\\mathrm{in~}[0,T],}\\\\ {u(0)\\:=\\:u_{0},}\\end{array}\n$$  \n\nwhere $v$ belongs to a prescribed set $U_{a d}$ that usually is chosen compact in $C[0,T]$. In this way, a class of \u201cadmissible free boundaries\u201d is defined. The original problem may then be reformulated as the optimal shape design problem  \n\n$$\n\\operatorname*{Min}_{v\\in U_{a d}}\\left\\{\\int_{0}^{T}\\left[\\beta_{2}\\,y_{2,x}(t,u(t))-\\beta_{1}\\,y_{1,x}(t,u(t))-v(t)\\right]^{2}d t\\right\\},\n$$  \n\nsubject to the system (5.1.21)-(5.1.25) and (5.1.28), (5.1.29).  \n\nWe remark that here the optimal shape design problem could be stated directly as an optimal control problem, since we considered the one-dimensional case. This is not possible in higher dimensions of space.  \n\nThe above relationship between free boundary problems and shape optimization problems is reflected in the scientific literature by the use of similar methods. A survey along these lines may be found in the work of Hoffmann and Tiba [1995]. Several important techniques will be discussed below in this chapter.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "The original problem may then be reformulated as the optimal shape design problem\n \\operatorname*{Min}_{v\\in U_{a d}}\\left\\{\\int_{0}^{T}\\left[\beta_{2}\\,y_{2,x}(t,u(t))-\beta_{1}\\,y_{1,x}(t,u(t))-v(t)\right]^{2}d t\right\\},",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/[undefined_series_for_scimag_]_-_[10.1007_978-0-387-27236-8]_-_libgen.li.pdf_268",
        "ID": "0567732a-6739-4bfc-acc1-6b269efd95e1",
        "questions": "Do Hoffmann and Tiba [1995] discuss methods related to free boundary and shape optimization problems in higher dimensions of space?",
        "answers": "No",
        "context": "$$\n\\begin{array}{r l}{y_{1,t}(t,x)=\\alpha_{1}y_{1,x x}(t,x),\\quad}&{0<t<T,\\ 0<x<u(t),}\\\\ {y_{2,t}(t,x)=\\alpha_{2}y_{2,x x}(t,x),\\quad}&{0<t<T,\\ u(t)<x<b,}\\\\ {y_{1}(0,x)=\\varphi_{1}(x),\\ x\\in[0,u_{0}],\\quad}&{y_{2}(0,x)=\\varphi_{2}(x),\\ x\\in[u_{0},b],}\\\\ {y_{1}(t,0)=0,\\quad}&{y_{2}(t,b)=0,}\\\\ {y_{1}(t,u(t))=y_{2}(t,u(t))=0,\\quad}&{0\\leq t\\leq T,}\\\\ u_{t}(t)=\\beta_2\\,{y_{2,x}(t,u(t))-\\beta_{1}y_{1,x}(t,u(t)),\\quad}&{0<t\\leq T,}\\\\ {u(0)=u_{0}\\in[0,b]\\,.}\\end{array}\n$$  \n\nHere, $y_{1},\\;y_{2}$ represent the \u201ctemperatures\u201d in the two phases (solid and liquid, say), which coexist in the one-dimensional \"container\" $[0,b]$, separated by an interface located at time $t$ at the space point $x=u(t)$, $0\\leq t\\leq T$. The positive constants $\\alpha_{i},\\ \\beta_{i}$, $i=1,2$, are related to the physics of the problem (thermal conductivity, Stefan condition on the interface), and the initial temperature distributions $\\varphi_{i}$, $i=1,2$, in the phases and the initial location $u(0)$ of the interface are known.  \n\nNow let $v\\in L^{2}(0,T)$ be a \"control\" function. We replace the Stefan condition (5.1.26) and (5.1.27) by  \n\n$$\n\\begin{array}{l}{u^{\\prime}\\!\\left(t\\right)\\:=\\:v(t)\\quad\\mathrm{in~}[0,T],}\\\\ {u(0)\\:=\\:u_{0},}\\end{array}\n$$  \n\nwhere $v$ belongs to a prescribed set $U_{a d}$ that usually is chosen compact in $C[0,T]$. In this way, a class of \u201cadmissible free boundaries\u201d is defined. The original problem may then be reformulated as the optimal shape design problem  \n\n$$\n\\operatorname*{Min}_{v\\in U_{a d}}\\left\\{\\int_{0}^{T}\\left[\\beta_{2}\\,y_{2,x}(t,u(t))-\\beta_{1}\\,y_{1,x}(t,u(t))-v(t)\\right]^{2}d t\\right\\},\n$$  \n\nsubject to the system (5.1.21)-(5.1.25) and (5.1.28), (5.1.29).  \n\nWe remark that here the optimal shape design problem could be stated directly as an optimal control problem, since we considered the one-dimensional case. This is not possible in higher dimensions of space.  \n\nThe above relationship between free boundary problems and shape optimization problems is reflected in the scientific literature by the use of similar methods. A survey along these lines may be found in the work of Hoffmann and Tiba [1995]. Several important techniques will be discussed below in this chapter.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Yes/No",
        "evidence_source": "text",
        "evidence_context": "We remark that here the optimal shape design problem could be stated directly as an optimal control problem, since we considered the one-dimensional case. This is not possible in higher dimensions of space.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/[undefined_series_for_scimag_]_-_[10.1007_978-0-387-27236-8]_-_libgen.li.pdf_268",
        "ID": "0571bb4d-3cd7-4d44-88f9-05859805c3f5",
        "questions": "What is the form of the differential equation governing the temperature in phase 1 within the interval $0<x<u(t)$?",
        "answers": "$y_{1,t}(t,x)=\\alpha_{1}y_{1,x x}(t,x)$",
        "context": "$$\n\\begin{array}{r l}{y_{1,t}(t,x)=\\alpha_{1}y_{1,x x}(t,x),\\quad}&{0<t<T,\\ 0<x<u(t),}\\\\ {y_{2,t}(t,x)=\\alpha_{2}y_{2,x x}(t,x),\\quad}&{0<t<T,\\ u(t)<x<b,}\\\\ {y_{1}(0,x)=\\varphi_{1}(x),\\ x\\in[0,u_{0}],\\quad}&{y_{2}(0,x)=\\varphi_{2}(x),\\ x\\in[u_{0},b],}\\\\ {y_{1}(t,0)=0,\\quad}&{y_{2}(t,b)=0,}\\\\ {y_{1}(t,u(t))=y_{2}(t,u(t))=0,\\quad}&{0\\leq t\\leq T,}\\\\ u_{t}(t)=\\beta_2\\,{y_{2,x}(t,u(t))-\\beta_{1}y_{1,x}(t,u(t)),\\quad}&{0<t\\leq T,}\\\\ {u(0)=u_{0}\\in[0,b]\\,.}\\end{array}\n$$  \n\nHere, $y_{1},\\;y_{2}$ represent the \u201ctemperatures\u201d in the two phases (solid and liquid, say), which coexist in the one-dimensional \"container\" $[0,b]$, separated by an interface located at time $t$ at the space point $x=u(t)$, $0\\leq t\\leq T$. The positive constants $\\alpha_{i},\\ \\beta_{i}$, $i=1,2$, are related to the physics of the problem (thermal conductivity, Stefan condition on the interface), and the initial temperature distributions $\\varphi_{i}$, $i=1,2$, in the phases and the initial location $u(0)$ of the interface are known.  \n\nNow let $v\\in L^{2}(0,T)$ be a \"control\" function. We replace the Stefan condition (5.1.26) and (5.1.27) by  \n\n$$\n\\begin{array}{l}{u^{\\prime}\\!\\left(t\\right)\\:=\\:v(t)\\quad\\mathrm{in~}[0,T],}\\\\ {u(0)\\:=\\:u_{0},}\\end{array}\n$$  \n\nwhere $v$ belongs to a prescribed set $U_{a d}$ that usually is chosen compact in $C[0,T]$. In this way, a class of \u201cadmissible free boundaries\u201d is defined. The original problem may then be reformulated as the optimal shape design problem  \n\n$$\n\\operatorname*{Min}_{v\\in U_{a d}}\\left\\{\\int_{0}^{T}\\left[\\beta_{2}\\,y_{2,x}(t,u(t))-\\beta_{1}\\,y_{1,x}(t,u(t))-v(t)\\right]^{2}d t\\right\\},\n$$  \n\nsubject to the system (5.1.21)-(5.1.25) and (5.1.28), (5.1.29).  \n\nWe remark that here the optimal shape design problem could be stated directly as an optimal control problem, since we considered the one-dimensional case. This is not possible in higher dimensions of space.  \n\nThe above relationship between free boundary problems and shape optimization problems is reflected in the scientific literature by the use of similar methods. A survey along these lines may be found in the work of Hoffmann and Tiba [1995]. Several important techniques will be discussed below in this chapter.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$y_{1,t}(t,x)=\\alpha_{1}y_{1,x x}(t,x),\\quad 0<t<T,\\ 0<x<u(t),$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/[undefined_series_for_scimag_]_-_[10.1007_978-0-387-27236-8]_-_libgen.li.pdf_268",
        "ID": "0573e598-b86a-49e7-8c0c-fe12f98647a9",
        "questions": "How is the initial temperature distribution in phase 1 described across the interval $[0,u_{0}]$?",
        "answers": "$y_{1}(0,x)=\\varphi_{1}(x)$",
        "context": "$$\n\\begin{array}{r l}{y_{1,t}(t,x)=\\alpha_{1}y_{1,x x}(t,x),\\quad}&{0<t<T,\\ 0<x<u(t),}\\\\ {y_{2,t}(t,x)=\\alpha_{2}y_{2,x x}(t,x),\\quad}&{0<t<T,\\ u(t)<x<b,}\\\\ {y_{1}(0,x)=\\varphi_{1}(x),\\ x\\in[0,u_{0}],\\quad}&{y_{2}(0,x)=\\varphi_{2}(x),\\ x\\in[u_{0},b],}\\\\ {y_{1}(t,0)=0,\\quad}&{y_{2}(t,b)=0,}\\\\ {y_{1}(t,u(t))=y_{2}(t,u(t))=0,\\quad}&{0\\leq t\\leq T,}\\\\ u_{t}(t)=\\beta_2\\,{y_{2,x}(t,u(t))-\\beta_{1}y_{1,x}(t,u(t)),\\quad}&{0<t\\leq T,}\\\\ {u(0)=u_{0}\\in[0,b]\\,.}\\end{array}\n$$  \n\nHere, $y_{1},\\;y_{2}$ represent the \u201ctemperatures\u201d in the two phases (solid and liquid, say), which coexist in the one-dimensional \"container\" $[0,b]$, separated by an interface located at time $t$ at the space point $x=u(t)$, $0\\leq t\\leq T$. The positive constants $\\alpha_{i},\\ \\beta_{i}$, $i=1,2$, are related to the physics of the problem (thermal conductivity, Stefan condition on the interface), and the initial temperature distributions $\\varphi_{i}$, $i=1,2$, in the phases and the initial location $u(0)$ of the interface are known.  \n\nNow let $v\\in L^{2}(0,T)$ be a \"control\" function. We replace the Stefan condition (5.1.26) and (5.1.27) by  \n\n$$\n\\begin{array}{l}{u^{\\prime}\\!\\left(t\\right)\\:=\\:v(t)\\quad\\mathrm{in~}[0,T],}\\\\ {u(0)\\:=\\:u_{0},}\\end{array}\n$$  \n\nwhere $v$ belongs to a prescribed set $U_{a d}$ that usually is chosen compact in $C[0,T]$. In this way, a class of \u201cadmissible free boundaries\u201d is defined. The original problem may then be reformulated as the optimal shape design problem  \n\n$$\n\\operatorname*{Min}_{v\\in U_{a d}}\\left\\{\\int_{0}^{T}\\left[\\beta_{2}\\,y_{2,x}(t,u(t))-\\beta_{1}\\,y_{1,x}(t,u(t))-v(t)\\right]^{2}d t\\right\\},\n$$  \n\nsubject to the system (5.1.21)-(5.1.25) and (5.1.28), (5.1.29).  \n\nWe remark that here the optimal shape design problem could be stated directly as an optimal control problem, since we considered the one-dimensional case. This is not possible in higher dimensions of space.  \n\nThe above relationship between free boundary problems and shape optimization problems is reflected in the scientific literature by the use of similar methods. A survey along these lines may be found in the work of Hoffmann and Tiba [1995]. Several important techniques will be discussed below in this chapter.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$y_{1}(0,x)=\\varphi_{1}(x),\\ x\\in[0,u_{0}],\\quad$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/[undefined_series_for_scimag_]_-_[10.1007_978-0-387-27236-8]_-_libgen.li.pdf_268",
        "ID": "057ff1be-e77b-4bcf-8741-79713063197a",
        "questions": "What is the integral expression for the optimal shape design problem when $v\\in U_{a d}$?",
        "answers": "$\\operatorname*{Min}_{v\\in U_{a d}}\\left\\{\\int_{0}^{T}\\left[\\beta_{2}\\,y_{2,x}(t,u(t))-\\beta_{1}\\,y_{1,x}(t,u(t))-v(t)\\right]^{2}d t\\right\\}$",
        "context": "$$\n\\begin{array}{r l}{y_{1,t}(t,x)=\\alpha_{1}y_{1,x x}(t,x),\\quad}&{0<t<T,\\ 0<x<u(t),}\\\\ {y_{2,t}(t,x)=\\alpha_{2}y_{2,x x}(t,x),\\quad}&{0<t<T,\\ u(t)<x<b,}\\\\ {y_{1}(0,x)=\\varphi_{1}(x),\\ x\\in[0,u_{0}],\\quad}&{y_{2}(0,x)=\\varphi_{2}(x),\\ x\\in[u_{0},b],}\\\\ {y_{1}(t,0)=0,\\quad}&{y_{2}(t,b)=0,}\\\\ {y_{1}(t,u(t))=y_{2}(t,u(t))=0,\\quad}&{0\\leq t\\leq T,}\\\\ u_{t}(t)=\\beta_2\\,{y_{2,x}(t,u(t))-\\beta_{1}y_{1,x}(t,u(t)),\\quad}&{0<t\\leq T,}\\\\ {u(0)=u_{0}\\in[0,b]\\,.}\\end{array}\n$$  \n\nHere, $y_{1},\\;y_{2}$ represent the \u201ctemperatures\u201d in the two phases (solid and liquid, say), which coexist in the one-dimensional \"container\" $[0,b]$, separated by an interface located at time $t$ at the space point $x=u(t)$, $0\\leq t\\leq T$. The positive constants $\\alpha_{i},\\ \\beta_{i}$, $i=1,2$, are related to the physics of the problem (thermal conductivity, Stefan condition on the interface), and the initial temperature distributions $\\varphi_{i}$, $i=1,2$, in the phases and the initial location $u(0)$ of the interface are known.  \n\nNow let $v\\in L^{2}(0,T)$ be a \"control\" function. We replace the Stefan condition (5.1.26) and (5.1.27) by  \n\n$$\n\\begin{array}{l}{u^{\\prime}\\!\\left(t\\right)\\:=\\:v(t)\\quad\\mathrm{in~}[0,T],}\\\\ {u(0)\\:=\\:u_{0},}\\end{array}\n$$  \n\nwhere $v$ belongs to a prescribed set $U_{a d}$ that usually is chosen compact in $C[0,T]$. In this way, a class of \u201cadmissible free boundaries\u201d is defined. The original problem may then be reformulated as the optimal shape design problem  \n\n$$\n\\operatorname*{Min}_{v\\in U_{a d}}\\left\\{\\int_{0}^{T}\\left[\\beta_{2}\\,y_{2,x}(t,u(t))-\\beta_{1}\\,y_{1,x}(t,u(t))-v(t)\\right]^{2}d t\\right\\},\n$$  \n\nsubject to the system (5.1.21)-(5.1.25) and (5.1.28), (5.1.29).  \n\nWe remark that here the optimal shape design problem could be stated directly as an optimal control problem, since we considered the one-dimensional case. This is not possible in higher dimensions of space.  \n\nThe above relationship between free boundary problems and shape optimization problems is reflected in the scientific literature by the use of similar methods. A survey along these lines may be found in the work of Hoffmann and Tiba [1995]. Several important techniques will be discussed below in this chapter.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$\\operatorname*{Min}_{v\\in U_{a d}}\\left\\{\\int_{0}^{T}\\left[\\beta_{2}\\,y_{2,x}(t,u(t))-\\beta_{1}\\,y_{1,x}(t,u(t))-v(t)\\right]^{2}d t\\right\\},$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/UTX_-_A_Course_in_Functional_Analysis_and_Measure_Theory.pdf_314",
        "ID": "0584d26c-f724-4a0c-8947-bf82b8ed3aa4",
        "questions": "What is the necessary and sufficient condition for a bounded subset D to be precompact in L_{1}[0,1]?",
        "answers": "It is equicontinuous in the mean.",
        "context": "Theorem 4 (Compactness criterion in $L_{1}[0,1]$). For a bounded subset $D\\subset L_{1}[0,1]$ to be pre compact it is necessary and sufficient that it is e qui continuous in the mean.\n\nProof. Suppose $D$ is pre compact. Since, by the lemma, $L_{\\tau}\\rightarrow I$ pointwise, one has that $L_{\\tau}\\rightarrow I$ uniformly on $D$. This uniform convergence is just another formulation of the requisite e qui continuity in the mean.\n\nNow the converse. Suppose the set $D$ is e qui continuous in the mean. Let us show that in this case the averaging operators $E_{n}$ introduced in Example 3 of Subsection 11.2.2 converge uniformly on $D$ to the unit operator. Since the sequence $(E_{n})$ is an approximate identity in $L_{1}[0,1]$, this will establish the pre compactness of $D$. Thus, given an arbitrary $\\varepsilon>0$, take a $1\\delta>0$ as in the definition of the e qui continuity in the mean: $\\begin{array}{r}{\\int_{0}^{1}|f(t+\\tau)-f(t)|d t<\\varepsilon}\\end{array}$ for all $f\\in D$ and all $\\tau\\in[-\\delta,\\delta]$. Then for any $n>1/\\delta$ and any $f\\in D$ we have\n\n$$\n\\|E_{n}(f)-f\\|=\\int_{0}^{1}{\\biggl|}\\sum_{k=1}^{n}n{\\int}_{\\Delta_{n,k}}f(x)d x\\mathbb{1}_{\\Delta_{n,k}}(t)-f(t){\\biggr|}d t\n$$\n\n$$\n=\\int_{0}^{1}\\left|\\sum_{k=1}^{n}n\\left(\\int_{\\varDelta_{n,k}}[f(x)-f(t)]d x\\right)\\mathbb{1}_{\\varDelta_{n,k}}(t)\\right|d t\n$$\n\n$$\n\\leqslant\\int_{0}^{1}\\sum_{k=1}^{n}n\\int_{\\varDelta_{n,k}}|f(x)-f(t)|d x\\mathbb{1}_{\\varDelta_{n,k}}(t)d t=n\\sum_{k=1}^{n}\\int_{\\varDelta_{n,k}}\\int_{\\varDelta_{n,k}}|f(x)-f(t)|d x d t.\n$$\n\nUsing the fact that all pairs $\\begin{array}{r}{(x,t)\\in\\bigcup_{k=1}^{n}\\varDelta_{n,k}\\times\\varDelta_{n,k}}\\end{array}$ obey the conditions $0\\leqslant t\\leqslant1$ $\\begin{array}{r}{t-\\frac{1}{n}\\leqslant x\\leqslant t+\\frac{1}{n}}\\end{array}$ $x\\to t+\\tau$ the estimate to\n\n$$\n\\|E_{n}(f)-f\\|\\leqslant\\int_{[-1/n,1/n]}\\,\\int_{0}^{1}|f(t+\\tau)-f(t)|d t d\\tau<2\\varepsilon.\n$$\n\n# Exercises\n\n1. In the definitions of continuity and equicontinuity in the mean, instead of $\\tau\\in [-\\delta,\\,\\delta]$ one can write $\\tau\\in[0,\\delta]$.\n\n2. In the space $\\ell_{\\infty}$, the operators $P_{n}$, acting as $P_{n}((x_{j})_{j=1}^{\\infty})=(x_{1},\\,.\\,.\\,.\\,,x_{n},0,0,.\\,.\\,.)$. do not form an approximate identity.\n\n3. The space $\\ell_{\\infty}$ admits no approximate identity (indeed, we note that in $\\ell_{\\infty}$ no convenient compactness criterion is known).\n\n4. Give an example of a precompact set $D\\subset\\ell_{p}$ that admits no joint majorant $z\\in\\ell_{p}$.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Theorem 4 (Compactness criterion in $L_{1}[0,1]$). For a bounded subset $D\\subset L_{1}[0,1]$ to be pre compact it is necessary and sufficient that it is equicontinuous in the mean.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTX_-_A_Course_in_Functional_Analysis_and_Measure_Theory.pdf_314",
        "ID": "0588d91d-fbe8-4a8e-a1cf-0d1d47b3df41",
        "questions": "Does the space $\\ell_{\\infty}$ admit an approximate identity?",
        "answers": "No",
        "context": "Theorem 4 (Compactness criterion in $L_{1}[0,1]$). For a bounded subset $D\\subset L_{1}[0,1]$ to be pre compact it is necessary and sufficient that it is e qui continuous in the mean.\n\nProof. Suppose $D$ is pre compact. Since, by the lemma, $L_{\\tau}\\rightarrow I$ pointwise, one has that $L_{\\tau}\\rightarrow I$ uniformly on $D$. This uniform convergence is just another formulation of the requisite e qui continuity in the mean.\n\nNow the converse. Suppose the set $D$ is e qui continuous in the mean. Let us show that in this case the averaging operators $E_{n}$ introduced in Example 3 of Subsection 11.2.2 converge uniformly on $D$ to the unit operator. Since the sequence $(E_{n})$ is an approximate identity in $L_{1}[0,1]$, this will establish the pre compactness of $D$. Thus, given an arbitrary $\\varepsilon>0$, take a $1\\delta>0$ as in the definition of the e qui continuity in the mean: $\\begin{array}{r}{\\int_{0}^{1}|f(t+\\tau)-f(t)|d t<\\varepsilon}\\end{array}$ for all $f\\in D$ and all $\\tau\\in[-\\delta,\\delta]$. Then for any $n>1/\\delta$ and any $f\\in D$ we have\n\n$$\n\\|E_{n}(f)-f\\|=\\int_{0}^{1}{\\biggl|}\\sum_{k=1}^{n}n{\\int}_{\\Delta_{n,k}}f(x)d x\\mathbb{1}_{\\Delta_{n,k}}(t)-f(t){\\biggr|}d t\n$$\n\n$$\n=\\int_{0}^{1}\\left|\\sum_{k=1}^{n}n\\left(\\int_{\\varDelta_{n,k}}[f(x)-f(t)]d x\\right)\\mathbb{1}_{\\varDelta_{n,k}}(t)\\right|d t\n$$\n\n$$\n\\leqslant\\int_{0}^{1}\\sum_{k=1}^{n}n\\int_{\\varDelta_{n,k}}|f(x)-f(t)|d x\\mathbb{1}_{\\varDelta_{n,k}}(t)d t=n\\sum_{k=1}^{n}\\int_{\\varDelta_{n,k}}\\int_{\\varDelta_{n,k}}|f(x)-f(t)|d x d t.\n$$\n\nUsing the fact that all pairs $\\begin{array}{r}{(x,t)\\in\\bigcup_{k=1}^{n}\\varDelta_{n,k}\\times\\varDelta_{n,k}}\\end{array}$ obey the conditions $0\\leqslant t\\leqslant1$ $\\begin{array}{r}{t-\\frac{1}{n}\\leqslant x\\leqslant t+\\frac{1}{n}}\\end{array}$ $x\\to t+\\tau$ the estimate to\n\n$$\n\\|E_{n}(f)-f\\|\\leqslant\\int_{[-1/n,1/n]}\\,\\int_{0}^{1}|f(t+\\tau)-f(t)|d t d\\tau<2\\varepsilon.\n$$\n\n# Exercises\n\n1. In the definitions of continuity and equicontinuity in the mean, instead of $\\tau\\in [-\\delta,\\,\\delta]$ one can write $\\tau\\in[0,\\delta]$.\n\n2. In the space $\\ell_{\\infty}$, the operators $P_{n}$, acting as $P_{n}((x_{j})_{j=1}^{\\infty})=(x_{1},\\,.\\,.\\,.\\,,x_{n},0,0,.\\,.\\,.)$. do not form an approximate identity.\n\n3. The space $\\ell_{\\infty}$ admits no approximate identity (indeed, we note that in $\\ell_{\\infty}$ no convenient compactness criterion is known).\n\n4. Give an example of a precompact set $D\\subset\\ell_{p}$ that admits no joint majorant $z\\in\\ell_{p}$.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Yes/No",
        "evidence_source": "text",
        "evidence_context": "The space \\ell_{\\infty}$ admits no approximate identity (indeed, we note that in \\ell_{\\infty}$ no convenient compactness criterion is known).",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTX_-_A_Course_in_Functional_Analysis_and_Measure_Theory.pdf_314",
        "ID": "058c4c3d-47be-46e8-95bc-077c94ebdc26",
        "questions": "If a set D is precompact in L_{1}[0,1], how does L_{\\tau} converge on D?",
        "answers": "Uniformly",
        "context": "Theorem 4 (Compactness criterion in $L_{1}[0,1]$). For a bounded subset $D\\subset L_{1}[0,1]$ to be pre compact it is necessary and sufficient that it is e qui continuous in the mean.\n\nProof. Suppose $D$ is pre compact. Since, by the lemma, $L_{\\tau}\\rightarrow I$ pointwise, one has that $L_{\\tau}\\rightarrow I$ uniformly on $D$. This uniform convergence is just another formulation of the requisite e qui continuity in the mean.\n\nNow the converse. Suppose the set $D$ is e qui continuous in the mean. Let us show that in this case the averaging operators $E_{n}$ introduced in Example 3 of Subsection 11.2.2 converge uniformly on $D$ to the unit operator. Since the sequence $(E_{n})$ is an approximate identity in $L_{1}[0,1]$, this will establish the pre compactness of $D$. Thus, given an arbitrary $\\varepsilon>0$, take a $1\\delta>0$ as in the definition of the e qui continuity in the mean: $\\begin{array}{r}{\\int_{0}^{1}|f(t+\\tau)-f(t)|d t<\\varepsilon}\\end{array}$ for all $f\\in D$ and all $\\tau\\in[-\\delta,\\delta]$. Then for any $n>1/\\delta$ and any $f\\in D$ we have\n\n$$\n\\|E_{n}(f)-f\\|=\\int_{0}^{1}{\\biggl|}\\sum_{k=1}^{n}n{\\int}_{\\Delta_{n,k}}f(x)d x\\mathbb{1}_{\\Delta_{n,k}}(t)-f(t){\\biggr|}d t\n$$\n\n$$\n=\\int_{0}^{1}\\left|\\sum_{k=1}^{n}n\\left(\\int_{\\varDelta_{n,k}}[f(x)-f(t)]d x\\right)\\mathbb{1}_{\\varDelta_{n,k}}(t)\\right|d t\n$$\n\n$$\n\\leqslant\\int_{0}^{1}\\sum_{k=1}^{n}n\\int_{\\varDelta_{n,k}}|f(x)-f(t)|d x\\mathbb{1}_{\\varDelta_{n,k}}(t)d t=n\\sum_{k=1}^{n}\\int_{\\varDelta_{n,k}}\\int_{\\varDelta_{n,k}}|f(x)-f(t)|d x d t.\n$$\n\nUsing the fact that all pairs $\\begin{array}{r}{(x,t)\\in\\bigcup_{k=1}^{n}\\varDelta_{n,k}\\times\\varDelta_{n,k}}\\end{array}$ obey the conditions $0\\leqslant t\\leqslant1$ $\\begin{array}{r}{t-\\frac{1}{n}\\leqslant x\\leqslant t+\\frac{1}{n}}\\end{array}$ $x\\to t+\\tau$ the estimate to\n\n$$\n\\|E_{n}(f)-f\\|\\leqslant\\int_{[-1/n,1/n]}\\,\\int_{0}^{1}|f(t+\\tau)-f(t)|d t d\\tau<2\\varepsilon.\n$$\n\n# Exercises\n\n1. In the definitions of continuity and equicontinuity in the mean, instead of $\\tau\\in [-\\delta,\\,\\delta]$ one can write $\\tau\\in[0,\\delta]$.\n\n2. In the space $\\ell_{\\infty}$, the operators $P_{n}$, acting as $P_{n}((x_{j})_{j=1}^{\\infty})=(x_{1},\\,.\\,.\\,.\\,,x_{n},0,0,.\\,.\\,.)$. do not form an approximate identity.\n\n3. The space $\\ell_{\\infty}$ admits no approximate identity (indeed, we note that in $\\ell_{\\infty}$ no convenient compactness criterion is known).\n\n4. Give an example of a precompact set $D\\subset\\ell_{p}$ that admits no joint majorant $z\\in\\ell_{p}$.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Since, by the lemma, $L_{\\tau}\\rightarrow I$ pointwise, one has that $L_{\\tau}\\rightarrow I$ uniformly on $D$. This uniform convergence is just another formulation of the requisite equicontinuity in the mean.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTX_-_A_Course_in_Functional_Analysis_and_Measure_Theory.pdf_314",
        "ID": "0597aab6-14d3-4dbc-a0ac-f4c9658de17e",
        "questions": "What inequality must the norm of the difference between the averaging operator $E_n$ applied to a function $f$ in the set $D$ and $f$ itself satisfy, given the equicontinuity condition in the mean?",
        "answers": "\\|E_{n}(f)-f\\| \\leqslant \\int_{[-1/n,1/n]}\\,\\int_{0}^{1}|f(t+\\tau)-f(t)|d t d\\tau<2\\varepsilon.",
        "context": "Theorem 4 (Compactness criterion in $L_{1}[0,1]$). For a bounded subset $D\\subset L_{1}[0,1]$ to be pre compact it is necessary and sufficient that it is e qui continuous in the mean.\n\nProof. Suppose $D$ is pre compact. Since, by the lemma, $L_{\\tau}\\rightarrow I$ pointwise, one has that $L_{\\tau}\\rightarrow I$ uniformly on $D$. This uniform convergence is just another formulation of the requisite e qui continuity in the mean.\n\nNow the converse. Suppose the set $D$ is e qui continuous in the mean. Let us show that in this case the averaging operators $E_{n}$ introduced in Example 3 of Subsection 11.2.2 converge uniformly on $D$ to the unit operator. Since the sequence $(E_{n})$ is an approximate identity in $L_{1}[0,1]$, this will establish the pre compactness of $D$. Thus, given an arbitrary $\\varepsilon>0$, take a $1\\delta>0$ as in the definition of the e qui continuity in the mean: $\\begin{array}{r}{\\int_{0}^{1}|f(t+\\tau)-f(t)|d t<\\varepsilon}\\end{array}$ for all $f\\in D$ and all $\\tau\\in[-\\delta,\\delta]$. Then for any $n>1/\\delta$ and any $f\\in D$ we have\n\n$$\n\\|E_{n}(f)-f\\|=\\int_{0}^{1}{\\biggl|}\\sum_{k=1}^{n}n{\\int}_{\\Delta_{n,k}}f(x)d x\\mathbb{1}_{\\Delta_{n,k}}(t)-f(t){\\biggr|}d t\n$$\n\n$$\n=\\int_{0}^{1}\\left|\\sum_{k=1}^{n}n\\left(\\int_{\\varDelta_{n,k}}[f(x)-f(t)]d x\\right)\\mathbb{1}_{\\varDelta_{n,k}}(t)\\right|d t\n$$\n\n$$\n\\leqslant\\int_{0}^{1}\\sum_{k=1}^{n}n\\int_{\\varDelta_{n,k}}|f(x)-f(t)|d x\\mathbb{1}_{\\varDelta_{n,k}}(t)d t=n\\sum_{k=1}^{n}\\int_{\\varDelta_{n,k}}\\int_{\\varDelta_{n,k}}|f(x)-f(t)|d x d t.\n$$\n\nUsing the fact that all pairs $\\begin{array}{r}{(x,t)\\in\\bigcup_{k=1}^{n}\\varDelta_{n,k}\\times\\varDelta_{n,k}}\\end{array}$ obey the conditions $0\\leqslant t\\leqslant1$ $\\begin{array}{r}{t-\\frac{1}{n}\\leqslant x\\leqslant t+\\frac{1}{n}}\\end{array}$ $x\\to t+\\tau$ the estimate to\n\n$$\n\\|E_{n}(f)-f\\|\\leqslant\\int_{[-1/n,1/n]}\\,\\int_{0}^{1}|f(t+\\tau)-f(t)|d t d\\tau<2\\varepsilon.\n$$\n\n# Exercises\n\n1. In the definitions of continuity and equicontinuity in the mean, instead of $\\tau\\in [-\\delta,\\,\\delta]$ one can write $\\tau\\in[0,\\delta]$.\n\n2. In the space $\\ell_{\\infty}$, the operators $P_{n}$, acting as $P_{n}((x_{j})_{j=1}^{\\infty})=(x_{1},\\,.\\,.\\,.\\,,x_{n},0,0,.\\,.\\,.)$. do not form an approximate identity.\n\n3. The space $\\ell_{\\infty}$ admits no approximate identity (indeed, we note that in $\\ell_{\\infty}$ no convenient compactness criterion is known).\n\n4. Give an example of a precompact set $D\\subset\\ell_{p}$ that admits no joint majorant $z\\in\\ell_{p}$.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Inequality",
        "evidence_source": "equation",
        "evidence_context": "\\|E_{n}(f)-f\\| \\leqslant \\int_{[-1/n,1/n]}\\,\\int_{0}^{1}|f(t+\\tau)-f(t)|d t d\\tau<2\\varepsilon.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/UTX_-_A_Course_in_Functional_Analysis_and_Measure_Theory.pdf_314",
        "ID": "05a3f71f-ab8c-4b93-a7ff-2b2894f55a32",
        "questions": "For any function $f$ in the set $D$ and a limit $1/\\delta$, what is the comparative form of the integral expression involving notations $\u000barDelta_{n,k}$?",
        "answers": "\\int_{0}^{1}\\sum_{k=1}^{n}n\\int_{\\varDelta_{n,k}}|f(x)-f(t)|d x\\mathbb{1}_{\\varDelta_{n,k}}(t)d t=n\\sum_{k=1}^{n}\\int_{\\varDelta_{n,k}}\\int_{\\varDelta_{n,k}}|f(x)-f(t)|d x d t.",
        "context": "Theorem 4 (Compactness criterion in $L_{1}[0,1]$). For a bounded subset $D\\subset L_{1}[0,1]$ to be pre compact it is necessary and sufficient that it is e qui continuous in the mean.\n\nProof. Suppose $D$ is pre compact. Since, by the lemma, $L_{\\tau}\\rightarrow I$ pointwise, one has that $L_{\\tau}\\rightarrow I$ uniformly on $D$. This uniform convergence is just another formulation of the requisite e qui continuity in the mean.\n\nNow the converse. Suppose the set $D$ is e qui continuous in the mean. Let us show that in this case the averaging operators $E_{n}$ introduced in Example 3 of Subsection 11.2.2 converge uniformly on $D$ to the unit operator. Since the sequence $(E_{n})$ is an approximate identity in $L_{1}[0,1]$, this will establish the pre compactness of $D$. Thus, given an arbitrary $\\varepsilon>0$, take a $1\\delta>0$ as in the definition of the e qui continuity in the mean: $\\begin{array}{r}{\\int_{0}^{1}|f(t+\\tau)-f(t)|d t<\\varepsilon}\\end{array}$ for all $f\\in D$ and all $\\tau\\in[-\\delta,\\delta]$. Then for any $n>1/\\delta$ and any $f\\in D$ we have\n\n$$\n\\|E_{n}(f)-f\\|=\\int_{0}^{1}{\\biggl|}\\sum_{k=1}^{n}n{\\int}_{\\Delta_{n,k}}f(x)d x\\mathbb{1}_{\\Delta_{n,k}}(t)-f(t){\\biggr|}d t\n$$\n\n$$\n=\\int_{0}^{1}\\left|\\sum_{k=1}^{n}n\\left(\\int_{\\varDelta_{n,k}}[f(x)-f(t)]d x\\right)\\mathbb{1}_{\\varDelta_{n,k}}(t)\\right|d t\n$$\n\n$$\n\\leqslant\\int_{0}^{1}\\sum_{k=1}^{n}n\\int_{\\varDelta_{n,k}}|f(x)-f(t)|d x\\mathbb{1}_{\\varDelta_{n,k}}(t)d t=n\\sum_{k=1}^{n}\\int_{\\varDelta_{n,k}}\\int_{\\varDelta_{n,k}}|f(x)-f(t)|d x d t.\n$$\n\nUsing the fact that all pairs $\\begin{array}{r}{(x,t)\\in\\bigcup_{k=1}^{n}\\varDelta_{n,k}\\times\\varDelta_{n,k}}\\end{array}$ obey the conditions $0\\leqslant t\\leqslant1$ $\\begin{array}{r}{t-\\frac{1}{n}\\leqslant x\\leqslant t+\\frac{1}{n}}\\end{array}$ $x\\to t+\\tau$ the estimate to\n\n$$\n\\|E_{n}(f)-f\\|\\leqslant\\int_{[-1/n,1/n]}\\,\\int_{0}^{1}|f(t+\\tau)-f(t)|d t d\\tau<2\\varepsilon.\n$$\n\n# Exercises\n\n1. In the definitions of continuity and equicontinuity in the mean, instead of $\\tau\\in [-\\delta,\\,\\delta]$ one can write $\\tau\\in[0,\\delta]$.\n\n2. In the space $\\ell_{\\infty}$, the operators $P_{n}$, acting as $P_{n}((x_{j})_{j=1}^{\\infty})=(x_{1},\\,.\\,.\\,.\\,,x_{n},0,0,.\\,.\\,.)$. do not form an approximate identity.\n\n3. The space $\\ell_{\\infty}$ admits no approximate identity (indeed, we note that in $\\ell_{\\infty}$ no convenient compactness criterion is known).\n\n4. Give an example of a precompact set $D\\subset\\ell_{p}$ that admits no joint majorant $z\\in\\ell_{p}$.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Integral Expression",
        "evidence_source": "equation",
        "evidence_context": "\\int_{0}^{1}\\sum_{k=1}^{n}n\\int_{\\varDelta_{n,k}}|f(x)-f(t)|d x\\mathbb{1}_{\\varDelta_{n,k}}(t)d t=n\\sum_{k=1}^{n}\\int_{\\varDelta_{n,k}}\\int_{\\varDelta_{n,k}}|f(x)-f(t)|d x d t.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/UTX_-_A_Course_in_Functional_Analysis_and_Measure_Theory.pdf_314",
        "ID": "05b827dc-f75f-4cd5-9516-c1a645d3fa2c",
        "questions": "What is the equation that shows the norm of $E_n(f) - f$ expressed as an integral involving potential differences within defined intervals $\\Delta_{n,k}$?",
        "answers": "\\|E_{n}(f)-f\\|=\\int_{0}^{1}{\\biggl|}\\sum_{k=1}^{n}n{\\int}_{\\Delta_{n,k}}f(x)d x\\mathbb{1}_{\\Delta_{n,k}}(t)-f(t){\\biggr|}d t.",
        "context": "Theorem 4 (Compactness criterion in $L_{1}[0,1]$). For a bounded subset $D\\subset L_{1}[0,1]$ to be pre compact it is necessary and sufficient that it is e qui continuous in the mean.\n\nProof. Suppose $D$ is pre compact. Since, by the lemma, $L_{\\tau}\\rightarrow I$ pointwise, one has that $L_{\\tau}\\rightarrow I$ uniformly on $D$. This uniform convergence is just another formulation of the requisite e qui continuity in the mean.\n\nNow the converse. Suppose the set $D$ is e qui continuous in the mean. Let us show that in this case the averaging operators $E_{n}$ introduced in Example 3 of Subsection 11.2.2 converge uniformly on $D$ to the unit operator. Since the sequence $(E_{n})$ is an approximate identity in $L_{1}[0,1]$, this will establish the pre compactness of $D$. Thus, given an arbitrary $\\varepsilon>0$, take a $1\\delta>0$ as in the definition of the e qui continuity in the mean: $\\begin{array}{r}{\\int_{0}^{1}|f(t+\\tau)-f(t)|d t<\\varepsilon}\\end{array}$ for all $f\\in D$ and all $\\tau\\in[-\\delta,\\delta]$. Then for any $n>1/\\delta$ and any $f\\in D$ we have\n\n$$\n\\|E_{n}(f)-f\\|=\\int_{0}^{1}{\\biggl|}\\sum_{k=1}^{n}n{\\int}_{\\Delta_{n,k}}f(x)d x\\mathbb{1}_{\\Delta_{n,k}}(t)-f(t){\\biggr|}d t\n$$\n\n$$\n=\\int_{0}^{1}\\left|\\sum_{k=1}^{n}n\\left(\\int_{\\varDelta_{n,k}}[f(x)-f(t)]d x\\right)\\mathbb{1}_{\\varDelta_{n,k}}(t)\\right|d t\n$$\n\n$$\n\\leqslant\\int_{0}^{1}\\sum_{k=1}^{n}n\\int_{\\varDelta_{n,k}}|f(x)-f(t)|d x\\mathbb{1}_{\\varDelta_{n,k}}(t)d t=n\\sum_{k=1}^{n}\\int_{\\varDelta_{n,k}}\\int_{\\varDelta_{n,k}}|f(x)-f(t)|d x d t.\n$$\n\nUsing the fact that all pairs $\\begin{array}{r}{(x,t)\\in\\bigcup_{k=1}^{n}\\varDelta_{n,k}\\times\\varDelta_{n,k}}\\end{array}$ obey the conditions $0\\leqslant t\\leqslant1$ $\\begin{array}{r}{t-\\frac{1}{n}\\leqslant x\\leqslant t+\\frac{1}{n}}\\end{array}$ $x\\to t+\\tau$ the estimate to\n\n$$\n\\|E_{n}(f)-f\\|\\leqslant\\int_{[-1/n,1/n]}\\,\\int_{0}^{1}|f(t+\\tau)-f(t)|d t d\\tau<2\\varepsilon.\n$$\n\n# Exercises\n\n1. In the definitions of continuity and equicontinuity in the mean, instead of $\\tau\\in [-\\delta,\\,\\delta]$ one can write $\\tau\\in[0,\\delta]$.\n\n2. In the space $\\ell_{\\infty}$, the operators $P_{n}$, acting as $P_{n}((x_{j})_{j=1}^{\\infty})=(x_{1},\\,.\\,.\\,.\\,,x_{n},0,0,.\\,.\\,.)$. do not form an approximate identity.\n\n3. The space $\\ell_{\\infty}$ admits no approximate identity (indeed, we note that in $\\ell_{\\infty}$ no convenient compactness criterion is known).\n\n4. Give an example of a precompact set $D\\subset\\ell_{p}$ that admits no joint majorant $z\\in\\ell_{p}$.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Integral Equality",
        "evidence_source": "equation",
        "evidence_context": "\\|E_{n}(f)-f\\|=\\int_{0}^{1}{\\biggl|}\\sum_{k=1}^{n}n{\\int}_{\\Delta_{n,k}}f(x)d x\\mathbb{1}_{\\Delta_{n,k}}(t)-f(t){\\biggr|}d t.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/GTM25-Real_and_Abstract_Analysis1975.pdf_362",
        "ID": "05c0826a-c67c-4d5a-8504-74442a6188b2",
        "questions": "What is the result of the linear mapping $T(g)$ in the theorem (20.20) for a decomposable measure space $(X,{\\mathcal{A}},\\mu)$?",
        "answers": "$L_{\\bar{g}}$",
        "context": "and (12.30) show that  \n\n$$\n\\begin{array}{r l}&{L\\left(f\\right)=\\operatorname*{lim}_{p\\rightarrow\\infty}\\,L\\left(\\sum^{p}_{n-1}\\,f\\xi_{F_{n}}\\right)=\\operatorname*{lim}_{p\\rightarrow\\infty}\\sum^{p}_{n-1}\\,L\\left(f\\xi_{F_{n}}\\right)}\\\\ &{\\quad\\quad=\\operatorname*{lim}_{p\\rightarrow\\infty}\\sum^{p}_{n-1}\\int_{F_n}/\\bar{g}\\;d\\mu=\\operatorname*{lim}_{p\\rightarrow\\infty}\\int_{X}{\\sum^{p}_{n-1}}\\,f\\xi_{F_{n}}\\bar{g}\\,d\\mu}\\\\ &{\\quad\\quad=\\int_{X} f\\bar{g}\\;d\\mu\\;.\\quad}\\end{array}\n$$  \n\n(20.20) Theorem. Let $(X,{\\mathcal{A}},\\mu)$ be a decomposable measure space (19.25). Then the mapping $T$ defined by  \n\n$$\nT(g)=L_{\\bar{g}}\n$$  \n\n[see (20.16)] is a norm-preserving linear mapping of $\\mathfrak{L}_{\\infty}$ onto the conjugate space $\\mathfrak{L}^{\\ast}_{1}$. Thus, as Banach spaces, $\\mathfrak{L}_{\\infty}$ and $\\mathfrak{L}_{1}^{\\ast}$ are isomorphic.  \n\nProof. The fact that $T$ is a norm-preserving mapping from $\\mathfrak{L}_{\\infty}$ into $\\mathfrak{L}_{1}^{\\ast}$ is (20.16). It follows from (20.19) that $T$ is onto $\\mathfrak{L}_{1}^{\\ast}$. It is trivial that $T$ is linear. Since $T$ is both linear and norm-preserving, it is one-to-one.\n\n(20.21) Note. As we have shown in (20.17), the conclusion in (20.20) fails for some nondecomposable measure spaces. However, J. Schwartz has found a representation of $\\mathfrak{L}_{1}^{\\ast}(X,{\\mathcal{A}},\\mu)$ for arbitrary $(X,{\\mathcal{A}},\\mu)$ [Proc. Amer. Math. Soc. 2 (1951), 270-275], to which the interested reader is referred.  \n\n(20.22) Exercise. Let $X$ be a locally compact Hausdorff space and let $t$ be an outer measure on $\\mathcal{P}(X)$ as in $\\S\\,9$. Prove that the definitions of local $t$ -nullity given in (9.29) and in (20.11) are equivalent.  \n\n(20.23) Exercise. Let $(X,{\\mathcal{A}},\\mu)$ be a degenerate measure space such that $\\mu\\left(X\\right)=\\infty$ [see (10.3) for the definition]. Is this measure space decomposable? Find $\\mathfrak{L}_{1},\\mathfrak{L}_{1}^{\\ast}$, and $\\mathfrak{L}_{\\infty}$ explicitly for this measure space.  \n\n(20.24) Exercise. Let $(X,{\\mathcal{A}},\\mu)$ be any measure space and let $f\\in\\mathfrak{L}_{1}(X,\\mathcal{A},\\mu)$. Define $L$ on $\\mathfrak{L}_{\\infty}(X,{\\mathcal{A}},\\mu)$ by  \n\n$$\n\\begin{array}{r}{L\\left(g\\right)=\\int_{X} g\\bar{f}d\\mu}\\;.\\end{array}\n$$  \n\nProve that $L\\in\\mathfrak{L}_{\\infty}^{*}$ and that $\\|L\\|=\\|f\\|_{1}$.  \n\n(20.25) Exercise. Prove that $\\mathfrak{L}_{1}([0,\\,1])$ [with Lebesgue measure] is not reflexive by showing that not every $L\\in\\mathfrak{L}_{\\infty}^{*}([0,\\,1])$ has the form described in (20.24). [Hint. Use the Hahn-Banach theorem to produce an $L\\neq0$ such that $L\\left(g\\right)=0$ for all $g\\in\\mathfrak{L}_{\\infty}$ for which $g$ is essentially continuous, i.e., $\\|g\\,-\\,h\\|_{\\infty}{=0}$ for some $h\\in\\mathfrak{C}([0,\\,1]).$  \n\n(20.26) Exercise. (a) Prove that $\\mathfrak{L}_{\\infty}([0,\\,1])$ is not separable.  \n\n(b) Find necessary and sufficient conditions on a measure space that its $\\mathfrak{L}_{\\infty}$ space be separable. [Do not forget (20.23).]  \n\nHaving found the conjugate space of $\\mathfrak{L}_{p}(X,{\\mathcal{A}},\\mu)$ for $1<\\phi<\\infty$ and any measure space $(X,{\\mathcal{A}},\\mu)$, and of $\\mathfrak{L}_{1}(X,{\\mathcal{A}},\\mu)$ for a large class of",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Then the mapping $T$ defined by $T(g)=L_{\\bar{g}}$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM25-Real_and_Abstract_Analysis1975.pdf_362",
        "ID": "05d5859b-111e-4105-90fb-1596b3deed9f",
        "questions": "In the exercise (20.24), what do we need to prove about $L$ on $\\mathfrak{L}_{\\infty}(X, {\\mathcal{A}}, \\mu)$ if $f\\in\\mathfrak{L}_{1}(X, {\\mathcal{A}}, \\mu)$?",
        "answers": "We need to prove that $L\\in \\mathfrak{L}_{\\infty}^{*}$ and that $\\|L\\|=\\|f\\|_{1}$.",
        "context": "and (12.30) show that  \n\n$$\n\\begin{array}{r l}&{L\\left(f\\right)=\\operatorname*{lim}_{p\\rightarrow\\infty}\\,L\\left(\\sum^{p}_{n-1}\\,f\\xi_{F_{n}}\\right)=\\operatorname*{lim}_{p\\rightarrow\\infty}\\sum^{p}_{n-1}\\,L\\left(f\\xi_{F_{n}}\\right)}\\\\ &{\\quad\\quad=\\operatorname*{lim}_{p\\rightarrow\\infty}\\sum^{p}_{n-1}\\int_{F_n}/\\bar{g}\\;d\\mu=\\operatorname*{lim}_{p\\rightarrow\\infty}\\int_{X}{\\sum^{p}_{n-1}}\\,f\\xi_{F_{n}}\\bar{g}\\,d\\mu}\\\\ &{\\quad\\quad=\\int_{X} f\\bar{g}\\;d\\mu\\;.\\quad}\\end{array}\n$$  \n\n(20.20) Theorem. Let $(X,{\\mathcal{A}},\\mu)$ be a decomposable measure space (19.25). Then the mapping $T$ defined by  \n\n$$\nT(g)=L_{\\bar{g}}\n$$  \n\n[see (20.16)] is a norm-preserving linear mapping of $\\mathfrak{L}_{\\infty}$ onto the conjugate space $\\mathfrak{L}^{\\ast}_{1}$. Thus, as Banach spaces, $\\mathfrak{L}_{\\infty}$ and $\\mathfrak{L}_{1}^{\\ast}$ are isomorphic.  \n\nProof. The fact that $T$ is a norm-preserving mapping from $\\mathfrak{L}_{\\infty}$ into $\\mathfrak{L}_{1}^{\\ast}$ is (20.16). It follows from (20.19) that $T$ is onto $\\mathfrak{L}_{1}^{\\ast}$. It is trivial that $T$ is linear. Since $T$ is both linear and norm-preserving, it is one-to-one.\n\n(20.21) Note. As we have shown in (20.17), the conclusion in (20.20) fails for some nondecomposable measure spaces. However, J. Schwartz has found a representation of $\\mathfrak{L}_{1}^{\\ast}(X,{\\mathcal{A}},\\mu)$ for arbitrary $(X,{\\mathcal{A}},\\mu)$ [Proc. Amer. Math. Soc. 2 (1951), 270-275], to which the interested reader is referred.  \n\n(20.22) Exercise. Let $X$ be a locally compact Hausdorff space and let $t$ be an outer measure on $\\mathcal{P}(X)$ as in $\\S\\,9$. Prove that the definitions of local $t$ -nullity given in (9.29) and in (20.11) are equivalent.  \n\n(20.23) Exercise. Let $(X,{\\mathcal{A}},\\mu)$ be a degenerate measure space such that $\\mu\\left(X\\right)=\\infty$ [see (10.3) for the definition]. Is this measure space decomposable? Find $\\mathfrak{L}_{1},\\mathfrak{L}_{1}^{\\ast}$, and $\\mathfrak{L}_{\\infty}$ explicitly for this measure space.  \n\n(20.24) Exercise. Let $(X,{\\mathcal{A}},\\mu)$ be any measure space and let $f\\in\\mathfrak{L}_{1}(X,\\mathcal{A},\\mu)$. Define $L$ on $\\mathfrak{L}_{\\infty}(X,{\\mathcal{A}},\\mu)$ by  \n\n$$\n\\begin{array}{r}{L\\left(g\\right)=\\int_{X} g\\bar{f}d\\mu}\\;.\\end{array}\n$$  \n\nProve that $L\\in\\mathfrak{L}_{\\infty}^{*}$ and that $\\|L\\|=\\|f\\|_{1}$.  \n\n(20.25) Exercise. Prove that $\\mathfrak{L}_{1}([0,\\,1])$ [with Lebesgue measure] is not reflexive by showing that not every $L\\in\\mathfrak{L}_{\\infty}^{*}([0,\\,1])$ has the form described in (20.24). [Hint. Use the Hahn-Banach theorem to produce an $L\\neq0$ such that $L\\left(g\\right)=0$ for all $g\\in\\mathfrak{L}_{\\infty}$ for which $g$ is essentially continuous, i.e., $\\|g\\,-\\,h\\|_{\\infty}{=0}$ for some $h\\in\\mathfrak{C}([0,\\,1]).$  \n\n(20.26) Exercise. (a) Prove that $\\mathfrak{L}_{\\infty}([0,\\,1])$ is not separable.  \n\n(b) Find necessary and sufficient conditions on a measure space that its $\\mathfrak{L}_{\\infty}$ space be separable. [Do not forget (20.23).]  \n\nHaving found the conjugate space of $\\mathfrak{L}_{p}(X,{\\mathcal{A}},\\mu)$ for $1<\\phi<\\infty$ and any measure space $(X,{\\mathcal{A}},\\mu)$, and of $\\mathfrak{L}_{1}(X,{\\mathcal{A}},\\mu)$ for a large class of",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Prove that $L\\in \\mathfrak{L}_{\\infty}^{*}$ and that $\\|L\\|=\\|f\\|_{1}$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM25-Real_and_Abstract_Analysis1975.pdf_362",
        "ID": "05dd1ef0-0806-48c9-8967-49fbb2e02961",
        "questions": "According to the note (20.21), in what kind of measure spaces does the conclusion of theorem (20.20) fail, and who provided an alternate representation of $\\mathfrak{L}_{1}^{\\ast}(X, {\\mathcal{A}}, \\mu)$?",
        "answers": "The conclusion in (20.20) fails for some nondecomposable measure spaces. J. Schwartz found a representation of $\\mathfrak{L}_{1}^{\\ast}(X, {\\mathcal{A}}, \\mu)$ for arbitrary $(X, {\\mathcal{A}}, \\mu)$.",
        "context": "and (12.30) show that  \n\n$$\n\\begin{array}{r l}&{L\\left(f\\right)=\\operatorname*{lim}_{p\\rightarrow\\infty}\\,L\\left(\\sum^{p}_{n-1}\\,f\\xi_{F_{n}}\\right)=\\operatorname*{lim}_{p\\rightarrow\\infty}\\sum^{p}_{n-1}\\,L\\left(f\\xi_{F_{n}}\\right)}\\\\ &{\\quad\\quad=\\operatorname*{lim}_{p\\rightarrow\\infty}\\sum^{p}_{n-1}\\int_{F_n}/\\bar{g}\\;d\\mu=\\operatorname*{lim}_{p\\rightarrow\\infty}\\int_{X}{\\sum^{p}_{n-1}}\\,f\\xi_{F_{n}}\\bar{g}\\,d\\mu}\\\\ &{\\quad\\quad=\\int_{X} f\\bar{g}\\;d\\mu\\;.\\quad}\\end{array}\n$$  \n\n(20.20) Theorem. Let $(X,{\\mathcal{A}},\\mu)$ be a decomposable measure space (19.25). Then the mapping $T$ defined by  \n\n$$\nT(g)=L_{\\bar{g}}\n$$  \n\n[see (20.16)] is a norm-preserving linear mapping of $\\mathfrak{L}_{\\infty}$ onto the conjugate space $\\mathfrak{L}^{\\ast}_{1}$. Thus, as Banach spaces, $\\mathfrak{L}_{\\infty}$ and $\\mathfrak{L}_{1}^{\\ast}$ are isomorphic.  \n\nProof. The fact that $T$ is a norm-preserving mapping from $\\mathfrak{L}_{\\infty}$ into $\\mathfrak{L}_{1}^{\\ast}$ is (20.16). It follows from (20.19) that $T$ is onto $\\mathfrak{L}_{1}^{\\ast}$. It is trivial that $T$ is linear. Since $T$ is both linear and norm-preserving, it is one-to-one.\n\n(20.21) Note. As we have shown in (20.17), the conclusion in (20.20) fails for some nondecomposable measure spaces. However, J. Schwartz has found a representation of $\\mathfrak{L}_{1}^{\\ast}(X,{\\mathcal{A}},\\mu)$ for arbitrary $(X,{\\mathcal{A}},\\mu)$ [Proc. Amer. Math. Soc. 2 (1951), 270-275], to which the interested reader is referred.  \n\n(20.22) Exercise. Let $X$ be a locally compact Hausdorff space and let $t$ be an outer measure on $\\mathcal{P}(X)$ as in $\\S\\,9$. Prove that the definitions of local $t$ -nullity given in (9.29) and in (20.11) are equivalent.  \n\n(20.23) Exercise. Let $(X,{\\mathcal{A}},\\mu)$ be a degenerate measure space such that $\\mu\\left(X\\right)=\\infty$ [see (10.3) for the definition]. Is this measure space decomposable? Find $\\mathfrak{L}_{1},\\mathfrak{L}_{1}^{\\ast}$, and $\\mathfrak{L}_{\\infty}$ explicitly for this measure space.  \n\n(20.24) Exercise. Let $(X,{\\mathcal{A}},\\mu)$ be any measure space and let $f\\in\\mathfrak{L}_{1}(X,\\mathcal{A},\\mu)$. Define $L$ on $\\mathfrak{L}_{\\infty}(X,{\\mathcal{A}},\\mu)$ by  \n\n$$\n\\begin{array}{r}{L\\left(g\\right)=\\int_{X} g\\bar{f}d\\mu}\\;.\\end{array}\n$$  \n\nProve that $L\\in\\mathfrak{L}_{\\infty}^{*}$ and that $\\|L\\|=\\|f\\|_{1}$.  \n\n(20.25) Exercise. Prove that $\\mathfrak{L}_{1}([0,\\,1])$ [with Lebesgue measure] is not reflexive by showing that not every $L\\in\\mathfrak{L}_{\\infty}^{*}([0,\\,1])$ has the form described in (20.24). [Hint. Use the Hahn-Banach theorem to produce an $L\\neq0$ such that $L\\left(g\\right)=0$ for all $g\\in\\mathfrak{L}_{\\infty}$ for which $g$ is essentially continuous, i.e., $\\|g\\,-\\,h\\|_{\\infty}{=0}$ for some $h\\in\\mathfrak{C}([0,\\,1]).$  \n\n(20.26) Exercise. (a) Prove that $\\mathfrak{L}_{\\infty}([0,\\,1])$ is not separable.  \n\n(b) Find necessary and sufficient conditions on a measure space that its $\\mathfrak{L}_{\\infty}$ space be separable. [Do not forget (20.23).]  \n\nHaving found the conjugate space of $\\mathfrak{L}_{p}(X,{\\mathcal{A}},\\mu)$ for $1<\\phi<\\infty$ and any measure space $(X,{\\mathcal{A}},\\mu)$, and of $\\mathfrak{L}_{1}(X,{\\mathcal{A}},\\mu)$ for a large class of",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "As we have shown in (20.17), the conclusion in (20.20) fails for some nondecomposable measure spaces. However, J. Schwartz has found a representation of $\\mathfrak{L}_{1}^{\\ast}(X, {\\mathcal{A}}, \\mu)$ for arbitrary $(X, {\\mathcal{A}}, \\mu)$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM25-Real_and_Abstract_Analysis1975.pdf_362",
        "ID": "05e8b8d8-966f-42d4-9b2c-7c5e3c4442a4",
        "questions": "What is the definition of T(g) in the context of a decomposable measure space $(X,{\\mathcal{A}},\\mu)$?",
        "answers": "T(g)=L_{\bar{g}}",
        "context": "and (12.30) show that  \n\n$$\n\\begin{array}{r l}&{L\\left(f\\right)=\\operatorname*{lim}_{p\\rightarrow\\infty}\\,L\\left(\\sum^{p}_{n-1}\\,f\\xi_{F_{n}}\\right)=\\operatorname*{lim}_{p\\rightarrow\\infty}\\sum^{p}_{n-1}\\,L\\left(f\\xi_{F_{n}}\\right)}\\\\ &{\\quad\\quad=\\operatorname*{lim}_{p\\rightarrow\\infty}\\sum^{p}_{n-1}\\int_{F_n}/\\bar{g}\\;d\\mu=\\operatorname*{lim}_{p\\rightarrow\\infty}\\int_{X}{\\sum^{p}_{n-1}}\\,f\\xi_{F_{n}}\\bar{g}\\,d\\mu}\\\\ &{\\quad\\quad=\\int_{X} f\\bar{g}\\;d\\mu\\;.\\quad}\\end{array}\n$$  \n\n(20.20) Theorem. Let $(X,{\\mathcal{A}},\\mu)$ be a decomposable measure space (19.25). Then the mapping $T$ defined by  \n\n$$\nT(g)=L_{\\bar{g}}\n$$  \n\n[see (20.16)] is a norm-preserving linear mapping of $\\mathfrak{L}_{\\infty}$ onto the conjugate space $\\mathfrak{L}^{\\ast}_{1}$. Thus, as Banach spaces, $\\mathfrak{L}_{\\infty}$ and $\\mathfrak{L}_{1}^{\\ast}$ are isomorphic.  \n\nProof. The fact that $T$ is a norm-preserving mapping from $\\mathfrak{L}_{\\infty}$ into $\\mathfrak{L}_{1}^{\\ast}$ is (20.16). It follows from (20.19) that $T$ is onto $\\mathfrak{L}_{1}^{\\ast}$. It is trivial that $T$ is linear. Since $T$ is both linear and norm-preserving, it is one-to-one.\n\n(20.21) Note. As we have shown in (20.17), the conclusion in (20.20) fails for some nondecomposable measure spaces. However, J. Schwartz has found a representation of $\\mathfrak{L}_{1}^{\\ast}(X,{\\mathcal{A}},\\mu)$ for arbitrary $(X,{\\mathcal{A}},\\mu)$ [Proc. Amer. Math. Soc. 2 (1951), 270-275], to which the interested reader is referred.  \n\n(20.22) Exercise. Let $X$ be a locally compact Hausdorff space and let $t$ be an outer measure on $\\mathcal{P}(X)$ as in $\\S\\,9$. Prove that the definitions of local $t$ -nullity given in (9.29) and in (20.11) are equivalent.  \n\n(20.23) Exercise. Let $(X,{\\mathcal{A}},\\mu)$ be a degenerate measure space such that $\\mu\\left(X\\right)=\\infty$ [see (10.3) for the definition]. Is this measure space decomposable? Find $\\mathfrak{L}_{1},\\mathfrak{L}_{1}^{\\ast}$, and $\\mathfrak{L}_{\\infty}$ explicitly for this measure space.  \n\n(20.24) Exercise. Let $(X,{\\mathcal{A}},\\mu)$ be any measure space and let $f\\in\\mathfrak{L}_{1}(X,\\mathcal{A},\\mu)$. Define $L$ on $\\mathfrak{L}_{\\infty}(X,{\\mathcal{A}},\\mu)$ by  \n\n$$\n\\begin{array}{r}{L\\left(g\\right)=\\int_{X} g\\bar{f}d\\mu}\\;.\\end{array}\n$$  \n\nProve that $L\\in\\mathfrak{L}_{\\infty}^{*}$ and that $\\|L\\|=\\|f\\|_{1}$.  \n\n(20.25) Exercise. Prove that $\\mathfrak{L}_{1}([0,\\,1])$ [with Lebesgue measure] is not reflexive by showing that not every $L\\in\\mathfrak{L}_{\\infty}^{*}([0,\\,1])$ has the form described in (20.24). [Hint. Use the Hahn-Banach theorem to produce an $L\\neq0$ such that $L\\left(g\\right)=0$ for all $g\\in\\mathfrak{L}_{\\infty}$ for which $g$ is essentially continuous, i.e., $\\|g\\,-\\,h\\|_{\\infty}{=0}$ for some $h\\in\\mathfrak{C}([0,\\,1]).$  \n\n(20.26) Exercise. (a) Prove that $\\mathfrak{L}_{\\infty}([0,\\,1])$ is not separable.  \n\n(b) Find necessary and sufficient conditions on a measure space that its $\\mathfrak{L}_{\\infty}$ space be separable. [Do not forget (20.23).]  \n\nHaving found the conjugate space of $\\mathfrak{L}_{p}(X,{\\mathcal{A}},\\mu)$ for $1<\\phi<\\infty$ and any measure space $(X,{\\mathcal{A}},\\mu)$, and of $\\mathfrak{L}_{1}(X,{\\mathcal{A}},\\mu)$ for a large class of",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Then the mapping $T$ defined by  $$ T(g)=L_{\bar{g}} $$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/GTM25-Real_and_Abstract_Analysis1975.pdf_362",
        "ID": "05eae756-111a-40c6-b6be-813738d0b720",
        "questions": "What is the integral formula for the linear operator $L$ defined on $\\mathfrak{L}_{\\infty}(X,{\\mathcal{A}},\\mu)$ with a function $f\\in\\mathfrak{L}_{1}(X,\\mathcal{A},\\mu)$?",
        "answers": "$L(g)=\\int_{X} g\\bar{f}d\\mu$",
        "context": "and (12.30) show that  \n\n$$\n\\begin{array}{r l}&{L\\left(f\\right)=\\operatorname*{lim}_{p\\rightarrow\\infty}\\,L\\left(\\sum^{p}_{n-1}\\,f\\xi_{F_{n}}\\right)=\\operatorname*{lim}_{p\\rightarrow\\infty}\\sum^{p}_{n-1}\\,L\\left(f\\xi_{F_{n}}\\right)}\\\\ &{\\quad\\quad=\\operatorname*{lim}_{p\\rightarrow\\infty}\\sum^{p}_{n-1}\\int_{F_n}/\\bar{g}\\;d\\mu=\\operatorname*{lim}_{p\\rightarrow\\infty}\\int_{X}{\\sum^{p}_{n-1}}\\,f\\xi_{F_{n}}\\bar{g}\\,d\\mu}\\\\ &{\\quad\\quad=\\int_{X} f\\bar{g}\\;d\\mu\\;.\\quad}\\end{array}\n$$  \n\n(20.20) Theorem. Let $(X,{\\mathcal{A}},\\mu)$ be a decomposable measure space (19.25). Then the mapping $T$ defined by  \n\n$$\nT(g)=L_{\\bar{g}}\n$$  \n\n[see (20.16)] is a norm-preserving linear mapping of $\\mathfrak{L}_{\\infty}$ onto the conjugate space $\\mathfrak{L}^{\\ast}_{1}$. Thus, as Banach spaces, $\\mathfrak{L}_{\\infty}$ and $\\mathfrak{L}_{1}^{\\ast}$ are isomorphic.  \n\nProof. The fact that $T$ is a norm-preserving mapping from $\\mathfrak{L}_{\\infty}$ into $\\mathfrak{L}_{1}^{\\ast}$ is (20.16). It follows from (20.19) that $T$ is onto $\\mathfrak{L}_{1}^{\\ast}$. It is trivial that $T$ is linear. Since $T$ is both linear and norm-preserving, it is one-to-one.\n\n(20.21) Note. As we have shown in (20.17), the conclusion in (20.20) fails for some nondecomposable measure spaces. However, J. Schwartz has found a representation of $\\mathfrak{L}_{1}^{\\ast}(X,{\\mathcal{A}},\\mu)$ for arbitrary $(X,{\\mathcal{A}},\\mu)$ [Proc. Amer. Math. Soc. 2 (1951), 270-275], to which the interested reader is referred.  \n\n(20.22) Exercise. Let $X$ be a locally compact Hausdorff space and let $t$ be an outer measure on $\\mathcal{P}(X)$ as in $\\S\\,9$. Prove that the definitions of local $t$ -nullity given in (9.29) and in (20.11) are equivalent.  \n\n(20.23) Exercise. Let $(X,{\\mathcal{A}},\\mu)$ be a degenerate measure space such that $\\mu\\left(X\\right)=\\infty$ [see (10.3) for the definition]. Is this measure space decomposable? Find $\\mathfrak{L}_{1},\\mathfrak{L}_{1}^{\\ast}$, and $\\mathfrak{L}_{\\infty}$ explicitly for this measure space.  \n\n(20.24) Exercise. Let $(X,{\\mathcal{A}},\\mu)$ be any measure space and let $f\\in\\mathfrak{L}_{1}(X,\\mathcal{A},\\mu)$. Define $L$ on $\\mathfrak{L}_{\\infty}(X,{\\mathcal{A}},\\mu)$ by  \n\n$$\n\\begin{array}{r}{L\\left(g\\right)=\\int_{X} g\\bar{f}d\\mu}\\;.\\end{array}\n$$  \n\nProve that $L\\in\\mathfrak{L}_{\\infty}^{*}$ and that $\\|L\\|=\\|f\\|_{1}$.  \n\n(20.25) Exercise. Prove that $\\mathfrak{L}_{1}([0,\\,1])$ [with Lebesgue measure] is not reflexive by showing that not every $L\\in\\mathfrak{L}_{\\infty}^{*}([0,\\,1])$ has the form described in (20.24). [Hint. Use the Hahn-Banach theorem to produce an $L\\neq0$ such that $L\\left(g\\right)=0$ for all $g\\in\\mathfrak{L}_{\\infty}$ for which $g$ is essentially continuous, i.e., $\\|g\\,-\\,h\\|_{\\infty}{=0}$ for some $h\\in\\mathfrak{C}([0,\\,1]).$  \n\n(20.26) Exercise. (a) Prove that $\\mathfrak{L}_{\\infty}([0,\\,1])$ is not separable.  \n\n(b) Find necessary and sufficient conditions on a measure space that its $\\mathfrak{L}_{\\infty}$ space be separable. [Do not forget (20.23).]  \n\nHaving found the conjugate space of $\\mathfrak{L}_{p}(X,{\\mathcal{A}},\\mu)$ for $1<\\phi<\\infty$ and any measure space $(X,{\\mathcal{A}},\\mu)$, and of $\\mathfrak{L}_{1}(X,{\\mathcal{A}},\\mu)$ for a large class of",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Define $L$ on $\\mathfrak{L}_{\\infty}(X,{\\mathcal{A}},\\mu)$ by  $$ \\begin{array}{r}{L\\left(g\\right)=\\int_{X} g\\bar{f}d\\mu}\\;.\\end{array} $$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/GTM25-Real_and_Abstract_Analysis1975.pdf_362",
        "ID": "05eb09ba-a028-4d1e-a595-04cada6b236d",
        "questions": "Using equation (12.30), express the integral of $f$ over $X$ multiplied by the conjugate of $g$ in terms of sums over partition elements $F_n$.",
        "answers": "$\\operatorname*{lim}_{p\\rightarrow\\infty}\\sum^{p}_{n-1}\\int_{F_n}/\\bar{g}\\;d\\mu=\\operatorname*{lim}_{p\\rightarrow\\infty}\\int_{X}{\\sum^{p}_{n-1}}\\,f\\xi_{F_{n}}\\bar{g}\\,d\\mu$",
        "context": "and (12.30) show that  \n\n$$\n\\begin{array}{r l}&{L\\left(f\\right)=\\operatorname*{lim}_{p\\rightarrow\\infty}\\,L\\left(\\sum^{p}_{n-1}\\,f\\xi_{F_{n}}\\right)=\\operatorname*{lim}_{p\\rightarrow\\infty}\\sum^{p}_{n-1}\\,L\\left(f\\xi_{F_{n}}\\right)}\\\\ &{\\quad\\quad=\\operatorname*{lim}_{p\\rightarrow\\infty}\\sum^{p}_{n-1}\\int_{F_n}/\\bar{g}\\;d\\mu=\\operatorname*{lim}_{p\\rightarrow\\infty}\\int_{X}{\\sum^{p}_{n-1}}\\,f\\xi_{F_{n}}\\bar{g}\\,d\\mu}\\\\ &{\\quad\\quad=\\int_{X} f\\bar{g}\\;d\\mu\\;.\\quad}\\end{array}\n$$  \n\n(20.20) Theorem. Let $(X,{\\mathcal{A}},\\mu)$ be a decomposable measure space (19.25). Then the mapping $T$ defined by  \n\n$$\nT(g)=L_{\\bar{g}}\n$$  \n\n[see (20.16)] is a norm-preserving linear mapping of $\\mathfrak{L}_{\\infty}$ onto the conjugate space $\\mathfrak{L}^{\\ast}_{1}$. Thus, as Banach spaces, $\\mathfrak{L}_{\\infty}$ and $\\mathfrak{L}_{1}^{\\ast}$ are isomorphic.  \n\nProof. The fact that $T$ is a norm-preserving mapping from $\\mathfrak{L}_{\\infty}$ into $\\mathfrak{L}_{1}^{\\ast}$ is (20.16). It follows from (20.19) that $T$ is onto $\\mathfrak{L}_{1}^{\\ast}$. It is trivial that $T$ is linear. Since $T$ is both linear and norm-preserving, it is one-to-one.\n\n(20.21) Note. As we have shown in (20.17), the conclusion in (20.20) fails for some nondecomposable measure spaces. However, J. Schwartz has found a representation of $\\mathfrak{L}_{1}^{\\ast}(X,{\\mathcal{A}},\\mu)$ for arbitrary $(X,{\\mathcal{A}},\\mu)$ [Proc. Amer. Math. Soc. 2 (1951), 270-275], to which the interested reader is referred.  \n\n(20.22) Exercise. Let $X$ be a locally compact Hausdorff space and let $t$ be an outer measure on $\\mathcal{P}(X)$ as in $\\S\\,9$. Prove that the definitions of local $t$ -nullity given in (9.29) and in (20.11) are equivalent.  \n\n(20.23) Exercise. Let $(X,{\\mathcal{A}},\\mu)$ be a degenerate measure space such that $\\mu\\left(X\\right)=\\infty$ [see (10.3) for the definition]. Is this measure space decomposable? Find $\\mathfrak{L}_{1},\\mathfrak{L}_{1}^{\\ast}$, and $\\mathfrak{L}_{\\infty}$ explicitly for this measure space.  \n\n(20.24) Exercise. Let $(X,{\\mathcal{A}},\\mu)$ be any measure space and let $f\\in\\mathfrak{L}_{1}(X,\\mathcal{A},\\mu)$. Define $L$ on $\\mathfrak{L}_{\\infty}(X,{\\mathcal{A}},\\mu)$ by  \n\n$$\n\\begin{array}{r}{L\\left(g\\right)=\\int_{X} g\\bar{f}d\\mu}\\;.\\end{array}\n$$  \n\nProve that $L\\in\\mathfrak{L}_{\\infty}^{*}$ and that $\\|L\\|=\\|f\\|_{1}$.  \n\n(20.25) Exercise. Prove that $\\mathfrak{L}_{1}([0,\\,1])$ [with Lebesgue measure] is not reflexive by showing that not every $L\\in\\mathfrak{L}_{\\infty}^{*}([0,\\,1])$ has the form described in (20.24). [Hint. Use the Hahn-Banach theorem to produce an $L\\neq0$ such that $L\\left(g\\right)=0$ for all $g\\in\\mathfrak{L}_{\\infty}$ for which $g$ is essentially continuous, i.e., $\\|g\\,-\\,h\\|_{\\infty}{=0}$ for some $h\\in\\mathfrak{C}([0,\\,1]).$  \n\n(20.26) Exercise. (a) Prove that $\\mathfrak{L}_{\\infty}([0,\\,1])$ is not separable.  \n\n(b) Find necessary and sufficient conditions on a measure space that its $\\mathfrak{L}_{\\infty}$ space be separable. [Do not forget (20.23).]  \n\nHaving found the conjugate space of $\\mathfrak{L}_{p}(X,{\\mathcal{A}},\\mu)$ for $1<\\phi<\\infty$ and any measure space $(X,{\\mathcal{A}},\\mu)$, and of $\\mathfrak{L}_{1}(X,{\\mathcal{A}},\\mu)$ for a large class of",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$\\quad\\quad=\\operatorname*{lim}_{p\\rightarrow\\infty}\\sum^{p}_{n-1}\\int_{F_n}/\\bar{g}\\;d\\mu=\\operatorname*{lim}_{p\\rightarrow\\infty}\\int_{X}{\\sum^{p}_{n-1}}\\,f\\xi_{F_{n}}\\bar{g}\\,d\\mu$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/stats-13961.pdf_52",
        "ID": "0615377a-6407-4a40-8f2f-1dd410e15c52",
        "questions": "What is the median of the homework scores earned by the student in the given dataset?",
        "answers": "84.5",
        "context": "# 2.5: Standard Deviation (4 of 4) \n>  Learning Objectives \n- Use mean and standard deviation to describe a distribution  \n\n# Deciding Which Measurements to Use  \n\nWe now have a choice between two measurements of center and spread. We can use the median with the interquartile range, or we can use the mean with the standard deviation. How do we decide which measurements to use?  \n\nOur next examples show that the shape of the distribution and the presence of outliers helps us answer this question.  \n\n# Example  \n\n# Homework Scores with an Outlier  \n\nHere are two summaries of the same set of homework scores earned by a student: a box plot and an SD hat plot. Notice that the distribution of scores has an outlier. This student has mostly high homework scores with one score of 0. Here are some observations about the homework data:  \n\n- Five-number summary: low: 0, Q1: 82, Q2: 84.5, Q3: 89, high: 100  \n\n- Median is 84.5 and IQR is 7  \n\n- Mean $=81.8$, $\\mathrm{{SD}}=17.6$  \n\n![](images/7b7e32e8758810b1570487321b3c2b38d2665afb176ac7185519a79c7a25785c.jpg)  \n\nThe typical range of scores based on the first and third quartiles is 82 to 89.  \n\nThe typical range of scores based on Mean $\\pm$ SD is 64.2 to 99.4 (Here's how we calculated this: $81.8-17.6=64.2,$ $81.8+17.6=99.4$.)  \n\nWhich is the better summary of the student's performance on homework?  \n\nThe typical range based on the mean and standard deviation is not a good summary of this student's homework scores. Here we see that the outlier decreases the mean so that the mean is too low to be representative of this student's typical performance. We also see that the outlier increases the standard deviation, which gives the impression of a wide variability in scores. This makes sense because the standard deviation measures the average deviation of the data from the mean. So a point that has a large deviation from the mean will increase the average of the deviations. In this example, a single score is responsible for giving the impression that the student's typical homework scores are lower than they really are.  \n\nThe typical range based on the first and third quartiles gives a better summary of this student's performance on homework because the outlier does not affect the quartile marks.  \n\n# Example  \n\n# Skewed Incomes  \n\nIn this example, we look at how skewness in a data set affects the standard deviation. The following histogram shows the personal income of a large sample of individuals drawn from U.S. census data in the year 2000. Notice that it is strongly skewed to the right. This type of skewness is often present in datasets of variables such as income.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Numeric",
        "evidence_source": "text",
        "evidence_context": "Median is 84.5 and IQR is 7",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/stats-13961.pdf_52",
        "ID": "0615594c-3ae1-4b40-8dfe-24b90d1b85c9",
        "questions": "Why is the typical range based on mean and standard deviation not a good summary of the student's homework scores?",
        "answers": "The typical range based on the mean and standard deviation is not a good summary of this student's homework scores. Here we see that the outlier decreases the mean so that the mean is too low to be representative of this student's typical performance. We also see that the outlier increases the standard deviation, which gives the impression of a wide variability in scores.",
        "context": "# 2.5: Standard Deviation (4 of 4) \n>  Learning Objectives \n- Use mean and standard deviation to describe a distribution  \n\n# Deciding Which Measurements to Use  \n\nWe now have a choice between two measurements of center and spread. We can use the median with the interquartile range, or we can use the mean with the standard deviation. How do we decide which measurements to use?  \n\nOur next examples show that the shape of the distribution and the presence of outliers helps us answer this question.  \n\n# Example  \n\n# Homework Scores with an Outlier  \n\nHere are two summaries of the same set of homework scores earned by a student: a box plot and an SD hat plot. Notice that the distribution of scores has an outlier. This student has mostly high homework scores with one score of 0. Here are some observations about the homework data:  \n\n- Five-number summary: low: 0, Q1: 82, Q2: 84.5, Q3: 89, high: 100  \n\n- Median is 84.5 and IQR is 7  \n\n- Mean $=81.8$, $\\mathrm{{SD}}=17.6$  \n\n![](images/7b7e32e8758810b1570487321b3c2b38d2665afb176ac7185519a79c7a25785c.jpg)  \n\nThe typical range of scores based on the first and third quartiles is 82 to 89.  \n\nThe typical range of scores based on Mean $\\pm$ SD is 64.2 to 99.4 (Here's how we calculated this: $81.8-17.6=64.2,$ $81.8+17.6=99.4$.)  \n\nWhich is the better summary of the student's performance on homework?  \n\nThe typical range based on the mean and standard deviation is not a good summary of this student's homework scores. Here we see that the outlier decreases the mean so that the mean is too low to be representative of this student's typical performance. We also see that the outlier increases the standard deviation, which gives the impression of a wide variability in scores. This makes sense because the standard deviation measures the average deviation of the data from the mean. So a point that has a large deviation from the mean will increase the average of the deviations. In this example, a single score is responsible for giving the impression that the student's typical homework scores are lower than they really are.  \n\nThe typical range based on the first and third quartiles gives a better summary of this student's performance on homework because the outlier does not affect the quartile marks.  \n\n# Example  \n\n# Skewed Incomes  \n\nIn this example, we look at how skewness in a data set affects the standard deviation. The following histogram shows the personal income of a large sample of individuals drawn from U.S. census data in the year 2000. Notice that it is strongly skewed to the right. This type of skewness is often present in datasets of variables such as income.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "The typical range based on the mean and standard deviation is not a good summary of this student's homework scores. Here we see that the outlier decreases the mean so that the mean is too low to be representative of this student's typical performance. We also see that the outlier increases the standard deviation, which gives the impression of a wide variability in scores.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/stats-13961.pdf_52",
        "ID": "061948c4-031f-40dc-9cab-745448ea5a56",
        "questions": "How does skewness in a dataset of variables such as income affect the standard deviation, according to the histogram drawn from U.S. census data in the year 2000?",
        "answers": "the personal income of a large sample of individuals drawn from U.S. census data in the year 2000. Notice that it is strongly skewed to the right.",
        "context": "# 2.5: Standard Deviation (4 of 4) \n>  Learning Objectives \n- Use mean and standard deviation to describe a distribution  \n\n# Deciding Which Measurements to Use  \n\nWe now have a choice between two measurements of center and spread. We can use the median with the interquartile range, or we can use the mean with the standard deviation. How do we decide which measurements to use?  \n\nOur next examples show that the shape of the distribution and the presence of outliers helps us answer this question.  \n\n# Example  \n\n# Homework Scores with an Outlier  \n\nHere are two summaries of the same set of homework scores earned by a student: a box plot and an SD hat plot. Notice that the distribution of scores has an outlier. This student has mostly high homework scores with one score of 0. Here are some observations about the homework data:  \n\n- Five-number summary: low: 0, Q1: 82, Q2: 84.5, Q3: 89, high: 100  \n\n- Median is 84.5 and IQR is 7  \n\n- Mean $=81.8$, $\\mathrm{{SD}}=17.6$  \n\n![](images/7b7e32e8758810b1570487321b3c2b38d2665afb176ac7185519a79c7a25785c.jpg)  \n\nThe typical range of scores based on the first and third quartiles is 82 to 89.  \n\nThe typical range of scores based on Mean $\\pm$ SD is 64.2 to 99.4 (Here's how we calculated this: $81.8-17.6=64.2,$ $81.8+17.6=99.4$.)  \n\nWhich is the better summary of the student's performance on homework?  \n\nThe typical range based on the mean and standard deviation is not a good summary of this student's homework scores. Here we see that the outlier decreases the mean so that the mean is too low to be representative of this student's typical performance. We also see that the outlier increases the standard deviation, which gives the impression of a wide variability in scores. This makes sense because the standard deviation measures the average deviation of the data from the mean. So a point that has a large deviation from the mean will increase the average of the deviations. In this example, a single score is responsible for giving the impression that the student's typical homework scores are lower than they really are.  \n\nThe typical range based on the first and third quartiles gives a better summary of this student's performance on homework because the outlier does not affect the quartile marks.  \n\n# Example  \n\n# Skewed Incomes  \n\nIn this example, we look at how skewness in a data set affects the standard deviation. The following histogram shows the personal income of a large sample of individuals drawn from U.S. census data in the year 2000. Notice that it is strongly skewed to the right. This type of skewness is often present in datasets of variables such as income.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "the personal income of a large sample of individuals drawn from U.S. census data in the year 2000. Notice that it is strongly skewed to the right.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTX_-_Introduction_to_Noncommutative_Algebra.pdf_185",
        "ID": "06274afb-6071-411e-bb25-59fb54d6aa2d",
        "questions": "What is the value of $p_{j}$ when $\\omega_1,\\ldots,\\omega_n$ are inputs?",
        "answers": "$p_{j}=p_{j}(\\omega_{1},\\ldots,\\omega_{n}):=\\sum_{i=1}^{n}\\omega_{i}^{j}$",
        "context": "Elementary symmetric polynomials are thus intimately connected with the roots of polynomials. Another reason for their importance is that they generate the algebra of all symmetric polynomials, but we will not need this fact. Our goal is to connect the elementary symmetric polynomials with the symmetric polynomials.  \n\n$$\np_{j}=p_{j}(\\omega_{1},\\ldots,\\omega_{n}):=\\sum_{i=1}^{n}\\omega_{i}^{j},~~j\\geq1.\n$$  \n\nOne can verify that  \n\n$$\ne_{1}=p_{1},\\;\\;2e_{2}=e_{1}p_{1}-p_{2},\\;\\;3e_{3}=e_{2}p_{1}-e_{1}p_{2}+p_{3},\n$$  \n\nwhich indicates the general rule.  \n\nLemma 6.35 (Newton's formulas) For $k=1,\\ldots,n$ we have  \n\n$$\nk e_{k}=\\sum_{j=1}^{k}(-1)^{j-1}e_{k-j}p_{j}.\n$$  \n\nProof From (6.6) it follows that  \n\n$$\n\\sum_{j=0}^{n}(-1)^{j}e_{n-j}\\omega_{i}^{j}=0,\\;\\;\\;i=1,\\ldots,n.\n$$  \n\nSumming up over all $i$ we obtain (6.8) for $k=n$. The case where $k<n$ follows easily from this one, basically we are facing only a problem in notation. The one that we are using suggests that $n$ is fixed and $k$ varies. While this setting is natural in view of applications, in the proof that follows it is inconvenient to regard $n$ as fixed. Let us therefore write, just for the purpose of this proof, $e_{k,n}$ for $e_{k}$ and $p_{j,n}$ for $p_{j}$. Our goal is to show that the polynomial  \n\n$$\nP:=k e_{k,n}-\\sum_{j=1}^{k}(-1)^{j-1}e_{k-j,n}p_{j,n}\n$$  \n\nis 0. Note that for any $i,j\\leq k$ we have  \n\n$$\n\\begin{array}{r}{e_{i,n}(\\omega_{1},\\dots,\\omega_{k},0,\\dots,0)=e_{i,k}(\\omega_{1},\\dots,\\omega_{k}),}\\\\ {\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad}\\\\ {p_{j,n}(\\omega_{1},\\dots,\\omega_{k},0,\\dots,0)=p_{j,k}(\\omega_{1},\\dots,\\omega_{k}).}\\end{array}\n$$  \n\nSince (6.8) holds for $n=k$, it follows that $P(\\omega_{1},.\\,.\\,,\\omega_{k},0,.\\,.\\,.\\,,0)=0.$ This means that $P$ does not contain nonzero monomials in $\\omega_{1},.\\,.\\,.\\,,\\,\\omega_{k}$. Similarly, by setting zeros at other places, we see that $P$ does not contain nonzero monomials in any set of $k$ indeterminates. However, from the definition of $P$ it is obvious that its nonzero",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Equation",
        "evidence_source": "equation",
        "evidence_context": "$$ p_{j}=p_{j}(\\omega_{1},\\ldots,\\omega_{n}):=\\sum_{i=1}^{n}\\omega_{i}^{j},~~j\\geq1. $$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTX_-_Introduction_to_Noncommutative_Algebra.pdf_185",
        "ID": "062e35b8-2580-42a2-bf96-4bd9f93a0f7b",
        "questions": "What polynomial is described as generating the algebra of all symmetric polynomials and is connected to the roots of polynomials?",
        "answers": "Elementary symmetric polynomials",
        "context": "Elementary symmetric polynomials are thus intimately connected with the roots of polynomials. Another reason for their importance is that they generate the algebra of all symmetric polynomials, but we will not need this fact. Our goal is to connect the elementary symmetric polynomials with the symmetric polynomials.  \n\n$$\np_{j}=p_{j}(\\omega_{1},\\ldots,\\omega_{n}):=\\sum_{i=1}^{n}\\omega_{i}^{j},~~j\\geq1.\n$$  \n\nOne can verify that  \n\n$$\ne_{1}=p_{1},\\;\\;2e_{2}=e_{1}p_{1}-p_{2},\\;\\;3e_{3}=e_{2}p_{1}-e_{1}p_{2}+p_{3},\n$$  \n\nwhich indicates the general rule.  \n\nLemma 6.35 (Newton's formulas) For $k=1,\\ldots,n$ we have  \n\n$$\nk e_{k}=\\sum_{j=1}^{k}(-1)^{j-1}e_{k-j}p_{j}.\n$$  \n\nProof From (6.6) it follows that  \n\n$$\n\\sum_{j=0}^{n}(-1)^{j}e_{n-j}\\omega_{i}^{j}=0,\\;\\;\\;i=1,\\ldots,n.\n$$  \n\nSumming up over all $i$ we obtain (6.8) for $k=n$. The case where $k<n$ follows easily from this one, basically we are facing only a problem in notation. The one that we are using suggests that $n$ is fixed and $k$ varies. While this setting is natural in view of applications, in the proof that follows it is inconvenient to regard $n$ as fixed. Let us therefore write, just for the purpose of this proof, $e_{k,n}$ for $e_{k}$ and $p_{j,n}$ for $p_{j}$. Our goal is to show that the polynomial  \n\n$$\nP:=k e_{k,n}-\\sum_{j=1}^{k}(-1)^{j-1}e_{k-j,n}p_{j,n}\n$$  \n\nis 0. Note that for any $i,j\\leq k$ we have  \n\n$$\n\\begin{array}{r}{e_{i,n}(\\omega_{1},\\dots,\\omega_{k},0,\\dots,0)=e_{i,k}(\\omega_{1},\\dots,\\omega_{k}),}\\\\ {\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad}\\\\ {p_{j,n}(\\omega_{1},\\dots,\\omega_{k},0,\\dots,0)=p_{j,k}(\\omega_{1},\\dots,\\omega_{k}).}\\end{array}\n$$  \n\nSince (6.8) holds for $n=k$, it follows that $P(\\omega_{1},.\\,.\\,,\\omega_{k},0,.\\,.\\,.\\,,0)=0.$ This means that $P$ does not contain nonzero monomials in $\\omega_{1},.\\,.\\,.\\,,\\,\\omega_{k}$. Similarly, by setting zeros at other places, we see that $P$ does not contain nonzero monomials in any set of $k$ indeterminates. However, from the definition of $P$ it is obvious that its nonzero",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Elementary symmetric polynomials are thus intimately connected with the roots of polynomials. Another reason for their importance is that they generate the algebra of all symmetric polynomials, but we will not need this fact.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTX_-_Introduction_to_Noncommutative_Algebra.pdf_185",
        "ID": "062fce1b-34ed-4821-bae3-a848e79d67bc",
        "questions": "What is Lemma 6.35 known as, which relates $k e_k$ with a combination of other elementary symmetric polynomials and power sums?",
        "answers": "Newton's formulas",
        "context": "Elementary symmetric polynomials are thus intimately connected with the roots of polynomials. Another reason for their importance is that they generate the algebra of all symmetric polynomials, but we will not need this fact. Our goal is to connect the elementary symmetric polynomials with the symmetric polynomials.  \n\n$$\np_{j}=p_{j}(\\omega_{1},\\ldots,\\omega_{n}):=\\sum_{i=1}^{n}\\omega_{i}^{j},~~j\\geq1.\n$$  \n\nOne can verify that  \n\n$$\ne_{1}=p_{1},\\;\\;2e_{2}=e_{1}p_{1}-p_{2},\\;\\;3e_{3}=e_{2}p_{1}-e_{1}p_{2}+p_{3},\n$$  \n\nwhich indicates the general rule.  \n\nLemma 6.35 (Newton's formulas) For $k=1,\\ldots,n$ we have  \n\n$$\nk e_{k}=\\sum_{j=1}^{k}(-1)^{j-1}e_{k-j}p_{j}.\n$$  \n\nProof From (6.6) it follows that  \n\n$$\n\\sum_{j=0}^{n}(-1)^{j}e_{n-j}\\omega_{i}^{j}=0,\\;\\;\\;i=1,\\ldots,n.\n$$  \n\nSumming up over all $i$ we obtain (6.8) for $k=n$. The case where $k<n$ follows easily from this one, basically we are facing only a problem in notation. The one that we are using suggests that $n$ is fixed and $k$ varies. While this setting is natural in view of applications, in the proof that follows it is inconvenient to regard $n$ as fixed. Let us therefore write, just for the purpose of this proof, $e_{k,n}$ for $e_{k}$ and $p_{j,n}$ for $p_{j}$. Our goal is to show that the polynomial  \n\n$$\nP:=k e_{k,n}-\\sum_{j=1}^{k}(-1)^{j-1}e_{k-j,n}p_{j,n}\n$$  \n\nis 0. Note that for any $i,j\\leq k$ we have  \n\n$$\n\\begin{array}{r}{e_{i,n}(\\omega_{1},\\dots,\\omega_{k},0,\\dots,0)=e_{i,k}(\\omega_{1},\\dots,\\omega_{k}),}\\\\ {\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad}\\\\ {p_{j,n}(\\omega_{1},\\dots,\\omega_{k},0,\\dots,0)=p_{j,k}(\\omega_{1},\\dots,\\omega_{k}).}\\end{array}\n$$  \n\nSince (6.8) holds for $n=k$, it follows that $P(\\omega_{1},.\\,.\\,,\\omega_{k},0,.\\,.\\,.\\,,0)=0.$ This means that $P$ does not contain nonzero monomials in $\\omega_{1},.\\,.\\,.\\,,\\,\\omega_{k}$. Similarly, by setting zeros at other places, we see that $P$ does not contain nonzero monomials in any set of $k$ indeterminates. However, from the definition of $P$ it is obvious that its nonzero",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Lemma 6.35 (Newton's formulas) For $k=1,\\ldots,n$ we have  $k e_{k}=\\sum_{j=1}^{k}(-1)^{j-1}e_{k-j}p_{j}.$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTX_-_Introduction_to_Noncommutative_Algebra.pdf_185",
        "ID": "0642f2b0-e84f-440f-b0ea-a3c6d844bf78",
        "questions": "What is the definition of the polynomial $p_j$ in terms of the variables $\\omega_1, \\ldots, \\omega_n$ for $j \\geq 1$?",
        "answers": "$p_{j}=p_{j}(\\omega_{1},\\ldots,\\omega_{n}):=\\sum_{i=1}^{n}\\omega_{i}^{j}$",
        "context": "Elementary symmetric polynomials are thus intimately connected with the roots of polynomials. Another reason for their importance is that they generate the algebra of all symmetric polynomials, but we will not need this fact. Our goal is to connect the elementary symmetric polynomials with the symmetric polynomials.  \n\n$$\np_{j}=p_{j}(\\omega_{1},\\ldots,\\omega_{n}):=\\sum_{i=1}^{n}\\omega_{i}^{j},~~j\\geq1.\n$$  \n\nOne can verify that  \n\n$$\ne_{1}=p_{1},\\;\\;2e_{2}=e_{1}p_{1}-p_{2},\\;\\;3e_{3}=e_{2}p_{1}-e_{1}p_{2}+p_{3},\n$$  \n\nwhich indicates the general rule.  \n\nLemma 6.35 (Newton's formulas) For $k=1,\\ldots,n$ we have  \n\n$$\nk e_{k}=\\sum_{j=1}^{k}(-1)^{j-1}e_{k-j}p_{j}.\n$$  \n\nProof From (6.6) it follows that  \n\n$$\n\\sum_{j=0}^{n}(-1)^{j}e_{n-j}\\omega_{i}^{j}=0,\\;\\;\\;i=1,\\ldots,n.\n$$  \n\nSumming up over all $i$ we obtain (6.8) for $k=n$. The case where $k<n$ follows easily from this one, basically we are facing only a problem in notation. The one that we are using suggests that $n$ is fixed and $k$ varies. While this setting is natural in view of applications, in the proof that follows it is inconvenient to regard $n$ as fixed. Let us therefore write, just for the purpose of this proof, $e_{k,n}$ for $e_{k}$ and $p_{j,n}$ for $p_{j}$. Our goal is to show that the polynomial  \n\n$$\nP:=k e_{k,n}-\\sum_{j=1}^{k}(-1)^{j-1}e_{k-j,n}p_{j,n}\n$$  \n\nis 0. Note that for any $i,j\\leq k$ we have  \n\n$$\n\\begin{array}{r}{e_{i,n}(\\omega_{1},\\dots,\\omega_{k},0,\\dots,0)=e_{i,k}(\\omega_{1},\\dots,\\omega_{k}),}\\\\ {\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad}\\\\ {p_{j,n}(\\omega_{1},\\dots,\\omega_{k},0,\\dots,0)=p_{j,k}(\\omega_{1},\\dots,\\omega_{k}).}\\end{array}\n$$  \n\nSince (6.8) holds for $n=k$, it follows that $P(\\omega_{1},.\\,.\\,,\\omega_{k},0,.\\,.\\,.\\,,0)=0.$ This means that $P$ does not contain nonzero monomials in $\\omega_{1},.\\,.\\,.\\,,\\,\\omega_{k}$. Similarly, by setting zeros at other places, we see that $P$ does not contain nonzero monomials in any set of $k$ indeterminates. However, from the definition of $P$ it is obvious that its nonzero",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$p_{j}=p_{j}(\\omega_{1},\\ldots,\\omega_{n}):=\\sum_{i=1}^{n}\\omega_{i}^{j},~~j\\geq1.$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/UTX_-_Introduction_to_Noncommutative_Algebra.pdf_185",
        "ID": "064f94bf-0ef8-4629-893f-222b0b8fefe4",
        "questions": "Express the elementary symmetric polynomial $e_2$ in terms of $e_1$, $p_1$, and $p_2$.",
        "answers": "2e_{2}=e_{1}p_{1}-p_{2}",
        "context": "Elementary symmetric polynomials are thus intimately connected with the roots of polynomials. Another reason for their importance is that they generate the algebra of all symmetric polynomials, but we will not need this fact. Our goal is to connect the elementary symmetric polynomials with the symmetric polynomials.  \n\n$$\np_{j}=p_{j}(\\omega_{1},\\ldots,\\omega_{n}):=\\sum_{i=1}^{n}\\omega_{i}^{j},~~j\\geq1.\n$$  \n\nOne can verify that  \n\n$$\ne_{1}=p_{1},\\;\\;2e_{2}=e_{1}p_{1}-p_{2},\\;\\;3e_{3}=e_{2}p_{1}-e_{1}p_{2}+p_{3},\n$$  \n\nwhich indicates the general rule.  \n\nLemma 6.35 (Newton's formulas) For $k=1,\\ldots,n$ we have  \n\n$$\nk e_{k}=\\sum_{j=1}^{k}(-1)^{j-1}e_{k-j}p_{j}.\n$$  \n\nProof From (6.6) it follows that  \n\n$$\n\\sum_{j=0}^{n}(-1)^{j}e_{n-j}\\omega_{i}^{j}=0,\\;\\;\\;i=1,\\ldots,n.\n$$  \n\nSumming up over all $i$ we obtain (6.8) for $k=n$. The case where $k<n$ follows easily from this one, basically we are facing only a problem in notation. The one that we are using suggests that $n$ is fixed and $k$ varies. While this setting is natural in view of applications, in the proof that follows it is inconvenient to regard $n$ as fixed. Let us therefore write, just for the purpose of this proof, $e_{k,n}$ for $e_{k}$ and $p_{j,n}$ for $p_{j}$. Our goal is to show that the polynomial  \n\n$$\nP:=k e_{k,n}-\\sum_{j=1}^{k}(-1)^{j-1}e_{k-j,n}p_{j,n}\n$$  \n\nis 0. Note that for any $i,j\\leq k$ we have  \n\n$$\n\\begin{array}{r}{e_{i,n}(\\omega_{1},\\dots,\\omega_{k},0,\\dots,0)=e_{i,k}(\\omega_{1},\\dots,\\omega_{k}),}\\\\ {\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad}\\\\ {p_{j,n}(\\omega_{1},\\dots,\\omega_{k},0,\\dots,0)=p_{j,k}(\\omega_{1},\\dots,\\omega_{k}).}\\end{array}\n$$  \n\nSince (6.8) holds for $n=k$, it follows that $P(\\omega_{1},.\\,.\\,,\\omega_{k},0,.\\,.\\,.\\,,0)=0.$ This means that $P$ does not contain nonzero monomials in $\\omega_{1},.\\,.\\,.\\,,\\,\\omega_{k}$. Similarly, by setting zeros at other places, we see that $P$ does not contain nonzero monomials in any set of $k$ indeterminates. However, from the definition of $P$ it is obvious that its nonzero",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "2e_{2}=e_{1}p_{1}-p_{2}",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/UTX_-_Introduction_to_Noncommutative_Algebra.pdf_185",
        "ID": "0654f465-b311-49c4-9d86-fd12c8359b91",
        "questions": "Using Newton's formulas, write the general equation for $k e_{k}$ in terms of $p_j$ and $e_{k-j}$. ",
        "answers": "$k e_{k}=\\sum_{j=1}^{k}(-1)^{j-1}e_{k-j}p_{j}$",
        "context": "Elementary symmetric polynomials are thus intimately connected with the roots of polynomials. Another reason for their importance is that they generate the algebra of all symmetric polynomials, but we will not need this fact. Our goal is to connect the elementary symmetric polynomials with the symmetric polynomials.  \n\n$$\np_{j}=p_{j}(\\omega_{1},\\ldots,\\omega_{n}):=\\sum_{i=1}^{n}\\omega_{i}^{j},~~j\\geq1.\n$$  \n\nOne can verify that  \n\n$$\ne_{1}=p_{1},\\;\\;2e_{2}=e_{1}p_{1}-p_{2},\\;\\;3e_{3}=e_{2}p_{1}-e_{1}p_{2}+p_{3},\n$$  \n\nwhich indicates the general rule.  \n\nLemma 6.35 (Newton's formulas) For $k=1,\\ldots,n$ we have  \n\n$$\nk e_{k}=\\sum_{j=1}^{k}(-1)^{j-1}e_{k-j}p_{j}.\n$$  \n\nProof From (6.6) it follows that  \n\n$$\n\\sum_{j=0}^{n}(-1)^{j}e_{n-j}\\omega_{i}^{j}=0,\\;\\;\\;i=1,\\ldots,n.\n$$  \n\nSumming up over all $i$ we obtain (6.8) for $k=n$. The case where $k<n$ follows easily from this one, basically we are facing only a problem in notation. The one that we are using suggests that $n$ is fixed and $k$ varies. While this setting is natural in view of applications, in the proof that follows it is inconvenient to regard $n$ as fixed. Let us therefore write, just for the purpose of this proof, $e_{k,n}$ for $e_{k}$ and $p_{j,n}$ for $p_{j}$. Our goal is to show that the polynomial  \n\n$$\nP:=k e_{k,n}-\\sum_{j=1}^{k}(-1)^{j-1}e_{k-j,n}p_{j,n}\n$$  \n\nis 0. Note that for any $i,j\\leq k$ we have  \n\n$$\n\\begin{array}{r}{e_{i,n}(\\omega_{1},\\dots,\\omega_{k},0,\\dots,0)=e_{i,k}(\\omega_{1},\\dots,\\omega_{k}),}\\\\ {\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad}\\\\ {p_{j,n}(\\omega_{1},\\dots,\\omega_{k},0,\\dots,0)=p_{j,k}(\\omega_{1},\\dots,\\omega_{k}).}\\end{array}\n$$  \n\nSince (6.8) holds for $n=k$, it follows that $P(\\omega_{1},.\\,.\\,,\\omega_{k},0,.\\,.\\,.\\,,0)=0.$ This means that $P$ does not contain nonzero monomials in $\\omega_{1},.\\,.\\,.\\,,\\,\\omega_{k}$. Similarly, by setting zeros at other places, we see that $P$ does not contain nonzero monomials in any set of $k$ indeterminates. However, from the definition of $P$ it is obvious that its nonzero",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Lemma 6.35 (Newton's formulas) For $k=1,\\ldots,n$ we have $k e_{k}=\\sum_{j=1}^{k}(-1)^{j-1}e_{k-j}p_{j}.$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/1996_Book_MathematicalAnalysis.pdf_255",
        "ID": "065963f2-9471-45e5-8ded-3a7c0eeae85f",
        "questions": "What is the relationship between the measures of a cube Q and its epsilon-expanded version Q^epsilon in the given mathematical context?",
        "answers": "m(Q^{\\epsilon})=(1+\\epsilon)^{n}m(Q)",
        "context": "Proof. We observe that equation (10.3) is just the special case of equation (10.2) obtained by taking $f=\\mathbf{1}_{\\varphi(A)}$. We also observe that it suffices to consider Borel measurable functions, since every Lebesgue measurable function is almost everywhere equal to a Borel measurable function (Theorem 10.9).\n\nWe carry out the proof with a short sequence of lemmas. Let us introduce some terminology and notation. A cube with center $\\xi$ is a set of the form\n\n$$\nQ=\\{\\mathbf{x}\\in\\mathbf{R}^{n}:\\xi_{j}-h\\leq x_{j}<\\xi_{j}+h,\\;1\\leq j\\leq n\\}.\n$$\n\n(This describes a \u201chalf-open\u201d cube, which will be convenient for our purposes. Closed and open cubes are defined similarly.) If $Q$ is a cube with center $\\xi$, and $\\epsilon>0$, let $Q^{\\epsilon}$ denote the concentric cube with sides multiplied by $1+\\epsilon$; thus, for the cube $Q$ above,\n\n$$\nQ^{\\epsilon}=\\{\\mathbf{x}\\in\\mathbf{R}^{n}:\\xi_{j}-(1+\\epsilon)h\\leq x_{j}<\\xi_{j}+(1+\\epsilon)h,\\;1\\leq j\\leq n\\}.\n$$\n\nIt is clear that $m(Q^{\\epsilon})=(1+\\epsilon)^{n}m(Q)$ for any cube $Q$.\n\n10.47 Lemma. For each $\\xi\\in U$, let $T_{\\xi}$ be the affine map approximating $\\varphi$ near $\\xi$, i.e., $T_{\\xi}(\\mathbf{x})=\\varphi(\\xi)+\\varphi^{\\prime}(\\xi)(\\mathbf{x}-\\xi)$. For any compact subset $K$ of $U$ and any $\\epsilon>0$, there exists $\\delta=\\delta(K,\\epsilon)>0$ such that, for any cube $Q\\subset U$ with center $\\xi$ in $K$ and diameter $<\\delta$, we have\n\n$$\n\\varphi(Q)\\subset T_{\\xi}(Q^{\\epsilon}).\n$$\n\nProof. Let $\\begin{array}{r}{M=\\operatorname*{sup}_{\\xi\\in K}\\|(\\varphi^{\\prime})^{-1}(\\xi)\\|}\\end{array}$; since $K$ is compact and $\\varphi^{\\prime}$ is continuous, we know $M\\,<\\,\\infty$. The definition of the derivative of a mapping tells us that for any $\\eta>0$ there exists $\\delta\\,=\\,\\delta(\\xi,\\eta)\\,>\\,0$ such that $|\\varphi(\\mathbf{x})-T_{\\xi}(\\mathbf{x})|<\\eta|\\mathbf{x}-\\xi|$ whenever $0<|\\mathbf{x}-\\boldsymbol{\\xi}|<\\delta$. Since $K$ is compact, and $\\varphi^{\\prime}$ is continuous, we can choose $\\delta=\\delta(\\eta)$ so that this holds for every $\\xi\\in K$. $T_{\\xi}^{-1}\\mathbf{y}-T_{\\xi}^{-1}\\mathbf{z}=[\\varphi^{\\prime}(\\xi)]^{-1}(\\mathbf{y}-\\mathbf{z})$\n\n$$\n|T_{\\xi}^{-1}\\varphi(\\mathbf{x})-\\mathbf{x}|=|T_{\\xi}^{-1}[\\varphi(\\mathbf{x})-T_{\\xi}(\\mathbf{x})]|\\leq M\\eta|\\mathbf{x}-\\xi|,\n$$\n\nso that, if $\\eta>0$ is chosen sufficiently small $(\\eta\\,<\\,\\epsilon/(M\\sqrt{n})$ will do), we have $T_{\\xi}^{-1}\\varphi(\\mathbf{x})\\in Q^{\\epsilon}$, or equivalently, $\\varphi({\\bf x})\\in T_{\\xi}(Q^{\\epsilon})$, whenever $\\mathbf{x}\\in Q$ with $Q$ a cube of diameter less than $\\delta$ and center $\\xi\\in K$.\n\n10.48 Lemma. If $B$ is a Borel subset of $U$, then\n\n$$\nm{\\big(}\\varphi(B){\\big)}\\leq\\int_{B}|J_{\\varphi}|\\,d m.\n$$\n\nProof. Let $C$ be a compact subset of $\\varphi(B)$, and put $K=\\varphi^{-1}(C)$, so $K$ is a compact subset of $U$. Let $\\epsilon>0$. For each $i\\in\\mathbf{N}$, let $K_{i}=\\{{\\bf x}:\\rho({\\bf x},K)\\leq 1/i\\}$, where $\\rho(\\mathbf{x},K)=\\operatorname*{inf}\\left\\{|\\mathbf{x}-\\mathbf{y}|:\\mathbf{y}\\in K\\right\\}$. Then $K_{i}$ is compact, and for sufficiently large $i$, say $i\\geq i_{0}$, $K_{i}\\subset U$. We note that $K_{i+1}\\subset K_{i}$ for all $i$, and $\\textstyle\\bigcap_{i}K_{i}\\,=\\,K$. Since the function $\\textstyle A\\mapsto\\int_{A}|J_{\\varphi}|\\,d m$ is a measure, and",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Equation",
        "evidence_source": "equation",
        "evidence_context": "It is clear that $m(Q^{\\epsilon})=(1+\\epsilon)^{n}m(Q)$ for any cube $Q$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/1996_Book_MathematicalAnalysis.pdf_255",
        "ID": "065a13d4-32e9-433d-a49e-0f3a63e766b7",
        "questions": "In the mathematical proof, what condition is required for the function phi's approximation by the affine map T_xi to hold for a cube Q centered at xi?",
        "answers": "For any cube Q with center \u03be in K and diameter < \u03b4, we have \u03c6(Q) \u2282 T_{\u03be}(Q^{\u03b5}).",
        "context": "Proof. We observe that equation (10.3) is just the special case of equation (10.2) obtained by taking $f=\\mathbf{1}_{\\varphi(A)}$. We also observe that it suffices to consider Borel measurable functions, since every Lebesgue measurable function is almost everywhere equal to a Borel measurable function (Theorem 10.9).\n\nWe carry out the proof with a short sequence of lemmas. Let us introduce some terminology and notation. A cube with center $\\xi$ is a set of the form\n\n$$\nQ=\\{\\mathbf{x}\\in\\mathbf{R}^{n}:\\xi_{j}-h\\leq x_{j}<\\xi_{j}+h,\\;1\\leq j\\leq n\\}.\n$$\n\n(This describes a \u201chalf-open\u201d cube, which will be convenient for our purposes. Closed and open cubes are defined similarly.) If $Q$ is a cube with center $\\xi$, and $\\epsilon>0$, let $Q^{\\epsilon}$ denote the concentric cube with sides multiplied by $1+\\epsilon$; thus, for the cube $Q$ above,\n\n$$\nQ^{\\epsilon}=\\{\\mathbf{x}\\in\\mathbf{R}^{n}:\\xi_{j}-(1+\\epsilon)h\\leq x_{j}<\\xi_{j}+(1+\\epsilon)h,\\;1\\leq j\\leq n\\}.\n$$\n\nIt is clear that $m(Q^{\\epsilon})=(1+\\epsilon)^{n}m(Q)$ for any cube $Q$.\n\n10.47 Lemma. For each $\\xi\\in U$, let $T_{\\xi}$ be the affine map approximating $\\varphi$ near $\\xi$, i.e., $T_{\\xi}(\\mathbf{x})=\\varphi(\\xi)+\\varphi^{\\prime}(\\xi)(\\mathbf{x}-\\xi)$. For any compact subset $K$ of $U$ and any $\\epsilon>0$, there exists $\\delta=\\delta(K,\\epsilon)>0$ such that, for any cube $Q\\subset U$ with center $\\xi$ in $K$ and diameter $<\\delta$, we have\n\n$$\n\\varphi(Q)\\subset T_{\\xi}(Q^{\\epsilon}).\n$$\n\nProof. Let $\\begin{array}{r}{M=\\operatorname*{sup}_{\\xi\\in K}\\|(\\varphi^{\\prime})^{-1}(\\xi)\\|}\\end{array}$; since $K$ is compact and $\\varphi^{\\prime}$ is continuous, we know $M\\,<\\,\\infty$. The definition of the derivative of a mapping tells us that for any $\\eta>0$ there exists $\\delta\\,=\\,\\delta(\\xi,\\eta)\\,>\\,0$ such that $|\\varphi(\\mathbf{x})-T_{\\xi}(\\mathbf{x})|<\\eta|\\mathbf{x}-\\xi|$ whenever $0<|\\mathbf{x}-\\boldsymbol{\\xi}|<\\delta$. Since $K$ is compact, and $\\varphi^{\\prime}$ is continuous, we can choose $\\delta=\\delta(\\eta)$ so that this holds for every $\\xi\\in K$. $T_{\\xi}^{-1}\\mathbf{y}-T_{\\xi}^{-1}\\mathbf{z}=[\\varphi^{\\prime}(\\xi)]^{-1}(\\mathbf{y}-\\mathbf{z})$\n\n$$\n|T_{\\xi}^{-1}\\varphi(\\mathbf{x})-\\mathbf{x}|=|T_{\\xi}^{-1}[\\varphi(\\mathbf{x})-T_{\\xi}(\\mathbf{x})]|\\leq M\\eta|\\mathbf{x}-\\xi|,\n$$\n\nso that, if $\\eta>0$ is chosen sufficiently small $(\\eta\\,<\\,\\epsilon/(M\\sqrt{n})$ will do), we have $T_{\\xi}^{-1}\\varphi(\\mathbf{x})\\in Q^{\\epsilon}$, or equivalently, $\\varphi({\\bf x})\\in T_{\\xi}(Q^{\\epsilon})$, whenever $\\mathbf{x}\\in Q$ with $Q$ a cube of diameter less than $\\delta$ and center $\\xi\\in K$.\n\n10.48 Lemma. If $B$ is a Borel subset of $U$, then\n\n$$\nm{\\big(}\\varphi(B){\\big)}\\leq\\int_{B}|J_{\\varphi}|\\,d m.\n$$\n\nProof. Let $C$ be a compact subset of $\\varphi(B)$, and put $K=\\varphi^{-1}(C)$, so $K$ is a compact subset of $U$. Let $\\epsilon>0$. For each $i\\in\\mathbf{N}$, let $K_{i}=\\{{\\bf x}:\\rho({\\bf x},K)\\leq 1/i\\}$, where $\\rho(\\mathbf{x},K)=\\operatorname*{inf}\\left\\{|\\mathbf{x}-\\mathbf{y}|:\\mathbf{y}\\in K\\right\\}$. Then $K_{i}$ is compact, and for sufficiently large $i$, say $i\\geq i_{0}$, $K_{i}\\subset U$. We note that $K_{i+1}\\subset K_{i}$ for all $i$, and $\\textstyle\\bigcap_{i}K_{i}\\,=\\,K$. Since the function $\\textstyle A\\mapsto\\int_{A}|J_{\\varphi}|\\,d m$ is a measure, and",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "For any compact subset $K$ of $U$ and any $\\epsilon>0$, there exists $\\delta=\\delta(K,\\epsilon)>0$ such that, for any cube $Q\\subset U$ with center $\\xi$ in $K$ and diameter $<\\delta$, we have $\\varphi(Q)\\subset T_{\\xi}(Q^{\\epsilon}).$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/1996_Book_MathematicalAnalysis.pdf_255",
        "ID": "065a1e3f-aa81-415f-b803-a5e4194cfb47",
        "questions": "What property of the derivative of a mapping ensures the approximation of the function phi by the affine map T_xi within a delta range for the compact set K, and how is the compactness of K used in this context?",
        "answers": "Since $K$ is compact, and $\\varphi^{\\prime}$ is continuous, we can choose $\\delta=\\delta(\\eta)$ so that this holds for every $\\xi\\in K.",
        "context": "Proof. We observe that equation (10.3) is just the special case of equation (10.2) obtained by taking $f=\\mathbf{1}_{\\varphi(A)}$. We also observe that it suffices to consider Borel measurable functions, since every Lebesgue measurable function is almost everywhere equal to a Borel measurable function (Theorem 10.9).\n\nWe carry out the proof with a short sequence of lemmas. Let us introduce some terminology and notation. A cube with center $\\xi$ is a set of the form\n\n$$\nQ=\\{\\mathbf{x}\\in\\mathbf{R}^{n}:\\xi_{j}-h\\leq x_{j}<\\xi_{j}+h,\\;1\\leq j\\leq n\\}.\n$$\n\n(This describes a \u201chalf-open\u201d cube, which will be convenient for our purposes. Closed and open cubes are defined similarly.) If $Q$ is a cube with center $\\xi$, and $\\epsilon>0$, let $Q^{\\epsilon}$ denote the concentric cube with sides multiplied by $1+\\epsilon$; thus, for the cube $Q$ above,\n\n$$\nQ^{\\epsilon}=\\{\\mathbf{x}\\in\\mathbf{R}^{n}:\\xi_{j}-(1+\\epsilon)h\\leq x_{j}<\\xi_{j}+(1+\\epsilon)h,\\;1\\leq j\\leq n\\}.\n$$\n\nIt is clear that $m(Q^{\\epsilon})=(1+\\epsilon)^{n}m(Q)$ for any cube $Q$.\n\n10.47 Lemma. For each $\\xi\\in U$, let $T_{\\xi}$ be the affine map approximating $\\varphi$ near $\\xi$, i.e., $T_{\\xi}(\\mathbf{x})=\\varphi(\\xi)+\\varphi^{\\prime}(\\xi)(\\mathbf{x}-\\xi)$. For any compact subset $K$ of $U$ and any $\\epsilon>0$, there exists $\\delta=\\delta(K,\\epsilon)>0$ such that, for any cube $Q\\subset U$ with center $\\xi$ in $K$ and diameter $<\\delta$, we have\n\n$$\n\\varphi(Q)\\subset T_{\\xi}(Q^{\\epsilon}).\n$$\n\nProof. Let $\\begin{array}{r}{M=\\operatorname*{sup}_{\\xi\\in K}\\|(\\varphi^{\\prime})^{-1}(\\xi)\\|}\\end{array}$; since $K$ is compact and $\\varphi^{\\prime}$ is continuous, we know $M\\,<\\,\\infty$. The definition of the derivative of a mapping tells us that for any $\\eta>0$ there exists $\\delta\\,=\\,\\delta(\\xi,\\eta)\\,>\\,0$ such that $|\\varphi(\\mathbf{x})-T_{\\xi}(\\mathbf{x})|<\\eta|\\mathbf{x}-\\xi|$ whenever $0<|\\mathbf{x}-\\boldsymbol{\\xi}|<\\delta$. Since $K$ is compact, and $\\varphi^{\\prime}$ is continuous, we can choose $\\delta=\\delta(\\eta)$ so that this holds for every $\\xi\\in K$. $T_{\\xi}^{-1}\\mathbf{y}-T_{\\xi}^{-1}\\mathbf{z}=[\\varphi^{\\prime}(\\xi)]^{-1}(\\mathbf{y}-\\mathbf{z})$\n\n$$\n|T_{\\xi}^{-1}\\varphi(\\mathbf{x})-\\mathbf{x}|=|T_{\\xi}^{-1}[\\varphi(\\mathbf{x})-T_{\\xi}(\\mathbf{x})]|\\leq M\\eta|\\mathbf{x}-\\xi|,\n$$\n\nso that, if $\\eta>0$ is chosen sufficiently small $(\\eta\\,<\\,\\epsilon/(M\\sqrt{n})$ will do), we have $T_{\\xi}^{-1}\\varphi(\\mathbf{x})\\in Q^{\\epsilon}$, or equivalently, $\\varphi({\\bf x})\\in T_{\\xi}(Q^{\\epsilon})$, whenever $\\mathbf{x}\\in Q$ with $Q$ a cube of diameter less than $\\delta$ and center $\\xi\\in K$.\n\n10.48 Lemma. If $B$ is a Borel subset of $U$, then\n\n$$\nm{\\big(}\\varphi(B){\\big)}\\leq\\int_{B}|J_{\\varphi}|\\,d m.\n$$\n\nProof. Let $C$ be a compact subset of $\\varphi(B)$, and put $K=\\varphi^{-1}(C)$, so $K$ is a compact subset of $U$. Let $\\epsilon>0$. For each $i\\in\\mathbf{N}$, let $K_{i}=\\{{\\bf x}:\\rho({\\bf x},K)\\leq 1/i\\}$, where $\\rho(\\mathbf{x},K)=\\operatorname*{inf}\\left\\{|\\mathbf{x}-\\mathbf{y}|:\\mathbf{y}\\in K\\right\\}$. Then $K_{i}$ is compact, and for sufficiently large $i$, say $i\\geq i_{0}$, $K_{i}\\subset U$. We note that $K_{i+1}\\subset K_{i}$ for all $i$, and $\\textstyle\\bigcap_{i}K_{i}\\,=\\,K$. Since the function $\\textstyle A\\mapsto\\int_{A}|J_{\\varphi}|\\,d m$ is a measure, and",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Since $K$ is compact, and $\\varphi^{\\prime}$ is continuous, we can choose $\\delta=\\delta(\\eta)$ so that this holds for every $\\xi\\in K.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/1996_Book_MathematicalAnalysis.pdf_255",
        "ID": "066db941-5f7d-4765-831c-827638e4b0ca",
        "questions": "What is the expression for the volume of the concentric cube $Q^{\\epsilon}$ if $Q$ is a cube in $\\mathbf{R}^{n}$?",
        "answers": "$m(Q^{\\epsilon})=(1+\\epsilon)^{n}m(Q)$",
        "context": "Proof. We observe that equation (10.3) is just the special case of equation (10.2) obtained by taking $f=\\mathbf{1}_{\\varphi(A)}$. We also observe that it suffices to consider Borel measurable functions, since every Lebesgue measurable function is almost everywhere equal to a Borel measurable function (Theorem 10.9).\n\nWe carry out the proof with a short sequence of lemmas. Let us introduce some terminology and notation. A cube with center $\\xi$ is a set of the form\n\n$$\nQ=\\{\\mathbf{x}\\in\\mathbf{R}^{n}:\\xi_{j}-h\\leq x_{j}<\\xi_{j}+h,\\;1\\leq j\\leq n\\}.\n$$\n\n(This describes a \u201chalf-open\u201d cube, which will be convenient for our purposes. Closed and open cubes are defined similarly.) If $Q$ is a cube with center $\\xi$, and $\\epsilon>0$, let $Q^{\\epsilon}$ denote the concentric cube with sides multiplied by $1+\\epsilon$; thus, for the cube $Q$ above,\n\n$$\nQ^{\\epsilon}=\\{\\mathbf{x}\\in\\mathbf{R}^{n}:\\xi_{j}-(1+\\epsilon)h\\leq x_{j}<\\xi_{j}+(1+\\epsilon)h,\\;1\\leq j\\leq n\\}.\n$$\n\nIt is clear that $m(Q^{\\epsilon})=(1+\\epsilon)^{n}m(Q)$ for any cube $Q$.\n\n10.47 Lemma. For each $\\xi\\in U$, let $T_{\\xi}$ be the affine map approximating $\\varphi$ near $\\xi$, i.e., $T_{\\xi}(\\mathbf{x})=\\varphi(\\xi)+\\varphi^{\\prime}(\\xi)(\\mathbf{x}-\\xi)$. For any compact subset $K$ of $U$ and any $\\epsilon>0$, there exists $\\delta=\\delta(K,\\epsilon)>0$ such that, for any cube $Q\\subset U$ with center $\\xi$ in $K$ and diameter $<\\delta$, we have\n\n$$\n\\varphi(Q)\\subset T_{\\xi}(Q^{\\epsilon}).\n$$\n\nProof. Let $\\begin{array}{r}{M=\\operatorname*{sup}_{\\xi\\in K}\\|(\\varphi^{\\prime})^{-1}(\\xi)\\|}\\end{array}$; since $K$ is compact and $\\varphi^{\\prime}$ is continuous, we know $M\\,<\\,\\infty$. The definition of the derivative of a mapping tells us that for any $\\eta>0$ there exists $\\delta\\,=\\,\\delta(\\xi,\\eta)\\,>\\,0$ such that $|\\varphi(\\mathbf{x})-T_{\\xi}(\\mathbf{x})|<\\eta|\\mathbf{x}-\\xi|$ whenever $0<|\\mathbf{x}-\\boldsymbol{\\xi}|<\\delta$. Since $K$ is compact, and $\\varphi^{\\prime}$ is continuous, we can choose $\\delta=\\delta(\\eta)$ so that this holds for every $\\xi\\in K$. $T_{\\xi}^{-1}\\mathbf{y}-T_{\\xi}^{-1}\\mathbf{z}=[\\varphi^{\\prime}(\\xi)]^{-1}(\\mathbf{y}-\\mathbf{z})$\n\n$$\n|T_{\\xi}^{-1}\\varphi(\\mathbf{x})-\\mathbf{x}|=|T_{\\xi}^{-1}[\\varphi(\\mathbf{x})-T_{\\xi}(\\mathbf{x})]|\\leq M\\eta|\\mathbf{x}-\\xi|,\n$$\n\nso that, if $\\eta>0$ is chosen sufficiently small $(\\eta\\,<\\,\\epsilon/(M\\sqrt{n})$ will do), we have $T_{\\xi}^{-1}\\varphi(\\mathbf{x})\\in Q^{\\epsilon}$, or equivalently, $\\varphi({\\bf x})\\in T_{\\xi}(Q^{\\epsilon})$, whenever $\\mathbf{x}\\in Q$ with $Q$ a cube of diameter less than $\\delta$ and center $\\xi\\in K$.\n\n10.48 Lemma. If $B$ is a Borel subset of $U$, then\n\n$$\nm{\\big(}\\varphi(B){\\big)}\\leq\\int_{B}|J_{\\varphi}|\\,d m.\n$$\n\nProof. Let $C$ be a compact subset of $\\varphi(B)$, and put $K=\\varphi^{-1}(C)$, so $K$ is a compact subset of $U$. Let $\\epsilon>0$. For each $i\\in\\mathbf{N}$, let $K_{i}=\\{{\\bf x}:\\rho({\\bf x},K)\\leq 1/i\\}$, where $\\rho(\\mathbf{x},K)=\\operatorname*{inf}\\left\\{|\\mathbf{x}-\\mathbf{y}|:\\mathbf{y}\\in K\\right\\}$. Then $K_{i}$ is compact, and for sufficiently large $i$, say $i\\geq i_{0}$, $K_{i}\\subset U$. We note that $K_{i+1}\\subset K_{i}$ for all $i$, and $\\textstyle\\bigcap_{i}K_{i}\\,=\\,K$. Since the function $\\textstyle A\\mapsto\\int_{A}|J_{\\varphi}|\\,d m$ is a measure, and",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "It is clear that $m(Q^{\\epsilon})=(1+\\epsilon)^{n}m(Q)$ for any cube $Q$.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/1996_Book_MathematicalAnalysis.pdf_255",
        "ID": "066dee1e-a16b-447d-9bab-bdab0e1cae7a",
        "questions": "According to Lemma 10.48, how is the measure of $\\varphi(B)$ related to the integral over $B$ with the Jacobian $|J_{\\varphi}|$?",
        "answers": "$m{\\big(}\\varphi(B){\\big)}\\leq\\int_{B}|J_{\\varphi}|\\,d m$",
        "context": "Proof. We observe that equation (10.3) is just the special case of equation (10.2) obtained by taking $f=\\mathbf{1}_{\\varphi(A)}$. We also observe that it suffices to consider Borel measurable functions, since every Lebesgue measurable function is almost everywhere equal to a Borel measurable function (Theorem 10.9).\n\nWe carry out the proof with a short sequence of lemmas. Let us introduce some terminology and notation. A cube with center $\\xi$ is a set of the form\n\n$$\nQ=\\{\\mathbf{x}\\in\\mathbf{R}^{n}:\\xi_{j}-h\\leq x_{j}<\\xi_{j}+h,\\;1\\leq j\\leq n\\}.\n$$\n\n(This describes a \u201chalf-open\u201d cube, which will be convenient for our purposes. Closed and open cubes are defined similarly.) If $Q$ is a cube with center $\\xi$, and $\\epsilon>0$, let $Q^{\\epsilon}$ denote the concentric cube with sides multiplied by $1+\\epsilon$; thus, for the cube $Q$ above,\n\n$$\nQ^{\\epsilon}=\\{\\mathbf{x}\\in\\mathbf{R}^{n}:\\xi_{j}-(1+\\epsilon)h\\leq x_{j}<\\xi_{j}+(1+\\epsilon)h,\\;1\\leq j\\leq n\\}.\n$$\n\nIt is clear that $m(Q^{\\epsilon})=(1+\\epsilon)^{n}m(Q)$ for any cube $Q$.\n\n10.47 Lemma. For each $\\xi\\in U$, let $T_{\\xi}$ be the affine map approximating $\\varphi$ near $\\xi$, i.e., $T_{\\xi}(\\mathbf{x})=\\varphi(\\xi)+\\varphi^{\\prime}(\\xi)(\\mathbf{x}-\\xi)$. For any compact subset $K$ of $U$ and any $\\epsilon>0$, there exists $\\delta=\\delta(K,\\epsilon)>0$ such that, for any cube $Q\\subset U$ with center $\\xi$ in $K$ and diameter $<\\delta$, we have\n\n$$\n\\varphi(Q)\\subset T_{\\xi}(Q^{\\epsilon}).\n$$\n\nProof. Let $\\begin{array}{r}{M=\\operatorname*{sup}_{\\xi\\in K}\\|(\\varphi^{\\prime})^{-1}(\\xi)\\|}\\end{array}$; since $K$ is compact and $\\varphi^{\\prime}$ is continuous, we know $M\\,<\\,\\infty$. The definition of the derivative of a mapping tells us that for any $\\eta>0$ there exists $\\delta\\,=\\,\\delta(\\xi,\\eta)\\,>\\,0$ such that $|\\varphi(\\mathbf{x})-T_{\\xi}(\\mathbf{x})|<\\eta|\\mathbf{x}-\\xi|$ whenever $0<|\\mathbf{x}-\\boldsymbol{\\xi}|<\\delta$. Since $K$ is compact, and $\\varphi^{\\prime}$ is continuous, we can choose $\\delta=\\delta(\\eta)$ so that this holds for every $\\xi\\in K$. $T_{\\xi}^{-1}\\mathbf{y}-T_{\\xi}^{-1}\\mathbf{z}=[\\varphi^{\\prime}(\\xi)]^{-1}(\\mathbf{y}-\\mathbf{z})$\n\n$$\n|T_{\\xi}^{-1}\\varphi(\\mathbf{x})-\\mathbf{x}|=|T_{\\xi}^{-1}[\\varphi(\\mathbf{x})-T_{\\xi}(\\mathbf{x})]|\\leq M\\eta|\\mathbf{x}-\\xi|,\n$$\n\nso that, if $\\eta>0$ is chosen sufficiently small $(\\eta\\,<\\,\\epsilon/(M\\sqrt{n})$ will do), we have $T_{\\xi}^{-1}\\varphi(\\mathbf{x})\\in Q^{\\epsilon}$, or equivalently, $\\varphi({\\bf x})\\in T_{\\xi}(Q^{\\epsilon})$, whenever $\\mathbf{x}\\in Q$ with $Q$ a cube of diameter less than $\\delta$ and center $\\xi\\in K$.\n\n10.48 Lemma. If $B$ is a Borel subset of $U$, then\n\n$$\nm{\\big(}\\varphi(B){\\big)}\\leq\\int_{B}|J_{\\varphi}|\\,d m.\n$$\n\nProof. Let $C$ be a compact subset of $\\varphi(B)$, and put $K=\\varphi^{-1}(C)$, so $K$ is a compact subset of $U$. Let $\\epsilon>0$. For each $i\\in\\mathbf{N}$, let $K_{i}=\\{{\\bf x}:\\rho({\\bf x},K)\\leq 1/i\\}$, where $\\rho(\\mathbf{x},K)=\\operatorname*{inf}\\left\\{|\\mathbf{x}-\\mathbf{y}|:\\mathbf{y}\\in K\\right\\}$. Then $K_{i}$ is compact, and for sufficiently large $i$, say $i\\geq i_{0}$, $K_{i}\\subset U$. We note that $K_{i+1}\\subset K_{i}$ for all $i$, and $\\textstyle\\bigcap_{i}K_{i}\\,=\\,K$. Since the function $\\textstyle A\\mapsto\\int_{A}|J_{\\varphi}|\\,d m$ is a measure, and",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "If $B$ is a Borel subset of $U$, then $m{\\big(}\\varphi(B){\\big)}\\leq\\int_{B}|J_{\\varphi}|\\,d m.$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/1996_Book_MathematicalAnalysis.pdf_255",
        "ID": "066df3fe-8a07-4105-9547-0e5505adc80b",
        "questions": "What is the condition for the set $\\varphi(Q)$ to be contained in the set $T_{\\xi}(Q^{\\epsilon})$ involving the cubic subset $Q$ and mapping $T_{\\xi}$?",
        "answers": "$\\varphi(Q)\\subset T_{\\xi}(Q^{\\epsilon})$",
        "context": "Proof. We observe that equation (10.3) is just the special case of equation (10.2) obtained by taking $f=\\mathbf{1}_{\\varphi(A)}$. We also observe that it suffices to consider Borel measurable functions, since every Lebesgue measurable function is almost everywhere equal to a Borel measurable function (Theorem 10.9).\n\nWe carry out the proof with a short sequence of lemmas. Let us introduce some terminology and notation. A cube with center $\\xi$ is a set of the form\n\n$$\nQ=\\{\\mathbf{x}\\in\\mathbf{R}^{n}:\\xi_{j}-h\\leq x_{j}<\\xi_{j}+h,\\;1\\leq j\\leq n\\}.\n$$\n\n(This describes a \u201chalf-open\u201d cube, which will be convenient for our purposes. Closed and open cubes are defined similarly.) If $Q$ is a cube with center $\\xi$, and $\\epsilon>0$, let $Q^{\\epsilon}$ denote the concentric cube with sides multiplied by $1+\\epsilon$; thus, for the cube $Q$ above,\n\n$$\nQ^{\\epsilon}=\\{\\mathbf{x}\\in\\mathbf{R}^{n}:\\xi_{j}-(1+\\epsilon)h\\leq x_{j}<\\xi_{j}+(1+\\epsilon)h,\\;1\\leq j\\leq n\\}.\n$$\n\nIt is clear that $m(Q^{\\epsilon})=(1+\\epsilon)^{n}m(Q)$ for any cube $Q$.\n\n10.47 Lemma. For each $\\xi\\in U$, let $T_{\\xi}$ be the affine map approximating $\\varphi$ near $\\xi$, i.e., $T_{\\xi}(\\mathbf{x})=\\varphi(\\xi)+\\varphi^{\\prime}(\\xi)(\\mathbf{x}-\\xi)$. For any compact subset $K$ of $U$ and any $\\epsilon>0$, there exists $\\delta=\\delta(K,\\epsilon)>0$ such that, for any cube $Q\\subset U$ with center $\\xi$ in $K$ and diameter $<\\delta$, we have\n\n$$\n\\varphi(Q)\\subset T_{\\xi}(Q^{\\epsilon}).\n$$\n\nProof. Let $\\begin{array}{r}{M=\\operatorname*{sup}_{\\xi\\in K}\\|(\\varphi^{\\prime})^{-1}(\\xi)\\|}\\end{array}$; since $K$ is compact and $\\varphi^{\\prime}$ is continuous, we know $M\\,<\\,\\infty$. The definition of the derivative of a mapping tells us that for any $\\eta>0$ there exists $\\delta\\,=\\,\\delta(\\xi,\\eta)\\,>\\,0$ such that $|\\varphi(\\mathbf{x})-T_{\\xi}(\\mathbf{x})|<\\eta|\\mathbf{x}-\\xi|$ whenever $0<|\\mathbf{x}-\\boldsymbol{\\xi}|<\\delta$. Since $K$ is compact, and $\\varphi^{\\prime}$ is continuous, we can choose $\\delta=\\delta(\\eta)$ so that this holds for every $\\xi\\in K$. $T_{\\xi}^{-1}\\mathbf{y}-T_{\\xi}^{-1}\\mathbf{z}=[\\varphi^{\\prime}(\\xi)]^{-1}(\\mathbf{y}-\\mathbf{z})$\n\n$$\n|T_{\\xi}^{-1}\\varphi(\\mathbf{x})-\\mathbf{x}|=|T_{\\xi}^{-1}[\\varphi(\\mathbf{x})-T_{\\xi}(\\mathbf{x})]|\\leq M\\eta|\\mathbf{x}-\\xi|,\n$$\n\nso that, if $\\eta>0$ is chosen sufficiently small $(\\eta\\,<\\,\\epsilon/(M\\sqrt{n})$ will do), we have $T_{\\xi}^{-1}\\varphi(\\mathbf{x})\\in Q^{\\epsilon}$, or equivalently, $\\varphi({\\bf x})\\in T_{\\xi}(Q^{\\epsilon})$, whenever $\\mathbf{x}\\in Q$ with $Q$ a cube of diameter less than $\\delta$ and center $\\xi\\in K$.\n\n10.48 Lemma. If $B$ is a Borel subset of $U$, then\n\n$$\nm{\\big(}\\varphi(B){\\big)}\\leq\\int_{B}|J_{\\varphi}|\\,d m.\n$$\n\nProof. Let $C$ be a compact subset of $\\varphi(B)$, and put $K=\\varphi^{-1}(C)$, so $K$ is a compact subset of $U$. Let $\\epsilon>0$. For each $i\\in\\mathbf{N}$, let $K_{i}=\\{{\\bf x}:\\rho({\\bf x},K)\\leq 1/i\\}$, where $\\rho(\\mathbf{x},K)=\\operatorname*{inf}\\left\\{|\\mathbf{x}-\\mathbf{y}|:\\mathbf{y}\\in K\\right\\}$. Then $K_{i}$ is compact, and for sufficiently large $i$, say $i\\geq i_{0}$, $K_{i}\\subset U$. We note that $K_{i+1}\\subset K_{i}$ for all $i$, and $\\textstyle\\bigcap_{i}K_{i}\\,=\\,K$. Since the function $\\textstyle A\\mapsto\\int_{A}|J_{\\varphi}|\\,d m$ is a measure, and",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "For any cube $Q\\subset U$ with center $\\xi$ in $K$ and diameter $<\\delta$, we have $\\varphi(Q)\\subset T_{\\xi}(Q^{\\epsilon}).$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/textbook_needrop_en_2290",
        "ID": "06714938-04fe-473d-a61c-ec19fff83cec",
        "questions": "Does the problem imply that $w_{\\lambda}$ achieves its maximum on the boundary $\\partial\\Sigma_{\\lambda}\\cap\\Omega$ within the region $\\Sigma_{\\lambda}$ for any $\\lambda$ in the interval (0, a)?",
        "answers": "Yes",
        "context": "We need to show $w_{\\lambda}<0$ in $\\Sigma_{\\lambda}$ for any $\\lambda\\in(0,a)$. This implies in particular that $w_{\\lambda}$ assumes along $\\partial\\Sigma_{\\lambda}\\cap\\Omega$ its maximum in $\\Sigma_{\\lambda}$. By Theorem 2.5 (the Hopf lemma) we have for any such $\\lambda\\in(0,a)$\n\n$$\n\\left.D_{x_{1}}w_{\\lambda}\\right|_{x_{1}=\\lambda}=2\\left.D_{x_{1}}u\\right|_{x_{1}=\\lambda}<0.\n$$\n\nFor any $\\lambda$ close to $a$, we have $w_{\\lambda}<0$ by Proposition 2.13 (the maximum principle for a narrow domain) or Theorem 2.32. Let $(\\lambda_{0},a)$ be the largest interval of values of $\\lambda$ such that $w_{\\lambda}<0$ in $\\Sigma_{\\lambda}$. We want to show $\\lambda_{0}=0$. If $\\lambda_{0}>0$ by continuity, $w_{\\lambda_{0}}\\leq0$ in $\\Sigma_{\\lambda_{0}}$ and $w_{\\lambda_{0}}\\neq0$ on $\\partial\\Sigma_{\\lambda_{0}}$. Then Theorem 2.7 (the strong maximum principle) implies $w_{\\lambda_{0}}<0$ in $\\Sigma_{\\lambda_{0}}$. We will show that for any small $\\varepsilon>0$\n\n$$\nw_{\\lambda_{0}-\\varepsilon}<0\\quad\\mathrm{in}\\ \\Sigma_{\\lambda_{0}-\\varepsilon}.\n$$\n\nFix $\\delta>0$ (to be determined). Let $K$ be a closed subset in $\\Sigma_{\\lambda_{0}}$ such that $\\vert\\Sigma_{\\lambda_{0}}\\ \\rangle$ $\\begin{array}{r}{|K|<\\frac{\\delta}{2}}\\end{array}$. The fact that $w_{\\lambda_{0}}<0$ in $\\Sigma_{\\lambda_{0}}$ implies\n\n$$\nw_{\\lambda_{0}}(x)\\leq-\\eta<0\\quad\\mathrm{for\\;any}\\;x\\in K.\n$$\n\nBy continuity we have\n\n$$\nw_{\\lambda_{0}-\\varepsilon}<0\\quad\\mathrm{in}\\;K.\n$$\n\nFor $\\varepsilon>0$ small, $\\begin{array}{r}{|\\Sigma_{\\lambda_{0}-\\varepsilon}\\setminus K|<\\delta}\\end{array}$. We choose $\\delta$ in such a way that we may apply Theorem 2.32 (the maximum principle for a domain with small volume) to $w_{\\lambda_{0}-\\varepsilon}$ in $\\Sigma_{\\lambda_{0}-\\varepsilon}\\setminus K$. Hence we get\n\n$$\nw_{\\lambda_{0}-\\varepsilon}(x)\\leq0\\quad\\mathrm{in~}\\Sigma_{\\lambda_{0}-\\varepsilon}\\setminus K\n$$\n\nand then by Theorem 2.10\n\n$$\nw_{\\lambda_{0}-\\varepsilon}(x)<0\\quad\\mathrm{in~}\\Sigma_{\\lambda_{0}-\\varepsilon}\\setminus K.\n$$\n\nTherefore we obtain for any small $\\varepsilon>0$\n\n$$\nw_{\\lambda_{0}-\\varepsilon}(x)<0\\quad\\mathrm{in~}\\Sigma_{\\lambda_{0}-\\varepsilon}.\n$$\n\nThis contradicts the choice of $\\lambda_{0}$.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Yes/No",
        "evidence_source": "text",
        "evidence_context": "This implies in particular that $w_{\\lambda}$ assumes along $\\partial\\Sigma_{\\lambda}\\cap\\Omega$ its maximum in $\\Sigma_{\\lambda}$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/textbook_needrop_en_2290",
        "ID": "0677063d-f5f2-4759-a025-44a61bcb34b5",
        "questions": "What theorem provides that $D_{x_{1}}w_{\\lambda}$ at $x_{1}=\\lambda$ is negative for any $\\lambda$ in the interval (0, a)?",
        "answers": "Theorem 2.5 (the Hopf lemma)",
        "context": "We need to show $w_{\\lambda}<0$ in $\\Sigma_{\\lambda}$ for any $\\lambda\\in(0,a)$. This implies in particular that $w_{\\lambda}$ assumes along $\\partial\\Sigma_{\\lambda}\\cap\\Omega$ its maximum in $\\Sigma_{\\lambda}$. By Theorem 2.5 (the Hopf lemma) we have for any such $\\lambda\\in(0,a)$\n\n$$\n\\left.D_{x_{1}}w_{\\lambda}\\right|_{x_{1}=\\lambda}=2\\left.D_{x_{1}}u\\right|_{x_{1}=\\lambda}<0.\n$$\n\nFor any $\\lambda$ close to $a$, we have $w_{\\lambda}<0$ by Proposition 2.13 (the maximum principle for a narrow domain) or Theorem 2.32. Let $(\\lambda_{0},a)$ be the largest interval of values of $\\lambda$ such that $w_{\\lambda}<0$ in $\\Sigma_{\\lambda}$. We want to show $\\lambda_{0}=0$. If $\\lambda_{0}>0$ by continuity, $w_{\\lambda_{0}}\\leq0$ in $\\Sigma_{\\lambda_{0}}$ and $w_{\\lambda_{0}}\\neq0$ on $\\partial\\Sigma_{\\lambda_{0}}$. Then Theorem 2.7 (the strong maximum principle) implies $w_{\\lambda_{0}}<0$ in $\\Sigma_{\\lambda_{0}}$. We will show that for any small $\\varepsilon>0$\n\n$$\nw_{\\lambda_{0}-\\varepsilon}<0\\quad\\mathrm{in}\\ \\Sigma_{\\lambda_{0}-\\varepsilon}.\n$$\n\nFix $\\delta>0$ (to be determined). Let $K$ be a closed subset in $\\Sigma_{\\lambda_{0}}$ such that $\\vert\\Sigma_{\\lambda_{0}}\\ \\rangle$ $\\begin{array}{r}{|K|<\\frac{\\delta}{2}}\\end{array}$. The fact that $w_{\\lambda_{0}}<0$ in $\\Sigma_{\\lambda_{0}}$ implies\n\n$$\nw_{\\lambda_{0}}(x)\\leq-\\eta<0\\quad\\mathrm{for\\;any}\\;x\\in K.\n$$\n\nBy continuity we have\n\n$$\nw_{\\lambda_{0}-\\varepsilon}<0\\quad\\mathrm{in}\\;K.\n$$\n\nFor $\\varepsilon>0$ small, $\\begin{array}{r}{|\\Sigma_{\\lambda_{0}-\\varepsilon}\\setminus K|<\\delta}\\end{array}$. We choose $\\delta$ in such a way that we may apply Theorem 2.32 (the maximum principle for a domain with small volume) to $w_{\\lambda_{0}-\\varepsilon}$ in $\\Sigma_{\\lambda_{0}-\\varepsilon}\\setminus K$. Hence we get\n\n$$\nw_{\\lambda_{0}-\\varepsilon}(x)\\leq0\\quad\\mathrm{in~}\\Sigma_{\\lambda_{0}-\\varepsilon}\\setminus K\n$$\n\nand then by Theorem 2.10\n\n$$\nw_{\\lambda_{0}-\\varepsilon}(x)<0\\quad\\mathrm{in~}\\Sigma_{\\lambda_{0}-\\varepsilon}\\setminus K.\n$$\n\nTherefore we obtain for any small $\\varepsilon>0$\n\n$$\nw_{\\lambda_{0}-\\varepsilon}(x)<0\\quad\\mathrm{in~}\\Sigma_{\\lambda_{0}-\\varepsilon}.\n$$\n\nThis contradicts the choice of $\\lambda_{0}$.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "By Theorem 2.5 (the Hopf lemma) we have for any such $\\lambda\\in(0,a)$ $$ \\left.D_{x_{1}}w_{\\lambda}\right|_{x_{1}=\\lambda}=2\\left.D_{x_{1}}u\right|_{x_{1}=\\lambda}<0.$$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/textbook_needrop_en_2290",
        "ID": "067fece7-f1ff-46dc-b45a-a79bd855fb35",
        "questions": "For $w_{\\lambda_{0}}(x)\\leq-\\eta<0$ for any $x$ in a closed subset $K$ within $\\Sigma_{\\lambda_{0}}$, what condition on $K$ is necessary regarding its size in relation to $\\delta$?",
        "answers": "|K|<\frac{\\delta}{2}",
        "context": "We need to show $w_{\\lambda}<0$ in $\\Sigma_{\\lambda}$ for any $\\lambda\\in(0,a)$. This implies in particular that $w_{\\lambda}$ assumes along $\\partial\\Sigma_{\\lambda}\\cap\\Omega$ its maximum in $\\Sigma_{\\lambda}$. By Theorem 2.5 (the Hopf lemma) we have for any such $\\lambda\\in(0,a)$\n\n$$\n\\left.D_{x_{1}}w_{\\lambda}\\right|_{x_{1}=\\lambda}=2\\left.D_{x_{1}}u\\right|_{x_{1}=\\lambda}<0.\n$$\n\nFor any $\\lambda$ close to $a$, we have $w_{\\lambda}<0$ by Proposition 2.13 (the maximum principle for a narrow domain) or Theorem 2.32. Let $(\\lambda_{0},a)$ be the largest interval of values of $\\lambda$ such that $w_{\\lambda}<0$ in $\\Sigma_{\\lambda}$. We want to show $\\lambda_{0}=0$. If $\\lambda_{0}>0$ by continuity, $w_{\\lambda_{0}}\\leq0$ in $\\Sigma_{\\lambda_{0}}$ and $w_{\\lambda_{0}}\\neq0$ on $\\partial\\Sigma_{\\lambda_{0}}$. Then Theorem 2.7 (the strong maximum principle) implies $w_{\\lambda_{0}}<0$ in $\\Sigma_{\\lambda_{0}}$. We will show that for any small $\\varepsilon>0$\n\n$$\nw_{\\lambda_{0}-\\varepsilon}<0\\quad\\mathrm{in}\\ \\Sigma_{\\lambda_{0}-\\varepsilon}.\n$$\n\nFix $\\delta>0$ (to be determined). Let $K$ be a closed subset in $\\Sigma_{\\lambda_{0}}$ such that $\\vert\\Sigma_{\\lambda_{0}}\\ \\rangle$ $\\begin{array}{r}{|K|<\\frac{\\delta}{2}}\\end{array}$. The fact that $w_{\\lambda_{0}}<0$ in $\\Sigma_{\\lambda_{0}}$ implies\n\n$$\nw_{\\lambda_{0}}(x)\\leq-\\eta<0\\quad\\mathrm{for\\;any}\\;x\\in K.\n$$\n\nBy continuity we have\n\n$$\nw_{\\lambda_{0}-\\varepsilon}<0\\quad\\mathrm{in}\\;K.\n$$\n\nFor $\\varepsilon>0$ small, $\\begin{array}{r}{|\\Sigma_{\\lambda_{0}-\\varepsilon}\\setminus K|<\\delta}\\end{array}$. We choose $\\delta$ in such a way that we may apply Theorem 2.32 (the maximum principle for a domain with small volume) to $w_{\\lambda_{0}-\\varepsilon}$ in $\\Sigma_{\\lambda_{0}-\\varepsilon}\\setminus K$. Hence we get\n\n$$\nw_{\\lambda_{0}-\\varepsilon}(x)\\leq0\\quad\\mathrm{in~}\\Sigma_{\\lambda_{0}-\\varepsilon}\\setminus K\n$$\n\nand then by Theorem 2.10\n\n$$\nw_{\\lambda_{0}-\\varepsilon}(x)<0\\quad\\mathrm{in~}\\Sigma_{\\lambda_{0}-\\varepsilon}\\setminus K.\n$$\n\nTherefore we obtain for any small $\\varepsilon>0$\n\n$$\nw_{\\lambda_{0}-\\varepsilon}(x)<0\\quad\\mathrm{in~}\\Sigma_{\\lambda_{0}-\\varepsilon}.\n$$\n\nThis contradicts the choice of $\\lambda_{0}$.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Fix $\\delta>0$ (to be determined). Let $K$ be a closed subset in $\\Sigma_{\\lambda_{0}}$ such that $\u000bert\\Sigma_{\\lambda_{0}}\\ \rangle$ $\begin{array}{r}{|K|<\frac{\\delta}{2}}\\end{array}$. The fact that $w_{\\lambda_{0}}<0$ in $\\Sigma_{\\lambda_{0}}$ implies $$w_{\\lambda_{0}}(x)\\leq-\\eta<0\\quad\\mathrm{for\\;any}\\;x\\in K.$$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/textbook_needrop_en_2290",
        "ID": "06999e1e-2b02-437e-a2cd-159aebba80d2",
        "questions": "What is the condition for $D_{x_{1}}w_{\\lambda}$ at $x_{1}=\\lambda$ according to Theorem 2.5 (the Hopf lemma)?",
        "answers": "$\\left.D_{x_{1}}w_{\\lambda}\\right|_{x_{1}=\\lambda}=2\\left.D_{x_{1}}u\\right|_{x_{1}=\\lambda}<0.$",
        "context": "We need to show $w_{\\lambda}<0$ in $\\Sigma_{\\lambda}$ for any $\\lambda\\in(0,a)$. This implies in particular that $w_{\\lambda}$ assumes along $\\partial\\Sigma_{\\lambda}\\cap\\Omega$ its maximum in $\\Sigma_{\\lambda}$. By Theorem 2.5 (the Hopf lemma) we have for any such $\\lambda\\in(0,a)$\n\n$$\n\\left.D_{x_{1}}w_{\\lambda}\\right|_{x_{1}=\\lambda}=2\\left.D_{x_{1}}u\\right|_{x_{1}=\\lambda}<0.\n$$\n\nFor any $\\lambda$ close to $a$, we have $w_{\\lambda}<0$ by Proposition 2.13 (the maximum principle for a narrow domain) or Theorem 2.32. Let $(\\lambda_{0},a)$ be the largest interval of values of $\\lambda$ such that $w_{\\lambda}<0$ in $\\Sigma_{\\lambda}$. We want to show $\\lambda_{0}=0$. If $\\lambda_{0}>0$ by continuity, $w_{\\lambda_{0}}\\leq0$ in $\\Sigma_{\\lambda_{0}}$ and $w_{\\lambda_{0}}\\neq0$ on $\\partial\\Sigma_{\\lambda_{0}}$. Then Theorem 2.7 (the strong maximum principle) implies $w_{\\lambda_{0}}<0$ in $\\Sigma_{\\lambda_{0}}$. We will show that for any small $\\varepsilon>0$\n\n$$\nw_{\\lambda_{0}-\\varepsilon}<0\\quad\\mathrm{in}\\ \\Sigma_{\\lambda_{0}-\\varepsilon}.\n$$\n\nFix $\\delta>0$ (to be determined). Let $K$ be a closed subset in $\\Sigma_{\\lambda_{0}}$ such that $\\vert\\Sigma_{\\lambda_{0}}\\ \\rangle$ $\\begin{array}{r}{|K|<\\frac{\\delta}{2}}\\end{array}$. The fact that $w_{\\lambda_{0}}<0$ in $\\Sigma_{\\lambda_{0}}$ implies\n\n$$\nw_{\\lambda_{0}}(x)\\leq-\\eta<0\\quad\\mathrm{for\\;any}\\;x\\in K.\n$$\n\nBy continuity we have\n\n$$\nw_{\\lambda_{0}-\\varepsilon}<0\\quad\\mathrm{in}\\;K.\n$$\n\nFor $\\varepsilon>0$ small, $\\begin{array}{r}{|\\Sigma_{\\lambda_{0}-\\varepsilon}\\setminus K|<\\delta}\\end{array}$. We choose $\\delta$ in such a way that we may apply Theorem 2.32 (the maximum principle for a domain with small volume) to $w_{\\lambda_{0}-\\varepsilon}$ in $\\Sigma_{\\lambda_{0}-\\varepsilon}\\setminus K$. Hence we get\n\n$$\nw_{\\lambda_{0}-\\varepsilon}(x)\\leq0\\quad\\mathrm{in~}\\Sigma_{\\lambda_{0}-\\varepsilon}\\setminus K\n$$\n\nand then by Theorem 2.10\n\n$$\nw_{\\lambda_{0}-\\varepsilon}(x)<0\\quad\\mathrm{in~}\\Sigma_{\\lambda_{0}-\\varepsilon}\\setminus K.\n$$\n\nTherefore we obtain for any small $\\varepsilon>0$\n\n$$\nw_{\\lambda_{0}-\\varepsilon}(x)<0\\quad\\mathrm{in~}\\Sigma_{\\lambda_{0}-\\varepsilon}.\n$$\n\nThis contradicts the choice of $\\lambda_{0}$.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "By Theorem 2.5 (the Hopf lemma) we have for any such $\\lambda\\in(0,a) \\left.D_{x_{1}}w_{\\lambda}\\right|_{x_{1}=\\lambda}=2\\left.D_{x_{1}}u\\right|_{x_{1}=\\lambda}<0.$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/textbook_needrop_en_2290",
        "ID": "06a8e22f-d57c-4f0d-9db3-466d1ba6cc61",
        "questions": "What inequality must $w_{\\lambda_{0}}(x)$ satisfy in $K$ when $w_{\\lambda_{0}} < 0$ in $\\Sigma_{\\lambda_0}$?",
        "answers": "$w_{\\lambda_{0}}(x)\\leq-\\eta<0\\quad\\mathrm{for\\;any}\\;x\\in K.$",
        "context": "We need to show $w_{\\lambda}<0$ in $\\Sigma_{\\lambda}$ for any $\\lambda\\in(0,a)$. This implies in particular that $w_{\\lambda}$ assumes along $\\partial\\Sigma_{\\lambda}\\cap\\Omega$ its maximum in $\\Sigma_{\\lambda}$. By Theorem 2.5 (the Hopf lemma) we have for any such $\\lambda\\in(0,a)$\n\n$$\n\\left.D_{x_{1}}w_{\\lambda}\\right|_{x_{1}=\\lambda}=2\\left.D_{x_{1}}u\\right|_{x_{1}=\\lambda}<0.\n$$\n\nFor any $\\lambda$ close to $a$, we have $w_{\\lambda}<0$ by Proposition 2.13 (the maximum principle for a narrow domain) or Theorem 2.32. Let $(\\lambda_{0},a)$ be the largest interval of values of $\\lambda$ such that $w_{\\lambda}<0$ in $\\Sigma_{\\lambda}$. We want to show $\\lambda_{0}=0$. If $\\lambda_{0}>0$ by continuity, $w_{\\lambda_{0}}\\leq0$ in $\\Sigma_{\\lambda_{0}}$ and $w_{\\lambda_{0}}\\neq0$ on $\\partial\\Sigma_{\\lambda_{0}}$. Then Theorem 2.7 (the strong maximum principle) implies $w_{\\lambda_{0}}<0$ in $\\Sigma_{\\lambda_{0}}$. We will show that for any small $\\varepsilon>0$\n\n$$\nw_{\\lambda_{0}-\\varepsilon}<0\\quad\\mathrm{in}\\ \\Sigma_{\\lambda_{0}-\\varepsilon}.\n$$\n\nFix $\\delta>0$ (to be determined). Let $K$ be a closed subset in $\\Sigma_{\\lambda_{0}}$ such that $\\vert\\Sigma_{\\lambda_{0}}\\ \\rangle$ $\\begin{array}{r}{|K|<\\frac{\\delta}{2}}\\end{array}$. The fact that $w_{\\lambda_{0}}<0$ in $\\Sigma_{\\lambda_{0}}$ implies\n\n$$\nw_{\\lambda_{0}}(x)\\leq-\\eta<0\\quad\\mathrm{for\\;any}\\;x\\in K.\n$$\n\nBy continuity we have\n\n$$\nw_{\\lambda_{0}-\\varepsilon}<0\\quad\\mathrm{in}\\;K.\n$$\n\nFor $\\varepsilon>0$ small, $\\begin{array}{r}{|\\Sigma_{\\lambda_{0}-\\varepsilon}\\setminus K|<\\delta}\\end{array}$. We choose $\\delta$ in such a way that we may apply Theorem 2.32 (the maximum principle for a domain with small volume) to $w_{\\lambda_{0}-\\varepsilon}$ in $\\Sigma_{\\lambda_{0}-\\varepsilon}\\setminus K$. Hence we get\n\n$$\nw_{\\lambda_{0}-\\varepsilon}(x)\\leq0\\quad\\mathrm{in~}\\Sigma_{\\lambda_{0}-\\varepsilon}\\setminus K\n$$\n\nand then by Theorem 2.10\n\n$$\nw_{\\lambda_{0}-\\varepsilon}(x)<0\\quad\\mathrm{in~}\\Sigma_{\\lambda_{0}-\\varepsilon}\\setminus K.\n$$\n\nTherefore we obtain for any small $\\varepsilon>0$\n\n$$\nw_{\\lambda_{0}-\\varepsilon}(x)<0\\quad\\mathrm{in~}\\Sigma_{\\lambda_{0}-\\varepsilon}.\n$$\n\nThis contradicts the choice of $\\lambda_{0}$.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "The fact that $w_{\\lambda_{0}}<0$ in $\\Sigma_{\\lambda_{0}}$ implies $w_{\\lambda_{0}}(x)\\leq-\\eta<0\\quad\\mathrm{for\\;any}\\;x\\in K.$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/textbook_needrop_en_2290",
        "ID": "06a9232b-e797-497a-a972-7e1c1ad84f72",
        "questions": "What is the condition obtained by applying Theorem 2.32 (the maximum principle for a domain with small volume) to $w_{\\lambda_{0}-\\varepsilon}$ in $\\Sigma_{\\lambda_{0}-\\varepsilon} \\setminus K$?",
        "answers": "$w_{\\lambda_{0}-\\varepsilon}(x)<0\\quad\\mathrm{in~}\\Sigma_{\\lambda_{0}-\\varepsilon}.$",
        "context": "We need to show $w_{\\lambda}<0$ in $\\Sigma_{\\lambda}$ for any $\\lambda\\in(0,a)$. This implies in particular that $w_{\\lambda}$ assumes along $\\partial\\Sigma_{\\lambda}\\cap\\Omega$ its maximum in $\\Sigma_{\\lambda}$. By Theorem 2.5 (the Hopf lemma) we have for any such $\\lambda\\in(0,a)$\n\n$$\n\\left.D_{x_{1}}w_{\\lambda}\\right|_{x_{1}=\\lambda}=2\\left.D_{x_{1}}u\\right|_{x_{1}=\\lambda}<0.\n$$\n\nFor any $\\lambda$ close to $a$, we have $w_{\\lambda}<0$ by Proposition 2.13 (the maximum principle for a narrow domain) or Theorem 2.32. Let $(\\lambda_{0},a)$ be the largest interval of values of $\\lambda$ such that $w_{\\lambda}<0$ in $\\Sigma_{\\lambda}$. We want to show $\\lambda_{0}=0$. If $\\lambda_{0}>0$ by continuity, $w_{\\lambda_{0}}\\leq0$ in $\\Sigma_{\\lambda_{0}}$ and $w_{\\lambda_{0}}\\neq0$ on $\\partial\\Sigma_{\\lambda_{0}}$. Then Theorem 2.7 (the strong maximum principle) implies $w_{\\lambda_{0}}<0$ in $\\Sigma_{\\lambda_{0}}$. We will show that for any small $\\varepsilon>0$\n\n$$\nw_{\\lambda_{0}-\\varepsilon}<0\\quad\\mathrm{in}\\ \\Sigma_{\\lambda_{0}-\\varepsilon}.\n$$\n\nFix $\\delta>0$ (to be determined). Let $K$ be a closed subset in $\\Sigma_{\\lambda_{0}}$ such that $\\vert\\Sigma_{\\lambda_{0}}\\ \\rangle$ $\\begin{array}{r}{|K|<\\frac{\\delta}{2}}\\end{array}$. The fact that $w_{\\lambda_{0}}<0$ in $\\Sigma_{\\lambda_{0}}$ implies\n\n$$\nw_{\\lambda_{0}}(x)\\leq-\\eta<0\\quad\\mathrm{for\\;any}\\;x\\in K.\n$$\n\nBy continuity we have\n\n$$\nw_{\\lambda_{0}-\\varepsilon}<0\\quad\\mathrm{in}\\;K.\n$$\n\nFor $\\varepsilon>0$ small, $\\begin{array}{r}{|\\Sigma_{\\lambda_{0}-\\varepsilon}\\setminus K|<\\delta}\\end{array}$. We choose $\\delta$ in such a way that we may apply Theorem 2.32 (the maximum principle for a domain with small volume) to $w_{\\lambda_{0}-\\varepsilon}$ in $\\Sigma_{\\lambda_{0}-\\varepsilon}\\setminus K$. Hence we get\n\n$$\nw_{\\lambda_{0}-\\varepsilon}(x)\\leq0\\quad\\mathrm{in~}\\Sigma_{\\lambda_{0}-\\varepsilon}\\setminus K\n$$\n\nand then by Theorem 2.10\n\n$$\nw_{\\lambda_{0}-\\varepsilon}(x)<0\\quad\\mathrm{in~}\\Sigma_{\\lambda_{0}-\\varepsilon}\\setminus K.\n$$\n\nTherefore we obtain for any small $\\varepsilon>0$\n\n$$\nw_{\\lambda_{0}-\\varepsilon}(x)<0\\quad\\mathrm{in~}\\Sigma_{\\lambda_{0}-\\varepsilon}.\n$$\n\nThis contradicts the choice of $\\lambda_{0}$.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Hence we get $w_{\\lambda_{0}-\\varepsilon}(x)\\leq0\\quad\\mathrm{in~}\\Sigma_{\\lambda_{0}-\\varepsilon}\\setminus K$ and then by Theorem 2.10 $w_{\\lambda_{0}-\\varepsilon}(x)<0\\quad\\mathrm{in~}\\Sigma_{\\lambda_{0}-\\varepsilon}\\setminus K.$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/socialsci-145347.pdf_16",
        "ID": "06acc243-7243-4f0b-8f81-5b322a3a39cf",
        "questions": "What are the characteristics included under the 'Cultural & Social Characteristics of Groups' structural factor?",
        "answers": "Customs, lifestyles, values, attitudes, aesthetics, language, education, religion, formal and informal rules, social organization, and material objects of each group",
        "context": "\\begin{table}\n\\centering\n\\begin{tabular}{|>{\\columncolor[HTML]{ECF4FF}}m{0.4\\linewidth}|>{\\columncolor[HTML]{ECF4FF}}m{0.55\\linewidth}|}\n \nStructural Factor & Description \\\\\n \nFundamental Instructions & Characteristics of major institutions including family, education, and religion \\\\\n \nDominant Culture & Controlling and imposed ideologies and value system \\\\\n \nCultural \\& Social Characteristics of Groups & Customs, lifestyles, values, attitudes, aesthetics, language, education, religion, formal and informal rules, social organization, and material objects of each group \\\\\n \nHistorical Association & Past contact and interactions between racial-ethnic groups (i.e., voluntary or involuntary immigration, colonialism, segregation, etc.) \\\\\n \n\\end{tabular}\n\\end{table}\n\nThis material (Table 1) developed from concepts introduced by John E. Farley (2010) in Minority-Minority Relations $(6^{\\mathrm{th}}$ ed.) published by Prentice-Hall.  \n\nPeople may occupy multiple statuses in a society. At birth, people are **ascribed status** in alignment to their physical and mental features, race, and gender. In some societies, people may earn or **achieve status** from their talents, efforts, or accomplishments (Griffiths et al., 2015). Obtaining higher education or being an artistic prodigy often corresponds to high status. For example, a college degree awarded from an \u201cIvy League\u201d university social weighs higher status than a degree from a public state college. Just as talented artists, musicians, and athletes receive honors, privileges, and celebrity status.  \n\nIn addition, the social, political hierarchy of a society or region designates social status. Consider the social labels within class, race, ethnicity, gender, education, profession, age, and family. Labels defining a person's characteristics serve as their position within the larger group. People in a majority or dominant group have higher status (e.g., rich, White, male, physician, etc.) than those of the minority or **subordinate group** (e.g., poor, Black, female, housekeeper, etc.). Overall, the location of a person on the social strata influences their social power and participation (Griswold, 2013). Individuals with inferior power have limitations to social and physical resources including lack of authority, influence over others, formidable networks, capital, and money.  \n\nMinority groups are defined as people who receive unequal treatment and discrimination based on social categories such as age, gender, sexuality, race and ethnicity, religious beliefs, or socio-economic class. Minority groups are not necessarily numerical minorities (Griffith et al., 2015). For example, a large group of people may be a minority group because they lack social power. The physical and cultural traits of minority groups \u201care held in low esteem by the dominant or majority group which treats them unfairly\u201d (Henslin, 2011, p. 217). The dominant group has higher power and status in society and receives greater privileges. As a result, the dominant group uses its position to discriminate against those that are different. The dominant group in the United States is represented by White, middle-class, Protestant people of northern European descent (Doane, 2005). Minority groups can garner power by expanding political boundaries or through expanded migration though both efforts do not occur with ease and require societal support from both minority and dominant group members. The loss of power among dominant groups threatens not only their authority over other groups but also the privileges and way of life established by this majority.  \n\n![](images/fcd741d4060438da29925ae082f44a614b9ee80b72bd217812a5a826674855f6.jpg)  \n\nPeople sometimes engage in **status shifting** to garner acceptance or avoid attention. DuBois (1903) described the act of people looking through the eyes of others to measure social place or position as double consciousness. His research explored the history and cultural experiences of the American slavery and the plight of Black folk in translating thinking and behavior between racial contexts. DuBois\u2019 research helped social scientists understand how and why people display one identity in certain settings and another in different ones. People must negotiate a social situation to decide how to project their social identity and assign a label.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "table",
        "evidence_context": "Cultural & Social Characteristics of Groups: Customs, lifestyles, values, attitudes, aesthetics, language, education, religion, formal and informal rules, social organization, and material objects of each group",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/socialsci-145347.pdf_16",
        "ID": "06b42b6f-1f94-43c8-98a7-75945b8c4949",
        "questions": "What is the definition of minority groups according to Griffith et al., 2015?",
        "answers": "Minority groups are defined as people who receive unequal treatment and discrimination based on social categories such as age, gender, sexuality, race and ethnicity, religious beliefs, or socio-economic class.",
        "context": "\\begin{table}\n\\centering\n\\begin{tabular}{|>{\\columncolor[HTML]{ECF4FF}}m{0.4\\linewidth}|>{\\columncolor[HTML]{ECF4FF}}m{0.55\\linewidth}|}\n \nStructural Factor & Description \\\\\n \nFundamental Instructions & Characteristics of major institutions including family, education, and religion \\\\\n \nDominant Culture & Controlling and imposed ideologies and value system \\\\\n \nCultural \\& Social Characteristics of Groups & Customs, lifestyles, values, attitudes, aesthetics, language, education, religion, formal and informal rules, social organization, and material objects of each group \\\\\n \nHistorical Association & Past contact and interactions between racial-ethnic groups (i.e., voluntary or involuntary immigration, colonialism, segregation, etc.) \\\\\n \n\\end{tabular}\n\\end{table}\n\nThis material (Table 1) developed from concepts introduced by John E. Farley (2010) in Minority-Minority Relations $(6^{\\mathrm{th}}$ ed.) published by Prentice-Hall.  \n\nPeople may occupy multiple statuses in a society. At birth, people are **ascribed status** in alignment to their physical and mental features, race, and gender. In some societies, people may earn or **achieve status** from their talents, efforts, or accomplishments (Griffiths et al., 2015). Obtaining higher education or being an artistic prodigy often corresponds to high status. For example, a college degree awarded from an \u201cIvy League\u201d university social weighs higher status than a degree from a public state college. Just as talented artists, musicians, and athletes receive honors, privileges, and celebrity status.  \n\nIn addition, the social, political hierarchy of a society or region designates social status. Consider the social labels within class, race, ethnicity, gender, education, profession, age, and family. Labels defining a person's characteristics serve as their position within the larger group. People in a majority or dominant group have higher status (e.g., rich, White, male, physician, etc.) than those of the minority or **subordinate group** (e.g., poor, Black, female, housekeeper, etc.). Overall, the location of a person on the social strata influences their social power and participation (Griswold, 2013). Individuals with inferior power have limitations to social and physical resources including lack of authority, influence over others, formidable networks, capital, and money.  \n\nMinority groups are defined as people who receive unequal treatment and discrimination based on social categories such as age, gender, sexuality, race and ethnicity, religious beliefs, or socio-economic class. Minority groups are not necessarily numerical minorities (Griffith et al., 2015). For example, a large group of people may be a minority group because they lack social power. The physical and cultural traits of minority groups \u201care held in low esteem by the dominant or majority group which treats them unfairly\u201d (Henslin, 2011, p. 217). The dominant group has higher power and status in society and receives greater privileges. As a result, the dominant group uses its position to discriminate against those that are different. The dominant group in the United States is represented by White, middle-class, Protestant people of northern European descent (Doane, 2005). Minority groups can garner power by expanding political boundaries or through expanded migration though both efforts do not occur with ease and require societal support from both minority and dominant group members. The loss of power among dominant groups threatens not only their authority over other groups but also the privileges and way of life established by this majority.  \n\n![](images/fcd741d4060438da29925ae082f44a614b9ee80b72bd217812a5a826674855f6.jpg)  \n\nPeople sometimes engage in **status shifting** to garner acceptance or avoid attention. DuBois (1903) described the act of people looking through the eyes of others to measure social place or position as double consciousness. His research explored the history and cultural experiences of the American slavery and the plight of Black folk in translating thinking and behavior between racial contexts. DuBois\u2019 research helped social scientists understand how and why people display one identity in certain settings and another in different ones. People must negotiate a social situation to decide how to project their social identity and assign a label.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Minority groups are defined as people who receive unequal treatment and discrimination based on social categories such as age, gender, sexuality, race and ethnicity, religious beliefs, or socio-economic class.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/socialsci-145347.pdf_16",
        "ID": "06b91d3d-2efe-493b-9f00-2b5a7c1e3a6e",
        "questions": "Who described the act of people looking through the eyes of others to measure social place or position as double consciousness and what was this concept about?",
        "answers": "DuBois described the act of people looking through the eyes of others to measure social place or position as double consciousness. This concept explored how people display one identity in certain settings and another in different ones.",
        "context": "\\begin{table}\n\\centering\n\\begin{tabular}{|>{\\columncolor[HTML]{ECF4FF}}m{0.4\\linewidth}|>{\\columncolor[HTML]{ECF4FF}}m{0.55\\linewidth}|}\n \nStructural Factor & Description \\\\\n \nFundamental Instructions & Characteristics of major institutions including family, education, and religion \\\\\n \nDominant Culture & Controlling and imposed ideologies and value system \\\\\n \nCultural \\& Social Characteristics of Groups & Customs, lifestyles, values, attitudes, aesthetics, language, education, religion, formal and informal rules, social organization, and material objects of each group \\\\\n \nHistorical Association & Past contact and interactions between racial-ethnic groups (i.e., voluntary or involuntary immigration, colonialism, segregation, etc.) \\\\\n \n\\end{tabular}\n\\end{table}\n\nThis material (Table 1) developed from concepts introduced by John E. Farley (2010) in Minority-Minority Relations $(6^{\\mathrm{th}}$ ed.) published by Prentice-Hall.  \n\nPeople may occupy multiple statuses in a society. At birth, people are **ascribed status** in alignment to their physical and mental features, race, and gender. In some societies, people may earn or **achieve status** from their talents, efforts, or accomplishments (Griffiths et al., 2015). Obtaining higher education or being an artistic prodigy often corresponds to high status. For example, a college degree awarded from an \u201cIvy League\u201d university social weighs higher status than a degree from a public state college. Just as talented artists, musicians, and athletes receive honors, privileges, and celebrity status.  \n\nIn addition, the social, political hierarchy of a society or region designates social status. Consider the social labels within class, race, ethnicity, gender, education, profession, age, and family. Labels defining a person's characteristics serve as their position within the larger group. People in a majority or dominant group have higher status (e.g., rich, White, male, physician, etc.) than those of the minority or **subordinate group** (e.g., poor, Black, female, housekeeper, etc.). Overall, the location of a person on the social strata influences their social power and participation (Griswold, 2013). Individuals with inferior power have limitations to social and physical resources including lack of authority, influence over others, formidable networks, capital, and money.  \n\nMinority groups are defined as people who receive unequal treatment and discrimination based on social categories such as age, gender, sexuality, race and ethnicity, religious beliefs, or socio-economic class. Minority groups are not necessarily numerical minorities (Griffith et al., 2015). For example, a large group of people may be a minority group because they lack social power. The physical and cultural traits of minority groups \u201care held in low esteem by the dominant or majority group which treats them unfairly\u201d (Henslin, 2011, p. 217). The dominant group has higher power and status in society and receives greater privileges. As a result, the dominant group uses its position to discriminate against those that are different. The dominant group in the United States is represented by White, middle-class, Protestant people of northern European descent (Doane, 2005). Minority groups can garner power by expanding political boundaries or through expanded migration though both efforts do not occur with ease and require societal support from both minority and dominant group members. The loss of power among dominant groups threatens not only their authority over other groups but also the privileges and way of life established by this majority.  \n\n![](images/fcd741d4060438da29925ae082f44a614b9ee80b72bd217812a5a826674855f6.jpg)  \n\nPeople sometimes engage in **status shifting** to garner acceptance or avoid attention. DuBois (1903) described the act of people looking through the eyes of others to measure social place or position as double consciousness. His research explored the history and cultural experiences of the American slavery and the plight of Black folk in translating thinking and behavior between racial contexts. DuBois\u2019 research helped social scientists understand how and why people display one identity in certain settings and another in different ones. People must negotiate a social situation to decide how to project their social identity and assign a label.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "DuBois (1903) described the act of people looking through the eyes of others to measure social place or position as double consciousness. His research explored the history and cultural experiences of the American slavery and the plight of Black folk in translating thinking and behavior between racial contexts.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GSM_110-Matthias_Kreck_-_Differential_Algebraic_Topology__From_Stratifolds_to_Exotic_Spheres-American_Mathematical_Society_(2010).pdf_187",
        "ID": "06bba00e-615a-4c4a-979d-92bc2bd11b15",
        "questions": "What is the order of \\(S H_{1}(L_{k})\\) as mentioned in the document?",
        "answers": "\\(|k|\\)",
        "context": "have detected $|k|$ as the order of $S H_{1}(L_{k})$, whereas all $M_{k,-k}$ have the same homology, and we have used a more subtle invariant to distinguish them.\n\nFinally, we construct an (orientation-reversing) diffeomorphism from $M_{k,\\ell}$ to $M_{-k,-\\ell}$ by mapping $D^{4}\\times S^{3}$ to $D^{4}\\times S^{3}$ via $(x,y)\\;\\mapsto\\;(\\bar{x},y)$ and $-D^{4}\\times S^{3}$ to $-D^{4}\\times S^{3}$ via $(x,y)\\mapsto(\\bar{x},y)$. Thus, we conclude:\n\nTheorem 18.6. Two Milnor manifolds $M_{k,-k}$ and $M_{r,-r}$ are diffeomorphic if and only if $|k|=|r|$.\n\n# 5. Exercises\n\n(1) Let $E$ be a complex vector bundle over $S^{4k}$. Give a formula for the Pontrjagin class $p_{k}(E)$ in terms of $c_{2k}(E)$.\n\n(2) Let $E$ be a $2k$-dimensional oriented vector bundle. Prove that $p_{k}(E)=e(E)\\smile e(E)$.\n\n(3) Let $E$ be a not necessarily oriented $2k$-dimensional vector bundle. Prove that the class represented by $p_{k}(E)$ in $\\mathbb{Z}/2$-cohomology is equal to $w_{2k}(E)\\smile w_{2k}(E)$. \n\n(4) Prove that $\\langle p_{k}(E),[S^{4k}]\\rangle$ is even for all vector bundles $E$ over $S^{4k}$. You can use (or better prove it as an application of Sard's theorem) that an $r$-dimensional vector bundle over $S^{n}$ with $r\\ >\\ n$ is isomorphic to $F\\oplus(S^{n}\\times\\mathbb{R}^{r-n})$ for some $\\mathit{n}$-dimensional vector bundle $F$.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Numeric",
        "evidence_source": "text",
        "evidence_context": "have detected |k| as the order of S H_{1}(L_{k}), whereas all M_{k,-k} have the same homology, and we have used a more subtle invariant to distinguish them.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GSM_110-Matthias_Kreck_-_Differential_Algebraic_Topology__From_Stratifolds_to_Exotic_Spheres-American_Mathematical_Society_(2010).pdf_187",
        "ID": "06c6cb66-8e7f-4afd-8cc7-2f1c6923e8da",
        "questions": "Under what conditions are two Milnor manifolds \\(M_{k,-k}\\) and \\(M_{r,-r}\\) diffeomorphic?",
        "answers": "\\(|k|=|r|\\)",
        "context": "have detected $|k|$ as the order of $S H_{1}(L_{k})$, whereas all $M_{k,-k}$ have the same homology, and we have used a more subtle invariant to distinguish them.\n\nFinally, we construct an (orientation-reversing) diffeomorphism from $M_{k,\\ell}$ to $M_{-k,-\\ell}$ by mapping $D^{4}\\times S^{3}$ to $D^{4}\\times S^{3}$ via $(x,y)\\;\\mapsto\\;(\\bar{x},y)$ and $-D^{4}\\times S^{3}$ to $-D^{4}\\times S^{3}$ via $(x,y)\\mapsto(\\bar{x},y)$. Thus, we conclude:\n\nTheorem 18.6. Two Milnor manifolds $M_{k,-k}$ and $M_{r,-r}$ are diffeomorphic if and only if $|k|=|r|$.\n\n# 5. Exercises\n\n(1) Let $E$ be a complex vector bundle over $S^{4k}$. Give a formula for the Pontrjagin class $p_{k}(E)$ in terms of $c_{2k}(E)$.\n\n(2) Let $E$ be a $2k$-dimensional oriented vector bundle. Prove that $p_{k}(E)=e(E)\\smile e(E)$.\n\n(3) Let $E$ be a not necessarily oriented $2k$-dimensional vector bundle. Prove that the class represented by $p_{k}(E)$ in $\\mathbb{Z}/2$-cohomology is equal to $w_{2k}(E)\\smile w_{2k}(E)$. \n\n(4) Prove that $\\langle p_{k}(E),[S^{4k}]\\rangle$ is even for all vector bundles $E$ over $S^{4k}$. You can use (or better prove it as an application of Sard's theorem) that an $r$-dimensional vector bundle over $S^{n}$ with $r\\ >\\ n$ is isomorphic to $F\\oplus(S^{n}\\times\\mathbb{R}^{r-n})$ for some $\\mathit{n}$-dimensional vector bundle $F$.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Theorem 18.6. Two Milnor manifolds \\(M_{k,-k}\\) and \\(M_{r,-r}\\) are diffeomorphic if and only if |k|=|r|.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GSM_110-Matthias_Kreck_-_Differential_Algebraic_Topology__From_Stratifolds_to_Exotic_Spheres-American_Mathematical_Society_(2010).pdf_187",
        "ID": "06d2ed7c-e6ac-4d8a-8160-ff927c7550f2",
        "questions": "What is the diffeomorphism constructed between \\(M_{k,\\ell}\\) and \\(M_{-k,-\\ell}\\)?",
        "answers": "$(x,y) \\mapsto (\\bar{x},y)$",
        "context": "have detected $|k|$ as the order of $S H_{1}(L_{k})$, whereas all $M_{k,-k}$ have the same homology, and we have used a more subtle invariant to distinguish them.\n\nFinally, we construct an (orientation-reversing) diffeomorphism from $M_{k,\\ell}$ to $M_{-k,-\\ell}$ by mapping $D^{4}\\times S^{3}$ to $D^{4}\\times S^{3}$ via $(x,y)\\;\\mapsto\\;(\\bar{x},y)$ and $-D^{4}\\times S^{3}$ to $-D^{4}\\times S^{3}$ via $(x,y)\\mapsto(\\bar{x},y)$. Thus, we conclude:\n\nTheorem 18.6. Two Milnor manifolds $M_{k,-k}$ and $M_{r,-r}$ are diffeomorphic if and only if $|k|=|r|$.\n\n# 5. Exercises\n\n(1) Let $E$ be a complex vector bundle over $S^{4k}$. Give a formula for the Pontrjagin class $p_{k}(E)$ in terms of $c_{2k}(E)$.\n\n(2) Let $E$ be a $2k$-dimensional oriented vector bundle. Prove that $p_{k}(E)=e(E)\\smile e(E)$.\n\n(3) Let $E$ be a not necessarily oriented $2k$-dimensional vector bundle. Prove that the class represented by $p_{k}(E)$ in $\\mathbb{Z}/2$-cohomology is equal to $w_{2k}(E)\\smile w_{2k}(E)$. \n\n(4) Prove that $\\langle p_{k}(E),[S^{4k}]\\rangle$ is even for all vector bundles $E$ over $S^{4k}$. You can use (or better prove it as an application of Sard's theorem) that an $r$-dimensional vector bundle over $S^{n}$ with $r\\ >\\ n$ is isomorphic to $F\\oplus(S^{n}\\times\\mathbb{R}^{r-n})$ for some $\\mathit{n}$-dimensional vector bundle $F$.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Finally, we construct an (orientation-reversing) diffeomorphism from \\( M_{k,\\ell} \\) to \\( M_{-k,-\\ell} \\) by mapping \\( D^{4} \times S^{3} \\) to \\( D^{4} \times S^{3} \\) via $(x,y) \\mapsto (\\bar{x},y)$ and \\( -D^{4} \times S^{3} \\) to \\( -D^{4} \times S^{3} \\) via $(x,y) \\mapsto (\\bar{x},y)$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GSM_110-Matthias_Kreck_-_Differential_Algebraic_Topology__From_Stratifolds_to_Exotic_Spheres-American_Mathematical_Society_(2010).pdf_187",
        "ID": "06d9e13b-3838-4cfa-8e6b-13855e53d8da",
        "questions": "For which values of $|k|$ are two Milnor manifolds $M_{k,-k}$ and $M_{r,-r}$ diffeomorphic?",
        "answers": "$|k|=|r|$",
        "context": "have detected $|k|$ as the order of $S H_{1}(L_{k})$, whereas all $M_{k,-k}$ have the same homology, and we have used a more subtle invariant to distinguish them.\n\nFinally, we construct an (orientation-reversing) diffeomorphism from $M_{k,\\ell}$ to $M_{-k,-\\ell}$ by mapping $D^{4}\\times S^{3}$ to $D^{4}\\times S^{3}$ via $(x,y)\\;\\mapsto\\;(\\bar{x},y)$ and $-D^{4}\\times S^{3}$ to $-D^{4}\\times S^{3}$ via $(x,y)\\mapsto(\\bar{x},y)$. Thus, we conclude:\n\nTheorem 18.6. Two Milnor manifolds $M_{k,-k}$ and $M_{r,-r}$ are diffeomorphic if and only if $|k|=|r|$.\n\n# 5. Exercises\n\n(1) Let $E$ be a complex vector bundle over $S^{4k}$. Give a formula for the Pontrjagin class $p_{k}(E)$ in terms of $c_{2k}(E)$.\n\n(2) Let $E$ be a $2k$-dimensional oriented vector bundle. Prove that $p_{k}(E)=e(E)\\smile e(E)$.\n\n(3) Let $E$ be a not necessarily oriented $2k$-dimensional vector bundle. Prove that the class represented by $p_{k}(E)$ in $\\mathbb{Z}/2$-cohomology is equal to $w_{2k}(E)\\smile w_{2k}(E)$. \n\n(4) Prove that $\\langle p_{k}(E),[S^{4k}]\\rangle$ is even for all vector bundles $E$ over $S^{4k}$. You can use (or better prove it as an application of Sard's theorem) that an $r$-dimensional vector bundle over $S^{n}$ with $r\\ >\\ n$ is isomorphic to $F\\oplus(S^{n}\\times\\mathbb{R}^{r-n})$ for some $\\mathit{n}$-dimensional vector bundle $F$.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Theorem 18.6. Two Milnor manifolds $M_{k,-k}$ and $M_{r,-r}$ are diffeomorphic if and only if $|k|=|r|$.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/GSM_110-Matthias_Kreck_-_Differential_Algebraic_Topology__From_Stratifolds_to_Exotic_Spheres-American_Mathematical_Society_(2010).pdf_187",
        "ID": "06db83ae-66ca-4e67-83d1-01f3b98cd16c",
        "questions": "What is the required inequality in the context of an $r$-dimensional vector bundle over $S^{n}$ to conclude it is isomorphic to $F\\oplus(S^{n}\\times\\mathbb{R}^{r-n})$?",
        "answers": "$r > n$",
        "context": "have detected $|k|$ as the order of $S H_{1}(L_{k})$, whereas all $M_{k,-k}$ have the same homology, and we have used a more subtle invariant to distinguish them.\n\nFinally, we construct an (orientation-reversing) diffeomorphism from $M_{k,\\ell}$ to $M_{-k,-\\ell}$ by mapping $D^{4}\\times S^{3}$ to $D^{4}\\times S^{3}$ via $(x,y)\\;\\mapsto\\;(\\bar{x},y)$ and $-D^{4}\\times S^{3}$ to $-D^{4}\\times S^{3}$ via $(x,y)\\mapsto(\\bar{x},y)$. Thus, we conclude:\n\nTheorem 18.6. Two Milnor manifolds $M_{k,-k}$ and $M_{r,-r}$ are diffeomorphic if and only if $|k|=|r|$.\n\n# 5. Exercises\n\n(1) Let $E$ be a complex vector bundle over $S^{4k}$. Give a formula for the Pontrjagin class $p_{k}(E)$ in terms of $c_{2k}(E)$.\n\n(2) Let $E$ be a $2k$-dimensional oriented vector bundle. Prove that $p_{k}(E)=e(E)\\smile e(E)$.\n\n(3) Let $E$ be a not necessarily oriented $2k$-dimensional vector bundle. Prove that the class represented by $p_{k}(E)$ in $\\mathbb{Z}/2$-cohomology is equal to $w_{2k}(E)\\smile w_{2k}(E)$. \n\n(4) Prove that $\\langle p_{k}(E),[S^{4k}]\\rangle$ is even for all vector bundles $E$ over $S^{4k}$. You can use (or better prove it as an application of Sard's theorem) that an $r$-dimensional vector bundle over $S^{n}$ with $r\\ >\\ n$ is isomorphic to $F\\oplus(S^{n}\\times\\mathbb{R}^{r-n})$ for some $\\mathit{n}$-dimensional vector bundle $F$.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "an $r$-dimensional vector bundle over $S^{n}$ with $r\\ >\\ n$ is isomorphic to $F\\oplus(S^{n}\\times\\mathbb{R}^{r-n})$ for some $\\mathit{n}$-dimensional vector bundle $F$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/GSM_110-Matthias_Kreck_-_Differential_Algebraic_Topology__From_Stratifolds_to_Exotic_Spheres-American_Mathematical_Society_(2010).pdf_187",
        "ID": "06de025e-03e9-42fa-8696-db0e0a30a255",
        "questions": "What is the formula for the Pontrjagin class $p_{k}(E)$ in terms of the Euler class $e(E)$ for a $2k$-dimensional oriented vector bundle?",
        "answers": "$p_{k}(E)=e(E)\\smile e(E)$",
        "context": "have detected $|k|$ as the order of $S H_{1}(L_{k})$, whereas all $M_{k,-k}$ have the same homology, and we have used a more subtle invariant to distinguish them.\n\nFinally, we construct an (orientation-reversing) diffeomorphism from $M_{k,\\ell}$ to $M_{-k,-\\ell}$ by mapping $D^{4}\\times S^{3}$ to $D^{4}\\times S^{3}$ via $(x,y)\\;\\mapsto\\;(\\bar{x},y)$ and $-D^{4}\\times S^{3}$ to $-D^{4}\\times S^{3}$ via $(x,y)\\mapsto(\\bar{x},y)$. Thus, we conclude:\n\nTheorem 18.6. Two Milnor manifolds $M_{k,-k}$ and $M_{r,-r}$ are diffeomorphic if and only if $|k|=|r|$.\n\n# 5. Exercises\n\n(1) Let $E$ be a complex vector bundle over $S^{4k}$. Give a formula for the Pontrjagin class $p_{k}(E)$ in terms of $c_{2k}(E)$.\n\n(2) Let $E$ be a $2k$-dimensional oriented vector bundle. Prove that $p_{k}(E)=e(E)\\smile e(E)$.\n\n(3) Let $E$ be a not necessarily oriented $2k$-dimensional vector bundle. Prove that the class represented by $p_{k}(E)$ in $\\mathbb{Z}/2$-cohomology is equal to $w_{2k}(E)\\smile w_{2k}(E)$. \n\n(4) Prove that $\\langle p_{k}(E),[S^{4k}]\\rangle$ is even for all vector bundles $E$ over $S^{4k}$. You can use (or better prove it as an application of Sard's theorem) that an $r$-dimensional vector bundle over $S^{n}$ with $r\\ >\\ n$ is isomorphic to $F\\oplus(S^{n}\\times\\mathbb{R}^{r-n})$ for some $\\mathit{n}$-dimensional vector bundle $F$.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Let $E$ be a $2k$-dimensional oriented vector bundle. Prove that $p_{k}(E)=e(E)\\smile e(E)$.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/GTM84-A_Classical_Introduction_to_Modern_Number_Theory1990.pdf_174",
        "ID": "06e86e99-2c7d-449e-80b8-b40fd5f0098e",
        "questions": "If \\( f(x) \\) is the minimal polynomial for \\( \u0007lpha \\), what does \\( f(x) \\) divide according to the document?",
        "answers": "f(x) divides \\( x^{q^{k}}-x \\)",
        "context": "and so  \n\n$$\n\\alpha=\\alpha^{q^{ k}}.\n$$  \n\nSince  $f(x)$  is the minimal polynomial for  $\\alpha$  it follows that  $f(x)$  divides  $x^{q^{k}}-x$  and so by Theorem 2 of Chapter 7 we have  $d|k$.  However,  $0\\leq k<d$  and so  $k=0$  and we are done.  \n\nIt follows immediately from $\\operatorname{assertion}(a)$ that  $c_{1}=\\operatorname{tr}_{E/F}(\\alpha)$  and that  $c_{d}=N_{E/F}(\\alpha)$  \n\nSince  $\\alpha\\in E=F(\\alpha)$  we have  $\\operatorname{tr}_{K/E}(\\alpha)=[K:E]\\alpha=(n/d)\\alpha$  and  $N_{K/E}(\\alpha)$   $\\mathbf\\alpha=\\alpha^{n/d}$.\n\nBy Proposition 11.2.3  \n\n$$\n\\operatorname{tr}_{K/F}(\\alpha)=\\operatorname{tr}_{E/F}(\\operatorname{tr}_{K/E}(\\alpha))=\\operatorname{tr}_{E/F}\\!\\left({\\frac{n}{d}}\\,\\alpha\\right)={\\frac{n}{d}}\\operatorname{tr}_{E/F}(\\alpha)={\\frac{n}{d}}\\operatorname{c}_{1}.\n$$  \n\nSimilarly,  \n\n$$\nN_{K/F}(\\alpha)=N_{E/F}(N_{K/E}(\\alpha))=N_{E/F}(\\alpha^{n/d})=N_{E/F}(\\alpha)^{n/d}=c_{d}^{n/d}.\n$$  \n\n#  $\\S3$  The Rationality of the Zeta Function Associated to  $a_{0}\\,x_{0}^{m}\\,+\\,a_{1}x_{1}^{m}\\,+\\,\\cdot\\cdot\\,\\cdot\\,+\\,a_{n}\\,x_{n}^{m}$  \n\nLet  $f(x_{0},x_{1},\\ldots,x_{n})$  be the polynomial given in the title of this section. [notice that this is not the  $f(x)$  of Section 2]. Suppose that the coefficients are in  $F$, a finite field, with  $q$  elements and that  $q\\equiv1\\left(m\\right)$. We have to investigate the number  $N_{s}$  of elements in  $\\bar{H}_{f}(F_{s}).$  , where  $[F_{s}:F]=s$.  Theorem 2 of Chapter 10 shows that  $N_{s}$  is given by  \n\n$$\n\\displaystyle q^{s(n-1)}\\,+\\,q^{s(n-2)}\\,+\\,\\cdots\\,+\\,q^{s}\\,+\\,1+\\,\\frac1{q^{s}}\\sum_{\\chi_{0}^{(s)},\\,\\cdots,\\chi_{n}^{(s)}}\\chi_{0}^{(s)}(a_{0}^{-\\,1})\\cdots\\chi_{n}^{(s)}(a_{n}^{-\\,1})g(\\chi_{0}^{(s)})\\cdots g(\\chi_{n}^{(s)}),\n$$  \n\nwhere  $q^{s}$  is the number of elements in  $F_{s}$, and the  $\\chi_{i}^{(s)}$  are multiplicative characters of $F_{s}$ such that $\\chi_{i}^{(s)m}=\\varepsilon,\\chi_{i}^{(s)}\\neq\\varepsilon$ and $\\chi_{0}^{(s)}\\chi_{1}^{(s)}\\cdot\\cdot\\cdot\\chi_{n}^{(s)}=\\varepsilon$.\n\nWe must analyze the terms  $\\chi_{i}^{(s)}(a_{i}^{-1})$  and  $g(\\chi_{i}^{(s)})$. To do this we first relate characters of  $F_{s}$  to characters of $F$.\n\nLet  $\\chi$  be a character of  $F$  and set  $\\chi^{\\prime}=\\chi\\circ N_{F_{\\mathrm{s}}/F}$ ; i.e., for  $\\alpha\\in F_{s},\\,\\chi^{\\prime}(\\alpha)=\\chi(N_{F_{s}/F}(\\alpha))$  . Then one sees, using Proposition 11.2.2, that  $\\chi^{\\prime}$  is a character of  $F_{s}$, and moreover that  \n\n(a)  $\\chi\\neq\\rho$  implies that  $\\chi^{\\prime}\\neq\\rho^{\\prime}$  \n\n(b)  $\\chi^{m}=\\varepsilon$  implies that  ${{\\chi}}^{\\prime m}={{\\varepsilon}}$  \n\n$\\chi^{\\prime}(a)=\\chi(a)^{s}$  for all  $a\\in F$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Since  \\( f(x) \\)  is the minimal polynomial for  \\( \u0007lpha \\)  it follows that  \\( f(x) \\)  divides  \\( x^{q^{k}}-x \\).",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM84-A_Classical_Introduction_to_Modern_Number_Theory1990.pdf_174",
        "ID": "06f187c2-1805-4deb-83b9-996fcfe36f57",
        "questions": "What is the expression of \\( N_{K/F}(\u0007lpha) \\) in terms of \\( c_d \\) given that \\( N_{K/F}(\u0007lpha) = N_{E/F}(N_{K/E}(\u0007lpha)) \\)?",
        "answers": "N_{K/F}(\u0007lpha) = c_{d}^{n/d}",
        "context": "and so  \n\n$$\n\\alpha=\\alpha^{q^{ k}}.\n$$  \n\nSince  $f(x)$  is the minimal polynomial for  $\\alpha$  it follows that  $f(x)$  divides  $x^{q^{k}}-x$  and so by Theorem 2 of Chapter 7 we have  $d|k$.  However,  $0\\leq k<d$  and so  $k=0$  and we are done.  \n\nIt follows immediately from $\\operatorname{assertion}(a)$ that  $c_{1}=\\operatorname{tr}_{E/F}(\\alpha)$  and that  $c_{d}=N_{E/F}(\\alpha)$  \n\nSince  $\\alpha\\in E=F(\\alpha)$  we have  $\\operatorname{tr}_{K/E}(\\alpha)=[K:E]\\alpha=(n/d)\\alpha$  and  $N_{K/E}(\\alpha)$   $\\mathbf\\alpha=\\alpha^{n/d}$.\n\nBy Proposition 11.2.3  \n\n$$\n\\operatorname{tr}_{K/F}(\\alpha)=\\operatorname{tr}_{E/F}(\\operatorname{tr}_{K/E}(\\alpha))=\\operatorname{tr}_{E/F}\\!\\left({\\frac{n}{d}}\\,\\alpha\\right)={\\frac{n}{d}}\\operatorname{tr}_{E/F}(\\alpha)={\\frac{n}{d}}\\operatorname{c}_{1}.\n$$  \n\nSimilarly,  \n\n$$\nN_{K/F}(\\alpha)=N_{E/F}(N_{K/E}(\\alpha))=N_{E/F}(\\alpha^{n/d})=N_{E/F}(\\alpha)^{n/d}=c_{d}^{n/d}.\n$$  \n\n#  $\\S3$  The Rationality of the Zeta Function Associated to  $a_{0}\\,x_{0}^{m}\\,+\\,a_{1}x_{1}^{m}\\,+\\,\\cdot\\cdot\\,\\cdot\\,+\\,a_{n}\\,x_{n}^{m}$  \n\nLet  $f(x_{0},x_{1},\\ldots,x_{n})$  be the polynomial given in the title of this section. [notice that this is not the  $f(x)$  of Section 2]. Suppose that the coefficients are in  $F$, a finite field, with  $q$  elements and that  $q\\equiv1\\left(m\\right)$. We have to investigate the number  $N_{s}$  of elements in  $\\bar{H}_{f}(F_{s}).$  , where  $[F_{s}:F]=s$.  Theorem 2 of Chapter 10 shows that  $N_{s}$  is given by  \n\n$$\n\\displaystyle q^{s(n-1)}\\,+\\,q^{s(n-2)}\\,+\\,\\cdots\\,+\\,q^{s}\\,+\\,1+\\,\\frac1{q^{s}}\\sum_{\\chi_{0}^{(s)},\\,\\cdots,\\chi_{n}^{(s)}}\\chi_{0}^{(s)}(a_{0}^{-\\,1})\\cdots\\chi_{n}^{(s)}(a_{n}^{-\\,1})g(\\chi_{0}^{(s)})\\cdots g(\\chi_{n}^{(s)}),\n$$  \n\nwhere  $q^{s}$  is the number of elements in  $F_{s}$, and the  $\\chi_{i}^{(s)}$  are multiplicative characters of $F_{s}$ such that $\\chi_{i}^{(s)m}=\\varepsilon,\\chi_{i}^{(s)}\\neq\\varepsilon$ and $\\chi_{0}^{(s)}\\chi_{1}^{(s)}\\cdot\\cdot\\cdot\\chi_{n}^{(s)}=\\varepsilon$.\n\nWe must analyze the terms  $\\chi_{i}^{(s)}(a_{i}^{-1})$  and  $g(\\chi_{i}^{(s)})$. To do this we first relate characters of  $F_{s}$  to characters of $F$.\n\nLet  $\\chi$  be a character of  $F$  and set  $\\chi^{\\prime}=\\chi\\circ N_{F_{\\mathrm{s}}/F}$ ; i.e., for  $\\alpha\\in F_{s},\\,\\chi^{\\prime}(\\alpha)=\\chi(N_{F_{s}/F}(\\alpha))$  . Then one sees, using Proposition 11.2.2, that  $\\chi^{\\prime}$  is a character of  $F_{s}$, and moreover that  \n\n(a)  $\\chi\\neq\\rho$  implies that  $\\chi^{\\prime}\\neq\\rho^{\\prime}$  \n\n(b)  $\\chi^{m}=\\varepsilon$  implies that  ${{\\chi}}^{\\prime m}={{\\varepsilon}}$  \n\n$\\chi^{\\prime}(a)=\\chi(a)^{s}$  for all  $a\\in F$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Similarly, \\( N_{K/F}(\u0007lpha)=N_{E/F}(N_{K/E}(\u0007lpha))=N_{E/F}(\u0007lpha^{n/d})=N_{E/F}(\u0007lpha)^{n/d}=c_{d}^{n/d} \\).",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM84-A_Classical_Introduction_to_Modern_Number_Theory1990.pdf_174",
        "ID": "06f7302d-62bd-49ae-a072-6dd9e0738191",
        "questions": "How is the number \\(N_{s}\\) of elements in \\(\bar{H}_{f}(F_{s})\\) determined when \\(f(x_0,x_1,\\dots,x_n)\\) is the polynomial discussed in Section 3 and the coefficients are in a finite field \\(F\\) with \\(q\\) elements?",
        "answers": "N_{s} is given by \\( q^{s(n-1)} + q^{s(n-2)} + \\cdots + q^{s} + 1 + \frac{1}{q^{s}} \\sum_{\\chi_{0}^{(s)}, \\cdots, \\chi_{n}^{(s)}} \\chi_{0}^{(s)}(a_{0}^{-1}) \\cdots \\chi_{n}^{(s)}(a_{n}^{-1}) g(\\chi_{0}^{(s)}) \\cdots g(\\chi_{n}^{(s)}) \\).",
        "context": "and so  \n\n$$\n\\alpha=\\alpha^{q^{ k}}.\n$$  \n\nSince  $f(x)$  is the minimal polynomial for  $\\alpha$  it follows that  $f(x)$  divides  $x^{q^{k}}-x$  and so by Theorem 2 of Chapter 7 we have  $d|k$.  However,  $0\\leq k<d$  and so  $k=0$  and we are done.  \n\nIt follows immediately from $\\operatorname{assertion}(a)$ that  $c_{1}=\\operatorname{tr}_{E/F}(\\alpha)$  and that  $c_{d}=N_{E/F}(\\alpha)$  \n\nSince  $\\alpha\\in E=F(\\alpha)$  we have  $\\operatorname{tr}_{K/E}(\\alpha)=[K:E]\\alpha=(n/d)\\alpha$  and  $N_{K/E}(\\alpha)$   $\\mathbf\\alpha=\\alpha^{n/d}$.\n\nBy Proposition 11.2.3  \n\n$$\n\\operatorname{tr}_{K/F}(\\alpha)=\\operatorname{tr}_{E/F}(\\operatorname{tr}_{K/E}(\\alpha))=\\operatorname{tr}_{E/F}\\!\\left({\\frac{n}{d}}\\,\\alpha\\right)={\\frac{n}{d}}\\operatorname{tr}_{E/F}(\\alpha)={\\frac{n}{d}}\\operatorname{c}_{1}.\n$$  \n\nSimilarly,  \n\n$$\nN_{K/F}(\\alpha)=N_{E/F}(N_{K/E}(\\alpha))=N_{E/F}(\\alpha^{n/d})=N_{E/F}(\\alpha)^{n/d}=c_{d}^{n/d}.\n$$  \n\n#  $\\S3$  The Rationality of the Zeta Function Associated to  $a_{0}\\,x_{0}^{m}\\,+\\,a_{1}x_{1}^{m}\\,+\\,\\cdot\\cdot\\,\\cdot\\,+\\,a_{n}\\,x_{n}^{m}$  \n\nLet  $f(x_{0},x_{1},\\ldots,x_{n})$  be the polynomial given in the title of this section. [notice that this is not the  $f(x)$  of Section 2]. Suppose that the coefficients are in  $F$, a finite field, with  $q$  elements and that  $q\\equiv1\\left(m\\right)$. We have to investigate the number  $N_{s}$  of elements in  $\\bar{H}_{f}(F_{s}).$  , where  $[F_{s}:F]=s$.  Theorem 2 of Chapter 10 shows that  $N_{s}$  is given by  \n\n$$\n\\displaystyle q^{s(n-1)}\\,+\\,q^{s(n-2)}\\,+\\,\\cdots\\,+\\,q^{s}\\,+\\,1+\\,\\frac1{q^{s}}\\sum_{\\chi_{0}^{(s)},\\,\\cdots,\\chi_{n}^{(s)}}\\chi_{0}^{(s)}(a_{0}^{-\\,1})\\cdots\\chi_{n}^{(s)}(a_{n}^{-\\,1})g(\\chi_{0}^{(s)})\\cdots g(\\chi_{n}^{(s)}),\n$$  \n\nwhere  $q^{s}$  is the number of elements in  $F_{s}$, and the  $\\chi_{i}^{(s)}$  are multiplicative characters of $F_{s}$ such that $\\chi_{i}^{(s)m}=\\varepsilon,\\chi_{i}^{(s)}\\neq\\varepsilon$ and $\\chi_{0}^{(s)}\\chi_{1}^{(s)}\\cdot\\cdot\\cdot\\chi_{n}^{(s)}=\\varepsilon$.\n\nWe must analyze the terms  $\\chi_{i}^{(s)}(a_{i}^{-1})$  and  $g(\\chi_{i}^{(s)})$. To do this we first relate characters of  $F_{s}$  to characters of $F$.\n\nLet  $\\chi$  be a character of  $F$  and set  $\\chi^{\\prime}=\\chi\\circ N_{F_{\\mathrm{s}}/F}$ ; i.e., for  $\\alpha\\in F_{s},\\,\\chi^{\\prime}(\\alpha)=\\chi(N_{F_{s}/F}(\\alpha))$  . Then one sees, using Proposition 11.2.2, that  $\\chi^{\\prime}$  is a character of  $F_{s}$, and moreover that  \n\n(a)  $\\chi\\neq\\rho$  implies that  $\\chi^{\\prime}\\neq\\rho^{\\prime}$  \n\n(b)  $\\chi^{m}=\\varepsilon$  implies that  ${{\\chi}}^{\\prime m}={{\\varepsilon}}$  \n\n$\\chi^{\\prime}(a)=\\chi(a)^{s}$  for all  $a\\in F$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Theorem 2 of Chapter 10 shows that \\( N_{s} \\) is given by \\[ q^{s(n-1)} + q^{s(n-2)} + \\cdots + q^{s} + 1 + \frac{1}{q^{s}} \\sum_{\\chi_{0}^{(s)}, \\cdots, \\chi_{n}^{(s)}} \\chi_{0}^{(s)}(a_{0}^{-1}) \\cdots \\chi_{n}^{(s)}(a_{n}^{-1}) g(\\chi_{0}^{(s)}) \\cdots g(\\chi_{n}^{(s)}) \\], where \\( q^{s} \\) is the number of elements in \\( F_{s} \\), and the \\( \\chi_{i}^{(s)} \\) are multiplicative characters of \\( F_{s} \\) such that \\( \\chi_{i}^{(s)m} = \u000barepsilon, \\chi_{i}^{(s)} \neq \u000barepsilon \\) and \\( \\chi_{0}^{(s)} \\chi_{1}^{(s)} \\cdot \\cdot \\cdot \\chi_{n}^{(s)} = \u000barepsilon \\).",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM84-A_Classical_Introduction_to_Modern_Number_Theory1990.pdf_174",
        "ID": "070227a3-7a37-40a5-972e-78a53176ee40",
        "questions": "What is the value of $\\operatorname{tr}_{K/F}(\\alpha)$ in terms of $\\operatorname{tr}_{E/F}(\\alpha)$, $n$, and $d$?",
        "answers": "${\\frac{n}{d}}\\operatorname{tr}_{E/F}(\\alpha)={\\frac{n}{d}}c_{1}$",
        "context": "and so  \n\n$$\n\\alpha=\\alpha^{q^{ k}}.\n$$  \n\nSince  $f(x)$  is the minimal polynomial for  $\\alpha$  it follows that  $f(x)$  divides  $x^{q^{k}}-x$  and so by Theorem 2 of Chapter 7 we have  $d|k$.  However,  $0\\leq k<d$  and so  $k=0$  and we are done.  \n\nIt follows immediately from $\\operatorname{assertion}(a)$ that  $c_{1}=\\operatorname{tr}_{E/F}(\\alpha)$  and that  $c_{d}=N_{E/F}(\\alpha)$  \n\nSince  $\\alpha\\in E=F(\\alpha)$  we have  $\\operatorname{tr}_{K/E}(\\alpha)=[K:E]\\alpha=(n/d)\\alpha$  and  $N_{K/E}(\\alpha)$   $\\mathbf\\alpha=\\alpha^{n/d}$.\n\nBy Proposition 11.2.3  \n\n$$\n\\operatorname{tr}_{K/F}(\\alpha)=\\operatorname{tr}_{E/F}(\\operatorname{tr}_{K/E}(\\alpha))=\\operatorname{tr}_{E/F}\\!\\left({\\frac{n}{d}}\\,\\alpha\\right)={\\frac{n}{d}}\\operatorname{tr}_{E/F}(\\alpha)={\\frac{n}{d}}\\operatorname{c}_{1}.\n$$  \n\nSimilarly,  \n\n$$\nN_{K/F}(\\alpha)=N_{E/F}(N_{K/E}(\\alpha))=N_{E/F}(\\alpha^{n/d})=N_{E/F}(\\alpha)^{n/d}=c_{d}^{n/d}.\n$$  \n\n#  $\\S3$  The Rationality of the Zeta Function Associated to  $a_{0}\\,x_{0}^{m}\\,+\\,a_{1}x_{1}^{m}\\,+\\,\\cdot\\cdot\\,\\cdot\\,+\\,a_{n}\\,x_{n}^{m}$  \n\nLet  $f(x_{0},x_{1},\\ldots,x_{n})$  be the polynomial given in the title of this section. [notice that this is not the  $f(x)$  of Section 2]. Suppose that the coefficients are in  $F$, a finite field, with  $q$  elements and that  $q\\equiv1\\left(m\\right)$. We have to investigate the number  $N_{s}$  of elements in  $\\bar{H}_{f}(F_{s}).$  , where  $[F_{s}:F]=s$.  Theorem 2 of Chapter 10 shows that  $N_{s}$  is given by  \n\n$$\n\\displaystyle q^{s(n-1)}\\,+\\,q^{s(n-2)}\\,+\\,\\cdots\\,+\\,q^{s}\\,+\\,1+\\,\\frac1{q^{s}}\\sum_{\\chi_{0}^{(s)},\\,\\cdots,\\chi_{n}^{(s)}}\\chi_{0}^{(s)}(a_{0}^{-\\,1})\\cdots\\chi_{n}^{(s)}(a_{n}^{-\\,1})g(\\chi_{0}^{(s)})\\cdots g(\\chi_{n}^{(s)}),\n$$  \n\nwhere  $q^{s}$  is the number of elements in  $F_{s}$, and the  $\\chi_{i}^{(s)}$  are multiplicative characters of $F_{s}$ such that $\\chi_{i}^{(s)m}=\\varepsilon,\\chi_{i}^{(s)}\\neq\\varepsilon$ and $\\chi_{0}^{(s)}\\chi_{1}^{(s)}\\cdot\\cdot\\cdot\\chi_{n}^{(s)}=\\varepsilon$.\n\nWe must analyze the terms  $\\chi_{i}^{(s)}(a_{i}^{-1})$  and  $g(\\chi_{i}^{(s)})$. To do this we first relate characters of  $F_{s}$  to characters of $F$.\n\nLet  $\\chi$  be a character of  $F$  and set  $\\chi^{\\prime}=\\chi\\circ N_{F_{\\mathrm{s}}/F}$ ; i.e., for  $\\alpha\\in F_{s},\\,\\chi^{\\prime}(\\alpha)=\\chi(N_{F_{s}/F}(\\alpha))$  . Then one sees, using Proposition 11.2.2, that  $\\chi^{\\prime}$  is a character of  $F_{s}$, and moreover that  \n\n(a)  $\\chi\\neq\\rho$  implies that  $\\chi^{\\prime}\\neq\\rho^{\\prime}$  \n\n(b)  $\\chi^{m}=\\varepsilon$  implies that  ${{\\chi}}^{\\prime m}={{\\varepsilon}}$  \n\n$\\chi^{\\prime}(a)=\\chi(a)^{s}$  for all  $a\\in F$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$$\\operatorname{tr}_{K/F}(\\alpha)=\\operatorname{tr}_{E/F}(\\operatorname{tr}_{K/E}(\\alpha))=\\operatorname{tr}_{E/F}\\!\\left({\\frac{n}{d}}\\,\\alpha\\right)={\\frac{n}{d}}\\operatorname{tr}_{E/F}(\\alpha)={\\frac{n}{d}}\\operatorname{c}_{1}.$$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/GTM84-A_Classical_Introduction_to_Modern_Number_Theory1990.pdf_174",
        "ID": "0703c5f1-5b4f-4458-a523-923afe963e96",
        "questions": "What is the condition on $q$ in relation to $m$ for the rationality of the zeta function associated to $a_{0} x_{0}^{m} + a_{1} x_{1}^{m} + \\cdots + a_{n} x_{n}^{m}$?",
        "answers": "$q \\equiv 1 \\left(m\\right)$",
        "context": "and so  \n\n$$\n\\alpha=\\alpha^{q^{ k}}.\n$$  \n\nSince  $f(x)$  is the minimal polynomial for  $\\alpha$  it follows that  $f(x)$  divides  $x^{q^{k}}-x$  and so by Theorem 2 of Chapter 7 we have  $d|k$.  However,  $0\\leq k<d$  and so  $k=0$  and we are done.  \n\nIt follows immediately from $\\operatorname{assertion}(a)$ that  $c_{1}=\\operatorname{tr}_{E/F}(\\alpha)$  and that  $c_{d}=N_{E/F}(\\alpha)$  \n\nSince  $\\alpha\\in E=F(\\alpha)$  we have  $\\operatorname{tr}_{K/E}(\\alpha)=[K:E]\\alpha=(n/d)\\alpha$  and  $N_{K/E}(\\alpha)$   $\\mathbf\\alpha=\\alpha^{n/d}$.\n\nBy Proposition 11.2.3  \n\n$$\n\\operatorname{tr}_{K/F}(\\alpha)=\\operatorname{tr}_{E/F}(\\operatorname{tr}_{K/E}(\\alpha))=\\operatorname{tr}_{E/F}\\!\\left({\\frac{n}{d}}\\,\\alpha\\right)={\\frac{n}{d}}\\operatorname{tr}_{E/F}(\\alpha)={\\frac{n}{d}}\\operatorname{c}_{1}.\n$$  \n\nSimilarly,  \n\n$$\nN_{K/F}(\\alpha)=N_{E/F}(N_{K/E}(\\alpha))=N_{E/F}(\\alpha^{n/d})=N_{E/F}(\\alpha)^{n/d}=c_{d}^{n/d}.\n$$  \n\n#  $\\S3$  The Rationality of the Zeta Function Associated to  $a_{0}\\,x_{0}^{m}\\,+\\,a_{1}x_{1}^{m}\\,+\\,\\cdot\\cdot\\,\\cdot\\,+\\,a_{n}\\,x_{n}^{m}$  \n\nLet  $f(x_{0},x_{1},\\ldots,x_{n})$  be the polynomial given in the title of this section. [notice that this is not the  $f(x)$  of Section 2]. Suppose that the coefficients are in  $F$, a finite field, with  $q$  elements and that  $q\\equiv1\\left(m\\right)$. We have to investigate the number  $N_{s}$  of elements in  $\\bar{H}_{f}(F_{s}).$  , where  $[F_{s}:F]=s$.  Theorem 2 of Chapter 10 shows that  $N_{s}$  is given by  \n\n$$\n\\displaystyle q^{s(n-1)}\\,+\\,q^{s(n-2)}\\,+\\,\\cdots\\,+\\,q^{s}\\,+\\,1+\\,\\frac1{q^{s}}\\sum_{\\chi_{0}^{(s)},\\,\\cdots,\\chi_{n}^{(s)}}\\chi_{0}^{(s)}(a_{0}^{-\\,1})\\cdots\\chi_{n}^{(s)}(a_{n}^{-\\,1})g(\\chi_{0}^{(s)})\\cdots g(\\chi_{n}^{(s)}),\n$$  \n\nwhere  $q^{s}$  is the number of elements in  $F_{s}$, and the  $\\chi_{i}^{(s)}$  are multiplicative characters of $F_{s}$ such that $\\chi_{i}^{(s)m}=\\varepsilon,\\chi_{i}^{(s)}\\neq\\varepsilon$ and $\\chi_{0}^{(s)}\\chi_{1}^{(s)}\\cdot\\cdot\\cdot\\chi_{n}^{(s)}=\\varepsilon$.\n\nWe must analyze the terms  $\\chi_{i}^{(s)}(a_{i}^{-1})$  and  $g(\\chi_{i}^{(s)})$. To do this we first relate characters of  $F_{s}$  to characters of $F$.\n\nLet  $\\chi$  be a character of  $F$  and set  $\\chi^{\\prime}=\\chi\\circ N_{F_{\\mathrm{s}}/F}$ ; i.e., for  $\\alpha\\in F_{s},\\,\\chi^{\\prime}(\\alpha)=\\chi(N_{F_{s}/F}(\\alpha))$  . Then one sees, using Proposition 11.2.2, that  $\\chi^{\\prime}$  is a character of  $F_{s}$, and moreover that  \n\n(a)  $\\chi\\neq\\rho$  implies that  $\\chi^{\\prime}\\neq\\rho^{\\prime}$  \n\n(b)  $\\chi^{m}=\\varepsilon$  implies that  ${{\\chi}}^{\\prime m}={{\\varepsilon}}$  \n\n$\\chi^{\\prime}(a)=\\chi(a)^{s}$  for all  $a\\in F$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Suppose that the coefficients are in  $F$, a finite field, with  $q$  elements and that  $q\\equiv1\\left(m\\right)$. We have to investigate the number  $N_{s}$  of elements in  $\\bar{H}_{f}(F_{s}).$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/GTM84-A_Classical_Introduction_to_Modern_Number_Theory1990.pdf_174",
        "ID": "070cd0e8-dd17-4fb5-9005-155c763f6720",
        "questions": "How is $N_{K/F}(\\alpha)$ expressed in terms of $N_{E/F}(\\alpha)$ and $c_{d}$?",
        "answers": "$N_{E/F}(\\alpha)^{n/d}=c_{d}^{n/d}$",
        "context": "and so  \n\n$$\n\\alpha=\\alpha^{q^{ k}}.\n$$  \n\nSince  $f(x)$  is the minimal polynomial for  $\\alpha$  it follows that  $f(x)$  divides  $x^{q^{k}}-x$  and so by Theorem 2 of Chapter 7 we have  $d|k$.  However,  $0\\leq k<d$  and so  $k=0$  and we are done.  \n\nIt follows immediately from $\\operatorname{assertion}(a)$ that  $c_{1}=\\operatorname{tr}_{E/F}(\\alpha)$  and that  $c_{d}=N_{E/F}(\\alpha)$  \n\nSince  $\\alpha\\in E=F(\\alpha)$  we have  $\\operatorname{tr}_{K/E}(\\alpha)=[K:E]\\alpha=(n/d)\\alpha$  and  $N_{K/E}(\\alpha)$   $\\mathbf\\alpha=\\alpha^{n/d}$.\n\nBy Proposition 11.2.3  \n\n$$\n\\operatorname{tr}_{K/F}(\\alpha)=\\operatorname{tr}_{E/F}(\\operatorname{tr}_{K/E}(\\alpha))=\\operatorname{tr}_{E/F}\\!\\left({\\frac{n}{d}}\\,\\alpha\\right)={\\frac{n}{d}}\\operatorname{tr}_{E/F}(\\alpha)={\\frac{n}{d}}\\operatorname{c}_{1}.\n$$  \n\nSimilarly,  \n\n$$\nN_{K/F}(\\alpha)=N_{E/F}(N_{K/E}(\\alpha))=N_{E/F}(\\alpha^{n/d})=N_{E/F}(\\alpha)^{n/d}=c_{d}^{n/d}.\n$$  \n\n#  $\\S3$  The Rationality of the Zeta Function Associated to  $a_{0}\\,x_{0}^{m}\\,+\\,a_{1}x_{1}^{m}\\,+\\,\\cdot\\cdot\\,\\cdot\\,+\\,a_{n}\\,x_{n}^{m}$  \n\nLet  $f(x_{0},x_{1},\\ldots,x_{n})$  be the polynomial given in the title of this section. [notice that this is not the  $f(x)$  of Section 2]. Suppose that the coefficients are in  $F$, a finite field, with  $q$  elements and that  $q\\equiv1\\left(m\\right)$. We have to investigate the number  $N_{s}$  of elements in  $\\bar{H}_{f}(F_{s}).$  , where  $[F_{s}:F]=s$.  Theorem 2 of Chapter 10 shows that  $N_{s}$  is given by  \n\n$$\n\\displaystyle q^{s(n-1)}\\,+\\,q^{s(n-2)}\\,+\\,\\cdots\\,+\\,q^{s}\\,+\\,1+\\,\\frac1{q^{s}}\\sum_{\\chi_{0}^{(s)},\\,\\cdots,\\chi_{n}^{(s)}}\\chi_{0}^{(s)}(a_{0}^{-\\,1})\\cdots\\chi_{n}^{(s)}(a_{n}^{-\\,1})g(\\chi_{0}^{(s)})\\cdots g(\\chi_{n}^{(s)}),\n$$  \n\nwhere  $q^{s}$  is the number of elements in  $F_{s}$, and the  $\\chi_{i}^{(s)}$  are multiplicative characters of $F_{s}$ such that $\\chi_{i}^{(s)m}=\\varepsilon,\\chi_{i}^{(s)}\\neq\\varepsilon$ and $\\chi_{0}^{(s)}\\chi_{1}^{(s)}\\cdot\\cdot\\cdot\\chi_{n}^{(s)}=\\varepsilon$.\n\nWe must analyze the terms  $\\chi_{i}^{(s)}(a_{i}^{-1})$  and  $g(\\chi_{i}^{(s)})$. To do this we first relate characters of  $F_{s}$  to characters of $F$.\n\nLet  $\\chi$  be a character of  $F$  and set  $\\chi^{\\prime}=\\chi\\circ N_{F_{\\mathrm{s}}/F}$ ; i.e., for  $\\alpha\\in F_{s},\\,\\chi^{\\prime}(\\alpha)=\\chi(N_{F_{s}/F}(\\alpha))$  . Then one sees, using Proposition 11.2.2, that  $\\chi^{\\prime}$  is a character of  $F_{s}$, and moreover that  \n\n(a)  $\\chi\\neq\\rho$  implies that  $\\chi^{\\prime}\\neq\\rho^{\\prime}$  \n\n(b)  $\\chi^{m}=\\varepsilon$  implies that  ${{\\chi}}^{\\prime m}={{\\varepsilon}}$  \n\n$\\chi^{\\prime}(a)=\\chi(a)^{s}$  for all  $a\\in F$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$$N_{K/F}(\\alpha)=N_{E/F}(N_{K/E}(\\alpha))=N_{E/F}(\\alpha^{n/d})=N_{E/F}(\\alpha)^{n/d}=c_{d}^{n/d}.$$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/Taylor_Approximations_For_Stochastic_Partial_.pdf_112",
        "ID": "0717eb47-3104-47c5-b152-5077a7806577",
        "questions": "What is the Taylor approximation order given by the equation used in Section 7.7 to derive the numerical scheme (7.68)?",
        "answers": "1+min(1,2\u03b8)",
        "context": "This can also be written as  \n\n$$\n\\begin{array}{r l r}{\\displaystyle X_{t}=S_{\\Delta t}\\,X_{t_{0}}+\\left(\\int_{0}^{\\Delta t}S_{s}\\,d s\\right)F(X_{t_{0}})+\\left(O_{t}-S_{\\Delta t}\\,O_{t_{0}}\\right)}&{}&\\\\ {\\displaystyle+\\int_{t_{0}}^{t}S_{(t-s)}F^{\\prime}(X_{t_{0}})\\Delta\\,O_{s}\\,d s+O\\left((\\Delta t)^{1+\\operatorname*{min}(1,2\\theta)}\\right)}&{}&\\end{array}\n$$  \n\nand is a Taylor approximation of order  $1+\\operatorname*{min}(1,2\\theta)$  . It will be used in Section 7.7 to derive the numerical scheme (7.68).  \n\n# Taylor expansion of order  $1+\\operatorname*{min}(1,3\\theta)$  \n\nThe remainder term (7.34) consists of three parts, namely  \n\n$$\n\\begin{array}{r}{I_{*}^{1}[I_{*}^{0}](t)=O\\left((\\Delta t)^{2}\\right),\\qquad I_{*}^{2}[I_{*}^{0},\\Delta O](t)=O\\left((\\Delta t)^{2+\\theta}\\right),}\\\\ {I_{*}^{2}[\\Delta O,\\Delta O](t)=O\\left((\\Delta t)^{1+2\\theta}\\right).\\qquad}\\end{array}\n$$  \n\nSince  $\\theta<\\frac{1}{2}$  and hence  $\\operatorname*{min}(2,2+\\theta,1+2\\theta)=1+2\\theta$  in the examples in Section 7.6, the stochastic process  $I_{*}^{2}[\\Delta O,\\Delta O]$  will be expanded here. Applying Proposition 5 to this term yields  \n\n$$\nI_{*}^{2}[\\Delta O,\\Delta O]=I^{2}[\\Delta O,\\Delta O]+I_{*}^{3}[I_{*}^{0},\\Delta O,\\Delta O]+I_{*}^{3}[\\Delta O,\\Delta O,\\Delta O],\n$$  \n\nand inserting this into (7.33) then gives  \n\n$$\n\\Delta X=I^{0}+\\Delta O+I^{1}[\\Delta O]+I^{2}[\\Delta O,\\Delta O]+R,\n$$  \n\nwhere the remainder  $R\\in{\\mathfrak{C}}$  reads  \n\n$$\nR=I_{*}^{1}[I_{*}^{0}]+I_{*}^{2}[I_{*}^{0},\\Delta O]+I_{*}^{3}[I_{*}^{0},\\Delta O,\\Delta O]+I_{*}^{3}[\\Delta O,\\Delta O,\\Delta O].\n$$  \n\nBy Proposition 6  \n\n$$\nI_{*}^{3}[I_{*}^{0},\\Delta O,\\Delta O](t)=O\\left((\\Delta t)^{2+2\\theta}\\right),\\qquad I_{*}^{3}[\\Delta O,\\Delta O,\\Delta O](t)=O\\left((\\Delta t)^{1+3\\theta}\\right),\n$$  \n\nso  $R=O\\left((\\Delta t)^{1+\\operatorname*{min}(1,3\\theta)}\\right)$  since  $\\operatorname*{min}(2,2+\\theta,2+2\\theta,1+3\\theta)=1+\\operatorname*{min}(1,3\\theta)$  . Finally, the Taylor expansion written out fully is  \n\n$$\n\\begin{array}{c}{{X_{t}=S_{\\Delta t}X_{t_{0}}+\\displaystyle{\\left(\\displaystyle\\int_{0}^{\\Delta t}S_{s}\\,d s\\right)F(X_{t_{0}})+\\left(O_{t}-S_{\\Delta t}\\,O_{t_{0}}\\right)}+\\displaystyle{\\int_{t_{0}}^{t}S_{(t-s)}F^{\\prime}(X_{t_{0}})\\Delta O_{s}\\,d s}}}\\\\ {{+\\displaystyle{\\frac{1}{2}\\displaystyle\\int_{t_{0}}^{t}S_{(t-s)}F^{\\prime\\prime}(X_{t_{0}})(\\Delta O_{s},\\Delta O_{s})\\,d s+O\\left((\\Delta t)^{1+\\operatorname*{min}(1,3\\theta)}\\right).\\qquad(7.38)}}}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "and is a Taylor approximation of order 1+operatorname*{min}(1,2\u03b8) . It will be used in Section 7.7 to derive the numerical scheme (7.68).",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Taylor_Approximations_For_Stochastic_Partial_.pdf_112",
        "ID": "0719a856-b791-44d4-a51e-79030364180e",
        "questions": "In the context of the Taylor expansion, when $\\theta$ is less than $\\frac{1}{2}$, what is the order for the process $I_{*}^{2}[\\Delta O,\\Delta O](t)$?",
        "answers": "O((\u0394t)\u00b9\u207a\u00b2\u03b8)",
        "context": "This can also be written as  \n\n$$\n\\begin{array}{r l r}{\\displaystyle X_{t}=S_{\\Delta t}\\,X_{t_{0}}+\\left(\\int_{0}^{\\Delta t}S_{s}\\,d s\\right)F(X_{t_{0}})+\\left(O_{t}-S_{\\Delta t}\\,O_{t_{0}}\\right)}&{}&\\\\ {\\displaystyle+\\int_{t_{0}}^{t}S_{(t-s)}F^{\\prime}(X_{t_{0}})\\Delta\\,O_{s}\\,d s+O\\left((\\Delta t)^{1+\\operatorname*{min}(1,2\\theta)}\\right)}&{}&\\end{array}\n$$  \n\nand is a Taylor approximation of order  $1+\\operatorname*{min}(1,2\\theta)$  . It will be used in Section 7.7 to derive the numerical scheme (7.68).  \n\n# Taylor expansion of order  $1+\\operatorname*{min}(1,3\\theta)$  \n\nThe remainder term (7.34) consists of three parts, namely  \n\n$$\n\\begin{array}{r}{I_{*}^{1}[I_{*}^{0}](t)=O\\left((\\Delta t)^{2}\\right),\\qquad I_{*}^{2}[I_{*}^{0},\\Delta O](t)=O\\left((\\Delta t)^{2+\\theta}\\right),}\\\\ {I_{*}^{2}[\\Delta O,\\Delta O](t)=O\\left((\\Delta t)^{1+2\\theta}\\right).\\qquad}\\end{array}\n$$  \n\nSince  $\\theta<\\frac{1}{2}$  and hence  $\\operatorname*{min}(2,2+\\theta,1+2\\theta)=1+2\\theta$  in the examples in Section 7.6, the stochastic process  $I_{*}^{2}[\\Delta O,\\Delta O]$  will be expanded here. Applying Proposition 5 to this term yields  \n\n$$\nI_{*}^{2}[\\Delta O,\\Delta O]=I^{2}[\\Delta O,\\Delta O]+I_{*}^{3}[I_{*}^{0},\\Delta O,\\Delta O]+I_{*}^{3}[\\Delta O,\\Delta O,\\Delta O],\n$$  \n\nand inserting this into (7.33) then gives  \n\n$$\n\\Delta X=I^{0}+\\Delta O+I^{1}[\\Delta O]+I^{2}[\\Delta O,\\Delta O]+R,\n$$  \n\nwhere the remainder  $R\\in{\\mathfrak{C}}$  reads  \n\n$$\nR=I_{*}^{1}[I_{*}^{0}]+I_{*}^{2}[I_{*}^{0},\\Delta O]+I_{*}^{3}[I_{*}^{0},\\Delta O,\\Delta O]+I_{*}^{3}[\\Delta O,\\Delta O,\\Delta O].\n$$  \n\nBy Proposition 6  \n\n$$\nI_{*}^{3}[I_{*}^{0},\\Delta O,\\Delta O](t)=O\\left((\\Delta t)^{2+2\\theta}\\right),\\qquad I_{*}^{3}[\\Delta O,\\Delta O,\\Delta O](t)=O\\left((\\Delta t)^{1+3\\theta}\\right),\n$$  \n\nso  $R=O\\left((\\Delta t)^{1+\\operatorname*{min}(1,3\\theta)}\\right)$  since  $\\operatorname*{min}(2,2+\\theta,2+2\\theta,1+3\\theta)=1+\\operatorname*{min}(1,3\\theta)$  . Finally, the Taylor expansion written out fully is  \n\n$$\n\\begin{array}{c}{{X_{t}=S_{\\Delta t}X_{t_{0}}+\\displaystyle{\\left(\\displaystyle\\int_{0}^{\\Delta t}S_{s}\\,d s\\right)F(X_{t_{0}})+\\left(O_{t}-S_{\\Delta t}\\,O_{t_{0}}\\right)}+\\displaystyle{\\int_{t_{0}}^{t}S_{(t-s)}F^{\\prime}(X_{t_{0}})\\Delta O_{s}\\,d s}}}\\\\ {{+\\displaystyle{\\frac{1}{2}\\displaystyle\\int_{t_{0}}^{t}S_{(t-s)}F^{\\prime\\prime}(X_{t_{0}})(\\Delta O_{s},\\Delta O_{s})\\,d s+O\\left((\\Delta t)^{1+\\operatorname*{min}(1,3\\theta)}\\right).\\qquad(7.38)}}}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Since  \u03b8<1/2  and hence  operatorname*{min}(2,2+\u03b8,1+2\u03b8)=1+2\u03b8  in the examples in Section 7.6, the stochastic process  I_{*}^{2}[\\Delta O,\\Delta O]  will be expanded here.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Taylor_Approximations_For_Stochastic_Partial_.pdf_112",
        "ID": "071c6ee3-2c95-4683-afba-87f598ee53b7",
        "questions": "What is the remainder term $R$ in the Taylor expansion equation where $R$ belongs to ${\\mathfrak{C}}$?",
        "answers": "R= I_{*}^{1}[I_{*}^{0}]+I_{*}^{2}[I_{*}^{0},\u0394O]+I_{*}^{3}[I_{*}^{0},\u0394O,\u0394O]+I_{*}^{3}[\u0394O,\u0394O,\u0394O].",
        "context": "This can also be written as  \n\n$$\n\\begin{array}{r l r}{\\displaystyle X_{t}=S_{\\Delta t}\\,X_{t_{0}}+\\left(\\int_{0}^{\\Delta t}S_{s}\\,d s\\right)F(X_{t_{0}})+\\left(O_{t}-S_{\\Delta t}\\,O_{t_{0}}\\right)}&{}&\\\\ {\\displaystyle+\\int_{t_{0}}^{t}S_{(t-s)}F^{\\prime}(X_{t_{0}})\\Delta\\,O_{s}\\,d s+O\\left((\\Delta t)^{1+\\operatorname*{min}(1,2\\theta)}\\right)}&{}&\\end{array}\n$$  \n\nand is a Taylor approximation of order  $1+\\operatorname*{min}(1,2\\theta)$  . It will be used in Section 7.7 to derive the numerical scheme (7.68).  \n\n# Taylor expansion of order  $1+\\operatorname*{min}(1,3\\theta)$  \n\nThe remainder term (7.34) consists of three parts, namely  \n\n$$\n\\begin{array}{r}{I_{*}^{1}[I_{*}^{0}](t)=O\\left((\\Delta t)^{2}\\right),\\qquad I_{*}^{2}[I_{*}^{0},\\Delta O](t)=O\\left((\\Delta t)^{2+\\theta}\\right),}\\\\ {I_{*}^{2}[\\Delta O,\\Delta O](t)=O\\left((\\Delta t)^{1+2\\theta}\\right).\\qquad}\\end{array}\n$$  \n\nSince  $\\theta<\\frac{1}{2}$  and hence  $\\operatorname*{min}(2,2+\\theta,1+2\\theta)=1+2\\theta$  in the examples in Section 7.6, the stochastic process  $I_{*}^{2}[\\Delta O,\\Delta O]$  will be expanded here. Applying Proposition 5 to this term yields  \n\n$$\nI_{*}^{2}[\\Delta O,\\Delta O]=I^{2}[\\Delta O,\\Delta O]+I_{*}^{3}[I_{*}^{0},\\Delta O,\\Delta O]+I_{*}^{3}[\\Delta O,\\Delta O,\\Delta O],\n$$  \n\nand inserting this into (7.33) then gives  \n\n$$\n\\Delta X=I^{0}+\\Delta O+I^{1}[\\Delta O]+I^{2}[\\Delta O,\\Delta O]+R,\n$$  \n\nwhere the remainder  $R\\in{\\mathfrak{C}}$  reads  \n\n$$\nR=I_{*}^{1}[I_{*}^{0}]+I_{*}^{2}[I_{*}^{0},\\Delta O]+I_{*}^{3}[I_{*}^{0},\\Delta O,\\Delta O]+I_{*}^{3}[\\Delta O,\\Delta O,\\Delta O].\n$$  \n\nBy Proposition 6  \n\n$$\nI_{*}^{3}[I_{*}^{0},\\Delta O,\\Delta O](t)=O\\left((\\Delta t)^{2+2\\theta}\\right),\\qquad I_{*}^{3}[\\Delta O,\\Delta O,\\Delta O](t)=O\\left((\\Delta t)^{1+3\\theta}\\right),\n$$  \n\nso  $R=O\\left((\\Delta t)^{1+\\operatorname*{min}(1,3\\theta)}\\right)$  since  $\\operatorname*{min}(2,2+\\theta,2+2\\theta,1+3\\theta)=1+\\operatorname*{min}(1,3\\theta)$  . Finally, the Taylor expansion written out fully is  \n\n$$\n\\begin{array}{c}{{X_{t}=S_{\\Delta t}X_{t_{0}}+\\displaystyle{\\left(\\displaystyle\\int_{0}^{\\Delta t}S_{s}\\,d s\\right)F(X_{t_{0}})+\\left(O_{t}-S_{\\Delta t}\\,O_{t_{0}}\\right)}+\\displaystyle{\\int_{t_{0}}^{t}S_{(t-s)}F^{\\prime}(X_{t_{0}})\\Delta O_{s}\\,d s}}}\\\\ {{+\\displaystyle{\\frac{1}{2}\\displaystyle\\int_{t_{0}}^{t}S_{(t-s)}F^{\\prime\\prime}(X_{t_{0}})(\\Delta O_{s},\\Delta O_{s})\\,d s+O\\left((\\Delta t)^{1+\\operatorname*{min}(1,3\\theta)}\\right).\\qquad(7.38)}}}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "where the remainder  R\u2208{\\mathfrak{C}}  reads  \n$$ R=I_{*}^{1}[I_{*}^{0}]+I_{*}^{2}[I_{*}^{0},\u0394O]+I_{*}^{3}[I_{*}^{0},\u0394O,\u0394O]+I_{*}^{3}[\u0394O,\u0394O,\u0394O]. $$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Taylor_Approximations_For_Stochastic_Partial_.pdf_112",
        "ID": "071ffe50-24e1-4d44-9fca-49e8c93fdc20",
        "questions": "What is the Taylor approximation order for the expression provided in the first equation that includes the term $S_{\\Delta t} X_{t_{0}}$?",
        "answers": "1+\\operatorname*{min}(1,2\\theta)",
        "context": "This can also be written as  \n\n$$\n\\begin{array}{r l r}{\\displaystyle X_{t}=S_{\\Delta t}\\,X_{t_{0}}+\\left(\\int_{0}^{\\Delta t}S_{s}\\,d s\\right)F(X_{t_{0}})+\\left(O_{t}-S_{\\Delta t}\\,O_{t_{0}}\\right)}&{}&\\\\ {\\displaystyle+\\int_{t_{0}}^{t}S_{(t-s)}F^{\\prime}(X_{t_{0}})\\Delta\\,O_{s}\\,d s+O\\left((\\Delta t)^{1+\\operatorname*{min}(1,2\\theta)}\\right)}&{}&\\end{array}\n$$  \n\nand is a Taylor approximation of order  $1+\\operatorname*{min}(1,2\\theta)$  . It will be used in Section 7.7 to derive the numerical scheme (7.68).  \n\n# Taylor expansion of order  $1+\\operatorname*{min}(1,3\\theta)$  \n\nThe remainder term (7.34) consists of three parts, namely  \n\n$$\n\\begin{array}{r}{I_{*}^{1}[I_{*}^{0}](t)=O\\left((\\Delta t)^{2}\\right),\\qquad I_{*}^{2}[I_{*}^{0},\\Delta O](t)=O\\left((\\Delta t)^{2+\\theta}\\right),}\\\\ {I_{*}^{2}[\\Delta O,\\Delta O](t)=O\\left((\\Delta t)^{1+2\\theta}\\right).\\qquad}\\end{array}\n$$  \n\nSince  $\\theta<\\frac{1}{2}$  and hence  $\\operatorname*{min}(2,2+\\theta,1+2\\theta)=1+2\\theta$  in the examples in Section 7.6, the stochastic process  $I_{*}^{2}[\\Delta O,\\Delta O]$  will be expanded here. Applying Proposition 5 to this term yields  \n\n$$\nI_{*}^{2}[\\Delta O,\\Delta O]=I^{2}[\\Delta O,\\Delta O]+I_{*}^{3}[I_{*}^{0},\\Delta O,\\Delta O]+I_{*}^{3}[\\Delta O,\\Delta O,\\Delta O],\n$$  \n\nand inserting this into (7.33) then gives  \n\n$$\n\\Delta X=I^{0}+\\Delta O+I^{1}[\\Delta O]+I^{2}[\\Delta O,\\Delta O]+R,\n$$  \n\nwhere the remainder  $R\\in{\\mathfrak{C}}$  reads  \n\n$$\nR=I_{*}^{1}[I_{*}^{0}]+I_{*}^{2}[I_{*}^{0},\\Delta O]+I_{*}^{3}[I_{*}^{0},\\Delta O,\\Delta O]+I_{*}^{3}[\\Delta O,\\Delta O,\\Delta O].\n$$  \n\nBy Proposition 6  \n\n$$\nI_{*}^{3}[I_{*}^{0},\\Delta O,\\Delta O](t)=O\\left((\\Delta t)^{2+2\\theta}\\right),\\qquad I_{*}^{3}[\\Delta O,\\Delta O,\\Delta O](t)=O\\left((\\Delta t)^{1+3\\theta}\\right),\n$$  \n\nso  $R=O\\left((\\Delta t)^{1+\\operatorname*{min}(1,3\\theta)}\\right)$  since  $\\operatorname*{min}(2,2+\\theta,2+2\\theta,1+3\\theta)=1+\\operatorname*{min}(1,3\\theta)$  . Finally, the Taylor expansion written out fully is  \n\n$$\n\\begin{array}{c}{{X_{t}=S_{\\Delta t}X_{t_{0}}+\\displaystyle{\\left(\\displaystyle\\int_{0}^{\\Delta t}S_{s}\\,d s\\right)F(X_{t_{0}})+\\left(O_{t}-S_{\\Delta t}\\,O_{t_{0}}\\right)}+\\displaystyle{\\int_{t_{0}}^{t}S_{(t-s)}F^{\\prime}(X_{t_{0}})\\Delta O_{s}\\,d s}}}\\\\ {{+\\displaystyle{\\frac{1}{2}\\displaystyle\\int_{t_{0}}^{t}S_{(t-s)}F^{\\prime\\prime}(X_{t_{0}})(\\Delta O_{s},\\Delta O_{s})\\,d s+O\\left((\\Delta t)^{1+\\operatorname*{min}(1,3\\theta)}\\right).\\qquad(7.38)}}}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "and is a Taylor approximation of order $1+\\operatorname*{min}(1,2\\theta)$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/Taylor_Approximations_For_Stochastic_Partial_.pdf_112",
        "ID": "0726d44a-2152-43c7-821a-a15ef58c43ce",
        "questions": "According to the document, what is the order of the remainder $R$ when $\\theta<\\frac{1}{2}$?",
        "answers": "O\\left((\\Delta t)^{1+\\operatorname*{min}(1,3\\theta)}\\right)",
        "context": "This can also be written as  \n\n$$\n\\begin{array}{r l r}{\\displaystyle X_{t}=S_{\\Delta t}\\,X_{t_{0}}+\\left(\\int_{0}^{\\Delta t}S_{s}\\,d s\\right)F(X_{t_{0}})+\\left(O_{t}-S_{\\Delta t}\\,O_{t_{0}}\\right)}&{}&\\\\ {\\displaystyle+\\int_{t_{0}}^{t}S_{(t-s)}F^{\\prime}(X_{t_{0}})\\Delta\\,O_{s}\\,d s+O\\left((\\Delta t)^{1+\\operatorname*{min}(1,2\\theta)}\\right)}&{}&\\end{array}\n$$  \n\nand is a Taylor approximation of order  $1+\\operatorname*{min}(1,2\\theta)$  . It will be used in Section 7.7 to derive the numerical scheme (7.68).  \n\n# Taylor expansion of order  $1+\\operatorname*{min}(1,3\\theta)$  \n\nThe remainder term (7.34) consists of three parts, namely  \n\n$$\n\\begin{array}{r}{I_{*}^{1}[I_{*}^{0}](t)=O\\left((\\Delta t)^{2}\\right),\\qquad I_{*}^{2}[I_{*}^{0},\\Delta O](t)=O\\left((\\Delta t)^{2+\\theta}\\right),}\\\\ {I_{*}^{2}[\\Delta O,\\Delta O](t)=O\\left((\\Delta t)^{1+2\\theta}\\right).\\qquad}\\end{array}\n$$  \n\nSince  $\\theta<\\frac{1}{2}$  and hence  $\\operatorname*{min}(2,2+\\theta,1+2\\theta)=1+2\\theta$  in the examples in Section 7.6, the stochastic process  $I_{*}^{2}[\\Delta O,\\Delta O]$  will be expanded here. Applying Proposition 5 to this term yields  \n\n$$\nI_{*}^{2}[\\Delta O,\\Delta O]=I^{2}[\\Delta O,\\Delta O]+I_{*}^{3}[I_{*}^{0},\\Delta O,\\Delta O]+I_{*}^{3}[\\Delta O,\\Delta O,\\Delta O],\n$$  \n\nand inserting this into (7.33) then gives  \n\n$$\n\\Delta X=I^{0}+\\Delta O+I^{1}[\\Delta O]+I^{2}[\\Delta O,\\Delta O]+R,\n$$  \n\nwhere the remainder  $R\\in{\\mathfrak{C}}$  reads  \n\n$$\nR=I_{*}^{1}[I_{*}^{0}]+I_{*}^{2}[I_{*}^{0},\\Delta O]+I_{*}^{3}[I_{*}^{0},\\Delta O,\\Delta O]+I_{*}^{3}[\\Delta O,\\Delta O,\\Delta O].\n$$  \n\nBy Proposition 6  \n\n$$\nI_{*}^{3}[I_{*}^{0},\\Delta O,\\Delta O](t)=O\\left((\\Delta t)^{2+2\\theta}\\right),\\qquad I_{*}^{3}[\\Delta O,\\Delta O,\\Delta O](t)=O\\left((\\Delta t)^{1+3\\theta}\\right),\n$$  \n\nso  $R=O\\left((\\Delta t)^{1+\\operatorname*{min}(1,3\\theta)}\\right)$  since  $\\operatorname*{min}(2,2+\\theta,2+2\\theta,1+3\\theta)=1+\\operatorname*{min}(1,3\\theta)$  . Finally, the Taylor expansion written out fully is  \n\n$$\n\\begin{array}{c}{{X_{t}=S_{\\Delta t}X_{t_{0}}+\\displaystyle{\\left(\\displaystyle\\int_{0}^{\\Delta t}S_{s}\\,d s\\right)F(X_{t_{0}})+\\left(O_{t}-S_{\\Delta t}\\,O_{t_{0}}\\right)}+\\displaystyle{\\int_{t_{0}}^{t}S_{(t-s)}F^{\\prime}(X_{t_{0}})\\Delta O_{s}\\,d s}}}\\\\ {{+\\displaystyle{\\frac{1}{2}\\displaystyle\\int_{t_{0}}^{t}S_{(t-s)}F^{\\prime\\prime}(X_{t_{0}})(\\Delta O_{s},\\Delta O_{s})\\,d s+O\\left((\\Delta t)^{1+\\operatorname*{min}(1,3\\theta)}\\right).\\qquad(7.38)}}}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "so $R=O\\left((\\Delta t)^{1+\\operatorname*{min}(1,3\\theta)}\\right)$ since $\\operatorname*{min}(2,2+\\theta,2+2\\theta,1+3\\theta)=1+\\operatorname*{min}(1,3\\theta)$ .",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/Taylor_Approximations_For_Stochastic_Partial_.pdf_112",
        "ID": "074712fc-9efd-4e7b-a0d0-4ce1d581f828",
        "questions": "What are the components that make up the remainder term $R$ in the document?",
        "answers": "$R=I_{*}^{1}[I_{*}^{0}]+I_{*}^{2}[I_{*}^{0},\\Delta O]+I_{*}^{3}[I_{*}^{0},\\Delta O,\\Delta O]+I_{*}^{3}[\\Delta O,\\Delta O,\\Delta O]$",
        "context": "This can also be written as  \n\n$$\n\\begin{array}{r l r}{\\displaystyle X_{t}=S_{\\Delta t}\\,X_{t_{0}}+\\left(\\int_{0}^{\\Delta t}S_{s}\\,d s\\right)F(X_{t_{0}})+\\left(O_{t}-S_{\\Delta t}\\,O_{t_{0}}\\right)}&{}&\\\\ {\\displaystyle+\\int_{t_{0}}^{t}S_{(t-s)}F^{\\prime}(X_{t_{0}})\\Delta\\,O_{s}\\,d s+O\\left((\\Delta t)^{1+\\operatorname*{min}(1,2\\theta)}\\right)}&{}&\\end{array}\n$$  \n\nand is a Taylor approximation of order  $1+\\operatorname*{min}(1,2\\theta)$  . It will be used in Section 7.7 to derive the numerical scheme (7.68).  \n\n# Taylor expansion of order  $1+\\operatorname*{min}(1,3\\theta)$  \n\nThe remainder term (7.34) consists of three parts, namely  \n\n$$\n\\begin{array}{r}{I_{*}^{1}[I_{*}^{0}](t)=O\\left((\\Delta t)^{2}\\right),\\qquad I_{*}^{2}[I_{*}^{0},\\Delta O](t)=O\\left((\\Delta t)^{2+\\theta}\\right),}\\\\ {I_{*}^{2}[\\Delta O,\\Delta O](t)=O\\left((\\Delta t)^{1+2\\theta}\\right).\\qquad}\\end{array}\n$$  \n\nSince  $\\theta<\\frac{1}{2}$  and hence  $\\operatorname*{min}(2,2+\\theta,1+2\\theta)=1+2\\theta$  in the examples in Section 7.6, the stochastic process  $I_{*}^{2}[\\Delta O,\\Delta O]$  will be expanded here. Applying Proposition 5 to this term yields  \n\n$$\nI_{*}^{2}[\\Delta O,\\Delta O]=I^{2}[\\Delta O,\\Delta O]+I_{*}^{3}[I_{*}^{0},\\Delta O,\\Delta O]+I_{*}^{3}[\\Delta O,\\Delta O,\\Delta O],\n$$  \n\nand inserting this into (7.33) then gives  \n\n$$\n\\Delta X=I^{0}+\\Delta O+I^{1}[\\Delta O]+I^{2}[\\Delta O,\\Delta O]+R,\n$$  \n\nwhere the remainder  $R\\in{\\mathfrak{C}}$  reads  \n\n$$\nR=I_{*}^{1}[I_{*}^{0}]+I_{*}^{2}[I_{*}^{0},\\Delta O]+I_{*}^{3}[I_{*}^{0},\\Delta O,\\Delta O]+I_{*}^{3}[\\Delta O,\\Delta O,\\Delta O].\n$$  \n\nBy Proposition 6  \n\n$$\nI_{*}^{3}[I_{*}^{0},\\Delta O,\\Delta O](t)=O\\left((\\Delta t)^{2+2\\theta}\\right),\\qquad I_{*}^{3}[\\Delta O,\\Delta O,\\Delta O](t)=O\\left((\\Delta t)^{1+3\\theta}\\right),\n$$  \n\nso  $R=O\\left((\\Delta t)^{1+\\operatorname*{min}(1,3\\theta)}\\right)$  since  $\\operatorname*{min}(2,2+\\theta,2+2\\theta,1+3\\theta)=1+\\operatorname*{min}(1,3\\theta)$  . Finally, the Taylor expansion written out fully is  \n\n$$\n\\begin{array}{c}{{X_{t}=S_{\\Delta t}X_{t_{0}}+\\displaystyle{\\left(\\displaystyle\\int_{0}^{\\Delta t}S_{s}\\,d s\\right)F(X_{t_{0}})+\\left(O_{t}-S_{\\Delta t}\\,O_{t_{0}}\\right)}+\\displaystyle{\\int_{t_{0}}^{t}S_{(t-s)}F^{\\prime}(X_{t_{0}})\\Delta O_{s}\\,d s}}}\\\\ {{+\\displaystyle{\\frac{1}{2}\\displaystyle\\int_{t_{0}}^{t}S_{(t-s)}F^{\\prime\\prime}(X_{t_{0}})(\\Delta O_{s},\\Delta O_{s})\\,d s+O\\left((\\Delta t)^{1+\\operatorname*{min}(1,3\\theta)}\\right).\\qquad(7.38)}}}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "where the remainder $R\\in{\\mathfrak{C}}$ reads $R=I_{*}^{1}[I_{*}^{0}]+I_{*}^{2}[I_{*}^{0},\\Delta O]+I_{*}^{3}[I_{*}^{0},\\Delta O,\\Delta O]+I_{*}^{3}[\\Delta O,\\Delta O,\\Delta O].$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/UTX_-_Analysis_II.pdf_385",
        "ID": "074a2910-319e-43bc-96d7-027b5c3d2d4d",
        "questions": "What is the inequality that needs to hold for any continuous linear form \\( T:S \to \\mathbb{C} \\) to be considered a tempered distribution on \\( \\mathbb{R} \\) according to Schwartz?",
        "answers": "|T(f)| < \u000barepsilon",
        "context": "A finite result\u2014whence $M f \\in S$\u2014and implying the estimate  \n\n$$\nN_{r}(M f) \\leq c_{r}N_{r+1}(f)\n$$  \n\nwith a constant $c_{r}$ whose exact value is of little importance, because (6) is enough to establish the continuity of $M$.  \n\nAs a map of $S$ into $S$, the Fourier transform $F$ is also continuous in each sense. To see this without much calculating, first remark that  \n\n$$\nN_{p,q}(f) = N_{0}\\left(M^{p}D^{q}f\\right) = \\|M^{p}D^{q}f\\|_{\\mathbb{R}}\n$$  \n\nand then $N_{p,q}(\\tilde{f}) = N_{0}\\left(M^{p}D^{q}F\\tilde{f}\\right) = N_{0}\\left(M^{p}F M^{q}\\tilde{f}\\right) = N_{0}\\left(F D^{p}M^{q}\\tilde{f}\\right)$ by the \u201ccommutation formulae\u201d (31.2\") and (31.6). Now, in general,  \n\n$$\nN_{0}(F f) = \\operatorname*{sup}\\left|\\int f(x){\\overline{{\\mathbf{e}(x y)}}}d x\\right| \\leq \\int|f(x)|d x = \\|f\\|_{1};\n$$  \n\nsince the function $(x^{2}+1)f(x)$ is bounded by $N_{2}(f)$, by (3), one finds  \n\n$$\nN_{0}(F f) \\leq N_{2}(f)\\int\\left(x^{2}+1\\right)^{-1}d x,\n$$  \n\nwith a convergent integral whose exact value, $c = \\pi$, is not important. It follows that  \n\n$$\nN_{p,q}(\\hat{f}) = N_{0}\\left(F D^{p}M^{q}f\\right) \\leq c N_{2}\\left(D^{p}M^{q}f\\right);\n$$  \n\non applying (5) $p$ times to the function $M^{q}f$ one finds a result $\\leq N_{p+2}\\left(M^{q}f\\right)$ up to a constant factor, and by applying (6) $q$ times to $f$ one obtains a relation of the form $N_{p,q}(\\hat{f}) \\leq N_{p+q+2}(f)$ up to a constant factor. Remembering the definition (3) of $N_{r}$, we finally have  \n\n$$\nN_{r}(\\hat{f}) \\leq c_{r}^{\\prime}N_{r+2}(f)\n$$  \n\nwhere $c_{r}^{\\prime}$ is a new constant. This proves the continuity of the Fourier transform. Since it is bijective and quasi identical to its inverse map by virtue of the relation $\\widehat{\\widehat{f}}(x) = f(-x)$, we conclude that the Fourier transform is a bijective and bi continuous map of $s$ onto $S$, in other words what in topology one calls a homeomorphism (linear too) of $s$ onto $s$.  \n\nWith their systematic recourse to the operators $D, M$ and $F$, these calculations can appear a little abstract. But to write explicitly the integrals and derivatives which they mask would be even less enticing.  \n\nWe can now return to distribution theory. Following Schwartz, we will call any continuous linear form $T:S \\to \\mathbb{C}$ a tempered distribution on $\\mathbb{R}$. The inequality $|T(f)| < \\varepsilon$ has to hold for every $f \\in S$ \u201cclose enough\u201d to O; this means that there exists an $r \\in \\mathbb{N}$ and a $\\delta > 0$ such that",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "We can now return to distribution theory. Following Schwartz, we will call any continuous linear form $T:S \to \\mathbb{C}$ a tempered distribution on $\\mathbb{R}$. The inequality $|T(f)| < \u000barepsilon$ has to hold for every $f \\in S$ 'close enough' to O; this means that there exists an $r \\in \\mathbb{N}$ and a $\\delta > 0$ such that",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTX_-_Analysis_II.pdf_385",
        "ID": "074af7dc-29c4-48b3-971b-d58f50b7865f",
        "questions": "How is the constant factor denoted in the inequality \\( N_{r}(Mf) \\leq ? N_{r+1}(f) \\)?",
        "answers": "c_{r}",
        "context": "A finite result\u2014whence $M f \\in S$\u2014and implying the estimate  \n\n$$\nN_{r}(M f) \\leq c_{r}N_{r+1}(f)\n$$  \n\nwith a constant $c_{r}$ whose exact value is of little importance, because (6) is enough to establish the continuity of $M$.  \n\nAs a map of $S$ into $S$, the Fourier transform $F$ is also continuous in each sense. To see this without much calculating, first remark that  \n\n$$\nN_{p,q}(f) = N_{0}\\left(M^{p}D^{q}f\\right) = \\|M^{p}D^{q}f\\|_{\\mathbb{R}}\n$$  \n\nand then $N_{p,q}(\\tilde{f}) = N_{0}\\left(M^{p}D^{q}F\\tilde{f}\\right) = N_{0}\\left(M^{p}F M^{q}\\tilde{f}\\right) = N_{0}\\left(F D^{p}M^{q}\\tilde{f}\\right)$ by the \u201ccommutation formulae\u201d (31.2\") and (31.6). Now, in general,  \n\n$$\nN_{0}(F f) = \\operatorname*{sup}\\left|\\int f(x){\\overline{{\\mathbf{e}(x y)}}}d x\\right| \\leq \\int|f(x)|d x = \\|f\\|_{1};\n$$  \n\nsince the function $(x^{2}+1)f(x)$ is bounded by $N_{2}(f)$, by (3), one finds  \n\n$$\nN_{0}(F f) \\leq N_{2}(f)\\int\\left(x^{2}+1\\right)^{-1}d x,\n$$  \n\nwith a convergent integral whose exact value, $c = \\pi$, is not important. It follows that  \n\n$$\nN_{p,q}(\\hat{f}) = N_{0}\\left(F D^{p}M^{q}f\\right) \\leq c N_{2}\\left(D^{p}M^{q}f\\right);\n$$  \n\non applying (5) $p$ times to the function $M^{q}f$ one finds a result $\\leq N_{p+2}\\left(M^{q}f\\right)$ up to a constant factor, and by applying (6) $q$ times to $f$ one obtains a relation of the form $N_{p,q}(\\hat{f}) \\leq N_{p+q+2}(f)$ up to a constant factor. Remembering the definition (3) of $N_{r}$, we finally have  \n\n$$\nN_{r}(\\hat{f}) \\leq c_{r}^{\\prime}N_{r+2}(f)\n$$  \n\nwhere $c_{r}^{\\prime}$ is a new constant. This proves the continuity of the Fourier transform. Since it is bijective and quasi identical to its inverse map by virtue of the relation $\\widehat{\\widehat{f}}(x) = f(-x)$, we conclude that the Fourier transform is a bijective and bi continuous map of $s$ onto $S$, in other words what in topology one calls a homeomorphism (linear too) of $s$ onto $s$.  \n\nWith their systematic recourse to the operators $D, M$ and $F$, these calculations can appear a little abstract. But to write explicitly the integrals and derivatives which they mask would be even less enticing.  \n\nWe can now return to distribution theory. Following Schwartz, we will call any continuous linear form $T:S \\to \\mathbb{C}$ a tempered distribution on $\\mathbb{R}$. The inequality $|T(f)| < \\varepsilon$ has to hold for every $f \\in S$ \u201cclose enough\u201d to O; this means that there exists an $r \\in \\mathbb{N}$ and a $\\delta > 0$ such that",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "N_{r}(M f) \\leq c_{r}N_{r+1}(f) with a constant $c_{r}$ whose exact value is of little importance, because (6) is enough to establish the continuity of $M$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTX_-_Analysis_II.pdf_385",
        "ID": "074b68af-45e8-46a0-94a5-a5d08fe0b3ed",
        "questions": "Is the integral \\( \\int (x^{2}+1)^{-1} dx \\) convergent according to the document? If yes, what is its exact value?",
        "answers": "Yes, its exact value is \\( \\pi \\).",
        "context": "A finite result\u2014whence $M f \\in S$\u2014and implying the estimate  \n\n$$\nN_{r}(M f) \\leq c_{r}N_{r+1}(f)\n$$  \n\nwith a constant $c_{r}$ whose exact value is of little importance, because (6) is enough to establish the continuity of $M$.  \n\nAs a map of $S$ into $S$, the Fourier transform $F$ is also continuous in each sense. To see this without much calculating, first remark that  \n\n$$\nN_{p,q}(f) = N_{0}\\left(M^{p}D^{q}f\\right) = \\|M^{p}D^{q}f\\|_{\\mathbb{R}}\n$$  \n\nand then $N_{p,q}(\\tilde{f}) = N_{0}\\left(M^{p}D^{q}F\\tilde{f}\\right) = N_{0}\\left(M^{p}F M^{q}\\tilde{f}\\right) = N_{0}\\left(F D^{p}M^{q}\\tilde{f}\\right)$ by the \u201ccommutation formulae\u201d (31.2\") and (31.6). Now, in general,  \n\n$$\nN_{0}(F f) = \\operatorname*{sup}\\left|\\int f(x){\\overline{{\\mathbf{e}(x y)}}}d x\\right| \\leq \\int|f(x)|d x = \\|f\\|_{1};\n$$  \n\nsince the function $(x^{2}+1)f(x)$ is bounded by $N_{2}(f)$, by (3), one finds  \n\n$$\nN_{0}(F f) \\leq N_{2}(f)\\int\\left(x^{2}+1\\right)^{-1}d x,\n$$  \n\nwith a convergent integral whose exact value, $c = \\pi$, is not important. It follows that  \n\n$$\nN_{p,q}(\\hat{f}) = N_{0}\\left(F D^{p}M^{q}f\\right) \\leq c N_{2}\\left(D^{p}M^{q}f\\right);\n$$  \n\non applying (5) $p$ times to the function $M^{q}f$ one finds a result $\\leq N_{p+2}\\left(M^{q}f\\right)$ up to a constant factor, and by applying (6) $q$ times to $f$ one obtains a relation of the form $N_{p,q}(\\hat{f}) \\leq N_{p+q+2}(f)$ up to a constant factor. Remembering the definition (3) of $N_{r}$, we finally have  \n\n$$\nN_{r}(\\hat{f}) \\leq c_{r}^{\\prime}N_{r+2}(f)\n$$  \n\nwhere $c_{r}^{\\prime}$ is a new constant. This proves the continuity of the Fourier transform. Since it is bijective and quasi identical to its inverse map by virtue of the relation $\\widehat{\\widehat{f}}(x) = f(-x)$, we conclude that the Fourier transform is a bijective and bi continuous map of $s$ onto $S$, in other words what in topology one calls a homeomorphism (linear too) of $s$ onto $s$.  \n\nWith their systematic recourse to the operators $D, M$ and $F$, these calculations can appear a little abstract. But to write explicitly the integrals and derivatives which they mask would be even less enticing.  \n\nWe can now return to distribution theory. Following Schwartz, we will call any continuous linear form $T:S \\to \\mathbb{C}$ a tempered distribution on $\\mathbb{R}$. The inequality $|T(f)| < \\varepsilon$ has to hold for every $f \\in S$ \u201cclose enough\u201d to O; this means that there exists an $r \\in \\mathbb{N}$ and a $\\delta > 0$ such that",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Yes/No",
        "evidence_source": "text",
        "evidence_context": "with a convergent integral whose exact value, c = \\pi, is not important. It follows that N_{p,q}(\\hat{f}) = N_{0}(F D^{p}M^{q}f) \\leq c N_{2}(D^{p}M^{q}f);",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTX_-_Analysis_II.pdf_385",
        "ID": "07716ddf-e7a4-42f7-a7ef-50b1190fe075",
        "questions": "What is the upper bound for the Fourier norm \\(N_{r}(\\hat{f})\\) as shown in the document?",
        "answers": "$N_{r}(\\hat{f}) \\leq c_{r}^{\\prime}N_{r+2}(f)$",
        "context": "A finite result\u2014whence $M f \\in S$\u2014and implying the estimate  \n\n$$\nN_{r}(M f) \\leq c_{r}N_{r+1}(f)\n$$  \n\nwith a constant $c_{r}$ whose exact value is of little importance, because (6) is enough to establish the continuity of $M$.  \n\nAs a map of $S$ into $S$, the Fourier transform $F$ is also continuous in each sense. To see this without much calculating, first remark that  \n\n$$\nN_{p,q}(f) = N_{0}\\left(M^{p}D^{q}f\\right) = \\|M^{p}D^{q}f\\|_{\\mathbb{R}}\n$$  \n\nand then $N_{p,q}(\\tilde{f}) = N_{0}\\left(M^{p}D^{q}F\\tilde{f}\\right) = N_{0}\\left(M^{p}F M^{q}\\tilde{f}\\right) = N_{0}\\left(F D^{p}M^{q}\\tilde{f}\\right)$ by the \u201ccommutation formulae\u201d (31.2\") and (31.6). Now, in general,  \n\n$$\nN_{0}(F f) = \\operatorname*{sup}\\left|\\int f(x){\\overline{{\\mathbf{e}(x y)}}}d x\\right| \\leq \\int|f(x)|d x = \\|f\\|_{1};\n$$  \n\nsince the function $(x^{2}+1)f(x)$ is bounded by $N_{2}(f)$, by (3), one finds  \n\n$$\nN_{0}(F f) \\leq N_{2}(f)\\int\\left(x^{2}+1\\right)^{-1}d x,\n$$  \n\nwith a convergent integral whose exact value, $c = \\pi$, is not important. It follows that  \n\n$$\nN_{p,q}(\\hat{f}) = N_{0}\\left(F D^{p}M^{q}f\\right) \\leq c N_{2}\\left(D^{p}M^{q}f\\right);\n$$  \n\non applying (5) $p$ times to the function $M^{q}f$ one finds a result $\\leq N_{p+2}\\left(M^{q}f\\right)$ up to a constant factor, and by applying (6) $q$ times to $f$ one obtains a relation of the form $N_{p,q}(\\hat{f}) \\leq N_{p+q+2}(f)$ up to a constant factor. Remembering the definition (3) of $N_{r}$, we finally have  \n\n$$\nN_{r}(\\hat{f}) \\leq c_{r}^{\\prime}N_{r+2}(f)\n$$  \n\nwhere $c_{r}^{\\prime}$ is a new constant. This proves the continuity of the Fourier transform. Since it is bijective and quasi identical to its inverse map by virtue of the relation $\\widehat{\\widehat{f}}(x) = f(-x)$, we conclude that the Fourier transform is a bijective and bi continuous map of $s$ onto $S$, in other words what in topology one calls a homeomorphism (linear too) of $s$ onto $s$.  \n\nWith their systematic recourse to the operators $D, M$ and $F$, these calculations can appear a little abstract. But to write explicitly the integrals and derivatives which they mask would be even less enticing.  \n\nWe can now return to distribution theory. Following Schwartz, we will call any continuous linear form $T:S \\to \\mathbb{C}$ a tempered distribution on $\\mathbb{R}$. The inequality $|T(f)| < \\varepsilon$ has to hold for every $f \\in S$ \u201cclose enough\u201d to O; this means that there exists an $r \\in \\mathbb{N}$ and a $\\delta > 0$ such that",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "We finally have $N_{r}(\\hat{f}) \\leq c_{r}^{\\prime}N_{r+2}(f)$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/UTX_-_Analysis_II.pdf_385",
        "ID": "07750580-bdc5-4359-a45b-2246d30ce37c",
        "questions": "What constant value is the integral of \\((x^2 + 1)^{-1}\\) evaluated in the context of \\(N_{0}(F f)\\) upper-bound?",
        "answers": "$c = \\pi$",
        "context": "A finite result\u2014whence $M f \\in S$\u2014and implying the estimate  \n\n$$\nN_{r}(M f) \\leq c_{r}N_{r+1}(f)\n$$  \n\nwith a constant $c_{r}$ whose exact value is of little importance, because (6) is enough to establish the continuity of $M$.  \n\nAs a map of $S$ into $S$, the Fourier transform $F$ is also continuous in each sense. To see this without much calculating, first remark that  \n\n$$\nN_{p,q}(f) = N_{0}\\left(M^{p}D^{q}f\\right) = \\|M^{p}D^{q}f\\|_{\\mathbb{R}}\n$$  \n\nand then $N_{p,q}(\\tilde{f}) = N_{0}\\left(M^{p}D^{q}F\\tilde{f}\\right) = N_{0}\\left(M^{p}F M^{q}\\tilde{f}\\right) = N_{0}\\left(F D^{p}M^{q}\\tilde{f}\\right)$ by the \u201ccommutation formulae\u201d (31.2\") and (31.6). Now, in general,  \n\n$$\nN_{0}(F f) = \\operatorname*{sup}\\left|\\int f(x){\\overline{{\\mathbf{e}(x y)}}}d x\\right| \\leq \\int|f(x)|d x = \\|f\\|_{1};\n$$  \n\nsince the function $(x^{2}+1)f(x)$ is bounded by $N_{2}(f)$, by (3), one finds  \n\n$$\nN_{0}(F f) \\leq N_{2}(f)\\int\\left(x^{2}+1\\right)^{-1}d x,\n$$  \n\nwith a convergent integral whose exact value, $c = \\pi$, is not important. It follows that  \n\n$$\nN_{p,q}(\\hat{f}) = N_{0}\\left(F D^{p}M^{q}f\\right) \\leq c N_{2}\\left(D^{p}M^{q}f\\right);\n$$  \n\non applying (5) $p$ times to the function $M^{q}f$ one finds a result $\\leq N_{p+2}\\left(M^{q}f\\right)$ up to a constant factor, and by applying (6) $q$ times to $f$ one obtains a relation of the form $N_{p,q}(\\hat{f}) \\leq N_{p+q+2}(f)$ up to a constant factor. Remembering the definition (3) of $N_{r}$, we finally have  \n\n$$\nN_{r}(\\hat{f}) \\leq c_{r}^{\\prime}N_{r+2}(f)\n$$  \n\nwhere $c_{r}^{\\prime}$ is a new constant. This proves the continuity of the Fourier transform. Since it is bijective and quasi identical to its inverse map by virtue of the relation $\\widehat{\\widehat{f}}(x) = f(-x)$, we conclude that the Fourier transform is a bijective and bi continuous map of $s$ onto $S$, in other words what in topology one calls a homeomorphism (linear too) of $s$ onto $s$.  \n\nWith their systematic recourse to the operators $D, M$ and $F$, these calculations can appear a little abstract. But to write explicitly the integrals and derivatives which they mask would be even less enticing.  \n\nWe can now return to distribution theory. Following Schwartz, we will call any continuous linear form $T:S \\to \\mathbb{C}$ a tempered distribution on $\\mathbb{R}$. The inequality $|T(f)| < \\varepsilon$ has to hold for every $f \\in S$ \u201cclose enough\u201d to O; this means that there exists an $r \\in \\mathbb{N}$ and a $\\delta > 0$ such that",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "with a convergent integral whose exact value, $c = \\pi$, is not important.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/UTX_-_Analysis_II.pdf_385",
        "ID": "0777a678-3c89-4d01-883e-3b0c72e6ea7b",
        "questions": "In the context of the continuity of the map \\(M\\), what is the estimate given for \\(N_r(Mf)\\)?",
        "answers": "$N_{r}(M f) \\leq c_{r}N_{r+1}(f)$",
        "context": "A finite result\u2014whence $M f \\in S$\u2014and implying the estimate  \n\n$$\nN_{r}(M f) \\leq c_{r}N_{r+1}(f)\n$$  \n\nwith a constant $c_{r}$ whose exact value is of little importance, because (6) is enough to establish the continuity of $M$.  \n\nAs a map of $S$ into $S$, the Fourier transform $F$ is also continuous in each sense. To see this without much calculating, first remark that  \n\n$$\nN_{p,q}(f) = N_{0}\\left(M^{p}D^{q}f\\right) = \\|M^{p}D^{q}f\\|_{\\mathbb{R}}\n$$  \n\nand then $N_{p,q}(\\tilde{f}) = N_{0}\\left(M^{p}D^{q}F\\tilde{f}\\right) = N_{0}\\left(M^{p}F M^{q}\\tilde{f}\\right) = N_{0}\\left(F D^{p}M^{q}\\tilde{f}\\right)$ by the \u201ccommutation formulae\u201d (31.2\") and (31.6). Now, in general,  \n\n$$\nN_{0}(F f) = \\operatorname*{sup}\\left|\\int f(x){\\overline{{\\mathbf{e}(x y)}}}d x\\right| \\leq \\int|f(x)|d x = \\|f\\|_{1};\n$$  \n\nsince the function $(x^{2}+1)f(x)$ is bounded by $N_{2}(f)$, by (3), one finds  \n\n$$\nN_{0}(F f) \\leq N_{2}(f)\\int\\left(x^{2}+1\\right)^{-1}d x,\n$$  \n\nwith a convergent integral whose exact value, $c = \\pi$, is not important. It follows that  \n\n$$\nN_{p,q}(\\hat{f}) = N_{0}\\left(F D^{p}M^{q}f\\right) \\leq c N_{2}\\left(D^{p}M^{q}f\\right);\n$$  \n\non applying (5) $p$ times to the function $M^{q}f$ one finds a result $\\leq N_{p+2}\\left(M^{q}f\\right)$ up to a constant factor, and by applying (6) $q$ times to $f$ one obtains a relation of the form $N_{p,q}(\\hat{f}) \\leq N_{p+q+2}(f)$ up to a constant factor. Remembering the definition (3) of $N_{r}$, we finally have  \n\n$$\nN_{r}(\\hat{f}) \\leq c_{r}^{\\prime}N_{r+2}(f)\n$$  \n\nwhere $c_{r}^{\\prime}$ is a new constant. This proves the continuity of the Fourier transform. Since it is bijective and quasi identical to its inverse map by virtue of the relation $\\widehat{\\widehat{f}}(x) = f(-x)$, we conclude that the Fourier transform is a bijective and bi continuous map of $s$ onto $S$, in other words what in topology one calls a homeomorphism (linear too) of $s$ onto $s$.  \n\nWith their systematic recourse to the operators $D, M$ and $F$, these calculations can appear a little abstract. But to write explicitly the integrals and derivatives which they mask would be even less enticing.  \n\nWe can now return to distribution theory. Following Schwartz, we will call any continuous linear form $T:S \\to \\mathbb{C}$ a tempered distribution on $\\mathbb{R}$. The inequality $|T(f)| < \\varepsilon$ has to hold for every $f \\in S$ \u201cclose enough\u201d to O; this means that there exists an $r \\in \\mathbb{N}$ and a $\\delta > 0$ such that",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "A finite result\u2014whence $M f \\in S$\u2014and implying the estimate $N_{r}(M f) \\leq c_{r}N_{r+1}(f)$ with a constant $c_{r}$ whose exact value is of little importance.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/Applied_Mathematical_Demography,_Third_Edition_(Statistics_for_Biology_and_Health).pdf_466",
        "ID": "079092e4-537d-4c63-95a2-888492747f90",
        "questions": "What is the value of \\( R_{0} \\) when \\( h = 0.80 \\) and \\( k = 0.65 \\) in the given model?",
        "answers": "1.28",
        "context": "$\n\\begin{tabular}{lccccccc}\n \nh & \\multicolumn{7}{c}{k} \\\\\n\\cline{2-8}\n & 0.40 & 0.45 & 0.50 & 0.55 & 0.60 & 0.65 & 0.70 \\\\\n \n0.60 & 0.59 & 0.61 & 0.64 & 0.68 & 0.73 & 0.79 & 0.88 \\\\\n \n0.65 & 0.66 & 0.69 & 0.73 & 0.78 & 0.83 & 0.91 & 1.00 \\\\\n \n0.70 & 0.74 & 0.78 & 0.82 & 0.87 & 0.94 & 1.02 & 1.14 \\\\\n \n0.75 & 0.82 & 0.86 & 0.91 & 0.98 & 1.05 & 1.15 & 1.28 \\\\\n \n0.80 & 0.91 & 0.96 & 1.01 & 1.08 & 1.17 & 1.28 & 1.43 \\\\\n \n0.85 & 1.00 & 1.06 & 1.12 & 1.20 & 1.30 & 1.42 & 1.59 \\\\\n \n\\end{tabular}\n$\n\nStates. Now, since  \n\n$$\nR_{0}=\\frac{1}{1+s}\\left(h+\\frac{h^{2}}{1-k}\\right),\n$$  \n\nwe have  \n\n$$\n\\frac{d R_{0}}{d k}=\\frac{1}{1+s}\\left(\\frac{h}{1-k}\\right)^{2}.\n$$  \n\nAround  $s=1.05, h=0.80, k=0.65$  , we have  $d R_{0}/d k=2.55$  , so that each increase of  $0.01\\ \\mathrm{in}\\ k$  produces an increase of 0.0255 in  $R_{0}$  , and similarly for decreases.  \n\nTo see the effects of successive childbearing decisions on population growth, we need also to take account of timing. The age at which a woman has her first child, and the successive interbirth intervals, will evidently make a difference in the rate at which the population grows. Timing is the one element lacking in the present model. For the effect of its omission, consider  $h\\,=\\,0.80$  and  $k\\,=\\,0.65$  , so that  $R_{0}\\,=\\,2.63/2.05\\,=\\,1.28$  . If the mean age of childbearing (strictly, the length of generation) is 25 years, the intrinsic rate is 0.0099; if it is 30 years, the intrinsic rate is 0.0082.  \n\n# 16.9 For a Given Probability of Survivors, Lower Mortality Lowers the Rate of Increase  \n\nWhen mortality is high, a man who wants to have a son who will see him through his old age requires many children. This point has often been made before, but we still need clarification of the relation between mortality and the rate of population increase among people who want a certain assurance of surviving children. With the number of births given, the rate of increase  $r$  goes up as mortality  $\\mu_{x}$  goes down; we will see that the relation between  $r$  and  $\\mu_{x}$  is reversed if the birthrate is determined by the wish to have surviving sons.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "For the effect of its omission, consider  $h\\,=\\,0.80$  and  $k\\,=\\,0.65$  , so that  $R_{0}\\,=\\,2.63/2.05\\,=\\,1.28$  .",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Applied_Mathematical_Demography,_Third_Edition_(Statistics_for_Biology_and_Health).pdf_466",
        "ID": "0791002d-fc4f-4338-972b-8e79021fcf08",
        "questions": "By how much does \\( R_{0} \\) increase with each 0.01 increase in \\( k \\) around \\( s=1.05, h=0.80, k=0.65 \\)?",
        "answers": "0.0255",
        "context": "$\n\\begin{tabular}{lccccccc}\n \nh & \\multicolumn{7}{c}{k} \\\\\n\\cline{2-8}\n & 0.40 & 0.45 & 0.50 & 0.55 & 0.60 & 0.65 & 0.70 \\\\\n \n0.60 & 0.59 & 0.61 & 0.64 & 0.68 & 0.73 & 0.79 & 0.88 \\\\\n \n0.65 & 0.66 & 0.69 & 0.73 & 0.78 & 0.83 & 0.91 & 1.00 \\\\\n \n0.70 & 0.74 & 0.78 & 0.82 & 0.87 & 0.94 & 1.02 & 1.14 \\\\\n \n0.75 & 0.82 & 0.86 & 0.91 & 0.98 & 1.05 & 1.15 & 1.28 \\\\\n \n0.80 & 0.91 & 0.96 & 1.01 & 1.08 & 1.17 & 1.28 & 1.43 \\\\\n \n0.85 & 1.00 & 1.06 & 1.12 & 1.20 & 1.30 & 1.42 & 1.59 \\\\\n \n\\end{tabular}\n$\n\nStates. Now, since  \n\n$$\nR_{0}=\\frac{1}{1+s}\\left(h+\\frac{h^{2}}{1-k}\\right),\n$$  \n\nwe have  \n\n$$\n\\frac{d R_{0}}{d k}=\\frac{1}{1+s}\\left(\\frac{h}{1-k}\\right)^{2}.\n$$  \n\nAround  $s=1.05, h=0.80, k=0.65$  , we have  $d R_{0}/d k=2.55$  , so that each increase of  $0.01\\ \\mathrm{in}\\ k$  produces an increase of 0.0255 in  $R_{0}$  , and similarly for decreases.  \n\nTo see the effects of successive childbearing decisions on population growth, we need also to take account of timing. The age at which a woman has her first child, and the successive interbirth intervals, will evidently make a difference in the rate at which the population grows. Timing is the one element lacking in the present model. For the effect of its omission, consider  $h\\,=\\,0.80$  and  $k\\,=\\,0.65$  , so that  $R_{0}\\,=\\,2.63/2.05\\,=\\,1.28$  . If the mean age of childbearing (strictly, the length of generation) is 25 years, the intrinsic rate is 0.0099; if it is 30 years, the intrinsic rate is 0.0082.  \n\n# 16.9 For a Given Probability of Survivors, Lower Mortality Lowers the Rate of Increase  \n\nWhen mortality is high, a man who wants to have a son who will see him through his old age requires many children. This point has often been made before, but we still need clarification of the relation between mortality and the rate of population increase among people who want a certain assurance of surviving children. With the number of births given, the rate of increase  $r$  goes up as mortality  $\\mu_{x}$  goes down; we will see that the relation between  $r$  and  $\\mu_{x}$  is reversed if the birthrate is determined by the wish to have surviving sons.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Around  $s=1.05, h=0.80, k=0.65$  , we have  $d R_{0}/d k=2.55$  , so that each increase of  $0.01\\ \\mathrm{in}\\ k$  produces an increase of 0.0255 in  $R_{0}$  , and similarly for decreases.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Applied_Mathematical_Demography,_Third_Edition_(Statistics_for_Biology_and_Health).pdf_466",
        "ID": "079720d1-63aa-49e3-afdb-2d547d0dfcc6",
        "questions": "If the intrinsic rate is 0.0082, what is the mean age of childbearing in the given population model?",
        "answers": "30 years",
        "context": "$\n\\begin{tabular}{lccccccc}\n \nh & \\multicolumn{7}{c}{k} \\\\\n\\cline{2-8}\n & 0.40 & 0.45 & 0.50 & 0.55 & 0.60 & 0.65 & 0.70 \\\\\n \n0.60 & 0.59 & 0.61 & 0.64 & 0.68 & 0.73 & 0.79 & 0.88 \\\\\n \n0.65 & 0.66 & 0.69 & 0.73 & 0.78 & 0.83 & 0.91 & 1.00 \\\\\n \n0.70 & 0.74 & 0.78 & 0.82 & 0.87 & 0.94 & 1.02 & 1.14 \\\\\n \n0.75 & 0.82 & 0.86 & 0.91 & 0.98 & 1.05 & 1.15 & 1.28 \\\\\n \n0.80 & 0.91 & 0.96 & 1.01 & 1.08 & 1.17 & 1.28 & 1.43 \\\\\n \n0.85 & 1.00 & 1.06 & 1.12 & 1.20 & 1.30 & 1.42 & 1.59 \\\\\n \n\\end{tabular}\n$\n\nStates. Now, since  \n\n$$\nR_{0}=\\frac{1}{1+s}\\left(h+\\frac{h^{2}}{1-k}\\right),\n$$  \n\nwe have  \n\n$$\n\\frac{d R_{0}}{d k}=\\frac{1}{1+s}\\left(\\frac{h}{1-k}\\right)^{2}.\n$$  \n\nAround  $s=1.05, h=0.80, k=0.65$  , we have  $d R_{0}/d k=2.55$  , so that each increase of  $0.01\\ \\mathrm{in}\\ k$  produces an increase of 0.0255 in  $R_{0}$  , and similarly for decreases.  \n\nTo see the effects of successive childbearing decisions on population growth, we need also to take account of timing. The age at which a woman has her first child, and the successive interbirth intervals, will evidently make a difference in the rate at which the population grows. Timing is the one element lacking in the present model. For the effect of its omission, consider  $h\\,=\\,0.80$  and  $k\\,=\\,0.65$  , so that  $R_{0}\\,=\\,2.63/2.05\\,=\\,1.28$  . If the mean age of childbearing (strictly, the length of generation) is 25 years, the intrinsic rate is 0.0099; if it is 30 years, the intrinsic rate is 0.0082.  \n\n# 16.9 For a Given Probability of Survivors, Lower Mortality Lowers the Rate of Increase  \n\nWhen mortality is high, a man who wants to have a son who will see him through his old age requires many children. This point has often been made before, but we still need clarification of the relation between mortality and the rate of population increase among people who want a certain assurance of surviving children. With the number of births given, the rate of increase  $r$  goes up as mortality  $\\mu_{x}$  goes down; we will see that the relation between  $r$  and  $\\mu_{x}$  is reversed if the birthrate is determined by the wish to have surviving sons.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "If the mean age of childbearing (strictly, the length of generation) is 25 years, the intrinsic rate is 0.0099; if it is 30 years, the intrinsic rate is 0.0082.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Applied_Mathematical_Demography,_Third_Edition_(Statistics_for_Biology_and_Health).pdf_466",
        "ID": "07991818-0e7b-4cac-8f1d-04cc8eb0f052",
        "questions": "What is the value of R\u2080 when h=0.80 and k=0.65, according to the equations provided?",
        "answers": "1.28",
        "context": "$\n\\begin{tabular}{lccccccc}\n \nh & \\multicolumn{7}{c}{k} \\\\\n\\cline{2-8}\n & 0.40 & 0.45 & 0.50 & 0.55 & 0.60 & 0.65 & 0.70 \\\\\n \n0.60 & 0.59 & 0.61 & 0.64 & 0.68 & 0.73 & 0.79 & 0.88 \\\\\n \n0.65 & 0.66 & 0.69 & 0.73 & 0.78 & 0.83 & 0.91 & 1.00 \\\\\n \n0.70 & 0.74 & 0.78 & 0.82 & 0.87 & 0.94 & 1.02 & 1.14 \\\\\n \n0.75 & 0.82 & 0.86 & 0.91 & 0.98 & 1.05 & 1.15 & 1.28 \\\\\n \n0.80 & 0.91 & 0.96 & 1.01 & 1.08 & 1.17 & 1.28 & 1.43 \\\\\n \n0.85 & 1.00 & 1.06 & 1.12 & 1.20 & 1.30 & 1.42 & 1.59 \\\\\n \n\\end{tabular}\n$\n\nStates. Now, since  \n\n$$\nR_{0}=\\frac{1}{1+s}\\left(h+\\frac{h^{2}}{1-k}\\right),\n$$  \n\nwe have  \n\n$$\n\\frac{d R_{0}}{d k}=\\frac{1}{1+s}\\left(\\frac{h}{1-k}\\right)^{2}.\n$$  \n\nAround  $s=1.05, h=0.80, k=0.65$  , we have  $d R_{0}/d k=2.55$  , so that each increase of  $0.01\\ \\mathrm{in}\\ k$  produces an increase of 0.0255 in  $R_{0}$  , and similarly for decreases.  \n\nTo see the effects of successive childbearing decisions on population growth, we need also to take account of timing. The age at which a woman has her first child, and the successive interbirth intervals, will evidently make a difference in the rate at which the population grows. Timing is the one element lacking in the present model. For the effect of its omission, consider  $h\\,=\\,0.80$  and  $k\\,=\\,0.65$  , so that  $R_{0}\\,=\\,2.63/2.05\\,=\\,1.28$  . If the mean age of childbearing (strictly, the length of generation) is 25 years, the intrinsic rate is 0.0099; if it is 30 years, the intrinsic rate is 0.0082.  \n\n# 16.9 For a Given Probability of Survivors, Lower Mortality Lowers the Rate of Increase  \n\nWhen mortality is high, a man who wants to have a son who will see him through his old age requires many children. This point has often been made before, but we still need clarification of the relation between mortality and the rate of population increase among people who want a certain assurance of surviving children. With the number of births given, the rate of increase  $r$  goes up as mortality  $\\mu_{x}$  goes down; we will see that the relation between  $r$  and  $\\mu_{x}$  is reversed if the birthrate is determined by the wish to have surviving sons.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Numeric",
        "evidence_source": "equation",
        "evidence_context": "consider  $h\\,=\\,0.80$  and  $k\\,=\\,0.65$  , so that  $R_{0}\\,=\\,2.63/2.05\\,=\\,1.28$  .",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/Applied_Mathematical_Demography,_Third_Edition_(Statistics_for_Biology_and_Health).pdf_466",
        "ID": "079aec91-13d7-4fa7-9f06-74c4bd4ad557",
        "questions": "Calculate the value of \\(\frac{d R_{0}}{d k}\\) when \\(h = 0.80\\) and \\(k = 0.65\\), given the expression for \\(\frac{d R_{0}}{d k}\\).",
        "answers": "2.55",
        "context": "$\n\\begin{tabular}{lccccccc}\n \nh & \\multicolumn{7}{c}{k} \\\\\n\\cline{2-8}\n & 0.40 & 0.45 & 0.50 & 0.55 & 0.60 & 0.65 & 0.70 \\\\\n \n0.60 & 0.59 & 0.61 & 0.64 & 0.68 & 0.73 & 0.79 & 0.88 \\\\\n \n0.65 & 0.66 & 0.69 & 0.73 & 0.78 & 0.83 & 0.91 & 1.00 \\\\\n \n0.70 & 0.74 & 0.78 & 0.82 & 0.87 & 0.94 & 1.02 & 1.14 \\\\\n \n0.75 & 0.82 & 0.86 & 0.91 & 0.98 & 1.05 & 1.15 & 1.28 \\\\\n \n0.80 & 0.91 & 0.96 & 1.01 & 1.08 & 1.17 & 1.28 & 1.43 \\\\\n \n0.85 & 1.00 & 1.06 & 1.12 & 1.20 & 1.30 & 1.42 & 1.59 \\\\\n \n\\end{tabular}\n$\n\nStates. Now, since  \n\n$$\nR_{0}=\\frac{1}{1+s}\\left(h+\\frac{h^{2}}{1-k}\\right),\n$$  \n\nwe have  \n\n$$\n\\frac{d R_{0}}{d k}=\\frac{1}{1+s}\\left(\\frac{h}{1-k}\\right)^{2}.\n$$  \n\nAround  $s=1.05, h=0.80, k=0.65$  , we have  $d R_{0}/d k=2.55$  , so that each increase of  $0.01\\ \\mathrm{in}\\ k$  produces an increase of 0.0255 in  $R_{0}$  , and similarly for decreases.  \n\nTo see the effects of successive childbearing decisions on population growth, we need also to take account of timing. The age at which a woman has her first child, and the successive interbirth intervals, will evidently make a difference in the rate at which the population grows. Timing is the one element lacking in the present model. For the effect of its omission, consider  $h\\,=\\,0.80$  and  $k\\,=\\,0.65$  , so that  $R_{0}\\,=\\,2.63/2.05\\,=\\,1.28$  . If the mean age of childbearing (strictly, the length of generation) is 25 years, the intrinsic rate is 0.0099; if it is 30 years, the intrinsic rate is 0.0082.  \n\n# 16.9 For a Given Probability of Survivors, Lower Mortality Lowers the Rate of Increase  \n\nWhen mortality is high, a man who wants to have a son who will see him through his old age requires many children. This point has often been made before, but we still need clarification of the relation between mortality and the rate of population increase among people who want a certain assurance of surviving children. With the number of births given, the rate of increase  $r$  goes up as mortality  $\\mu_{x}$  goes down; we will see that the relation between  $r$  and  $\\mu_{x}$  is reversed if the birthrate is determined by the wish to have surviving sons.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Numeric",
        "evidence_source": "equation",
        "evidence_context": "Around  $s=1.05, h=0.80, k=0.65$  , we have  $d R_{0}/d k=2.55$  ,",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/Applied_Mathematical_Demography,_Third_Edition_(Statistics_for_Biology_and_Health).pdf_466",
        "ID": "079b2d72-86de-4552-9152-7d3846c4f1c4",
        "questions": "How does each increase of 0.01 in k affect R\u2080 based on the derivative expression of R\u2080 with respect to k?",
        "answers": "Each increase of 0.01 in k produces an increase of 0.0255 in R\u2080.",
        "context": "$\n\\begin{tabular}{lccccccc}\n \nh & \\multicolumn{7}{c}{k} \\\\\n\\cline{2-8}\n & 0.40 & 0.45 & 0.50 & 0.55 & 0.60 & 0.65 & 0.70 \\\\\n \n0.60 & 0.59 & 0.61 & 0.64 & 0.68 & 0.73 & 0.79 & 0.88 \\\\\n \n0.65 & 0.66 & 0.69 & 0.73 & 0.78 & 0.83 & 0.91 & 1.00 \\\\\n \n0.70 & 0.74 & 0.78 & 0.82 & 0.87 & 0.94 & 1.02 & 1.14 \\\\\n \n0.75 & 0.82 & 0.86 & 0.91 & 0.98 & 1.05 & 1.15 & 1.28 \\\\\n \n0.80 & 0.91 & 0.96 & 1.01 & 1.08 & 1.17 & 1.28 & 1.43 \\\\\n \n0.85 & 1.00 & 1.06 & 1.12 & 1.20 & 1.30 & 1.42 & 1.59 \\\\\n \n\\end{tabular}\n$\n\nStates. Now, since  \n\n$$\nR_{0}=\\frac{1}{1+s}\\left(h+\\frac{h^{2}}{1-k}\\right),\n$$  \n\nwe have  \n\n$$\n\\frac{d R_{0}}{d k}=\\frac{1}{1+s}\\left(\\frac{h}{1-k}\\right)^{2}.\n$$  \n\nAround  $s=1.05, h=0.80, k=0.65$  , we have  $d R_{0}/d k=2.55$  , so that each increase of  $0.01\\ \\mathrm{in}\\ k$  produces an increase of 0.0255 in  $R_{0}$  , and similarly for decreases.  \n\nTo see the effects of successive childbearing decisions on population growth, we need also to take account of timing. The age at which a woman has her first child, and the successive interbirth intervals, will evidently make a difference in the rate at which the population grows. Timing is the one element lacking in the present model. For the effect of its omission, consider  $h\\,=\\,0.80$  and  $k\\,=\\,0.65$  , so that  $R_{0}\\,=\\,2.63/2.05\\,=\\,1.28$  . If the mean age of childbearing (strictly, the length of generation) is 25 years, the intrinsic rate is 0.0099; if it is 30 years, the intrinsic rate is 0.0082.  \n\n# 16.9 For a Given Probability of Survivors, Lower Mortality Lowers the Rate of Increase  \n\nWhen mortality is high, a man who wants to have a son who will see him through his old age requires many children. This point has often been made before, but we still need clarification of the relation between mortality and the rate of population increase among people who want a certain assurance of surviving children. With the number of births given, the rate of increase  $r$  goes up as mortality  $\\mu_{x}$  goes down; we will see that the relation between  $r$  and  $\\mu_{x}$  is reversed if the birthrate is determined by the wish to have surviving sons.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "each increase of  $0.01\\ \\mathrm{in}\\ k$  produces an increase of 0.0255 in  $R_{0}$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/UTX_-_Proof_Theory.pdf_208",
        "ID": "07a446fe-5e0b-44ea-8034-a0664417d108",
        "questions": "In the context of the document, what is the value of gamma when alpha equals V(Omega)?",
        "answers": "omega_1",
        "context": "$$\n\\begin{array}{r l}&{\\beta\\in\\mathcal{B}_{\\Theta}\\cap\\left(\\Theta+1\\right)\\,\\land\\,\\alpha\\in\\mathcal{B}_{b^{S t}}\\ \\Rightarrow\\ \\alpha^{V}\\in\\mathcal{B}_{\\beta^{V}}^{V}}\\\\ &{\\beta\\in\\mathcal{B}_{\\Theta+1}\\,\\land\\,\\alpha\\in C r\\left(\\beta\\right)\\ \\Rightarrow\\ \\alpha^{V}\\in C r\\left(\\beta^{V}\\right)\\mathrm{.}}\\end{array}\n$$  \n\nProperty (9.42) holds true since $ \\alpha \\in Cr(\\beta) $  implies that there is a $ \\beta_0 \\geq \\beta $ such that \n$ alpha \\in Cr(\\beta_0) \\setminus Cr(\\beta_0 + 1) $ . Then $ \\alpha = \\bar{\\varphi}_{\\beta_0}(\\eta) $  for some $ \\eta $  and thus $ \\alpha^V = \\lceil \\alpha^{-1} V\\rceil = \n\\bar{\\varphi}_{\\beta_0} \\vee \\lceil \\eta^{-1} V\\rceil \\in Cr(\\beta'_0) \\subseteq Cr(\\beta^V) $  since $ \\beta^V \\leq \\beta'_0 $ by (9.40).\n\n\nFor $\\beta\\in\\mathcal{B}_{\\Theta}\\cap(\\Theta+1)$, the interpretation V is thus an embedding from $\\mathcal{B}_{\\beta}$ into\n\n  $\\mathcal{B}_{\\beta^{V}}^{V}$  prove that this embedding is also on to. The proof will need a relativized version of $\\psi_{V}(\\alpha)\\in\\mathcal{B}_{\\beta}^{V,n}$   $\\alpha_{0}\\in\\mathcal{B}_{\\beta}^{V,n}$  such that $\\alpha_{0}\\in\\mathcal{B}_{\\alpha_{0}}^{V}$   $\\psi_{V}(\\alpha)=\\psi_{V}(\\alpha_{0})$   $\\mathcal{B}_{\\beta}^{V,n}$   $B_{\\beta}^{n}$  Lemma 9.6.2 only needs $\\psi(\\alpha)<\\Omega$, it relativizes easily to interpretations which are good relative to some $\\Theta$  \n\n9.7.8 Lemma  $Let\\;V$  be a good interpretation relative to $\\Theta$ and $\\beta\\in\\mathcal{B}_{\\Theta}\\cap(\\Theta+1)$. Then for every $\\alpha\\in\\mathcal{B}_{\\beta^{V}}^{V}$ there is a $\\gamma\\in{\\mathcal{B}}_{\\beta}$ such that $\\alpha=\\gamma^{V}$. Moreover, we have $\\alpha\\in S C$ iff $\\gamma\\in S C$ and $\\alpha\\in\\mathbb{H}$ iff $\\gamma\\in\\mathbb{H}$  \n\nProof Let $\\alpha\\in\\mathcal{B}_{\\beta}^{V,n}$. We prove the lemma by induction on  $\\beta^{V}$  with side induction on n.\n\nIf $\\alpha=0$, we put $\\gamma:=0$ and if $\\alpha=V(\\Omega)$, we put $\\gamma:=\\omega_{1}$. Now assume $\\alpha=_{NF}\\alpha_{1}+\\cdot\\cdot\\cdot+\\alpha_{n}$. Then $\\mathbb{H}\\ni\\alpha_{i}<\\alpha$ for $i=1,\\dots,n$. By the main induction hypothesis there are ordinals $\\gamma_{i}\\in\\mathcal{B}_{\\beta}$ such that $\\alpha_{i}=\\gamma_{i}^{V}$ and $\\gamma_{i}\\in\\mathbb{H}$. By equation (9.40) we obtain\n\n  $\\gamma_{1}\\geq\\ldots\\geq\\gamma_{n}$ and put $\\gamma:=\\gamma_{1}\\cdots+\\gamma_{n}$. Then $ \\gamma =_{\\_{NF}} \\gamma_1 + \\cdots + \\gamma_n  $  and $\\gamma^{V}=\\gamma_{1}^{V}\\cdots+\\gamma_{n}^{V},  \\gamma\\in{\\mathcal{B}}_\\beta$ and $\\gamma\\not\\in{\\mathbb H}$  \n\nNext assume $\\alpha=\\bar{\\varphi}_{\\alpha_{1}}(\\alpha_{2})$. Then $\\alpha\\in\\mathbb{H}\\setminus S C$ and $\\alpha_{l}<\\alpha$. By the main induction hypothesis there are ordinals $\\gamma_{1},\\gamma_{2}\\in{\\mathcal{B}}_{\\beta}$ such that $\\gamma_{i}^{V}=\\alpha_{i}$ for $i=1,2$. Let $\\gamma=$   $\\bar{\\varphi}_{\\gamma_{1}}(\\gamma_{2})$. Then $\\gamma\\in{\\mathcal{B}}_{\\beta}$ and $\\gamma_{l}<\\gamma$ for $i=1,2$  \n\n$\\alpha=\\psi_{V}(\\eta)$   $\\eta\\in\\mathcal{B}_{\\beta^{V}}^{V,n-1}\\cap\\beta^{V}$. Then $\\alpha\\in SC$   $\\eta_{0}\\in\\mathcal{B}_{\\beta^{V}}^{V,n-1}\\cap\\beta^{V}$ such that $\\eta_{0}\\in\\mathcal{B}_{\\eta_{0}}^{V}$ and $\\alpha=\\psi_{V}(\\eta_{0})$. By induction hypothesis there is an $\\alpha_{0}$ such that $\\eta_{0}=\\alpha_{0}^{V}$, hence $\\alpha_{0}^{V}\\in\\mathcal{B}_{\\alpha_{0}^{V}}^{V}$, which implies $ \\alpha_{0}\\in{\\mathcal{B}}_{\\alpha_{0}}.\\operatorname{Sp}\\gamma:=\\psi(\\alpha_{0})$ implies $\\gamma\\in S C$ and $\\scriptstyle\\gamma\\,=\\,N F\\ \\psi(\\alpha_{0})$ and we obtain $\\alpha=\\psi_{V}(\\eta_{0})=\\psi_{V}(\\alpha_{0}^{V})=\\psi(\\alpha_{0})^{V}=\\gamma^{V}$ \u53e3  \n\n9.7.9 Theorem Let $V$ be an interpretation which is good relative to $ \\Theta $ and $ \\beta\\in\\mathcal{B}_{\\Theta}\\cap\\left(\\Theta+1\\right)$   $(\\mathcal{B}_{\\beta})^{V}=\\mathcal{B}_{\\beta^{V}}^{V}$  \n\nProof From $\\alpha\\in{\\mathcal{B}}\\beta$ we obtain $\\alpha^{V}\\,\\in\\,\\mathcal{B}_{\\beta^{V}}^{V}$ by (9.41). Hence $({\\mathcal{B}}_{\\beta})^{V}:=\\{\\alpha^{V}\\,|\\,\\,\\alpha\\in\\mathcal{B}_{\\beta}\\}\\subseteq\\mathcal{B}_{\\beta^{V}}^{V}$   $\\alpha\\in\\mathcal{B}_{\\beta^{V}}^{V}$ a $\\gamma\\in{\\mathcal{B}}_{\\beta}$ such that\n\n  $\\alpha=\\gamma^{V}\\in(\\mathcal{B}_{\\beta})^{V}$ by Lemma 9.7.8. Hence $\\mathcal{B}_{\\beta^{V}}^{V}\\subseteq(\\mathcal{B}_{\\beta})^{V}$ \u53e3",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "If alpha=V(Omega), we put gamma:=omega_1.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTX_-_Proof_Theory.pdf_208",
        "ID": "07afe1c5-1f37-40f4-9132-a7635a344fd7",
        "questions": "What does Lemma 9.7.8 assert regarding alpha in the set mathcal{B}_{beta^V}^V according to the document?",
        "answers": "There is a gamma in mathcal{B}_{beta} such that alpha=gamma^V.",
        "context": "$$\n\\begin{array}{r l}&{\\beta\\in\\mathcal{B}_{\\Theta}\\cap\\left(\\Theta+1\\right)\\,\\land\\,\\alpha\\in\\mathcal{B}_{b^{S t}}\\ \\Rightarrow\\ \\alpha^{V}\\in\\mathcal{B}_{\\beta^{V}}^{V}}\\\\ &{\\beta\\in\\mathcal{B}_{\\Theta+1}\\,\\land\\,\\alpha\\in C r\\left(\\beta\\right)\\ \\Rightarrow\\ \\alpha^{V}\\in C r\\left(\\beta^{V}\\right)\\mathrm{.}}\\end{array}\n$$  \n\nProperty (9.42) holds true since $ \\alpha \\in Cr(\\beta) $  implies that there is a $ \\beta_0 \\geq \\beta $ such that \n$ alpha \\in Cr(\\beta_0) \\setminus Cr(\\beta_0 + 1) $ . Then $ \\alpha = \\bar{\\varphi}_{\\beta_0}(\\eta) $  for some $ \\eta $  and thus $ \\alpha^V = \\lceil \\alpha^{-1} V\\rceil = \n\\bar{\\varphi}_{\\beta_0} \\vee \\lceil \\eta^{-1} V\\rceil \\in Cr(\\beta'_0) \\subseteq Cr(\\beta^V) $  since $ \\beta^V \\leq \\beta'_0 $ by (9.40).\n\n\nFor $\\beta\\in\\mathcal{B}_{\\Theta}\\cap(\\Theta+1)$, the interpretation V is thus an embedding from $\\mathcal{B}_{\\beta}$ into\n\n  $\\mathcal{B}_{\\beta^{V}}^{V}$  prove that this embedding is also on to. The proof will need a relativized version of $\\psi_{V}(\\alpha)\\in\\mathcal{B}_{\\beta}^{V,n}$   $\\alpha_{0}\\in\\mathcal{B}_{\\beta}^{V,n}$  such that $\\alpha_{0}\\in\\mathcal{B}_{\\alpha_{0}}^{V}$   $\\psi_{V}(\\alpha)=\\psi_{V}(\\alpha_{0})$   $\\mathcal{B}_{\\beta}^{V,n}$   $B_{\\beta}^{n}$  Lemma 9.6.2 only needs $\\psi(\\alpha)<\\Omega$, it relativizes easily to interpretations which are good relative to some $\\Theta$  \n\n9.7.8 Lemma  $Let\\;V$  be a good interpretation relative to $\\Theta$ and $\\beta\\in\\mathcal{B}_{\\Theta}\\cap(\\Theta+1)$. Then for every $\\alpha\\in\\mathcal{B}_{\\beta^{V}}^{V}$ there is a $\\gamma\\in{\\mathcal{B}}_{\\beta}$ such that $\\alpha=\\gamma^{V}$. Moreover, we have $\\alpha\\in S C$ iff $\\gamma\\in S C$ and $\\alpha\\in\\mathbb{H}$ iff $\\gamma\\in\\mathbb{H}$  \n\nProof Let $\\alpha\\in\\mathcal{B}_{\\beta}^{V,n}$. We prove the lemma by induction on  $\\beta^{V}$  with side induction on n.\n\nIf $\\alpha=0$, we put $\\gamma:=0$ and if $\\alpha=V(\\Omega)$, we put $\\gamma:=\\omega_{1}$. Now assume $\\alpha=_{NF}\\alpha_{1}+\\cdot\\cdot\\cdot+\\alpha_{n}$. Then $\\mathbb{H}\\ni\\alpha_{i}<\\alpha$ for $i=1,\\dots,n$. By the main induction hypothesis there are ordinals $\\gamma_{i}\\in\\mathcal{B}_{\\beta}$ such that $\\alpha_{i}=\\gamma_{i}^{V}$ and $\\gamma_{i}\\in\\mathbb{H}$. By equation (9.40) we obtain\n\n  $\\gamma_{1}\\geq\\ldots\\geq\\gamma_{n}$ and put $\\gamma:=\\gamma_{1}\\cdots+\\gamma_{n}$. Then $ \\gamma =_{\\_{NF}} \\gamma_1 + \\cdots + \\gamma_n  $  and $\\gamma^{V}=\\gamma_{1}^{V}\\cdots+\\gamma_{n}^{V},  \\gamma\\in{\\mathcal{B}}_\\beta$ and $\\gamma\\not\\in{\\mathbb H}$  \n\nNext assume $\\alpha=\\bar{\\varphi}_{\\alpha_{1}}(\\alpha_{2})$. Then $\\alpha\\in\\mathbb{H}\\setminus S C$ and $\\alpha_{l}<\\alpha$. By the main induction hypothesis there are ordinals $\\gamma_{1},\\gamma_{2}\\in{\\mathcal{B}}_{\\beta}$ such that $\\gamma_{i}^{V}=\\alpha_{i}$ for $i=1,2$. Let $\\gamma=$   $\\bar{\\varphi}_{\\gamma_{1}}(\\gamma_{2})$. Then $\\gamma\\in{\\mathcal{B}}_{\\beta}$ and $\\gamma_{l}<\\gamma$ for $i=1,2$  \n\n$\\alpha=\\psi_{V}(\\eta)$   $\\eta\\in\\mathcal{B}_{\\beta^{V}}^{V,n-1}\\cap\\beta^{V}$. Then $\\alpha\\in SC$   $\\eta_{0}\\in\\mathcal{B}_{\\beta^{V}}^{V,n-1}\\cap\\beta^{V}$ such that $\\eta_{0}\\in\\mathcal{B}_{\\eta_{0}}^{V}$ and $\\alpha=\\psi_{V}(\\eta_{0})$. By induction hypothesis there is an $\\alpha_{0}$ such that $\\eta_{0}=\\alpha_{0}^{V}$, hence $\\alpha_{0}^{V}\\in\\mathcal{B}_{\\alpha_{0}^{V}}^{V}$, which implies $ \\alpha_{0}\\in{\\mathcal{B}}_{\\alpha_{0}}.\\operatorname{Sp}\\gamma:=\\psi(\\alpha_{0})$ implies $\\gamma\\in S C$ and $\\scriptstyle\\gamma\\,=\\,N F\\ \\psi(\\alpha_{0})$ and we obtain $\\alpha=\\psi_{V}(\\eta_{0})=\\psi_{V}(\\alpha_{0}^{V})=\\psi(\\alpha_{0})^{V}=\\gamma^{V}$ \u53e3  \n\n9.7.9 Theorem Let $V$ be an interpretation which is good relative to $ \\Theta $ and $ \\beta\\in\\mathcal{B}_{\\Theta}\\cap\\left(\\Theta+1\\right)$   $(\\mathcal{B}_{\\beta})^{V}=\\mathcal{B}_{\\beta^{V}}^{V}$  \n\nProof From $\\alpha\\in{\\mathcal{B}}\\beta$ we obtain $\\alpha^{V}\\,\\in\\,\\mathcal{B}_{\\beta^{V}}^{V}$ by (9.41). Hence $({\\mathcal{B}}_{\\beta})^{V}:=\\{\\alpha^{V}\\,|\\,\\,\\alpha\\in\\mathcal{B}_{\\beta}\\}\\subseteq\\mathcal{B}_{\\beta^{V}}^{V}$   $\\alpha\\in\\mathcal{B}_{\\beta^{V}}^{V}$ a $\\gamma\\in{\\mathcal{B}}_{\\beta}$ such that\n\n  $\\alpha=\\gamma^{V}\\in(\\mathcal{B}_{\\beta})^{V}$ by Lemma 9.7.8. Hence $\\mathcal{B}_{\\beta^{V}}^{V}\\subseteq(\\mathcal{B}_{\\beta})^{V}$ \u53e3",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Then for every alpha in mathcal{B}_{beta^{V}}^{V} there is a gamma in mathcal{B}_{beta} such that alpha=gamma^{V}.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTX_-_Proof_Theory.pdf_208",
        "ID": "07b52a8b-0af0-4e69-853a-91353ee2151b",
        "questions": "According to the document, if beta belongs to mathcal{B}_{Theta} and alpha belongs to Cr(beta), what can be deduced about alpha^V?",
        "answers": "alpha^{V} in Cr(beta^{V})",
        "context": "$$\n\\begin{array}{r l}&{\\beta\\in\\mathcal{B}_{\\Theta}\\cap\\left(\\Theta+1\\right)\\,\\land\\,\\alpha\\in\\mathcal{B}_{b^{S t}}\\ \\Rightarrow\\ \\alpha^{V}\\in\\mathcal{B}_{\\beta^{V}}^{V}}\\\\ &{\\beta\\in\\mathcal{B}_{\\Theta+1}\\,\\land\\,\\alpha\\in C r\\left(\\beta\\right)\\ \\Rightarrow\\ \\alpha^{V}\\in C r\\left(\\beta^{V}\\right)\\mathrm{.}}\\end{array}\n$$  \n\nProperty (9.42) holds true since $ \\alpha \\in Cr(\\beta) $  implies that there is a $ \\beta_0 \\geq \\beta $ such that \n$ alpha \\in Cr(\\beta_0) \\setminus Cr(\\beta_0 + 1) $ . Then $ \\alpha = \\bar{\\varphi}_{\\beta_0}(\\eta) $  for some $ \\eta $  and thus $ \\alpha^V = \\lceil \\alpha^{-1} V\\rceil = \n\\bar{\\varphi}_{\\beta_0} \\vee \\lceil \\eta^{-1} V\\rceil \\in Cr(\\beta'_0) \\subseteq Cr(\\beta^V) $  since $ \\beta^V \\leq \\beta'_0 $ by (9.40).\n\n\nFor $\\beta\\in\\mathcal{B}_{\\Theta}\\cap(\\Theta+1)$, the interpretation V is thus an embedding from $\\mathcal{B}_{\\beta}$ into\n\n  $\\mathcal{B}_{\\beta^{V}}^{V}$  prove that this embedding is also on to. The proof will need a relativized version of $\\psi_{V}(\\alpha)\\in\\mathcal{B}_{\\beta}^{V,n}$   $\\alpha_{0}\\in\\mathcal{B}_{\\beta}^{V,n}$  such that $\\alpha_{0}\\in\\mathcal{B}_{\\alpha_{0}}^{V}$   $\\psi_{V}(\\alpha)=\\psi_{V}(\\alpha_{0})$   $\\mathcal{B}_{\\beta}^{V,n}$   $B_{\\beta}^{n}$  Lemma 9.6.2 only needs $\\psi(\\alpha)<\\Omega$, it relativizes easily to interpretations which are good relative to some $\\Theta$  \n\n9.7.8 Lemma  $Let\\;V$  be a good interpretation relative to $\\Theta$ and $\\beta\\in\\mathcal{B}_{\\Theta}\\cap(\\Theta+1)$. Then for every $\\alpha\\in\\mathcal{B}_{\\beta^{V}}^{V}$ there is a $\\gamma\\in{\\mathcal{B}}_{\\beta}$ such that $\\alpha=\\gamma^{V}$. Moreover, we have $\\alpha\\in S C$ iff $\\gamma\\in S C$ and $\\alpha\\in\\mathbb{H}$ iff $\\gamma\\in\\mathbb{H}$  \n\nProof Let $\\alpha\\in\\mathcal{B}_{\\beta}^{V,n}$. We prove the lemma by induction on  $\\beta^{V}$  with side induction on n.\n\nIf $\\alpha=0$, we put $\\gamma:=0$ and if $\\alpha=V(\\Omega)$, we put $\\gamma:=\\omega_{1}$. Now assume $\\alpha=_{NF}\\alpha_{1}+\\cdot\\cdot\\cdot+\\alpha_{n}$. Then $\\mathbb{H}\\ni\\alpha_{i}<\\alpha$ for $i=1,\\dots,n$. By the main induction hypothesis there are ordinals $\\gamma_{i}\\in\\mathcal{B}_{\\beta}$ such that $\\alpha_{i}=\\gamma_{i}^{V}$ and $\\gamma_{i}\\in\\mathbb{H}$. By equation (9.40) we obtain\n\n  $\\gamma_{1}\\geq\\ldots\\geq\\gamma_{n}$ and put $\\gamma:=\\gamma_{1}\\cdots+\\gamma_{n}$. Then $ \\gamma =_{\\_{NF}} \\gamma_1 + \\cdots + \\gamma_n  $  and $\\gamma^{V}=\\gamma_{1}^{V}\\cdots+\\gamma_{n}^{V},  \\gamma\\in{\\mathcal{B}}_\\beta$ and $\\gamma\\not\\in{\\mathbb H}$  \n\nNext assume $\\alpha=\\bar{\\varphi}_{\\alpha_{1}}(\\alpha_{2})$. Then $\\alpha\\in\\mathbb{H}\\setminus S C$ and $\\alpha_{l}<\\alpha$. By the main induction hypothesis there are ordinals $\\gamma_{1},\\gamma_{2}\\in{\\mathcal{B}}_{\\beta}$ such that $\\gamma_{i}^{V}=\\alpha_{i}$ for $i=1,2$. Let $\\gamma=$   $\\bar{\\varphi}_{\\gamma_{1}}(\\gamma_{2})$. Then $\\gamma\\in{\\mathcal{B}}_{\\beta}$ and $\\gamma_{l}<\\gamma$ for $i=1,2$  \n\n$\\alpha=\\psi_{V}(\\eta)$   $\\eta\\in\\mathcal{B}_{\\beta^{V}}^{V,n-1}\\cap\\beta^{V}$. Then $\\alpha\\in SC$   $\\eta_{0}\\in\\mathcal{B}_{\\beta^{V}}^{V,n-1}\\cap\\beta^{V}$ such that $\\eta_{0}\\in\\mathcal{B}_{\\eta_{0}}^{V}$ and $\\alpha=\\psi_{V}(\\eta_{0})$. By induction hypothesis there is an $\\alpha_{0}$ such that $\\eta_{0}=\\alpha_{0}^{V}$, hence $\\alpha_{0}^{V}\\in\\mathcal{B}_{\\alpha_{0}^{V}}^{V}$, which implies $ \\alpha_{0}\\in{\\mathcal{B}}_{\\alpha_{0}}.\\operatorname{Sp}\\gamma:=\\psi(\\alpha_{0})$ implies $\\gamma\\in S C$ and $\\scriptstyle\\gamma\\,=\\,N F\\ \\psi(\\alpha_{0})$ and we obtain $\\alpha=\\psi_{V}(\\eta_{0})=\\psi_{V}(\\alpha_{0}^{V})=\\psi(\\alpha_{0})^{V}=\\gamma^{V}$ \u53e3  \n\n9.7.9 Theorem Let $V$ be an interpretation which is good relative to $ \\Theta $ and $ \\beta\\in\\mathcal{B}_{\\Theta}\\cap\\left(\\Theta+1\\right)$   $(\\mathcal{B}_{\\beta})^{V}=\\mathcal{B}_{\\beta^{V}}^{V}$  \n\nProof From $\\alpha\\in{\\mathcal{B}}\\beta$ we obtain $\\alpha^{V}\\,\\in\\,\\mathcal{B}_{\\beta^{V}}^{V}$ by (9.41). Hence $({\\mathcal{B}}_{\\beta})^{V}:=\\{\\alpha^{V}\\,|\\,\\,\\alpha\\in\\mathcal{B}_{\\beta}\\}\\subseteq\\mathcal{B}_{\\beta^{V}}^{V}$   $\\alpha\\in\\mathcal{B}_{\\beta^{V}}^{V}$ a $\\gamma\\in{\\mathcal{B}}_{\\beta}$ such that\n\n  $\\alpha=\\gamma^{V}\\in(\\mathcal{B}_{\\beta})^{V}$ by Lemma 9.7.8. Hence $\\mathcal{B}_{\\beta^{V}}^{V}\\subseteq(\\mathcal{B}_{\\beta})^{V}$ \u53e3",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "beta in mathcal{B}_{Theta+1} land alpha in Cr(beta) Rightarrow alpha^{V} in Cr(beta^{V}).",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTX_-_Proof_Theory.pdf_208",
        "ID": "07b62caf-fafd-460a-8544-0df00080c826",
        "questions": "If \\( \\beta \\) is an element of \\( \\mathcal{B}_{\\Theta} \\cap (\\Theta+1) \\) and \\( \\alpha \\) belongs to the relation \\( Cr(\\beta) \\), where will \\( \\alpha^{V} \\) be situated?",
        "answers": "Cr(\\beta^{V})",
        "context": "$$\n\\begin{array}{r l}&{\\beta\\in\\mathcal{B}_{\\Theta}\\cap\\left(\\Theta+1\\right)\\,\\land\\,\\alpha\\in\\mathcal{B}_{b^{S t}}\\ \\Rightarrow\\ \\alpha^{V}\\in\\mathcal{B}_{\\beta^{V}}^{V}}\\\\ &{\\beta\\in\\mathcal{B}_{\\Theta+1}\\,\\land\\,\\alpha\\in C r\\left(\\beta\\right)\\ \\Rightarrow\\ \\alpha^{V}\\in C r\\left(\\beta^{V}\\right)\\mathrm{.}}\\end{array}\n$$  \n\nProperty (9.42) holds true since $ \\alpha \\in Cr(\\beta) $  implies that there is a $ \\beta_0 \\geq \\beta $ such that \n$ alpha \\in Cr(\\beta_0) \\setminus Cr(\\beta_0 + 1) $ . Then $ \\alpha = \\bar{\\varphi}_{\\beta_0}(\\eta) $  for some $ \\eta $  and thus $ \\alpha^V = \\lceil \\alpha^{-1} V\\rceil = \n\\bar{\\varphi}_{\\beta_0} \\vee \\lceil \\eta^{-1} V\\rceil \\in Cr(\\beta'_0) \\subseteq Cr(\\beta^V) $  since $ \\beta^V \\leq \\beta'_0 $ by (9.40).\n\n\nFor $\\beta\\in\\mathcal{B}_{\\Theta}\\cap(\\Theta+1)$, the interpretation V is thus an embedding from $\\mathcal{B}_{\\beta}$ into\n\n  $\\mathcal{B}_{\\beta^{V}}^{V}$  prove that this embedding is also on to. The proof will need a relativized version of $\\psi_{V}(\\alpha)\\in\\mathcal{B}_{\\beta}^{V,n}$   $\\alpha_{0}\\in\\mathcal{B}_{\\beta}^{V,n}$  such that $\\alpha_{0}\\in\\mathcal{B}_{\\alpha_{0}}^{V}$   $\\psi_{V}(\\alpha)=\\psi_{V}(\\alpha_{0})$   $\\mathcal{B}_{\\beta}^{V,n}$   $B_{\\beta}^{n}$  Lemma 9.6.2 only needs $\\psi(\\alpha)<\\Omega$, it relativizes easily to interpretations which are good relative to some $\\Theta$  \n\n9.7.8 Lemma  $Let\\;V$  be a good interpretation relative to $\\Theta$ and $\\beta\\in\\mathcal{B}_{\\Theta}\\cap(\\Theta+1)$. Then for every $\\alpha\\in\\mathcal{B}_{\\beta^{V}}^{V}$ there is a $\\gamma\\in{\\mathcal{B}}_{\\beta}$ such that $\\alpha=\\gamma^{V}$. Moreover, we have $\\alpha\\in S C$ iff $\\gamma\\in S C$ and $\\alpha\\in\\mathbb{H}$ iff $\\gamma\\in\\mathbb{H}$  \n\nProof Let $\\alpha\\in\\mathcal{B}_{\\beta}^{V,n}$. We prove the lemma by induction on  $\\beta^{V}$  with side induction on n.\n\nIf $\\alpha=0$, we put $\\gamma:=0$ and if $\\alpha=V(\\Omega)$, we put $\\gamma:=\\omega_{1}$. Now assume $\\alpha=_{NF}\\alpha_{1}+\\cdot\\cdot\\cdot+\\alpha_{n}$. Then $\\mathbb{H}\\ni\\alpha_{i}<\\alpha$ for $i=1,\\dots,n$. By the main induction hypothesis there are ordinals $\\gamma_{i}\\in\\mathcal{B}_{\\beta}$ such that $\\alpha_{i}=\\gamma_{i}^{V}$ and $\\gamma_{i}\\in\\mathbb{H}$. By equation (9.40) we obtain\n\n  $\\gamma_{1}\\geq\\ldots\\geq\\gamma_{n}$ and put $\\gamma:=\\gamma_{1}\\cdots+\\gamma_{n}$. Then $ \\gamma =_{\\_{NF}} \\gamma_1 + \\cdots + \\gamma_n  $  and $\\gamma^{V}=\\gamma_{1}^{V}\\cdots+\\gamma_{n}^{V},  \\gamma\\in{\\mathcal{B}}_\\beta$ and $\\gamma\\not\\in{\\mathbb H}$  \n\nNext assume $\\alpha=\\bar{\\varphi}_{\\alpha_{1}}(\\alpha_{2})$. Then $\\alpha\\in\\mathbb{H}\\setminus S C$ and $\\alpha_{l}<\\alpha$. By the main induction hypothesis there are ordinals $\\gamma_{1},\\gamma_{2}\\in{\\mathcal{B}}_{\\beta}$ such that $\\gamma_{i}^{V}=\\alpha_{i}$ for $i=1,2$. Let $\\gamma=$   $\\bar{\\varphi}_{\\gamma_{1}}(\\gamma_{2})$. Then $\\gamma\\in{\\mathcal{B}}_{\\beta}$ and $\\gamma_{l}<\\gamma$ for $i=1,2$  \n\n$\\alpha=\\psi_{V}(\\eta)$   $\\eta\\in\\mathcal{B}_{\\beta^{V}}^{V,n-1}\\cap\\beta^{V}$. Then $\\alpha\\in SC$   $\\eta_{0}\\in\\mathcal{B}_{\\beta^{V}}^{V,n-1}\\cap\\beta^{V}$ such that $\\eta_{0}\\in\\mathcal{B}_{\\eta_{0}}^{V}$ and $\\alpha=\\psi_{V}(\\eta_{0})$. By induction hypothesis there is an $\\alpha_{0}$ such that $\\eta_{0}=\\alpha_{0}^{V}$, hence $\\alpha_{0}^{V}\\in\\mathcal{B}_{\\alpha_{0}^{V}}^{V}$, which implies $ \\alpha_{0}\\in{\\mathcal{B}}_{\\alpha_{0}}.\\operatorname{Sp}\\gamma:=\\psi(\\alpha_{0})$ implies $\\gamma\\in S C$ and $\\scriptstyle\\gamma\\,=\\,N F\\ \\psi(\\alpha_{0})$ and we obtain $\\alpha=\\psi_{V}(\\eta_{0})=\\psi_{V}(\\alpha_{0}^{V})=\\psi(\\alpha_{0})^{V}=\\gamma^{V}$ \u53e3  \n\n9.7.9 Theorem Let $V$ be an interpretation which is good relative to $ \\Theta $ and $ \\beta\\in\\mathcal{B}_{\\Theta}\\cap\\left(\\Theta+1\\right)$   $(\\mathcal{B}_{\\beta})^{V}=\\mathcal{B}_{\\beta^{V}}^{V}$  \n\nProof From $\\alpha\\in{\\mathcal{B}}\\beta$ we obtain $\\alpha^{V}\\,\\in\\,\\mathcal{B}_{\\beta^{V}}^{V}$ by (9.41). Hence $({\\mathcal{B}}_{\\beta})^{V}:=\\{\\alpha^{V}\\,|\\,\\,\\alpha\\in\\mathcal{B}_{\\beta}\\}\\subseteq\\mathcal{B}_{\\beta^{V}}^{V}$   $\\alpha\\in\\mathcal{B}_{\\beta^{V}}^{V}$ a $\\gamma\\in{\\mathcal{B}}_{\\beta}$ such that\n\n  $\\alpha=\\gamma^{V}\\in(\\mathcal{B}_{\\beta})^{V}$ by Lemma 9.7.8. Hence $\\mathcal{B}_{\\beta^{V}}^{V}\\subseteq(\\mathcal{B}_{\\beta})^{V}$ \u53e3",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "\\( \\beta \\in \\mathcal{B}_{\\Theta+1} \\land \\alpha \\in Cr(\\beta) \\Rightarrow \\alpha^{V} \\in Cr(\\beta^{V}) \\mathrm{.} \\)",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/UTX_-_Proof_Theory.pdf_208",
        "ID": "07b9ae99-656b-4d12-bfc7-9d4117affe0c",
        "questions": "In Lemma 9.7.8, when applying an interpretation \\( V \\) relative to \\( \\Theta \\), if \\( \\alpha = 0 \\), what value is assigned to \\( \\gamma \\)?",
        "answers": "0",
        "context": "$$\n\\begin{array}{r l}&{\\beta\\in\\mathcal{B}_{\\Theta}\\cap\\left(\\Theta+1\\right)\\,\\land\\,\\alpha\\in\\mathcal{B}_{b^{S t}}\\ \\Rightarrow\\ \\alpha^{V}\\in\\mathcal{B}_{\\beta^{V}}^{V}}\\\\ &{\\beta\\in\\mathcal{B}_{\\Theta+1}\\,\\land\\,\\alpha\\in C r\\left(\\beta\\right)\\ \\Rightarrow\\ \\alpha^{V}\\in C r\\left(\\beta^{V}\\right)\\mathrm{.}}\\end{array}\n$$  \n\nProperty (9.42) holds true since $ \\alpha \\in Cr(\\beta) $  implies that there is a $ \\beta_0 \\geq \\beta $ such that \n$ alpha \\in Cr(\\beta_0) \\setminus Cr(\\beta_0 + 1) $ . Then $ \\alpha = \\bar{\\varphi}_{\\beta_0}(\\eta) $  for some $ \\eta $  and thus $ \\alpha^V = \\lceil \\alpha^{-1} V\\rceil = \n\\bar{\\varphi}_{\\beta_0} \\vee \\lceil \\eta^{-1} V\\rceil \\in Cr(\\beta'_0) \\subseteq Cr(\\beta^V) $  since $ \\beta^V \\leq \\beta'_0 $ by (9.40).\n\n\nFor $\\beta\\in\\mathcal{B}_{\\Theta}\\cap(\\Theta+1)$, the interpretation V is thus an embedding from $\\mathcal{B}_{\\beta}$ into\n\n  $\\mathcal{B}_{\\beta^{V}}^{V}$  prove that this embedding is also on to. The proof will need a relativized version of $\\psi_{V}(\\alpha)\\in\\mathcal{B}_{\\beta}^{V,n}$   $\\alpha_{0}\\in\\mathcal{B}_{\\beta}^{V,n}$  such that $\\alpha_{0}\\in\\mathcal{B}_{\\alpha_{0}}^{V}$   $\\psi_{V}(\\alpha)=\\psi_{V}(\\alpha_{0})$   $\\mathcal{B}_{\\beta}^{V,n}$   $B_{\\beta}^{n}$  Lemma 9.6.2 only needs $\\psi(\\alpha)<\\Omega$, it relativizes easily to interpretations which are good relative to some $\\Theta$  \n\n9.7.8 Lemma  $Let\\;V$  be a good interpretation relative to $\\Theta$ and $\\beta\\in\\mathcal{B}_{\\Theta}\\cap(\\Theta+1)$. Then for every $\\alpha\\in\\mathcal{B}_{\\beta^{V}}^{V}$ there is a $\\gamma\\in{\\mathcal{B}}_{\\beta}$ such that $\\alpha=\\gamma^{V}$. Moreover, we have $\\alpha\\in S C$ iff $\\gamma\\in S C$ and $\\alpha\\in\\mathbb{H}$ iff $\\gamma\\in\\mathbb{H}$  \n\nProof Let $\\alpha\\in\\mathcal{B}_{\\beta}^{V,n}$. We prove the lemma by induction on  $\\beta^{V}$  with side induction on n.\n\nIf $\\alpha=0$, we put $\\gamma:=0$ and if $\\alpha=V(\\Omega)$, we put $\\gamma:=\\omega_{1}$. Now assume $\\alpha=_{NF}\\alpha_{1}+\\cdot\\cdot\\cdot+\\alpha_{n}$. Then $\\mathbb{H}\\ni\\alpha_{i}<\\alpha$ for $i=1,\\dots,n$. By the main induction hypothesis there are ordinals $\\gamma_{i}\\in\\mathcal{B}_{\\beta}$ such that $\\alpha_{i}=\\gamma_{i}^{V}$ and $\\gamma_{i}\\in\\mathbb{H}$. By equation (9.40) we obtain\n\n  $\\gamma_{1}\\geq\\ldots\\geq\\gamma_{n}$ and put $\\gamma:=\\gamma_{1}\\cdots+\\gamma_{n}$. Then $ \\gamma =_{\\_{NF}} \\gamma_1 + \\cdots + \\gamma_n  $  and $\\gamma^{V}=\\gamma_{1}^{V}\\cdots+\\gamma_{n}^{V},  \\gamma\\in{\\mathcal{B}}_\\beta$ and $\\gamma\\not\\in{\\mathbb H}$  \n\nNext assume $\\alpha=\\bar{\\varphi}_{\\alpha_{1}}(\\alpha_{2})$. Then $\\alpha\\in\\mathbb{H}\\setminus S C$ and $\\alpha_{l}<\\alpha$. By the main induction hypothesis there are ordinals $\\gamma_{1},\\gamma_{2}\\in{\\mathcal{B}}_{\\beta}$ such that $\\gamma_{i}^{V}=\\alpha_{i}$ for $i=1,2$. Let $\\gamma=$   $\\bar{\\varphi}_{\\gamma_{1}}(\\gamma_{2})$. Then $\\gamma\\in{\\mathcal{B}}_{\\beta}$ and $\\gamma_{l}<\\gamma$ for $i=1,2$  \n\n$\\alpha=\\psi_{V}(\\eta)$   $\\eta\\in\\mathcal{B}_{\\beta^{V}}^{V,n-1}\\cap\\beta^{V}$. Then $\\alpha\\in SC$   $\\eta_{0}\\in\\mathcal{B}_{\\beta^{V}}^{V,n-1}\\cap\\beta^{V}$ such that $\\eta_{0}\\in\\mathcal{B}_{\\eta_{0}}^{V}$ and $\\alpha=\\psi_{V}(\\eta_{0})$. By induction hypothesis there is an $\\alpha_{0}$ such that $\\eta_{0}=\\alpha_{0}^{V}$, hence $\\alpha_{0}^{V}\\in\\mathcal{B}_{\\alpha_{0}^{V}}^{V}$, which implies $ \\alpha_{0}\\in{\\mathcal{B}}_{\\alpha_{0}}.\\operatorname{Sp}\\gamma:=\\psi(\\alpha_{0})$ implies $\\gamma\\in S C$ and $\\scriptstyle\\gamma\\,=\\,N F\\ \\psi(\\alpha_{0})$ and we obtain $\\alpha=\\psi_{V}(\\eta_{0})=\\psi_{V}(\\alpha_{0}^{V})=\\psi(\\alpha_{0})^{V}=\\gamma^{V}$ \u53e3  \n\n9.7.9 Theorem Let $V$ be an interpretation which is good relative to $ \\Theta $ and $ \\beta\\in\\mathcal{B}_{\\Theta}\\cap\\left(\\Theta+1\\right)$   $(\\mathcal{B}_{\\beta})^{V}=\\mathcal{B}_{\\beta^{V}}^{V}$  \n\nProof From $\\alpha\\in{\\mathcal{B}}\\beta$ we obtain $\\alpha^{V}\\,\\in\\,\\mathcal{B}_{\\beta^{V}}^{V}$ by (9.41). Hence $({\\mathcal{B}}_{\\beta})^{V}:=\\{\\alpha^{V}\\,|\\,\\,\\alpha\\in\\mathcal{B}_{\\beta}\\}\\subseteq\\mathcal{B}_{\\beta^{V}}^{V}$   $\\alpha\\in\\mathcal{B}_{\\beta^{V}}^{V}$ a $\\gamma\\in{\\mathcal{B}}_{\\beta}$ such that\n\n  $\\alpha=\\gamma^{V}\\in(\\mathcal{B}_{\\beta})^{V}$ by Lemma 9.7.8. Hence $\\mathcal{B}_{\\beta^{V}}^{V}\\subseteq(\\mathcal{B}_{\\beta})^{V}$ \u53e3",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "If \\( \\alpha=0 \\), we put \\( \\gamma:=0 \\)",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/UTX_-_Proof_Theory.pdf_208",
        "ID": "07bbd20a-55e6-47c1-8b59-49a41a8a7384",
        "questions": "According to Theorem 9.7.9, what relationship exists between \\( (\\mathcal{B}_{\\beta})^{V} \\) and \\( \\mathcal{B}_{\\beta^{V}}^{V} \\) when \\( V \\) is good relative to \\( \\Theta \\) and \\( \\beta \\in \\mathcal{B}_{\\Theta} \\cap (\\Theta+1) \\)?",
        "answers": "(\\mathcal{B}_{\\beta})^{V} = \\mathcal{B}_{\\beta^{V}}^{V}",
        "context": "$$\n\\begin{array}{r l}&{\\beta\\in\\mathcal{B}_{\\Theta}\\cap\\left(\\Theta+1\\right)\\,\\land\\,\\alpha\\in\\mathcal{B}_{b^{S t}}\\ \\Rightarrow\\ \\alpha^{V}\\in\\mathcal{B}_{\\beta^{V}}^{V}}\\\\ &{\\beta\\in\\mathcal{B}_{\\Theta+1}\\,\\land\\,\\alpha\\in C r\\left(\\beta\\right)\\ \\Rightarrow\\ \\alpha^{V}\\in C r\\left(\\beta^{V}\\right)\\mathrm{.}}\\end{array}\n$$  \n\nProperty (9.42) holds true since $ \\alpha \\in Cr(\\beta) $  implies that there is a $ \\beta_0 \\geq \\beta $ such that \n$ alpha \\in Cr(\\beta_0) \\setminus Cr(\\beta_0 + 1) $ . Then $ \\alpha = \\bar{\\varphi}_{\\beta_0}(\\eta) $  for some $ \\eta $  and thus $ \\alpha^V = \\lceil \\alpha^{-1} V\\rceil = \n\\bar{\\varphi}_{\\beta_0} \\vee \\lceil \\eta^{-1} V\\rceil \\in Cr(\\beta'_0) \\subseteq Cr(\\beta^V) $  since $ \\beta^V \\leq \\beta'_0 $ by (9.40).\n\n\nFor $\\beta\\in\\mathcal{B}_{\\Theta}\\cap(\\Theta+1)$, the interpretation V is thus an embedding from $\\mathcal{B}_{\\beta}$ into\n\n  $\\mathcal{B}_{\\beta^{V}}^{V}$  prove that this embedding is also on to. The proof will need a relativized version of $\\psi_{V}(\\alpha)\\in\\mathcal{B}_{\\beta}^{V,n}$   $\\alpha_{0}\\in\\mathcal{B}_{\\beta}^{V,n}$  such that $\\alpha_{0}\\in\\mathcal{B}_{\\alpha_{0}}^{V}$   $\\psi_{V}(\\alpha)=\\psi_{V}(\\alpha_{0})$   $\\mathcal{B}_{\\beta}^{V,n}$   $B_{\\beta}^{n}$  Lemma 9.6.2 only needs $\\psi(\\alpha)<\\Omega$, it relativizes easily to interpretations which are good relative to some $\\Theta$  \n\n9.7.8 Lemma  $Let\\;V$  be a good interpretation relative to $\\Theta$ and $\\beta\\in\\mathcal{B}_{\\Theta}\\cap(\\Theta+1)$. Then for every $\\alpha\\in\\mathcal{B}_{\\beta^{V}}^{V}$ there is a $\\gamma\\in{\\mathcal{B}}_{\\beta}$ such that $\\alpha=\\gamma^{V}$. Moreover, we have $\\alpha\\in S C$ iff $\\gamma\\in S C$ and $\\alpha\\in\\mathbb{H}$ iff $\\gamma\\in\\mathbb{H}$  \n\nProof Let $\\alpha\\in\\mathcal{B}_{\\beta}^{V,n}$. We prove the lemma by induction on  $\\beta^{V}$  with side induction on n.\n\nIf $\\alpha=0$, we put $\\gamma:=0$ and if $\\alpha=V(\\Omega)$, we put $\\gamma:=\\omega_{1}$. Now assume $\\alpha=_{NF}\\alpha_{1}+\\cdot\\cdot\\cdot+\\alpha_{n}$. Then $\\mathbb{H}\\ni\\alpha_{i}<\\alpha$ for $i=1,\\dots,n$. By the main induction hypothesis there are ordinals $\\gamma_{i}\\in\\mathcal{B}_{\\beta}$ such that $\\alpha_{i}=\\gamma_{i}^{V}$ and $\\gamma_{i}\\in\\mathbb{H}$. By equation (9.40) we obtain\n\n  $\\gamma_{1}\\geq\\ldots\\geq\\gamma_{n}$ and put $\\gamma:=\\gamma_{1}\\cdots+\\gamma_{n}$. Then $ \\gamma =_{\\_{NF}} \\gamma_1 + \\cdots + \\gamma_n  $  and $\\gamma^{V}=\\gamma_{1}^{V}\\cdots+\\gamma_{n}^{V},  \\gamma\\in{\\mathcal{B}}_\\beta$ and $\\gamma\\not\\in{\\mathbb H}$  \n\nNext assume $\\alpha=\\bar{\\varphi}_{\\alpha_{1}}(\\alpha_{2})$. Then $\\alpha\\in\\mathbb{H}\\setminus S C$ and $\\alpha_{l}<\\alpha$. By the main induction hypothesis there are ordinals $\\gamma_{1},\\gamma_{2}\\in{\\mathcal{B}}_{\\beta}$ such that $\\gamma_{i}^{V}=\\alpha_{i}$ for $i=1,2$. Let $\\gamma=$   $\\bar{\\varphi}_{\\gamma_{1}}(\\gamma_{2})$. Then $\\gamma\\in{\\mathcal{B}}_{\\beta}$ and $\\gamma_{l}<\\gamma$ for $i=1,2$  \n\n$\\alpha=\\psi_{V}(\\eta)$   $\\eta\\in\\mathcal{B}_{\\beta^{V}}^{V,n-1}\\cap\\beta^{V}$. Then $\\alpha\\in SC$   $\\eta_{0}\\in\\mathcal{B}_{\\beta^{V}}^{V,n-1}\\cap\\beta^{V}$ such that $\\eta_{0}\\in\\mathcal{B}_{\\eta_{0}}^{V}$ and $\\alpha=\\psi_{V}(\\eta_{0})$. By induction hypothesis there is an $\\alpha_{0}$ such that $\\eta_{0}=\\alpha_{0}^{V}$, hence $\\alpha_{0}^{V}\\in\\mathcal{B}_{\\alpha_{0}^{V}}^{V}$, which implies $ \\alpha_{0}\\in{\\mathcal{B}}_{\\alpha_{0}}.\\operatorname{Sp}\\gamma:=\\psi(\\alpha_{0})$ implies $\\gamma\\in S C$ and $\\scriptstyle\\gamma\\,=\\,N F\\ \\psi(\\alpha_{0})$ and we obtain $\\alpha=\\psi_{V}(\\eta_{0})=\\psi_{V}(\\alpha_{0}^{V})=\\psi(\\alpha_{0})^{V}=\\gamma^{V}$ \u53e3  \n\n9.7.9 Theorem Let $V$ be an interpretation which is good relative to $ \\Theta $ and $ \\beta\\in\\mathcal{B}_{\\Theta}\\cap\\left(\\Theta+1\\right)$   $(\\mathcal{B}_{\\beta})^{V}=\\mathcal{B}_{\\beta^{V}}^{V}$  \n\nProof From $\\alpha\\in{\\mathcal{B}}\\beta$ we obtain $\\alpha^{V}\\,\\in\\,\\mathcal{B}_{\\beta^{V}}^{V}$ by (9.41). Hence $({\\mathcal{B}}_{\\beta})^{V}:=\\{\\alpha^{V}\\,|\\,\\,\\alpha\\in\\mathcal{B}_{\\beta}\\}\\subseteq\\mathcal{B}_{\\beta^{V}}^{V}$   $\\alpha\\in\\mathcal{B}_{\\beta^{V}}^{V}$ a $\\gamma\\in{\\mathcal{B}}_{\\beta}$ such that\n\n  $\\alpha=\\gamma^{V}\\in(\\mathcal{B}_{\\beta})^{V}$ by Lemma 9.7.8. Hence $\\mathcal{B}_{\\beta^{V}}^{V}\\subseteq(\\mathcal{B}_{\\beta})^{V}$ \u53e3",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Theorem Let \\( V \\) be an interpretation which is good relative to \\( \\Theta \\) and \\( \\beta \\in \\mathcal{B}_{\\Theta}\\cap\\left(\\Theta+1\\right) \\)   \\( (\\mathcal{B}_{\\beta})^{V}=\\mathcal{B}_{\\beta^{V}}^{V} \\)",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/399b19bd30c0341148c232399b97d6c10d2d105ff9205425015bf63cd0b151eb.pdf_0",
        "ID": "07c0c00f-05ff-461b-91f0-0aad0dbab83e",
        "questions": "Which model did Ginkgo biloba best fit according to the photographic data method?",
        "answers": "Murray's Law",
        "context": "# Photo-based comparison of Ginkgo biloba's task optimization  versus that of two native species.  \n\nNoah Holkeboer, with team members Collin Fox, Nicole Foy, Joshua Stayman, Brendan May, Annie Eckman, Kathryne Kuhlmann, and mentor Gary K. Greer\n\n# BACKGROUND  \n\nTo survive, trees must complete multiple tasks, which can be optimized for. The closer a tree is to being optimized for a task, the better it does that task, but the more risk it takes on. A species optimization is determined by how well it fits a corresponding model.\n\n- Hydraulic efficiency is predicted by Murray's Law, which is based off area being conserved at branching points.\n- Structural support of limbs is predicted by the Uniform Stress Model (USM). Over optimization (ratio $>1$) puts branches at risk of breaking, so a safety margin must be kept. \n- Total size is optimized under the West-Brown-Enquist (WBE) Model, if over optimized trees are more susceptible to wind.\n\nThese models have previously been used with destructive methods, we aim to develop a photographic based methodology, that can still produce precise and accurate enough data to distinguish between models and species.\n\n# METHODS\n\n- DB Hand scaled photos of the entire tree and first node were taken for 30 Ginkgo.\n- Tree height, mother diameter, daughter diameter, and angle between branches of the basal node were measured using Image J (NIH). \n- For each model, a regression compared observed data for mother and daughter attributes, and predicted values were generated using residuals from the observed data regression. An ANCOVA compared slope and y-intercept of the observed regression and the predicted.\n\n![](images/5ba36eef1964c67652e69724fb49872428049da41afad8f2aa1e33119fa52be8.jpg)\nFigure 1. Full tree image for a Ginkgo\n\n![](images/96ba2e0567c26f00b88066593658aa48db34550887db9477b1f5e246a90a1298.jpg)\nFigure 2. Node 1 image for a Ginkgo\n\n![](images/a32783e93e839fa0de11566159c4d4eb22e6d2eb576a03bfb15e0edd0f7225bd.jpg)\n\nFigure 3. Node image with Image J measurements labeled.\n\n# KEY RESULTS AND CONCLUSIONS  \n\n- Photographic data allowed us to see where Ginkgo deviated from the models' predictions, the biggest deviation being from the WBE model. (Fig. 4)\n- Ginkgo best fit Murray's Law and USM, respectively. (Fig. 5) Thus, Ginkgo is best optimized for hydraulic efficiency and structural support, at the cost of total mass.\n- We do not know why Ginkgo keeps such a large safety margin for total mass. One hypothesis is that because Ginkgo was mostly found in cities, where it does not have nearby trees to compete with, reducing pressure to be tall. Lack of neighbors also means Ginkgo are more exposed to the wind.\n- The photographic data we gathered provided usable data that highlighted even small deviations from the models and differences between species.\n\n# BOTTOM LINE  \n\nAs a proof of concept that photographs can yield usable data, our experiments were a success. It is also clear that different species optimize for different tasks, and that for Ginkgo biloba, minimizing the risk of buckling in the wind is important.\n\n![](images/5846f47236c45418030282d974d8b5cd880170eb511bd998dcbdf499ee4e544a.jpg)\n\nFigure 4. ANCOVA for WBE model, the slopes of observed and predicted differed statistically significantly. Observed Ginkgo differed from models' predictions most in its optimization for total mass.\n\n![](images/5d62f8cd5fb097c19d85a13f2a39d5ceaa557f77c392e78bfef5e0b3dcf0ee19.jpg)  \n\nFigure 5. Comparison of how well Sugar Maple, American Beech, and Gingko fit each model. Ginkgo has a large safety margin to reduce risk of buckling, because of its under optimization for total mass.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Ginkgo best fit Murray's Law and USM, respectively.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/399b19bd30c0341148c232399b97d6c10d2d105ff9205425015bf63cd0b151eb.pdf_0",
        "ID": "07c57156-2d68-433b-92c2-8839db514bc0",
        "questions": "For which hypothesis do the authors suggest that Ginkgo biloba keeps a large safety margin for total mass?",
        "answers": "One hypothesis is that because Ginkgo was mostly found in cities, where it does not have nearby trees to compete with, reducing pressure to be tall. Lack of neighbors also means Ginkgo are more exposed to the wind.",
        "context": "# Photo-based comparison of Ginkgo biloba's task optimization  versus that of two native species.  \n\nNoah Holkeboer, with team members Collin Fox, Nicole Foy, Joshua Stayman, Brendan May, Annie Eckman, Kathryne Kuhlmann, and mentor Gary K. Greer\n\n# BACKGROUND  \n\nTo survive, trees must complete multiple tasks, which can be optimized for. The closer a tree is to being optimized for a task, the better it does that task, but the more risk it takes on. A species optimization is determined by how well it fits a corresponding model.\n\n- Hydraulic efficiency is predicted by Murray's Law, which is based off area being conserved at branching points.\n- Structural support of limbs is predicted by the Uniform Stress Model (USM). Over optimization (ratio $>1$) puts branches at risk of breaking, so a safety margin must be kept. \n- Total size is optimized under the West-Brown-Enquist (WBE) Model, if over optimized trees are more susceptible to wind.\n\nThese models have previously been used with destructive methods, we aim to develop a photographic based methodology, that can still produce precise and accurate enough data to distinguish between models and species.\n\n# METHODS\n\n- DB Hand scaled photos of the entire tree and first node were taken for 30 Ginkgo.\n- Tree height, mother diameter, daughter diameter, and angle between branches of the basal node were measured using Image J (NIH). \n- For each model, a regression compared observed data for mother and daughter attributes, and predicted values were generated using residuals from the observed data regression. An ANCOVA compared slope and y-intercept of the observed regression and the predicted.\n\n![](images/5ba36eef1964c67652e69724fb49872428049da41afad8f2aa1e33119fa52be8.jpg)\nFigure 1. Full tree image for a Ginkgo\n\n![](images/96ba2e0567c26f00b88066593658aa48db34550887db9477b1f5e246a90a1298.jpg)\nFigure 2. Node 1 image for a Ginkgo\n\n![](images/a32783e93e839fa0de11566159c4d4eb22e6d2eb576a03bfb15e0edd0f7225bd.jpg)\n\nFigure 3. Node image with Image J measurements labeled.\n\n# KEY RESULTS AND CONCLUSIONS  \n\n- Photographic data allowed us to see where Ginkgo deviated from the models' predictions, the biggest deviation being from the WBE model. (Fig. 4)\n- Ginkgo best fit Murray's Law and USM, respectively. (Fig. 5) Thus, Ginkgo is best optimized for hydraulic efficiency and structural support, at the cost of total mass.\n- We do not know why Ginkgo keeps such a large safety margin for total mass. One hypothesis is that because Ginkgo was mostly found in cities, where it does not have nearby trees to compete with, reducing pressure to be tall. Lack of neighbors also means Ginkgo are more exposed to the wind.\n- The photographic data we gathered provided usable data that highlighted even small deviations from the models and differences between species.\n\n# BOTTOM LINE  \n\nAs a proof of concept that photographs can yield usable data, our experiments were a success. It is also clear that different species optimize for different tasks, and that for Ginkgo biloba, minimizing the risk of buckling in the wind is important.\n\n![](images/5846f47236c45418030282d974d8b5cd880170eb511bd998dcbdf499ee4e544a.jpg)\n\nFigure 4. ANCOVA for WBE model, the slopes of observed and predicted differed statistically significantly. Observed Ginkgo differed from models' predictions most in its optimization for total mass.\n\n![](images/5d62f8cd5fb097c19d85a13f2a39d5ceaa557f77c392e78bfef5e0b3dcf0ee19.jpg)  \n\nFigure 5. Comparison of how well Sugar Maple, American Beech, and Gingko fit each model. Ginkgo has a large safety margin to reduce risk of buckling, because of its under optimization for total mass.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "One hypothesis is that because Ginkgo was mostly found in cities, where it does not have nearby trees to compete with, reducing pressure to be tall. Lack of neighbors also means Ginkgo are more exposed to the wind.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/399b19bd30c0341148c232399b97d6c10d2d105ff9205425015bf63cd0b151eb.pdf_0",
        "ID": "07d5e121-623a-45ae-ba31-a27cced4dd7c",
        "questions": "Based on Figure 5, how does Ginkgo biloba's optimization for total mass compare to the predictions of the WBE model?",
        "answers": "Observed Ginkgo differed from models' predictions most in its optimization for total mass.",
        "context": "# Photo-based comparison of Ginkgo biloba's task optimization  versus that of two native species.  \n\nNoah Holkeboer, with team members Collin Fox, Nicole Foy, Joshua Stayman, Brendan May, Annie Eckman, Kathryne Kuhlmann, and mentor Gary K. Greer\n\n# BACKGROUND  \n\nTo survive, trees must complete multiple tasks, which can be optimized for. The closer a tree is to being optimized for a task, the better it does that task, but the more risk it takes on. A species optimization is determined by how well it fits a corresponding model.\n\n- Hydraulic efficiency is predicted by Murray's Law, which is based off area being conserved at branching points.\n- Structural support of limbs is predicted by the Uniform Stress Model (USM). Over optimization (ratio $>1$) puts branches at risk of breaking, so a safety margin must be kept. \n- Total size is optimized under the West-Brown-Enquist (WBE) Model, if over optimized trees are more susceptible to wind.\n\nThese models have previously been used with destructive methods, we aim to develop a photographic based methodology, that can still produce precise and accurate enough data to distinguish between models and species.\n\n# METHODS\n\n- DB Hand scaled photos of the entire tree and first node were taken for 30 Ginkgo.\n- Tree height, mother diameter, daughter diameter, and angle between branches of the basal node were measured using Image J (NIH). \n- For each model, a regression compared observed data for mother and daughter attributes, and predicted values were generated using residuals from the observed data regression. An ANCOVA compared slope and y-intercept of the observed regression and the predicted.\n\n![](images/5ba36eef1964c67652e69724fb49872428049da41afad8f2aa1e33119fa52be8.jpg)\nFigure 1. Full tree image for a Ginkgo\n\n![](images/96ba2e0567c26f00b88066593658aa48db34550887db9477b1f5e246a90a1298.jpg)\nFigure 2. Node 1 image for a Ginkgo\n\n![](images/a32783e93e839fa0de11566159c4d4eb22e6d2eb576a03bfb15e0edd0f7225bd.jpg)\n\nFigure 3. Node image with Image J measurements labeled.\n\n# KEY RESULTS AND CONCLUSIONS  \n\n- Photographic data allowed us to see where Ginkgo deviated from the models' predictions, the biggest deviation being from the WBE model. (Fig. 4)\n- Ginkgo best fit Murray's Law and USM, respectively. (Fig. 5) Thus, Ginkgo is best optimized for hydraulic efficiency and structural support, at the cost of total mass.\n- We do not know why Ginkgo keeps such a large safety margin for total mass. One hypothesis is that because Ginkgo was mostly found in cities, where it does not have nearby trees to compete with, reducing pressure to be tall. Lack of neighbors also means Ginkgo are more exposed to the wind.\n- The photographic data we gathered provided usable data that highlighted even small deviations from the models and differences between species.\n\n# BOTTOM LINE  \n\nAs a proof of concept that photographs can yield usable data, our experiments were a success. It is also clear that different species optimize for different tasks, and that for Ginkgo biloba, minimizing the risk of buckling in the wind is important.\n\n![](images/5846f47236c45418030282d974d8b5cd880170eb511bd998dcbdf499ee4e544a.jpg)\n\nFigure 4. ANCOVA for WBE model, the slopes of observed and predicted differed statistically significantly. Observed Ginkgo differed from models' predictions most in its optimization for total mass.\n\n![](images/5d62f8cd5fb097c19d85a13f2a39d5ceaa557f77c392e78bfef5e0b3dcf0ee19.jpg)  \n\nFigure 5. Comparison of how well Sugar Maple, American Beech, and Gingko fit each model. Ginkgo has a large safety margin to reduce risk of buckling, because of its under optimization for total mass.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Observed Ginkgo differed from models' predictions most in its optimization for total mass.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/[H._S._M._Coxeter,_Samuel_L._Greitzer]_Geometry_Re(z-lib.org).pdf_160",
        "ID": "07d8ab49-76e2-44c4-b1a5-621012fdd312",
        "questions": "What happens to the value of the fraction $\frac{OC}{OA'}$ when $\\epsilon < 1$?",
        "answers": "It becomes negative.",
        "context": "and\n\n$$\n\\begin{array}{l}{{O C\\times O C^{\\prime}\\ =\\ k^{2}\\ =\\ O A\\times O A^{\\prime}}}\\\\ {{r^{2}\\ =\\ A O\\times A C^{\\prime}\\ =\\ O A\\times C^{\\prime}A}}\\end{array}\n$$\n\n(in the notation of directed distances), we have\n\n$$\n\\begin{array}{l}{\\displaystyle\\frac{O C}{O A^{\\prime}}\\,=\\,\\frac{O A}{O C^{\\prime}}\\,=\\,\\frac{O A}{O A\\,-\\,C^{\\prime}A}\\,\\,=\\,\\frac{O A^{2}}{O A^{2}\\,-\\,(O A\\,\\times\\,C^{\\prime}A)}}\\\\ {\\displaystyle\\,=\\,\\frac{O A^{2}}{O A^{2}\\,-\\,r^{2}}\\,=\\,\\frac{\\epsilon^{2}}{\\epsilon^{2}\\,-\\,1}\\,,}\\end{array}\n$$\n\nwhich is negative or positive according as $\\epsilon<1$ or $\\epsilon>1$ . Hence, for an ellipse the center $c$ and directrix $a$ are on opposite sides of $O_{j}$ as in Figure 6.6B, but for a hyperbola they are on the same side, as in Figure 6.6C. In other words, the ellipse encloses its two foci and lies entirely between its two directrices, but the two directrices of a hyperbola both lie in the \"empty\" space between the two branches.\n\n![](images/c827c16a66035b32054275f8bcbdd9bc963b2db91f2a25f30fc799908973de5d.jpg)  \nFigure 66D\n\nIn mechanics we learn that, when air resistance is neglected, the trajectory of a thrown ball is an arc of a parabola whose focus can be located without much difficulty. Since the thrown ball is, for a few seconds, a little artificial satellite, the apparent parabola is more accurately an enormously elongated ellipse, whose eccentricity is just a shade less than 1. Where is its second focus? At the center of the earth!\n\n# EXERCISES\n\n1. When a point $\\pmb{P}$ varies on an ellipse, the sum $O P\\,+\\,O_{1}P$ of its two focal distances is constant. (See Figure 6.6B.)",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "which is negative or positive according as $\\epsilon<1$ or $\\epsilon>1$ .",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/[H._S._M._Coxeter,_Samuel_L._Greitzer]_Geometry_Re(z-lib.org).pdf_160",
        "ID": "07e124e3-2292-44c0-8cbc-b225b7c8dc61",
        "questions": "What describes the position of the center and directrix of an ellipse in relation to $O_j$?",
        "answers": "The center and directrix are on opposite sides of $O_j$.",
        "context": "and\n\n$$\n\\begin{array}{l}{{O C\\times O C^{\\prime}\\ =\\ k^{2}\\ =\\ O A\\times O A^{\\prime}}}\\\\ {{r^{2}\\ =\\ A O\\times A C^{\\prime}\\ =\\ O A\\times C^{\\prime}A}}\\end{array}\n$$\n\n(in the notation of directed distances), we have\n\n$$\n\\begin{array}{l}{\\displaystyle\\frac{O C}{O A^{\\prime}}\\,=\\,\\frac{O A}{O C^{\\prime}}\\,=\\,\\frac{O A}{O A\\,-\\,C^{\\prime}A}\\,\\,=\\,\\frac{O A^{2}}{O A^{2}\\,-\\,(O A\\,\\times\\,C^{\\prime}A)}}\\\\ {\\displaystyle\\,=\\,\\frac{O A^{2}}{O A^{2}\\,-\\,r^{2}}\\,=\\,\\frac{\\epsilon^{2}}{\\epsilon^{2}\\,-\\,1}\\,,}\\end{array}\n$$\n\nwhich is negative or positive according as $\\epsilon<1$ or $\\epsilon>1$ . Hence, for an ellipse the center $c$ and directrix $a$ are on opposite sides of $O_{j}$ as in Figure 6.6B, but for a hyperbola they are on the same side, as in Figure 6.6C. In other words, the ellipse encloses its two foci and lies entirely between its two directrices, but the two directrices of a hyperbola both lie in the \"empty\" space between the two branches.\n\n![](images/c827c16a66035b32054275f8bcbdd9bc963b2db91f2a25f30fc799908973de5d.jpg)  \nFigure 66D\n\nIn mechanics we learn that, when air resistance is neglected, the trajectory of a thrown ball is an arc of a parabola whose focus can be located without much difficulty. Since the thrown ball is, for a few seconds, a little artificial satellite, the apparent parabola is more accurately an enormously elongated ellipse, whose eccentricity is just a shade less than 1. Where is its second focus? At the center of the earth!\n\n# EXERCISES\n\n1. When a point $\\pmb{P}$ varies on an ellipse, the sum $O P\\,+\\,O_{1}P$ of its two focal distances is constant. (See Figure 6.6B.)",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Hence, for an ellipse the center $c$ and directrix $a$ are on opposite sides of $O_{j}$ as in Figure 6.6B, but for a hyperbola they are on the same side, as in Figure 6.6C.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/[H._S._M._Coxeter,_Samuel_L._Greitzer]_Geometry_Re(z-lib.org).pdf_160",
        "ID": "07f819db-e8d7-425b-8a8b-c03efafd02b8",
        "questions": "What geometric shape does the trajectory of a thrown ball follow when air resistance is neglected, and where is its second focus located?",
        "answers": "The trajectory follows an arc of a parabola, and the second focus is at the center of the Earth.",
        "context": "and\n\n$$\n\\begin{array}{l}{{O C\\times O C^{\\prime}\\ =\\ k^{2}\\ =\\ O A\\times O A^{\\prime}}}\\\\ {{r^{2}\\ =\\ A O\\times A C^{\\prime}\\ =\\ O A\\times C^{\\prime}A}}\\end{array}\n$$\n\n(in the notation of directed distances), we have\n\n$$\n\\begin{array}{l}{\\displaystyle\\frac{O C}{O A^{\\prime}}\\,=\\,\\frac{O A}{O C^{\\prime}}\\,=\\,\\frac{O A}{O A\\,-\\,C^{\\prime}A}\\,\\,=\\,\\frac{O A^{2}}{O A^{2}\\,-\\,(O A\\,\\times\\,C^{\\prime}A)}}\\\\ {\\displaystyle\\,=\\,\\frac{O A^{2}}{O A^{2}\\,-\\,r^{2}}\\,=\\,\\frac{\\epsilon^{2}}{\\epsilon^{2}\\,-\\,1}\\,,}\\end{array}\n$$\n\nwhich is negative or positive according as $\\epsilon<1$ or $\\epsilon>1$ . Hence, for an ellipse the center $c$ and directrix $a$ are on opposite sides of $O_{j}$ as in Figure 6.6B, but for a hyperbola they are on the same side, as in Figure 6.6C. In other words, the ellipse encloses its two foci and lies entirely between its two directrices, but the two directrices of a hyperbola both lie in the \"empty\" space between the two branches.\n\n![](images/c827c16a66035b32054275f8bcbdd9bc963b2db91f2a25f30fc799908973de5d.jpg)  \nFigure 66D\n\nIn mechanics we learn that, when air resistance is neglected, the trajectory of a thrown ball is an arc of a parabola whose focus can be located without much difficulty. Since the thrown ball is, for a few seconds, a little artificial satellite, the apparent parabola is more accurately an enormously elongated ellipse, whose eccentricity is just a shade less than 1. Where is its second focus? At the center of the earth!\n\n# EXERCISES\n\n1. When a point $\\pmb{P}$ varies on an ellipse, the sum $O P\\,+\\,O_{1}P$ of its two focal distances is constant. (See Figure 6.6B.)",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "In mechanics we learn that, when air resistance is neglected, the trajectory of a thrown ball is an arc of a parabola whose focus can be located without much difficulty. Since the thrown ball is, for a few seconds, a little artificial satellite, the apparent parabola is more accurately an enormously elongated ellipse, whose eccentricity is just a shade less than 1. Where is its second focus? At the center of the earth!",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/[H._S._M._Coxeter,_Samuel_L._Greitzer]_Geometry_Re(z-lib.org).pdf_160",
        "ID": "07fd4672-7c9d-48a5-a764-6631867eda2e",
        "questions": "What is the relationship between the distances $O A$, $O C^{\\prime}$, and the radius $r$ in the equations given?",
        "answers": "$r^{2} = A O \\times A C^{\\prime} = O A \\times C^{\\prime}A$",
        "context": "and\n\n$$\n\\begin{array}{l}{{O C\\times O C^{\\prime}\\ =\\ k^{2}\\ =\\ O A\\times O A^{\\prime}}}\\\\ {{r^{2}\\ =\\ A O\\times A C^{\\prime}\\ =\\ O A\\times C^{\\prime}A}}\\end{array}\n$$\n\n(in the notation of directed distances), we have\n\n$$\n\\begin{array}{l}{\\displaystyle\\frac{O C}{O A^{\\prime}}\\,=\\,\\frac{O A}{O C^{\\prime}}\\,=\\,\\frac{O A}{O A\\,-\\,C^{\\prime}A}\\,\\,=\\,\\frac{O A^{2}}{O A^{2}\\,-\\,(O A\\,\\times\\,C^{\\prime}A)}}\\\\ {\\displaystyle\\,=\\,\\frac{O A^{2}}{O A^{2}\\,-\\,r^{2}}\\,=\\,\\frac{\\epsilon^{2}}{\\epsilon^{2}\\,-\\,1}\\,,}\\end{array}\n$$\n\nwhich is negative or positive according as $\\epsilon<1$ or $\\epsilon>1$ . Hence, for an ellipse the center $c$ and directrix $a$ are on opposite sides of $O_{j}$ as in Figure 6.6B, but for a hyperbola they are on the same side, as in Figure 6.6C. In other words, the ellipse encloses its two foci and lies entirely between its two directrices, but the two directrices of a hyperbola both lie in the \"empty\" space between the two branches.\n\n![](images/c827c16a66035b32054275f8bcbdd9bc963b2db91f2a25f30fc799908973de5d.jpg)  \nFigure 66D\n\nIn mechanics we learn that, when air resistance is neglected, the trajectory of a thrown ball is an arc of a parabola whose focus can be located without much difficulty. Since the thrown ball is, for a few seconds, a little artificial satellite, the apparent parabola is more accurately an enormously elongated ellipse, whose eccentricity is just a shade less than 1. Where is its second focus? At the center of the earth!\n\n# EXERCISES\n\n1. When a point $\\pmb{P}$ varies on an ellipse, the sum $O P\\,+\\,O_{1}P$ of its two focal distances is constant. (See Figure 6.6B.)",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Numeric",
        "evidence_source": "equation",
        "evidence_context": "$r^{2} = A O \\times A C^{\\prime} = O A \\times C^{\\prime}A$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/[H._S._M._Coxeter,_Samuel_L._Greitzer]_Geometry_Re(z-lib.org).pdf_160",
        "ID": "07fe6a4e-2a6f-4e47-9b61-f92b9cf600ec",
        "questions": "How is the expression $\\frac{OC}{OA^{\\prime}}$ related to $\\epsilon$ in the context of whether it is positive or negative?",
        "answers": "$\\frac{\\epsilon^{2}}{\\epsilon^{2}-1}$, which is negative or positive according as $\\epsilon<1$ or $\\epsilon>1$",
        "context": "and\n\n$$\n\\begin{array}{l}{{O C\\times O C^{\\prime}\\ =\\ k^{2}\\ =\\ O A\\times O A^{\\prime}}}\\\\ {{r^{2}\\ =\\ A O\\times A C^{\\prime}\\ =\\ O A\\times C^{\\prime}A}}\\end{array}\n$$\n\n(in the notation of directed distances), we have\n\n$$\n\\begin{array}{l}{\\displaystyle\\frac{O C}{O A^{\\prime}}\\,=\\,\\frac{O A}{O C^{\\prime}}\\,=\\,\\frac{O A}{O A\\,-\\,C^{\\prime}A}\\,\\,=\\,\\frac{O A^{2}}{O A^{2}\\,-\\,(O A\\,\\times\\,C^{\\prime}A)}}\\\\ {\\displaystyle\\,=\\,\\frac{O A^{2}}{O A^{2}\\,-\\,r^{2}}\\,=\\,\\frac{\\epsilon^{2}}{\\epsilon^{2}\\,-\\,1}\\,,}\\end{array}\n$$\n\nwhich is negative or positive according as $\\epsilon<1$ or $\\epsilon>1$ . Hence, for an ellipse the center $c$ and directrix $a$ are on opposite sides of $O_{j}$ as in Figure 6.6B, but for a hyperbola they are on the same side, as in Figure 6.6C. In other words, the ellipse encloses its two foci and lies entirely between its two directrices, but the two directrices of a hyperbola both lie in the \"empty\" space between the two branches.\n\n![](images/c827c16a66035b32054275f8bcbdd9bc963b2db91f2a25f30fc799908973de5d.jpg)  \nFigure 66D\n\nIn mechanics we learn that, when air resistance is neglected, the trajectory of a thrown ball is an arc of a parabola whose focus can be located without much difficulty. Since the thrown ball is, for a few seconds, a little artificial satellite, the apparent parabola is more accurately an enormously elongated ellipse, whose eccentricity is just a shade less than 1. Where is its second focus? At the center of the earth!\n\n# EXERCISES\n\n1. When a point $\\pmb{P}$ varies on an ellipse, the sum $O P\\,+\\,O_{1}P$ of its two focal distances is constant. (See Figure 6.6B.)",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$\\frac{OC}{OA^{\\prime}} = \\frac{OA^{2}}{OA^{2}-r^{2}} = \\frac{\\epsilon^{2}}{\\epsilon^{2}-1}$, which is negative or positive according as $\\epsilon<1$ or $\\epsilon>1$.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/[H._S._M._Coxeter,_Samuel_L._Greitzer]_Geometry_Re(z-lib.org).pdf_160",
        "ID": "08055d83-2d81-4097-b80f-142f87bfef1a",
        "questions": "What equation determines the constant nature of the relationship between $OC$, $OA^{\\prime}$, and $OA$ as the distances vary in an ellipse?",
        "answers": "$\\frac{OC}{OA^{\\prime}} = \\frac{OA}{OC^{\\prime}} = \\frac{OA}{OA-C^{\\prime}A} = \\frac{OA^{2}}{OA^{2}-(OA \\times C^{\\prime}A)}$",
        "context": "and\n\n$$\n\\begin{array}{l}{{O C\\times O C^{\\prime}\\ =\\ k^{2}\\ =\\ O A\\times O A^{\\prime}}}\\\\ {{r^{2}\\ =\\ A O\\times A C^{\\prime}\\ =\\ O A\\times C^{\\prime}A}}\\end{array}\n$$\n\n(in the notation of directed distances), we have\n\n$$\n\\begin{array}{l}{\\displaystyle\\frac{O C}{O A^{\\prime}}\\,=\\,\\frac{O A}{O C^{\\prime}}\\,=\\,\\frac{O A}{O A\\,-\\,C^{\\prime}A}\\,\\,=\\,\\frac{O A^{2}}{O A^{2}\\,-\\,(O A\\,\\times\\,C^{\\prime}A)}}\\\\ {\\displaystyle\\,=\\,\\frac{O A^{2}}{O A^{2}\\,-\\,r^{2}}\\,=\\,\\frac{\\epsilon^{2}}{\\epsilon^{2}\\,-\\,1}\\,,}\\end{array}\n$$\n\nwhich is negative or positive according as $\\epsilon<1$ or $\\epsilon>1$ . Hence, for an ellipse the center $c$ and directrix $a$ are on opposite sides of $O_{j}$ as in Figure 6.6B, but for a hyperbola they are on the same side, as in Figure 6.6C. In other words, the ellipse encloses its two foci and lies entirely between its two directrices, but the two directrices of a hyperbola both lie in the \"empty\" space between the two branches.\n\n![](images/c827c16a66035b32054275f8bcbdd9bc963b2db91f2a25f30fc799908973de5d.jpg)  \nFigure 66D\n\nIn mechanics we learn that, when air resistance is neglected, the trajectory of a thrown ball is an arc of a parabola whose focus can be located without much difficulty. Since the thrown ball is, for a few seconds, a little artificial satellite, the apparent parabola is more accurately an enormously elongated ellipse, whose eccentricity is just a shade less than 1. Where is its second focus? At the center of the earth!\n\n# EXERCISES\n\n1. When a point $\\pmb{P}$ varies on an ellipse, the sum $O P\\,+\\,O_{1}P$ of its two focal distances is constant. (See Figure 6.6B.)",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$\\frac{OC}{OA^{\\prime}} = \\frac{OA}{OC^{\\prime}} = \\frac{OA}{OA-C^{\\prime}A} = \\frac{OA^{2}}{OA^{2}-(OA \\times C^{\\prime}A)}$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/00e2c609b4339c40455281ce1793c5e2158dd90d163ff4d64bc0795b715b6393.pdf_4",
        "ID": "080ba0b1-bb47-4997-94b3-e0f143173432",
        "questions": "What percentage increase in projected cost is expected for U.S titles in the Arts & Humanities category from 1999 to 2000?",
        "answers": "9%",
        "context": "tions are that the publishers are having moderate success with the first model, less with the second.\n\n$\n \\begin{tabular}{|lcccccccc|}  \\multicolumn{9}{|c|}{TABLE 6: 2000 COST PROJECTIONS BY BROAD SUBJECT}\\\\   Citation Index&No. of Titles&\\% of List&1999 Cost&\\% of Cost&Projected \\% of increase&Projected 2000 Cost&\\% of Cost&Projected Overall \\% increase\\  \\multicolumn{9}{|l|}{ARTS\\&HUMANITIES}\\\\   U.S.&701&49.9&\\$90,889&35.5&9&\\$99,047&35.7&\\multirow{2}{*}{8.4}\\\\NON-U.S.&703&50.1&168,327&64.5&8&178,553&64.3&\\ \\multicolumn{9}{|l|}{SOCIAL SCIENCE}\\ US.&1,369&51.8&\\$400,921&32.9&11&\\$445,0222&33.3&\\multirow{2}{*}{9.7}\\\\NON-US.&1,272&48.2&818,099&67.1&9&891,728&66.7&\\multirow{2}{*}{...\\text{--}.--}.\\ \\multicolumn{9}{|l|}{SCIENCE}\\ U.S.&1,196&40.6&\\$787,959&29.7&11.5&\\$878,574&30.3&\\multirow{2}{*}{9.4}\\\\NON-U.S.&1,749&59.4&1,863,324&70.3&8.5&2,021,707&69.7&\\ \\multicolumn{9}{|c|}{PROJECTED OVERALL INCREASE FOR ALL ISI TITLES: 9.4\\%}\\  \\end{tabular}\n$\n\n# Acquiring the critical mass  \n\nPublisher buyouts are another response to market uncertainty and are big news in the serials market. Despite a merger between Kluwer and Reed-Elsevier being called off in the face of growing attention from antitrust agencies on both sides of the Atlantic, smaller, quieter mergers have proceeded toward the same end unnoticed. Large commercial publishers are steadily absorbing smaller publishers whose journals can round out their offerings and help them achieve brand identity, or critical mass, in specialty areas. In 1998 alone, Kluwer acquired Waverly/Williams Wilkins, Plenum, and Ovid Technologies; Taylor & Francis acquired Routledge and Carfax; Harcourt/Academic Press acquired Mosby; Bertelsmann, a large entertainment conglomerate, acquired Springer Verlag; and Elsevier Science acquired six publishers, including JAI Press, BioMedNet, and Beilstein. Smaller publishers undoubtedly see these mergers as opportunities to get their titles into the electronic mainstream. For library customers, this trend represents a loss of competition, which does not bode well for prices.  \n\n# Librarians creating mass, too  \n\nIn response, libraries, universities, and learned societies are beginning to experiment with creating critical mass of their own to challenge commercial publishers and drive prices down. Two such experiments are drawing attention. SPARC, the Scholarly Publishing and Academic Resources Coalition founded by the Association of Research Libraries, uses funds pledged by its members to subsidize and support publishers whose e-journals can go head-to-head with very costly commercial journals but at lower subscription rates. SPARC has successfully launched electronic journals from two well-known chemical societies and a group of distinguished ecologists. (For more on SPARC, see Ken Frazier's \"Liberating Scholarship,\" LJ 10/15/98, p. 40-41. -Ed.)\n\nHighWire Press was begun by Stanford University Library in 1997 to assist society publishers in getting their journals online. With more than 100 titles now among its offerings and with growing markets in the United States and abroad, HighWire is challenging the assumption that full-featured web journals have to come from commercial STM publishers. These library-driven strategies, like the ones of the commercial publishers, are fueled by hopes of shaping future markets in their favor.\n\n# A global economy  \n\nPublishers and vendors have taken a hit from the economic crises in Asia and in Latin America. Reacting to the threat of significant cancellations in many Asian countries and in Brazil, some publishers attempted to protect their subscription base in these countries by extending credit directly to customers and/or to their agents to keep them from canceling titles. Other publishers decided to accept the cancellations and reduce their exposure to losses from bad credit. In the midst of the dilemma are agents, whose profits have also been affected by libraries that could not pay.  \n\nOn the positive side, the advent of the long-awaited Euro should have a stabilizing effect on periodical pricing, particularly for libraries in European countries, in that costs should become more transparent with fewer cross-border currency exchanges. Given the diversity among nations in the European Union relative to unemployment, inflation, and economic strength, experts split on the question of whether the dollar or the Euro will emerge as the favored currency in 1999. Either way, prices for serials sold across the Atlantic will be affected, just as they have in the past.  \n\n# Cost trends  \n\nDespite the chaos surrounding electronic journals, print subscriptions still command most of the serials dollars in libraries and, therefore, still require.\n\n# Periodical Prices for Public and School Libraries  \n\nTitles in EBSCO Publishing's general index, Magazine Article Summaries (MAS), are those most often subscribed to by school and public libraries in the United States based on data from EBSCO.\n\nSubscription Services. Table 7 provides historical data for about 35 titles in the index. Price increases for next year are expected to be in the range of five percent.\n\n$\n\\begin{tabular}{|lccccccccccc|}\n \n\\multicolumn{12}{|c|}{TABLE 7: COST HISTORY FOR TITLES IN MAGAZINE ARTICLE SUMMARIES} \\\\  \nMagazine Article Summaries & Average No. of Titles '95-'99 & Average Cost Per Title 1995 & Average Cost Per Title 1996 & \\% of Change '95-'96 & Average Cost Per Title 1997 & \\% of Change '96-'97 & Average Cost Per Title 1998 & \\% of Change '97-'98 & Average Cost Per Title 1999 & \\% of Change '98-'99 & '95-'99 \\% of Change \\\\  \nU.S. & 334 & \\$42.03 & \\$44.07 & 4.9 & \\$46.14 & 4.7 & \\$48.02 & 4.1 & \\$50.32 & 4.8 & 19.7 \\\\  \nNON-U.S. & 10 & 100.02 & 107.94 & 7.9 & 112.41 & 4.1 & 123.15 & 9.6 & 129.48 & 5.1 & 29.5 \\\\  \n\\end{tabular}\n$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "table",
        "evidence_context": "$ \\textbf{U.S.}&701&49.9&\\$90,889&35.5&9&\\$99,047&35.7&\\multirow{2}{*}{8.4}",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/00e2c609b4339c40455281ce1793c5e2158dd90d163ff4d64bc0795b715b6393.pdf_4",
        "ID": "081116e5-a4c0-4de0-9b94-82ed19691d41",
        "questions": "How many titles does HighWire Press have in its offerings since its inception by Stanford University Library in 1997?",
        "answers": "more than 100",
        "context": "tions are that the publishers are having moderate success with the first model, less with the second.\n\n$\n \\begin{tabular}{|lcccccccc|}  \\multicolumn{9}{|c|}{TABLE 6: 2000 COST PROJECTIONS BY BROAD SUBJECT}\\\\   Citation Index&No. of Titles&\\% of List&1999 Cost&\\% of Cost&Projected \\% of increase&Projected 2000 Cost&\\% of Cost&Projected Overall \\% increase\\  \\multicolumn{9}{|l|}{ARTS\\&HUMANITIES}\\\\   U.S.&701&49.9&\\$90,889&35.5&9&\\$99,047&35.7&\\multirow{2}{*}{8.4}\\\\NON-U.S.&703&50.1&168,327&64.5&8&178,553&64.3&\\ \\multicolumn{9}{|l|}{SOCIAL SCIENCE}\\ US.&1,369&51.8&\\$400,921&32.9&11&\\$445,0222&33.3&\\multirow{2}{*}{9.7}\\\\NON-US.&1,272&48.2&818,099&67.1&9&891,728&66.7&\\multirow{2}{*}{...\\text{--}.--}.\\ \\multicolumn{9}{|l|}{SCIENCE}\\ U.S.&1,196&40.6&\\$787,959&29.7&11.5&\\$878,574&30.3&\\multirow{2}{*}{9.4}\\\\NON-U.S.&1,749&59.4&1,863,324&70.3&8.5&2,021,707&69.7&\\ \\multicolumn{9}{|c|}{PROJECTED OVERALL INCREASE FOR ALL ISI TITLES: 9.4\\%}\\  \\end{tabular}\n$\n\n# Acquiring the critical mass  \n\nPublisher buyouts are another response to market uncertainty and are big news in the serials market. Despite a merger between Kluwer and Reed-Elsevier being called off in the face of growing attention from antitrust agencies on both sides of the Atlantic, smaller, quieter mergers have proceeded toward the same end unnoticed. Large commercial publishers are steadily absorbing smaller publishers whose journals can round out their offerings and help them achieve brand identity, or critical mass, in specialty areas. In 1998 alone, Kluwer acquired Waverly/Williams Wilkins, Plenum, and Ovid Technologies; Taylor & Francis acquired Routledge and Carfax; Harcourt/Academic Press acquired Mosby; Bertelsmann, a large entertainment conglomerate, acquired Springer Verlag; and Elsevier Science acquired six publishers, including JAI Press, BioMedNet, and Beilstein. Smaller publishers undoubtedly see these mergers as opportunities to get their titles into the electronic mainstream. For library customers, this trend represents a loss of competition, which does not bode well for prices.  \n\n# Librarians creating mass, too  \n\nIn response, libraries, universities, and learned societies are beginning to experiment with creating critical mass of their own to challenge commercial publishers and drive prices down. Two such experiments are drawing attention. SPARC, the Scholarly Publishing and Academic Resources Coalition founded by the Association of Research Libraries, uses funds pledged by its members to subsidize and support publishers whose e-journals can go head-to-head with very costly commercial journals but at lower subscription rates. SPARC has successfully launched electronic journals from two well-known chemical societies and a group of distinguished ecologists. (For more on SPARC, see Ken Frazier's \"Liberating Scholarship,\" LJ 10/15/98, p. 40-41. -Ed.)\n\nHighWire Press was begun by Stanford University Library in 1997 to assist society publishers in getting their journals online. With more than 100 titles now among its offerings and with growing markets in the United States and abroad, HighWire is challenging the assumption that full-featured web journals have to come from commercial STM publishers. These library-driven strategies, like the ones of the commercial publishers, are fueled by hopes of shaping future markets in their favor.\n\n# A global economy  \n\nPublishers and vendors have taken a hit from the economic crises in Asia and in Latin America. Reacting to the threat of significant cancellations in many Asian countries and in Brazil, some publishers attempted to protect their subscription base in these countries by extending credit directly to customers and/or to their agents to keep them from canceling titles. Other publishers decided to accept the cancellations and reduce their exposure to losses from bad credit. In the midst of the dilemma are agents, whose profits have also been affected by libraries that could not pay.  \n\nOn the positive side, the advent of the long-awaited Euro should have a stabilizing effect on periodical pricing, particularly for libraries in European countries, in that costs should become more transparent with fewer cross-border currency exchanges. Given the diversity among nations in the European Union relative to unemployment, inflation, and economic strength, experts split on the question of whether the dollar or the Euro will emerge as the favored currency in 1999. Either way, prices for serials sold across the Atlantic will be affected, just as they have in the past.  \n\n# Cost trends  \n\nDespite the chaos surrounding electronic journals, print subscriptions still command most of the serials dollars in libraries and, therefore, still require.\n\n# Periodical Prices for Public and School Libraries  \n\nTitles in EBSCO Publishing's general index, Magazine Article Summaries (MAS), are those most often subscribed to by school and public libraries in the United States based on data from EBSCO.\n\nSubscription Services. Table 7 provides historical data for about 35 titles in the index. Price increases for next year are expected to be in the range of five percent.\n\n$\n\\begin{tabular}{|lccccccccccc|}\n \n\\multicolumn{12}{|c|}{TABLE 7: COST HISTORY FOR TITLES IN MAGAZINE ARTICLE SUMMARIES} \\\\  \nMagazine Article Summaries & Average No. of Titles '95-'99 & Average Cost Per Title 1995 & Average Cost Per Title 1996 & \\% of Change '95-'96 & Average Cost Per Title 1997 & \\% of Change '96-'97 & Average Cost Per Title 1998 & \\% of Change '97-'98 & Average Cost Per Title 1999 & \\% of Change '98-'99 & '95-'99 \\% of Change \\\\  \nU.S. & 334 & \\$42.03 & \\$44.07 & 4.9 & \\$46.14 & 4.7 & \\$48.02 & 4.1 & \\$50.32 & 4.8 & 19.7 \\\\  \nNON-U.S. & 10 & 100.02 & 107.94 & 7.9 & 112.41 & 4.1 & 123.15 & 9.6 & 129.48 & 5.1 & 29.5 \\\\  \n\\end{tabular}\n$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "With more than 100 titles now among its offerings and with growing markets in the United States and abroad, HighWire is challenging the assumption that full-featured web journals have to come from commercial STM publishers.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/00e2c609b4339c40455281ce1793c5e2158dd90d163ff4d64bc0795b715b6393.pdf_4",
        "ID": "081797ca-99ac-4892-b26e-1c2f2fcfd8b7",
        "questions": "What was the average cost per title for U.S. magazines in the Magazine Article Summaries index in 1995?",
        "answers": "$42.03",
        "context": "tions are that the publishers are having moderate success with the first model, less with the second.\n\n$\n \\begin{tabular}{|lcccccccc|}  \\multicolumn{9}{|c|}{TABLE 6: 2000 COST PROJECTIONS BY BROAD SUBJECT}\\\\   Citation Index&No. of Titles&\\% of List&1999 Cost&\\% of Cost&Projected \\% of increase&Projected 2000 Cost&\\% of Cost&Projected Overall \\% increase\\  \\multicolumn{9}{|l|}{ARTS\\&HUMANITIES}\\\\   U.S.&701&49.9&\\$90,889&35.5&9&\\$99,047&35.7&\\multirow{2}{*}{8.4}\\\\NON-U.S.&703&50.1&168,327&64.5&8&178,553&64.3&\\ \\multicolumn{9}{|l|}{SOCIAL SCIENCE}\\ US.&1,369&51.8&\\$400,921&32.9&11&\\$445,0222&33.3&\\multirow{2}{*}{9.7}\\\\NON-US.&1,272&48.2&818,099&67.1&9&891,728&66.7&\\multirow{2}{*}{...\\text{--}.--}.\\ \\multicolumn{9}{|l|}{SCIENCE}\\ U.S.&1,196&40.6&\\$787,959&29.7&11.5&\\$878,574&30.3&\\multirow{2}{*}{9.4}\\\\NON-U.S.&1,749&59.4&1,863,324&70.3&8.5&2,021,707&69.7&\\ \\multicolumn{9}{|c|}{PROJECTED OVERALL INCREASE FOR ALL ISI TITLES: 9.4\\%}\\  \\end{tabular}\n$\n\n# Acquiring the critical mass  \n\nPublisher buyouts are another response to market uncertainty and are big news in the serials market. Despite a merger between Kluwer and Reed-Elsevier being called off in the face of growing attention from antitrust agencies on both sides of the Atlantic, smaller, quieter mergers have proceeded toward the same end unnoticed. Large commercial publishers are steadily absorbing smaller publishers whose journals can round out their offerings and help them achieve brand identity, or critical mass, in specialty areas. In 1998 alone, Kluwer acquired Waverly/Williams Wilkins, Plenum, and Ovid Technologies; Taylor & Francis acquired Routledge and Carfax; Harcourt/Academic Press acquired Mosby; Bertelsmann, a large entertainment conglomerate, acquired Springer Verlag; and Elsevier Science acquired six publishers, including JAI Press, BioMedNet, and Beilstein. Smaller publishers undoubtedly see these mergers as opportunities to get their titles into the electronic mainstream. For library customers, this trend represents a loss of competition, which does not bode well for prices.  \n\n# Librarians creating mass, too  \n\nIn response, libraries, universities, and learned societies are beginning to experiment with creating critical mass of their own to challenge commercial publishers and drive prices down. Two such experiments are drawing attention. SPARC, the Scholarly Publishing and Academic Resources Coalition founded by the Association of Research Libraries, uses funds pledged by its members to subsidize and support publishers whose e-journals can go head-to-head with very costly commercial journals but at lower subscription rates. SPARC has successfully launched electronic journals from two well-known chemical societies and a group of distinguished ecologists. (For more on SPARC, see Ken Frazier's \"Liberating Scholarship,\" LJ 10/15/98, p. 40-41. -Ed.)\n\nHighWire Press was begun by Stanford University Library in 1997 to assist society publishers in getting their journals online. With more than 100 titles now among its offerings and with growing markets in the United States and abroad, HighWire is challenging the assumption that full-featured web journals have to come from commercial STM publishers. These library-driven strategies, like the ones of the commercial publishers, are fueled by hopes of shaping future markets in their favor.\n\n# A global economy  \n\nPublishers and vendors have taken a hit from the economic crises in Asia and in Latin America. Reacting to the threat of significant cancellations in many Asian countries and in Brazil, some publishers attempted to protect their subscription base in these countries by extending credit directly to customers and/or to their agents to keep them from canceling titles. Other publishers decided to accept the cancellations and reduce their exposure to losses from bad credit. In the midst of the dilemma are agents, whose profits have also been affected by libraries that could not pay.  \n\nOn the positive side, the advent of the long-awaited Euro should have a stabilizing effect on periodical pricing, particularly for libraries in European countries, in that costs should become more transparent with fewer cross-border currency exchanges. Given the diversity among nations in the European Union relative to unemployment, inflation, and economic strength, experts split on the question of whether the dollar or the Euro will emerge as the favored currency in 1999. Either way, prices for serials sold across the Atlantic will be affected, just as they have in the past.  \n\n# Cost trends  \n\nDespite the chaos surrounding electronic journals, print subscriptions still command most of the serials dollars in libraries and, therefore, still require.\n\n# Periodical Prices for Public and School Libraries  \n\nTitles in EBSCO Publishing's general index, Magazine Article Summaries (MAS), are those most often subscribed to by school and public libraries in the United States based on data from EBSCO.\n\nSubscription Services. Table 7 provides historical data for about 35 titles in the index. Price increases for next year are expected to be in the range of five percent.\n\n$\n\\begin{tabular}{|lccccccccccc|}\n \n\\multicolumn{12}{|c|}{TABLE 7: COST HISTORY FOR TITLES IN MAGAZINE ARTICLE SUMMARIES} \\\\  \nMagazine Article Summaries & Average No. of Titles '95-'99 & Average Cost Per Title 1995 & Average Cost Per Title 1996 & \\% of Change '95-'96 & Average Cost Per Title 1997 & \\% of Change '96-'97 & Average Cost Per Title 1998 & \\% of Change '97-'98 & Average Cost Per Title 1999 & \\% of Change '98-'99 & '95-'99 \\% of Change \\\\  \nU.S. & 334 & \\$42.03 & \\$44.07 & 4.9 & \\$46.14 & 4.7 & \\$48.02 & 4.1 & \\$50.32 & 4.8 & 19.7 \\\\  \nNON-U.S. & 10 & 100.02 & 107.94 & 7.9 & 112.41 & 4.1 & 123.15 & 9.6 & 129.48 & 5.1 & 29.5 \\\\  \n\\end{tabular}\n$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "table",
        "evidence_context": "\\textbf{U.S.} & 334 & \\$42.03 & \\$44.07 & 4.9 & \\$46.14 & 4.7 & \\$48.02 & 4.1 & \\$50.32 & 4.8 & 19.7",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/00e2c609b4339c40455281ce1793c5e2158dd90d163ff4d64bc0795b715b6393.pdf_4",
        "ID": "081f7d48-bf27-4b0e-8900-2e4fcbb4b8dc",
        "questions": "What is the projected percentage increase in cost for U.S. social science titles from 1999 to 2000 according to the cost projections table?",
        "answers": "11",
        "context": "tions are that the publishers are having moderate success with the first model, less with the second.\n\n$\n \\begin{tabular}{|lcccccccc|}  \\multicolumn{9}{|c|}{TABLE 6: 2000 COST PROJECTIONS BY BROAD SUBJECT}\\\\   Citation Index&No. of Titles&\\% of List&1999 Cost&\\% of Cost&Projected \\% of increase&Projected 2000 Cost&\\% of Cost&Projected Overall \\% increase\\  \\multicolumn{9}{|l|}{ARTS\\&HUMANITIES}\\\\   U.S.&701&49.9&\\$90,889&35.5&9&\\$99,047&35.7&\\multirow{2}{*}{8.4}\\\\NON-U.S.&703&50.1&168,327&64.5&8&178,553&64.3&\\ \\multicolumn{9}{|l|}{SOCIAL SCIENCE}\\ US.&1,369&51.8&\\$400,921&32.9&11&\\$445,0222&33.3&\\multirow{2}{*}{9.7}\\\\NON-US.&1,272&48.2&818,099&67.1&9&891,728&66.7&\\multirow{2}{*}{...\\text{--}.--}.\\ \\multicolumn{9}{|l|}{SCIENCE}\\ U.S.&1,196&40.6&\\$787,959&29.7&11.5&\\$878,574&30.3&\\multirow{2}{*}{9.4}\\\\NON-U.S.&1,749&59.4&1,863,324&70.3&8.5&2,021,707&69.7&\\ \\multicolumn{9}{|c|}{PROJECTED OVERALL INCREASE FOR ALL ISI TITLES: 9.4\\%}\\  \\end{tabular}\n$\n\n# Acquiring the critical mass  \n\nPublisher buyouts are another response to market uncertainty and are big news in the serials market. Despite a merger between Kluwer and Reed-Elsevier being called off in the face of growing attention from antitrust agencies on both sides of the Atlantic, smaller, quieter mergers have proceeded toward the same end unnoticed. Large commercial publishers are steadily absorbing smaller publishers whose journals can round out their offerings and help them achieve brand identity, or critical mass, in specialty areas. In 1998 alone, Kluwer acquired Waverly/Williams Wilkins, Plenum, and Ovid Technologies; Taylor & Francis acquired Routledge and Carfax; Harcourt/Academic Press acquired Mosby; Bertelsmann, a large entertainment conglomerate, acquired Springer Verlag; and Elsevier Science acquired six publishers, including JAI Press, BioMedNet, and Beilstein. Smaller publishers undoubtedly see these mergers as opportunities to get their titles into the electronic mainstream. For library customers, this trend represents a loss of competition, which does not bode well for prices.  \n\n# Librarians creating mass, too  \n\nIn response, libraries, universities, and learned societies are beginning to experiment with creating critical mass of their own to challenge commercial publishers and drive prices down. Two such experiments are drawing attention. SPARC, the Scholarly Publishing and Academic Resources Coalition founded by the Association of Research Libraries, uses funds pledged by its members to subsidize and support publishers whose e-journals can go head-to-head with very costly commercial journals but at lower subscription rates. SPARC has successfully launched electronic journals from two well-known chemical societies and a group of distinguished ecologists. (For more on SPARC, see Ken Frazier's \"Liberating Scholarship,\" LJ 10/15/98, p. 40-41. -Ed.)\n\nHighWire Press was begun by Stanford University Library in 1997 to assist society publishers in getting their journals online. With more than 100 titles now among its offerings and with growing markets in the United States and abroad, HighWire is challenging the assumption that full-featured web journals have to come from commercial STM publishers. These library-driven strategies, like the ones of the commercial publishers, are fueled by hopes of shaping future markets in their favor.\n\n# A global economy  \n\nPublishers and vendors have taken a hit from the economic crises in Asia and in Latin America. Reacting to the threat of significant cancellations in many Asian countries and in Brazil, some publishers attempted to protect their subscription base in these countries by extending credit directly to customers and/or to their agents to keep them from canceling titles. Other publishers decided to accept the cancellations and reduce their exposure to losses from bad credit. In the midst of the dilemma are agents, whose profits have also been affected by libraries that could not pay.  \n\nOn the positive side, the advent of the long-awaited Euro should have a stabilizing effect on periodical pricing, particularly for libraries in European countries, in that costs should become more transparent with fewer cross-border currency exchanges. Given the diversity among nations in the European Union relative to unemployment, inflation, and economic strength, experts split on the question of whether the dollar or the Euro will emerge as the favored currency in 1999. Either way, prices for serials sold across the Atlantic will be affected, just as they have in the past.  \n\n# Cost trends  \n\nDespite the chaos surrounding electronic journals, print subscriptions still command most of the serials dollars in libraries and, therefore, still require.\n\n# Periodical Prices for Public and School Libraries  \n\nTitles in EBSCO Publishing's general index, Magazine Article Summaries (MAS), are those most often subscribed to by school and public libraries in the United States based on data from EBSCO.\n\nSubscription Services. Table 7 provides historical data for about 35 titles in the index. Price increases for next year are expected to be in the range of five percent.\n\n$\n\\begin{tabular}{|lccccccccccc|}\n \n\\multicolumn{12}{|c|}{TABLE 7: COST HISTORY FOR TITLES IN MAGAZINE ARTICLE SUMMARIES} \\\\  \nMagazine Article Summaries & Average No. of Titles '95-'99 & Average Cost Per Title 1995 & Average Cost Per Title 1996 & \\% of Change '95-'96 & Average Cost Per Title 1997 & \\% of Change '96-'97 & Average Cost Per Title 1998 & \\% of Change '97-'98 & Average Cost Per Title 1999 & \\% of Change '98-'99 & '95-'99 \\% of Change \\\\  \nU.S. & 334 & \\$42.03 & \\$44.07 & 4.9 & \\$46.14 & 4.7 & \\$48.02 & 4.1 & \\$50.32 & 4.8 & 19.7 \\\\  \nNON-U.S. & 10 & 100.02 & 107.94 & 7.9 & 112.41 & 4.1 & 123.15 & 9.6 & 129.48 & 5.1 & 29.5 \\\\  \n\\end{tabular}\n$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Numeric",
        "evidence_source": "equation",
        "evidence_context": "US.\\&1,369&51.8&\\$400,921&32.9&11&\\$445,0222&33.3&\\multirow{2}{*}{9.7}",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/00e2c609b4339c40455281ce1793c5e2158dd90d163ff4d64bc0795b715b6393.pdf_4",
        "ID": "08268550-d171-4798-91a0-375a2d0b4f43",
        "questions": "How much is the projected 2000 cost for non-U.S. science titles according to the 2000 cost projections table?",
        "answers": "2,021,707",
        "context": "tions are that the publishers are having moderate success with the first model, less with the second.\n\n$\n \\begin{tabular}{|lcccccccc|}  \\multicolumn{9}{|c|}{TABLE 6: 2000 COST PROJECTIONS BY BROAD SUBJECT}\\\\   Citation Index&No. of Titles&\\% of List&1999 Cost&\\% of Cost&Projected \\% of increase&Projected 2000 Cost&\\% of Cost&Projected Overall \\% increase\\  \\multicolumn{9}{|l|}{ARTS\\&HUMANITIES}\\\\   U.S.&701&49.9&\\$90,889&35.5&9&\\$99,047&35.7&\\multirow{2}{*}{8.4}\\\\NON-U.S.&703&50.1&168,327&64.5&8&178,553&64.3&\\ \\multicolumn{9}{|l|}{SOCIAL SCIENCE}\\ US.&1,369&51.8&\\$400,921&32.9&11&\\$445,0222&33.3&\\multirow{2}{*}{9.7}\\\\NON-US.&1,272&48.2&818,099&67.1&9&891,728&66.7&\\multirow{2}{*}{...\\text{--}.--}.\\ \\multicolumn{9}{|l|}{SCIENCE}\\ U.S.&1,196&40.6&\\$787,959&29.7&11.5&\\$878,574&30.3&\\multirow{2}{*}{9.4}\\\\NON-U.S.&1,749&59.4&1,863,324&70.3&8.5&2,021,707&69.7&\\ \\multicolumn{9}{|c|}{PROJECTED OVERALL INCREASE FOR ALL ISI TITLES: 9.4\\%}\\  \\end{tabular}\n$\n\n# Acquiring the critical mass  \n\nPublisher buyouts are another response to market uncertainty and are big news in the serials market. Despite a merger between Kluwer and Reed-Elsevier being called off in the face of growing attention from antitrust agencies on both sides of the Atlantic, smaller, quieter mergers have proceeded toward the same end unnoticed. Large commercial publishers are steadily absorbing smaller publishers whose journals can round out their offerings and help them achieve brand identity, or critical mass, in specialty areas. In 1998 alone, Kluwer acquired Waverly/Williams Wilkins, Plenum, and Ovid Technologies; Taylor & Francis acquired Routledge and Carfax; Harcourt/Academic Press acquired Mosby; Bertelsmann, a large entertainment conglomerate, acquired Springer Verlag; and Elsevier Science acquired six publishers, including JAI Press, BioMedNet, and Beilstein. Smaller publishers undoubtedly see these mergers as opportunities to get their titles into the electronic mainstream. For library customers, this trend represents a loss of competition, which does not bode well for prices.  \n\n# Librarians creating mass, too  \n\nIn response, libraries, universities, and learned societies are beginning to experiment with creating critical mass of their own to challenge commercial publishers and drive prices down. Two such experiments are drawing attention. SPARC, the Scholarly Publishing and Academic Resources Coalition founded by the Association of Research Libraries, uses funds pledged by its members to subsidize and support publishers whose e-journals can go head-to-head with very costly commercial journals but at lower subscription rates. SPARC has successfully launched electronic journals from two well-known chemical societies and a group of distinguished ecologists. (For more on SPARC, see Ken Frazier's \"Liberating Scholarship,\" LJ 10/15/98, p. 40-41. -Ed.)\n\nHighWire Press was begun by Stanford University Library in 1997 to assist society publishers in getting their journals online. With more than 100 titles now among its offerings and with growing markets in the United States and abroad, HighWire is challenging the assumption that full-featured web journals have to come from commercial STM publishers. These library-driven strategies, like the ones of the commercial publishers, are fueled by hopes of shaping future markets in their favor.\n\n# A global economy  \n\nPublishers and vendors have taken a hit from the economic crises in Asia and in Latin America. Reacting to the threat of significant cancellations in many Asian countries and in Brazil, some publishers attempted to protect their subscription base in these countries by extending credit directly to customers and/or to their agents to keep them from canceling titles. Other publishers decided to accept the cancellations and reduce their exposure to losses from bad credit. In the midst of the dilemma are agents, whose profits have also been affected by libraries that could not pay.  \n\nOn the positive side, the advent of the long-awaited Euro should have a stabilizing effect on periodical pricing, particularly for libraries in European countries, in that costs should become more transparent with fewer cross-border currency exchanges. Given the diversity among nations in the European Union relative to unemployment, inflation, and economic strength, experts split on the question of whether the dollar or the Euro will emerge as the favored currency in 1999. Either way, prices for serials sold across the Atlantic will be affected, just as they have in the past.  \n\n# Cost trends  \n\nDespite the chaos surrounding electronic journals, print subscriptions still command most of the serials dollars in libraries and, therefore, still require.\n\n# Periodical Prices for Public and School Libraries  \n\nTitles in EBSCO Publishing's general index, Magazine Article Summaries (MAS), are those most often subscribed to by school and public libraries in the United States based on data from EBSCO.\n\nSubscription Services. Table 7 provides historical data for about 35 titles in the index. Price increases for next year are expected to be in the range of five percent.\n\n$\n\\begin{tabular}{|lccccccccccc|}\n \n\\multicolumn{12}{|c|}{TABLE 7: COST HISTORY FOR TITLES IN MAGAZINE ARTICLE SUMMARIES} \\\\  \nMagazine Article Summaries & Average No. of Titles '95-'99 & Average Cost Per Title 1995 & Average Cost Per Title 1996 & \\% of Change '95-'96 & Average Cost Per Title 1997 & \\% of Change '96-'97 & Average Cost Per Title 1998 & \\% of Change '97-'98 & Average Cost Per Title 1999 & \\% of Change '98-'99 & '95-'99 \\% of Change \\\\  \nU.S. & 334 & \\$42.03 & \\$44.07 & 4.9 & \\$46.14 & 4.7 & \\$48.02 & 4.1 & \\$50.32 & 4.8 & 19.7 \\\\  \nNON-U.S. & 10 & 100.02 & 107.94 & 7.9 & 112.41 & 4.1 & 123.15 & 9.6 & 129.48 & 5.1 & 29.5 \\\\  \n\\end{tabular}\n$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Numeric",
        "evidence_source": "equation",
        "evidence_context": "NON-U.S.&1,749&59.4&1,863,324&70.3&8.5&2,021,707&69.7&",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/00e2c609b4339c40455281ce1793c5e2158dd90d163ff4d64bc0795b715b6393.pdf_4",
        "ID": "082aba19-4bc7-4aee-ae11-af49775c20e9",
        "questions": "What is the overall percentage change in cost for non-U.S. magazine article summaries titles from 1995 to 1999 displayed in the cost history table?",
        "answers": "29.5",
        "context": "tions are that the publishers are having moderate success with the first model, less with the second.\n\n$\n \\begin{tabular}{|lcccccccc|}  \\multicolumn{9}{|c|}{TABLE 6: 2000 COST PROJECTIONS BY BROAD SUBJECT}\\\\   Citation Index&No. of Titles&\\% of List&1999 Cost&\\% of Cost&Projected \\% of increase&Projected 2000 Cost&\\% of Cost&Projected Overall \\% increase\\  \\multicolumn{9}{|l|}{ARTS\\&HUMANITIES}\\\\   U.S.&701&49.9&\\$90,889&35.5&9&\\$99,047&35.7&\\multirow{2}{*}{8.4}\\\\NON-U.S.&703&50.1&168,327&64.5&8&178,553&64.3&\\ \\multicolumn{9}{|l|}{SOCIAL SCIENCE}\\ US.&1,369&51.8&\\$400,921&32.9&11&\\$445,0222&33.3&\\multirow{2}{*}{9.7}\\\\NON-US.&1,272&48.2&818,099&67.1&9&891,728&66.7&\\multirow{2}{*}{...\\text{--}.--}.\\ \\multicolumn{9}{|l|}{SCIENCE}\\ U.S.&1,196&40.6&\\$787,959&29.7&11.5&\\$878,574&30.3&\\multirow{2}{*}{9.4}\\\\NON-U.S.&1,749&59.4&1,863,324&70.3&8.5&2,021,707&69.7&\\ \\multicolumn{9}{|c|}{PROJECTED OVERALL INCREASE FOR ALL ISI TITLES: 9.4\\%}\\  \\end{tabular}\n$\n\n# Acquiring the critical mass  \n\nPublisher buyouts are another response to market uncertainty and are big news in the serials market. Despite a merger between Kluwer and Reed-Elsevier being called off in the face of growing attention from antitrust agencies on both sides of the Atlantic, smaller, quieter mergers have proceeded toward the same end unnoticed. Large commercial publishers are steadily absorbing smaller publishers whose journals can round out their offerings and help them achieve brand identity, or critical mass, in specialty areas. In 1998 alone, Kluwer acquired Waverly/Williams Wilkins, Plenum, and Ovid Technologies; Taylor & Francis acquired Routledge and Carfax; Harcourt/Academic Press acquired Mosby; Bertelsmann, a large entertainment conglomerate, acquired Springer Verlag; and Elsevier Science acquired six publishers, including JAI Press, BioMedNet, and Beilstein. Smaller publishers undoubtedly see these mergers as opportunities to get their titles into the electronic mainstream. For library customers, this trend represents a loss of competition, which does not bode well for prices.  \n\n# Librarians creating mass, too  \n\nIn response, libraries, universities, and learned societies are beginning to experiment with creating critical mass of their own to challenge commercial publishers and drive prices down. Two such experiments are drawing attention. SPARC, the Scholarly Publishing and Academic Resources Coalition founded by the Association of Research Libraries, uses funds pledged by its members to subsidize and support publishers whose e-journals can go head-to-head with very costly commercial journals but at lower subscription rates. SPARC has successfully launched electronic journals from two well-known chemical societies and a group of distinguished ecologists. (For more on SPARC, see Ken Frazier's \"Liberating Scholarship,\" LJ 10/15/98, p. 40-41. -Ed.)\n\nHighWire Press was begun by Stanford University Library in 1997 to assist society publishers in getting their journals online. With more than 100 titles now among its offerings and with growing markets in the United States and abroad, HighWire is challenging the assumption that full-featured web journals have to come from commercial STM publishers. These library-driven strategies, like the ones of the commercial publishers, are fueled by hopes of shaping future markets in their favor.\n\n# A global economy  \n\nPublishers and vendors have taken a hit from the economic crises in Asia and in Latin America. Reacting to the threat of significant cancellations in many Asian countries and in Brazil, some publishers attempted to protect their subscription base in these countries by extending credit directly to customers and/or to their agents to keep them from canceling titles. Other publishers decided to accept the cancellations and reduce their exposure to losses from bad credit. In the midst of the dilemma are agents, whose profits have also been affected by libraries that could not pay.  \n\nOn the positive side, the advent of the long-awaited Euro should have a stabilizing effect on periodical pricing, particularly for libraries in European countries, in that costs should become more transparent with fewer cross-border currency exchanges. Given the diversity among nations in the European Union relative to unemployment, inflation, and economic strength, experts split on the question of whether the dollar or the Euro will emerge as the favored currency in 1999. Either way, prices for serials sold across the Atlantic will be affected, just as they have in the past.  \n\n# Cost trends  \n\nDespite the chaos surrounding electronic journals, print subscriptions still command most of the serials dollars in libraries and, therefore, still require.\n\n# Periodical Prices for Public and School Libraries  \n\nTitles in EBSCO Publishing's general index, Magazine Article Summaries (MAS), are those most often subscribed to by school and public libraries in the United States based on data from EBSCO.\n\nSubscription Services. Table 7 provides historical data for about 35 titles in the index. Price increases for next year are expected to be in the range of five percent.\n\n$\n\\begin{tabular}{|lccccccccccc|}\n \n\\multicolumn{12}{|c|}{TABLE 7: COST HISTORY FOR TITLES IN MAGAZINE ARTICLE SUMMARIES} \\\\  \nMagazine Article Summaries & Average No. of Titles '95-'99 & Average Cost Per Title 1995 & Average Cost Per Title 1996 & \\% of Change '95-'96 & Average Cost Per Title 1997 & \\% of Change '96-'97 & Average Cost Per Title 1998 & \\% of Change '97-'98 & Average Cost Per Title 1999 & \\% of Change '98-'99 & '95-'99 \\% of Change \\\\  \nU.S. & 334 & \\$42.03 & \\$44.07 & 4.9 & \\$46.14 & 4.7 & \\$48.02 & 4.1 & \\$50.32 & 4.8 & 19.7 \\\\  \nNON-U.S. & 10 & 100.02 & 107.94 & 7.9 & 112.41 & 4.1 & 123.15 & 9.6 & 129.48 & 5.1 & 29.5 \\\\  \n\\end{tabular}\n$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Numeric",
        "evidence_source": "equation",
        "evidence_context": "NON-U.S. & 10 & 100.02 & 107.94 & 7.9 & 112.41 & 4.1 & 123.15 & 9.6 & 129.48 & 5.1 & 29.5",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/med-41731.pdf_31",
        "ID": "08359e8a-9268-4b5e-a8ad-335586e35301",
        "questions": "What is the rate range for an accelerated idioventricular rhythm in organized ventricular rhythms?",
        "answers": "40-100 BPM",
        "context": "![](images/94fa9a0cf014c2314e3dfaa7084a2b74fa1beda473b6e8dff7fade404fa2c2d6.jpg)  \nFigure 1.5.26 Organized Ventricular Rhythms  \n\nRate determines the name for an organized ventricular rhythm. Ventricular rhythms can be distinguished by their QRS complex length of ${\\tt>}0.12$ seconds and their absence of P waves.  \n\nVentricular escape rhythm: ${<}40$ BPM  \n\nAccelerated idioventricular rhythm: 40-100 BPM  \n\nVentricular tachycardia: $\\mathord{>}100$ BPM  \n\nA ventricular escape rhythm typically occurs when both the SA and AV nodes have failed, so there is no transfer of electricity from the atria to the ventricles; this forces the ventricles to take over as pacemaker. In a ventricular escape rhythm, the rate is typically 20-40 BPM, there are no $\\mathrm{P}$ waves, and the QRS complexes are wide and bizarre:  \n\n![](images/763ef6e7337254b7d605a6cba8819103c5124c6ef271bff78a0b5a3ddcc72784.jpg)  \nFigure 1.5.27: Image 27, Ventricular Escape Rhythms  \n\nIn an accelerated ventricular rhythm, the irritable ventricular site that has taken over as pacemaker is contracting at a rate ${>}40$, but is not a true ventricular tachycardia. The physiology of this rhythm is similar, but is accelerated due to increased irritability of the pacemaker site:  \n\n![](images/19890dd4942b3928381de14f8eec1fccd57fabd99deb7fe0b1b568a547f48b74.jpg)  \nFigure 1.5.28: Image 28, Accelerated Ventricular Rhythms  \n\nVentricular tachycardia is essentially the ventricular version of atrial flutter. With ventricular tachycardia, the irritable ventricular site has taken over as pacemaker by depolarizing rapidly. Ventricular tachycardia is not always an indicator that the SA and AV nodes have failed, as is usually the case with ventricular escape and accelerated ventricular rhythms; instead, the ventricle has taken over as pacemaker by depolarizing at a rate faster than the SA node.  \n\n![](images/c60335027545d8e7513999f2f9a5f73568f47ea5a0ef6357b320105ad62a2597.jpg)  \nFigure 1.5.29: Image 29, Ventricular Tachycardia  \n\nVentricular tachycardia is sometimes pulseless, but not always. If you see or suspect ventricular tachycardia, it is important to check a pulse before intervening.  \n\nA patient can also have \u201cruns\u201d of ventricular tachycardia. A run of ventricular tachycardia refers to a rhythm that converts from the underlying rhythm to ventricular tachycardia for ${>}4$ QRS complexes, then reverts to the underlying rhythm. The reversion is important; it is not a \u201crun\u201d of ventricular tachycardia if it never converts back out of ventricular tachycardia.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Accelerated idioventricular rhythm: 40-100 BPM",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/med-41731.pdf_31",
        "ID": "083851f3-d845-4428-af7a-08bc65b57e18",
        "questions": "What is the physiological difference between ventricular escape rhythm and ventricular tachycardia?",
        "answers": "Ventricular tachycardia is not always an indicator that the SA and AV nodes have failed, as is usually the case with ventricular escape rhythms; instead, the ventricle has taken over as pacemaker by depolarizing at a rate faster than the SA node.",
        "context": "![](images/94fa9a0cf014c2314e3dfaa7084a2b74fa1beda473b6e8dff7fade404fa2c2d6.jpg)  \nFigure 1.5.26 Organized Ventricular Rhythms  \n\nRate determines the name for an organized ventricular rhythm. Ventricular rhythms can be distinguished by their QRS complex length of ${\\tt>}0.12$ seconds and their absence of P waves.  \n\nVentricular escape rhythm: ${<}40$ BPM  \n\nAccelerated idioventricular rhythm: 40-100 BPM  \n\nVentricular tachycardia: $\\mathord{>}100$ BPM  \n\nA ventricular escape rhythm typically occurs when both the SA and AV nodes have failed, so there is no transfer of electricity from the atria to the ventricles; this forces the ventricles to take over as pacemaker. In a ventricular escape rhythm, the rate is typically 20-40 BPM, there are no $\\mathrm{P}$ waves, and the QRS complexes are wide and bizarre:  \n\n![](images/763ef6e7337254b7d605a6cba8819103c5124c6ef271bff78a0b5a3ddcc72784.jpg)  \nFigure 1.5.27: Image 27, Ventricular Escape Rhythms  \n\nIn an accelerated ventricular rhythm, the irritable ventricular site that has taken over as pacemaker is contracting at a rate ${>}40$, but is not a true ventricular tachycardia. The physiology of this rhythm is similar, but is accelerated due to increased irritability of the pacemaker site:  \n\n![](images/19890dd4942b3928381de14f8eec1fccd57fabd99deb7fe0b1b568a547f48b74.jpg)  \nFigure 1.5.28: Image 28, Accelerated Ventricular Rhythms  \n\nVentricular tachycardia is essentially the ventricular version of atrial flutter. With ventricular tachycardia, the irritable ventricular site has taken over as pacemaker by depolarizing rapidly. Ventricular tachycardia is not always an indicator that the SA and AV nodes have failed, as is usually the case with ventricular escape and accelerated ventricular rhythms; instead, the ventricle has taken over as pacemaker by depolarizing at a rate faster than the SA node.  \n\n![](images/c60335027545d8e7513999f2f9a5f73568f47ea5a0ef6357b320105ad62a2597.jpg)  \nFigure 1.5.29: Image 29, Ventricular Tachycardia  \n\nVentricular tachycardia is sometimes pulseless, but not always. If you see or suspect ventricular tachycardia, it is important to check a pulse before intervening.  \n\nA patient can also have \u201cruns\u201d of ventricular tachycardia. A run of ventricular tachycardia refers to a rhythm that converts from the underlying rhythm to ventricular tachycardia for ${>}4$ QRS complexes, then reverts to the underlying rhythm. The reversion is important; it is not a \u201crun\u201d of ventricular tachycardia if it never converts back out of ventricular tachycardia.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Ventricular tachycardia is not always an indicator that the SA and AV nodes have failed, as is usually the case with ventricular escape and accelerated ventricular rhythms; instead, the ventricle has taken over as pacemaker by depolarizing at a rate faster than the SA node.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/med-41731.pdf_31",
        "ID": "083d5ca3-616a-47da-b05d-8006f3c380d8",
        "questions": "Does a ventricular escape rhythm require the failure of both the SA and AV nodes for its occurrence?",
        "answers": "Yes",
        "context": "![](images/94fa9a0cf014c2314e3dfaa7084a2b74fa1beda473b6e8dff7fade404fa2c2d6.jpg)  \nFigure 1.5.26 Organized Ventricular Rhythms  \n\nRate determines the name for an organized ventricular rhythm. Ventricular rhythms can be distinguished by their QRS complex length of ${\\tt>}0.12$ seconds and their absence of P waves.  \n\nVentricular escape rhythm: ${<}40$ BPM  \n\nAccelerated idioventricular rhythm: 40-100 BPM  \n\nVentricular tachycardia: $\\mathord{>}100$ BPM  \n\nA ventricular escape rhythm typically occurs when both the SA and AV nodes have failed, so there is no transfer of electricity from the atria to the ventricles; this forces the ventricles to take over as pacemaker. In a ventricular escape rhythm, the rate is typically 20-40 BPM, there are no $\\mathrm{P}$ waves, and the QRS complexes are wide and bizarre:  \n\n![](images/763ef6e7337254b7d605a6cba8819103c5124c6ef271bff78a0b5a3ddcc72784.jpg)  \nFigure 1.5.27: Image 27, Ventricular Escape Rhythms  \n\nIn an accelerated ventricular rhythm, the irritable ventricular site that has taken over as pacemaker is contracting at a rate ${>}40$, but is not a true ventricular tachycardia. The physiology of this rhythm is similar, but is accelerated due to increased irritability of the pacemaker site:  \n\n![](images/19890dd4942b3928381de14f8eec1fccd57fabd99deb7fe0b1b568a547f48b74.jpg)  \nFigure 1.5.28: Image 28, Accelerated Ventricular Rhythms  \n\nVentricular tachycardia is essentially the ventricular version of atrial flutter. With ventricular tachycardia, the irritable ventricular site has taken over as pacemaker by depolarizing rapidly. Ventricular tachycardia is not always an indicator that the SA and AV nodes have failed, as is usually the case with ventricular escape and accelerated ventricular rhythms; instead, the ventricle has taken over as pacemaker by depolarizing at a rate faster than the SA node.  \n\n![](images/c60335027545d8e7513999f2f9a5f73568f47ea5a0ef6357b320105ad62a2597.jpg)  \nFigure 1.5.29: Image 29, Ventricular Tachycardia  \n\nVentricular tachycardia is sometimes pulseless, but not always. If you see or suspect ventricular tachycardia, it is important to check a pulse before intervening.  \n\nA patient can also have \u201cruns\u201d of ventricular tachycardia. A run of ventricular tachycardia refers to a rhythm that converts from the underlying rhythm to ventricular tachycardia for ${>}4$ QRS complexes, then reverts to the underlying rhythm. The reversion is important; it is not a \u201crun\u201d of ventricular tachycardia if it never converts back out of ventricular tachycardia.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Yes/No",
        "evidence_source": "text",
        "evidence_context": "A ventricular escape rhythm typically occurs when both the SA and AV nodes have failed, so there is no transfer of electricity from the atria to the ventricles; this forces the ventricles to take over as pacemaker.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/ch13.pdf_29",
        "ID": "08439ba1-2afd-45c3-a748-4ffbbfd9de84",
        "questions": "What was the weekly pay for participants in the Union Summer program, which was sponsored by the AFL-CIO?",
        "answers": "$210",
        "context": "While picketing is a mode of communication, it is inseparably something more and different. The very purpose of a picket line is to exert influence, and it produces consequences, different from other modes of communication. \u2014\u2014Justice Felix Frankfurter, 1950  \n\nBusiness. Many people will not cross a picket line, depriving a business of its workers and customers.  \n\nThrough much of American history, courts have supported many kinds of restraints on labor picketing. Then, in Thornhill v. Alabama1 (1940), the Supreme Court ruled that peaceful picketing was a form of free speech. It reflected the growing strength of the labor movement in American life.  \n\nIn later decisions, however, the Court severely limited the position it took in Thornhill. In Hughes v. Superior Court2 (1950), the Court refused to overturn a California court's ban on picketing at a supermarket to force it to hire African American workers. The Court wrote: This and other protestors demonstrated during the August 1997 Teamsters-UPS labor dispute which crippled the nation for 15 days.  \n\n![](images/3b9d2ff8779c046001a9b5f4ac0013d1f6b996d25d78ff8ca79c7932cc4f9185.jpg)\n\nSee the following footnoted materials in the Reference Handbook: 1. Thornhill v. Alabama case summary, page 766. 2. Hughes v. Superior Court case summary, page 759.\n\nIn 1996, Gladiola Campos joined 1,000 other college students and activists in a program called Union Summer. The program, which was sponsored by the AFL-CIO, was designed to strengthen the nation's labor movement by encouraging people to join unions and protest unfair labor practices. It was modeled after Freedom Summer, a similar program in 1964 in which students were bussed across the South to register African American voters. Union Summer participants were paid \\$210 a week and traveled to various parts of the country to help draw attention to unfair labor practices. Students helped sewage-plant employees protesting in Denver, put pressure on a Washington store to stop selling clothing made in sweatshops, and picketed hotels in South Carolina for their unfair labor practices.\n\nCampos, a University of Texas student, was sent to Los Angeles. One of her projects was distributing leaflets outside a hotel to urge people to boycott the establishment. The owners of the hotel had been blocking their employees' efforts to organize a union for three years. Many of the employees were Hispanic immigrants.\n\nThe union issue hits close to home with Campos. Her mother was a maintenance worker when she was growing up in El Paso, Texas. Before the hospital where her mother worked was unionized, Campos said her mother \"had to work two jobs, and we couldn't afford health insurance.\" Campos thinks her summer experience was worthwhile. \"I'm finally doing something instead of just talking,\" she said.\n\n![](images/b99781d4c7515463d5d7d3c26dd2d57fa4e7eda5944bb439b6bfb8e7988ca811.jpg)  \nWe the People Making a Difference Gladiola Campos -- Union Summer logo",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Numeric",
        "evidence_source": "text",
        "evidence_context": "Union Summer participants were paid $210 a week and traveled to various parts of the country to help draw attention to unfair labor practices.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/ch13.pdf_29",
        "ID": "084993fb-3fb1-408e-a5e2-f858789dba64",
        "questions": "Which 1940 Supreme Court case ruled that peaceful picketing was a form of free speech, reflecting the growing strength of the labor movement in American life?",
        "answers": "Thornhill v. Alabama",
        "context": "While picketing is a mode of communication, it is inseparably something more and different. The very purpose of a picket line is to exert influence, and it produces consequences, different from other modes of communication. \u2014\u2014Justice Felix Frankfurter, 1950  \n\nBusiness. Many people will not cross a picket line, depriving a business of its workers and customers.  \n\nThrough much of American history, courts have supported many kinds of restraints on labor picketing. Then, in Thornhill v. Alabama1 (1940), the Supreme Court ruled that peaceful picketing was a form of free speech. It reflected the growing strength of the labor movement in American life.  \n\nIn later decisions, however, the Court severely limited the position it took in Thornhill. In Hughes v. Superior Court2 (1950), the Court refused to overturn a California court's ban on picketing at a supermarket to force it to hire African American workers. The Court wrote: This and other protestors demonstrated during the August 1997 Teamsters-UPS labor dispute which crippled the nation for 15 days.  \n\n![](images/3b9d2ff8779c046001a9b5f4ac0013d1f6b996d25d78ff8ca79c7932cc4f9185.jpg)\n\nSee the following footnoted materials in the Reference Handbook: 1. Thornhill v. Alabama case summary, page 766. 2. Hughes v. Superior Court case summary, page 759.\n\nIn 1996, Gladiola Campos joined 1,000 other college students and activists in a program called Union Summer. The program, which was sponsored by the AFL-CIO, was designed to strengthen the nation's labor movement by encouraging people to join unions and protest unfair labor practices. It was modeled after Freedom Summer, a similar program in 1964 in which students were bussed across the South to register African American voters. Union Summer participants were paid \\$210 a week and traveled to various parts of the country to help draw attention to unfair labor practices. Students helped sewage-plant employees protesting in Denver, put pressure on a Washington store to stop selling clothing made in sweatshops, and picketed hotels in South Carolina for their unfair labor practices.\n\nCampos, a University of Texas student, was sent to Los Angeles. One of her projects was distributing leaflets outside a hotel to urge people to boycott the establishment. The owners of the hotel had been blocking their employees' efforts to organize a union for three years. Many of the employees were Hispanic immigrants.\n\nThe union issue hits close to home with Campos. Her mother was a maintenance worker when she was growing up in El Paso, Texas. Before the hospital where her mother worked was unionized, Campos said her mother \"had to work two jobs, and we couldn't afford health insurance.\" Campos thinks her summer experience was worthwhile. \"I'm finally doing something instead of just talking,\" she said.\n\n![](images/b99781d4c7515463d5d7d3c26dd2d57fa4e7eda5944bb439b6bfb8e7988ca811.jpg)  \nWe the People Making a Difference Gladiola Campos -- Union Summer logo",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Then, in Thornhill v. Alabama (1940), the Supreme Court ruled that peaceful picketing was a form of free speech. It reflected the growing strength of the labor movement in American life.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/ch13.pdf_29",
        "ID": "084e0003-5046-4dca-8b7d-71e98eb00e64",
        "questions": "In which case did the Court refuse to overturn a California court's ban on picketing at a supermarket to force it to hire African American workers, demonstrating the limitations placed on the Thornhill decision?",
        "answers": "Hughes v. Superior Court",
        "context": "While picketing is a mode of communication, it is inseparably something more and different. The very purpose of a picket line is to exert influence, and it produces consequences, different from other modes of communication. \u2014\u2014Justice Felix Frankfurter, 1950  \n\nBusiness. Many people will not cross a picket line, depriving a business of its workers and customers.  \n\nThrough much of American history, courts have supported many kinds of restraints on labor picketing. Then, in Thornhill v. Alabama1 (1940), the Supreme Court ruled that peaceful picketing was a form of free speech. It reflected the growing strength of the labor movement in American life.  \n\nIn later decisions, however, the Court severely limited the position it took in Thornhill. In Hughes v. Superior Court2 (1950), the Court refused to overturn a California court's ban on picketing at a supermarket to force it to hire African American workers. The Court wrote: This and other protestors demonstrated during the August 1997 Teamsters-UPS labor dispute which crippled the nation for 15 days.  \n\n![](images/3b9d2ff8779c046001a9b5f4ac0013d1f6b996d25d78ff8ca79c7932cc4f9185.jpg)\n\nSee the following footnoted materials in the Reference Handbook: 1. Thornhill v. Alabama case summary, page 766. 2. Hughes v. Superior Court case summary, page 759.\n\nIn 1996, Gladiola Campos joined 1,000 other college students and activists in a program called Union Summer. The program, which was sponsored by the AFL-CIO, was designed to strengthen the nation's labor movement by encouraging people to join unions and protest unfair labor practices. It was modeled after Freedom Summer, a similar program in 1964 in which students were bussed across the South to register African American voters. Union Summer participants were paid \\$210 a week and traveled to various parts of the country to help draw attention to unfair labor practices. Students helped sewage-plant employees protesting in Denver, put pressure on a Washington store to stop selling clothing made in sweatshops, and picketed hotels in South Carolina for their unfair labor practices.\n\nCampos, a University of Texas student, was sent to Los Angeles. One of her projects was distributing leaflets outside a hotel to urge people to boycott the establishment. The owners of the hotel had been blocking their employees' efforts to organize a union for three years. Many of the employees were Hispanic immigrants.\n\nThe union issue hits close to home with Campos. Her mother was a maintenance worker when she was growing up in El Paso, Texas. Before the hospital where her mother worked was unionized, Campos said her mother \"had to work two jobs, and we couldn't afford health insurance.\" Campos thinks her summer experience was worthwhile. \"I'm finally doing something instead of just talking,\" she said.\n\n![](images/b99781d4c7515463d5d7d3c26dd2d57fa4e7eda5944bb439b6bfb8e7988ca811.jpg)  \nWe the People Making a Difference Gladiola Campos -- Union Summer logo",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "In Hughes v. Superior Court (1950), the Court refused to overturn a California court's ban on picketing at a supermarket to force it to hire African American workers.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/socialsci-181231.pdf_473",
        "ID": "084edeb0-e53a-4fe5-846a-87592dbca078",
        "questions": "What does the abbreviation DAX stand for in the stock market context?",
        "answers": "Deutscher Aktienindex",
        "context": "\\begin{table}[ht]\n\\centering\n\\caption{Measures of the Stock Market}\n\\begin{tabular}{|>{\\columncolor[gray]{0.9}}m{0.4\\textwidth}|>{\\columncolor[gray]{0.9}}m{0.55\\textwidth}|}\n \nMeasure of the Stock Market & Comments \\\\[1.5em]\n \nNASDAQ: \\url{http://www.nasdaq.com} & Founded in 1971 as an electronic stock market, allowing people to buy or sell from many physical locations. It includes about 3,600 companies. \\\\[1.5em]\n \nFTSE: \\url{http://www.ftse.com} & Includes the 100 largest companies on the London Stock Exchange. Pronounced \"footsie.\" Originally stood for Financial Times Stock Exchange. \\\\[1.5em]\n \nNikkei: \\url{http://www.nikkei.co.jp/nukkeinfoen} & Nikkei stands for \\emph{Nihon Keizai Shimbun}, which translates as the Japan Economic Journal, a major business newspaper in Japan. The index includes the 225 largest and most actively traded stocks on the Tokyo Stock Exchange. \\\\[1.5em]\n \nDAX: \\url{http://www.exchange.de} & Tracks 30 of the largest companies on the Frankfurt, Germany, stock exchange. DAX is an abbreviation for \\emph{Deutscher Aktienindex} (German Stock Index). \\\\[1.5em]\n \n\\end{tabular}\n\\end{table}\n\n\nTable 17.1 Some Stock Market Measures  \n\nThe trend in the stock market is generally up over time, but with some large dips along the way. Figure 17.6 shows the path of the Standard & Poor's 500 index (which is measured on the left-hand vertical axis) and the Dow Jones Index (which is measured on the right-hand vertical axis). Broad stock market measures, like the ones we list here, tend to move together. The S&P 500 Index is the weighted average market capitalization of the firms selected to be in the index. The Dow Jones Industrial Average is the price weighted average of 30 industrial stocks tracked on the New York Stock Exchange.  \n\nWhen the Dow Jones average rises from 5,000 to 10,000, you know that the average price of the stocks in that index has roughly doubled. Figure 17.6 shows that stock prices did not rise much in the 1970s, but then started a steady climb in the 1980s. From 2000 to 2013, stock prices bounced up and down, but ended up at about the same level.  \n\n![](images/a862eeb76d1a76970b94ffad79e9b46da8ebf1f26e4fc6f73b3d5174bad379b6.jpg)  \n\nFigure 17.6 The Dow Jones Industrial Index and the Standard & Poor's 500, 1965-2021. Stock prices rose dramatically from the 1980s up to about 2000. From 2000 to 2013, stock prices bounced up and down, but ended up at about the same level. Since 2009, both indexes have for the most part increased.  \n\nTable 17.2 shows the total annual rate of return an investor would have received from buying the stocks in the S&P 500 index over recent decades. The total return here includes both dividends paid by these companies and also capital gains arising from increases.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "DAX is an abbreviation for \\emph{Deutscher Aktienindex} (German Stock Index).",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/socialsci-181231.pdf_473",
        "ID": "085d7943-eb63-47ef-9540-654de644d4f4",
        "questions": "How many companies are included in the NASDAQ stock market index?",
        "answers": "about 3,600 companies",
        "context": "\\begin{table}[ht]\n\\centering\n\\caption{Measures of the Stock Market}\n\\begin{tabular}{|>{\\columncolor[gray]{0.9}}m{0.4\\textwidth}|>{\\columncolor[gray]{0.9}}m{0.55\\textwidth}|}\n \nMeasure of the Stock Market & Comments \\\\[1.5em]\n \nNASDAQ: \\url{http://www.nasdaq.com} & Founded in 1971 as an electronic stock market, allowing people to buy or sell from many physical locations. It includes about 3,600 companies. \\\\[1.5em]\n \nFTSE: \\url{http://www.ftse.com} & Includes the 100 largest companies on the London Stock Exchange. Pronounced \"footsie.\" Originally stood for Financial Times Stock Exchange. \\\\[1.5em]\n \nNikkei: \\url{http://www.nikkei.co.jp/nukkeinfoen} & Nikkei stands for \\emph{Nihon Keizai Shimbun}, which translates as the Japan Economic Journal, a major business newspaper in Japan. The index includes the 225 largest and most actively traded stocks on the Tokyo Stock Exchange. \\\\[1.5em]\n \nDAX: \\url{http://www.exchange.de} & Tracks 30 of the largest companies on the Frankfurt, Germany, stock exchange. DAX is an abbreviation for \\emph{Deutscher Aktienindex} (German Stock Index). \\\\[1.5em]\n \n\\end{tabular}\n\\end{table}\n\n\nTable 17.1 Some Stock Market Measures  \n\nThe trend in the stock market is generally up over time, but with some large dips along the way. Figure 17.6 shows the path of the Standard & Poor's 500 index (which is measured on the left-hand vertical axis) and the Dow Jones Index (which is measured on the right-hand vertical axis). Broad stock market measures, like the ones we list here, tend to move together. The S&P 500 Index is the weighted average market capitalization of the firms selected to be in the index. The Dow Jones Industrial Average is the price weighted average of 30 industrial stocks tracked on the New York Stock Exchange.  \n\nWhen the Dow Jones average rises from 5,000 to 10,000, you know that the average price of the stocks in that index has roughly doubled. Figure 17.6 shows that stock prices did not rise much in the 1970s, but then started a steady climb in the 1980s. From 2000 to 2013, stock prices bounced up and down, but ended up at about the same level.  \n\n![](images/a862eeb76d1a76970b94ffad79e9b46da8ebf1f26e4fc6f73b3d5174bad379b6.jpg)  \n\nFigure 17.6 The Dow Jones Industrial Index and the Standard & Poor's 500, 1965-2021. Stock prices rose dramatically from the 1980s up to about 2000. From 2000 to 2013, stock prices bounced up and down, but ended up at about the same level. Since 2009, both indexes have for the most part increased.  \n\nTable 17.2 shows the total annual rate of return an investor would have received from buying the stocks in the S&P 500 index over recent decades. The total return here includes both dividends paid by these companies and also capital gains arising from increases.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Numeric",
        "evidence_source": "text",
        "evidence_context": "It includes about 3,600 companies.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/socialsci-181231.pdf_473",
        "ID": "0870e15c-2fcd-41b5-924b-ace4307bf326",
        "questions": "What is the name of the document that the Nikkei index, which includes the 225 largest and most actively traded stocks on the Tokyo Stock Exchange, originates from?",
        "answers": "Nihon Keizai Shimbun",
        "context": "\\begin{table}[ht]\n\\centering\n\\caption{Measures of the Stock Market}\n\\begin{tabular}{|>{\\columncolor[gray]{0.9}}m{0.4\\textwidth}|>{\\columncolor[gray]{0.9}}m{0.55\\textwidth}|}\n \nMeasure of the Stock Market & Comments \\\\[1.5em]\n \nNASDAQ: \\url{http://www.nasdaq.com} & Founded in 1971 as an electronic stock market, allowing people to buy or sell from many physical locations. It includes about 3,600 companies. \\\\[1.5em]\n \nFTSE: \\url{http://www.ftse.com} & Includes the 100 largest companies on the London Stock Exchange. Pronounced \"footsie.\" Originally stood for Financial Times Stock Exchange. \\\\[1.5em]\n \nNikkei: \\url{http://www.nikkei.co.jp/nukkeinfoen} & Nikkei stands for \\emph{Nihon Keizai Shimbun}, which translates as the Japan Economic Journal, a major business newspaper in Japan. The index includes the 225 largest and most actively traded stocks on the Tokyo Stock Exchange. \\\\[1.5em]\n \nDAX: \\url{http://www.exchange.de} & Tracks 30 of the largest companies on the Frankfurt, Germany, stock exchange. DAX is an abbreviation for \\emph{Deutscher Aktienindex} (German Stock Index). \\\\[1.5em]\n \n\\end{tabular}\n\\end{table}\n\n\nTable 17.1 Some Stock Market Measures  \n\nThe trend in the stock market is generally up over time, but with some large dips along the way. Figure 17.6 shows the path of the Standard & Poor's 500 index (which is measured on the left-hand vertical axis) and the Dow Jones Index (which is measured on the right-hand vertical axis). Broad stock market measures, like the ones we list here, tend to move together. The S&P 500 Index is the weighted average market capitalization of the firms selected to be in the index. The Dow Jones Industrial Average is the price weighted average of 30 industrial stocks tracked on the New York Stock Exchange.  \n\nWhen the Dow Jones average rises from 5,000 to 10,000, you know that the average price of the stocks in that index has roughly doubled. Figure 17.6 shows that stock prices did not rise much in the 1970s, but then started a steady climb in the 1980s. From 2000 to 2013, stock prices bounced up and down, but ended up at about the same level.  \n\n![](images/a862eeb76d1a76970b94ffad79e9b46da8ebf1f26e4fc6f73b3d5174bad379b6.jpg)  \n\nFigure 17.6 The Dow Jones Industrial Index and the Standard & Poor's 500, 1965-2021. Stock prices rose dramatically from the 1980s up to about 2000. From 2000 to 2013, stock prices bounced up and down, but ended up at about the same level. Since 2009, both indexes have for the most part increased.  \n\nTable 17.2 shows the total annual rate of return an investor would have received from buying the stocks in the S&P 500 index over recent decades. The total return here includes both dividends paid by these companies and also capital gains arising from increases.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Nikkei stands for \\emph{Nihon Keizai Shimbun}, which translates as the Japan Economic Journal, a major business newspaper in Japan. The index includes the 225 largest and most actively traded stocks on the Tokyo Stock Exchange.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM_229_-_ISBN978-0-387-22215-8_-_David_Eisenbud_-_The_Geometry_of_Syzygies_-_A_Second_Course_in_Commutative_Algebra_and_Algebraic_Geometry.pdf_37",
        "ID": "0876daaa-01ce-4fc6-b2d1-16fe8f08963c",
        "questions": "What is the depth of the ring $S_{X}$ given that it is reduced and of dimension 1?",
        "answers": "1",
        "context": "Two linear forms that generate the ideal of the line, together with any form of degree 7 vanishing on the points but not on the line. But Theorem 4.2(c) tells us that since the 7 points of $X$ are in linearly general position, the Castelnuovo-Mumford regularity of $S_{X}$ (defined in Chapter 4) is 2, or equivalently, that the Betti diagram of $S_{X}$ fits into 3 rows. Moreover, the ring $S_{X}$ is reduced and of dimension 1, so it has depth 1. The Auslander-Buchsbaum Formula A2.15 shows that the resolution will have length 3. Putting this together, and using Corollary 1.9, we see that the minimal free resolution of $S_{X}$ must have a Betti diagram of the form  \n\n$$\n\\begin{array}{c c c c}{{}}&{{}}&{{\\begin{array}{c c c c}{{}}&{{0}}&{{1}}&{{2}}&{{3}}\\\\ {{0}}&{{1}}&{{-}}&{{-}}&{{-}}\\\\ {{1}}&{{-}}&{{\\beta_{1,2}}}&{{\\beta_{2,3}}}&{{\\beta_{3,4}}}\\\\ {{2}}&{{-}}&{{\\beta_{1,3}}}&{{\\beta_{2,4}}}&{{\\beta_{3,5}}}\\end{array}}}\\end{array}\n$$  \n\nwhere the $\\beta_{i,j}$ that are not shown are zero. In particular, the ideal of $X$ is generated by quadrics and cubics.  \n\nUsing Corollary 1.10, we compute successively $\\beta_{1,2}=3$, $\\beta_{1,3}-\\beta_{2,3}=1$, $\\beta_{2,4}-\\beta_{3,4}=6$, $\\beta_{3,5}=3$, and the Betti diagram has the form  \n\n$$\n\\begin{array}{c c c c}{{}}&{{}}&{{\\begin{array}{c c c c}{{}}&{{0}}&{{1}}&{{2}}&{{3}}\\\\ {{0}}&{{1}}&{{-}}&{{-}}&{{-}}\\\\ {{1}}&{{-}}&{{3}}&{{\\beta_{2,3}}}&{{\\beta_{3,4}}}\\\\ {{2}}&{{-}}&{{1+\\beta_{2,3}}}&{{6+\\beta_{3,4}}}&{{3}}\\end{array}}}\\end{array}\n$$  \n\n(This is the same diagram as at the end of the previous section. Here is the connection: Extending the ground field if necessary to make it infinite, we could use Lemma A2.3 and choose a linear form $x\\in S$ that is a nonzero divisor on $S_{X}$. By Lemma 3.15, the graded Betti numbers of $S_{X}/x S_{X}$ as an $S/x S$ -module are the same as those of $S_{X}$ as an $S$ -module. Using our knowledge of the Hilbert function of $S_{X}$ and the exactness of the sequence  \n\n$$\n0\\longrightarrow S_{X}(-1)\\stackrel{x}{\\longrightarrow}S_{X}\\longrightarrow S_{X}/x S_{x}\\longrightarrow0,\n$$  \n\nwe see that the cyclic $(S/x S)$ -module $S_{X}/x S_{x}$ has a Hilbert function with values $1, 3, 3$. This is what we used in Section 2B.)  \n\n# ..and Other Information in the Resolution  \n\nWe see that even in this simple case, the Hilbert function does not determine the $\\beta_{i,j}$, and indeed they can take different values. It turns out that the difference reflects a fundamental geometric distinction between different sets $X$ of 7 points in linearly general position in $\\mathbb{P^{3}}$: whether or not $X$ lies on a curve of degree 3.  \n\nUp to linear automorphisms of $\\mathbb{P}^{3}$, there is only one irreducible curve of degree 3 not contained in a plane. This twisted cubic is one of the rational normal curves studied in Chapter 6. Any 6 points in linearly general position in $\\mathbb{P}^{3}$ lie",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Numeric",
        "evidence_source": "text",
        "evidence_context": "Moreover, the ring $S_{X}$ is reduced and of dimension 1, so it has depth 1.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM_229_-_ISBN978-0-387-22215-8_-_David_Eisenbud_-_The_Geometry_of_Syzygies_-_A_Second_Course_in_Commutative_Algebra_and_Algebraic_Geometry.pdf_37",
        "ID": "087d9b9c-202c-440d-bbfe-de43b337ed27",
        "questions": "According to the document, what length will the resolution have as shown by the Auslander-Buchsbaum Formula A2.15?",
        "answers": "length 3",
        "context": "Two linear forms that generate the ideal of the line, together with any form of degree 7 vanishing on the points but not on the line. But Theorem 4.2(c) tells us that since the 7 points of $X$ are in linearly general position, the Castelnuovo-Mumford regularity of $S_{X}$ (defined in Chapter 4) is 2, or equivalently, that the Betti diagram of $S_{X}$ fits into 3 rows. Moreover, the ring $S_{X}$ is reduced and of dimension 1, so it has depth 1. The Auslander-Buchsbaum Formula A2.15 shows that the resolution will have length 3. Putting this together, and using Corollary 1.9, we see that the minimal free resolution of $S_{X}$ must have a Betti diagram of the form  \n\n$$\n\\begin{array}{c c c c}{{}}&{{}}&{{\\begin{array}{c c c c}{{}}&{{0}}&{{1}}&{{2}}&{{3}}\\\\ {{0}}&{{1}}&{{-}}&{{-}}&{{-}}\\\\ {{1}}&{{-}}&{{\\beta_{1,2}}}&{{\\beta_{2,3}}}&{{\\beta_{3,4}}}\\\\ {{2}}&{{-}}&{{\\beta_{1,3}}}&{{\\beta_{2,4}}}&{{\\beta_{3,5}}}\\end{array}}}\\end{array}\n$$  \n\nwhere the $\\beta_{i,j}$ that are not shown are zero. In particular, the ideal of $X$ is generated by quadrics and cubics.  \n\nUsing Corollary 1.10, we compute successively $\\beta_{1,2}=3$, $\\beta_{1,3}-\\beta_{2,3}=1$, $\\beta_{2,4}-\\beta_{3,4}=6$, $\\beta_{3,5}=3$, and the Betti diagram has the form  \n\n$$\n\\begin{array}{c c c c}{{}}&{{}}&{{\\begin{array}{c c c c}{{}}&{{0}}&{{1}}&{{2}}&{{3}}\\\\ {{0}}&{{1}}&{{-}}&{{-}}&{{-}}\\\\ {{1}}&{{-}}&{{3}}&{{\\beta_{2,3}}}&{{\\beta_{3,4}}}\\\\ {{2}}&{{-}}&{{1+\\beta_{2,3}}}&{{6+\\beta_{3,4}}}&{{3}}\\end{array}}}\\end{array}\n$$  \n\n(This is the same diagram as at the end of the previous section. Here is the connection: Extending the ground field if necessary to make it infinite, we could use Lemma A2.3 and choose a linear form $x\\in S$ that is a nonzero divisor on $S_{X}$. By Lemma 3.15, the graded Betti numbers of $S_{X}/x S_{X}$ as an $S/x S$ -module are the same as those of $S_{X}$ as an $S$ -module. Using our knowledge of the Hilbert function of $S_{X}$ and the exactness of the sequence  \n\n$$\n0\\longrightarrow S_{X}(-1)\\stackrel{x}{\\longrightarrow}S_{X}\\longrightarrow S_{X}/x S_{x}\\longrightarrow0,\n$$  \n\nwe see that the cyclic $(S/x S)$ -module $S_{X}/x S_{x}$ has a Hilbert function with values $1, 3, 3$. This is what we used in Section 2B.)  \n\n# ..and Other Information in the Resolution  \n\nWe see that even in this simple case, the Hilbert function does not determine the $\\beta_{i,j}$, and indeed they can take different values. It turns out that the difference reflects a fundamental geometric distinction between different sets $X$ of 7 points in linearly general position in $\\mathbb{P^{3}}$: whether or not $X$ lies on a curve of degree 3.  \n\nUp to linear automorphisms of $\\mathbb{P}^{3}$, there is only one irreducible curve of degree 3 not contained in a plane. This twisted cubic is one of the rational normal curves studied in Chapter 6. Any 6 points in linearly general position in $\\mathbb{P}^{3}$ lie",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "The Auslander-Buchsbaum Formula A2.15 shows that the resolution will have length 3.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM_229_-_ISBN978-0-387-22215-8_-_David_Eisenbud_-_The_Geometry_of_Syzygies_-_A_Second_Course_in_Commutative_Algebra_and_Algebraic_Geometry.pdf_37",
        "ID": "0884fd16-636a-4f8c-a7e3-f52c0cbf404d",
        "questions": "What are the computed values of $\beta_{1,2}$ and $\beta_{3,5}$ according to Corollary 1.10?",
        "answers": "3, 3",
        "context": "Two linear forms that generate the ideal of the line, together with any form of degree 7 vanishing on the points but not on the line. But Theorem 4.2(c) tells us that since the 7 points of $X$ are in linearly general position, the Castelnuovo-Mumford regularity of $S_{X}$ (defined in Chapter 4) is 2, or equivalently, that the Betti diagram of $S_{X}$ fits into 3 rows. Moreover, the ring $S_{X}$ is reduced and of dimension 1, so it has depth 1. The Auslander-Buchsbaum Formula A2.15 shows that the resolution will have length 3. Putting this together, and using Corollary 1.9, we see that the minimal free resolution of $S_{X}$ must have a Betti diagram of the form  \n\n$$\n\\begin{array}{c c c c}{{}}&{{}}&{{\\begin{array}{c c c c}{{}}&{{0}}&{{1}}&{{2}}&{{3}}\\\\ {{0}}&{{1}}&{{-}}&{{-}}&{{-}}\\\\ {{1}}&{{-}}&{{\\beta_{1,2}}}&{{\\beta_{2,3}}}&{{\\beta_{3,4}}}\\\\ {{2}}&{{-}}&{{\\beta_{1,3}}}&{{\\beta_{2,4}}}&{{\\beta_{3,5}}}\\end{array}}}\\end{array}\n$$  \n\nwhere the $\\beta_{i,j}$ that are not shown are zero. In particular, the ideal of $X$ is generated by quadrics and cubics.  \n\nUsing Corollary 1.10, we compute successively $\\beta_{1,2}=3$, $\\beta_{1,3}-\\beta_{2,3}=1$, $\\beta_{2,4}-\\beta_{3,4}=6$, $\\beta_{3,5}=3$, and the Betti diagram has the form  \n\n$$\n\\begin{array}{c c c c}{{}}&{{}}&{{\\begin{array}{c c c c}{{}}&{{0}}&{{1}}&{{2}}&{{3}}\\\\ {{0}}&{{1}}&{{-}}&{{-}}&{{-}}\\\\ {{1}}&{{-}}&{{3}}&{{\\beta_{2,3}}}&{{\\beta_{3,4}}}\\\\ {{2}}&{{-}}&{{1+\\beta_{2,3}}}&{{6+\\beta_{3,4}}}&{{3}}\\end{array}}}\\end{array}\n$$  \n\n(This is the same diagram as at the end of the previous section. Here is the connection: Extending the ground field if necessary to make it infinite, we could use Lemma A2.3 and choose a linear form $x\\in S$ that is a nonzero divisor on $S_{X}$. By Lemma 3.15, the graded Betti numbers of $S_{X}/x S_{X}$ as an $S/x S$ -module are the same as those of $S_{X}$ as an $S$ -module. Using our knowledge of the Hilbert function of $S_{X}$ and the exactness of the sequence  \n\n$$\n0\\longrightarrow S_{X}(-1)\\stackrel{x}{\\longrightarrow}S_{X}\\longrightarrow S_{X}/x S_{x}\\longrightarrow0,\n$$  \n\nwe see that the cyclic $(S/x S)$ -module $S_{X}/x S_{x}$ has a Hilbert function with values $1, 3, 3$. This is what we used in Section 2B.)  \n\n# ..and Other Information in the Resolution  \n\nWe see that even in this simple case, the Hilbert function does not determine the $\\beta_{i,j}$, and indeed they can take different values. It turns out that the difference reflects a fundamental geometric distinction between different sets $X$ of 7 points in linearly general position in $\\mathbb{P^{3}}$: whether or not $X$ lies on a curve of degree 3.  \n\nUp to linear automorphisms of $\\mathbb{P}^{3}$, there is only one irreducible curve of degree 3 not contained in a plane. This twisted cubic is one of the rational normal curves studied in Chapter 6. Any 6 points in linearly general position in $\\mathbb{P}^{3}$ lie",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Using Corollary 1.10, we compute successively $\beta_{1,2}=3$, $\beta_{1,3}-\beta_{2,3}=1$, $\beta_{2,4}-\beta_{3,4}=6$, $\beta_{3,5}=3$...",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM_229_-_ISBN978-0-387-22215-8_-_David_Eisenbud_-_The_Geometry_of_Syzygies_-_A_Second_Course_in_Commutative_Algebra_and_Algebraic_Geometry.pdf_37",
        "ID": "088808b9-fc23-48aa-9df1-ec81bc54eab3",
        "questions": "What is the value of $\beta_{1,2}$ as computed using Corollary 1.10 for the Betti diagram of $S_X$?",
        "answers": "3",
        "context": "Two linear forms that generate the ideal of the line, together with any form of degree 7 vanishing on the points but not on the line. But Theorem 4.2(c) tells us that since the 7 points of $X$ are in linearly general position, the Castelnuovo-Mumford regularity of $S_{X}$ (defined in Chapter 4) is 2, or equivalently, that the Betti diagram of $S_{X}$ fits into 3 rows. Moreover, the ring $S_{X}$ is reduced and of dimension 1, so it has depth 1. The Auslander-Buchsbaum Formula A2.15 shows that the resolution will have length 3. Putting this together, and using Corollary 1.9, we see that the minimal free resolution of $S_{X}$ must have a Betti diagram of the form  \n\n$$\n\\begin{array}{c c c c}{{}}&{{}}&{{\\begin{array}{c c c c}{{}}&{{0}}&{{1}}&{{2}}&{{3}}\\\\ {{0}}&{{1}}&{{-}}&{{-}}&{{-}}\\\\ {{1}}&{{-}}&{{\\beta_{1,2}}}&{{\\beta_{2,3}}}&{{\\beta_{3,4}}}\\\\ {{2}}&{{-}}&{{\\beta_{1,3}}}&{{\\beta_{2,4}}}&{{\\beta_{3,5}}}\\end{array}}}\\end{array}\n$$  \n\nwhere the $\\beta_{i,j}$ that are not shown are zero. In particular, the ideal of $X$ is generated by quadrics and cubics.  \n\nUsing Corollary 1.10, we compute successively $\\beta_{1,2}=3$, $\\beta_{1,3}-\\beta_{2,3}=1$, $\\beta_{2,4}-\\beta_{3,4}=6$, $\\beta_{3,5}=3$, and the Betti diagram has the form  \n\n$$\n\\begin{array}{c c c c}{{}}&{{}}&{{\\begin{array}{c c c c}{{}}&{{0}}&{{1}}&{{2}}&{{3}}\\\\ {{0}}&{{1}}&{{-}}&{{-}}&{{-}}\\\\ {{1}}&{{-}}&{{3}}&{{\\beta_{2,3}}}&{{\\beta_{3,4}}}\\\\ {{2}}&{{-}}&{{1+\\beta_{2,3}}}&{{6+\\beta_{3,4}}}&{{3}}\\end{array}}}\\end{array}\n$$  \n\n(This is the same diagram as at the end of the previous section. Here is the connection: Extending the ground field if necessary to make it infinite, we could use Lemma A2.3 and choose a linear form $x\\in S$ that is a nonzero divisor on $S_{X}$. By Lemma 3.15, the graded Betti numbers of $S_{X}/x S_{X}$ as an $S/x S$ -module are the same as those of $S_{X}$ as an $S$ -module. Using our knowledge of the Hilbert function of $S_{X}$ and the exactness of the sequence  \n\n$$\n0\\longrightarrow S_{X}(-1)\\stackrel{x}{\\longrightarrow}S_{X}\\longrightarrow S_{X}/x S_{x}\\longrightarrow0,\n$$  \n\nwe see that the cyclic $(S/x S)$ -module $S_{X}/x S_{x}$ has a Hilbert function with values $1, 3, 3$. This is what we used in Section 2B.)  \n\n# ..and Other Information in the Resolution  \n\nWe see that even in this simple case, the Hilbert function does not determine the $\\beta_{i,j}$, and indeed they can take different values. It turns out that the difference reflects a fundamental geometric distinction between different sets $X$ of 7 points in linearly general position in $\\mathbb{P^{3}}$: whether or not $X$ lies on a curve of degree 3.  \n\nUp to linear automorphisms of $\\mathbb{P}^{3}$, there is only one irreducible curve of degree 3 not contained in a plane. This twisted cubic is one of the rational normal curves studied in Chapter 6. Any 6 points in linearly general position in $\\mathbb{P}^{3}$ lie",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Numeric",
        "evidence_source": "equation",
        "evidence_context": "$\\beta_{1,2}=3$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/GTM_229_-_ISBN978-0-387-22215-8_-_David_Eisenbud_-_The_Geometry_of_Syzygies_-_A_Second_Course_in_Commutative_Algebra_and_Algebraic_Geometry.pdf_37",
        "ID": "088affd2-f3f8-46ad-985c-7b8c67b340cf",
        "questions": "What is the formula involving $\beta_{1,3}$ and $\beta_{2,3}$ derived in the computation using Corollary 1.10?",
        "answers": "$\\beta_{1,3}-\\beta_{2,3}=1$",
        "context": "Two linear forms that generate the ideal of the line, together with any form of degree 7 vanishing on the points but not on the line. But Theorem 4.2(c) tells us that since the 7 points of $X$ are in linearly general position, the Castelnuovo-Mumford regularity of $S_{X}$ (defined in Chapter 4) is 2, or equivalently, that the Betti diagram of $S_{X}$ fits into 3 rows. Moreover, the ring $S_{X}$ is reduced and of dimension 1, so it has depth 1. The Auslander-Buchsbaum Formula A2.15 shows that the resolution will have length 3. Putting this together, and using Corollary 1.9, we see that the minimal free resolution of $S_{X}$ must have a Betti diagram of the form  \n\n$$\n\\begin{array}{c c c c}{{}}&{{}}&{{\\begin{array}{c c c c}{{}}&{{0}}&{{1}}&{{2}}&{{3}}\\\\ {{0}}&{{1}}&{{-}}&{{-}}&{{-}}\\\\ {{1}}&{{-}}&{{\\beta_{1,2}}}&{{\\beta_{2,3}}}&{{\\beta_{3,4}}}\\\\ {{2}}&{{-}}&{{\\beta_{1,3}}}&{{\\beta_{2,4}}}&{{\\beta_{3,5}}}\\end{array}}}\\end{array}\n$$  \n\nwhere the $\\beta_{i,j}$ that are not shown are zero. In particular, the ideal of $X$ is generated by quadrics and cubics.  \n\nUsing Corollary 1.10, we compute successively $\\beta_{1,2}=3$, $\\beta_{1,3}-\\beta_{2,3}=1$, $\\beta_{2,4}-\\beta_{3,4}=6$, $\\beta_{3,5}=3$, and the Betti diagram has the form  \n\n$$\n\\begin{array}{c c c c}{{}}&{{}}&{{\\begin{array}{c c c c}{{}}&{{0}}&{{1}}&{{2}}&{{3}}\\\\ {{0}}&{{1}}&{{-}}&{{-}}&{{-}}\\\\ {{1}}&{{-}}&{{3}}&{{\\beta_{2,3}}}&{{\\beta_{3,4}}}\\\\ {{2}}&{{-}}&{{1+\\beta_{2,3}}}&{{6+\\beta_{3,4}}}&{{3}}\\end{array}}}\\end{array}\n$$  \n\n(This is the same diagram as at the end of the previous section. Here is the connection: Extending the ground field if necessary to make it infinite, we could use Lemma A2.3 and choose a linear form $x\\in S$ that is a nonzero divisor on $S_{X}$. By Lemma 3.15, the graded Betti numbers of $S_{X}/x S_{X}$ as an $S/x S$ -module are the same as those of $S_{X}$ as an $S$ -module. Using our knowledge of the Hilbert function of $S_{X}$ and the exactness of the sequence  \n\n$$\n0\\longrightarrow S_{X}(-1)\\stackrel{x}{\\longrightarrow}S_{X}\\longrightarrow S_{X}/x S_{x}\\longrightarrow0,\n$$  \n\nwe see that the cyclic $(S/x S)$ -module $S_{X}/x S_{x}$ has a Hilbert function with values $1, 3, 3$. This is what we used in Section 2B.)  \n\n# ..and Other Information in the Resolution  \n\nWe see that even in this simple case, the Hilbert function does not determine the $\\beta_{i,j}$, and indeed they can take different values. It turns out that the difference reflects a fundamental geometric distinction between different sets $X$ of 7 points in linearly general position in $\\mathbb{P^{3}}$: whether or not $X$ lies on a curve of degree 3.  \n\nUp to linear automorphisms of $\\mathbb{P}^{3}$, there is only one irreducible curve of degree 3 not contained in a plane. This twisted cubic is one of the rational normal curves studied in Chapter 6. Any 6 points in linearly general position in $\\mathbb{P}^{3}$ lie",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$\\beta_{1,3}-\\beta_{2,3}=1$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/GTM_229_-_ISBN978-0-387-22215-8_-_David_Eisenbud_-_The_Geometry_of_Syzygies_-_A_Second_Course_in_Commutative_Algebra_and_Algebraic_Geometry.pdf_37",
        "ID": "08900b58-d75d-4659-a079-45e39329393d",
        "questions": "Determine the difference between $\beta_{2,4}$ and $\beta_{3,4}$ as per the derived Betti diagram for $S_X$.",
        "answers": "6",
        "context": "Two linear forms that generate the ideal of the line, together with any form of degree 7 vanishing on the points but not on the line. But Theorem 4.2(c) tells us that since the 7 points of $X$ are in linearly general position, the Castelnuovo-Mumford regularity of $S_{X}$ (defined in Chapter 4) is 2, or equivalently, that the Betti diagram of $S_{X}$ fits into 3 rows. Moreover, the ring $S_{X}$ is reduced and of dimension 1, so it has depth 1. The Auslander-Buchsbaum Formula A2.15 shows that the resolution will have length 3. Putting this together, and using Corollary 1.9, we see that the minimal free resolution of $S_{X}$ must have a Betti diagram of the form  \n\n$$\n\\begin{array}{c c c c}{{}}&{{}}&{{\\begin{array}{c c c c}{{}}&{{0}}&{{1}}&{{2}}&{{3}}\\\\ {{0}}&{{1}}&{{-}}&{{-}}&{{-}}\\\\ {{1}}&{{-}}&{{\\beta_{1,2}}}&{{\\beta_{2,3}}}&{{\\beta_{3,4}}}\\\\ {{2}}&{{-}}&{{\\beta_{1,3}}}&{{\\beta_{2,4}}}&{{\\beta_{3,5}}}\\end{array}}}\\end{array}\n$$  \n\nwhere the $\\beta_{i,j}$ that are not shown are zero. In particular, the ideal of $X$ is generated by quadrics and cubics.  \n\nUsing Corollary 1.10, we compute successively $\\beta_{1,2}=3$, $\\beta_{1,3}-\\beta_{2,3}=1$, $\\beta_{2,4}-\\beta_{3,4}=6$, $\\beta_{3,5}=3$, and the Betti diagram has the form  \n\n$$\n\\begin{array}{c c c c}{{}}&{{}}&{{\\begin{array}{c c c c}{{}}&{{0}}&{{1}}&{{2}}&{{3}}\\\\ {{0}}&{{1}}&{{-}}&{{-}}&{{-}}\\\\ {{1}}&{{-}}&{{3}}&{{\\beta_{2,3}}}&{{\\beta_{3,4}}}\\\\ {{2}}&{{-}}&{{1+\\beta_{2,3}}}&{{6+\\beta_{3,4}}}&{{3}}\\end{array}}}\\end{array}\n$$  \n\n(This is the same diagram as at the end of the previous section. Here is the connection: Extending the ground field if necessary to make it infinite, we could use Lemma A2.3 and choose a linear form $x\\in S$ that is a nonzero divisor on $S_{X}$. By Lemma 3.15, the graded Betti numbers of $S_{X}/x S_{X}$ as an $S/x S$ -module are the same as those of $S_{X}$ as an $S$ -module. Using our knowledge of the Hilbert function of $S_{X}$ and the exactness of the sequence  \n\n$$\n0\\longrightarrow S_{X}(-1)\\stackrel{x}{\\longrightarrow}S_{X}\\longrightarrow S_{X}/x S_{x}\\longrightarrow0,\n$$  \n\nwe see that the cyclic $(S/x S)$ -module $S_{X}/x S_{x}$ has a Hilbert function with values $1, 3, 3$. This is what we used in Section 2B.)  \n\n# ..and Other Information in the Resolution  \n\nWe see that even in this simple case, the Hilbert function does not determine the $\\beta_{i,j}$, and indeed they can take different values. It turns out that the difference reflects a fundamental geometric distinction between different sets $X$ of 7 points in linearly general position in $\\mathbb{P^{3}}$: whether or not $X$ lies on a curve of degree 3.  \n\nUp to linear automorphisms of $\\mathbb{P}^{3}$, there is only one irreducible curve of degree 3 not contained in a plane. This twisted cubic is one of the rational normal curves studied in Chapter 6. Any 6 points in linearly general position in $\\mathbb{P}^{3}$ lie",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Numeric",
        "evidence_source": "equation",
        "evidence_context": "$\\beta_{2,4}-\\beta_{3,4}=6$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/UTX_-_Spectral_and_Scattering_Theory_for_Ordinary_Differential_Equations.pdf_206",
        "ID": "0895e48e-6e22-438d-afb5-fe36642d0f77",
        "questions": "What function is bounded on (a,x) by a function integrable with weight w?",
        "answers": "sqrt(|lambda|)|m(t,lambda)|",
        "context": "where  $M_{s}=\\{t\\in(a,d):P_{w}(t)>s>0\\}$  . Now  \n\\[\n\\int_a^d \\sqrt{P_w} w = \\int_a^d \\left( \\int_0^{\\sqrt{P_w}} ds \\right) w = \\int_0^\\infty \\int_{M_{s_2}}^1 \\int_0^1 w ds = \\left( \\int_0^1 + \\int_1^\\infty \\right) \\int_{M_{s_2}} w ds\n\\]\n\n\\[\n\\leq \\int_a^d w + \\int_a^d \\frac{1}{|p|} w \\int_1^\\infty \\frac{3}{s^2} ds = \\int_a^d w + 3 \\int_a^d \\frac{1}{|p|}\n\\]\n\n\\[\n< \\infty.\n\\]\n\nIt follows that  $\\sqrt{|\\lambda|}\\,\\left|m(t,\\lambda)\\right|$  is bounded on  $(a,x)$  by a function in te grable with weight  $w$  . The theorem now follows, under the restriction of the size of gaps of supp  $w$  assumed, by dominated convergence from the point wise result of Theorem 6.3.1.  \n\nTo complete the proof we must remove this restriction. We have just proved that the theorem is true for  $x$  up to and including the left endpoint  $d$  in the first gap. Violating the restriction, for  $x$  in this gap we have  \n\n$$\n\\psi(x,\\lambda)=\\psi(d,\\lambda)u(x)+p\\psi^{\\prime}(d,\\lambda)v(x)\\;,\n$$  \n\nwhere  $u$  and  $v$  are solutions of  $-(p u^{\\prime})^{\\prime}+q u\\,=\\,0$  with appropriate  $\\mathcal{A}$  -independent initial data in  $d$  . Since  $m(d,\\cdot)$  is a non-trivial Nevanlinna function, it follows that  $p\\psi^{\\prime}(x,\\lambda)/p\\psi^{\\prime}(d,\\lambda)\\,=\\,\\exp\\{O(\\log|\\lambda|)\\}$  , so the theorem holds up to and including the right endpoint of the gap and therefore up to and including the first point in the next large gap (if any). Since the support of  $w$  can only have a finite number of such large gaps in any compact interval, this completes the proof. \u53e3  \n\n# Exercises  \n\nExercise 6.4.1 Give a result analogous to Theorem 6.4.4 but for the kernel of  $u\\mapsto$   $p(R\\boldsymbol{\\lrcorner}\\boldsymbol{u})^{\\prime}$  . Also prove corresponding results for the left-definite case.  \n\nExercise 6.4.2 Prove that the radius of the circle defined by  $\\|\\theta(\\cdot,\\lambda)+m\\varphi(\\cdot,\\lambda)\\|_{x}^{2}\\leq$   $\\operatorname{Im}m/\\operatorname{Im}\\lambda$  in both the right- and left-definite cases is given by  $(2\\,|\\mathrm{Im}\\,\\lambda|\\,\\|\\varphi\\|_{x}^{2})^{-1}$  . Hint: The inequality  $\\|\\psi\\|_{x}^{2}\\,\\leq\\,\\mathrm{Im}\\,m/\\mathrm{Im}\\,\\lambda$  may be rewritten as  $\\left|m-c\\right|^{2}\\leq r^{2}$  , where  $r^{2}=A(2\\operatorname{Im}\\lambda\\|\\varphi\\|_{x}^{2})^{-2}$  and  \n\n$$\nA=|2\\mathrm{i}\\,\\mathrm{Im}\\,\\lambda\\langle\\theta,\\varphi\\rangle_{x}+1|^{2}+2\\mathrm{i}\\,\\mathrm{Im}\\,\\lambda\\|\\theta\\|_{x}^{2}\\,2\\mathrm{i}\\,\\mathrm{Im}\\,\\lambda\\|\\varphi\\|_{x}^{2}\\ .\n$$  \n\nUse the differential equation and integration by parts to write  $\\lambda\\langle\\theta,\\varphi\\rangle_{x}$  as an integrated term plus  $\\overline{{\\lambda}}\\langle\\theta,\\varphi\\rangle_{x}$  . Similarly for  $\\lambda||\\theta||_{x}^{2}$  and  $\\lambda\\|\\varphi\\|_{x}^{2}.$  Now rearrange the resulting terms to show that  $A=\\left|\\mathcal{W}_{p}(\\varphi,\\theta)\\right|^{2}=1$  \n\nExercise 6.4.3 Prove Theorem 6.4.1 in the left-definite case.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "It follows that sqrt(|lambda|)|m(t,lambda)| is bounded on (a,x) by a function in te grable with weight w.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTX_-_Spectral_and_Scattering_Theory_for_Ordinary_Differential_Equations.pdf_206",
        "ID": "089b30a0-809f-4923-87a1-798fe6addd9e",
        "questions": "What is the inequality rewritten as involving r, m, and A when proving the radius of a circle related to theta and lambda?",
        "answers": "left|m-c right^2 leq r^2",
        "context": "where  $M_{s}=\\{t\\in(a,d):P_{w}(t)>s>0\\}$  . Now  \n\\[\n\\int_a^d \\sqrt{P_w} w = \\int_a^d \\left( \\int_0^{\\sqrt{P_w}} ds \\right) w = \\int_0^\\infty \\int_{M_{s_2}}^1 \\int_0^1 w ds = \\left( \\int_0^1 + \\int_1^\\infty \\right) \\int_{M_{s_2}} w ds\n\\]\n\n\\[\n\\leq \\int_a^d w + \\int_a^d \\frac{1}{|p|} w \\int_1^\\infty \\frac{3}{s^2} ds = \\int_a^d w + 3 \\int_a^d \\frac{1}{|p|}\n\\]\n\n\\[\n< \\infty.\n\\]\n\nIt follows that  $\\sqrt{|\\lambda|}\\,\\left|m(t,\\lambda)\\right|$  is bounded on  $(a,x)$  by a function in te grable with weight  $w$  . The theorem now follows, under the restriction of the size of gaps of supp  $w$  assumed, by dominated convergence from the point wise result of Theorem 6.3.1.  \n\nTo complete the proof we must remove this restriction. We have just proved that the theorem is true for  $x$  up to and including the left endpoint  $d$  in the first gap. Violating the restriction, for  $x$  in this gap we have  \n\n$$\n\\psi(x,\\lambda)=\\psi(d,\\lambda)u(x)+p\\psi^{\\prime}(d,\\lambda)v(x)\\;,\n$$  \n\nwhere  $u$  and  $v$  are solutions of  $-(p u^{\\prime})^{\\prime}+q u\\,=\\,0$  with appropriate  $\\mathcal{A}$  -independent initial data in  $d$  . Since  $m(d,\\cdot)$  is a non-trivial Nevanlinna function, it follows that  $p\\psi^{\\prime}(x,\\lambda)/p\\psi^{\\prime}(d,\\lambda)\\,=\\,\\exp\\{O(\\log|\\lambda|)\\}$  , so the theorem holds up to and including the right endpoint of the gap and therefore up to and including the first point in the next large gap (if any). Since the support of  $w$  can only have a finite number of such large gaps in any compact interval, this completes the proof. \u53e3  \n\n# Exercises  \n\nExercise 6.4.1 Give a result analogous to Theorem 6.4.4 but for the kernel of  $u\\mapsto$   $p(R\\boldsymbol{\\lrcorner}\\boldsymbol{u})^{\\prime}$  . Also prove corresponding results for the left-definite case.  \n\nExercise 6.4.2 Prove that the radius of the circle defined by  $\\|\\theta(\\cdot,\\lambda)+m\\varphi(\\cdot,\\lambda)\\|_{x}^{2}\\leq$   $\\operatorname{Im}m/\\operatorname{Im}\\lambda$  in both the right- and left-definite cases is given by  $(2\\,|\\mathrm{Im}\\,\\lambda|\\,\\|\\varphi\\|_{x}^{2})^{-1}$  . Hint: The inequality  $\\|\\psi\\|_{x}^{2}\\,\\leq\\,\\mathrm{Im}\\,m/\\mathrm{Im}\\,\\lambda$  may be rewritten as  $\\left|m-c\\right|^{2}\\leq r^{2}$  , where  $r^{2}=A(2\\operatorname{Im}\\lambda\\|\\varphi\\|_{x}^{2})^{-2}$  and  \n\n$$\nA=|2\\mathrm{i}\\,\\mathrm{Im}\\,\\lambda\\langle\\theta,\\varphi\\rangle_{x}+1|^{2}+2\\mathrm{i}\\,\\mathrm{Im}\\,\\lambda\\|\\theta\\|_{x}^{2}\\,2\\mathrm{i}\\,\\mathrm{Im}\\,\\lambda\\|\\varphi\\|_{x}^{2}\\ .\n$$  \n\nUse the differential equation and integration by parts to write  $\\lambda\\langle\\theta,\\varphi\\rangle_{x}$  as an integrated term plus  $\\overline{{\\lambda}}\\langle\\theta,\\varphi\\rangle_{x}$  . Similarly for  $\\lambda||\\theta||_{x}^{2}$  and  $\\lambda\\|\\varphi\\|_{x}^{2}.$  Now rearrange the resulting terms to show that  $A=\\left|\\mathcal{W}_{p}(\\varphi,\\theta)\\right|^{2}=1$  \n\nExercise 6.4.3 Prove Theorem 6.4.1 in the left-definite case.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "The inequality ||psi||_x^2 leq Im m/Im lambda may be rewritten as left|m-c right^2 leq r^2, where r^2=A(2 operatorname{Im}lambda ||varphi||_x^2)^{-2}.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTX_-_Spectral_and_Scattering_Theory_for_Ordinary_Differential_Equations.pdf_206",
        "ID": "089f059c-f6e6-4035-b612-12fe40dac72e",
        "questions": "What must be shown to prove that the radius of the circle involving theta, lambda, and Im lambda is A=(2i Im lambdau03bblangleu03c6,u03c6 angle_{x}+1)^{2}+2ilambda Im lambda||theta||_{x}^{2}.?",
        "answers": "A=|2iIMlambdaangletheta,varphiangle_x+1|^2+2imIMlambda||theta||^2IMlambda||varphi||^2=1",
        "context": "where  $M_{s}=\\{t\\in(a,d):P_{w}(t)>s>0\\}$  . Now  \n\\[\n\\int_a^d \\sqrt{P_w} w = \\int_a^d \\left( \\int_0^{\\sqrt{P_w}} ds \\right) w = \\int_0^\\infty \\int_{M_{s_2}}^1 \\int_0^1 w ds = \\left( \\int_0^1 + \\int_1^\\infty \\right) \\int_{M_{s_2}} w ds\n\\]\n\n\\[\n\\leq \\int_a^d w + \\int_a^d \\frac{1}{|p|} w \\int_1^\\infty \\frac{3}{s^2} ds = \\int_a^d w + 3 \\int_a^d \\frac{1}{|p|}\n\\]\n\n\\[\n< \\infty.\n\\]\n\nIt follows that  $\\sqrt{|\\lambda|}\\,\\left|m(t,\\lambda)\\right|$  is bounded on  $(a,x)$  by a function in te grable with weight  $w$  . The theorem now follows, under the restriction of the size of gaps of supp  $w$  assumed, by dominated convergence from the point wise result of Theorem 6.3.1.  \n\nTo complete the proof we must remove this restriction. We have just proved that the theorem is true for  $x$  up to and including the left endpoint  $d$  in the first gap. Violating the restriction, for  $x$  in this gap we have  \n\n$$\n\\psi(x,\\lambda)=\\psi(d,\\lambda)u(x)+p\\psi^{\\prime}(d,\\lambda)v(x)\\;,\n$$  \n\nwhere  $u$  and  $v$  are solutions of  $-(p u^{\\prime})^{\\prime}+q u\\,=\\,0$  with appropriate  $\\mathcal{A}$  -independent initial data in  $d$  . Since  $m(d,\\cdot)$  is a non-trivial Nevanlinna function, it follows that  $p\\psi^{\\prime}(x,\\lambda)/p\\psi^{\\prime}(d,\\lambda)\\,=\\,\\exp\\{O(\\log|\\lambda|)\\}$  , so the theorem holds up to and including the right endpoint of the gap and therefore up to and including the first point in the next large gap (if any). Since the support of  $w$  can only have a finite number of such large gaps in any compact interval, this completes the proof. \u53e3  \n\n# Exercises  \n\nExercise 6.4.1 Give a result analogous to Theorem 6.4.4 but for the kernel of  $u\\mapsto$   $p(R\\boldsymbol{\\lrcorner}\\boldsymbol{u})^{\\prime}$  . Also prove corresponding results for the left-definite case.  \n\nExercise 6.4.2 Prove that the radius of the circle defined by  $\\|\\theta(\\cdot,\\lambda)+m\\varphi(\\cdot,\\lambda)\\|_{x}^{2}\\leq$   $\\operatorname{Im}m/\\operatorname{Im}\\lambda$  in both the right- and left-definite cases is given by  $(2\\,|\\mathrm{Im}\\,\\lambda|\\,\\|\\varphi\\|_{x}^{2})^{-1}$  . Hint: The inequality  $\\|\\psi\\|_{x}^{2}\\,\\leq\\,\\mathrm{Im}\\,m/\\mathrm{Im}\\,\\lambda$  may be rewritten as  $\\left|m-c\\right|^{2}\\leq r^{2}$  , where  $r^{2}=A(2\\operatorname{Im}\\lambda\\|\\varphi\\|_{x}^{2})^{-2}$  and  \n\n$$\nA=|2\\mathrm{i}\\,\\mathrm{Im}\\,\\lambda\\langle\\theta,\\varphi\\rangle_{x}+1|^{2}+2\\mathrm{i}\\,\\mathrm{Im}\\,\\lambda\\|\\theta\\|_{x}^{2}\\,2\\mathrm{i}\\,\\mathrm{Im}\\,\\lambda\\|\\varphi\\|_{x}^{2}\\ .\n$$  \n\nUse the differential equation and integration by parts to write  $\\lambda\\langle\\theta,\\varphi\\rangle_{x}$  as an integrated term plus  $\\overline{{\\lambda}}\\langle\\theta,\\varphi\\rangle_{x}$  . Similarly for  $\\lambda||\\theta||_{x}^{2}$  and  $\\lambda\\|\\varphi\\|_{x}^{2}.$  Now rearrange the resulting terms to show that  $A=\\left|\\mathcal{W}_{p}(\\varphi,\\theta)\\right|^{2}=1$  \n\nExercise 6.4.3 Prove Theorem 6.4.1 in the left-definite case.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "rearrange the resulting terms to show that A=|2iIMlambdaangletheta,varphiangle_x+1|^2+2imIMlambda||theta||^2IMlambda||varphi||^2=1",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTX_-_Spectral_and_Scattering_Theory_for_Ordinary_Differential_Equations.pdf_206",
        "ID": "08a30261-b675-4bef-ac60-1ff0b0350134",
        "questions": "What is the value of the double integral \u222b\u2090^\ud835\udc51 w + 3 \u222b\u2090^\ud835\udc51 1/|p| given the first term is finite?",
        "answers": "\u222b\u2090^\ud835\udc51 w + 3 \u222b\u2090^\ud835\udc51 1/|p| < \u221e",
        "context": "where  $M_{s}=\\{t\\in(a,d):P_{w}(t)>s>0\\}$  . Now  \n\\[\n\\int_a^d \\sqrt{P_w} w = \\int_a^d \\left( \\int_0^{\\sqrt{P_w}} ds \\right) w = \\int_0^\\infty \\int_{M_{s_2}}^1 \\int_0^1 w ds = \\left( \\int_0^1 + \\int_1^\\infty \\right) \\int_{M_{s_2}} w ds\n\\]\n\n\\[\n\\leq \\int_a^d w + \\int_a^d \\frac{1}{|p|} w \\int_1^\\infty \\frac{3}{s^2} ds = \\int_a^d w + 3 \\int_a^d \\frac{1}{|p|}\n\\]\n\n\\[\n< \\infty.\n\\]\n\nIt follows that  $\\sqrt{|\\lambda|}\\,\\left|m(t,\\lambda)\\right|$  is bounded on  $(a,x)$  by a function in te grable with weight  $w$  . The theorem now follows, under the restriction of the size of gaps of supp  $w$  assumed, by dominated convergence from the point wise result of Theorem 6.3.1.  \n\nTo complete the proof we must remove this restriction. We have just proved that the theorem is true for  $x$  up to and including the left endpoint  $d$  in the first gap. Violating the restriction, for  $x$  in this gap we have  \n\n$$\n\\psi(x,\\lambda)=\\psi(d,\\lambda)u(x)+p\\psi^{\\prime}(d,\\lambda)v(x)\\;,\n$$  \n\nwhere  $u$  and  $v$  are solutions of  $-(p u^{\\prime})^{\\prime}+q u\\,=\\,0$  with appropriate  $\\mathcal{A}$  -independent initial data in  $d$  . Since  $m(d,\\cdot)$  is a non-trivial Nevanlinna function, it follows that  $p\\psi^{\\prime}(x,\\lambda)/p\\psi^{\\prime}(d,\\lambda)\\,=\\,\\exp\\{O(\\log|\\lambda|)\\}$  , so the theorem holds up to and including the right endpoint of the gap and therefore up to and including the first point in the next large gap (if any). Since the support of  $w$  can only have a finite number of such large gaps in any compact interval, this completes the proof. \u53e3  \n\n# Exercises  \n\nExercise 6.4.1 Give a result analogous to Theorem 6.4.4 but for the kernel of  $u\\mapsto$   $p(R\\boldsymbol{\\lrcorner}\\boldsymbol{u})^{\\prime}$  . Also prove corresponding results for the left-definite case.  \n\nExercise 6.4.2 Prove that the radius of the circle defined by  $\\|\\theta(\\cdot,\\lambda)+m\\varphi(\\cdot,\\lambda)\\|_{x}^{2}\\leq$   $\\operatorname{Im}m/\\operatorname{Im}\\lambda$  in both the right- and left-definite cases is given by  $(2\\,|\\mathrm{Im}\\,\\lambda|\\,\\|\\varphi\\|_{x}^{2})^{-1}$  . Hint: The inequality  $\\|\\psi\\|_{x}^{2}\\,\\leq\\,\\mathrm{Im}\\,m/\\mathrm{Im}\\,\\lambda$  may be rewritten as  $\\left|m-c\\right|^{2}\\leq r^{2}$  , where  $r^{2}=A(2\\operatorname{Im}\\lambda\\|\\varphi\\|_{x}^{2})^{-2}$  and  \n\n$$\nA=|2\\mathrm{i}\\,\\mathrm{Im}\\,\\lambda\\langle\\theta,\\varphi\\rangle_{x}+1|^{2}+2\\mathrm{i}\\,\\mathrm{Im}\\,\\lambda\\|\\theta\\|_{x}^{2}\\,2\\mathrm{i}\\,\\mathrm{Im}\\,\\lambda\\|\\varphi\\|_{x}^{2}\\ .\n$$  \n\nUse the differential equation and integration by parts to write  $\\lambda\\langle\\theta,\\varphi\\rangle_{x}$  as an integrated term plus  $\\overline{{\\lambda}}\\langle\\theta,\\varphi\\rangle_{x}$  . Similarly for  $\\lambda||\\theta||_{x}^{2}$  and  $\\lambda\\|\\varphi\\|_{x}^{2}.$  Now rearrange the resulting terms to show that  $A=\\left|\\mathcal{W}_{p}(\\varphi,\\theta)\\right|^{2}=1$  \n\nExercise 6.4.3 Prove Theorem 6.4.1 in the left-definite case.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Numeric",
        "evidence_source": "equation",
        "evidence_context": "\u222b\u2090^\ud835\udc51 w + 3 \u222b\u2090^\ud835\udc51 1/|p|",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/UTX_-_Spectral_and_Scattering_Theory_for_Ordinary_Differential_Equations.pdf_206",
        "ID": "08a3b1e3-64e2-4c6f-bb48-146954fe81bb",
        "questions": "In Exercise 6.4.2, what does A equal when rearranging terms involving \u03b8, \u03d5, and \u03bb?",
        "answers": "A = |2i Im \u03bb\u27e8\u03b8,\u03d5\u27e9\u1d6a + 1|\u00b2 + 2i Im \u03bb ||\u03b8||\u1d6a\u00b2 2i Im \u03bb ||\u03d5||\u1d6a\u00b2",
        "context": "where  $M_{s}=\\{t\\in(a,d):P_{w}(t)>s>0\\}$  . Now  \n\\[\n\\int_a^d \\sqrt{P_w} w = \\int_a^d \\left( \\int_0^{\\sqrt{P_w}} ds \\right) w = \\int_0^\\infty \\int_{M_{s_2}}^1 \\int_0^1 w ds = \\left( \\int_0^1 + \\int_1^\\infty \\right) \\int_{M_{s_2}} w ds\n\\]\n\n\\[\n\\leq \\int_a^d w + \\int_a^d \\frac{1}{|p|} w \\int_1^\\infty \\frac{3}{s^2} ds = \\int_a^d w + 3 \\int_a^d \\frac{1}{|p|}\n\\]\n\n\\[\n< \\infty.\n\\]\n\nIt follows that  $\\sqrt{|\\lambda|}\\,\\left|m(t,\\lambda)\\right|$  is bounded on  $(a,x)$  by a function in te grable with weight  $w$  . The theorem now follows, under the restriction of the size of gaps of supp  $w$  assumed, by dominated convergence from the point wise result of Theorem 6.3.1.  \n\nTo complete the proof we must remove this restriction. We have just proved that the theorem is true for  $x$  up to and including the left endpoint  $d$  in the first gap. Violating the restriction, for  $x$  in this gap we have  \n\n$$\n\\psi(x,\\lambda)=\\psi(d,\\lambda)u(x)+p\\psi^{\\prime}(d,\\lambda)v(x)\\;,\n$$  \n\nwhere  $u$  and  $v$  are solutions of  $-(p u^{\\prime})^{\\prime}+q u\\,=\\,0$  with appropriate  $\\mathcal{A}$  -independent initial data in  $d$  . Since  $m(d,\\cdot)$  is a non-trivial Nevanlinna function, it follows that  $p\\psi^{\\prime}(x,\\lambda)/p\\psi^{\\prime}(d,\\lambda)\\,=\\,\\exp\\{O(\\log|\\lambda|)\\}$  , so the theorem holds up to and including the right endpoint of the gap and therefore up to and including the first point in the next large gap (if any). Since the support of  $w$  can only have a finite number of such large gaps in any compact interval, this completes the proof. \u53e3  \n\n# Exercises  \n\nExercise 6.4.1 Give a result analogous to Theorem 6.4.4 but for the kernel of  $u\\mapsto$   $p(R\\boldsymbol{\\lrcorner}\\boldsymbol{u})^{\\prime}$  . Also prove corresponding results for the left-definite case.  \n\nExercise 6.4.2 Prove that the radius of the circle defined by  $\\|\\theta(\\cdot,\\lambda)+m\\varphi(\\cdot,\\lambda)\\|_{x}^{2}\\leq$   $\\operatorname{Im}m/\\operatorname{Im}\\lambda$  in both the right- and left-definite cases is given by  $(2\\,|\\mathrm{Im}\\,\\lambda|\\,\\|\\varphi\\|_{x}^{2})^{-1}$  . Hint: The inequality  $\\|\\psi\\|_{x}^{2}\\,\\leq\\,\\mathrm{Im}\\,m/\\mathrm{Im}\\,\\lambda$  may be rewritten as  $\\left|m-c\\right|^{2}\\leq r^{2}$  , where  $r^{2}=A(2\\operatorname{Im}\\lambda\\|\\varphi\\|_{x}^{2})^{-2}$  and  \n\n$$\nA=|2\\mathrm{i}\\,\\mathrm{Im}\\,\\lambda\\langle\\theta,\\varphi\\rangle_{x}+1|^{2}+2\\mathrm{i}\\,\\mathrm{Im}\\,\\lambda\\|\\theta\\|_{x}^{2}\\,2\\mathrm{i}\\,\\mathrm{Im}\\,\\lambda\\|\\varphi\\|_{x}^{2}\\ .\n$$  \n\nUse the differential equation and integration by parts to write  $\\lambda\\langle\\theta,\\varphi\\rangle_{x}$  as an integrated term plus  $\\overline{{\\lambda}}\\langle\\theta,\\varphi\\rangle_{x}$  . Similarly for  $\\lambda||\\theta||_{x}^{2}$  and  $\\lambda\\|\\varphi\\|_{x}^{2}.$  Now rearrange the resulting terms to show that  $A=\\left|\\mathcal{W}_{p}(\\varphi,\\theta)\\right|^{2}=1$  \n\nExercise 6.4.3 Prove Theorem 6.4.1 in the left-definite case.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "A = |2i Im \u03bb\u27e8\u03b8,\u03d5\u27e9\u1d6a + 1|\u00b2 + 2i Im \u03bb ||\u03b8||\u1d6a\u00b2 2i Im \u03bb ||\u03d5||\u1d6a\u00b2.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/UTX_-_Spectral_and_Scattering_Theory_for_Ordinary_Differential_Equations.pdf_206",
        "ID": "08b2ace5-f544-412b-8fb5-f417de2c4c68",
        "questions": "According to Exercise 6.4.2, if the radius of a circle is defined by (2 |Im \u03bb| ||\u03d5||\u1d6a\u00b2)\u207b\u00b9, what inequality should you prove to derive this result?",
        "answers": "||\u03b8(\u22c5,\u03bb) + m\u03d5(\u22c5,\u03bb)||\u1d6a\u00b2 \u2264 Im m / Im \u03bb",
        "context": "where  $M_{s}=\\{t\\in(a,d):P_{w}(t)>s>0\\}$  . Now  \n\\[\n\\int_a^d \\sqrt{P_w} w = \\int_a^d \\left( \\int_0^{\\sqrt{P_w}} ds \\right) w = \\int_0^\\infty \\int_{M_{s_2}}^1 \\int_0^1 w ds = \\left( \\int_0^1 + \\int_1^\\infty \\right) \\int_{M_{s_2}} w ds\n\\]\n\n\\[\n\\leq \\int_a^d w + \\int_a^d \\frac{1}{|p|} w \\int_1^\\infty \\frac{3}{s^2} ds = \\int_a^d w + 3 \\int_a^d \\frac{1}{|p|}\n\\]\n\n\\[\n< \\infty.\n\\]\n\nIt follows that  $\\sqrt{|\\lambda|}\\,\\left|m(t,\\lambda)\\right|$  is bounded on  $(a,x)$  by a function in te grable with weight  $w$  . The theorem now follows, under the restriction of the size of gaps of supp  $w$  assumed, by dominated convergence from the point wise result of Theorem 6.3.1.  \n\nTo complete the proof we must remove this restriction. We have just proved that the theorem is true for  $x$  up to and including the left endpoint  $d$  in the first gap. Violating the restriction, for  $x$  in this gap we have  \n\n$$\n\\psi(x,\\lambda)=\\psi(d,\\lambda)u(x)+p\\psi^{\\prime}(d,\\lambda)v(x)\\;,\n$$  \n\nwhere  $u$  and  $v$  are solutions of  $-(p u^{\\prime})^{\\prime}+q u\\,=\\,0$  with appropriate  $\\mathcal{A}$  -independent initial data in  $d$  . Since  $m(d,\\cdot)$  is a non-trivial Nevanlinna function, it follows that  $p\\psi^{\\prime}(x,\\lambda)/p\\psi^{\\prime}(d,\\lambda)\\,=\\,\\exp\\{O(\\log|\\lambda|)\\}$  , so the theorem holds up to and including the right endpoint of the gap and therefore up to and including the first point in the next large gap (if any). Since the support of  $w$  can only have a finite number of such large gaps in any compact interval, this completes the proof. \u53e3  \n\n# Exercises  \n\nExercise 6.4.1 Give a result analogous to Theorem 6.4.4 but for the kernel of  $u\\mapsto$   $p(R\\boldsymbol{\\lrcorner}\\boldsymbol{u})^{\\prime}$  . Also prove corresponding results for the left-definite case.  \n\nExercise 6.4.2 Prove that the radius of the circle defined by  $\\|\\theta(\\cdot,\\lambda)+m\\varphi(\\cdot,\\lambda)\\|_{x}^{2}\\leq$   $\\operatorname{Im}m/\\operatorname{Im}\\lambda$  in both the right- and left-definite cases is given by  $(2\\,|\\mathrm{Im}\\,\\lambda|\\,\\|\\varphi\\|_{x}^{2})^{-1}$  . Hint: The inequality  $\\|\\psi\\|_{x}^{2}\\,\\leq\\,\\mathrm{Im}\\,m/\\mathrm{Im}\\,\\lambda$  may be rewritten as  $\\left|m-c\\right|^{2}\\leq r^{2}$  , where  $r^{2}=A(2\\operatorname{Im}\\lambda\\|\\varphi\\|_{x}^{2})^{-2}$  and  \n\n$$\nA=|2\\mathrm{i}\\,\\mathrm{Im}\\,\\lambda\\langle\\theta,\\varphi\\rangle_{x}+1|^{2}+2\\mathrm{i}\\,\\mathrm{Im}\\,\\lambda\\|\\theta\\|_{x}^{2}\\,2\\mathrm{i}\\,\\mathrm{Im}\\,\\lambda\\|\\varphi\\|_{x}^{2}\\ .\n$$  \n\nUse the differential equation and integration by parts to write  $\\lambda\\langle\\theta,\\varphi\\rangle_{x}$  as an integrated term plus  $\\overline{{\\lambda}}\\langle\\theta,\\varphi\\rangle_{x}$  . Similarly for  $\\lambda||\\theta||_{x}^{2}$  and  $\\lambda\\|\\varphi\\|_{x}^{2}.$  Now rearrange the resulting terms to show that  $A=\\left|\\mathcal{W}_{p}(\\varphi,\\theta)\\right|^{2}=1$  \n\nExercise 6.4.3 Prove Theorem 6.4.1 in the left-definite case.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "||\u03b8(\u22c5,\u03bb) + m\u03d5(\u22c5,\u03bb)||\u1d6a\u00b2 \u2264 Im m / Im \u03bb",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/GTM098.Representations.of.compact.Lie.groups,.Broecker.T.,.tom.Dieck.T.(Springer,.2003)(ISBN.3540136789)(KA)(T)(326s)_MAr_.pdf_49",
        "ID": "08b8427a-8a34-46d4-8dc7-8aa722ee475c",
        "questions": "What does the expression '[X,Y]=0' imply about the exponentials of elements X and Y in a Lie group G?",
        "answers": "The expression '[X,Y]=0' implies that the exponentials of elements X and Y commute for all scalars s and t.",
        "context": "3. Let $G$ be a compact Lie group and $M \\times G \\to M$ a differentiable right $G$-manifold. Assume further that the maps $\\alpha_{p}\\colon G\\to M$, $G \\mapsto pg$ are injections for every $p\\in M$. Show that the $G$-manifold has the structure of a differentiable $G$-principal bundle.\n\n4. Show that a bijective immersion of differentiable manifolds is a diffeomorphism. Hint: An immersion $f\\colon M\\to N$ is locally an embedding. If we had dim $N >$ dim M, then $f(M)$ would have Lebesgue measure zero (locally) in $N$ (see Brocker and Janich [1], $\\S 6$).\n\n5. Show that any two fibers of the Hopf fibration (4.10) are linked in $S^{3}$: see Hopf [1].\n\n![](images/7125c2855f87d6bb66dfb6024f8a314c44ef6a8f08e4d49202e53ffdf3388db4.jpg)  \nFigure 12\n\n6. Give a diffeomorphism $\\mathrm{SO}(3)\\cong\\mathbb{R}P^{3}$, and, if you know enough about fundamental groups, show that $\\pi_{1}(\\mathrm{SO}(n))\\cong\\mathbb{Z}/2$ for $n > 2$ with a generator represented by the mapping $S^{1}=\\mathrm{SO}(1)\\to\\mathrm{SO}(n)$.\n\n7. Show that ${\\mathrm{Sp}}(n)$ is simply connected. Show that $\\mathrm{SU}(n)$ is simply connected.\n\n8. Show that there is a $G$-equivariant diffeomorphism of homogeneous spaces $G/H\\to G/K$ if and only if $H$ and $K$ are conjugate in $G$.\n\n9. Show that a homomorphism of tori $T^{n}\\to T^{k}$ is induced by a linear map $\\mathbb{R}^{n}\\to\\mathbb{R}^{k}$ whose associated matrix has integer coefficients.\n\n10. Show that the only noncompact topologically cyclic Lie group is $\\mathbb{Z}$.\n\n11. Let $G$ be a Lie group and let $X, Y \\in \\mathbb{L}(G)$. Show that $[X,Y]=0$ if and only if $\\exp(s X)\\cdot\\exp(t Y)=\\exp(t Y)\\cdot\\exp(s X)$ for all $s, t\\in\\mathbb{R}$. If $G$ is connected, then the Lie algebra of the center of $G$ is $\\{X\\in L G|[X, Y]=0$ for all $Y\\in LG$.\n\n# 5. Invariant Integration\n\nLet $X$ be a locally compact space and $C_{c}^{0}(X)$ be the vector space of continuous real-valued functions on $X$ with compact support. An integral on $X$ is a monotone linear map\n\n$$\n\\int\\colon C_{c}^{0}(X)\\to\\mathbb{R},\\quad f \\mapsto\\int f.\n$$\n\n\"Monotone\" means that if $f(x)\\leq g(x)$ for all $x\\in X$, then $\\int f\\leq\\int g$. The integral $\\int f$ is often denoted $\\int_{X}f(x)\\,d x$.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Let $G$ be a Lie group and let $X, Y \\in \\mathbb{L}(G)$. Show that $[X,Y]=0$ if and only if \\(\\exp(s X)\\cdot\\exp(t Y)=\\exp(t Y)\\cdot\\exp(s X)\\) for all $s, t\\in\\mathbb{R}$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM098.Representations.of.compact.Lie.groups,.Broecker.T.,.tom.Dieck.T.(Springer,.2003)(ISBN.3540136789)(KA)(T)(326s)_MAr_.pdf_49",
        "ID": "08ba3f66-b596-4a46-8fd0-fc309e875edb",
        "questions": "What is required for the integral of a function f over a locally compact space X in terms of monotonicity?",
        "answers": "The integral of a function f over a locally compact space X must be such that if $f(x) \\leq g(x)$ for all $x \\in X$, then $\\int f \\leq \\int g$.",
        "context": "3. Let $G$ be a compact Lie group and $M \\times G \\to M$ a differentiable right $G$-manifold. Assume further that the maps $\\alpha_{p}\\colon G\\to M$, $G \\mapsto pg$ are injections for every $p\\in M$. Show that the $G$-manifold has the structure of a differentiable $G$-principal bundle.\n\n4. Show that a bijective immersion of differentiable manifolds is a diffeomorphism. Hint: An immersion $f\\colon M\\to N$ is locally an embedding. If we had dim $N >$ dim M, then $f(M)$ would have Lebesgue measure zero (locally) in $N$ (see Brocker and Janich [1], $\\S 6$).\n\n5. Show that any two fibers of the Hopf fibration (4.10) are linked in $S^{3}$: see Hopf [1].\n\n![](images/7125c2855f87d6bb66dfb6024f8a314c44ef6a8f08e4d49202e53ffdf3388db4.jpg)  \nFigure 12\n\n6. Give a diffeomorphism $\\mathrm{SO}(3)\\cong\\mathbb{R}P^{3}$, and, if you know enough about fundamental groups, show that $\\pi_{1}(\\mathrm{SO}(n))\\cong\\mathbb{Z}/2$ for $n > 2$ with a generator represented by the mapping $S^{1}=\\mathrm{SO}(1)\\to\\mathrm{SO}(n)$.\n\n7. Show that ${\\mathrm{Sp}}(n)$ is simply connected. Show that $\\mathrm{SU}(n)$ is simply connected.\n\n8. Show that there is a $G$-equivariant diffeomorphism of homogeneous spaces $G/H\\to G/K$ if and only if $H$ and $K$ are conjugate in $G$.\n\n9. Show that a homomorphism of tori $T^{n}\\to T^{k}$ is induced by a linear map $\\mathbb{R}^{n}\\to\\mathbb{R}^{k}$ whose associated matrix has integer coefficients.\n\n10. Show that the only noncompact topologically cyclic Lie group is $\\mathbb{Z}$.\n\n11. Let $G$ be a Lie group and let $X, Y \\in \\mathbb{L}(G)$. Show that $[X,Y]=0$ if and only if $\\exp(s X)\\cdot\\exp(t Y)=\\exp(t Y)\\cdot\\exp(s X)$ for all $s, t\\in\\mathbb{R}$. If $G$ is connected, then the Lie algebra of the center of $G$ is $\\{X\\in L G|[X, Y]=0$ for all $Y\\in LG$.\n\n# 5. Invariant Integration\n\nLet $X$ be a locally compact space and $C_{c}^{0}(X)$ be the vector space of continuous real-valued functions on $X$ with compact support. An integral on $X$ is a monotone linear map\n\n$$\n\\int\\colon C_{c}^{0}(X)\\to\\mathbb{R},\\quad f \\mapsto\\int f.\n$$\n\n\"Monotone\" means that if $f(x)\\leq g(x)$ for all $x\\in X$, then $\\int f\\leq\\int g$. The integral $\\int f$ is often denoted $\\int_{X}f(x)\\,d x$.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "An integral on $X$ is a monotone linear map ... 'Monotone' means that if $f(x)\\leq g(x)$ for all $x\\in X$, then $\\int f\\leq\\int g$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM098.Representations.of.compact.Lie.groups,.Broecker.T.,.tom.Dieck.T.(Springer,.2003)(ISBN.3540136789)(KA)(T)(326s)_MAr_.pdf_49",
        "ID": "08bd4713-f044-472f-88d4-005ef427a696",
        "questions": "Is the syntactic condition given for the center of the Lie algebra of a connected Lie group G that its elements X commute with every element Y?",
        "answers": "Yes",
        "context": "3. Let $G$ be a compact Lie group and $M \\times G \\to M$ a differentiable right $G$-manifold. Assume further that the maps $\\alpha_{p}\\colon G\\to M$, $G \\mapsto pg$ are injections for every $p\\in M$. Show that the $G$-manifold has the structure of a differentiable $G$-principal bundle.\n\n4. Show that a bijective immersion of differentiable manifolds is a diffeomorphism. Hint: An immersion $f\\colon M\\to N$ is locally an embedding. If we had dim $N >$ dim M, then $f(M)$ would have Lebesgue measure zero (locally) in $N$ (see Brocker and Janich [1], $\\S 6$).\n\n5. Show that any two fibers of the Hopf fibration (4.10) are linked in $S^{3}$: see Hopf [1].\n\n![](images/7125c2855f87d6bb66dfb6024f8a314c44ef6a8f08e4d49202e53ffdf3388db4.jpg)  \nFigure 12\n\n6. Give a diffeomorphism $\\mathrm{SO}(3)\\cong\\mathbb{R}P^{3}$, and, if you know enough about fundamental groups, show that $\\pi_{1}(\\mathrm{SO}(n))\\cong\\mathbb{Z}/2$ for $n > 2$ with a generator represented by the mapping $S^{1}=\\mathrm{SO}(1)\\to\\mathrm{SO}(n)$.\n\n7. Show that ${\\mathrm{Sp}}(n)$ is simply connected. Show that $\\mathrm{SU}(n)$ is simply connected.\n\n8. Show that there is a $G$-equivariant diffeomorphism of homogeneous spaces $G/H\\to G/K$ if and only if $H$ and $K$ are conjugate in $G$.\n\n9. Show that a homomorphism of tori $T^{n}\\to T^{k}$ is induced by a linear map $\\mathbb{R}^{n}\\to\\mathbb{R}^{k}$ whose associated matrix has integer coefficients.\n\n10. Show that the only noncompact topologically cyclic Lie group is $\\mathbb{Z}$.\n\n11. Let $G$ be a Lie group and let $X, Y \\in \\mathbb{L}(G)$. Show that $[X,Y]=0$ if and only if $\\exp(s X)\\cdot\\exp(t Y)=\\exp(t Y)\\cdot\\exp(s X)$ for all $s, t\\in\\mathbb{R}$. If $G$ is connected, then the Lie algebra of the center of $G$ is $\\{X\\in L G|[X, Y]=0$ for all $Y\\in LG$.\n\n# 5. Invariant Integration\n\nLet $X$ be a locally compact space and $C_{c}^{0}(X)$ be the vector space of continuous real-valued functions on $X$ with compact support. An integral on $X$ is a monotone linear map\n\n$$\n\\int\\colon C_{c}^{0}(X)\\to\\mathbb{R},\\quad f \\mapsto\\int f.\n$$\n\n\"Monotone\" means that if $f(x)\\leq g(x)$ for all $x\\in X$, then $\\int f\\leq\\int g$. The integral $\\int f$ is often denoted $\\int_{X}f(x)\\,d x$.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Yes/No",
        "evidence_source": "text",
        "evidence_context": "If $G$ is connected, then the Lie algebra of the center of $G$ is $\\{X\\in L G|[X, Y]=0$ for all $Y\\in LG$\\}.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM098.Representations.of.compact.Lie.groups,.Broecker.T.,.tom.Dieck.T.(Springer,.2003)(ISBN.3540136789)(KA)(T)(326s)_MAr_.pdf_49",
        "ID": "08bee994-0814-44b9-b7fb-38722edee8e6",
        "questions": "What does the notation $\\int_{X} f(x)\\,d x$ represent in the context of integrals on locally compact spaces?",
        "answers": "The integral $\\int f$ is often denoted $\\int_{X}f(x)\\,d x.",
        "context": "3. Let $G$ be a compact Lie group and $M \\times G \\to M$ a differentiable right $G$-manifold. Assume further that the maps $\\alpha_{p}\\colon G\\to M$, $G \\mapsto pg$ are injections for every $p\\in M$. Show that the $G$-manifold has the structure of a differentiable $G$-principal bundle.\n\n4. Show that a bijective immersion of differentiable manifolds is a diffeomorphism. Hint: An immersion $f\\colon M\\to N$ is locally an embedding. If we had dim $N >$ dim M, then $f(M)$ would have Lebesgue measure zero (locally) in $N$ (see Brocker and Janich [1], $\\S 6$).\n\n5. Show that any two fibers of the Hopf fibration (4.10) are linked in $S^{3}$: see Hopf [1].\n\n![](images/7125c2855f87d6bb66dfb6024f8a314c44ef6a8f08e4d49202e53ffdf3388db4.jpg)  \nFigure 12\n\n6. Give a diffeomorphism $\\mathrm{SO}(3)\\cong\\mathbb{R}P^{3}$, and, if you know enough about fundamental groups, show that $\\pi_{1}(\\mathrm{SO}(n))\\cong\\mathbb{Z}/2$ for $n > 2$ with a generator represented by the mapping $S^{1}=\\mathrm{SO}(1)\\to\\mathrm{SO}(n)$.\n\n7. Show that ${\\mathrm{Sp}}(n)$ is simply connected. Show that $\\mathrm{SU}(n)$ is simply connected.\n\n8. Show that there is a $G$-equivariant diffeomorphism of homogeneous spaces $G/H\\to G/K$ if and only if $H$ and $K$ are conjugate in $G$.\n\n9. Show that a homomorphism of tori $T^{n}\\to T^{k}$ is induced by a linear map $\\mathbb{R}^{n}\\to\\mathbb{R}^{k}$ whose associated matrix has integer coefficients.\n\n10. Show that the only noncompact topologically cyclic Lie group is $\\mathbb{Z}$.\n\n11. Let $G$ be a Lie group and let $X, Y \\in \\mathbb{L}(G)$. Show that $[X,Y]=0$ if and only if $\\exp(s X)\\cdot\\exp(t Y)=\\exp(t Y)\\cdot\\exp(s X)$ for all $s, t\\in\\mathbb{R}$. If $G$ is connected, then the Lie algebra of the center of $G$ is $\\{X\\in L G|[X, Y]=0$ for all $Y\\in LG$.\n\n# 5. Invariant Integration\n\nLet $X$ be a locally compact space and $C_{c}^{0}(X)$ be the vector space of continuous real-valued functions on $X$ with compact support. An integral on $X$ is a monotone linear map\n\n$$\n\\int\\colon C_{c}^{0}(X)\\to\\mathbb{R},\\quad f \\mapsto\\int f.\n$$\n\n\"Monotone\" means that if $f(x)\\leq g(x)$ for all $x\\in X$, then $\\int f\\leq\\int g$. The integral $\\int f$ is often denoted $\\int_{X}f(x)\\,d x$.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "The integral $\\int f$ is often denoted $\\int_{X}f(x)\\,d x.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/GTM098.Representations.of.compact.Lie.groups,.Broecker.T.,.tom.Dieck.T.(Springer,.2003)(ISBN.3540136789)(KA)(T)(326s)_MAr_.pdf_49",
        "ID": "08ccf199-2ed9-43d0-b846-ce9a623d110d",
        "questions": "Given that $f$ and $g$ are continuous real-valued functions on a locally compact space $X$ with compact support, under what condition is the integral $\\int f$ less than or equal to the integral $\\int g$?",
        "answers": "$f(x)\\leq g(x)$ for all $x\\in X$",
        "context": "3. Let $G$ be a compact Lie group and $M \\times G \\to M$ a differentiable right $G$-manifold. Assume further that the maps $\\alpha_{p}\\colon G\\to M$, $G \\mapsto pg$ are injections for every $p\\in M$. Show that the $G$-manifold has the structure of a differentiable $G$-principal bundle.\n\n4. Show that a bijective immersion of differentiable manifolds is a diffeomorphism. Hint: An immersion $f\\colon M\\to N$ is locally an embedding. If we had dim $N >$ dim M, then $f(M)$ would have Lebesgue measure zero (locally) in $N$ (see Brocker and Janich [1], $\\S 6$).\n\n5. Show that any two fibers of the Hopf fibration (4.10) are linked in $S^{3}$: see Hopf [1].\n\n![](images/7125c2855f87d6bb66dfb6024f8a314c44ef6a8f08e4d49202e53ffdf3388db4.jpg)  \nFigure 12\n\n6. Give a diffeomorphism $\\mathrm{SO}(3)\\cong\\mathbb{R}P^{3}$, and, if you know enough about fundamental groups, show that $\\pi_{1}(\\mathrm{SO}(n))\\cong\\mathbb{Z}/2$ for $n > 2$ with a generator represented by the mapping $S^{1}=\\mathrm{SO}(1)\\to\\mathrm{SO}(n)$.\n\n7. Show that ${\\mathrm{Sp}}(n)$ is simply connected. Show that $\\mathrm{SU}(n)$ is simply connected.\n\n8. Show that there is a $G$-equivariant diffeomorphism of homogeneous spaces $G/H\\to G/K$ if and only if $H$ and $K$ are conjugate in $G$.\n\n9. Show that a homomorphism of tori $T^{n}\\to T^{k}$ is induced by a linear map $\\mathbb{R}^{n}\\to\\mathbb{R}^{k}$ whose associated matrix has integer coefficients.\n\n10. Show that the only noncompact topologically cyclic Lie group is $\\mathbb{Z}$.\n\n11. Let $G$ be a Lie group and let $X, Y \\in \\mathbb{L}(G)$. Show that $[X,Y]=0$ if and only if $\\exp(s X)\\cdot\\exp(t Y)=\\exp(t Y)\\cdot\\exp(s X)$ for all $s, t\\in\\mathbb{R}$. If $G$ is connected, then the Lie algebra of the center of $G$ is $\\{X\\in L G|[X, Y]=0$ for all $Y\\in LG$.\n\n# 5. Invariant Integration\n\nLet $X$ be a locally compact space and $C_{c}^{0}(X)$ be the vector space of continuous real-valued functions on $X$ with compact support. An integral on $X$ is a monotone linear map\n\n$$\n\\int\\colon C_{c}^{0}(X)\\to\\mathbb{R},\\quad f \\mapsto\\int f.\n$$\n\n\"Monotone\" means that if $f(x)\\leq g(x)$ for all $x\\in X$, then $\\int f\\leq\\int g$. The integral $\\int f$ is often denoted $\\int_{X}f(x)\\,d x$.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "\"Monotone\" means that if $f(x)\u2264g(x)$ for all $x\\in X$, then $\\int f\u2264\\int g$.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/GTM098.Representations.of.compact.Lie.groups,.Broecker.T.,.tom.Dieck.T.(Springer,.2003)(ISBN.3540136789)(KA)(T)(326s)_MAr_.pdf_49",
        "ID": "08db1e3e-915c-4259-bab2-d8ab2818e27a",
        "questions": "What is the mathematical representation for defining an integral as a monotone linear map from $C_{c}^{0}(X)$ to $\\mathbb{R}$ in the context of locally compact spaces?",
        "answers": "$\\int\\colon C_{c}^{0}(X)\to\\mathbb{R},\\quad f \\mapsto\\int f.$",
        "context": "3. Let $G$ be a compact Lie group and $M \\times G \\to M$ a differentiable right $G$-manifold. Assume further that the maps $\\alpha_{p}\\colon G\\to M$, $G \\mapsto pg$ are injections for every $p\\in M$. Show that the $G$-manifold has the structure of a differentiable $G$-principal bundle.\n\n4. Show that a bijective immersion of differentiable manifolds is a diffeomorphism. Hint: An immersion $f\\colon M\\to N$ is locally an embedding. If we had dim $N >$ dim M, then $f(M)$ would have Lebesgue measure zero (locally) in $N$ (see Brocker and Janich [1], $\\S 6$).\n\n5. Show that any two fibers of the Hopf fibration (4.10) are linked in $S^{3}$: see Hopf [1].\n\n![](images/7125c2855f87d6bb66dfb6024f8a314c44ef6a8f08e4d49202e53ffdf3388db4.jpg)  \nFigure 12\n\n6. Give a diffeomorphism $\\mathrm{SO}(3)\\cong\\mathbb{R}P^{3}$, and, if you know enough about fundamental groups, show that $\\pi_{1}(\\mathrm{SO}(n))\\cong\\mathbb{Z}/2$ for $n > 2$ with a generator represented by the mapping $S^{1}=\\mathrm{SO}(1)\\to\\mathrm{SO}(n)$.\n\n7. Show that ${\\mathrm{Sp}}(n)$ is simply connected. Show that $\\mathrm{SU}(n)$ is simply connected.\n\n8. Show that there is a $G$-equivariant diffeomorphism of homogeneous spaces $G/H\\to G/K$ if and only if $H$ and $K$ are conjugate in $G$.\n\n9. Show that a homomorphism of tori $T^{n}\\to T^{k}$ is induced by a linear map $\\mathbb{R}^{n}\\to\\mathbb{R}^{k}$ whose associated matrix has integer coefficients.\n\n10. Show that the only noncompact topologically cyclic Lie group is $\\mathbb{Z}$.\n\n11. Let $G$ be a Lie group and let $X, Y \\in \\mathbb{L}(G)$. Show that $[X,Y]=0$ if and only if $\\exp(s X)\\cdot\\exp(t Y)=\\exp(t Y)\\cdot\\exp(s X)$ for all $s, t\\in\\mathbb{R}$. If $G$ is connected, then the Lie algebra of the center of $G$ is $\\{X\\in L G|[X, Y]=0$ for all $Y\\in LG$.\n\n# 5. Invariant Integration\n\nLet $X$ be a locally compact space and $C_{c}^{0}(X)$ be the vector space of continuous real-valued functions on $X$ with compact support. An integral on $X$ is a monotone linear map\n\n$$\n\\int\\colon C_{c}^{0}(X)\\to\\mathbb{R},\\quad f \\mapsto\\int f.\n$$\n\n\"Monotone\" means that if $f(x)\\leq g(x)$ for all $x\\in X$, then $\\int f\\leq\\int g$. The integral $\\int f$ is often denoted $\\int_{X}f(x)\\,d x$.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$\\int\\colon C_{c}^{0}(X)\to\\mathbb{R},\\quad f \\mapsto\\int f.$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/SMM_Integral_Closure_Rees_Algebras_Multiplicities_Algorithms_(Wolmer_Vasconcelos).pdf_80",
        "ID": "08df6b19-7c3a-4037-a0d5-c16e961139cf",
        "questions": "What type of ring is R assumed to be in Proposition 1.122?",
        "answers": "commutative Noetherian ring without nontrivial idempotents",
        "context": "Proposition 1.122. Let R be a commutative Noetherian ring without nontrivial idempotents, and let  \n\n$$\n\\begin{array}{r l}{0\\xrightarrow{}}&{{}-E_{1}\\xrightarrow{}-E_{2}\\xrightarrow{}-E_{3}\\xrightarrow{}0}\\\\ &{{}\\qquad\\Bigg|\\,\\varphi_{1}\\qquad\\Bigg|\\,\\varphi_{2}\\qquad\\Bigg|\\,\\varphi_{3}\\qquad}\\\\ &{{}0\\xrightarrow{}-E_{1}\\xrightarrow{}-E_{2}\\xrightarrow{}-E_{3}\\xrightarrow{}0}\\end{array}\n$$  \n\nbe an exact commutative diagram of modules of finite projective dimension. Then  \n\n$$\nP_{\\Phi_{2}}(t)=P_{\\Phi_{1}}(t)\\cdot P_{\\Phi_{3}}(t).\n$$  \n\nProof. This follows directly from the preceding comments.  \n\nRemark 1.123. If $E$ is a graded module and $\\phi$ is homogeneous, then $P_{\\Phi}(t)$ is a homogeneous polynomial and deg $E=\\deg P_{\\Phi}(t)$.  \n\n# Minimal Polynomial  \n\nUnder special conditions, one can obtain the minimal polynomial of certain endomorphisms instead of the characteristic polynomial. This may occur in the setting of an affine domain $A$ and one of its Noetherian normalizations $R=k[z_{1},\\dots,z_{d}]$. For $u\\in A$, the kernel of the homomorphism  \n\n$$\nR[t]\\longrightarrow A,\\quad t\\longmapsto u,\n$$  \n\nis an irreducible polynomial $h_{u}(t)$ (appropriately homogeneous if $A$ is a graded algebra and $u$ is homogeneous). It is related to the characteristic polynomial $f_{u}(t)$ of $u$ by an equality of the form  \n\n$$\nf_{u}(t)=h_{u}(t)^{r}.\n$$  \n\n# The Determinant of an Endomorphism  \n\nLet $R$ be a commutative ring and $A$ a finite $R$-module. An element $a\\in A$ defines an endomorphism  \n\n$$\nf_{a}:A\\rightarrow A,\\;f_{a}(x)=a x,\n$$  \n\nof $R$-modules. We seek ways to define the determinant of $f_{a}$ relative to $R$. For example, if $A$ is a free $R$-module, we may use the standard definition. More generally, if $A$ has a finite free $R$-resolution $\\mathbb{F}$  \n\n$$\n0\\to F_{n}\\longrightarrow\\cdots\\longrightarrow F_{1}\\longrightarrow F_{0}\\longrightarrow A\\to0,\n$$  \n\nas above, we lift $f_{a}$ to an endomorphism of $\\mathbb{F}$, and \u201cdefine\u201d $\\operatorname*{det}(f_{a})$ as the alternating product  \n\n$$\n\\operatorname*{det}(f_{a})=\\prod_{i=0}^{n}\\operatorname*{det}(f_{i})^{(-1)^{i}},\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Let R be a commutative Noetherian ring without nontrivial idempotents, and let...",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/SMM_Integral_Closure_Rees_Algebras_Multiplicities_Algorithms_(Wolmer_Vasconcelos).pdf_80",
        "ID": "08e0e8df-688b-49e7-8449-6aef90a27b0e",
        "questions": "How is the kernel of the homomorphism mapped for an element u in an affine domain A and its Noetherian normalizations R?",
        "answers": "R[t] \u2192 A, t \u21a6 u",
        "context": "Proposition 1.122. Let R be a commutative Noetherian ring without nontrivial idempotents, and let  \n\n$$\n\\begin{array}{r l}{0\\xrightarrow{}}&{{}-E_{1}\\xrightarrow{}-E_{2}\\xrightarrow{}-E_{3}\\xrightarrow{}0}\\\\ &{{}\\qquad\\Bigg|\\,\\varphi_{1}\\qquad\\Bigg|\\,\\varphi_{2}\\qquad\\Bigg|\\,\\varphi_{3}\\qquad}\\\\ &{{}0\\xrightarrow{}-E_{1}\\xrightarrow{}-E_{2}\\xrightarrow{}-E_{3}\\xrightarrow{}0}\\end{array}\n$$  \n\nbe an exact commutative diagram of modules of finite projective dimension. Then  \n\n$$\nP_{\\Phi_{2}}(t)=P_{\\Phi_{1}}(t)\\cdot P_{\\Phi_{3}}(t).\n$$  \n\nProof. This follows directly from the preceding comments.  \n\nRemark 1.123. If $E$ is a graded module and $\\phi$ is homogeneous, then $P_{\\Phi}(t)$ is a homogeneous polynomial and deg $E=\\deg P_{\\Phi}(t)$.  \n\n# Minimal Polynomial  \n\nUnder special conditions, one can obtain the minimal polynomial of certain endomorphisms instead of the characteristic polynomial. This may occur in the setting of an affine domain $A$ and one of its Noetherian normalizations $R=k[z_{1},\\dots,z_{d}]$. For $u\\in A$, the kernel of the homomorphism  \n\n$$\nR[t]\\longrightarrow A,\\quad t\\longmapsto u,\n$$  \n\nis an irreducible polynomial $h_{u}(t)$ (appropriately homogeneous if $A$ is a graded algebra and $u$ is homogeneous). It is related to the characteristic polynomial $f_{u}(t)$ of $u$ by an equality of the form  \n\n$$\nf_{u}(t)=h_{u}(t)^{r}.\n$$  \n\n# The Determinant of an Endomorphism  \n\nLet $R$ be a commutative ring and $A$ a finite $R$-module. An element $a\\in A$ defines an endomorphism  \n\n$$\nf_{a}:A\\rightarrow A,\\;f_{a}(x)=a x,\n$$  \n\nof $R$-modules. We seek ways to define the determinant of $f_{a}$ relative to $R$. For example, if $A$ is a free $R$-module, we may use the standard definition. More generally, if $A$ has a finite free $R$-resolution $\\mathbb{F}$  \n\n$$\n0\\to F_{n}\\longrightarrow\\cdots\\longrightarrow F_{1}\\longrightarrow F_{0}\\longrightarrow A\\to0,\n$$  \n\nas above, we lift $f_{a}$ to an endomorphism of $\\mathbb{F}$, and \u201cdefine\u201d $\\operatorname*{det}(f_{a})$ as the alternating product  \n\n$$\n\\operatorname*{det}(f_{a})=\\prod_{i=0}^{n}\\operatorname*{det}(f_{i})^{(-1)^{i}},\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$$ R[t]\\longrightarrow A,\\quad t\\longmapsto u, $$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/SMM_Integral_Closure_Rees_Algebras_Multiplicities_Algorithms_(Wolmer_Vasconcelos).pdf_80",
        "ID": "08e2745c-f106-4c85-b87c-252130c4e2e6",
        "questions": "Is the determinant of an endomorphism f_a defined for a free R-module A using the standard definition?",
        "answers": "Yes",
        "context": "Proposition 1.122. Let R be a commutative Noetherian ring without nontrivial idempotents, and let  \n\n$$\n\\begin{array}{r l}{0\\xrightarrow{}}&{{}-E_{1}\\xrightarrow{}-E_{2}\\xrightarrow{}-E_{3}\\xrightarrow{}0}\\\\ &{{}\\qquad\\Bigg|\\,\\varphi_{1}\\qquad\\Bigg|\\,\\varphi_{2}\\qquad\\Bigg|\\,\\varphi_{3}\\qquad}\\\\ &{{}0\\xrightarrow{}-E_{1}\\xrightarrow{}-E_{2}\\xrightarrow{}-E_{3}\\xrightarrow{}0}\\end{array}\n$$  \n\nbe an exact commutative diagram of modules of finite projective dimension. Then  \n\n$$\nP_{\\Phi_{2}}(t)=P_{\\Phi_{1}}(t)\\cdot P_{\\Phi_{3}}(t).\n$$  \n\nProof. This follows directly from the preceding comments.  \n\nRemark 1.123. If $E$ is a graded module and $\\phi$ is homogeneous, then $P_{\\Phi}(t)$ is a homogeneous polynomial and deg $E=\\deg P_{\\Phi}(t)$.  \n\n# Minimal Polynomial  \n\nUnder special conditions, one can obtain the minimal polynomial of certain endomorphisms instead of the characteristic polynomial. This may occur in the setting of an affine domain $A$ and one of its Noetherian normalizations $R=k[z_{1},\\dots,z_{d}]$. For $u\\in A$, the kernel of the homomorphism  \n\n$$\nR[t]\\longrightarrow A,\\quad t\\longmapsto u,\n$$  \n\nis an irreducible polynomial $h_{u}(t)$ (appropriately homogeneous if $A$ is a graded algebra and $u$ is homogeneous). It is related to the characteristic polynomial $f_{u}(t)$ of $u$ by an equality of the form  \n\n$$\nf_{u}(t)=h_{u}(t)^{r}.\n$$  \n\n# The Determinant of an Endomorphism  \n\nLet $R$ be a commutative ring and $A$ a finite $R$-module. An element $a\\in A$ defines an endomorphism  \n\n$$\nf_{a}:A\\rightarrow A,\\;f_{a}(x)=a x,\n$$  \n\nof $R$-modules. We seek ways to define the determinant of $f_{a}$ relative to $R$. For example, if $A$ is a free $R$-module, we may use the standard definition. More generally, if $A$ has a finite free $R$-resolution $\\mathbb{F}$  \n\n$$\n0\\to F_{n}\\longrightarrow\\cdots\\longrightarrow F_{1}\\longrightarrow F_{0}\\longrightarrow A\\to0,\n$$  \n\nas above, we lift $f_{a}$ to an endomorphism of $\\mathbb{F}$, and \u201cdefine\u201d $\\operatorname*{det}(f_{a})$ as the alternating product  \n\n$$\n\\operatorname*{det}(f_{a})=\\prod_{i=0}^{n}\\operatorname*{det}(f_{i})^{(-1)^{i}},\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Yes/No",
        "evidence_source": "text",
        "evidence_context": "For example, if A is a free R-module, we may use the standard definition.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/SMM_Integral_Closure_Rees_Algebras_Multiplicities_Algorithms_(Wolmer_Vasconcelos).pdf_80",
        "ID": "08f2bc96-d0a7-46b0-9c3e-5d9b0640151e",
        "questions": "What is the relationship between the polynomials $P_{\\Phi_{2}}(t)$, $P_{\\Phi_{1}}(t)$, and $P_{\\Phi_{3}}(t)$ in the exact commutative diagram of modules of finite projective dimension?",
        "answers": "$P_{\\Phi_{2}}(t)=P_{\\Phi_{1}}(t)\\cdot P_{\\Phi_{3}}(t)$",
        "context": "Proposition 1.122. Let R be a commutative Noetherian ring without nontrivial idempotents, and let  \n\n$$\n\\begin{array}{r l}{0\\xrightarrow{}}&{{}-E_{1}\\xrightarrow{}-E_{2}\\xrightarrow{}-E_{3}\\xrightarrow{}0}\\\\ &{{}\\qquad\\Bigg|\\,\\varphi_{1}\\qquad\\Bigg|\\,\\varphi_{2}\\qquad\\Bigg|\\,\\varphi_{3}\\qquad}\\\\ &{{}0\\xrightarrow{}-E_{1}\\xrightarrow{}-E_{2}\\xrightarrow{}-E_{3}\\xrightarrow{}0}\\end{array}\n$$  \n\nbe an exact commutative diagram of modules of finite projective dimension. Then  \n\n$$\nP_{\\Phi_{2}}(t)=P_{\\Phi_{1}}(t)\\cdot P_{\\Phi_{3}}(t).\n$$  \n\nProof. This follows directly from the preceding comments.  \n\nRemark 1.123. If $E$ is a graded module and $\\phi$ is homogeneous, then $P_{\\Phi}(t)$ is a homogeneous polynomial and deg $E=\\deg P_{\\Phi}(t)$.  \n\n# Minimal Polynomial  \n\nUnder special conditions, one can obtain the minimal polynomial of certain endomorphisms instead of the characteristic polynomial. This may occur in the setting of an affine domain $A$ and one of its Noetherian normalizations $R=k[z_{1},\\dots,z_{d}]$. For $u\\in A$, the kernel of the homomorphism  \n\n$$\nR[t]\\longrightarrow A,\\quad t\\longmapsto u,\n$$  \n\nis an irreducible polynomial $h_{u}(t)$ (appropriately homogeneous if $A$ is a graded algebra and $u$ is homogeneous). It is related to the characteristic polynomial $f_{u}(t)$ of $u$ by an equality of the form  \n\n$$\nf_{u}(t)=h_{u}(t)^{r}.\n$$  \n\n# The Determinant of an Endomorphism  \n\nLet $R$ be a commutative ring and $A$ a finite $R$-module. An element $a\\in A$ defines an endomorphism  \n\n$$\nf_{a}:A\\rightarrow A,\\;f_{a}(x)=a x,\n$$  \n\nof $R$-modules. We seek ways to define the determinant of $f_{a}$ relative to $R$. For example, if $A$ is a free $R$-module, we may use the standard definition. More generally, if $A$ has a finite free $R$-resolution $\\mathbb{F}$  \n\n$$\n0\\to F_{n}\\longrightarrow\\cdots\\longrightarrow F_{1}\\longrightarrow F_{0}\\longrightarrow A\\to0,\n$$  \n\nas above, we lift $f_{a}$ to an endomorphism of $\\mathbb{F}$, and \u201cdefine\u201d $\\operatorname*{det}(f_{a})$ as the alternating product  \n\n$$\n\\operatorname*{det}(f_{a})=\\prod_{i=0}^{n}\\operatorname*{det}(f_{i})^{(-1)^{i}},\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "P_{\\Phi_{2}}(t)=P_{\\Phi_{1}}(t)\\cdot P_{\\Phi_{3}}(t).",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/SMM_Integral_Closure_Rees_Algebras_Multiplicities_Algorithms_(Wolmer_Vasconcelos).pdf_80",
        "ID": "08ffe28c-5926-4d4d-8c75-c775c02ff5f2",
        "questions": "In the context of a commutative ring $R$ and a finite $R$-module $A$, how can the determinant of endomorphism $f_{a}$ be defined if $A$ has a finite free $R$-resolution $\\mathbb{F}$?",
        "answers": "The alternate product",
        "context": "Proposition 1.122. Let R be a commutative Noetherian ring without nontrivial idempotents, and let  \n\n$$\n\\begin{array}{r l}{0\\xrightarrow{}}&{{}-E_{1}\\xrightarrow{}-E_{2}\\xrightarrow{}-E_{3}\\xrightarrow{}0}\\\\ &{{}\\qquad\\Bigg|\\,\\varphi_{1}\\qquad\\Bigg|\\,\\varphi_{2}\\qquad\\Bigg|\\,\\varphi_{3}\\qquad}\\\\ &{{}0\\xrightarrow{}-E_{1}\\xrightarrow{}-E_{2}\\xrightarrow{}-E_{3}\\xrightarrow{}0}\\end{array}\n$$  \n\nbe an exact commutative diagram of modules of finite projective dimension. Then  \n\n$$\nP_{\\Phi_{2}}(t)=P_{\\Phi_{1}}(t)\\cdot P_{\\Phi_{3}}(t).\n$$  \n\nProof. This follows directly from the preceding comments.  \n\nRemark 1.123. If $E$ is a graded module and $\\phi$ is homogeneous, then $P_{\\Phi}(t)$ is a homogeneous polynomial and deg $E=\\deg P_{\\Phi}(t)$.  \n\n# Minimal Polynomial  \n\nUnder special conditions, one can obtain the minimal polynomial of certain endomorphisms instead of the characteristic polynomial. This may occur in the setting of an affine domain $A$ and one of its Noetherian normalizations $R=k[z_{1},\\dots,z_{d}]$. For $u\\in A$, the kernel of the homomorphism  \n\n$$\nR[t]\\longrightarrow A,\\quad t\\longmapsto u,\n$$  \n\nis an irreducible polynomial $h_{u}(t)$ (appropriately homogeneous if $A$ is a graded algebra and $u$ is homogeneous). It is related to the characteristic polynomial $f_{u}(t)$ of $u$ by an equality of the form  \n\n$$\nf_{u}(t)=h_{u}(t)^{r}.\n$$  \n\n# The Determinant of an Endomorphism  \n\nLet $R$ be a commutative ring and $A$ a finite $R$-module. An element $a\\in A$ defines an endomorphism  \n\n$$\nf_{a}:A\\rightarrow A,\\;f_{a}(x)=a x,\n$$  \n\nof $R$-modules. We seek ways to define the determinant of $f_{a}$ relative to $R$. For example, if $A$ is a free $R$-module, we may use the standard definition. More generally, if $A$ has a finite free $R$-resolution $\\mathbb{F}$  \n\n$$\n0\\to F_{n}\\longrightarrow\\cdots\\longrightarrow F_{1}\\longrightarrow F_{0}\\longrightarrow A\\to0,\n$$  \n\nas above, we lift $f_{a}$ to an endomorphism of $\\mathbb{F}$, and \u201cdefine\u201d $\\operatorname*{det}(f_{a})$ as the alternating product  \n\n$$\n\\operatorname*{det}(f_{a})=\\prod_{i=0}^{n}\\operatorname*{det}(f_{i})^{(-1)^{i}},\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Numeric",
        "evidence_source": "equation",
        "evidence_context": "we lift $f_{a}$ to an endomorphism of $\\mathbb{F}$, and \u201cdefine\u201d $\\operatorname*{det}(f_{a})$ as the alternating product \n\\operatorname*{det}(f_{a})=\\prod_{i=0}^{n}\\operatorname*{det}(f_{i})^{(-1)^{i}},",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/SMM_Integral_Closure_Rees_Algebras_Multiplicities_Algorithms_(Wolmer_Vasconcelos).pdf_80",
        "ID": "0907ca13-1511-43f9-846e-1738790b1990",
        "questions": "For an element $u$ in an affine domain $A$ and one of its Noetherian normalizations $R$, how is the polynomial $f_{u}(t)$ related to the polynomial $h_{u}(t)$?",
        "answers": "f_{u}(t)=h_{u}(t)^{r}",
        "context": "Proposition 1.122. Let R be a commutative Noetherian ring without nontrivial idempotents, and let  \n\n$$\n\\begin{array}{r l}{0\\xrightarrow{}}&{{}-E_{1}\\xrightarrow{}-E_{2}\\xrightarrow{}-E_{3}\\xrightarrow{}0}\\\\ &{{}\\qquad\\Bigg|\\,\\varphi_{1}\\qquad\\Bigg|\\,\\varphi_{2}\\qquad\\Bigg|\\,\\varphi_{3}\\qquad}\\\\ &{{}0\\xrightarrow{}-E_{1}\\xrightarrow{}-E_{2}\\xrightarrow{}-E_{3}\\xrightarrow{}0}\\end{array}\n$$  \n\nbe an exact commutative diagram of modules of finite projective dimension. Then  \n\n$$\nP_{\\Phi_{2}}(t)=P_{\\Phi_{1}}(t)\\cdot P_{\\Phi_{3}}(t).\n$$  \n\nProof. This follows directly from the preceding comments.  \n\nRemark 1.123. If $E$ is a graded module and $\\phi$ is homogeneous, then $P_{\\Phi}(t)$ is a homogeneous polynomial and deg $E=\\deg P_{\\Phi}(t)$.  \n\n# Minimal Polynomial  \n\nUnder special conditions, one can obtain the minimal polynomial of certain endomorphisms instead of the characteristic polynomial. This may occur in the setting of an affine domain $A$ and one of its Noetherian normalizations $R=k[z_{1},\\dots,z_{d}]$. For $u\\in A$, the kernel of the homomorphism  \n\n$$\nR[t]\\longrightarrow A,\\quad t\\longmapsto u,\n$$  \n\nis an irreducible polynomial $h_{u}(t)$ (appropriately homogeneous if $A$ is a graded algebra and $u$ is homogeneous). It is related to the characteristic polynomial $f_{u}(t)$ of $u$ by an equality of the form  \n\n$$\nf_{u}(t)=h_{u}(t)^{r}.\n$$  \n\n# The Determinant of an Endomorphism  \n\nLet $R$ be a commutative ring and $A$ a finite $R$-module. An element $a\\in A$ defines an endomorphism  \n\n$$\nf_{a}:A\\rightarrow A,\\;f_{a}(x)=a x,\n$$  \n\nof $R$-modules. We seek ways to define the determinant of $f_{a}$ relative to $R$. For example, if $A$ is a free $R$-module, we may use the standard definition. More generally, if $A$ has a finite free $R$-resolution $\\mathbb{F}$  \n\n$$\n0\\to F_{n}\\longrightarrow\\cdots\\longrightarrow F_{1}\\longrightarrow F_{0}\\longrightarrow A\\to0,\n$$  \n\nas above, we lift $f_{a}$ to an endomorphism of $\\mathbb{F}$, and \u201cdefine\u201d $\\operatorname*{det}(f_{a})$ as the alternating product  \n\n$$\n\\operatorname*{det}(f_{a})=\\prod_{i=0}^{n}\\operatorname*{det}(f_{i})^{(-1)^{i}},\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "f_{u}(t)=h_{u}(t)^{r}.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/UTX_-_Linear_Algebra_and_Linear_Models,_Third_Edition.pdf_79",
        "ID": "0909d045-4cde-4dae-b6a0-17da86a284e8",
        "questions": "What is the interpretation of the parameter 'mu' in the model used to compare 'k' treatments?",
        "answers": "general effect",
        "context": "where  $\\varepsilon_{i j}$  are independent with mean O and variance  $\\sigma^{2}$. This model arises when we want to compare  $k$  treatments. We have  $n_{i}$  observations on the  $i$  -th treatment. The parameter  $\\mu$  is interpreted as the \"general effect,\" and  $\\alpha_{i}$  is the \"effect due to the  $i$  -th treatment.\" We wish to find the RSs. Instead of writing the model in standard form, we follow a different approach. The RSS is the minimum value of  \n\n$$\n\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}(y_{i j}-\\mu-\\alpha_{i})^{2}.\n$$  \n\nWe use the fact that if  $u_{1},.\\ldots,u_{m}$  are real numbers, then  \n\n$$\n\\sum_{i=1}^{m}(u_{i}-\\theta)^{2}\n$$  \n\nis minimized when  $\\theta=\\overline{{u}}$  , the mean of  $u_{1},\\ldots,u_{n}$. This is easily proved using calculus. The sum (7.8) is minimized when  $\\mu+\\alpha_{i}=\\overline{{y}}_{i.},i=1,\\ldots,k;$  and therefore  \n\n$$\n{\\mathrm{RSS}}=\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}(y_{i j}-{\\overline{{y}}}_{i.})^{2}.\n$$  \n\nNow, suppose we wish to find the RSS subject to the constraints  $\\alpha_{i}-\\alpha_{j}=0$  for all  $i,j$  . Since  $\\alpha_{i}=\\alpha_{j}$  is estimable, we may proceed to apply 7.6. Thus, we must calculate  $\\tilde{\\alpha}$  using the formula immediately preceding 7.6. However, again there is a more elementary way. Let  $\\alpha$  denote the common value of  $\\alpha_{1},.\\,.\\,.\\,,\\,\\alpha_{k}$. Then we must minimize  \n\n$$\n\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}(y_{i j}-\\mu-\\alpha)^{2}\n$$  \n\nand this is achieved by setting  \n\n$$\n\\mu+\\alpha=\\overline{{y}}_{..}=\\frac{1}{n}\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}y_{i j},\n$$  \nwhere $\\textstyle n=\\sum_{i=1}^{k}n_{i}$  Thus the RSS now is\n\n$$\n\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}(y_{i j}-{\\overline{{y}}}_{..})^{2}.\n$$\n\n\nThe computation of RSS subject to linear restrictions will be useful in deriving a test of the hypothesis that the restrictions are indeed valid. This will be achieved in the next chapter.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "The parameter  \\(\\mu\\)  is interpreted as the \"general effect,\"",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTX_-_Linear_Algebra_and_Linear_Models,_Third_Edition.pdf_79",
        "ID": "090d126a-af7e-41c1-bde6-0d956338d2c6",
        "questions": "What must be minimized to find the RSS in the given model?",
        "answers": "\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}(y_{i j}-\\mu-\\alpha_{i})^{2}",
        "context": "where  $\\varepsilon_{i j}$  are independent with mean O and variance  $\\sigma^{2}$. This model arises when we want to compare  $k$  treatments. We have  $n_{i}$  observations on the  $i$  -th treatment. The parameter  $\\mu$  is interpreted as the \"general effect,\" and  $\\alpha_{i}$  is the \"effect due to the  $i$  -th treatment.\" We wish to find the RSs. Instead of writing the model in standard form, we follow a different approach. The RSS is the minimum value of  \n\n$$\n\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}(y_{i j}-\\mu-\\alpha_{i})^{2}.\n$$  \n\nWe use the fact that if  $u_{1},.\\ldots,u_{m}$  are real numbers, then  \n\n$$\n\\sum_{i=1}^{m}(u_{i}-\\theta)^{2}\n$$  \n\nis minimized when  $\\theta=\\overline{{u}}$  , the mean of  $u_{1},\\ldots,u_{n}$. This is easily proved using calculus. The sum (7.8) is minimized when  $\\mu+\\alpha_{i}=\\overline{{y}}_{i.},i=1,\\ldots,k;$  and therefore  \n\n$$\n{\\mathrm{RSS}}=\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}(y_{i j}-{\\overline{{y}}}_{i.})^{2}.\n$$  \n\nNow, suppose we wish to find the RSS subject to the constraints  $\\alpha_{i}-\\alpha_{j}=0$  for all  $i,j$  . Since  $\\alpha_{i}=\\alpha_{j}$  is estimable, we may proceed to apply 7.6. Thus, we must calculate  $\\tilde{\\alpha}$  using the formula immediately preceding 7.6. However, again there is a more elementary way. Let  $\\alpha$  denote the common value of  $\\alpha_{1},.\\,.\\,.\\,,\\,\\alpha_{k}$. Then we must minimize  \n\n$$\n\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}(y_{i j}-\\mu-\\alpha)^{2}\n$$  \n\nand this is achieved by setting  \n\n$$\n\\mu+\\alpha=\\overline{{y}}_{..}=\\frac{1}{n}\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}y_{i j},\n$$  \nwhere $\\textstyle n=\\sum_{i=1}^{k}n_{i}$  Thus the RSS now is\n\n$$\n\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}(y_{i j}-{\\overline{{y}}}_{..})^{2}.\n$$\n\n\nThe computation of RSS subject to linear restrictions will be useful in deriving a test of the hypothesis that the restrictions are indeed valid. This will be achieved in the next chapter.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "The RSS is the minimum value of \\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}(y_{i j}-\\mu-\\alpha_{i})^{2}.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTX_-_Linear_Algebra_and_Linear_Models,_Third_Edition.pdf_79",
        "ID": "09122343-1611-4688-a843-acb103a17a29",
        "questions": "In the given model, what is the expression for \\(\\mu + \\alpha\\) that minimizes the sum \\(\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}(y_{i j}-\\mu-\\alpha)^{2}\\) when all \\(\\alpha_{i}\\) are set to a common value?",
        "answers": "\\overline{y}_{..} = \\frac{1}{n}\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}y_{i j}",
        "context": "where  $\\varepsilon_{i j}$  are independent with mean O and variance  $\\sigma^{2}$. This model arises when we want to compare  $k$  treatments. We have  $n_{i}$  observations on the  $i$  -th treatment. The parameter  $\\mu$  is interpreted as the \"general effect,\" and  $\\alpha_{i}$  is the \"effect due to the  $i$  -th treatment.\" We wish to find the RSs. Instead of writing the model in standard form, we follow a different approach. The RSS is the minimum value of  \n\n$$\n\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}(y_{i j}-\\mu-\\alpha_{i})^{2}.\n$$  \n\nWe use the fact that if  $u_{1},.\\ldots,u_{m}$  are real numbers, then  \n\n$$\n\\sum_{i=1}^{m}(u_{i}-\\theta)^{2}\n$$  \n\nis minimized when  $\\theta=\\overline{{u}}$  , the mean of  $u_{1},\\ldots,u_{n}$. This is easily proved using calculus. The sum (7.8) is minimized when  $\\mu+\\alpha_{i}=\\overline{{y}}_{i.},i=1,\\ldots,k;$  and therefore  \n\n$$\n{\\mathrm{RSS}}=\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}(y_{i j}-{\\overline{{y}}}_{i.})^{2}.\n$$  \n\nNow, suppose we wish to find the RSS subject to the constraints  $\\alpha_{i}-\\alpha_{j}=0$  for all  $i,j$  . Since  $\\alpha_{i}=\\alpha_{j}$  is estimable, we may proceed to apply 7.6. Thus, we must calculate  $\\tilde{\\alpha}$  using the formula immediately preceding 7.6. However, again there is a more elementary way. Let  $\\alpha$  denote the common value of  $\\alpha_{1},.\\,.\\,.\\,,\\,\\alpha_{k}$. Then we must minimize  \n\n$$\n\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}(y_{i j}-\\mu-\\alpha)^{2}\n$$  \n\nand this is achieved by setting  \n\n$$\n\\mu+\\alpha=\\overline{{y}}_{..}=\\frac{1}{n}\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}y_{i j},\n$$  \nwhere $\\textstyle n=\\sum_{i=1}^{k}n_{i}$  Thus the RSS now is\n\n$$\n\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}(y_{i j}-{\\overline{{y}}}_{..})^{2}.\n$$\n\n\nThe computation of RSS subject to linear restrictions will be useful in deriving a test of the hypothesis that the restrictions are indeed valid. This will be achieved in the next chapter.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Equation",
        "evidence_source": "text",
        "evidence_context": "and this is achieved by setting  \\(\\mu + \\alpha = \\overline{y}_{..} = \\frac{1}{n}\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}y_{i j}\\)",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTX_-_Linear_Algebra_and_Linear_Models,_Third_Edition.pdf_79",
        "ID": "09176692-6bc8-40e3-af9c-64ef9806ba8f",
        "questions": "How is the residual sum of squares (RSS) expressed when independent errors with mean zero and variance $\\sigma^2$ are considered across $k$ treatments with observations $n_i$?",
        "answers": "${\\mathrm{RSS}}=\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}(y_{i j}-{\\overline{{y}}}_{i.})^{2}$",
        "context": "where  $\\varepsilon_{i j}$  are independent with mean O and variance  $\\sigma^{2}$. This model arises when we want to compare  $k$  treatments. We have  $n_{i}$  observations on the  $i$  -th treatment. The parameter  $\\mu$  is interpreted as the \"general effect,\" and  $\\alpha_{i}$  is the \"effect due to the  $i$  -th treatment.\" We wish to find the RSs. Instead of writing the model in standard form, we follow a different approach. The RSS is the minimum value of  \n\n$$\n\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}(y_{i j}-\\mu-\\alpha_{i})^{2}.\n$$  \n\nWe use the fact that if  $u_{1},.\\ldots,u_{m}$  are real numbers, then  \n\n$$\n\\sum_{i=1}^{m}(u_{i}-\\theta)^{2}\n$$  \n\nis minimized when  $\\theta=\\overline{{u}}$  , the mean of  $u_{1},\\ldots,u_{n}$. This is easily proved using calculus. The sum (7.8) is minimized when  $\\mu+\\alpha_{i}=\\overline{{y}}_{i.},i=1,\\ldots,k;$  and therefore  \n\n$$\n{\\mathrm{RSS}}=\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}(y_{i j}-{\\overline{{y}}}_{i.})^{2}.\n$$  \n\nNow, suppose we wish to find the RSS subject to the constraints  $\\alpha_{i}-\\alpha_{j}=0$  for all  $i,j$  . Since  $\\alpha_{i}=\\alpha_{j}$  is estimable, we may proceed to apply 7.6. Thus, we must calculate  $\\tilde{\\alpha}$  using the formula immediately preceding 7.6. However, again there is a more elementary way. Let  $\\alpha$  denote the common value of  $\\alpha_{1},.\\,.\\,.\\,,\\,\\alpha_{k}$. Then we must minimize  \n\n$$\n\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}(y_{i j}-\\mu-\\alpha)^{2}\n$$  \n\nand this is achieved by setting  \n\n$$\n\\mu+\\alpha=\\overline{{y}}_{..}=\\frac{1}{n}\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}y_{i j},\n$$  \nwhere $\\textstyle n=\\sum_{i=1}^{k}n_{i}$  Thus the RSS now is\n\n$$\n\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}(y_{i j}-{\\overline{{y}}}_{..})^{2}.\n$$\n\n\nThe computation of RSS subject to linear restrictions will be useful in deriving a test of the hypothesis that the restrictions are indeed valid. This will be achieved in the next chapter.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "${\\mathrm{RSS}}=\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}(y_{i j}-{\\overline{{y}}}_{i.})^{2}.$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/UTX_-_Linear_Algebra_and_Linear_Models,_Third_Edition.pdf_79",
        "ID": "091c5153-2564-4c18-a192-083fd999d865",
        "questions": "What is the condition to be satisfied for minimizing the expression $\\sum_{i=1}^{m}(u_{i}-\\theta)^{2}$ with real numbers $u_1, \\ldots, u_m$?",
        "answers": "$\\theta=\\overline{{u}}$",
        "context": "where  $\\varepsilon_{i j}$  are independent with mean O and variance  $\\sigma^{2}$. This model arises when we want to compare  $k$  treatments. We have  $n_{i}$  observations on the  $i$  -th treatment. The parameter  $\\mu$  is interpreted as the \"general effect,\" and  $\\alpha_{i}$  is the \"effect due to the  $i$  -th treatment.\" We wish to find the RSs. Instead of writing the model in standard form, we follow a different approach. The RSS is the minimum value of  \n\n$$\n\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}(y_{i j}-\\mu-\\alpha_{i})^{2}.\n$$  \n\nWe use the fact that if  $u_{1},.\\ldots,u_{m}$  are real numbers, then  \n\n$$\n\\sum_{i=1}^{m}(u_{i}-\\theta)^{2}\n$$  \n\nis minimized when  $\\theta=\\overline{{u}}$  , the mean of  $u_{1},\\ldots,u_{n}$. This is easily proved using calculus. The sum (7.8) is minimized when  $\\mu+\\alpha_{i}=\\overline{{y}}_{i.},i=1,\\ldots,k;$  and therefore  \n\n$$\n{\\mathrm{RSS}}=\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}(y_{i j}-{\\overline{{y}}}_{i.})^{2}.\n$$  \n\nNow, suppose we wish to find the RSS subject to the constraints  $\\alpha_{i}-\\alpha_{j}=0$  for all  $i,j$  . Since  $\\alpha_{i}=\\alpha_{j}$  is estimable, we may proceed to apply 7.6. Thus, we must calculate  $\\tilde{\\alpha}$  using the formula immediately preceding 7.6. However, again there is a more elementary way. Let  $\\alpha$  denote the common value of  $\\alpha_{1},.\\,.\\,.\\,,\\,\\alpha_{k}$. Then we must minimize  \n\n$$\n\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}(y_{i j}-\\mu-\\alpha)^{2}\n$$  \n\nand this is achieved by setting  \n\n$$\n\\mu+\\alpha=\\overline{{y}}_{..}=\\frac{1}{n}\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}y_{i j},\n$$  \nwhere $\\textstyle n=\\sum_{i=1}^{k}n_{i}$  Thus the RSS now is\n\n$$\n\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}(y_{i j}-{\\overline{{y}}}_{..})^{2}.\n$$\n\n\nThe computation of RSS subject to linear restrictions will be useful in deriving a test of the hypothesis that the restrictions are indeed valid. This will be achieved in the next chapter.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "is minimized when $\\theta=\\overline{{u}}$ , the mean of $u_{1},\\ldots,u_{n}$. This is easily proved using calculus.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/UTX_-_Linear_Algebra_and_Linear_Models,_Third_Edition.pdf_79",
        "ID": "091d5dc7-e584-42a4-bfbb-6e84b04e67ee",
        "questions": "In the model with $k$ treatments and $n$ observations, what is the expression for $\\mu+\\alpha$ when $\u0007lpha_{i}=\\alpha_{j}$ is a given constraint?",
        "answers": "$\\mu+\\alpha=\\overline{y}_{..}=\\frac{1}{n}\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}y_{i j}$",
        "context": "where  $\\varepsilon_{i j}$  are independent with mean O and variance  $\\sigma^{2}$. This model arises when we want to compare  $k$  treatments. We have  $n_{i}$  observations on the  $i$  -th treatment. The parameter  $\\mu$  is interpreted as the \"general effect,\" and  $\\alpha_{i}$  is the \"effect due to the  $i$  -th treatment.\" We wish to find the RSs. Instead of writing the model in standard form, we follow a different approach. The RSS is the minimum value of  \n\n$$\n\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}(y_{i j}-\\mu-\\alpha_{i})^{2}.\n$$  \n\nWe use the fact that if  $u_{1},.\\ldots,u_{m}$  are real numbers, then  \n\n$$\n\\sum_{i=1}^{m}(u_{i}-\\theta)^{2}\n$$  \n\nis minimized when  $\\theta=\\overline{{u}}$  , the mean of  $u_{1},\\ldots,u_{n}$. This is easily proved using calculus. The sum (7.8) is minimized when  $\\mu+\\alpha_{i}=\\overline{{y}}_{i.},i=1,\\ldots,k;$  and therefore  \n\n$$\n{\\mathrm{RSS}}=\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}(y_{i j}-{\\overline{{y}}}_{i.})^{2}.\n$$  \n\nNow, suppose we wish to find the RSS subject to the constraints  $\\alpha_{i}-\\alpha_{j}=0$  for all  $i,j$  . Since  $\\alpha_{i}=\\alpha_{j}$  is estimable, we may proceed to apply 7.6. Thus, we must calculate  $\\tilde{\\alpha}$  using the formula immediately preceding 7.6. However, again there is a more elementary way. Let  $\\alpha$  denote the common value of  $\\alpha_{1},.\\,.\\,.\\,,\\,\\alpha_{k}$. Then we must minimize  \n\n$$\n\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}(y_{i j}-\\mu-\\alpha)^{2}\n$$  \n\nand this is achieved by setting  \n\n$$\n\\mu+\\alpha=\\overline{{y}}_{..}=\\frac{1}{n}\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}y_{i j},\n$$  \nwhere $\\textstyle n=\\sum_{i=1}^{k}n_{i}$  Thus the RSS now is\n\n$$\n\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}(y_{i j}-{\\overline{{y}}}_{..})^{2}.\n$$\n\n\nThe computation of RSS subject to linear restrictions will be useful in deriving a test of the hypothesis that the restrictions are indeed valid. This will be achieved in the next chapter.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$\\mu+\\alpha=\\overline{{y}}_{..}=\\frac{1}{n}\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}y_{i j},$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/socialsci-74973.pdf_31",
        "ID": "091eca72-0278-4963-b9be-384524584b39",
        "questions": "Who is Julian, and what is his level of experience in the EWC?",
        "answers": "Julian is a white, senior English/Comparative Literature major who had worked in the EWC for two years, including a quarter as an in-class tutor.",
        "context": "# TeamOne: Julian and Anne  \n\nJulian, from Team One, is a white, senior English/Comparative Literature major who had worked in the EwC for two years, including a quarter as an in-class tutor with me. Julian commented minimally on papers and met one-to-one with students at the EWC. He also attended two in-class peer reviews. He has the most experience tutoring one-to-one and in the classroom of all the tutors. Having worked with Julian very closely for two years prior to this study, I found him outspoken and highly intelligent.  \n\nAnne is a white, third-year TA in English Language and Rhetoric. She had one year of teaching experience with first-years prior to this pairing. She had extensive training and experience, about five years, teaching one-to-one for the EWC and CLUE (CLUE, or the Center for Learning and Undergraduate Enrichment, is another campus student-support service that houses an evening writing center). She had also presented at several national and regional writing center and Composition and Rhetoric conferences.  \n\n\n\\begin{table}[h]\n    \\centering\n    \\caption{Table 2.2. Team One descriptions}\n    \\begin{tabular}{|m{0.3\\linewidth}|m{0.3\\linewidth}|m{0.25\\linewidth}|m{0.3\\linewidth}|}\n         \n        The Model &  The Tutor &  The Instructor \\\\ \n         \n        Writing Advisor Tutor Tutor commented on papers and met one-to-one with students at the English Department Writing Center (EWC). He attended two in-class peer response sessions. &  \n        Julian is a white, senior English/Comparative Literature major who had worked in the EWC for two years, including a prior quarter as an in-class tutor. He had the most experience extensive training and experience in tutoring one-to-one and in the classroom of all the tutors. &  \n        Anne is a white, third year TA in Language and Rhetoric. She had taught two years of traditional FYC prior to this pairing. She had extensive training and experience in tutoring one-to-one for the EWC. \\\\\n         \n    \\end{tabular}\n\\end{table}\n\n\n\n# TeamTwo: Megan and Laura  \n\nTeam Two includes Megan and Laura. Megan attended class every day and worked one-to-one with students at the EWC. Megan is a white, senior Communications/English major who had been tutoring at the EWC for two years. She was planning to pursue K-12 teaching. Like all the EWC tutors (except Sam), she took a five-credit course in writing center theory and practice. Megan considered herself not the strongest writer. During her interview, she described how struggling with an English class, from which she eventually earned a 4.0, persuaded her to apply to the EWC. Having worked with her an entire summer, to me, Megan always seemed very nice (often \"bubbly\") and approachable.  \n\nLaura is a second-year TA and Chinese International student, focusing on postcolonial studies and Asian-American literature. She had one year of teaching experience with first-years prior to this pairing.  \n\n\\begin{table}[h]\n    \\centering\n    \\caption{Table 2-3: Team Two Descriptions}\n    \\begin{tabular}{|m{0.3\\textwidth}|m{0.35\\textwidth}|m{0.35\\textwidth}|}\n         \n        The Model & The Tutor & The Instructor \\\\ \n         \n        In-Class Tutor & Megan is a white, senior Communications/English major with two years tutoring in the Department Writing Center (EWC). & Laura is a second year, Chinese international grad student and TA in English Literature. She had one year of teaching experience in a traditional first-year composition (FYC) classroom prior to this pairing. \\\\\n         \n        Tutor attended class every day and worked one-to-one with students at the English Department Writing Center (EWC). & Megan is a white, senior Communications/English major with two years tutoring in the EWC. She planned to pursue K-12 teaching. Like all the EWC tutors (except Sam) she took a 5-credit course in writing center theory. & Laura is a second year, Chinese international grad student and TA in English Literature. She had one year of teaching experience in a traditional first-year composition (FYC) classroom prior to this pairing. \\\\\n         \n    \\end{tabular}\n\\end{table}\n\n\n\n# TeamThree: Madeleine and Sydney  \n\nDue to her schedule, Madeleine, from Team Three, attended class every other day and worked one-to-one with students at the IC. Madeleine is an African-American sophomore English (creative writing) major who had worked for the IC only one quarter prior to this pairing. She enjoys performing spoken-word poetry. She did not receive any formal training in one-to-one teaching prior to this pairing. She attended a college prep high school and participated in running start. Prior to this study, I was not familiar with the personality or tutoring patterns of Madeleine.  \n\nSydney, a woman of color (African-American) herself, is a second-year TA studying nineteenth- and twentieth-century African-American literature. She had about five years of teaching and tutoring experience with high school students and one year of teaching with first-years prior to this pairing. On her wish-list, Sydney had written me a note asking, if at all possible, for a tutor of color. Serendipity worked in her favor in the form of Madeleine, who I would later learn was the only IC tutor willing to participate in this study.  \n\n\\begin{table}[h]\n    \\centering\n    \\caption*{Table 2-4:Team Three descriptioins}\n    \\begin{tabular}{|c|c|c|c|c|}\n         \n        The Model & The Tor & The Disctor & Inserted & Uncertainty \\\\\n         \n    \\end{tabular}\n\\end{table}",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Julian is a white, senior English/Comparative Literature major who had worked in the EWC for two years, including a prior quarter as an in-class tutor.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/socialsci-74973.pdf_31",
        "ID": "092770d2-86c5-4c45-b9dd-6e7597a03443",
        "questions": "How many years of tutoring and teaching experience does Sydney have before her pairing with Madeleine?",
        "answers": "Sydney had about five years of teaching and tutoring experience with high school students and one year of teaching with first-years prior to this pairing.",
        "context": "# TeamOne: Julian and Anne  \n\nJulian, from Team One, is a white, senior English/Comparative Literature major who had worked in the EwC for two years, including a quarter as an in-class tutor with me. Julian commented minimally on papers and met one-to-one with students at the EWC. He also attended two in-class peer reviews. He has the most experience tutoring one-to-one and in the classroom of all the tutors. Having worked with Julian very closely for two years prior to this study, I found him outspoken and highly intelligent.  \n\nAnne is a white, third-year TA in English Language and Rhetoric. She had one year of teaching experience with first-years prior to this pairing. She had extensive training and experience, about five years, teaching one-to-one for the EWC and CLUE (CLUE, or the Center for Learning and Undergraduate Enrichment, is another campus student-support service that houses an evening writing center). She had also presented at several national and regional writing center and Composition and Rhetoric conferences.  \n\n\n\\begin{table}[h]\n    \\centering\n    \\caption{Table 2.2. Team One descriptions}\n    \\begin{tabular}{|m{0.3\\linewidth}|m{0.3\\linewidth}|m{0.25\\linewidth}|m{0.3\\linewidth}|}\n         \n        The Model &  The Tutor &  The Instructor \\\\ \n         \n        Writing Advisor Tutor Tutor commented on papers and met one-to-one with students at the English Department Writing Center (EWC). He attended two in-class peer response sessions. &  \n        Julian is a white, senior English/Comparative Literature major who had worked in the EWC for two years, including a prior quarter as an in-class tutor. He had the most experience extensive training and experience in tutoring one-to-one and in the classroom of all the tutors. &  \n        Anne is a white, third year TA in Language and Rhetoric. She had taught two years of traditional FYC prior to this pairing. She had extensive training and experience in tutoring one-to-one for the EWC. \\\\\n         \n    \\end{tabular}\n\\end{table}\n\n\n\n# TeamTwo: Megan and Laura  \n\nTeam Two includes Megan and Laura. Megan attended class every day and worked one-to-one with students at the EWC. Megan is a white, senior Communications/English major who had been tutoring at the EWC for two years. She was planning to pursue K-12 teaching. Like all the EWC tutors (except Sam), she took a five-credit course in writing center theory and practice. Megan considered herself not the strongest writer. During her interview, she described how struggling with an English class, from which she eventually earned a 4.0, persuaded her to apply to the EWC. Having worked with her an entire summer, to me, Megan always seemed very nice (often \"bubbly\") and approachable.  \n\nLaura is a second-year TA and Chinese International student, focusing on postcolonial studies and Asian-American literature. She had one year of teaching experience with first-years prior to this pairing.  \n\n\\begin{table}[h]\n    \\centering\n    \\caption{Table 2-3: Team Two Descriptions}\n    \\begin{tabular}{|m{0.3\\textwidth}|m{0.35\\textwidth}|m{0.35\\textwidth}|}\n         \n        The Model & The Tutor & The Instructor \\\\ \n         \n        In-Class Tutor & Megan is a white, senior Communications/English major with two years tutoring in the Department Writing Center (EWC). & Laura is a second year, Chinese international grad student and TA in English Literature. She had one year of teaching experience in a traditional first-year composition (FYC) classroom prior to this pairing. \\\\\n         \n        Tutor attended class every day and worked one-to-one with students at the English Department Writing Center (EWC). & Megan is a white, senior Communications/English major with two years tutoring in the EWC. She planned to pursue K-12 teaching. Like all the EWC tutors (except Sam) she took a 5-credit course in writing center theory. & Laura is a second year, Chinese international grad student and TA in English Literature. She had one year of teaching experience in a traditional first-year composition (FYC) classroom prior to this pairing. \\\\\n         \n    \\end{tabular}\n\\end{table}\n\n\n\n# TeamThree: Madeleine and Sydney  \n\nDue to her schedule, Madeleine, from Team Three, attended class every other day and worked one-to-one with students at the IC. Madeleine is an African-American sophomore English (creative writing) major who had worked for the IC only one quarter prior to this pairing. She enjoys performing spoken-word poetry. She did not receive any formal training in one-to-one teaching prior to this pairing. She attended a college prep high school and participated in running start. Prior to this study, I was not familiar with the personality or tutoring patterns of Madeleine.  \n\nSydney, a woman of color (African-American) herself, is a second-year TA studying nineteenth- and twentieth-century African-American literature. She had about five years of teaching and tutoring experience with high school students and one year of teaching with first-years prior to this pairing. On her wish-list, Sydney had written me a note asking, if at all possible, for a tutor of color. Serendipity worked in her favor in the form of Madeleine, who I would later learn was the only IC tutor willing to participate in this study.  \n\n\\begin{table}[h]\n    \\centering\n    \\caption*{Table 2-4:Team Three descriptioins}\n    \\begin{tabular}{|c|c|c|c|c|}\n         \n        The Model & The Tor & The Disctor & Inserted & Uncertainty \\\\\n         \n    \\end{tabular}\n\\end{table}",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Sydney, a woman of color (African-American) herself, is a second-year TA studying nineteenth- and twentieth-century African-American literature. She had about five years of teaching and tutoring experience with high school students and one year of teaching with first-years prior to this pairing.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/socialsci-74973.pdf_31",
        "ID": "0934fe22-440c-4ed5-81a8-ccc35c33da30",
        "questions": "Which student was planning to pursue K-12 teaching and described struggling with an English class despite eventually earning a 4.0?",
        "answers": "Megan",
        "context": "# TeamOne: Julian and Anne  \n\nJulian, from Team One, is a white, senior English/Comparative Literature major who had worked in the EwC for two years, including a quarter as an in-class tutor with me. Julian commented minimally on papers and met one-to-one with students at the EWC. He also attended two in-class peer reviews. He has the most experience tutoring one-to-one and in the classroom of all the tutors. Having worked with Julian very closely for two years prior to this study, I found him outspoken and highly intelligent.  \n\nAnne is a white, third-year TA in English Language and Rhetoric. She had one year of teaching experience with first-years prior to this pairing. She had extensive training and experience, about five years, teaching one-to-one for the EWC and CLUE (CLUE, or the Center for Learning and Undergraduate Enrichment, is another campus student-support service that houses an evening writing center). She had also presented at several national and regional writing center and Composition and Rhetoric conferences.  \n\n\n\\begin{table}[h]\n    \\centering\n    \\caption{Table 2.2. Team One descriptions}\n    \\begin{tabular}{|m{0.3\\linewidth}|m{0.3\\linewidth}|m{0.25\\linewidth}|m{0.3\\linewidth}|}\n         \n        The Model &  The Tutor &  The Instructor \\\\ \n         \n        Writing Advisor Tutor Tutor commented on papers and met one-to-one with students at the English Department Writing Center (EWC). He attended two in-class peer response sessions. &  \n        Julian is a white, senior English/Comparative Literature major who had worked in the EWC for two years, including a prior quarter as an in-class tutor. He had the most experience extensive training and experience in tutoring one-to-one and in the classroom of all the tutors. &  \n        Anne is a white, third year TA in Language and Rhetoric. She had taught two years of traditional FYC prior to this pairing. She had extensive training and experience in tutoring one-to-one for the EWC. \\\\\n         \n    \\end{tabular}\n\\end{table}\n\n\n\n# TeamTwo: Megan and Laura  \n\nTeam Two includes Megan and Laura. Megan attended class every day and worked one-to-one with students at the EWC. Megan is a white, senior Communications/English major who had been tutoring at the EWC for two years. She was planning to pursue K-12 teaching. Like all the EWC tutors (except Sam), she took a five-credit course in writing center theory and practice. Megan considered herself not the strongest writer. During her interview, she described how struggling with an English class, from which she eventually earned a 4.0, persuaded her to apply to the EWC. Having worked with her an entire summer, to me, Megan always seemed very nice (often \"bubbly\") and approachable.  \n\nLaura is a second-year TA and Chinese International student, focusing on postcolonial studies and Asian-American literature. She had one year of teaching experience with first-years prior to this pairing.  \n\n\\begin{table}[h]\n    \\centering\n    \\caption{Table 2-3: Team Two Descriptions}\n    \\begin{tabular}{|m{0.3\\textwidth}|m{0.35\\textwidth}|m{0.35\\textwidth}|}\n         \n        The Model & The Tutor & The Instructor \\\\ \n         \n        In-Class Tutor & Megan is a white, senior Communications/English major with two years tutoring in the Department Writing Center (EWC). & Laura is a second year, Chinese international grad student and TA in English Literature. She had one year of teaching experience in a traditional first-year composition (FYC) classroom prior to this pairing. \\\\\n         \n        Tutor attended class every day and worked one-to-one with students at the English Department Writing Center (EWC). & Megan is a white, senior Communications/English major with two years tutoring in the EWC. She planned to pursue K-12 teaching. Like all the EWC tutors (except Sam) she took a 5-credit course in writing center theory. & Laura is a second year, Chinese international grad student and TA in English Literature. She had one year of teaching experience in a traditional first-year composition (FYC) classroom prior to this pairing. \\\\\n         \n    \\end{tabular}\n\\end{table}\n\n\n\n# TeamThree: Madeleine and Sydney  \n\nDue to her schedule, Madeleine, from Team Three, attended class every other day and worked one-to-one with students at the IC. Madeleine is an African-American sophomore English (creative writing) major who had worked for the IC only one quarter prior to this pairing. She enjoys performing spoken-word poetry. She did not receive any formal training in one-to-one teaching prior to this pairing. She attended a college prep high school and participated in running start. Prior to this study, I was not familiar with the personality or tutoring patterns of Madeleine.  \n\nSydney, a woman of color (African-American) herself, is a second-year TA studying nineteenth- and twentieth-century African-American literature. She had about five years of teaching and tutoring experience with high school students and one year of teaching with first-years prior to this pairing. On her wish-list, Sydney had written me a note asking, if at all possible, for a tutor of color. Serendipity worked in her favor in the form of Madeleine, who I would later learn was the only IC tutor willing to participate in this study.  \n\n\\begin{table}[h]\n    \\centering\n    \\caption*{Table 2-4:Team Three descriptioins}\n    \\begin{tabular}{|c|c|c|c|c|}\n         \n        The Model & The Tor & The Disctor & Inserted & Uncertainty \\\\\n         \n    \\end{tabular}\n\\end{table}",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Megan is a white, senior Communications/English major who had been tutoring at the EWC for two years. She was planning to pursue K-12 teaching. Megan considered herself not the strongest writer. During her interview, she described how struggling with an English class, from which she eventually earned a 4.0, persuaded her to apply to the EWC.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/[Durrett_R.]_Probability_theory_and_examples(b-ok.org).pdf_228",
        "ID": "09352795-6ef0-4999-bae8-cb671361eca3",
        "questions": "According to Theorem 4.4.4, how is the function H(t) defined?",
        "answers": "H(t)=\\int_{0}^{t}h(t-s)\\,d U(s)",
        "context": "Intuitively, this holds since Theorem 4.4.4 implies  \n\n$$\nH(t)=\\int_{0}^{t}h(t-s)\\,d U(s)\n$$  \n\nand Theorem 4.4.3 implies $d U(s)\\to d s/\\mu$ as $s\\rightarrow\\infty$. We will define directly Riemann integrable in a minute. We will start doing the proof and then figure out what we need to assume.  \n\nProof. Suppose  \n\n$$\nh(s)=\\sum_{k=0}^{\\infty}a_{k}1_{[k\\delta,(k+1)\\delta)}(s)\n$$  \n\nwhere $\\textstyle\\sum_{k=0}^{\\infty}|a_{k}|<\\infty$. Since $U([t,t+\\delta])\\leq U([0,\\delta])<\\infty,$ it follows easily from Theorem 4.4.3 that  \n\n$$\n\\int_{0}^{t}h(t-s)d U(s)=\\sum_{k=0}^{\\infty}a_{k}U((t-(k+1)\\delta,t-k\\delta])\\to\\frac{1}{\\mu}\\sum_{k=0}^{\\infty}a_{k}\\delta\n$$  \n\n(Pick $K$ so that $\\begin{array}{r}{\\sum_{k\\geq K}|a_{k}|\\leq\\epsilon/2U([0,\\delta])}\\end{array}$ and then $T$ so that  \n\n$$\n\\lvert a_{k}\\rvert\\cdot\\lvert U((t-(k+1)\\delta,t-k\\delta])-\\delta/\\mu\\rvert\\le\\frac{\\epsilon}{2K}\n$$  \n\nfor $t\\geq T$ and $0\\leq k<K$.) If $h$ is an arbitrary function on $[0,\\infty)$, we let  \n\n$$\nI^{\\delta}=\\sum_{k=0}^{\\infty}\\,\\delta\\,\\operatorname*{sup}\\{h(x):x\\in[k\\delta,(k+1)\\delta)\\}\n$$  \n\n$$\nI_{\\delta}=\\sum_{k=0}^{\\infty}\\,\\delta\\,\\operatorname*{inf}\\{h(x):x\\in[k\\delta,(k+1)\\delta)\\}\n$$  \n\nbe upper and lower Riemann sums approximating the integral of $h$ over $[0,\\infty)$. Comparing $h$ with the obvious upper and lower bounds that are constant on $[k\\delta,(k+$ $1)\\delta,$, and using the result for the special case,  \n\n$$\n{\\frac{I_{\\delta}}{\\mu}}\\leq\\operatorname*{lim}_{t\\to\\infty}\\int_{0}^{t}h(t-s)\\,d U(s)\\leq\\operatorname*{lim}_{t\\to\\infty}\\int_{0}^{t}h(t-s)\\,d U(s)\\leq{\\frac{I^{\\delta}}{\\mu}}\n$$  \n\nIf $I^{\\delta}$ and $I_{\\delta}$ both approach the same finite limit $I$ as $\\delta\\to0$, then $h$ is said to be directly Riemann integrable, and it follows that  \n\n$$\n\\int_{0}^{t}h(t-s)\\,d U(y)\\to I/\\mu\n$$  \n\nRemark. The word \u201cdirect\u201d in the name refers to the fact that although the Riemann integral over $[0,\\infty)$ is usually defined as the limit of integrals over $[0,a]$, we are approximating the integral over $[0,\\infty)$ directly.  \n\nIn checking the new hypothesis in Theorem 4.4.5, the following result is useful.  \n\nLemma 4.4.6. If $h(x)\\geq0$ is decreasing with $h(0)<\\infty$ and $\\begin{array}{r}{\\int_{0}^{\\infty}h(x)\\,d x\\,<\\,\\infty,}\\end{array}$ then $h$ is directly Riemann integrable.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Theorem 4.4.4 implies  $$ H(t)=\\int_{0}^{t}h(t-s)\\,d U(s) $$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/[Durrett_R.]_Probability_theory_and_examples(b-ok.org).pdf_228",
        "ID": "093585a3-96ce-4513-8d60-1dd36c4b30d2",
        "questions": "What is the condition under which the function h is said to be directly Riemann integrable as $\\delta$ approaches 0?",
        "answers": "If $I^{\\delta}$ and $I_{\\delta}$ both approach the same finite limit $I$ as $\\delta\to0$",
        "context": "Intuitively, this holds since Theorem 4.4.4 implies  \n\n$$\nH(t)=\\int_{0}^{t}h(t-s)\\,d U(s)\n$$  \n\nand Theorem 4.4.3 implies $d U(s)\\to d s/\\mu$ as $s\\rightarrow\\infty$. We will define directly Riemann integrable in a minute. We will start doing the proof and then figure out what we need to assume.  \n\nProof. Suppose  \n\n$$\nh(s)=\\sum_{k=0}^{\\infty}a_{k}1_{[k\\delta,(k+1)\\delta)}(s)\n$$  \n\nwhere $\\textstyle\\sum_{k=0}^{\\infty}|a_{k}|<\\infty$. Since $U([t,t+\\delta])\\leq U([0,\\delta])<\\infty,$ it follows easily from Theorem 4.4.3 that  \n\n$$\n\\int_{0}^{t}h(t-s)d U(s)=\\sum_{k=0}^{\\infty}a_{k}U((t-(k+1)\\delta,t-k\\delta])\\to\\frac{1}{\\mu}\\sum_{k=0}^{\\infty}a_{k}\\delta\n$$  \n\n(Pick $K$ so that $\\begin{array}{r}{\\sum_{k\\geq K}|a_{k}|\\leq\\epsilon/2U([0,\\delta])}\\end{array}$ and then $T$ so that  \n\n$$\n\\lvert a_{k}\\rvert\\cdot\\lvert U((t-(k+1)\\delta,t-k\\delta])-\\delta/\\mu\\rvert\\le\\frac{\\epsilon}{2K}\n$$  \n\nfor $t\\geq T$ and $0\\leq k<K$.) If $h$ is an arbitrary function on $[0,\\infty)$, we let  \n\n$$\nI^{\\delta}=\\sum_{k=0}^{\\infty}\\,\\delta\\,\\operatorname*{sup}\\{h(x):x\\in[k\\delta,(k+1)\\delta)\\}\n$$  \n\n$$\nI_{\\delta}=\\sum_{k=0}^{\\infty}\\,\\delta\\,\\operatorname*{inf}\\{h(x):x\\in[k\\delta,(k+1)\\delta)\\}\n$$  \n\nbe upper and lower Riemann sums approximating the integral of $h$ over $[0,\\infty)$. Comparing $h$ with the obvious upper and lower bounds that are constant on $[k\\delta,(k+$ $1)\\delta,$, and using the result for the special case,  \n\n$$\n{\\frac{I_{\\delta}}{\\mu}}\\leq\\operatorname*{lim}_{t\\to\\infty}\\int_{0}^{t}h(t-s)\\,d U(s)\\leq\\operatorname*{lim}_{t\\to\\infty}\\int_{0}^{t}h(t-s)\\,d U(s)\\leq{\\frac{I^{\\delta}}{\\mu}}\n$$  \n\nIf $I^{\\delta}$ and $I_{\\delta}$ both approach the same finite limit $I$ as $\\delta\\to0$, then $h$ is said to be directly Riemann integrable, and it follows that  \n\n$$\n\\int_{0}^{t}h(t-s)\\,d U(y)\\to I/\\mu\n$$  \n\nRemark. The word \u201cdirect\u201d in the name refers to the fact that although the Riemann integral over $[0,\\infty)$ is usually defined as the limit of integrals over $[0,a]$, we are approximating the integral over $[0,\\infty)$ directly.  \n\nIn checking the new hypothesis in Theorem 4.4.5, the following result is useful.  \n\nLemma 4.4.6. If $h(x)\\geq0$ is decreasing with $h(0)<\\infty$ and $\\begin{array}{r}{\\int_{0}^{\\infty}h(x)\\,d x\\,<\\,\\infty,}\\end{array}$ then $h$ is directly Riemann integrable.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "If $I^{\\delta}$ and $I_{\\delta}$ both approach the same finite limit $I$ as $\\delta\to0$, then $h$ is said to be directly Riemann integrable",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/[Durrett_R.]_Probability_theory_and_examples(b-ok.org).pdf_228",
        "ID": "093c656e-b5fa-419e-8c38-38a24b44b4f9",
        "questions": "What does Lemma 4.4.6 state about the function h(x)?",
        "answers": "If $h(x)\\geq0$ is decreasing with $h(0)<\\infty$ and $\\begin{array}{r}{\\int_{0}^{\\infty}h(x)\\,d x\\,<\\,\\infty,}\\end{array}$ then $h$ is directly Riemann integrable.",
        "context": "Intuitively, this holds since Theorem 4.4.4 implies  \n\n$$\nH(t)=\\int_{0}^{t}h(t-s)\\,d U(s)\n$$  \n\nand Theorem 4.4.3 implies $d U(s)\\to d s/\\mu$ as $s\\rightarrow\\infty$. We will define directly Riemann integrable in a minute. We will start doing the proof and then figure out what we need to assume.  \n\nProof. Suppose  \n\n$$\nh(s)=\\sum_{k=0}^{\\infty}a_{k}1_{[k\\delta,(k+1)\\delta)}(s)\n$$  \n\nwhere $\\textstyle\\sum_{k=0}^{\\infty}|a_{k}|<\\infty$. Since $U([t,t+\\delta])\\leq U([0,\\delta])<\\infty,$ it follows easily from Theorem 4.4.3 that  \n\n$$\n\\int_{0}^{t}h(t-s)d U(s)=\\sum_{k=0}^{\\infty}a_{k}U((t-(k+1)\\delta,t-k\\delta])\\to\\frac{1}{\\mu}\\sum_{k=0}^{\\infty}a_{k}\\delta\n$$  \n\n(Pick $K$ so that $\\begin{array}{r}{\\sum_{k\\geq K}|a_{k}|\\leq\\epsilon/2U([0,\\delta])}\\end{array}$ and then $T$ so that  \n\n$$\n\\lvert a_{k}\\rvert\\cdot\\lvert U((t-(k+1)\\delta,t-k\\delta])-\\delta/\\mu\\rvert\\le\\frac{\\epsilon}{2K}\n$$  \n\nfor $t\\geq T$ and $0\\leq k<K$.) If $h$ is an arbitrary function on $[0,\\infty)$, we let  \n\n$$\nI^{\\delta}=\\sum_{k=0}^{\\infty}\\,\\delta\\,\\operatorname*{sup}\\{h(x):x\\in[k\\delta,(k+1)\\delta)\\}\n$$  \n\n$$\nI_{\\delta}=\\sum_{k=0}^{\\infty}\\,\\delta\\,\\operatorname*{inf}\\{h(x):x\\in[k\\delta,(k+1)\\delta)\\}\n$$  \n\nbe upper and lower Riemann sums approximating the integral of $h$ over $[0,\\infty)$. Comparing $h$ with the obvious upper and lower bounds that are constant on $[k\\delta,(k+$ $1)\\delta,$, and using the result for the special case,  \n\n$$\n{\\frac{I_{\\delta}}{\\mu}}\\leq\\operatorname*{lim}_{t\\to\\infty}\\int_{0}^{t}h(t-s)\\,d U(s)\\leq\\operatorname*{lim}_{t\\to\\infty}\\int_{0}^{t}h(t-s)\\,d U(s)\\leq{\\frac{I^{\\delta}}{\\mu}}\n$$  \n\nIf $I^{\\delta}$ and $I_{\\delta}$ both approach the same finite limit $I$ as $\\delta\\to0$, then $h$ is said to be directly Riemann integrable, and it follows that  \n\n$$\n\\int_{0}^{t}h(t-s)\\,d U(y)\\to I/\\mu\n$$  \n\nRemark. The word \u201cdirect\u201d in the name refers to the fact that although the Riemann integral over $[0,\\infty)$ is usually defined as the limit of integrals over $[0,a]$, we are approximating the integral over $[0,\\infty)$ directly.  \n\nIn checking the new hypothesis in Theorem 4.4.5, the following result is useful.  \n\nLemma 4.4.6. If $h(x)\\geq0$ is decreasing with $h(0)<\\infty$ and $\\begin{array}{r}{\\int_{0}^{\\infty}h(x)\\,d x\\,<\\,\\infty,}\\end{array}$ then $h$ is directly Riemann integrable.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Lemma 4.4.6. If $h(x)\\geq0$ is decreasing with $h(0)<\\infty$ and \\begin{array}{r}{\\int_{0}^{\\infty}h(x)\\,d x\\,<\\,\\infty,}\\end{array}$ then $h$ is directly Riemann integrable.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/[Durrett_R.]_Probability_theory_and_examples(b-ok.org).pdf_228",
        "ID": "09449a97-fa7a-44b0-b4d1-630a3268e92b",
        "questions": "What is the expression for the function $h(s)$ in terms of the series involving $a_k$?",
        "answers": "$h(s)=\\sum_{k=0}^{\\infty}a_{k}1_{[k\\delta,(k+1)\\delta)}(s)$",
        "context": "Intuitively, this holds since Theorem 4.4.4 implies  \n\n$$\nH(t)=\\int_{0}^{t}h(t-s)\\,d U(s)\n$$  \n\nand Theorem 4.4.3 implies $d U(s)\\to d s/\\mu$ as $s\\rightarrow\\infty$. We will define directly Riemann integrable in a minute. We will start doing the proof and then figure out what we need to assume.  \n\nProof. Suppose  \n\n$$\nh(s)=\\sum_{k=0}^{\\infty}a_{k}1_{[k\\delta,(k+1)\\delta)}(s)\n$$  \n\nwhere $\\textstyle\\sum_{k=0}^{\\infty}|a_{k}|<\\infty$. Since $U([t,t+\\delta])\\leq U([0,\\delta])<\\infty,$ it follows easily from Theorem 4.4.3 that  \n\n$$\n\\int_{0}^{t}h(t-s)d U(s)=\\sum_{k=0}^{\\infty}a_{k}U((t-(k+1)\\delta,t-k\\delta])\\to\\frac{1}{\\mu}\\sum_{k=0}^{\\infty}a_{k}\\delta\n$$  \n\n(Pick $K$ so that $\\begin{array}{r}{\\sum_{k\\geq K}|a_{k}|\\leq\\epsilon/2U([0,\\delta])}\\end{array}$ and then $T$ so that  \n\n$$\n\\lvert a_{k}\\rvert\\cdot\\lvert U((t-(k+1)\\delta,t-k\\delta])-\\delta/\\mu\\rvert\\le\\frac{\\epsilon}{2K}\n$$  \n\nfor $t\\geq T$ and $0\\leq k<K$.) If $h$ is an arbitrary function on $[0,\\infty)$, we let  \n\n$$\nI^{\\delta}=\\sum_{k=0}^{\\infty}\\,\\delta\\,\\operatorname*{sup}\\{h(x):x\\in[k\\delta,(k+1)\\delta)\\}\n$$  \n\n$$\nI_{\\delta}=\\sum_{k=0}^{\\infty}\\,\\delta\\,\\operatorname*{inf}\\{h(x):x\\in[k\\delta,(k+1)\\delta)\\}\n$$  \n\nbe upper and lower Riemann sums approximating the integral of $h$ over $[0,\\infty)$. Comparing $h$ with the obvious upper and lower bounds that are constant on $[k\\delta,(k+$ $1)\\delta,$, and using the result for the special case,  \n\n$$\n{\\frac{I_{\\delta}}{\\mu}}\\leq\\operatorname*{lim}_{t\\to\\infty}\\int_{0}^{t}h(t-s)\\,d U(s)\\leq\\operatorname*{lim}_{t\\to\\infty}\\int_{0}^{t}h(t-s)\\,d U(s)\\leq{\\frac{I^{\\delta}}{\\mu}}\n$$  \n\nIf $I^{\\delta}$ and $I_{\\delta}$ both approach the same finite limit $I$ as $\\delta\\to0$, then $h$ is said to be directly Riemann integrable, and it follows that  \n\n$$\n\\int_{0}^{t}h(t-s)\\,d U(y)\\to I/\\mu\n$$  \n\nRemark. The word \u201cdirect\u201d in the name refers to the fact that although the Riemann integral over $[0,\\infty)$ is usually defined as the limit of integrals over $[0,a]$, we are approximating the integral over $[0,\\infty)$ directly.  \n\nIn checking the new hypothesis in Theorem 4.4.5, the following result is useful.  \n\nLemma 4.4.6. If $h(x)\\geq0$ is decreasing with $h(0)<\\infty$ and $\\begin{array}{r}{\\int_{0}^{\\infty}h(x)\\,d x\\,<\\,\\infty,}\\end{array}$ then $h$ is directly Riemann integrable.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$h(s)=\\sum_{k=0}^{\\infty}a_{k}1_{[k\\delta,(k+1)\\delta)}(s)$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/[Durrett_R.]_Probability_theory_and_examples(b-ok.org).pdf_228",
        "ID": "094e8d7b-68d6-49ec-af0c-09a520632407",
        "questions": "How are the upper and lower Riemann sums $I^{\\delta}$ and $I_{\\delta}$ defined for a function $h$ over $[0,\\infty)$?",
        "answers": "I^{\\delta}=\\sum_{k=0}^{\\infty}\\,\\delta\\,\\operatorname*{sup}\\{h(x):x\\in[k\\delta,(k+1)\\delta)\\}, I_{\\delta}=\\sum_{k=0}^{\\infty}\\,\\delta\\,\\operatorname*{inf}\\{h(x):x\\in[k\\delta,(k+1)\\delta)\\}",
        "context": "Intuitively, this holds since Theorem 4.4.4 implies  \n\n$$\nH(t)=\\int_{0}^{t}h(t-s)\\,d U(s)\n$$  \n\nand Theorem 4.4.3 implies $d U(s)\\to d s/\\mu$ as $s\\rightarrow\\infty$. We will define directly Riemann integrable in a minute. We will start doing the proof and then figure out what we need to assume.  \n\nProof. Suppose  \n\n$$\nh(s)=\\sum_{k=0}^{\\infty}a_{k}1_{[k\\delta,(k+1)\\delta)}(s)\n$$  \n\nwhere $\\textstyle\\sum_{k=0}^{\\infty}|a_{k}|<\\infty$. Since $U([t,t+\\delta])\\leq U([0,\\delta])<\\infty,$ it follows easily from Theorem 4.4.3 that  \n\n$$\n\\int_{0}^{t}h(t-s)d U(s)=\\sum_{k=0}^{\\infty}a_{k}U((t-(k+1)\\delta,t-k\\delta])\\to\\frac{1}{\\mu}\\sum_{k=0}^{\\infty}a_{k}\\delta\n$$  \n\n(Pick $K$ so that $\\begin{array}{r}{\\sum_{k\\geq K}|a_{k}|\\leq\\epsilon/2U([0,\\delta])}\\end{array}$ and then $T$ so that  \n\n$$\n\\lvert a_{k}\\rvert\\cdot\\lvert U((t-(k+1)\\delta,t-k\\delta])-\\delta/\\mu\\rvert\\le\\frac{\\epsilon}{2K}\n$$  \n\nfor $t\\geq T$ and $0\\leq k<K$.) If $h$ is an arbitrary function on $[0,\\infty)$, we let  \n\n$$\nI^{\\delta}=\\sum_{k=0}^{\\infty}\\,\\delta\\,\\operatorname*{sup}\\{h(x):x\\in[k\\delta,(k+1)\\delta)\\}\n$$  \n\n$$\nI_{\\delta}=\\sum_{k=0}^{\\infty}\\,\\delta\\,\\operatorname*{inf}\\{h(x):x\\in[k\\delta,(k+1)\\delta)\\}\n$$  \n\nbe upper and lower Riemann sums approximating the integral of $h$ over $[0,\\infty)$. Comparing $h$ with the obvious upper and lower bounds that are constant on $[k\\delta,(k+$ $1)\\delta,$, and using the result for the special case,  \n\n$$\n{\\frac{I_{\\delta}}{\\mu}}\\leq\\operatorname*{lim}_{t\\to\\infty}\\int_{0}^{t}h(t-s)\\,d U(s)\\leq\\operatorname*{lim}_{t\\to\\infty}\\int_{0}^{t}h(t-s)\\,d U(s)\\leq{\\frac{I^{\\delta}}{\\mu}}\n$$  \n\nIf $I^{\\delta}$ and $I_{\\delta}$ both approach the same finite limit $I$ as $\\delta\\to0$, then $h$ is said to be directly Riemann integrable, and it follows that  \n\n$$\n\\int_{0}^{t}h(t-s)\\,d U(y)\\to I/\\mu\n$$  \n\nRemark. The word \u201cdirect\u201d in the name refers to the fact that although the Riemann integral over $[0,\\infty)$ is usually defined as the limit of integrals over $[0,a]$, we are approximating the integral over $[0,\\infty)$ directly.  \n\nIn checking the new hypothesis in Theorem 4.4.5, the following result is useful.  \n\nLemma 4.4.6. If $h(x)\\geq0$ is decreasing with $h(0)<\\infty$ and $\\begin{array}{r}{\\int_{0}^{\\infty}h(x)\\,d x\\,<\\,\\infty,}\\end{array}$ then $h$ is directly Riemann integrable.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$I^{\\delta}=\\sum_{k=0}^{\\infty}\\,\\delta\\,\\operatorname*{sup}\\{h(x):x\\in[k\\delta,(k+1)\\delta)\\}$ $I_{\\delta}=\\sum_{k=0}^{\\infty}\\,\\delta\\,\\operatorname*{inf}\\{h(x):x\\in[k\\delta,(k+1)\\delta)\\}$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/[Durrett_R.]_Probability_theory_and_examples(b-ok.org).pdf_228",
        "ID": "0956b326-6af9-47d5-b619-2485c72b9b25",
        "questions": "What condition must $h$ satisfy for $h$ to be directly Riemann integrable and ensure that the integral of $h(t-s)d U(y)$ converges to $I/\\mu$?",
        "answers": "$I^{\\delta}$ and $I_{\\delta}$ both approach the same finite limit $I$ as $\\delta\\to0$",
        "context": "Intuitively, this holds since Theorem 4.4.4 implies  \n\n$$\nH(t)=\\int_{0}^{t}h(t-s)\\,d U(s)\n$$  \n\nand Theorem 4.4.3 implies $d U(s)\\to d s/\\mu$ as $s\\rightarrow\\infty$. We will define directly Riemann integrable in a minute. We will start doing the proof and then figure out what we need to assume.  \n\nProof. Suppose  \n\n$$\nh(s)=\\sum_{k=0}^{\\infty}a_{k}1_{[k\\delta,(k+1)\\delta)}(s)\n$$  \n\nwhere $\\textstyle\\sum_{k=0}^{\\infty}|a_{k}|<\\infty$. Since $U([t,t+\\delta])\\leq U([0,\\delta])<\\infty,$ it follows easily from Theorem 4.4.3 that  \n\n$$\n\\int_{0}^{t}h(t-s)d U(s)=\\sum_{k=0}^{\\infty}a_{k}U((t-(k+1)\\delta,t-k\\delta])\\to\\frac{1}{\\mu}\\sum_{k=0}^{\\infty}a_{k}\\delta\n$$  \n\n(Pick $K$ so that $\\begin{array}{r}{\\sum_{k\\geq K}|a_{k}|\\leq\\epsilon/2U([0,\\delta])}\\end{array}$ and then $T$ so that  \n\n$$\n\\lvert a_{k}\\rvert\\cdot\\lvert U((t-(k+1)\\delta,t-k\\delta])-\\delta/\\mu\\rvert\\le\\frac{\\epsilon}{2K}\n$$  \n\nfor $t\\geq T$ and $0\\leq k<K$.) If $h$ is an arbitrary function on $[0,\\infty)$, we let  \n\n$$\nI^{\\delta}=\\sum_{k=0}^{\\infty}\\,\\delta\\,\\operatorname*{sup}\\{h(x):x\\in[k\\delta,(k+1)\\delta)\\}\n$$  \n\n$$\nI_{\\delta}=\\sum_{k=0}^{\\infty}\\,\\delta\\,\\operatorname*{inf}\\{h(x):x\\in[k\\delta,(k+1)\\delta)\\}\n$$  \n\nbe upper and lower Riemann sums approximating the integral of $h$ over $[0,\\infty)$. Comparing $h$ with the obvious upper and lower bounds that are constant on $[k\\delta,(k+$ $1)\\delta,$, and using the result for the special case,  \n\n$$\n{\\frac{I_{\\delta}}{\\mu}}\\leq\\operatorname*{lim}_{t\\to\\infty}\\int_{0}^{t}h(t-s)\\,d U(s)\\leq\\operatorname*{lim}_{t\\to\\infty}\\int_{0}^{t}h(t-s)\\,d U(s)\\leq{\\frac{I^{\\delta}}{\\mu}}\n$$  \n\nIf $I^{\\delta}$ and $I_{\\delta}$ both approach the same finite limit $I$ as $\\delta\\to0$, then $h$ is said to be directly Riemann integrable, and it follows that  \n\n$$\n\\int_{0}^{t}h(t-s)\\,d U(y)\\to I/\\mu\n$$  \n\nRemark. The word \u201cdirect\u201d in the name refers to the fact that although the Riemann integral over $[0,\\infty)$ is usually defined as the limit of integrals over $[0,a]$, we are approximating the integral over $[0,\\infty)$ directly.  \n\nIn checking the new hypothesis in Theorem 4.4.5, the following result is useful.  \n\nLemma 4.4.6. If $h(x)\\geq0$ is decreasing with $h(0)<\\infty$ and $\\begin{array}{r}{\\int_{0}^{\\infty}h(x)\\,d x\\,<\\,\\infty,}\\end{array}$ then $h$ is directly Riemann integrable.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "If $I^{\\delta}$ and $I_{\\delta}$ both approach the same finite limit $I$ as $\\delta\\to0$, then $h$ is said to be directly Riemann integrable, and it follows that  $$ \\int_{0}^{t}h(t-s)\\,d U(y)\\to I/\\mu $$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/Lectures_On_Probability_Theory_And_Statistics_(1).pdf_157",
        "ID": "09584d18-42a2-48aa-a0ab-508b75f9277c",
        "questions": "What function describes the 'size' of the compact set K_t in terms of the conformal map g_t?",
        "answers": "a(K_t) = t",
        "context": "# 6 Radial SLE  \n\n# 6.1 Definitions  \n\nMotivated by the example of LERW (among others) given in the introductory chapter, we now want to find a nice way to encode growing families of compact subsets  $(K_{t}, t \\ge 0)$  of the closed unit disk that are growing from the boundary point 1 towards 0. As in the chordal case, we are in fact going to focus on the conformal geometry of the complement  $H_{t}$  of  $K_{t}$  in the unit disk  $\\mathbb{U}$. One first has to find a natural time-parametrization. It turns out to be convenient to define the conformal map  $g_{t}$  from  $H_{t}$  onto  $\\mathbb{U}$  that is normalised by  \n\n$$\ng_{t}(0) = 0 \\ \\mathrm{and} \\ g_{t}^{\\prime}(0) > 0.\n$$  \n\nNote that  $g_{t}^{\\prime}(0) \\geq 1$. This can be, for instance, derived using the fact that  $\\log g_{t}^{\\prime}(0)$  is the limit when  $\\varepsilon \\rightarrow 0$  of  $\\log(1/\\varepsilon)$  times the probability that a planar Brownian motion started from  $\\varepsilon$  hits the circle of radius  $\\varepsilon^{2}$  before exiting  $H_{t}$  (an analyst would find this justification very strange, for sure).  \n\nThen (and this is simply because, with obvious notation,  $(\\widetilde{g}_{s} \\circ g_{t})(0) = \\widetilde{g}_{s}(0) \\circ g_{t}^{\\prime}(0))$, one measures the \u201csize\u201d  $a(K_{t})$  of  $K_{t}$  via the derivative of  $g_{t}$  at the origin:  \n\n$$\ng_{t}^{\\prime}(0) = \\exp(a(t)).\n$$  \n\nHence, we will consider growing families of compact sets such that  $a(K_{t}) = t$.  \n\nSuppose now that  $(\\zeta_{t}, t \\geq 0)$  is a continuous function on the unit circle  $\\mathcal{O}\\mathbb{U}$. Define for all  $z \\in \\overline{\\mathbb{U}}$, the solution  $g_{t}(z)$  to the ODE  \n\n$$\n\\partial_{t}g_{t}(z) = -g_{t}(z) \\frac{g_{t}(z) + \\zeta_{t}}{g_{t}(z) - \\zeta_{t}}\n$$  \n\nsuch that  $g_{0}(z) = z$. This solution is well-defined up to the (possibly infinite) time  $T(z)$  defined by  \n\n$$\nT(z) = \\operatorname*{sup}\\{t > 0 : \\operatorname*{min}_{s \\in [0, t]} |g_{s}(z) - \\zeta_{s}| > 0\\}.\n$$  \n\nWe then define  \n\n$$\nK_{t} := \\{z \\in \\mathbb{U} : T(z) \\leq t\\}\n$$  \n\nand  \n\n$$\nU_{t} := \\mathbb{U} \\setminus K_{t}.\n$$  \n\nThe family  $(K_{t}, t \\ge 0)$  is called the (radial) Loewner chain associated to the driving function  $\\zeta^{-}$.  \n\nThe general statements that we described in the chordal case are also valid in this radial case. One can add one feature that has no analog in the chordal case: It is possible to estimate the Euclidean distance  $d_{t}$  from 0 to  $K_{t}$  in terms of  $a(t) = t$. Indeed, since  $U_{t}$  contains the disc  $d_{t} \\times \\mathbb{U}$, it is clear that  $g_{t}^{\\prime}(0) \\leq 1/d_{t}$. On the other hand, a classical result of the theory of",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Hence, we will consider growing families of compact sets such that a(K_t) = t.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Lectures_On_Probability_Theory_And_Statistics_(1).pdf_157",
        "ID": "095859f7-610a-42d9-84a0-1681277e68dc",
        "questions": "In the context of radial SLE, what is the normalization condition for the conformal map g_t from H_t onto the unit disk?",
        "answers": "g_t(0) = 0 and g_t'(0) > 0",
        "context": "# 6 Radial SLE  \n\n# 6.1 Definitions  \n\nMotivated by the example of LERW (among others) given in the introductory chapter, we now want to find a nice way to encode growing families of compact subsets  $(K_{t}, t \\ge 0)$  of the closed unit disk that are growing from the boundary point 1 towards 0. As in the chordal case, we are in fact going to focus on the conformal geometry of the complement  $H_{t}$  of  $K_{t}$  in the unit disk  $\\mathbb{U}$. One first has to find a natural time-parametrization. It turns out to be convenient to define the conformal map  $g_{t}$  from  $H_{t}$  onto  $\\mathbb{U}$  that is normalised by  \n\n$$\ng_{t}(0) = 0 \\ \\mathrm{and} \\ g_{t}^{\\prime}(0) > 0.\n$$  \n\nNote that  $g_{t}^{\\prime}(0) \\geq 1$. This can be, for instance, derived using the fact that  $\\log g_{t}^{\\prime}(0)$  is the limit when  $\\varepsilon \\rightarrow 0$  of  $\\log(1/\\varepsilon)$  times the probability that a planar Brownian motion started from  $\\varepsilon$  hits the circle of radius  $\\varepsilon^{2}$  before exiting  $H_{t}$  (an analyst would find this justification very strange, for sure).  \n\nThen (and this is simply because, with obvious notation,  $(\\widetilde{g}_{s} \\circ g_{t})(0) = \\widetilde{g}_{s}(0) \\circ g_{t}^{\\prime}(0))$, one measures the \u201csize\u201d  $a(K_{t})$  of  $K_{t}$  via the derivative of  $g_{t}$  at the origin:  \n\n$$\ng_{t}^{\\prime}(0) = \\exp(a(t)).\n$$  \n\nHence, we will consider growing families of compact sets such that  $a(K_{t}) = t$.  \n\nSuppose now that  $(\\zeta_{t}, t \\geq 0)$  is a continuous function on the unit circle  $\\mathcal{O}\\mathbb{U}$. Define for all  $z \\in \\overline{\\mathbb{U}}$, the solution  $g_{t}(z)$  to the ODE  \n\n$$\n\\partial_{t}g_{t}(z) = -g_{t}(z) \\frac{g_{t}(z) + \\zeta_{t}}{g_{t}(z) - \\zeta_{t}}\n$$  \n\nsuch that  $g_{0}(z) = z$. This solution is well-defined up to the (possibly infinite) time  $T(z)$  defined by  \n\n$$\nT(z) = \\operatorname*{sup}\\{t > 0 : \\operatorname*{min}_{s \\in [0, t]} |g_{s}(z) - \\zeta_{s}| > 0\\}.\n$$  \n\nWe then define  \n\n$$\nK_{t} := \\{z \\in \\mathbb{U} : T(z) \\leq t\\}\n$$  \n\nand  \n\n$$\nU_{t} := \\mathbb{U} \\setminus K_{t}.\n$$  \n\nThe family  $(K_{t}, t \\ge 0)$  is called the (radial) Loewner chain associated to the driving function  $\\zeta^{-}$.  \n\nThe general statements that we described in the chordal case are also valid in this radial case. One can add one feature that has no analog in the chordal case: It is possible to estimate the Euclidean distance  $d_{t}$  from 0 to  $K_{t}$  in terms of  $a(t) = t$. Indeed, since  $U_{t}$  contains the disc  $d_{t} \\times \\mathbb{U}$, it is clear that  $g_{t}^{\\prime}(0) \\leq 1/d_{t}$. On the other hand, a classical result of the theory of",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "It turns out to be convenient to define the conformal map g_t from H_t onto \u2133 that is normalised by g_t(0) = 0 \\mathrm{and} g_t'(0) > 0.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Lectures_On_Probability_Theory_And_Statistics_(1).pdf_157",
        "ID": "095fb252-e683-4156-87f3-11b5b2759630",
        "questions": "What is the ODE that defines the solution g_t(z) such that g_0(z) = z in the radial SLE?",
        "answers": "\u2202_t g_t(z) = -g_t(z) (g_t(z) + \u03b6_t) / (g_t(z) - \u03b6_t)",
        "context": "# 6 Radial SLE  \n\n# 6.1 Definitions  \n\nMotivated by the example of LERW (among others) given in the introductory chapter, we now want to find a nice way to encode growing families of compact subsets  $(K_{t}, t \\ge 0)$  of the closed unit disk that are growing from the boundary point 1 towards 0. As in the chordal case, we are in fact going to focus on the conformal geometry of the complement  $H_{t}$  of  $K_{t}$  in the unit disk  $\\mathbb{U}$. One first has to find a natural time-parametrization. It turns out to be convenient to define the conformal map  $g_{t}$  from  $H_{t}$  onto  $\\mathbb{U}$  that is normalised by  \n\n$$\ng_{t}(0) = 0 \\ \\mathrm{and} \\ g_{t}^{\\prime}(0) > 0.\n$$  \n\nNote that  $g_{t}^{\\prime}(0) \\geq 1$. This can be, for instance, derived using the fact that  $\\log g_{t}^{\\prime}(0)$  is the limit when  $\\varepsilon \\rightarrow 0$  of  $\\log(1/\\varepsilon)$  times the probability that a planar Brownian motion started from  $\\varepsilon$  hits the circle of radius  $\\varepsilon^{2}$  before exiting  $H_{t}$  (an analyst would find this justification very strange, for sure).  \n\nThen (and this is simply because, with obvious notation,  $(\\widetilde{g}_{s} \\circ g_{t})(0) = \\widetilde{g}_{s}(0) \\circ g_{t}^{\\prime}(0))$, one measures the \u201csize\u201d  $a(K_{t})$  of  $K_{t}$  via the derivative of  $g_{t}$  at the origin:  \n\n$$\ng_{t}^{\\prime}(0) = \\exp(a(t)).\n$$  \n\nHence, we will consider growing families of compact sets such that  $a(K_{t}) = t$.  \n\nSuppose now that  $(\\zeta_{t}, t \\geq 0)$  is a continuous function on the unit circle  $\\mathcal{O}\\mathbb{U}$. Define for all  $z \\in \\overline{\\mathbb{U}}$, the solution  $g_{t}(z)$  to the ODE  \n\n$$\n\\partial_{t}g_{t}(z) = -g_{t}(z) \\frac{g_{t}(z) + \\zeta_{t}}{g_{t}(z) - \\zeta_{t}}\n$$  \n\nsuch that  $g_{0}(z) = z$. This solution is well-defined up to the (possibly infinite) time  $T(z)$  defined by  \n\n$$\nT(z) = \\operatorname*{sup}\\{t > 0 : \\operatorname*{min}_{s \\in [0, t]} |g_{s}(z) - \\zeta_{s}| > 0\\}.\n$$  \n\nWe then define  \n\n$$\nK_{t} := \\{z \\in \\mathbb{U} : T(z) \\leq t\\}\n$$  \n\nand  \n\n$$\nU_{t} := \\mathbb{U} \\setminus K_{t}.\n$$  \n\nThe family  $(K_{t}, t \\ge 0)$  is called the (radial) Loewner chain associated to the driving function  $\\zeta^{-}$.  \n\nThe general statements that we described in the chordal case are also valid in this radial case. One can add one feature that has no analog in the chordal case: It is possible to estimate the Euclidean distance  $d_{t}$  from 0 to  $K_{t}$  in terms of  $a(t) = t$. Indeed, since  $U_{t}$  contains the disc  $d_{t} \\times \\mathbb{U}$, it is clear that  $g_{t}^{\\prime}(0) \\leq 1/d_{t}$. On the other hand, a classical result of the theory of",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Define for all z \u2208  \u2133, the solution g_t(z) to the ODE \u2202_t g_t(z) = -g_t(z) suppose now that \u03b6)",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Lectures_On_Probability_Theory_And_Statistics_(1).pdf_157",
        "ID": "09650fe0-d5df-4c49-9942-69b4dd60375a",
        "questions": "In Radial SLE, what is the relationship between the derivative of the conformal map $g_{t}$ at the origin and the size of $K_{t}$?",
        "answers": "$g_{t}^{\\prime}(0) = \\exp(a(t))$",
        "context": "# 6 Radial SLE  \n\n# 6.1 Definitions  \n\nMotivated by the example of LERW (among others) given in the introductory chapter, we now want to find a nice way to encode growing families of compact subsets  $(K_{t}, t \\ge 0)$  of the closed unit disk that are growing from the boundary point 1 towards 0. As in the chordal case, we are in fact going to focus on the conformal geometry of the complement  $H_{t}$  of  $K_{t}$  in the unit disk  $\\mathbb{U}$. One first has to find a natural time-parametrization. It turns out to be convenient to define the conformal map  $g_{t}$  from  $H_{t}$  onto  $\\mathbb{U}$  that is normalised by  \n\n$$\ng_{t}(0) = 0 \\ \\mathrm{and} \\ g_{t}^{\\prime}(0) > 0.\n$$  \n\nNote that  $g_{t}^{\\prime}(0) \\geq 1$. This can be, for instance, derived using the fact that  $\\log g_{t}^{\\prime}(0)$  is the limit when  $\\varepsilon \\rightarrow 0$  of  $\\log(1/\\varepsilon)$  times the probability that a planar Brownian motion started from  $\\varepsilon$  hits the circle of radius  $\\varepsilon^{2}$  before exiting  $H_{t}$  (an analyst would find this justification very strange, for sure).  \n\nThen (and this is simply because, with obvious notation,  $(\\widetilde{g}_{s} \\circ g_{t})(0) = \\widetilde{g}_{s}(0) \\circ g_{t}^{\\prime}(0))$, one measures the \u201csize\u201d  $a(K_{t})$  of  $K_{t}$  via the derivative of  $g_{t}$  at the origin:  \n\n$$\ng_{t}^{\\prime}(0) = \\exp(a(t)).\n$$  \n\nHence, we will consider growing families of compact sets such that  $a(K_{t}) = t$.  \n\nSuppose now that  $(\\zeta_{t}, t \\geq 0)$  is a continuous function on the unit circle  $\\mathcal{O}\\mathbb{U}$. Define for all  $z \\in \\overline{\\mathbb{U}}$, the solution  $g_{t}(z)$  to the ODE  \n\n$$\n\\partial_{t}g_{t}(z) = -g_{t}(z) \\frac{g_{t}(z) + \\zeta_{t}}{g_{t}(z) - \\zeta_{t}}\n$$  \n\nsuch that  $g_{0}(z) = z$. This solution is well-defined up to the (possibly infinite) time  $T(z)$  defined by  \n\n$$\nT(z) = \\operatorname*{sup}\\{t > 0 : \\operatorname*{min}_{s \\in [0, t]} |g_{s}(z) - \\zeta_{s}| > 0\\}.\n$$  \n\nWe then define  \n\n$$\nK_{t} := \\{z \\in \\mathbb{U} : T(z) \\leq t\\}\n$$  \n\nand  \n\n$$\nU_{t} := \\mathbb{U} \\setminus K_{t}.\n$$  \n\nThe family  $(K_{t}, t \\ge 0)$  is called the (radial) Loewner chain associated to the driving function  $\\zeta^{-}$.  \n\nThe general statements that we described in the chordal case are also valid in this radial case. One can add one feature that has no analog in the chordal case: It is possible to estimate the Euclidean distance  $d_{t}$  from 0 to  $K_{t}$  in terms of  $a(t) = t$. Indeed, since  $U_{t}$  contains the disc  $d_{t} \\times \\mathbb{U}$, it is clear that  $g_{t}^{\\prime}(0) \\leq 1/d_{t}$. On the other hand, a classical result of the theory of",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "one measures the \u201csize\u201d $a(K_{t})$ of $K_{t}$ via the derivative of $g_{t}$ at the origin: $g_{t}^{\\prime}(0) = \\exp(a(t))$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/Lectures_On_Probability_Theory_And_Statistics_(1).pdf_157",
        "ID": "096b03e6-21a4-4722-a253-00a248d44211",
        "questions": "In the context of Radial SLE, what is the differential equation governing the conformal map $g_{t}(z)$ for a driving function $(\\zeta_{t}, t \\geq 0)$?",
        "answers": "$\\partial_{t}g_{t}(z) = -g_{t}(z) \frac{g_{t}(z) + \\zeta_{t}}{g_{t}(z) - \\zeta_{t}}$",
        "context": "# 6 Radial SLE  \n\n# 6.1 Definitions  \n\nMotivated by the example of LERW (among others) given in the introductory chapter, we now want to find a nice way to encode growing families of compact subsets  $(K_{t}, t \\ge 0)$  of the closed unit disk that are growing from the boundary point 1 towards 0. As in the chordal case, we are in fact going to focus on the conformal geometry of the complement  $H_{t}$  of  $K_{t}$  in the unit disk  $\\mathbb{U}$. One first has to find a natural time-parametrization. It turns out to be convenient to define the conformal map  $g_{t}$  from  $H_{t}$  onto  $\\mathbb{U}$  that is normalised by  \n\n$$\ng_{t}(0) = 0 \\ \\mathrm{and} \\ g_{t}^{\\prime}(0) > 0.\n$$  \n\nNote that  $g_{t}^{\\prime}(0) \\geq 1$. This can be, for instance, derived using the fact that  $\\log g_{t}^{\\prime}(0)$  is the limit when  $\\varepsilon \\rightarrow 0$  of  $\\log(1/\\varepsilon)$  times the probability that a planar Brownian motion started from  $\\varepsilon$  hits the circle of radius  $\\varepsilon^{2}$  before exiting  $H_{t}$  (an analyst would find this justification very strange, for sure).  \n\nThen (and this is simply because, with obvious notation,  $(\\widetilde{g}_{s} \\circ g_{t})(0) = \\widetilde{g}_{s}(0) \\circ g_{t}^{\\prime}(0))$, one measures the \u201csize\u201d  $a(K_{t})$  of  $K_{t}$  via the derivative of  $g_{t}$  at the origin:  \n\n$$\ng_{t}^{\\prime}(0) = \\exp(a(t)).\n$$  \n\nHence, we will consider growing families of compact sets such that  $a(K_{t}) = t$.  \n\nSuppose now that  $(\\zeta_{t}, t \\geq 0)$  is a continuous function on the unit circle  $\\mathcal{O}\\mathbb{U}$. Define for all  $z \\in \\overline{\\mathbb{U}}$, the solution  $g_{t}(z)$  to the ODE  \n\n$$\n\\partial_{t}g_{t}(z) = -g_{t}(z) \\frac{g_{t}(z) + \\zeta_{t}}{g_{t}(z) - \\zeta_{t}}\n$$  \n\nsuch that  $g_{0}(z) = z$. This solution is well-defined up to the (possibly infinite) time  $T(z)$  defined by  \n\n$$\nT(z) = \\operatorname*{sup}\\{t > 0 : \\operatorname*{min}_{s \\in [0, t]} |g_{s}(z) - \\zeta_{s}| > 0\\}.\n$$  \n\nWe then define  \n\n$$\nK_{t} := \\{z \\in \\mathbb{U} : T(z) \\leq t\\}\n$$  \n\nand  \n\n$$\nU_{t} := \\mathbb{U} \\setminus K_{t}.\n$$  \n\nThe family  $(K_{t}, t \\ge 0)$  is called the (radial) Loewner chain associated to the driving function  $\\zeta^{-}$.  \n\nThe general statements that we described in the chordal case are also valid in this radial case. One can add one feature that has no analog in the chordal case: It is possible to estimate the Euclidean distance  $d_{t}$  from 0 to  $K_{t}$  in terms of  $a(t) = t$. Indeed, since  $U_{t}$  contains the disc  $d_{t} \\times \\mathbb{U}$, it is clear that  $g_{t}^{\\prime}(0) \\leq 1/d_{t}$. On the other hand, a classical result of the theory of",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Define for all $z \\in \\overline{\\mathbb{U}}$, the solution $g_{t}(z)$ to the ODE $\\partial_{t}g_{t}(z) = -g_{t}(z) \frac{g_{t}(z) + \\zeta_{t}}{g_{t}(z) - \\zeta_{t}}$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/Lectures_On_Probability_Theory_And_Statistics_(1).pdf_157",
        "ID": "09748216-8ca5-4731-b124-3f80cfedf631",
        "questions": "How is the supremum $T(z)$ defined in Radial SLE for a point $z$ in $\\mathbb{U}$ given the driving function $(\\zeta_{t}, t \\geq 0)$?",
        "answers": "T(z) = \\operatorname*{sup}\\{t > 0 : \\operatorname*{min}_{s \\in [0, t]} |g_{s}(z) - \\zeta_{s}| > 0\\}",
        "context": "# 6 Radial SLE  \n\n# 6.1 Definitions  \n\nMotivated by the example of LERW (among others) given in the introductory chapter, we now want to find a nice way to encode growing families of compact subsets  $(K_{t}, t \\ge 0)$  of the closed unit disk that are growing from the boundary point 1 towards 0. As in the chordal case, we are in fact going to focus on the conformal geometry of the complement  $H_{t}$  of  $K_{t}$  in the unit disk  $\\mathbb{U}$. One first has to find a natural time-parametrization. It turns out to be convenient to define the conformal map  $g_{t}$  from  $H_{t}$  onto  $\\mathbb{U}$  that is normalised by  \n\n$$\ng_{t}(0) = 0 \\ \\mathrm{and} \\ g_{t}^{\\prime}(0) > 0.\n$$  \n\nNote that  $g_{t}^{\\prime}(0) \\geq 1$. This can be, for instance, derived using the fact that  $\\log g_{t}^{\\prime}(0)$  is the limit when  $\\varepsilon \\rightarrow 0$  of  $\\log(1/\\varepsilon)$  times the probability that a planar Brownian motion started from  $\\varepsilon$  hits the circle of radius  $\\varepsilon^{2}$  before exiting  $H_{t}$  (an analyst would find this justification very strange, for sure).  \n\nThen (and this is simply because, with obvious notation,  $(\\widetilde{g}_{s} \\circ g_{t})(0) = \\widetilde{g}_{s}(0) \\circ g_{t}^{\\prime}(0))$, one measures the \u201csize\u201d  $a(K_{t})$  of  $K_{t}$  via the derivative of  $g_{t}$  at the origin:  \n\n$$\ng_{t}^{\\prime}(0) = \\exp(a(t)).\n$$  \n\nHence, we will consider growing families of compact sets such that  $a(K_{t}) = t$.  \n\nSuppose now that  $(\\zeta_{t}, t \\geq 0)$  is a continuous function on the unit circle  $\\mathcal{O}\\mathbb{U}$. Define for all  $z \\in \\overline{\\mathbb{U}}$, the solution  $g_{t}(z)$  to the ODE  \n\n$$\n\\partial_{t}g_{t}(z) = -g_{t}(z) \\frac{g_{t}(z) + \\zeta_{t}}{g_{t}(z) - \\zeta_{t}}\n$$  \n\nsuch that  $g_{0}(z) = z$. This solution is well-defined up to the (possibly infinite) time  $T(z)$  defined by  \n\n$$\nT(z) = \\operatorname*{sup}\\{t > 0 : \\operatorname*{min}_{s \\in [0, t]} |g_{s}(z) - \\zeta_{s}| > 0\\}.\n$$  \n\nWe then define  \n\n$$\nK_{t} := \\{z \\in \\mathbb{U} : T(z) \\leq t\\}\n$$  \n\nand  \n\n$$\nU_{t} := \\mathbb{U} \\setminus K_{t}.\n$$  \n\nThe family  $(K_{t}, t \\ge 0)$  is called the (radial) Loewner chain associated to the driving function  $\\zeta^{-}$.  \n\nThe general statements that we described in the chordal case are also valid in this radial case. One can add one feature that has no analog in the chordal case: It is possible to estimate the Euclidean distance  $d_{t}$  from 0 to  $K_{t}$  in terms of  $a(t) = t$. Indeed, since  $U_{t}$  contains the disc  $d_{t} \\times \\mathbb{U}$, it is clear that  $g_{t}^{\\prime}(0) \\leq 1/d_{t}$. On the other hand, a classical result of the theory of",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "This solution is well-defined up to the (possibly infinite) time $T(z)$ defined by $T(z) = \\operatorname*{sup}\\{t > 0 : \\operatorname*{min}_{s \\in [0, t]} |g_{s}(z) - \\zeta_{s}| > 0\\}",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/GTM170-Sheaf_Theory1997.pdf_296",
        "ID": "0982e050-9c9a-4e13-951d-43c326cbfc7b",
        "questions": "What condition must a flabby cosheaf $\\mathfrak{A}$ satisfy to be torsion-free according to Proposition 1.8?",
        "answers": "$|m s|=|s|$ for all $s\\,\\in\\,{\\mathfrak{A}}(X)$ and all $0\\,\neq\\,m\\,\\in\\,L$",
        "context": "Proof. By Exercise 3 it suffices to show that\n\n$$\n\\Gamma_{c}(\\mathcal{L}|U\\cap V)\\to\\Gamma_{c}(\\mathcal{L}|U)\\oplus\\Gamma_{c}(\\mathcal{L}|V)\\to\\Gamma_{c}(\\mathcal{L}|U\\cup V)\\to0\n$$\n\nis exact for $U, V$ open, since part (b) of that exercise clearly holds for\n\n$\\mathfrak{A}=\\Gamma_{c}\\mathcal{L}$. But this follows from the Mayer-Vietoris sequence (27) on page\n\n94. \u53e3\n\nNow we wish to prove the converse of 1.6. Let $\\mathfrak{A}$ be a flabby cosheaf and let $A$ be the presheaf defined by $A(U)=\\mathfrak{A}(X)/\\mathfrak{A}_{X-U}(X)$, where\n\n$$\n\\boxed{\\mathfrak{A}_{B}(X)=\\{s\\in\\mathfrak{A}(X)\\,|\\,|s|\\subset B\\}.}\n$$\n\nLet $\\mathcal{A}=\\mathcal{A}\\!e a\\!f(A)$. Note that\n\n$$\n{\\mathcal{A}}_{x}={\\mathfrak{A}}(X)/{\\mathfrak{A}}_{X-\\{x\\}}(X).\n$$\n\nThere is the canonical map\n\n$$\n{\\boxed{\\theta:{\\mathfrak{A}}(X)\\to{\\mathcal{A}}(X).}}\n$$\n\nClearly, $\\theta(s)(x)=0\\Leftrightarrow|s|\\subset X-\\{x\\}$. Thus $|\\theta(s)|=|s|$ and in particular $\\theta$ maps ${\\mathfrak{A}}(X)$ into $\\Gamma_{c}(\\mathcal{A})$ monomorphically. We shall show that $\\theta$ maps onto $\\Gamma_{c}(x)$\n\n$\n\n1.7. Lemma. Let $U\\subset X$ be open and let $t\\in{\\mathcal{A}}(U)$. Suppose that $s^{1}, s^{2}\\in\\mathfrak{A}(X)$ are given such that $\\theta(s_{1})|U_{i}\\;=\\;t|U_{i}$ for some open sets $U_{i}\\subset U$, $i=1, 2$. If $V_{i}$ is any open set with closure in $U_{i}$, $i=1, 2$, then there exists an element $s\\in\\mathfrak{A}(X)$ such that $\\theta(s)|\\big(V_{1}\\cup V_{2}\\big)=t|\\big(V_{1}\\cup V_{2}\\big)$.\n\nProof. Since $|s_{1}-s_{2}|\\,=\\,|\\theta(s_{1}-s_{2})|\\,=\\,|\\theta(s_{1})\\,-\\,\\theta(s_{2})|$ is contained in $X-\\left(U_{1}\\cap U_{2}\\right)$, it is also contained in $(X-{\\overline{{V}}}_{1})\\cup(X-{\\overline{{V}}}_{2})$. Since $\\mathfrak{A}$ is a cosheaf, there exist elements $t_{i}\\in\\mathfrak{A}(X),\\,i=1, 2$, with $\\left|t_{i}\\right|\\subset X-{\\overline{{V}}}_{i}$ and with $s_{1}-s_{2}=t_{1}-t_{2}$. Let $s=s_{1}-t_{1}=s_{2}-t_{2}$. Then\n\n$$\n\\theta(s)|V_{i}=\\theta(s_{i})|V_{i}=t|V_{i},\n$$\n\nfor $i=1, 2$, as claimed.\n\n1.8. Proposition. Every flabby cosheaf $\\mathfrak{A}$ has the form ${\\mathfrak{A}}=\\Gamma_{c}{\\mathfrak{A}}$ for a unique c-soft sheaf $\\mathcal{A}$. Moreover, the sheaf $\\mathcal{A}$ is torsion-free $\\Leftrightarrow|m s|=|s|$ for all $s\\,\\in\\,{\\mathfrak{A}}(X)$ and all $0\\,\\neq\\,m\\,\\in\\,L$. (In this case, we say that $\\mathfrak{A}$ is \"torsion-free\".)",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Moreover, the sheaf $\\mathcal{A}$ is torsion-free $\\Leftrightarrow|m s|=|s|$ for all $s\\,\\in\\,{\\mathfrak{A}}(X)$ and all $0\\,\neq\\,m\\,\\in\\,L$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM170-Sheaf_Theory1997.pdf_296",
        "ID": "0984447f-2c5f-4d55-a777-592e6f599e20",
        "questions": "In Lemma 1.7, what does the map $\theta(s_1)$ satisfy with respect to open sets $U_i$?",
        "answers": "$\\theta(s_{1})|U_{i}\\;=\\;t|U_{i}$",
        "context": "Proof. By Exercise 3 it suffices to show that\n\n$$\n\\Gamma_{c}(\\mathcal{L}|U\\cap V)\\to\\Gamma_{c}(\\mathcal{L}|U)\\oplus\\Gamma_{c}(\\mathcal{L}|V)\\to\\Gamma_{c}(\\mathcal{L}|U\\cup V)\\to0\n$$\n\nis exact for $U, V$ open, since part (b) of that exercise clearly holds for\n\n$\\mathfrak{A}=\\Gamma_{c}\\mathcal{L}$. But this follows from the Mayer-Vietoris sequence (27) on page\n\n94. \u53e3\n\nNow we wish to prove the converse of 1.6. Let $\\mathfrak{A}$ be a flabby cosheaf and let $A$ be the presheaf defined by $A(U)=\\mathfrak{A}(X)/\\mathfrak{A}_{X-U}(X)$, where\n\n$$\n\\boxed{\\mathfrak{A}_{B}(X)=\\{s\\in\\mathfrak{A}(X)\\,|\\,|s|\\subset B\\}.}\n$$\n\nLet $\\mathcal{A}=\\mathcal{A}\\!e a\\!f(A)$. Note that\n\n$$\n{\\mathcal{A}}_{x}={\\mathfrak{A}}(X)/{\\mathfrak{A}}_{X-\\{x\\}}(X).\n$$\n\nThere is the canonical map\n\n$$\n{\\boxed{\\theta:{\\mathfrak{A}}(X)\\to{\\mathcal{A}}(X).}}\n$$\n\nClearly, $\\theta(s)(x)=0\\Leftrightarrow|s|\\subset X-\\{x\\}$. Thus $|\\theta(s)|=|s|$ and in particular $\\theta$ maps ${\\mathfrak{A}}(X)$ into $\\Gamma_{c}(\\mathcal{A})$ monomorphically. We shall show that $\\theta$ maps onto $\\Gamma_{c}(x)$\n\n$\n\n1.7. Lemma. Let $U\\subset X$ be open and let $t\\in{\\mathcal{A}}(U)$. Suppose that $s^{1}, s^{2}\\in\\mathfrak{A}(X)$ are given such that $\\theta(s_{1})|U_{i}\\;=\\;t|U_{i}$ for some open sets $U_{i}\\subset U$, $i=1, 2$. If $V_{i}$ is any open set with closure in $U_{i}$, $i=1, 2$, then there exists an element $s\\in\\mathfrak{A}(X)$ such that $\\theta(s)|\\big(V_{1}\\cup V_{2}\\big)=t|\\big(V_{1}\\cup V_{2}\\big)$.\n\nProof. Since $|s_{1}-s_{2}|\\,=\\,|\\theta(s_{1}-s_{2})|\\,=\\,|\\theta(s_{1})\\,-\\,\\theta(s_{2})|$ is contained in $X-\\left(U_{1}\\cap U_{2}\\right)$, it is also contained in $(X-{\\overline{{V}}}_{1})\\cup(X-{\\overline{{V}}}_{2})$. Since $\\mathfrak{A}$ is a cosheaf, there exist elements $t_{i}\\in\\mathfrak{A}(X),\\,i=1, 2$, with $\\left|t_{i}\\right|\\subset X-{\\overline{{V}}}_{i}$ and with $s_{1}-s_{2}=t_{1}-t_{2}$. Let $s=s_{1}-t_{1}=s_{2}-t_{2}$. Then\n\n$$\n\\theta(s)|V_{i}=\\theta(s_{i})|V_{i}=t|V_{i},\n$$\n\nfor $i=1, 2$, as claimed.\n\n1.8. Proposition. Every flabby cosheaf $\\mathfrak{A}$ has the form ${\\mathfrak{A}}=\\Gamma_{c}{\\mathfrak{A}}$ for a unique c-soft sheaf $\\mathcal{A}$. Moreover, the sheaf $\\mathcal{A}$ is torsion-free $\\Leftrightarrow|m s|=|s|$ for all $s\\,\\in\\,{\\mathfrak{A}}(X)$ and all $0\\,\\neq\\,m\\,\\in\\,L$. (In this case, we say that $\\mathfrak{A}$ is \"torsion-free\".)",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Suppose that $s^{1}, s^{2}\\in\\mathfrak{A}(X)$ are given such that $\theta(s_{1})|U_{i}\\;=\\;t|U_{i}$ for some open sets $U_{i}\\subset U$, $i=1, 2$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM170-Sheaf_Theory1997.pdf_296",
        "ID": "098d49b6-3edb-4746-a118-32cc4ae40aa0",
        "questions": "For which mathematical object does the document state, 'Clearly, $\theta$ maps it into $\\Gamma_{c}(\\mathcal{A})$ monomorphically'?",
        "answers": "${\\mathfrak{A}}(X)$",
        "context": "Proof. By Exercise 3 it suffices to show that\n\n$$\n\\Gamma_{c}(\\mathcal{L}|U\\cap V)\\to\\Gamma_{c}(\\mathcal{L}|U)\\oplus\\Gamma_{c}(\\mathcal{L}|V)\\to\\Gamma_{c}(\\mathcal{L}|U\\cup V)\\to0\n$$\n\nis exact for $U, V$ open, since part (b) of that exercise clearly holds for\n\n$\\mathfrak{A}=\\Gamma_{c}\\mathcal{L}$. But this follows from the Mayer-Vietoris sequence (27) on page\n\n94. \u53e3\n\nNow we wish to prove the converse of 1.6. Let $\\mathfrak{A}$ be a flabby cosheaf and let $A$ be the presheaf defined by $A(U)=\\mathfrak{A}(X)/\\mathfrak{A}_{X-U}(X)$, where\n\n$$\n\\boxed{\\mathfrak{A}_{B}(X)=\\{s\\in\\mathfrak{A}(X)\\,|\\,|s|\\subset B\\}.}\n$$\n\nLet $\\mathcal{A}=\\mathcal{A}\\!e a\\!f(A)$. Note that\n\n$$\n{\\mathcal{A}}_{x}={\\mathfrak{A}}(X)/{\\mathfrak{A}}_{X-\\{x\\}}(X).\n$$\n\nThere is the canonical map\n\n$$\n{\\boxed{\\theta:{\\mathfrak{A}}(X)\\to{\\mathcal{A}}(X).}}\n$$\n\nClearly, $\\theta(s)(x)=0\\Leftrightarrow|s|\\subset X-\\{x\\}$. Thus $|\\theta(s)|=|s|$ and in particular $\\theta$ maps ${\\mathfrak{A}}(X)$ into $\\Gamma_{c}(\\mathcal{A})$ monomorphically. We shall show that $\\theta$ maps onto $\\Gamma_{c}(x)$\n\n$\n\n1.7. Lemma. Let $U\\subset X$ be open and let $t\\in{\\mathcal{A}}(U)$. Suppose that $s^{1}, s^{2}\\in\\mathfrak{A}(X)$ are given such that $\\theta(s_{1})|U_{i}\\;=\\;t|U_{i}$ for some open sets $U_{i}\\subset U$, $i=1, 2$. If $V_{i}$ is any open set with closure in $U_{i}$, $i=1, 2$, then there exists an element $s\\in\\mathfrak{A}(X)$ such that $\\theta(s)|\\big(V_{1}\\cup V_{2}\\big)=t|\\big(V_{1}\\cup V_{2}\\big)$.\n\nProof. Since $|s_{1}-s_{2}|\\,=\\,|\\theta(s_{1}-s_{2})|\\,=\\,|\\theta(s_{1})\\,-\\,\\theta(s_{2})|$ is contained in $X-\\left(U_{1}\\cap U_{2}\\right)$, it is also contained in $(X-{\\overline{{V}}}_{1})\\cup(X-{\\overline{{V}}}_{2})$. Since $\\mathfrak{A}$ is a cosheaf, there exist elements $t_{i}\\in\\mathfrak{A}(X),\\,i=1, 2$, with $\\left|t_{i}\\right|\\subset X-{\\overline{{V}}}_{i}$ and with $s_{1}-s_{2}=t_{1}-t_{2}$. Let $s=s_{1}-t_{1}=s_{2}-t_{2}$. Then\n\n$$\n\\theta(s)|V_{i}=\\theta(s_{i})|V_{i}=t|V_{i},\n$$\n\nfor $i=1, 2$, as claimed.\n\n1.8. Proposition. Every flabby cosheaf $\\mathfrak{A}$ has the form ${\\mathfrak{A}}=\\Gamma_{c}{\\mathfrak{A}}$ for a unique c-soft sheaf $\\mathcal{A}$. Moreover, the sheaf $\\mathcal{A}$ is torsion-free $\\Leftrightarrow|m s|=|s|$ for all $s\\,\\in\\,{\\mathfrak{A}}(X)$ and all $0\\,\\neq\\,m\\,\\in\\,L$. (In this case, we say that $\\mathfrak{A}$ is \"torsion-free\".)",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Thus $|\\theta(s)|=|s|$ and in particular $\\theta$ maps ${\\mathfrak{A}}(X)$ into $\\Gamma_{c}(\\mathcal{A})$ monomorphically.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM170-Sheaf_Theory1997.pdf_296",
        "ID": "09a024d4-31ce-4830-99ce-734e5998e86e",
        "questions": "What is the exact sequence involving sections $\\Gamma_c(\\mathcal{L})$ over open sets $U$ and $V$?",
        "answers": "$\\Gamma_{c}(\\mathcal{L}|U\\cap V)\\to\\Gamma_{c}(\\mathcal{L}|U)\\oplus\\Gamma_{c}(\\mathcal{L}|V)\\to\\Gamma_{c}(\\mathcal{L}|U\\cup V)\\to0$",
        "context": "Proof. By Exercise 3 it suffices to show that\n\n$$\n\\Gamma_{c}(\\mathcal{L}|U\\cap V)\\to\\Gamma_{c}(\\mathcal{L}|U)\\oplus\\Gamma_{c}(\\mathcal{L}|V)\\to\\Gamma_{c}(\\mathcal{L}|U\\cup V)\\to0\n$$\n\nis exact for $U, V$ open, since part (b) of that exercise clearly holds for\n\n$\\mathfrak{A}=\\Gamma_{c}\\mathcal{L}$. But this follows from the Mayer-Vietoris sequence (27) on page\n\n94. \u53e3\n\nNow we wish to prove the converse of 1.6. Let $\\mathfrak{A}$ be a flabby cosheaf and let $A$ be the presheaf defined by $A(U)=\\mathfrak{A}(X)/\\mathfrak{A}_{X-U}(X)$, where\n\n$$\n\\boxed{\\mathfrak{A}_{B}(X)=\\{s\\in\\mathfrak{A}(X)\\,|\\,|s|\\subset B\\}.}\n$$\n\nLet $\\mathcal{A}=\\mathcal{A}\\!e a\\!f(A)$. Note that\n\n$$\n{\\mathcal{A}}_{x}={\\mathfrak{A}}(X)/{\\mathfrak{A}}_{X-\\{x\\}}(X).\n$$\n\nThere is the canonical map\n\n$$\n{\\boxed{\\theta:{\\mathfrak{A}}(X)\\to{\\mathcal{A}}(X).}}\n$$\n\nClearly, $\\theta(s)(x)=0\\Leftrightarrow|s|\\subset X-\\{x\\}$. Thus $|\\theta(s)|=|s|$ and in particular $\\theta$ maps ${\\mathfrak{A}}(X)$ into $\\Gamma_{c}(\\mathcal{A})$ monomorphically. We shall show that $\\theta$ maps onto $\\Gamma_{c}(x)$\n\n$\n\n1.7. Lemma. Let $U\\subset X$ be open and let $t\\in{\\mathcal{A}}(U)$. Suppose that $s^{1}, s^{2}\\in\\mathfrak{A}(X)$ are given such that $\\theta(s_{1})|U_{i}\\;=\\;t|U_{i}$ for some open sets $U_{i}\\subset U$, $i=1, 2$. If $V_{i}$ is any open set with closure in $U_{i}$, $i=1, 2$, then there exists an element $s\\in\\mathfrak{A}(X)$ such that $\\theta(s)|\\big(V_{1}\\cup V_{2}\\big)=t|\\big(V_{1}\\cup V_{2}\\big)$.\n\nProof. Since $|s_{1}-s_{2}|\\,=\\,|\\theta(s_{1}-s_{2})|\\,=\\,|\\theta(s_{1})\\,-\\,\\theta(s_{2})|$ is contained in $X-\\left(U_{1}\\cap U_{2}\\right)$, it is also contained in $(X-{\\overline{{V}}}_{1})\\cup(X-{\\overline{{V}}}_{2})$. Since $\\mathfrak{A}$ is a cosheaf, there exist elements $t_{i}\\in\\mathfrak{A}(X),\\,i=1, 2$, with $\\left|t_{i}\\right|\\subset X-{\\overline{{V}}}_{i}$ and with $s_{1}-s_{2}=t_{1}-t_{2}$. Let $s=s_{1}-t_{1}=s_{2}-t_{2}$. Then\n\n$$\n\\theta(s)|V_{i}=\\theta(s_{i})|V_{i}=t|V_{i},\n$$\n\nfor $i=1, 2$, as claimed.\n\n1.8. Proposition. Every flabby cosheaf $\\mathfrak{A}$ has the form ${\\mathfrak{A}}=\\Gamma_{c}{\\mathfrak{A}}$ for a unique c-soft sheaf $\\mathcal{A}$. Moreover, the sheaf $\\mathcal{A}$ is torsion-free $\\Leftrightarrow|m s|=|s|$ for all $s\\,\\in\\,{\\mathfrak{A}}(X)$ and all $0\\,\\neq\\,m\\,\\in\\,L$. (In this case, we say that $\\mathfrak{A}$ is \"torsion-free\".)",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$\\Gamma_{c}(\\mathcal{L}|U\\cap V)\\to\\Gamma_{c}(\\mathcal{L}|U)\\oplus\\Gamma_{c}(\\mathcal{L}|V)\\to\\Gamma_{c}(\\mathcal{L}|U\\cup V)\\to0$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/GTM170-Sheaf_Theory1997.pdf_296",
        "ID": "09aedbd0-6d31-4b4a-bf6b-8793b318ad4c",
        "questions": "What is the definition of ${\\mathfrak{A}}_{B}(X)$ for a set $B$?",
        "answers": "$\\mathfrak{A}_{B}(X)=\\{s\\in\\mathfrak{A}(X)\\,|\\,|s|\\subset B\\}$",
        "context": "Proof. By Exercise 3 it suffices to show that\n\n$$\n\\Gamma_{c}(\\mathcal{L}|U\\cap V)\\to\\Gamma_{c}(\\mathcal{L}|U)\\oplus\\Gamma_{c}(\\mathcal{L}|V)\\to\\Gamma_{c}(\\mathcal{L}|U\\cup V)\\to0\n$$\n\nis exact for $U, V$ open, since part (b) of that exercise clearly holds for\n\n$\\mathfrak{A}=\\Gamma_{c}\\mathcal{L}$. But this follows from the Mayer-Vietoris sequence (27) on page\n\n94. \u53e3\n\nNow we wish to prove the converse of 1.6. Let $\\mathfrak{A}$ be a flabby cosheaf and let $A$ be the presheaf defined by $A(U)=\\mathfrak{A}(X)/\\mathfrak{A}_{X-U}(X)$, where\n\n$$\n\\boxed{\\mathfrak{A}_{B}(X)=\\{s\\in\\mathfrak{A}(X)\\,|\\,|s|\\subset B\\}.}\n$$\n\nLet $\\mathcal{A}=\\mathcal{A}\\!e a\\!f(A)$. Note that\n\n$$\n{\\mathcal{A}}_{x}={\\mathfrak{A}}(X)/{\\mathfrak{A}}_{X-\\{x\\}}(X).\n$$\n\nThere is the canonical map\n\n$$\n{\\boxed{\\theta:{\\mathfrak{A}}(X)\\to{\\mathcal{A}}(X).}}\n$$\n\nClearly, $\\theta(s)(x)=0\\Leftrightarrow|s|\\subset X-\\{x\\}$. Thus $|\\theta(s)|=|s|$ and in particular $\\theta$ maps ${\\mathfrak{A}}(X)$ into $\\Gamma_{c}(\\mathcal{A})$ monomorphically. We shall show that $\\theta$ maps onto $\\Gamma_{c}(x)$\n\n$\n\n1.7. Lemma. Let $U\\subset X$ be open and let $t\\in{\\mathcal{A}}(U)$. Suppose that $s^{1}, s^{2}\\in\\mathfrak{A}(X)$ are given such that $\\theta(s_{1})|U_{i}\\;=\\;t|U_{i}$ for some open sets $U_{i}\\subset U$, $i=1, 2$. If $V_{i}$ is any open set with closure in $U_{i}$, $i=1, 2$, then there exists an element $s\\in\\mathfrak{A}(X)$ such that $\\theta(s)|\\big(V_{1}\\cup V_{2}\\big)=t|\\big(V_{1}\\cup V_{2}\\big)$.\n\nProof. Since $|s_{1}-s_{2}|\\,=\\,|\\theta(s_{1}-s_{2})|\\,=\\,|\\theta(s_{1})\\,-\\,\\theta(s_{2})|$ is contained in $X-\\left(U_{1}\\cap U_{2}\\right)$, it is also contained in $(X-{\\overline{{V}}}_{1})\\cup(X-{\\overline{{V}}}_{2})$. Since $\\mathfrak{A}$ is a cosheaf, there exist elements $t_{i}\\in\\mathfrak{A}(X),\\,i=1, 2$, with $\\left|t_{i}\\right|\\subset X-{\\overline{{V}}}_{i}$ and with $s_{1}-s_{2}=t_{1}-t_{2}$. Let $s=s_{1}-t_{1}=s_{2}-t_{2}$. Then\n\n$$\n\\theta(s)|V_{i}=\\theta(s_{i})|V_{i}=t|V_{i},\n$$\n\nfor $i=1, 2$, as claimed.\n\n1.8. Proposition. Every flabby cosheaf $\\mathfrak{A}$ has the form ${\\mathfrak{A}}=\\Gamma_{c}{\\mathfrak{A}}$ for a unique c-soft sheaf $\\mathcal{A}$. Moreover, the sheaf $\\mathcal{A}$ is torsion-free $\\Leftrightarrow|m s|=|s|$ for all $s\\,\\in\\,{\\mathfrak{A}}(X)$ and all $0\\,\\neq\\,m\\,\\in\\,L$. (In this case, we say that $\\mathfrak{A}$ is \"torsion-free\".)",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$\\mathfrak{A}_{B}(X)=\\{s\\in\\mathfrak{A}(X)\\,|\\,|s|\\subset B\\}$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/GTM170-Sheaf_Theory1997.pdf_296",
        "ID": "09b3f5f8-de9c-4d73-a3f4-9a4207814183",
        "questions": "What equation defines the canonical map $\\theta$ from ${\\mathfrak{A}}(X)$ to ${\\mathcal{A}}(X)$?",
        "answers": "$\\theta:{\\mathfrak{A}}(X)\\to{\\mathcal{A}}(X)$",
        "context": "Proof. By Exercise 3 it suffices to show that\n\n$$\n\\Gamma_{c}(\\mathcal{L}|U\\cap V)\\to\\Gamma_{c}(\\mathcal{L}|U)\\oplus\\Gamma_{c}(\\mathcal{L}|V)\\to\\Gamma_{c}(\\mathcal{L}|U\\cup V)\\to0\n$$\n\nis exact for $U, V$ open, since part (b) of that exercise clearly holds for\n\n$\\mathfrak{A}=\\Gamma_{c}\\mathcal{L}$. But this follows from the Mayer-Vietoris sequence (27) on page\n\n94. \u53e3\n\nNow we wish to prove the converse of 1.6. Let $\\mathfrak{A}$ be a flabby cosheaf and let $A$ be the presheaf defined by $A(U)=\\mathfrak{A}(X)/\\mathfrak{A}_{X-U}(X)$, where\n\n$$\n\\boxed{\\mathfrak{A}_{B}(X)=\\{s\\in\\mathfrak{A}(X)\\,|\\,|s|\\subset B\\}.}\n$$\n\nLet $\\mathcal{A}=\\mathcal{A}\\!e a\\!f(A)$. Note that\n\n$$\n{\\mathcal{A}}_{x}={\\mathfrak{A}}(X)/{\\mathfrak{A}}_{X-\\{x\\}}(X).\n$$\n\nThere is the canonical map\n\n$$\n{\\boxed{\\theta:{\\mathfrak{A}}(X)\\to{\\mathcal{A}}(X).}}\n$$\n\nClearly, $\\theta(s)(x)=0\\Leftrightarrow|s|\\subset X-\\{x\\}$. Thus $|\\theta(s)|=|s|$ and in particular $\\theta$ maps ${\\mathfrak{A}}(X)$ into $\\Gamma_{c}(\\mathcal{A})$ monomorphically. We shall show that $\\theta$ maps onto $\\Gamma_{c}(x)$\n\n$\n\n1.7. Lemma. Let $U\\subset X$ be open and let $t\\in{\\mathcal{A}}(U)$. Suppose that $s^{1}, s^{2}\\in\\mathfrak{A}(X)$ are given such that $\\theta(s_{1})|U_{i}\\;=\\;t|U_{i}$ for some open sets $U_{i}\\subset U$, $i=1, 2$. If $V_{i}$ is any open set with closure in $U_{i}$, $i=1, 2$, then there exists an element $s\\in\\mathfrak{A}(X)$ such that $\\theta(s)|\\big(V_{1}\\cup V_{2}\\big)=t|\\big(V_{1}\\cup V_{2}\\big)$.\n\nProof. Since $|s_{1}-s_{2}|\\,=\\,|\\theta(s_{1}-s_{2})|\\,=\\,|\\theta(s_{1})\\,-\\,\\theta(s_{2})|$ is contained in $X-\\left(U_{1}\\cap U_{2}\\right)$, it is also contained in $(X-{\\overline{{V}}}_{1})\\cup(X-{\\overline{{V}}}_{2})$. Since $\\mathfrak{A}$ is a cosheaf, there exist elements $t_{i}\\in\\mathfrak{A}(X),\\,i=1, 2$, with $\\left|t_{i}\\right|\\subset X-{\\overline{{V}}}_{i}$ and with $s_{1}-s_{2}=t_{1}-t_{2}$. Let $s=s_{1}-t_{1}=s_{2}-t_{2}$. Then\n\n$$\n\\theta(s)|V_{i}=\\theta(s_{i})|V_{i}=t|V_{i},\n$$\n\nfor $i=1, 2$, as claimed.\n\n1.8. Proposition. Every flabby cosheaf $\\mathfrak{A}$ has the form ${\\mathfrak{A}}=\\Gamma_{c}{\\mathfrak{A}}$ for a unique c-soft sheaf $\\mathcal{A}$. Moreover, the sheaf $\\mathcal{A}$ is torsion-free $\\Leftrightarrow|m s|=|s|$ for all $s\\,\\in\\,{\\mathfrak{A}}(X)$ and all $0\\,\\neq\\,m\\,\\in\\,L$. (In this case, we say that $\\mathfrak{A}$ is \"torsion-free\".)",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$\\theta:{\\mathfrak{A}}(X)\\to{\\mathcal{A}}(X)$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/(Springer_Monographs_in_Mathematics)_V.I._Bogachev,_O.G._Smolyanov_-_Topological_Vector_Spaces_and_Their_Applications-Springer_(2017).pdf_48",
        "ID": "09c67417-306a-4871-beef-71cbc915d113",
        "questions": "What is the definition of a precompact subset in a topological vector space?",
        "answers": "A subset $A$ of a topological vector space $E$ is called precompact and totally bounded if for every neighborhood of zero $V$ in $E$ one can find a finite set $\\{a_{1},\\,\\.\\,\\.\\,\\.\\,,a_{n}\\}$ in $E$ such that $\\textstyle A\\subset\\bigcup_{k=1}^{n}(a_{k}+V)$.",
        "context": "PROOF. The quotient space $E/F$ is Hausdorff and finite-dimensional, and the natural projection $\\pi\\colon E\\,\\rightarrow\\,E/F$ is continuous. Its restriction $\\pi|_{G}$ to $G$ is an algebraic, hence by the proven theorem also a topological isomorphism between $G$ and $E/F$. The projection $p_{G}\\colon E\\to G$ has the form $p_{G}=(\\pi|_{G})^{-1}\\circ\\pi,$ hence is continuous.\n\n1.5.4. Definition. A subset $A$ of a topological vector space $E$ is called precompact and totally bounded if for every neighborhood of zero $V$ in $E$ one can find a finite set $\\{a_{1},\\,.\\,.\\,.\\,,a_{n}\\}$ in $E$ such that $\\textstyle A\\subset\\bigcup_{k=1}^{n}(a_{k}+V)$.\n\nThe set $\\{a_{1},\\ldots,a_{n}\\}$ is called a finite $V$-net (or an $\\varepsilon$-net if $V$ is a ball of radius $\\varepsilon$ in a metric space). It is easily seen that every compact set in a topological vector space is precompact. We observe (this fact is not needed now, so it will be proven in $\\S\\,1.8$ after we discuss completions of topological vector spaces) that a subset of a topological vector space is precompact precisely when its closure in the completion of this topological vector space is compact. However, the closure of a precompact set in an incomplete space may fail to be compact.\n\n1.5.5. Lemma. Every precompact subset of a topological vector space is bounded.\n\nPROOF. Let $A$ be a precompact subset of a topological vector space $E$ and let $V$ be a neighborhood of zero in $E$; we have to prove that there exists $\\nu>0$ such that $A\\subset t V$ if $|t|>\\nu$. Let $W$ be a circled neighborhood of zero such that $W+W\\subset V$ and let $a_{1},\\,.\\,.\\,.\\,,a_{n}$ be elements of $E$ for which $\\textstyle A\\subset\\bigcup_{k=1}^{n}(a_{k}+W)$. Let $\\nu>1$ be such that $\\{a_{1},\\,.\\,.\\,.\\,,a_{n}\\}\\,\\subset\\,t W$ if $|t|>\\nu$. Then for such numbers $t$ we have\n\n$$\nA\\subset\\bigcup_{k=1}^{n}(a_{k}+W)\\subset t W+W\\subset t W+t W=t(W+W)\\subset t V,\n$$\n\nwhich shows that $A$ is bounded.\n\n1.5.6. Theorem. A Hausdorff topological vector space $E$ over the field $\\mathbb{R}$ or $\\mathbb{C}$ is finite-dimensional if and only if it possesses a compact neighborhood of zero. Moreover, it is sufficient that it possess a precompact neighborhood of zero.\n\nPROOF. The necessity is clear from Theorem 1.5.1, since any Hausdorff topological vector space (over an on discrete complete normed field $\\mathbb{K}$) of finite dimension $n$ is isomorphic (as a topological vector space) to the space ${\\mathbb K}^{n}$, and if $S$ is a compact neighborhood of zero in $\\mathbb{K}$ then the product of $n$ copies of $S$ is a compact neighborhood of zero in $\\mathbb{K}^{n}$.\n\nLet us prove the sufficiency (the given proof is due to Gleason). Let $V$ be a precompact neighborhood of zero in $E$ and let $a_{1},\\ldots,a_{n}\\in E$ be elements such that\n\n$$\nV\\subset\\bigcup_{k=1}^{n}{\\Big(}a_{k}+{\\frac{1}{2}}V{\\Big)}.\n$$\n\nWe show that the linear span of the set $A\\;=\\;\\{a_{1},\\,.\\,.\\,.\\,,a_{n}\\}$ coincides with the whole space, i.e., that every element in $E$ is a linear combination of elements of $A$.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "A subset $A$ of a topological vector space $E$ is called precompact and totally bounded if for every neighborhood of zero $V$ in $E$ one can find a finite set $\\{a_{1},\\,.\\,.\\,.\\,,a_{n}\\}$ in $E$ such that $\\textstyle A\\subset\\bigcup_{k=1}^{n}(a_{k}+V)$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/(Springer_Monographs_in_Mathematics)_V.I._Bogachev,_O.G._Smolyanov_-_Topological_Vector_Spaces_and_Their_Applications-Springer_(2017).pdf_48",
        "ID": "09ce689b-f968-4434-ad21-715531ef5d1e",
        "questions": "In the context of a Hausdorff topological vector space, when is it considered finite-dimensional?",
        "answers": "A Hausdorff topological vector space is finite-dimensional if and only if it possesses a compact neighborhood of zero.",
        "context": "PROOF. The quotient space $E/F$ is Hausdorff and finite-dimensional, and the natural projection $\\pi\\colon E\\,\\rightarrow\\,E/F$ is continuous. Its restriction $\\pi|_{G}$ to $G$ is an algebraic, hence by the proven theorem also a topological isomorphism between $G$ and $E/F$. The projection $p_{G}\\colon E\\to G$ has the form $p_{G}=(\\pi|_{G})^{-1}\\circ\\pi,$ hence is continuous.\n\n1.5.4. Definition. A subset $A$ of a topological vector space $E$ is called precompact and totally bounded if for every neighborhood of zero $V$ in $E$ one can find a finite set $\\{a_{1},\\,.\\,.\\,.\\,,a_{n}\\}$ in $E$ such that $\\textstyle A\\subset\\bigcup_{k=1}^{n}(a_{k}+V)$.\n\nThe set $\\{a_{1},\\ldots,a_{n}\\}$ is called a finite $V$-net (or an $\\varepsilon$-net if $V$ is a ball of radius $\\varepsilon$ in a metric space). It is easily seen that every compact set in a topological vector space is precompact. We observe (this fact is not needed now, so it will be proven in $\\S\\,1.8$ after we discuss completions of topological vector spaces) that a subset of a topological vector space is precompact precisely when its closure in the completion of this topological vector space is compact. However, the closure of a precompact set in an incomplete space may fail to be compact.\n\n1.5.5. Lemma. Every precompact subset of a topological vector space is bounded.\n\nPROOF. Let $A$ be a precompact subset of a topological vector space $E$ and let $V$ be a neighborhood of zero in $E$; we have to prove that there exists $\\nu>0$ such that $A\\subset t V$ if $|t|>\\nu$. Let $W$ be a circled neighborhood of zero such that $W+W\\subset V$ and let $a_{1},\\,.\\,.\\,.\\,,a_{n}$ be elements of $E$ for which $\\textstyle A\\subset\\bigcup_{k=1}^{n}(a_{k}+W)$. Let $\\nu>1$ be such that $\\{a_{1},\\,.\\,.\\,.\\,,a_{n}\\}\\,\\subset\\,t W$ if $|t|>\\nu$. Then for such numbers $t$ we have\n\n$$\nA\\subset\\bigcup_{k=1}^{n}(a_{k}+W)\\subset t W+W\\subset t W+t W=t(W+W)\\subset t V,\n$$\n\nwhich shows that $A$ is bounded.\n\n1.5.6. Theorem. A Hausdorff topological vector space $E$ over the field $\\mathbb{R}$ or $\\mathbb{C}$ is finite-dimensional if and only if it possesses a compact neighborhood of zero. Moreover, it is sufficient that it possess a precompact neighborhood of zero.\n\nPROOF. The necessity is clear from Theorem 1.5.1, since any Hausdorff topological vector space (over an on discrete complete normed field $\\mathbb{K}$) of finite dimension $n$ is isomorphic (as a topological vector space) to the space ${\\mathbb K}^{n}$, and if $S$ is a compact neighborhood of zero in $\\mathbb{K}$ then the product of $n$ copies of $S$ is a compact neighborhood of zero in $\\mathbb{K}^{n}$.\n\nLet us prove the sufficiency (the given proof is due to Gleason). Let $V$ be a precompact neighborhood of zero in $E$ and let $a_{1},\\ldots,a_{n}\\in E$ be elements such that\n\n$$\nV\\subset\\bigcup_{k=1}^{n}{\\Big(}a_{k}+{\\frac{1}{2}}V{\\Big)}.\n$$\n\nWe show that the linear span of the set $A\\;=\\;\\{a_{1},\\,.\\,.\\,.\\,,a_{n}\\}$ coincides with the whole space, i.e., that every element in $E$ is a linear combination of elements of $A$.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "A Hausdorff topological vector space $E$ over the field $\\mathbb{R}$ or $\\mathbb{C}$ is finite-dimensional if and only if it possesses a compact neighborhood of zero.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/(Springer_Monographs_in_Mathematics)_V.I._Bogachev,_O.G._Smolyanov_-_Topological_Vector_Spaces_and_Their_Applications-Springer_(2017).pdf_48",
        "ID": "09cef0ea-d6ca-4f41-adf1-fe3fefd9373e",
        "questions": "According to the theorem proven by Gleason, what condition on the neighborhood of zero is sufficient for a topological vector space to be finite-dimensional?",
        "answers": "It is sufficient that it possess a precompact neighborhood of zero.",
        "context": "PROOF. The quotient space $E/F$ is Hausdorff and finite-dimensional, and the natural projection $\\pi\\colon E\\,\\rightarrow\\,E/F$ is continuous. Its restriction $\\pi|_{G}$ to $G$ is an algebraic, hence by the proven theorem also a topological isomorphism between $G$ and $E/F$. The projection $p_{G}\\colon E\\to G$ has the form $p_{G}=(\\pi|_{G})^{-1}\\circ\\pi,$ hence is continuous.\n\n1.5.4. Definition. A subset $A$ of a topological vector space $E$ is called precompact and totally bounded if for every neighborhood of zero $V$ in $E$ one can find a finite set $\\{a_{1},\\,.\\,.\\,.\\,,a_{n}\\}$ in $E$ such that $\\textstyle A\\subset\\bigcup_{k=1}^{n}(a_{k}+V)$.\n\nThe set $\\{a_{1},\\ldots,a_{n}\\}$ is called a finite $V$-net (or an $\\varepsilon$-net if $V$ is a ball of radius $\\varepsilon$ in a metric space). It is easily seen that every compact set in a topological vector space is precompact. We observe (this fact is not needed now, so it will be proven in $\\S\\,1.8$ after we discuss completions of topological vector spaces) that a subset of a topological vector space is precompact precisely when its closure in the completion of this topological vector space is compact. However, the closure of a precompact set in an incomplete space may fail to be compact.\n\n1.5.5. Lemma. Every precompact subset of a topological vector space is bounded.\n\nPROOF. Let $A$ be a precompact subset of a topological vector space $E$ and let $V$ be a neighborhood of zero in $E$; we have to prove that there exists $\\nu>0$ such that $A\\subset t V$ if $|t|>\\nu$. Let $W$ be a circled neighborhood of zero such that $W+W\\subset V$ and let $a_{1},\\,.\\,.\\,.\\,,a_{n}$ be elements of $E$ for which $\\textstyle A\\subset\\bigcup_{k=1}^{n}(a_{k}+W)$. Let $\\nu>1$ be such that $\\{a_{1},\\,.\\,.\\,.\\,,a_{n}\\}\\,\\subset\\,t W$ if $|t|>\\nu$. Then for such numbers $t$ we have\n\n$$\nA\\subset\\bigcup_{k=1}^{n}(a_{k}+W)\\subset t W+W\\subset t W+t W=t(W+W)\\subset t V,\n$$\n\nwhich shows that $A$ is bounded.\n\n1.5.6. Theorem. A Hausdorff topological vector space $E$ over the field $\\mathbb{R}$ or $\\mathbb{C}$ is finite-dimensional if and only if it possesses a compact neighborhood of zero. Moreover, it is sufficient that it possess a precompact neighborhood of zero.\n\nPROOF. The necessity is clear from Theorem 1.5.1, since any Hausdorff topological vector space (over an on discrete complete normed field $\\mathbb{K}$) of finite dimension $n$ is isomorphic (as a topological vector space) to the space ${\\mathbb K}^{n}$, and if $S$ is a compact neighborhood of zero in $\\mathbb{K}$ then the product of $n$ copies of $S$ is a compact neighborhood of zero in $\\mathbb{K}^{n}$.\n\nLet us prove the sufficiency (the given proof is due to Gleason). Let $V$ be a precompact neighborhood of zero in $E$ and let $a_{1},\\ldots,a_{n}\\in E$ be elements such that\n\n$$\nV\\subset\\bigcup_{k=1}^{n}{\\Big(}a_{k}+{\\frac{1}{2}}V{\\Big)}.\n$$\n\nWe show that the linear span of the set $A\\;=\\;\\{a_{1},\\,.\\,.\\,.\\,,a_{n}\\}$ coincides with the whole space, i.e., that every element in $E$ is a linear combination of elements of $A$.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Moreover, it is sufficient that it possess a precompact neighborhood of zero.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/(Springer_Monographs_in_Mathematics)_V.I._Bogachev,_O.G._Smolyanov_-_Topological_Vector_Spaces_and_Their_Applications-Springer_(2017).pdf_48",
        "ID": "09d1887e-5a23-42f2-a62a-cd409067f726",
        "questions": "What is the equation that shows a set $A$ is bounded in a topological vector space if it is precompact?",
        "answers": "$A\\subset\\bigcup_{k=1}^{n}(a_{k}+W)\\subset t W+W\\subset t W+t W=t(W+W)\\subset t V$",
        "context": "PROOF. The quotient space $E/F$ is Hausdorff and finite-dimensional, and the natural projection $\\pi\\colon E\\,\\rightarrow\\,E/F$ is continuous. Its restriction $\\pi|_{G}$ to $G$ is an algebraic, hence by the proven theorem also a topological isomorphism between $G$ and $E/F$. The projection $p_{G}\\colon E\\to G$ has the form $p_{G}=(\\pi|_{G})^{-1}\\circ\\pi,$ hence is continuous.\n\n1.5.4. Definition. A subset $A$ of a topological vector space $E$ is called precompact and totally bounded if for every neighborhood of zero $V$ in $E$ one can find a finite set $\\{a_{1},\\,.\\,.\\,.\\,,a_{n}\\}$ in $E$ such that $\\textstyle A\\subset\\bigcup_{k=1}^{n}(a_{k}+V)$.\n\nThe set $\\{a_{1},\\ldots,a_{n}\\}$ is called a finite $V$-net (or an $\\varepsilon$-net if $V$ is a ball of radius $\\varepsilon$ in a metric space). It is easily seen that every compact set in a topological vector space is precompact. We observe (this fact is not needed now, so it will be proven in $\\S\\,1.8$ after we discuss completions of topological vector spaces) that a subset of a topological vector space is precompact precisely when its closure in the completion of this topological vector space is compact. However, the closure of a precompact set in an incomplete space may fail to be compact.\n\n1.5.5. Lemma. Every precompact subset of a topological vector space is bounded.\n\nPROOF. Let $A$ be a precompact subset of a topological vector space $E$ and let $V$ be a neighborhood of zero in $E$; we have to prove that there exists $\\nu>0$ such that $A\\subset t V$ if $|t|>\\nu$. Let $W$ be a circled neighborhood of zero such that $W+W\\subset V$ and let $a_{1},\\,.\\,.\\,.\\,,a_{n}$ be elements of $E$ for which $\\textstyle A\\subset\\bigcup_{k=1}^{n}(a_{k}+W)$. Let $\\nu>1$ be such that $\\{a_{1},\\,.\\,.\\,.\\,,a_{n}\\}\\,\\subset\\,t W$ if $|t|>\\nu$. Then for such numbers $t$ we have\n\n$$\nA\\subset\\bigcup_{k=1}^{n}(a_{k}+W)\\subset t W+W\\subset t W+t W=t(W+W)\\subset t V,\n$$\n\nwhich shows that $A$ is bounded.\n\n1.5.6. Theorem. A Hausdorff topological vector space $E$ over the field $\\mathbb{R}$ or $\\mathbb{C}$ is finite-dimensional if and only if it possesses a compact neighborhood of zero. Moreover, it is sufficient that it possess a precompact neighborhood of zero.\n\nPROOF. The necessity is clear from Theorem 1.5.1, since any Hausdorff topological vector space (over an on discrete complete normed field $\\mathbb{K}$) of finite dimension $n$ is isomorphic (as a topological vector space) to the space ${\\mathbb K}^{n}$, and if $S$ is a compact neighborhood of zero in $\\mathbb{K}$ then the product of $n$ copies of $S$ is a compact neighborhood of zero in $\\mathbb{K}^{n}$.\n\nLet us prove the sufficiency (the given proof is due to Gleason). Let $V$ be a precompact neighborhood of zero in $E$ and let $a_{1},\\ldots,a_{n}\\in E$ be elements such that\n\n$$\nV\\subset\\bigcup_{k=1}^{n}{\\Big(}a_{k}+{\\frac{1}{2}}V{\\Big)}.\n$$\n\nWe show that the linear span of the set $A\\;=\\;\\{a_{1},\\,.\\,.\\,.\\,,a_{n}\\}$ coincides with the whole space, i.e., that every element in $E$ is a linear combination of elements of $A$.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Numeric",
        "evidence_source": "equation",
        "evidence_context": "Then for such numbers $t$ we have $A\\subset\\bigcup_{k=1}^{n}(a_{k}+W)\\subset t W+W\\subset t W+t W=t(W+W)\\subset t V,$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/(Springer_Monographs_in_Mathematics)_V.I._Bogachev,_O.G._Smolyanov_-_Topological_Vector_Spaces_and_Their_Applications-Springer_(2017).pdf_48",
        "ID": "09d1a23b-41ed-4ad7-b799-e29648d44935",
        "questions": "What is the equation that shows the sufficiency of possessing a precompact neighborhood of zero in a Hausdorff topological vector space $E$?",
        "answers": "$V\\subset\\bigcup_{k=1}^{n}{\\Big(}a_{k}+{\\frac{1}{2}}V{\\Big)}.$",
        "context": "PROOF. The quotient space $E/F$ is Hausdorff and finite-dimensional, and the natural projection $\\pi\\colon E\\,\\rightarrow\\,E/F$ is continuous. Its restriction $\\pi|_{G}$ to $G$ is an algebraic, hence by the proven theorem also a topological isomorphism between $G$ and $E/F$. The projection $p_{G}\\colon E\\to G$ has the form $p_{G}=(\\pi|_{G})^{-1}\\circ\\pi,$ hence is continuous.\n\n1.5.4. Definition. A subset $A$ of a topological vector space $E$ is called precompact and totally bounded if for every neighborhood of zero $V$ in $E$ one can find a finite set $\\{a_{1},\\,.\\,.\\,.\\,,a_{n}\\}$ in $E$ such that $\\textstyle A\\subset\\bigcup_{k=1}^{n}(a_{k}+V)$.\n\nThe set $\\{a_{1},\\ldots,a_{n}\\}$ is called a finite $V$-net (or an $\\varepsilon$-net if $V$ is a ball of radius $\\varepsilon$ in a metric space). It is easily seen that every compact set in a topological vector space is precompact. We observe (this fact is not needed now, so it will be proven in $\\S\\,1.8$ after we discuss completions of topological vector spaces) that a subset of a topological vector space is precompact precisely when its closure in the completion of this topological vector space is compact. However, the closure of a precompact set in an incomplete space may fail to be compact.\n\n1.5.5. Lemma. Every precompact subset of a topological vector space is bounded.\n\nPROOF. Let $A$ be a precompact subset of a topological vector space $E$ and let $V$ be a neighborhood of zero in $E$; we have to prove that there exists $\\nu>0$ such that $A\\subset t V$ if $|t|>\\nu$. Let $W$ be a circled neighborhood of zero such that $W+W\\subset V$ and let $a_{1},\\,.\\,.\\,.\\,,a_{n}$ be elements of $E$ for which $\\textstyle A\\subset\\bigcup_{k=1}^{n}(a_{k}+W)$. Let $\\nu>1$ be such that $\\{a_{1},\\,.\\,.\\,.\\,,a_{n}\\}\\,\\subset\\,t W$ if $|t|>\\nu$. Then for such numbers $t$ we have\n\n$$\nA\\subset\\bigcup_{k=1}^{n}(a_{k}+W)\\subset t W+W\\subset t W+t W=t(W+W)\\subset t V,\n$$\n\nwhich shows that $A$ is bounded.\n\n1.5.6. Theorem. A Hausdorff topological vector space $E$ over the field $\\mathbb{R}$ or $\\mathbb{C}$ is finite-dimensional if and only if it possesses a compact neighborhood of zero. Moreover, it is sufficient that it possess a precompact neighborhood of zero.\n\nPROOF. The necessity is clear from Theorem 1.5.1, since any Hausdorff topological vector space (over an on discrete complete normed field $\\mathbb{K}$) of finite dimension $n$ is isomorphic (as a topological vector space) to the space ${\\mathbb K}^{n}$, and if $S$ is a compact neighborhood of zero in $\\mathbb{K}$ then the product of $n$ copies of $S$ is a compact neighborhood of zero in $\\mathbb{K}^{n}$.\n\nLet us prove the sufficiency (the given proof is due to Gleason). Let $V$ be a precompact neighborhood of zero in $E$ and let $a_{1},\\ldots,a_{n}\\in E$ be elements such that\n\n$$\nV\\subset\\bigcup_{k=1}^{n}{\\Big(}a_{k}+{\\frac{1}{2}}V{\\Big)}.\n$$\n\nWe show that the linear span of the set $A\\;=\\;\\{a_{1},\\,.\\,.\\,.\\,,a_{n}\\}$ coincides with the whole space, i.e., that every element in $E$ is a linear combination of elements of $A$.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Let $V$ be a precompact neighborhood of zero in $E$ and let $a_{1},\\ldots,a_{n}\\in E$ be elements such that $V\\subset\\bigcup_{k=1}^{n}{\\Big(}a_{k}+{\\frac{1}{2}}V{\\Big)}.$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/(Springer_Monographs_in_Mathematics)_V.I._Bogachev,_O.G._Smolyanov_-_Topological_Vector_Spaces_and_Their_Applications-Springer_(2017).pdf_48",
        "ID": "09df8915-dc00-45b5-8dfb-dc9fb5816a50",
        "questions": "If $|t|>\nu$ where $\nu>1$, what are the sets $t W$, $t(W+W)$ and $t V$ bounded in terms of $A$ in the proof of Lemma 1.5.5?",
        "answers": "The sets $t W$, $t(W+W)$ and $t V$ are bounded in terms of $A$ as $A\\subset t W+t W=t(W+W)\\subset t V$.",
        "context": "PROOF. The quotient space $E/F$ is Hausdorff and finite-dimensional, and the natural projection $\\pi\\colon E\\,\\rightarrow\\,E/F$ is continuous. Its restriction $\\pi|_{G}$ to $G$ is an algebraic, hence by the proven theorem also a topological isomorphism between $G$ and $E/F$. The projection $p_{G}\\colon E\\to G$ has the form $p_{G}=(\\pi|_{G})^{-1}\\circ\\pi,$ hence is continuous.\n\n1.5.4. Definition. A subset $A$ of a topological vector space $E$ is called precompact and totally bounded if for every neighborhood of zero $V$ in $E$ one can find a finite set $\\{a_{1},\\,.\\,.\\,.\\,,a_{n}\\}$ in $E$ such that $\\textstyle A\\subset\\bigcup_{k=1}^{n}(a_{k}+V)$.\n\nThe set $\\{a_{1},\\ldots,a_{n}\\}$ is called a finite $V$-net (or an $\\varepsilon$-net if $V$ is a ball of radius $\\varepsilon$ in a metric space). It is easily seen that every compact set in a topological vector space is precompact. We observe (this fact is not needed now, so it will be proven in $\\S\\,1.8$ after we discuss completions of topological vector spaces) that a subset of a topological vector space is precompact precisely when its closure in the completion of this topological vector space is compact. However, the closure of a precompact set in an incomplete space may fail to be compact.\n\n1.5.5. Lemma. Every precompact subset of a topological vector space is bounded.\n\nPROOF. Let $A$ be a precompact subset of a topological vector space $E$ and let $V$ be a neighborhood of zero in $E$; we have to prove that there exists $\\nu>0$ such that $A\\subset t V$ if $|t|>\\nu$. Let $W$ be a circled neighborhood of zero such that $W+W\\subset V$ and let $a_{1},\\,.\\,.\\,.\\,,a_{n}$ be elements of $E$ for which $\\textstyle A\\subset\\bigcup_{k=1}^{n}(a_{k}+W)$. Let $\\nu>1$ be such that $\\{a_{1},\\,.\\,.\\,.\\,,a_{n}\\}\\,\\subset\\,t W$ if $|t|>\\nu$. Then for such numbers $t$ we have\n\n$$\nA\\subset\\bigcup_{k=1}^{n}(a_{k}+W)\\subset t W+W\\subset t W+t W=t(W+W)\\subset t V,\n$$\n\nwhich shows that $A$ is bounded.\n\n1.5.6. Theorem. A Hausdorff topological vector space $E$ over the field $\\mathbb{R}$ or $\\mathbb{C}$ is finite-dimensional if and only if it possesses a compact neighborhood of zero. Moreover, it is sufficient that it possess a precompact neighborhood of zero.\n\nPROOF. The necessity is clear from Theorem 1.5.1, since any Hausdorff topological vector space (over an on discrete complete normed field $\\mathbb{K}$) of finite dimension $n$ is isomorphic (as a topological vector space) to the space ${\\mathbb K}^{n}$, and if $S$ is a compact neighborhood of zero in $\\mathbb{K}$ then the product of $n$ copies of $S$ is a compact neighborhood of zero in $\\mathbb{K}^{n}$.\n\nLet us prove the sufficiency (the given proof is due to Gleason). Let $V$ be a precompact neighborhood of zero in $E$ and let $a_{1},\\ldots,a_{n}\\in E$ be elements such that\n\n$$\nV\\subset\\bigcup_{k=1}^{n}{\\Big(}a_{k}+{\\frac{1}{2}}V{\\Big)}.\n$$\n\nWe show that the linear span of the set $A\\;=\\;\\{a_{1},\\,.\\,.\\,.\\,,a_{n}\\}$ coincides with the whole space, i.e., that every element in $E$ is a linear combination of elements of $A$.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Then for such numbers $t$ we have $A\\subset\\bigcup_{k=1}^{n}(a_{k}+W)\\subset t W+W\\subset t W+t W=t(W+W)\\subset t V,$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/biz-47556.pdf_465",
        "ID": "09edc0e4-dfb6-46ec-b8a4-c61ca22287fe",
        "questions": "Which company now owns Ben & Jerry's?",
        "answers": "A Dutch and British firm",
        "context": "# 16.10: Introduction to Current Trends in Global Business  \n\n# What you'll learn to do: describe current trends in global business  \n\nMany people don't understand the extent to which globalization influences their daily lives. Do you want an ice cream cone to cool off? Ben & Jerry's is now owned by a Dutch and British firm. Brewing a nice cup of tea for an afternoon pick-me-up? Tata Group of India owns the Tetley Tea Company. Putting on your Nike running shoes for an early morning jog? Most Nike products are produced in China. There are very few large businesses today who can say they are \u201c100 percent American owned and operated.\u201d  \n\nThis section looks at how politics and economics affect business globalization and the factors that influence global competition. It will also examine the role of global supply chains in reducing costs and the need for innovation in the rapidly changing world of business.  \n\n# Contributors and Attributions  \n\nCC licensed content, Original  \n\nIntroduction to Current Trends in Global Business. Authored by: John/Lynn Bruton and Lumen Learning. License: CC BY: Attribution",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Ben & Jerry's is now owned by a Dutch and British firm.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/biz-47556.pdf_465",
        "ID": "09f6048f-e245-4460-8004-884cc167733f",
        "questions": "Are most Nike products produced in China?",
        "answers": "Yes",
        "context": "# 16.10: Introduction to Current Trends in Global Business  \n\n# What you'll learn to do: describe current trends in global business  \n\nMany people don't understand the extent to which globalization influences their daily lives. Do you want an ice cream cone to cool off? Ben & Jerry's is now owned by a Dutch and British firm. Brewing a nice cup of tea for an afternoon pick-me-up? Tata Group of India owns the Tetley Tea Company. Putting on your Nike running shoes for an early morning jog? Most Nike products are produced in China. There are very few large businesses today who can say they are \u201c100 percent American owned and operated.\u201d  \n\nThis section looks at how politics and economics affect business globalization and the factors that influence global competition. It will also examine the role of global supply chains in reducing costs and the need for innovation in the rapidly changing world of business.  \n\n# Contributors and Attributions  \n\nCC licensed content, Original  \n\nIntroduction to Current Trends in Global Business. Authored by: John/Lynn Bruton and Lumen Learning. License: CC BY: Attribution",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Yes/No",
        "evidence_source": "text",
        "evidence_context": "Most Nike products are produced in China.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/biz-47556.pdf_465",
        "ID": "09f954f8-3b20-4dc1-8668-5be76eb542e7",
        "questions": "Which company owns the Tetley Tea Company?",
        "answers": "Tata Group of India",
        "context": "# 16.10: Introduction to Current Trends in Global Business  \n\n# What you'll learn to do: describe current trends in global business  \n\nMany people don't understand the extent to which globalization influences their daily lives. Do you want an ice cream cone to cool off? Ben & Jerry's is now owned by a Dutch and British firm. Brewing a nice cup of tea for an afternoon pick-me-up? Tata Group of India owns the Tetley Tea Company. Putting on your Nike running shoes for an early morning jog? Most Nike products are produced in China. There are very few large businesses today who can say they are \u201c100 percent American owned and operated.\u201d  \n\nThis section looks at how politics and economics affect business globalization and the factors that influence global competition. It will also examine the role of global supply chains in reducing costs and the need for innovation in the rapidly changing world of business.  \n\n# Contributors and Attributions  \n\nCC licensed content, Original  \n\nIntroduction to Current Trends in Global Business. Authored by: John/Lynn Bruton and Lumen Learning. License: CC BY: Attribution",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Tata Group of India owns the Tetley Tea Company.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM_147_-_ISBN978-1-4612-4314-4_-_Jonathan_Rosenberg_-_Algebraic_K-Theory_and_Its_Applications.pdf_149",
        "ID": "0a00792f-1475-461e-8cd7-cea507b008f8",
        "questions": "For which range of indices $i$ is the map $S\\otimes_{R}Q_{i}$ to $F_{i}(M)/F_{i-1}(M)$ obviously an isomorphism?",
        "answers": "For $i<n_{0}$ or $i>n_{1}$",
        "context": "If $M_{i}=0$ for $i<n_{0}$, then  \n\n$$\n0=F_{n_{0}-1}(M)\\subseteq F_{n_{0}}(M)\\subseteq\\cdots\\subseteq F_{+\\infty}(M)=M,\n$$  \n\nand the filtration must terminate at some finite stage, i.e., $F_{n_{1}}(M)=M$ for some $\\mathbf{\\mathit{n}_{1}}$, since $M$ is finitely generated and Noetherian. Note that there is a map of graded $S$-modules from $S\\otimes_{R}M_{i}$ to $F_{i}(M)$, which induces by passage to the quotient a surjective map of graded $S$-modules  \n\n$$\nS\\otimes_{R}Q_{i}\\to F_{i}(M)/F_{i-1}(M).\n$$  \n\nHere we are reviewing $M_{i}$ and $Q_{i}$ as graded modules concentrated in the single degree $i$. We will show this map is an isomorphism for each $i$.  \n\nFor $i<n_{0}$ or $i>n_{1}$, this is obvious since both sides are zero. Suppose we know that $\\operatorname{Tor}_{1}^{S}(R,\\,F_{i}(M))=0$, which is at least the case for $i=n_{1}$ since $M\\in\\operatorname{Obj}\\mathcal{F}$. From the short exact sequence of graded modules  \n\n$$\n0\\to F_{i-1}(M)\\to F_{i}(M)\\to F_{i}(M)/F_{i-1}(M)\\to0\n$$  \n\nand the fact that the natural map  \n\n$$\nR\\otimes_{S}F_{i-1}(M)\\to R\\otimes_{S}F_{i}(M)\n$$  \n\nis injective with cokernel $Q_{i}$, we see first that $\\operatorname{Tor}_{1}^{S}(R,\\,F_{i}(M))=0$ implies also $\\operatorname{Tor}_{1}^{S}(R,\\,F_{i}(M)/F_{i-1}(M))=0$ and  \n\n$$\n\\operatorname{Tor}_{1}^{S}(R,\\,F_{i-1}(M))\\cong\\operatorname{Tor}_{2}^{S}(R,\\,F_{i}(M)/F_{i-1}(M)).\n$$  \n\nThen if $K_{i}$ denotes the kernel of  \n\n$$\nS\\otimes_{R}Q_{i}\\to F_{i}(M)/F_{i-1}(M),\n$$  \n\ntensoring with $R$ gives the exact sequence  \n\n$$\n0=\\operatorname{Tor}_{1}^{S}(R,\\,F_{i}(M)/F_{i-1}(M))\\to R\\otimes_{S}K_{i}\n$$  \n\n$$\n\\begin{array}{c c c c}{{\\longrightarrow}}&{R\\otimes_{S}(S\\otimes_{R}Q_{i})}&{\\longrightarrow}&{R\\otimes_{S}(F_{i}(M)/F_{i-1}(M))}\\\\{{ }}&{{\\Big\\Vert}}&{{ }}&{{\\Big\\Vert}}\\\\ &{{Q_{i}}}&{{=}}&{{Q_{i}.}}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "For $i<n_{0}$ or $i>n_{1}$, this is obvious since both sides are zero.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM_147_-_ISBN978-1-4612-4314-4_-_Jonathan_Rosenberg_-_Algebraic_K-Theory_and_Its_Applications.pdf_149",
        "ID": "0a02da60-749d-4601-9f98-377981bd5336",
        "questions": "What condition about the module $M$ is given for ensuring that the filtration $F_i(M)$ terminates at a finite stage?",
        "answers": "M is finitely generated and Noetherian",
        "context": "If $M_{i}=0$ for $i<n_{0}$, then  \n\n$$\n0=F_{n_{0}-1}(M)\\subseteq F_{n_{0}}(M)\\subseteq\\cdots\\subseteq F_{+\\infty}(M)=M,\n$$  \n\nand the filtration must terminate at some finite stage, i.e., $F_{n_{1}}(M)=M$ for some $\\mathbf{\\mathit{n}_{1}}$, since $M$ is finitely generated and Noetherian. Note that there is a map of graded $S$-modules from $S\\otimes_{R}M_{i}$ to $F_{i}(M)$, which induces by passage to the quotient a surjective map of graded $S$-modules  \n\n$$\nS\\otimes_{R}Q_{i}\\to F_{i}(M)/F_{i-1}(M).\n$$  \n\nHere we are reviewing $M_{i}$ and $Q_{i}$ as graded modules concentrated in the single degree $i$. We will show this map is an isomorphism for each $i$.  \n\nFor $i<n_{0}$ or $i>n_{1}$, this is obvious since both sides are zero. Suppose we know that $\\operatorname{Tor}_{1}^{S}(R,\\,F_{i}(M))=0$, which is at least the case for $i=n_{1}$ since $M\\in\\operatorname{Obj}\\mathcal{F}$. From the short exact sequence of graded modules  \n\n$$\n0\\to F_{i-1}(M)\\to F_{i}(M)\\to F_{i}(M)/F_{i-1}(M)\\to0\n$$  \n\nand the fact that the natural map  \n\n$$\nR\\otimes_{S}F_{i-1}(M)\\to R\\otimes_{S}F_{i}(M)\n$$  \n\nis injective with cokernel $Q_{i}$, we see first that $\\operatorname{Tor}_{1}^{S}(R,\\,F_{i}(M))=0$ implies also $\\operatorname{Tor}_{1}^{S}(R,\\,F_{i}(M)/F_{i-1}(M))=0$ and  \n\n$$\n\\operatorname{Tor}_{1}^{S}(R,\\,F_{i-1}(M))\\cong\\operatorname{Tor}_{2}^{S}(R,\\,F_{i}(M)/F_{i-1}(M)).\n$$  \n\nThen if $K_{i}$ denotes the kernel of  \n\n$$\nS\\otimes_{R}Q_{i}\\to F_{i}(M)/F_{i-1}(M),\n$$  \n\ntensoring with $R$ gives the exact sequence  \n\n$$\n0=\\operatorname{Tor}_{1}^{S}(R,\\,F_{i}(M)/F_{i-1}(M))\\to R\\otimes_{S}K_{i}\n$$  \n\n$$\n\\begin{array}{c c c c}{{\\longrightarrow}}&{R\\otimes_{S}(S\\otimes_{R}Q_{i})}&{\\longrightarrow}&{R\\otimes_{S}(F_{i}(M)/F_{i-1}(M))}\\\\{{ }}&{{\\Big\\Vert}}&{{ }}&{{\\Big\\Vert}}\\\\ &{{Q_{i}}}&{{=}}&{{Q_{i}.}}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "the filtration must terminate at some finite stage, i.e., $F_{n_{1}}(M)=M$ for some $\\mathbf{\\mathit{n}_{1}}$, since $M$ is finitely generated and Noetherian.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM_147_-_ISBN978-1-4612-4314-4_-_Jonathan_Rosenberg_-_Algebraic_K-Theory_and_Its_Applications.pdf_149",
        "ID": "0a06c083-e848-4a50-9524-7332c4f56173",
        "questions": "What is the consequence of $\\operatorname{Tor}_{1}^{S}(R,\\,F_{i}(M))=0$ regarding $\\operatorname{Tor}_{1}^{S}(R,\\,F_{i}(M)/F_{i-1}(M))$?",
        "answers": "$\\operatorname{Tor}_{1}^{S}(R,\\,F_{i}(M))=0$ implies also $\\operatorname{Tor}_{1}^{S}(R,\\,F_{i}(M)/F_{i-1}(M))=0$",
        "context": "If $M_{i}=0$ for $i<n_{0}$, then  \n\n$$\n0=F_{n_{0}-1}(M)\\subseteq F_{n_{0}}(M)\\subseteq\\cdots\\subseteq F_{+\\infty}(M)=M,\n$$  \n\nand the filtration must terminate at some finite stage, i.e., $F_{n_{1}}(M)=M$ for some $\\mathbf{\\mathit{n}_{1}}$, since $M$ is finitely generated and Noetherian. Note that there is a map of graded $S$-modules from $S\\otimes_{R}M_{i}$ to $F_{i}(M)$, which induces by passage to the quotient a surjective map of graded $S$-modules  \n\n$$\nS\\otimes_{R}Q_{i}\\to F_{i}(M)/F_{i-1}(M).\n$$  \n\nHere we are reviewing $M_{i}$ and $Q_{i}$ as graded modules concentrated in the single degree $i$. We will show this map is an isomorphism for each $i$.  \n\nFor $i<n_{0}$ or $i>n_{1}$, this is obvious since both sides are zero. Suppose we know that $\\operatorname{Tor}_{1}^{S}(R,\\,F_{i}(M))=0$, which is at least the case for $i=n_{1}$ since $M\\in\\operatorname{Obj}\\mathcal{F}$. From the short exact sequence of graded modules  \n\n$$\n0\\to F_{i-1}(M)\\to F_{i}(M)\\to F_{i}(M)/F_{i-1}(M)\\to0\n$$  \n\nand the fact that the natural map  \n\n$$\nR\\otimes_{S}F_{i-1}(M)\\to R\\otimes_{S}F_{i}(M)\n$$  \n\nis injective with cokernel $Q_{i}$, we see first that $\\operatorname{Tor}_{1}^{S}(R,\\,F_{i}(M))=0$ implies also $\\operatorname{Tor}_{1}^{S}(R,\\,F_{i}(M)/F_{i-1}(M))=0$ and  \n\n$$\n\\operatorname{Tor}_{1}^{S}(R,\\,F_{i-1}(M))\\cong\\operatorname{Tor}_{2}^{S}(R,\\,F_{i}(M)/F_{i-1}(M)).\n$$  \n\nThen if $K_{i}$ denotes the kernel of  \n\n$$\nS\\otimes_{R}Q_{i}\\to F_{i}(M)/F_{i-1}(M),\n$$  \n\ntensoring with $R$ gives the exact sequence  \n\n$$\n0=\\operatorname{Tor}_{1}^{S}(R,\\,F_{i}(M)/F_{i-1}(M))\\to R\\otimes_{S}K_{i}\n$$  \n\n$$\n\\begin{array}{c c c c}{{\\longrightarrow}}&{R\\otimes_{S}(S\\otimes_{R}Q_{i})}&{\\longrightarrow}&{R\\otimes_{S}(F_{i}(M)/F_{i-1}(M))}\\\\{{ }}&{{\\Big\\Vert}}&{{ }}&{{\\Big\\Vert}}\\\\ &{{Q_{i}}}&{{=}}&{{Q_{i}.}}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "$\\operatorname{Tor}_{1}^{S}(R,\\,F_{i}(M))=0$ implies also $\\operatorname{Tor}_{1}^{S}(R,\\,F_{i}(M)/F_{i-1}(M))=0$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM_147_-_ISBN978-1-4612-4314-4_-_Jonathan_Rosenberg_-_Algebraic_K-Theory_and_Its_Applications.pdf_149",
        "ID": "0a091c4a-a6e3-4dc1-a9e1-f6375ab9c945",
        "questions": "For which values of $i$ is it obvious that the map $S\\otimes_{R}Q_{i} \\to F_{i}(M)/F_{i-1}(M)$ is an isomorphism?",
        "answers": "For $i < n_{0}$ or $i > n_{1}$.",
        "context": "If $M_{i}=0$ for $i<n_{0}$, then  \n\n$$\n0=F_{n_{0}-1}(M)\\subseteq F_{n_{0}}(M)\\subseteq\\cdots\\subseteq F_{+\\infty}(M)=M,\n$$  \n\nand the filtration must terminate at some finite stage, i.e., $F_{n_{1}}(M)=M$ for some $\\mathbf{\\mathit{n}_{1}}$, since $M$ is finitely generated and Noetherian. Note that there is a map of graded $S$-modules from $S\\otimes_{R}M_{i}$ to $F_{i}(M)$, which induces by passage to the quotient a surjective map of graded $S$-modules  \n\n$$\nS\\otimes_{R}Q_{i}\\to F_{i}(M)/F_{i-1}(M).\n$$  \n\nHere we are reviewing $M_{i}$ and $Q_{i}$ as graded modules concentrated in the single degree $i$. We will show this map is an isomorphism for each $i$.  \n\nFor $i<n_{0}$ or $i>n_{1}$, this is obvious since both sides are zero. Suppose we know that $\\operatorname{Tor}_{1}^{S}(R,\\,F_{i}(M))=0$, which is at least the case for $i=n_{1}$ since $M\\in\\operatorname{Obj}\\mathcal{F}$. From the short exact sequence of graded modules  \n\n$$\n0\\to F_{i-1}(M)\\to F_{i}(M)\\to F_{i}(M)/F_{i-1}(M)\\to0\n$$  \n\nand the fact that the natural map  \n\n$$\nR\\otimes_{S}F_{i-1}(M)\\to R\\otimes_{S}F_{i}(M)\n$$  \n\nis injective with cokernel $Q_{i}$, we see first that $\\operatorname{Tor}_{1}^{S}(R,\\,F_{i}(M))=0$ implies also $\\operatorname{Tor}_{1}^{S}(R,\\,F_{i}(M)/F_{i-1}(M))=0$ and  \n\n$$\n\\operatorname{Tor}_{1}^{S}(R,\\,F_{i-1}(M))\\cong\\operatorname{Tor}_{2}^{S}(R,\\,F_{i}(M)/F_{i-1}(M)).\n$$  \n\nThen if $K_{i}$ denotes the kernel of  \n\n$$\nS\\otimes_{R}Q_{i}\\to F_{i}(M)/F_{i-1}(M),\n$$  \n\ntensoring with $R$ gives the exact sequence  \n\n$$\n0=\\operatorname{Tor}_{1}^{S}(R,\\,F_{i}(M)/F_{i-1}(M))\\to R\\otimes_{S}K_{i}\n$$  \n\n$$\n\\begin{array}{c c c c}{{\\longrightarrow}}&{R\\otimes_{S}(S\\otimes_{R}Q_{i})}&{\\longrightarrow}&{R\\otimes_{S}(F_{i}(M)/F_{i-1}(M))}\\\\{{ }}&{{\\Big\\Vert}}&{{ }}&{{\\Big\\Vert}}\\\\ &{{Q_{i}}}&{{=}}&{{Q_{i}.}}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "For $i<n_{0}$ or $i>n_{1}$, this is obvious since both sides are zero.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/GTM_147_-_ISBN978-1-4612-4314-4_-_Jonathan_Rosenberg_-_Algebraic_K-Theory_and_Its_Applications.pdf_149",
        "ID": "0a0bde93-307e-49b4-b740-79fcca49ae99",
        "questions": "What implication can be drawn if $\\operatorname{Tor}_{1}^{S}(R,\\,F_{i}(M))=0$?",
        "answers": "It implies $\\operatorname{Tor}_{1}^{S}(R,\\,F_{i}(M)/F_{i-1}(M))=0$ and $\\operatorname{Tor}_{1}^{S}(R,\\,F_{i-1}(M))\\cong\\operatorname{Tor}_{2}^{S}(R,\\,F_{i}(M)/F_{i-1}(M)).",
        "context": "If $M_{i}=0$ for $i<n_{0}$, then  \n\n$$\n0=F_{n_{0}-1}(M)\\subseteq F_{n_{0}}(M)\\subseteq\\cdots\\subseteq F_{+\\infty}(M)=M,\n$$  \n\nand the filtration must terminate at some finite stage, i.e., $F_{n_{1}}(M)=M$ for some $\\mathbf{\\mathit{n}_{1}}$, since $M$ is finitely generated and Noetherian. Note that there is a map of graded $S$-modules from $S\\otimes_{R}M_{i}$ to $F_{i}(M)$, which induces by passage to the quotient a surjective map of graded $S$-modules  \n\n$$\nS\\otimes_{R}Q_{i}\\to F_{i}(M)/F_{i-1}(M).\n$$  \n\nHere we are reviewing $M_{i}$ and $Q_{i}$ as graded modules concentrated in the single degree $i$. We will show this map is an isomorphism for each $i$.  \n\nFor $i<n_{0}$ or $i>n_{1}$, this is obvious since both sides are zero. Suppose we know that $\\operatorname{Tor}_{1}^{S}(R,\\,F_{i}(M))=0$, which is at least the case for $i=n_{1}$ since $M\\in\\operatorname{Obj}\\mathcal{F}$. From the short exact sequence of graded modules  \n\n$$\n0\\to F_{i-1}(M)\\to F_{i}(M)\\to F_{i}(M)/F_{i-1}(M)\\to0\n$$  \n\nand the fact that the natural map  \n\n$$\nR\\otimes_{S}F_{i-1}(M)\\to R\\otimes_{S}F_{i}(M)\n$$  \n\nis injective with cokernel $Q_{i}$, we see first that $\\operatorname{Tor}_{1}^{S}(R,\\,F_{i}(M))=0$ implies also $\\operatorname{Tor}_{1}^{S}(R,\\,F_{i}(M)/F_{i-1}(M))=0$ and  \n\n$$\n\\operatorname{Tor}_{1}^{S}(R,\\,F_{i-1}(M))\\cong\\operatorname{Tor}_{2}^{S}(R,\\,F_{i}(M)/F_{i-1}(M)).\n$$  \n\nThen if $K_{i}$ denotes the kernel of  \n\n$$\nS\\otimes_{R}Q_{i}\\to F_{i}(M)/F_{i-1}(M),\n$$  \n\ntensoring with $R$ gives the exact sequence  \n\n$$\n0=\\operatorname{Tor}_{1}^{S}(R,\\,F_{i}(M)/F_{i-1}(M))\\to R\\otimes_{S}K_{i}\n$$  \n\n$$\n\\begin{array}{c c c c}{{\\longrightarrow}}&{R\\otimes_{S}(S\\otimes_{R}Q_{i})}&{\\longrightarrow}&{R\\otimes_{S}(F_{i}(M)/F_{i-1}(M))}\\\\{{ }}&{{\\Big\\Vert}}&{{ }}&{{\\Big\\Vert}}\\\\ &{{Q_{i}}}&{{=}}&{{Q_{i}.}}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$\\operatorname{Tor}_{1}^{S}(R,\\,F_{i}(M))=0$ implies also $\\operatorname{Tor}_{1}^{S}(R,\\,F_{i}(M)/F_{i-1}(M))=0$ and $\\operatorname{Tor}_{1}^{S}(R,\\,F_{i-1}(M))\\cong\\operatorname{Tor}_{2}^{S}(R,\\,F_{i}(M)/F_{i-1}(M)).",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/GTM_147_-_ISBN978-1-4612-4314-4_-_Jonathan_Rosenberg_-_Algebraic_K-Theory_and_Its_Applications.pdf_149",
        "ID": "0a1ef423-c774-4f6f-b3cf-95610dacd533",
        "questions": "What is the sequence obtained after tensoring $K_{i}$ with $R$?",
        "answers": "0 = \\operatorname{Tor}_{1}^{S}(R,\\,F_{i}(M)/F_{i-1}(M)) \\to R\\otimes_{S}K_{i} \\longrightarrow R\\otimes_{S}(S\\otimes_{R}Q_{i}) \\longrightarrow R\\otimes_{S}(F_{i}(M)/F_{i-1}(M)) \\Big\\Vert Q_{i} = Q_{i}.",
        "context": "If $M_{i}=0$ for $i<n_{0}$, then  \n\n$$\n0=F_{n_{0}-1}(M)\\subseteq F_{n_{0}}(M)\\subseteq\\cdots\\subseteq F_{+\\infty}(M)=M,\n$$  \n\nand the filtration must terminate at some finite stage, i.e., $F_{n_{1}}(M)=M$ for some $\\mathbf{\\mathit{n}_{1}}$, since $M$ is finitely generated and Noetherian. Note that there is a map of graded $S$-modules from $S\\otimes_{R}M_{i}$ to $F_{i}(M)$, which induces by passage to the quotient a surjective map of graded $S$-modules  \n\n$$\nS\\otimes_{R}Q_{i}\\to F_{i}(M)/F_{i-1}(M).\n$$  \n\nHere we are reviewing $M_{i}$ and $Q_{i}$ as graded modules concentrated in the single degree $i$. We will show this map is an isomorphism for each $i$.  \n\nFor $i<n_{0}$ or $i>n_{1}$, this is obvious since both sides are zero. Suppose we know that $\\operatorname{Tor}_{1}^{S}(R,\\,F_{i}(M))=0$, which is at least the case for $i=n_{1}$ since $M\\in\\operatorname{Obj}\\mathcal{F}$. From the short exact sequence of graded modules  \n\n$$\n0\\to F_{i-1}(M)\\to F_{i}(M)\\to F_{i}(M)/F_{i-1}(M)\\to0\n$$  \n\nand the fact that the natural map  \n\n$$\nR\\otimes_{S}F_{i-1}(M)\\to R\\otimes_{S}F_{i}(M)\n$$  \n\nis injective with cokernel $Q_{i}$, we see first that $\\operatorname{Tor}_{1}^{S}(R,\\,F_{i}(M))=0$ implies also $\\operatorname{Tor}_{1}^{S}(R,\\,F_{i}(M)/F_{i-1}(M))=0$ and  \n\n$$\n\\operatorname{Tor}_{1}^{S}(R,\\,F_{i-1}(M))\\cong\\operatorname{Tor}_{2}^{S}(R,\\,F_{i}(M)/F_{i-1}(M)).\n$$  \n\nThen if $K_{i}$ denotes the kernel of  \n\n$$\nS\\otimes_{R}Q_{i}\\to F_{i}(M)/F_{i-1}(M),\n$$  \n\ntensoring with $R$ gives the exact sequence  \n\n$$\n0=\\operatorname{Tor}_{1}^{S}(R,\\,F_{i}(M)/F_{i-1}(M))\\to R\\otimes_{S}K_{i}\n$$  \n\n$$\n\\begin{array}{c c c c}{{\\longrightarrow}}&{R\\otimes_{S}(S\\otimes_{R}Q_{i})}&{\\longrightarrow}&{R\\otimes_{S}(F_{i}(M)/F_{i-1}(M))}\\\\{{ }}&{{\\Big\\Vert}}&{{ }}&{{\\Big\\Vert}}\\\\ &{{Q_{i}}}&{{=}}&{{Q_{i}.}}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "tensoring with $R$ gives the exact sequence 0=\\operatorname{Tor}_{1}^{S}(R,\\,F_{i}(M)/F_{i-1}(M))\\to R\\otimes_{S}K_{i} \\begin{array}{c c c c}{{\\longrightarrow}}&{R\\otimes_{S}(S\\otimes_{R}Q_{i})}&{{\\longrightarrow}}&{R\\otimes_{S}(F_{i}(M)/F_{i-1}(M))}{{ }}&{{\\Big\\Vert}}&{{ }}&{{\\Big\\Vert}} &{{Q_{i}}}&{{=}}&{{Q_{i}.}}\\end{array}",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/(Graduate_Studies_in_Mathematics,201)_Lee,_Dan_A._-_Geometric_relativity_(2019,_American_Mathematical_Society).pdf_289",
        "ID": "0a22b2ce-234e-45fe-bcee-7eb021653fa6",
        "questions": "What is the connection $\tilde{\nabla}$ defined as on $\tilde{S}(M)$ in terms of the Levi-Civita connection $\nabla$ and the extrinsic curvature $k_{ij}$?",
        "answers": "$\tilde{\nabla}_{i}=\nabla_{i}+\frac{1}{2}k_{ij}e_{j}e_{0}$",
        "context": "In this section, we will adopt Einstein summation notation except when we say otherwise. We define a new connection $\\tilde{\\nabla}$ on $\\tilde{S}(M)$ according to\n\n$$\n\\tilde{\\nabla}_{i}=\\nabla_{i}+\\frac{1}{2}k_{i j}e_{j}e_{0}.\n$$\n\n(From a spacetime perspective, the connection $\\tilde{\\nabla}$ comes from the ambient Levi-Civita connection on $T M$, while $\\nabla$ comes from the intrinsically defined Levi-Civita connection on $T M$.) We now define the hypersurface Dirac operator $\\tilde{\\mathcal{D}}$ on $\\tilde{S}(M)$ by\n\n$$\n\\begin{array}{l}{{\\tilde{D}=e_{i}\\cdot\\tilde{\\nabla}_{i}}}\\\\ {{\\ }}\\\\ {{\\displaystyle=D+\\frac12k_{i j}e_{i}e_{j}e_{0}}}\\\\ {{\\ }}\\\\ {{\\displaystyle={\\mathcal{D}}-\\frac12({\\mathrm{tr}}\\,k)e_{0},}}\\end{array}\n$$\n\nwhere $\\mathcal{D}$ is the usual Dirac operator on $\\tilde{S}(M)$ as defined in Chapter 5, and we used symmetry considerations in the last line. (The trace of $k$ is computed with respect to $g$.) Next, we obtain a version of the Schr\u00f6dinger-Lichnerowicz formula (Theorem 5.10) for initial data sets.\n\nTheorem 8.21 (Witten). Let $(M,g,k)$ be a spin initial data set. For any $\\psi\\in C^{\\infty}(\\tilde{S}(M))$\n\n$$\n\\tilde{D}^{2}\\psi=\\tilde{\\nabla}_{i}^{\\ast}\\tilde{\\nabla}_{i}\\psi+\\frac{1}{2}(\\mu+J e_{0})\\cdot\\psi,\n$$\n\nwhere $\\tilde{\\nabla}^{*}$ is the formal adjoint of $\\tilde{\\nabla}$ on ${\\tilde{S}}(M)$\n\nProof. We will take advantage of the work we already did to prove Theorem 5.10 in Chapter 5. As usual, we choose an orthonormal basis $e_{1},.\\cdot\\cdot\\cdot,e_{n}$ that is parallel at the point where we are computing. For any $\\psi\\!\\in\\!C^{\\infty}(\\tilde{S}(M))$, we have\n\n$$\n\\begin{array}{r l}&{\\tilde{\\mathcal{D}}^{2}\\psi=\\mathcal{D}^{2}\\psi-\\cfrac{1}{2}e_{i}\\cdot\\nabla_{i}[(\\operatorname{tr}k)e_{0}\\cdot\\psi]-\\cfrac{1}{2}(\\operatorname{tr}k)e_{0}e_{i}\\cdot\\nabla_{i}\\psi-\\cfrac{1}{4}(\\operatorname{tr}k)^{2}\\psi}\\\\ &{\\quad\\quad=\\big(\\nabla^{*}\\nabla\\psi+\\cfrac{1}{4}R\\psi\\big)-\\cfrac{1}{2}\\nabla_{i}(\\operatorname{tr}k)e_{i}e_{0}\\cdot\\psi-\\cfrac{1}{4}(\\operatorname{tr}k)^{2}\\psi}\\\\ &{\\quad\\quad=\\nabla^{*}\\nabla\\psi+\\cfrac{1}{2}\\left[\\cfrac{1}{2}(R-(\\operatorname{tr}k)^{2})-\\nabla(\\operatorname{tr}k)e_{0}\\right]\\cdot\\psi,}\\end{array}\n$$\n\nwhere we used Theorem 5.10 in the second line. On the other hand, since the formal adjoint of $\\nabla$ on $\\tilde{S}(M)$ is\n\n$$\n\\tilde{\\nabla}_{i}^{*}=-\\nabla_{i}+\\frac{1}{2}k_{i j}e_{j}e_{0},\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Equation",
        "evidence_source": "text",
        "evidence_context": "We define a new connection $\tilde{\nabla}$ on $\tilde{S}(M)$ according to $\tilde{\nabla}_{i}=\nabla_{i}+\frac{1}{2}k_{ij}e_{j}e_{0}$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/(Graduate_Studies_in_Mathematics,201)_Lee,_Dan_A._-_Geometric_relativity_(2019,_American_Mathematical_Society).pdf_289",
        "ID": "0a24076e-a335-4b03-a152-aaa9cc01bc9b",
        "questions": "What theorem provides a version of the Schr\u00f6dinger-Lichnerowicz formula for spin initial data sets $(M,g,k)$?",
        "answers": "Theorem 8.21 (Witten)",
        "context": "In this section, we will adopt Einstein summation notation except when we say otherwise. We define a new connection $\\tilde{\\nabla}$ on $\\tilde{S}(M)$ according to\n\n$$\n\\tilde{\\nabla}_{i}=\\nabla_{i}+\\frac{1}{2}k_{i j}e_{j}e_{0}.\n$$\n\n(From a spacetime perspective, the connection $\\tilde{\\nabla}$ comes from the ambient Levi-Civita connection on $T M$, while $\\nabla$ comes from the intrinsically defined Levi-Civita connection on $T M$.) We now define the hypersurface Dirac operator $\\tilde{\\mathcal{D}}$ on $\\tilde{S}(M)$ by\n\n$$\n\\begin{array}{l}{{\\tilde{D}=e_{i}\\cdot\\tilde{\\nabla}_{i}}}\\\\ {{\\ }}\\\\ {{\\displaystyle=D+\\frac12k_{i j}e_{i}e_{j}e_{0}}}\\\\ {{\\ }}\\\\ {{\\displaystyle={\\mathcal{D}}-\\frac12({\\mathrm{tr}}\\,k)e_{0},}}\\end{array}\n$$\n\nwhere $\\mathcal{D}$ is the usual Dirac operator on $\\tilde{S}(M)$ as defined in Chapter 5, and we used symmetry considerations in the last line. (The trace of $k$ is computed with respect to $g$.) Next, we obtain a version of the Schr\u00f6dinger-Lichnerowicz formula (Theorem 5.10) for initial data sets.\n\nTheorem 8.21 (Witten). Let $(M,g,k)$ be a spin initial data set. For any $\\psi\\in C^{\\infty}(\\tilde{S}(M))$\n\n$$\n\\tilde{D}^{2}\\psi=\\tilde{\\nabla}_{i}^{\\ast}\\tilde{\\nabla}_{i}\\psi+\\frac{1}{2}(\\mu+J e_{0})\\cdot\\psi,\n$$\n\nwhere $\\tilde{\\nabla}^{*}$ is the formal adjoint of $\\tilde{\\nabla}$ on ${\\tilde{S}}(M)$\n\nProof. We will take advantage of the work we already did to prove Theorem 5.10 in Chapter 5. As usual, we choose an orthonormal basis $e_{1},.\\cdot\\cdot\\cdot,e_{n}$ that is parallel at the point where we are computing. For any $\\psi\\!\\in\\!C^{\\infty}(\\tilde{S}(M))$, we have\n\n$$\n\\begin{array}{r l}&{\\tilde{\\mathcal{D}}^{2}\\psi=\\mathcal{D}^{2}\\psi-\\cfrac{1}{2}e_{i}\\cdot\\nabla_{i}[(\\operatorname{tr}k)e_{0}\\cdot\\psi]-\\cfrac{1}{2}(\\operatorname{tr}k)e_{0}e_{i}\\cdot\\nabla_{i}\\psi-\\cfrac{1}{4}(\\operatorname{tr}k)^{2}\\psi}\\\\ &{\\quad\\quad=\\big(\\nabla^{*}\\nabla\\psi+\\cfrac{1}{4}R\\psi\\big)-\\cfrac{1}{2}\\nabla_{i}(\\operatorname{tr}k)e_{i}e_{0}\\cdot\\psi-\\cfrac{1}{4}(\\operatorname{tr}k)^{2}\\psi}\\\\ &{\\quad\\quad=\\nabla^{*}\\nabla\\psi+\\cfrac{1}{2}\\left[\\cfrac{1}{2}(R-(\\operatorname{tr}k)^{2})-\\nabla(\\operatorname{tr}k)e_{0}\\right]\\cdot\\psi,}\\end{array}\n$$\n\nwhere we used Theorem 5.10 in the second line. On the other hand, since the formal adjoint of $\\nabla$ on $\\tilde{S}(M)$ is\n\n$$\n\\tilde{\\nabla}_{i}^{*}=-\\nabla_{i}+\\frac{1}{2}k_{i j}e_{j}e_{0},\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Theorem 8.21 (Witten). Let $(M,g,k)$ be a spin initial data set. For any $\\psi\\in C^{\\infty}(\tilde{S}(M))$ ...",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/(Graduate_Studies_in_Mathematics,201)_Lee,_Dan_A._-_Geometric_relativity_(2019,_American_Mathematical_Society).pdf_289",
        "ID": "0a31f6e2-ad79-44d6-95cb-74713ed0141c",
        "questions": "In the proof of Theorem 8.21, what expression is used to represent the formal adjoint of $\tilde{\nabla}$ on $\tilde{S}(M)$?",
        "answers": "$\tilde{\nabla}_{i}^{*}=-\nabla_{i}+\frac{1}{2}k_{ij}e_{j}e_{0}$",
        "context": "In this section, we will adopt Einstein summation notation except when we say otherwise. We define a new connection $\\tilde{\\nabla}$ on $\\tilde{S}(M)$ according to\n\n$$\n\\tilde{\\nabla}_{i}=\\nabla_{i}+\\frac{1}{2}k_{i j}e_{j}e_{0}.\n$$\n\n(From a spacetime perspective, the connection $\\tilde{\\nabla}$ comes from the ambient Levi-Civita connection on $T M$, while $\\nabla$ comes from the intrinsically defined Levi-Civita connection on $T M$.) We now define the hypersurface Dirac operator $\\tilde{\\mathcal{D}}$ on $\\tilde{S}(M)$ by\n\n$$\n\\begin{array}{l}{{\\tilde{D}=e_{i}\\cdot\\tilde{\\nabla}_{i}}}\\\\ {{\\ }}\\\\ {{\\displaystyle=D+\\frac12k_{i j}e_{i}e_{j}e_{0}}}\\\\ {{\\ }}\\\\ {{\\displaystyle={\\mathcal{D}}-\\frac12({\\mathrm{tr}}\\,k)e_{0},}}\\end{array}\n$$\n\nwhere $\\mathcal{D}$ is the usual Dirac operator on $\\tilde{S}(M)$ as defined in Chapter 5, and we used symmetry considerations in the last line. (The trace of $k$ is computed with respect to $g$.) Next, we obtain a version of the Schr\u00f6dinger-Lichnerowicz formula (Theorem 5.10) for initial data sets.\n\nTheorem 8.21 (Witten). Let $(M,g,k)$ be a spin initial data set. For any $\\psi\\in C^{\\infty}(\\tilde{S}(M))$\n\n$$\n\\tilde{D}^{2}\\psi=\\tilde{\\nabla}_{i}^{\\ast}\\tilde{\\nabla}_{i}\\psi+\\frac{1}{2}(\\mu+J e_{0})\\cdot\\psi,\n$$\n\nwhere $\\tilde{\\nabla}^{*}$ is the formal adjoint of $\\tilde{\\nabla}$ on ${\\tilde{S}}(M)$\n\nProof. We will take advantage of the work we already did to prove Theorem 5.10 in Chapter 5. As usual, we choose an orthonormal basis $e_{1},.\\cdot\\cdot\\cdot,e_{n}$ that is parallel at the point where we are computing. For any $\\psi\\!\\in\\!C^{\\infty}(\\tilde{S}(M))$, we have\n\n$$\n\\begin{array}{r l}&{\\tilde{\\mathcal{D}}^{2}\\psi=\\mathcal{D}^{2}\\psi-\\cfrac{1}{2}e_{i}\\cdot\\nabla_{i}[(\\operatorname{tr}k)e_{0}\\cdot\\psi]-\\cfrac{1}{2}(\\operatorname{tr}k)e_{0}e_{i}\\cdot\\nabla_{i}\\psi-\\cfrac{1}{4}(\\operatorname{tr}k)^{2}\\psi}\\\\ &{\\quad\\quad=\\big(\\nabla^{*}\\nabla\\psi+\\cfrac{1}{4}R\\psi\\big)-\\cfrac{1}{2}\\nabla_{i}(\\operatorname{tr}k)e_{i}e_{0}\\cdot\\psi-\\cfrac{1}{4}(\\operatorname{tr}k)^{2}\\psi}\\\\ &{\\quad\\quad=\\nabla^{*}\\nabla\\psi+\\cfrac{1}{2}\\left[\\cfrac{1}{2}(R-(\\operatorname{tr}k)^{2})-\\nabla(\\operatorname{tr}k)e_{0}\\right]\\cdot\\psi,}\\end{array}\n$$\n\nwhere we used Theorem 5.10 in the second line. On the other hand, since the formal adjoint of $\\nabla$ on $\\tilde{S}(M)$ is\n\n$$\n\\tilde{\\nabla}_{i}^{*}=-\\nabla_{i}+\\frac{1}{2}k_{i j}e_{j}e_{0},\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Equation",
        "evidence_source": "text",
        "evidence_context": "On the other hand, since the formal adjoint of $\nabla$ on $\tilde{S}(M)$ is $\tilde{\nabla}_{i}^{*}=-\nabla_{i}+\frac{1}{2}k_{ij}e_{j}e_{0}$,",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/(Graduate_Studies_in_Mathematics,201)_Lee,_Dan_A._-_Geometric_relativity_(2019,_American_Mathematical_Society).pdf_289",
        "ID": "0a34886c-802e-4a41-86bc-6b82f5943dda",
        "questions": "What is the modified connection $\tilde{\nabla}_i$ in terms of the Levi-Civita connection $\nabla_i$ and other components on $\tilde{S}(M)$?",
        "answers": "$\\tilde{\\nabla}_{i}=\\nabla_{i}+\\frac{1}{2}k_{i j}e_{j}e_{0}$",
        "context": "In this section, we will adopt Einstein summation notation except when we say otherwise. We define a new connection $\\tilde{\\nabla}$ on $\\tilde{S}(M)$ according to\n\n$$\n\\tilde{\\nabla}_{i}=\\nabla_{i}+\\frac{1}{2}k_{i j}e_{j}e_{0}.\n$$\n\n(From a spacetime perspective, the connection $\\tilde{\\nabla}$ comes from the ambient Levi-Civita connection on $T M$, while $\\nabla$ comes from the intrinsically defined Levi-Civita connection on $T M$.) We now define the hypersurface Dirac operator $\\tilde{\\mathcal{D}}$ on $\\tilde{S}(M)$ by\n\n$$\n\\begin{array}{l}{{\\tilde{D}=e_{i}\\cdot\\tilde{\\nabla}_{i}}}\\\\ {{\\ }}\\\\ {{\\displaystyle=D+\\frac12k_{i j}e_{i}e_{j}e_{0}}}\\\\ {{\\ }}\\\\ {{\\displaystyle={\\mathcal{D}}-\\frac12({\\mathrm{tr}}\\,k)e_{0},}}\\end{array}\n$$\n\nwhere $\\mathcal{D}$ is the usual Dirac operator on $\\tilde{S}(M)$ as defined in Chapter 5, and we used symmetry considerations in the last line. (The trace of $k$ is computed with respect to $g$.) Next, we obtain a version of the Schr\u00f6dinger-Lichnerowicz formula (Theorem 5.10) for initial data sets.\n\nTheorem 8.21 (Witten). Let $(M,g,k)$ be a spin initial data set. For any $\\psi\\in C^{\\infty}(\\tilde{S}(M))$\n\n$$\n\\tilde{D}^{2}\\psi=\\tilde{\\nabla}_{i}^{\\ast}\\tilde{\\nabla}_{i}\\psi+\\frac{1}{2}(\\mu+J e_{0})\\cdot\\psi,\n$$\n\nwhere $\\tilde{\\nabla}^{*}$ is the formal adjoint of $\\tilde{\\nabla}$ on ${\\tilde{S}}(M)$\n\nProof. We will take advantage of the work we already did to prove Theorem 5.10 in Chapter 5. As usual, we choose an orthonormal basis $e_{1},.\\cdot\\cdot\\cdot,e_{n}$ that is parallel at the point where we are computing. For any $\\psi\\!\\in\\!C^{\\infty}(\\tilde{S}(M))$, we have\n\n$$\n\\begin{array}{r l}&{\\tilde{\\mathcal{D}}^{2}\\psi=\\mathcal{D}^{2}\\psi-\\cfrac{1}{2}e_{i}\\cdot\\nabla_{i}[(\\operatorname{tr}k)e_{0}\\cdot\\psi]-\\cfrac{1}{2}(\\operatorname{tr}k)e_{0}e_{i}\\cdot\\nabla_{i}\\psi-\\cfrac{1}{4}(\\operatorname{tr}k)^{2}\\psi}\\\\ &{\\quad\\quad=\\big(\\nabla^{*}\\nabla\\psi+\\cfrac{1}{4}R\\psi\\big)-\\cfrac{1}{2}\\nabla_{i}(\\operatorname{tr}k)e_{i}e_{0}\\cdot\\psi-\\cfrac{1}{4}(\\operatorname{tr}k)^{2}\\psi}\\\\ &{\\quad\\quad=\\nabla^{*}\\nabla\\psi+\\cfrac{1}{2}\\left[\\cfrac{1}{2}(R-(\\operatorname{tr}k)^{2})-\\nabla(\\operatorname{tr}k)e_{0}\\right]\\cdot\\psi,}\\end{array}\n$$\n\nwhere we used Theorem 5.10 in the second line. On the other hand, since the formal adjoint of $\\nabla$ on $\\tilde{S}(M)$ is\n\n$$\n\\tilde{\\nabla}_{i}^{*}=-\\nabla_{i}+\\frac{1}{2}k_{i j}e_{j}e_{0},\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$\\tilde{\\nabla}_{i}=\\nabla_{i}+\\frac{1}{2}k_{i j}e_{j}e_{0}$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/(Graduate_Studies_in_Mathematics,201)_Lee,_Dan_A._-_Geometric_relativity_(2019,_American_Mathematical_Society).pdf_289",
        "ID": "0a3c2c6f-ef2d-4a38-a6e4-b8df0b6d9611",
        "questions": "How is the hypersurface Dirac operator $\tilde{\\mathcal{D}}$ related to $\\mathcal{D}$, $k_{ij}$, and $e_0$ on $\tilde{S}(M)$?",
        "answers": "$\\tilde{D} = e_{i} \\cdot \\tilde{\\nabla}_{i} = D+\\frac{1}{2}k_{i j}e_{i}e_{j}e_{0} = \\mathcal{D} - \\frac{1}{2}(\\mathrm{tr}\\,k)e_{0}$",
        "context": "In this section, we will adopt Einstein summation notation except when we say otherwise. We define a new connection $\\tilde{\\nabla}$ on $\\tilde{S}(M)$ according to\n\n$$\n\\tilde{\\nabla}_{i}=\\nabla_{i}+\\frac{1}{2}k_{i j}e_{j}e_{0}.\n$$\n\n(From a spacetime perspective, the connection $\\tilde{\\nabla}$ comes from the ambient Levi-Civita connection on $T M$, while $\\nabla$ comes from the intrinsically defined Levi-Civita connection on $T M$.) We now define the hypersurface Dirac operator $\\tilde{\\mathcal{D}}$ on $\\tilde{S}(M)$ by\n\n$$\n\\begin{array}{l}{{\\tilde{D}=e_{i}\\cdot\\tilde{\\nabla}_{i}}}\\\\ {{\\ }}\\\\ {{\\displaystyle=D+\\frac12k_{i j}e_{i}e_{j}e_{0}}}\\\\ {{\\ }}\\\\ {{\\displaystyle={\\mathcal{D}}-\\frac12({\\mathrm{tr}}\\,k)e_{0},}}\\end{array}\n$$\n\nwhere $\\mathcal{D}$ is the usual Dirac operator on $\\tilde{S}(M)$ as defined in Chapter 5, and we used symmetry considerations in the last line. (The trace of $k$ is computed with respect to $g$.) Next, we obtain a version of the Schr\u00f6dinger-Lichnerowicz formula (Theorem 5.10) for initial data sets.\n\nTheorem 8.21 (Witten). Let $(M,g,k)$ be a spin initial data set. For any $\\psi\\in C^{\\infty}(\\tilde{S}(M))$\n\n$$\n\\tilde{D}^{2}\\psi=\\tilde{\\nabla}_{i}^{\\ast}\\tilde{\\nabla}_{i}\\psi+\\frac{1}{2}(\\mu+J e_{0})\\cdot\\psi,\n$$\n\nwhere $\\tilde{\\nabla}^{*}$ is the formal adjoint of $\\tilde{\\nabla}$ on ${\\tilde{S}}(M)$\n\nProof. We will take advantage of the work we already did to prove Theorem 5.10 in Chapter 5. As usual, we choose an orthonormal basis $e_{1},.\\cdot\\cdot\\cdot,e_{n}$ that is parallel at the point where we are computing. For any $\\psi\\!\\in\\!C^{\\infty}(\\tilde{S}(M))$, we have\n\n$$\n\\begin{array}{r l}&{\\tilde{\\mathcal{D}}^{2}\\psi=\\mathcal{D}^{2}\\psi-\\cfrac{1}{2}e_{i}\\cdot\\nabla_{i}[(\\operatorname{tr}k)e_{0}\\cdot\\psi]-\\cfrac{1}{2}(\\operatorname{tr}k)e_{0}e_{i}\\cdot\\nabla_{i}\\psi-\\cfrac{1}{4}(\\operatorname{tr}k)^{2}\\psi}\\\\ &{\\quad\\quad=\\big(\\nabla^{*}\\nabla\\psi+\\cfrac{1}{4}R\\psi\\big)-\\cfrac{1}{2}\\nabla_{i}(\\operatorname{tr}k)e_{i}e_{0}\\cdot\\psi-\\cfrac{1}{4}(\\operatorname{tr}k)^{2}\\psi}\\\\ &{\\quad\\quad=\\nabla^{*}\\nabla\\psi+\\cfrac{1}{2}\\left[\\cfrac{1}{2}(R-(\\operatorname{tr}k)^{2})-\\nabla(\\operatorname{tr}k)e_{0}\\right]\\cdot\\psi,}\\end{array}\n$$\n\nwhere we used Theorem 5.10 in the second line. On the other hand, since the formal adjoint of $\\nabla$ on $\\tilde{S}(M)$ is\n\n$$\n\\tilde{\\nabla}_{i}^{*}=-\\nabla_{i}+\\frac{1}{2}k_{i j}e_{j}e_{0},\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$\\begin{array}{l}{\\tilde{D}=e_{i}\\cdot\\tilde{\\nabla}_{i}}\\\\}}{{\\\\}}{{\\displaystyle=D+\\frac{1}{2}k_{i j}e_{i}e_{j}e_{0}}\\\\}}{{\\\\}}{{\\displaystyle=\\mathcal{D}-\\frac{1}{2}(\\mathrm{tr}\\,k)e_{0},}}\\\\",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/(Graduate_Studies_in_Mathematics,201)_Lee,_Dan_A._-_Geometric_relativity_(2019,_American_Mathematical_Society).pdf_289",
        "ID": "0a3db26e-992d-4d24-854f-7963b6e1da18",
        "questions": "According to Theorem 8.21 (Witten), how is the squared hypersurface Dirac operator $\tilde{\\mathcal{D}}^2$ expressed in terms of $\tilde{\nabla}_i^\u0007st$, $\tilde{\nabla}_i$, $\\mu$, and $J$ on a spin initial data set $(M,g,k)$ for $\\psi \\in C^{\\infty}(\tilde{S}(M))$?",
        "answers": "$\\tilde{D}^{2}\\psi=\\tilde{\\nabla}_{i}^{\\ast}\\tilde{\\nabla}_{i}\\psi+\\frac{1}{2}(\\mu+J e_{0})\\cdot\\psi$",
        "context": "In this section, we will adopt Einstein summation notation except when we say otherwise. We define a new connection $\\tilde{\\nabla}$ on $\\tilde{S}(M)$ according to\n\n$$\n\\tilde{\\nabla}_{i}=\\nabla_{i}+\\frac{1}{2}k_{i j}e_{j}e_{0}.\n$$\n\n(From a spacetime perspective, the connection $\\tilde{\\nabla}$ comes from the ambient Levi-Civita connection on $T M$, while $\\nabla$ comes from the intrinsically defined Levi-Civita connection on $T M$.) We now define the hypersurface Dirac operator $\\tilde{\\mathcal{D}}$ on $\\tilde{S}(M)$ by\n\n$$\n\\begin{array}{l}{{\\tilde{D}=e_{i}\\cdot\\tilde{\\nabla}_{i}}}\\\\ {{\\ }}\\\\ {{\\displaystyle=D+\\frac12k_{i j}e_{i}e_{j}e_{0}}}\\\\ {{\\ }}\\\\ {{\\displaystyle={\\mathcal{D}}-\\frac12({\\mathrm{tr}}\\,k)e_{0},}}\\end{array}\n$$\n\nwhere $\\mathcal{D}$ is the usual Dirac operator on $\\tilde{S}(M)$ as defined in Chapter 5, and we used symmetry considerations in the last line. (The trace of $k$ is computed with respect to $g$.) Next, we obtain a version of the Schr\u00f6dinger-Lichnerowicz formula (Theorem 5.10) for initial data sets.\n\nTheorem 8.21 (Witten). Let $(M,g,k)$ be a spin initial data set. For any $\\psi\\in C^{\\infty}(\\tilde{S}(M))$\n\n$$\n\\tilde{D}^{2}\\psi=\\tilde{\\nabla}_{i}^{\\ast}\\tilde{\\nabla}_{i}\\psi+\\frac{1}{2}(\\mu+J e_{0})\\cdot\\psi,\n$$\n\nwhere $\\tilde{\\nabla}^{*}$ is the formal adjoint of $\\tilde{\\nabla}$ on ${\\tilde{S}}(M)$\n\nProof. We will take advantage of the work we already did to prove Theorem 5.10 in Chapter 5. As usual, we choose an orthonormal basis $e_{1},.\\cdot\\cdot\\cdot,e_{n}$ that is parallel at the point where we are computing. For any $\\psi\\!\\in\\!C^{\\infty}(\\tilde{S}(M))$, we have\n\n$$\n\\begin{array}{r l}&{\\tilde{\\mathcal{D}}^{2}\\psi=\\mathcal{D}^{2}\\psi-\\cfrac{1}{2}e_{i}\\cdot\\nabla_{i}[(\\operatorname{tr}k)e_{0}\\cdot\\psi]-\\cfrac{1}{2}(\\operatorname{tr}k)e_{0}e_{i}\\cdot\\nabla_{i}\\psi-\\cfrac{1}{4}(\\operatorname{tr}k)^{2}\\psi}\\\\ &{\\quad\\quad=\\big(\\nabla^{*}\\nabla\\psi+\\cfrac{1}{4}R\\psi\\big)-\\cfrac{1}{2}\\nabla_{i}(\\operatorname{tr}k)e_{i}e_{0}\\cdot\\psi-\\cfrac{1}{4}(\\operatorname{tr}k)^{2}\\psi}\\\\ &{\\quad\\quad=\\nabla^{*}\\nabla\\psi+\\cfrac{1}{2}\\left[\\cfrac{1}{2}(R-(\\operatorname{tr}k)^{2})-\\nabla(\\operatorname{tr}k)e_{0}\\right]\\cdot\\psi,}\\end{array}\n$$\n\nwhere we used Theorem 5.10 in the second line. On the other hand, since the formal adjoint of $\\nabla$ on $\\tilde{S}(M)$ is\n\n$$\n\\tilde{\\nabla}_{i}^{*}=-\\nabla_{i}+\\frac{1}{2}k_{i j}e_{j}e_{0},\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$\\tilde{D}^{2}\\psi=\\tilde{\\nabla}_{i}^{\\ast}\\tilde{\\nabla}_{i}\\psi+\\frac{1}{2}(\\mu+J e_{0})\\cdot\\psi,$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/GTM164-Additive_Number_Theory1996.pdf_200",
        "ID": "0a4dd54b-4682-4f04-9e7d-0a5fc4ebb04b",
        "questions": "What is the Shnirel'man density of a set $A$ that contains every positive integer?",
        "answers": "1",
        "context": "and so\n\n$$\n0\\leq{\\frac{A(x)}{x}}\\leq1.\n$$\n\nThe Shnirel'man density of the set $A$, denoted $\\sigma(A)$, is defined by\n\n$$\n\\sigma(A)=\\inf_{n=1,2,3,\\ldots}{\\frac{A(n)}{n}}.\n$$\n\nClearly,\n\n$$\n0\\leq\\sigma(A)\\leq1\n$$\n\nfor every set $A$ of integers. If $\\sigma(A)=\\alpha$, then\n\n$$\nA(n)\\geq\\alpha n\n$$\n\nfor all $n=1,2,3,\\ldots.$ If $1\\notin A$, then $A(1)=0$ and so $\\sigma(A)=0$.\n\nIf A contains every positive integer, then $A(n)=n$ for all $n\\geq1$ and so $\\sigma(A)=1$. If $m\\not\\in A$ for some $m\\geq1$, then $A(m)\\leq m-1$ and\n\n$$\n\\sigma(A)\\leq{\\frac{A(m)}{m}}\\leq1-{\\frac{1}{m}}<1.\n$$\n\nThus, $\\sigma(A)=1$ if and only if $A$ contains every positive integer.\n\nIf $A$ and $B$ are sets of integers, the sumset $A+B$ is the set consisting of all integers of the form $a+b$, where $a\\in A$ and $b\\in B$. If $A_{1},\\ldots,A_{h}$ are $h$ sets of integers, then\n\n$$\nA_{1}+A_{2}+\\cdots+A_{h}\n$$\n\ndenotes the set of all integers of the form $a_{1}+a_{2}+\\cdots+a_{h}$, where $a_{i}\\in A_{i}$ for $i=1,2,\\dots,h$. If $A_{i}=A$ for $i=1,2,\\dots,h$, we let\n\n$$\nh A=\\underbrace{A+\\cdots+A}_{h{\\mathrm{~times}}}.\n$$\n\nThe set $A$ is called a basis of order $h$ if $hA$ contains every non negative integer, that is, if every non negative integer can be represented as the sum of $h$ not necessarily distinct elements of $A$. The set $A$ is called a basis of finite order if $A$ is a basis of order $h$ for some $h\\geq1$.\n\nShnirel'man density is an important additive measure of the size of a set of integers. In particular, the set $A$ is a basis of order $h$ if and only if $\\sigma(h A)=1$, and the set $A$ is a basis of finite order if and only if $\\sigma(h A)=1$ for some $h\\geq1$.\n\nShnirel'man made the simple but extraordinarily powerful discovery that if $A$ is a set of integers that contains 0 and has positive Shnirel'man density, then $A$ is a basis of finite order.\n\nLemma 7.3 Let $A$ and $B$ be sets of integers such that $0\\in A, 0\\in B. If n\\geq0$ and $A(n)+B(n)\\geq n$, then $n\\in A+B$.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Numeric",
        "evidence_source": "text",
        "evidence_context": "If A contains every positive integer, then $A(n)=n$ for all $n\\geq1$ and so $\\sigma(A)=1$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM164-Additive_Number_Theory1996.pdf_200",
        "ID": "0a4ff145-58f8-489d-b848-c24c9f1079df",
        "questions": "What must be true about the value of $A(n)$ for a set of integers $A$ if the Shnirel'man density $\\sigma(A)$ is $\\alpha$?",
        "answers": "A(n)\\geq\\alpha n",
        "context": "and so\n\n$$\n0\\leq{\\frac{A(x)}{x}}\\leq1.\n$$\n\nThe Shnirel'man density of the set $A$, denoted $\\sigma(A)$, is defined by\n\n$$\n\\sigma(A)=\\inf_{n=1,2,3,\\ldots}{\\frac{A(n)}{n}}.\n$$\n\nClearly,\n\n$$\n0\\leq\\sigma(A)\\leq1\n$$\n\nfor every set $A$ of integers. If $\\sigma(A)=\\alpha$, then\n\n$$\nA(n)\\geq\\alpha n\n$$\n\nfor all $n=1,2,3,\\ldots.$ If $1\\notin A$, then $A(1)=0$ and so $\\sigma(A)=0$.\n\nIf A contains every positive integer, then $A(n)=n$ for all $n\\geq1$ and so $\\sigma(A)=1$. If $m\\not\\in A$ for some $m\\geq1$, then $A(m)\\leq m-1$ and\n\n$$\n\\sigma(A)\\leq{\\frac{A(m)}{m}}\\leq1-{\\frac{1}{m}}<1.\n$$\n\nThus, $\\sigma(A)=1$ if and only if $A$ contains every positive integer.\n\nIf $A$ and $B$ are sets of integers, the sumset $A+B$ is the set consisting of all integers of the form $a+b$, where $a\\in A$ and $b\\in B$. If $A_{1},\\ldots,A_{h}$ are $h$ sets of integers, then\n\n$$\nA_{1}+A_{2}+\\cdots+A_{h}\n$$\n\ndenotes the set of all integers of the form $a_{1}+a_{2}+\\cdots+a_{h}$, where $a_{i}\\in A_{i}$ for $i=1,2,\\dots,h$. If $A_{i}=A$ for $i=1,2,\\dots,h$, we let\n\n$$\nh A=\\underbrace{A+\\cdots+A}_{h{\\mathrm{~times}}}.\n$$\n\nThe set $A$ is called a basis of order $h$ if $hA$ contains every non negative integer, that is, if every non negative integer can be represented as the sum of $h$ not necessarily distinct elements of $A$. The set $A$ is called a basis of finite order if $A$ is a basis of order $h$ for some $h\\geq1$.\n\nShnirel'man density is an important additive measure of the size of a set of integers. In particular, the set $A$ is a basis of order $h$ if and only if $\\sigma(h A)=1$, and the set $A$ is a basis of finite order if and only if $\\sigma(h A)=1$ for some $h\\geq1$.\n\nShnirel'man made the simple but extraordinarily powerful discovery that if $A$ is a set of integers that contains 0 and has positive Shnirel'man density, then $A$ is a basis of finite order.\n\nLemma 7.3 Let $A$ and $B$ be sets of integers such that $0\\in A, 0\\in B. If n\\geq0$ and $A(n)+B(n)\\geq n$, then $n\\in A+B$.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "If $\\sigma(A)=\\alpha$, then $A(n)\\geq\\alpha n$ for all $n=1,2,3,\\ldots.$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM164-Additive_Number_Theory1996.pdf_200",
        "ID": "0a508313-d91d-45a8-9f0b-2a7076ee73db",
        "questions": "Can a set $A$ be a basis of order $h$ if $\\sigma(h A) < 1$ and why?",
        "answers": "No, because a set $A$ is a basis of order $h$ if and only if $\\sigma(h A)=1$.",
        "context": "and so\n\n$$\n0\\leq{\\frac{A(x)}{x}}\\leq1.\n$$\n\nThe Shnirel'man density of the set $A$, denoted $\\sigma(A)$, is defined by\n\n$$\n\\sigma(A)=\\inf_{n=1,2,3,\\ldots}{\\frac{A(n)}{n}}.\n$$\n\nClearly,\n\n$$\n0\\leq\\sigma(A)\\leq1\n$$\n\nfor every set $A$ of integers. If $\\sigma(A)=\\alpha$, then\n\n$$\nA(n)\\geq\\alpha n\n$$\n\nfor all $n=1,2,3,\\ldots.$ If $1\\notin A$, then $A(1)=0$ and so $\\sigma(A)=0$.\n\nIf A contains every positive integer, then $A(n)=n$ for all $n\\geq1$ and so $\\sigma(A)=1$. If $m\\not\\in A$ for some $m\\geq1$, then $A(m)\\leq m-1$ and\n\n$$\n\\sigma(A)\\leq{\\frac{A(m)}{m}}\\leq1-{\\frac{1}{m}}<1.\n$$\n\nThus, $\\sigma(A)=1$ if and only if $A$ contains every positive integer.\n\nIf $A$ and $B$ are sets of integers, the sumset $A+B$ is the set consisting of all integers of the form $a+b$, where $a\\in A$ and $b\\in B$. If $A_{1},\\ldots,A_{h}$ are $h$ sets of integers, then\n\n$$\nA_{1}+A_{2}+\\cdots+A_{h}\n$$\n\ndenotes the set of all integers of the form $a_{1}+a_{2}+\\cdots+a_{h}$, where $a_{i}\\in A_{i}$ for $i=1,2,\\dots,h$. If $A_{i}=A$ for $i=1,2,\\dots,h$, we let\n\n$$\nh A=\\underbrace{A+\\cdots+A}_{h{\\mathrm{~times}}}.\n$$\n\nThe set $A$ is called a basis of order $h$ if $hA$ contains every non negative integer, that is, if every non negative integer can be represented as the sum of $h$ not necessarily distinct elements of $A$. The set $A$ is called a basis of finite order if $A$ is a basis of order $h$ for some $h\\geq1$.\n\nShnirel'man density is an important additive measure of the size of a set of integers. In particular, the set $A$ is a basis of order $h$ if and only if $\\sigma(h A)=1$, and the set $A$ is a basis of finite order if and only if $\\sigma(h A)=1$ for some $h\\geq1$.\n\nShnirel'man made the simple but extraordinarily powerful discovery that if $A$ is a set of integers that contains 0 and has positive Shnirel'man density, then $A$ is a basis of finite order.\n\nLemma 7.3 Let $A$ and $B$ be sets of integers such that $0\\in A, 0\\in B. If n\\geq0$ and $A(n)+B(n)\\geq n$, then $n\\in A+B$.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "The set $A$ is a basis of order $h$ if and only if $\\sigma(h A)=1$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM164-Additive_Number_Theory1996.pdf_200",
        "ID": "0a53381b-2677-49f7-be90-db0bce796b42",
        "questions": "What is the inequality that defines the Shnirel'man density $\\sigma(A)$ for a set $A$ of integers?",
        "answers": "$0 \\leq \\sigma(A) \\leq 1$",
        "context": "and so\n\n$$\n0\\leq{\\frac{A(x)}{x}}\\leq1.\n$$\n\nThe Shnirel'man density of the set $A$, denoted $\\sigma(A)$, is defined by\n\n$$\n\\sigma(A)=\\inf_{n=1,2,3,\\ldots}{\\frac{A(n)}{n}}.\n$$\n\nClearly,\n\n$$\n0\\leq\\sigma(A)\\leq1\n$$\n\nfor every set $A$ of integers. If $\\sigma(A)=\\alpha$, then\n\n$$\nA(n)\\geq\\alpha n\n$$\n\nfor all $n=1,2,3,\\ldots.$ If $1\\notin A$, then $A(1)=0$ and so $\\sigma(A)=0$.\n\nIf A contains every positive integer, then $A(n)=n$ for all $n\\geq1$ and so $\\sigma(A)=1$. If $m\\not\\in A$ for some $m\\geq1$, then $A(m)\\leq m-1$ and\n\n$$\n\\sigma(A)\\leq{\\frac{A(m)}{m}}\\leq1-{\\frac{1}{m}}<1.\n$$\n\nThus, $\\sigma(A)=1$ if and only if $A$ contains every positive integer.\n\nIf $A$ and $B$ are sets of integers, the sumset $A+B$ is the set consisting of all integers of the form $a+b$, where $a\\in A$ and $b\\in B$. If $A_{1},\\ldots,A_{h}$ are $h$ sets of integers, then\n\n$$\nA_{1}+A_{2}+\\cdots+A_{h}\n$$\n\ndenotes the set of all integers of the form $a_{1}+a_{2}+\\cdots+a_{h}$, where $a_{i}\\in A_{i}$ for $i=1,2,\\dots,h$. If $A_{i}=A$ for $i=1,2,\\dots,h$, we let\n\n$$\nh A=\\underbrace{A+\\cdots+A}_{h{\\mathrm{~times}}}.\n$$\n\nThe set $A$ is called a basis of order $h$ if $hA$ contains every non negative integer, that is, if every non negative integer can be represented as the sum of $h$ not necessarily distinct elements of $A$. The set $A$ is called a basis of finite order if $A$ is a basis of order $h$ for some $h\\geq1$.\n\nShnirel'man density is an important additive measure of the size of a set of integers. In particular, the set $A$ is a basis of order $h$ if and only if $\\sigma(h A)=1$, and the set $A$ is a basis of finite order if and only if $\\sigma(h A)=1$ for some $h\\geq1$.\n\nShnirel'man made the simple but extraordinarily powerful discovery that if $A$ is a set of integers that contains 0 and has positive Shnirel'man density, then $A$ is a basis of finite order.\n\nLemma 7.3 Let $A$ and $B$ be sets of integers such that $0\\in A, 0\\in B. If n\\geq0$ and $A(n)+B(n)\\geq n$, then $n\\in A+B$.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$0\\leq\\sigma(A)\\leq1$ for every set $A$ of integers.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/GTM164-Additive_Number_Theory1996.pdf_200",
        "ID": "0a59f5dc-395a-4924-ad76-e2117f49992c",
        "questions": "When $m \\not\\in A$ for some $m \\geq 1$, how does the Shnirel'man density $\\sigma(A)$ relate to $m$ and $A(m)$?",
        "answers": "$\\sigma(A) \\leq \\frac{A(m)}{m} \\leq 1 - \\frac{1}{m} < 1$",
        "context": "and so\n\n$$\n0\\leq{\\frac{A(x)}{x}}\\leq1.\n$$\n\nThe Shnirel'man density of the set $A$, denoted $\\sigma(A)$, is defined by\n\n$$\n\\sigma(A)=\\inf_{n=1,2,3,\\ldots}{\\frac{A(n)}{n}}.\n$$\n\nClearly,\n\n$$\n0\\leq\\sigma(A)\\leq1\n$$\n\nfor every set $A$ of integers. If $\\sigma(A)=\\alpha$, then\n\n$$\nA(n)\\geq\\alpha n\n$$\n\nfor all $n=1,2,3,\\ldots.$ If $1\\notin A$, then $A(1)=0$ and so $\\sigma(A)=0$.\n\nIf A contains every positive integer, then $A(n)=n$ for all $n\\geq1$ and so $\\sigma(A)=1$. If $m\\not\\in A$ for some $m\\geq1$, then $A(m)\\leq m-1$ and\n\n$$\n\\sigma(A)\\leq{\\frac{A(m)}{m}}\\leq1-{\\frac{1}{m}}<1.\n$$\n\nThus, $\\sigma(A)=1$ if and only if $A$ contains every positive integer.\n\nIf $A$ and $B$ are sets of integers, the sumset $A+B$ is the set consisting of all integers of the form $a+b$, where $a\\in A$ and $b\\in B$. If $A_{1},\\ldots,A_{h}$ are $h$ sets of integers, then\n\n$$\nA_{1}+A_{2}+\\cdots+A_{h}\n$$\n\ndenotes the set of all integers of the form $a_{1}+a_{2}+\\cdots+a_{h}$, where $a_{i}\\in A_{i}$ for $i=1,2,\\dots,h$. If $A_{i}=A$ for $i=1,2,\\dots,h$, we let\n\n$$\nh A=\\underbrace{A+\\cdots+A}_{h{\\mathrm{~times}}}.\n$$\n\nThe set $A$ is called a basis of order $h$ if $hA$ contains every non negative integer, that is, if every non negative integer can be represented as the sum of $h$ not necessarily distinct elements of $A$. The set $A$ is called a basis of finite order if $A$ is a basis of order $h$ for some $h\\geq1$.\n\nShnirel'man density is an important additive measure of the size of a set of integers. In particular, the set $A$ is a basis of order $h$ if and only if $\\sigma(h A)=1$, and the set $A$ is a basis of finite order if and only if $\\sigma(h A)=1$ for some $h\\geq1$.\n\nShnirel'man made the simple but extraordinarily powerful discovery that if $A$ is a set of integers that contains 0 and has positive Shnirel'man density, then $A$ is a basis of finite order.\n\nLemma 7.3 Let $A$ and $B$ be sets of integers such that $0\\in A, 0\\in B. If n\\geq0$ and $A(n)+B(n)\\geq n$, then $n\\in A+B$.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "If $m\\not\\in A$ for some $m\\geq1$, then $A(m)\\leq m-1$ and $\\sigma(A)\\leq{\\frac{A(m)}{m}}\\leq1-{\\frac{1}{m}}<1.$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/GTM164-Additive_Number_Theory1996.pdf_200",
        "ID": "0a5ee510-fc99-409c-839c-cea17d41213a",
        "questions": "For two sets of integers $A$ and $B$, both containing 0, under what condition is $n \\in A+B$ according to Lemma 7.3?",
        "answers": "If $n \\geq 0$ and $A(n) + B(n) \\geq n$",
        "context": "and so\n\n$$\n0\\leq{\\frac{A(x)}{x}}\\leq1.\n$$\n\nThe Shnirel'man density of the set $A$, denoted $\\sigma(A)$, is defined by\n\n$$\n\\sigma(A)=\\inf_{n=1,2,3,\\ldots}{\\frac{A(n)}{n}}.\n$$\n\nClearly,\n\n$$\n0\\leq\\sigma(A)\\leq1\n$$\n\nfor every set $A$ of integers. If $\\sigma(A)=\\alpha$, then\n\n$$\nA(n)\\geq\\alpha n\n$$\n\nfor all $n=1,2,3,\\ldots.$ If $1\\notin A$, then $A(1)=0$ and so $\\sigma(A)=0$.\n\nIf A contains every positive integer, then $A(n)=n$ for all $n\\geq1$ and so $\\sigma(A)=1$. If $m\\not\\in A$ for some $m\\geq1$, then $A(m)\\leq m-1$ and\n\n$$\n\\sigma(A)\\leq{\\frac{A(m)}{m}}\\leq1-{\\frac{1}{m}}<1.\n$$\n\nThus, $\\sigma(A)=1$ if and only if $A$ contains every positive integer.\n\nIf $A$ and $B$ are sets of integers, the sumset $A+B$ is the set consisting of all integers of the form $a+b$, where $a\\in A$ and $b\\in B$. If $A_{1},\\ldots,A_{h}$ are $h$ sets of integers, then\n\n$$\nA_{1}+A_{2}+\\cdots+A_{h}\n$$\n\ndenotes the set of all integers of the form $a_{1}+a_{2}+\\cdots+a_{h}$, where $a_{i}\\in A_{i}$ for $i=1,2,\\dots,h$. If $A_{i}=A$ for $i=1,2,\\dots,h$, we let\n\n$$\nh A=\\underbrace{A+\\cdots+A}_{h{\\mathrm{~times}}}.\n$$\n\nThe set $A$ is called a basis of order $h$ if $hA$ contains every non negative integer, that is, if every non negative integer can be represented as the sum of $h$ not necessarily distinct elements of $A$. The set $A$ is called a basis of finite order if $A$ is a basis of order $h$ for some $h\\geq1$.\n\nShnirel'man density is an important additive measure of the size of a set of integers. In particular, the set $A$ is a basis of order $h$ if and only if $\\sigma(h A)=1$, and the set $A$ is a basis of finite order if and only if $\\sigma(h A)=1$ for some $h\\geq1$.\n\nShnirel'man made the simple but extraordinarily powerful discovery that if $A$ is a set of integers that contains 0 and has positive Shnirel'man density, then $A$ is a basis of finite order.\n\nLemma 7.3 Let $A$ and $B$ be sets of integers such that $0\\in A, 0\\in B. If n\\geq0$ and $A(n)+B(n)\\geq n$, then $n\\in A+B$.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "If $n\\geq0$ and $A(n)+B(n)\\geq n$, then $n\\in A+B$.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/chap02.pdf_16",
        "ID": "0a73a9a9-df49-4c15-a38b-c512d13d78bc",
        "questions": "What was the first large quantity export product from South Carolina?",
        "answers": "Deerskin",
        "context": "North Carolina From the beginning, Carolina developed as two separate regions. North Carolina was home to a small and scattered population of farmers. The lack of good harbors hindered growth, and the colony had only 3,000 people by 1700. Eventually, the farmers began growing tobacco for sale. They also used native pine to make and export shipbuilding supplies.\n\nSouth Carolina The proprietors of Carolina were always far more interested in the southern half of their holdings, where they hoped to cultivate sugar cane. In 1670, three ships brought settlers from England to South Carolina. They named their first settlement, Charles Town, after the king.  \n\nThe first years of the new colony were difficult. Sugar cane, as it turned out, did not grow well. The first product exported in large quantity was deerskin, popular for English leather. The colony also began to capture and enslave Native Americans, who were shipped to plantations in the Caribbean.  \n\nThe Georgia Experiment In the 1720s, General James Oglethorpe, a wealthy member of Parliament, began investigating English prisons. He was appalled to find so many debtors - people who could not pay their debts - behind bars. Oglethorpe asked King George II for a colony south of South Carolina where the poor could start over.\n\nThe English government saw several advantages to a new southern colony. It would help England's poor and provide a strategic buffer to keep Spain from expanding north. King George granted Oglethorpe and his friends permission to settle between the Savannah and Altamaha Rivers. The new colony was named Georgia, in honor of the king and the first settlers arrived in 1733.\n\nOglethorpe and his fellow trustees banned slavery, rum, and brandy in Georgia, and they limited the size of land grants. Still, the colony attracted settlers from all over Europe, including Scotch-Irish, Welsh, Germans, Swiss, and Italians. Increasingly, the settlers objected to the colony's strict rules. In the 1740s, the trustees lifted the restrictions on brandy, rum, and slavery, and in 1750, they granted the settlers their own elected assembly. The next year, the trustees gave control back to the king, and Georgia became a royal colony.  \n\nBy 1775, roughly 2.5 million people lived in England's American colonies. Despite the stumbling start in Jamestown, the English had succeeded in building a large and prosperous society on the east coast of North America.\n\nEngland's success, however, would prove its undoing. By permitting new patterns of land ownership and new types of worship and government in its colonies, the English government had planted the seeds of rebellion.\n\n# Reading Check  \n\nSummarizing In what ways was  \n\nEngland permissive with its American colonies?  \n\n# HISTORY Online\n\nStudent Web Activity Visit the American Republic Since 1877 Website at travol2.glencoe.com and and click on Student Web Activities - Chapter 2 for an activity on English settlers in America.\n\nStudy Central To review this section, go to tarvol2.glencoe.com and click on Study Central  \n\n# SECTIONS 3 ASSESSMENT  \n\n# Checking for Understanding  \n\n1. Define: pacifism, debtor.\n\n2. Identify: English Civil War, William Penn, James Oglethorpe.\n\n3. Summarize how the Quakers came to have a colony of their own.\n\n# Reviewing Themes\n\n4. Global Connections After Charles II became king, why did the English government openly work to promote colonization in North America?\n\n# Critical Thinking  \n\n5. Analyzing Why did England regard the Dutch and Spanish presence in North America as a threat, and how did England respond?\n\n6. Categorizing Use a graphic organizer similar to the one below to list the reasons that the listed colonies were founded.\n\n$\n\\begin{tabular}{|l|l|}\n \nColony & Reasons Founded \\\\\n \nNew York & \\\\\n \nNew Jersey & \\\\\n \nPennsylvania & \\\\\n \n\\end{tabular}\n$\n\n# Analyzing Visuals  \n\n7. Analyzing Charts Study the chart on page 54 on Spanish, English, and French colonization. In political organization, what was a trait of the English colonies that the French and Spanish colonies did not share?  \n\n# Writing About History\n\n8. Persuasive Writing Imagine you have been hired by the proprietors of New Jersey to persuade settlers to come to their colony. Write an editorial for a newspaper in England to convince people to settle in New Jersey.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "The first product exported in large quantity was deerskin, popular for English leather.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/chap02.pdf_16",
        "ID": "0a77e6a1-dda6-4272-87a1-cfb21b85e81d",
        "questions": "How many settlers were brought to South Carolina by three ships from England in 1670?",
        "answers": "Three ships brought settlers from England to South Carolina.",
        "context": "North Carolina From the beginning, Carolina developed as two separate regions. North Carolina was home to a small and scattered population of farmers. The lack of good harbors hindered growth, and the colony had only 3,000 people by 1700. Eventually, the farmers began growing tobacco for sale. They also used native pine to make and export shipbuilding supplies.\n\nSouth Carolina The proprietors of Carolina were always far more interested in the southern half of their holdings, where they hoped to cultivate sugar cane. In 1670, three ships brought settlers from England to South Carolina. They named their first settlement, Charles Town, after the king.  \n\nThe first years of the new colony were difficult. Sugar cane, as it turned out, did not grow well. The first product exported in large quantity was deerskin, popular for English leather. The colony also began to capture and enslave Native Americans, who were shipped to plantations in the Caribbean.  \n\nThe Georgia Experiment In the 1720s, General James Oglethorpe, a wealthy member of Parliament, began investigating English prisons. He was appalled to find so many debtors - people who could not pay their debts - behind bars. Oglethorpe asked King George II for a colony south of South Carolina where the poor could start over.\n\nThe English government saw several advantages to a new southern colony. It would help England's poor and provide a strategic buffer to keep Spain from expanding north. King George granted Oglethorpe and his friends permission to settle between the Savannah and Altamaha Rivers. The new colony was named Georgia, in honor of the king and the first settlers arrived in 1733.\n\nOglethorpe and his fellow trustees banned slavery, rum, and brandy in Georgia, and they limited the size of land grants. Still, the colony attracted settlers from all over Europe, including Scotch-Irish, Welsh, Germans, Swiss, and Italians. Increasingly, the settlers objected to the colony's strict rules. In the 1740s, the trustees lifted the restrictions on brandy, rum, and slavery, and in 1750, they granted the settlers their own elected assembly. The next year, the trustees gave control back to the king, and Georgia became a royal colony.  \n\nBy 1775, roughly 2.5 million people lived in England's American colonies. Despite the stumbling start in Jamestown, the English had succeeded in building a large and prosperous society on the east coast of North America.\n\nEngland's success, however, would prove its undoing. By permitting new patterns of land ownership and new types of worship and government in its colonies, the English government had planted the seeds of rebellion.\n\n# Reading Check  \n\nSummarizing In what ways was  \n\nEngland permissive with its American colonies?  \n\n# HISTORY Online\n\nStudent Web Activity Visit the American Republic Since 1877 Website at travol2.glencoe.com and and click on Student Web Activities - Chapter 2 for an activity on English settlers in America.\n\nStudy Central To review this section, go to tarvol2.glencoe.com and click on Study Central  \n\n# SECTIONS 3 ASSESSMENT  \n\n# Checking for Understanding  \n\n1. Define: pacifism, debtor.\n\n2. Identify: English Civil War, William Penn, James Oglethorpe.\n\n3. Summarize how the Quakers came to have a colony of their own.\n\n# Reviewing Themes\n\n4. Global Connections After Charles II became king, why did the English government openly work to promote colonization in North America?\n\n# Critical Thinking  \n\n5. Analyzing Why did England regard the Dutch and Spanish presence in North America as a threat, and how did England respond?\n\n6. Categorizing Use a graphic organizer similar to the one below to list the reasons that the listed colonies were founded.\n\n$\n\\begin{tabular}{|l|l|}\n \nColony & Reasons Founded \\\\\n \nNew York & \\\\\n \nNew Jersey & \\\\\n \nPennsylvania & \\\\\n \n\\end{tabular}\n$\n\n# Analyzing Visuals  \n\n7. Analyzing Charts Study the chart on page 54 on Spanish, English, and French colonization. In political organization, what was a trait of the English colonies that the French and Spanish colonies did not share?  \n\n# Writing About History\n\n8. Persuasive Writing Imagine you have been hired by the proprietors of New Jersey to persuade settlers to come to their colony. Write an editorial for a newspaper in England to convince people to settle in New Jersey.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "In 1670, three ships brought settlers from England to South Carolina.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/chap02.pdf_16",
        "ID": "0a828a9a-74f0-487f-9357-827ed6fc07d4",
        "questions": "By what year did Georgia become a royal colony and what were the contributing factors?",
        "answers": "Georgia became a royal colony in 1752 due to the lifting of restrictions on brandy, rum, and slavery, and the granting of an elected assembly.",
        "context": "North Carolina From the beginning, Carolina developed as two separate regions. North Carolina was home to a small and scattered population of farmers. The lack of good harbors hindered growth, and the colony had only 3,000 people by 1700. Eventually, the farmers began growing tobacco for sale. They also used native pine to make and export shipbuilding supplies.\n\nSouth Carolina The proprietors of Carolina were always far more interested in the southern half of their holdings, where they hoped to cultivate sugar cane. In 1670, three ships brought settlers from England to South Carolina. They named their first settlement, Charles Town, after the king.  \n\nThe first years of the new colony were difficult. Sugar cane, as it turned out, did not grow well. The first product exported in large quantity was deerskin, popular for English leather. The colony also began to capture and enslave Native Americans, who were shipped to plantations in the Caribbean.  \n\nThe Georgia Experiment In the 1720s, General James Oglethorpe, a wealthy member of Parliament, began investigating English prisons. He was appalled to find so many debtors - people who could not pay their debts - behind bars. Oglethorpe asked King George II for a colony south of South Carolina where the poor could start over.\n\nThe English government saw several advantages to a new southern colony. It would help England's poor and provide a strategic buffer to keep Spain from expanding north. King George granted Oglethorpe and his friends permission to settle between the Savannah and Altamaha Rivers. The new colony was named Georgia, in honor of the king and the first settlers arrived in 1733.\n\nOglethorpe and his fellow trustees banned slavery, rum, and brandy in Georgia, and they limited the size of land grants. Still, the colony attracted settlers from all over Europe, including Scotch-Irish, Welsh, Germans, Swiss, and Italians. Increasingly, the settlers objected to the colony's strict rules. In the 1740s, the trustees lifted the restrictions on brandy, rum, and slavery, and in 1750, they granted the settlers their own elected assembly. The next year, the trustees gave control back to the king, and Georgia became a royal colony.  \n\nBy 1775, roughly 2.5 million people lived in England's American colonies. Despite the stumbling start in Jamestown, the English had succeeded in building a large and prosperous society on the east coast of North America.\n\nEngland's success, however, would prove its undoing. By permitting new patterns of land ownership and new types of worship and government in its colonies, the English government had planted the seeds of rebellion.\n\n# Reading Check  \n\nSummarizing In what ways was  \n\nEngland permissive with its American colonies?  \n\n# HISTORY Online\n\nStudent Web Activity Visit the American Republic Since 1877 Website at travol2.glencoe.com and and click on Student Web Activities - Chapter 2 for an activity on English settlers in America.\n\nStudy Central To review this section, go to tarvol2.glencoe.com and click on Study Central  \n\n# SECTIONS 3 ASSESSMENT  \n\n# Checking for Understanding  \n\n1. Define: pacifism, debtor.\n\n2. Identify: English Civil War, William Penn, James Oglethorpe.\n\n3. Summarize how the Quakers came to have a colony of their own.\n\n# Reviewing Themes\n\n4. Global Connections After Charles II became king, why did the English government openly work to promote colonization in North America?\n\n# Critical Thinking  \n\n5. Analyzing Why did England regard the Dutch and Spanish presence in North America as a threat, and how did England respond?\n\n6. Categorizing Use a graphic organizer similar to the one below to list the reasons that the listed colonies were founded.\n\n$\n\\begin{tabular}{|l|l|}\n \nColony & Reasons Founded \\\\\n \nNew York & \\\\\n \nNew Jersey & \\\\\n \nPennsylvania & \\\\\n \n\\end{tabular}\n$\n\n# Analyzing Visuals  \n\n7. Analyzing Charts Study the chart on page 54 on Spanish, English, and French colonization. In political organization, what was a trait of the English colonies that the French and Spanish colonies did not share?  \n\n# Writing About History\n\n8. Persuasive Writing Imagine you have been hired by the proprietors of New Jersey to persuade settlers to come to their colony. Write an editorial for a newspaper in England to convince people to settle in New Jersey.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "In the 1740s, the trustees lifted the restrictions on brandy, rum, and slavery, and in 1750, they granted the settlers their own elected assembly. The next year, the trustees gave control back to the king, and Georgia became a royal colony.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/textbook_needrop_en_550",
        "ID": "0a8f541d-052b-4051-bc24-1ca590425d14",
        "questions": "What is the equation that represents the additional horizontal drag force \\(D_{2}\\) caused by the friction of the air flowing over the surface of the wing?",
        "answers": "$\\frac{\\Delta\\nu}{\\nu} = \\frac{f}{A}$",
        "context": "Side view of wing (in a frame of reference moving with the aircraft):  \n\n![](images/edb5a905c54a5429adf8b7b5b2f2607c79ef6cf10feefaacbb028536de54fbf6.jpg)  \n\nIgnore the modification of the air flow due to the propeller.  \n\n(a) Consider the change in momentum of the air moving past the wing, with no change in speed while it does so. Derive expressions for the vertical lift force \\(L\\) and the horizontal drag force \\(D_{I}\\) on the wing in terms of wing dimensions, \\(\\nu, \\varepsilon,\\) and the air density \\(\\rho.\\) Assume the direction of air flow is always parallel to the plane of the side-view diagram. (3 marks)  \n\n(b) There is an additional horizontal drag force \\(D_{2}\\) caused by the friction of air flowing over the surface of the wing. The air slows slightly, with a change of speed \\(\\nu \\left(<< 1\\%\\right.\\) of \\(\\nu\\)) given by:  \n\n$$\n\\frac{\\Delta\\nu}{\\nu}=\\frac{f}{A}\n$$  \n\nThe value of \\(f\\) is independent of \\(\\varepsilon.\\)  \n\nFind an expression (in terms of \\(M, f, A, S, \\rho\\) and \\(g_{r}\\) - the acceleration due to gravity) for the flight speed \\(\\nu_{\\theta}\\) corresponding to a minimum power being needed to maintain this aircraft in flight at constant altitude and velocity. Neglect terms of order \\((\\varepsilon^{2} f)\\) or higher. (3 marks)  \n\nYou may find the following small angle approximation useful:  \n\n$$\n1-\\cos\\varepsilon\\approx{\\frac{\\sin^{2}\\varepsilon}{2}}\n$$  \n\n(c) On the answer sheet, sketch a graph of power \\(P\\) versus flight speed \\(\\nu.\\) Show the separate contributions to the power needed from the two sources of drag. Find an expression (in terms of \\(M, f, A, S, \\rho\\) and \\(g\\)) for the minimum power, \\(P_{min}\\). (2 marks)",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Equation",
        "evidence_source": "equation",
        "evidence_context": "The air slows slightly, with a change of speed \\(\\nu\\left(<<1%\\right.\\) of \\(\\nu\\)) given by: $$\\frac{\\Delta\\nu}{\\nu} = \\frac{f}{A}$$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/textbook_needrop_en_550",
        "ID": "0a964cb9-a62a-44d0-9047-111af5dcd525",
        "questions": "What equation is given as useful for small angle approximations?",
        "answers": "$1-\\cos\\varepsilon \\approx \\frac{\\sin^{2}\\varepsilon}{2}$",
        "context": "Side view of wing (in a frame of reference moving with the aircraft):  \n\n![](images/edb5a905c54a5429adf8b7b5b2f2607c79ef6cf10feefaacbb028536de54fbf6.jpg)  \n\nIgnore the modification of the air flow due to the propeller.  \n\n(a) Consider the change in momentum of the air moving past the wing, with no change in speed while it does so. Derive expressions for the vertical lift force \\(L\\) and the horizontal drag force \\(D_{I}\\) on the wing in terms of wing dimensions, \\(\\nu, \\varepsilon,\\) and the air density \\(\\rho.\\) Assume the direction of air flow is always parallel to the plane of the side-view diagram. (3 marks)  \n\n(b) There is an additional horizontal drag force \\(D_{2}\\) caused by the friction of air flowing over the surface of the wing. The air slows slightly, with a change of speed \\(\\nu \\left(<< 1\\%\\right.\\) of \\(\\nu\\)) given by:  \n\n$$\n\\frac{\\Delta\\nu}{\\nu}=\\frac{f}{A}\n$$  \n\nThe value of \\(f\\) is independent of \\(\\varepsilon.\\)  \n\nFind an expression (in terms of \\(M, f, A, S, \\rho\\) and \\(g_{r}\\) - the acceleration due to gravity) for the flight speed \\(\\nu_{\\theta}\\) corresponding to a minimum power being needed to maintain this aircraft in flight at constant altitude and velocity. Neglect terms of order \\((\\varepsilon^{2} f)\\) or higher. (3 marks)  \n\nYou may find the following small angle approximation useful:  \n\n$$\n1-\\cos\\varepsilon\\approx{\\frac{\\sin^{2}\\varepsilon}{2}}\n$$  \n\n(c) On the answer sheet, sketch a graph of power \\(P\\) versus flight speed \\(\\nu.\\) Show the separate contributions to the power needed from the two sources of drag. Find an expression (in terms of \\(M, f, A, S, \\rho\\) and \\(g\\)) for the minimum power, \\(P_{min}\\). (2 marks)",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Equation",
        "evidence_source": "equation",
        "evidence_context": "You may find the following small angle approximation useful: $$1-\\cos\\varepsilon \\approx \\frac{\\sin^{2}\\varepsilon}{2}$$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/textbook_needrop_en_550",
        "ID": "0a97b6f9-aaf5-4770-a208-1bc46f3454e0",
        "questions": "In what terms should the expression for the flight speed \\(\\nu_{\\theta}\\) be found, corresponding to a minimum power needed to maintain constant altitude and velocity?",
        "answers": "M, f, A, S, \\(\\rho\\) and \\(g_{r}\\)",
        "context": "Side view of wing (in a frame of reference moving with the aircraft):  \n\n![](images/edb5a905c54a5429adf8b7b5b2f2607c79ef6cf10feefaacbb028536de54fbf6.jpg)  \n\nIgnore the modification of the air flow due to the propeller.  \n\n(a) Consider the change in momentum of the air moving past the wing, with no change in speed while it does so. Derive expressions for the vertical lift force \\(L\\) and the horizontal drag force \\(D_{I}\\) on the wing in terms of wing dimensions, \\(\\nu, \\varepsilon,\\) and the air density \\(\\rho.\\) Assume the direction of air flow is always parallel to the plane of the side-view diagram. (3 marks)  \n\n(b) There is an additional horizontal drag force \\(D_{2}\\) caused by the friction of air flowing over the surface of the wing. The air slows slightly, with a change of speed \\(\\nu \\left(<< 1\\%\\right.\\) of \\(\\nu\\)) given by:  \n\n$$\n\\frac{\\Delta\\nu}{\\nu}=\\frac{f}{A}\n$$  \n\nThe value of \\(f\\) is independent of \\(\\varepsilon.\\)  \n\nFind an expression (in terms of \\(M, f, A, S, \\rho\\) and \\(g_{r}\\) - the acceleration due to gravity) for the flight speed \\(\\nu_{\\theta}\\) corresponding to a minimum power being needed to maintain this aircraft in flight at constant altitude and velocity. Neglect terms of order \\((\\varepsilon^{2} f)\\) or higher. (3 marks)  \n\nYou may find the following small angle approximation useful:  \n\n$$\n1-\\cos\\varepsilon\\approx{\\frac{\\sin^{2}\\varepsilon}{2}}\n$$  \n\n(c) On the answer sheet, sketch a graph of power \\(P\\) versus flight speed \\(\\nu.\\) Show the separate contributions to the power needed from the two sources of drag. Find an expression (in terms of \\(M, f, A, S, \\rho\\) and \\(g\\)) for the minimum power, \\(P_{min}\\). (2 marks)",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Find an expression (in terms of \\(M, f, A, S, \\rho\\) and \\(g_{r}\\) - the acceleration due to gravity) for the flight speed \\(\\nu_{\\theta}\\) corresponding to a minimum power being needed to maintain this aircraft in flight at constant altitude and velocity.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/textbook_needrop_en_550",
        "ID": "0a9b5b1d-7baa-438d-9c07-f940909bfb6c",
        "questions": "Derive the expression for the change in speed \\(\nu\\) due to friction in terms of \\(f\\) and \\(A\\) when the air slows down slightly by a change \\(\nu (<< 1%)\\) of \\(\nu\\).",
        "answers": "\\(\frac{\\Delta \nu}{\nu} = \frac{f}{A}\\)",
        "context": "Side view of wing (in a frame of reference moving with the aircraft):  \n\n![](images/edb5a905c54a5429adf8b7b5b2f2607c79ef6cf10feefaacbb028536de54fbf6.jpg)  \n\nIgnore the modification of the air flow due to the propeller.  \n\n(a) Consider the change in momentum of the air moving past the wing, with no change in speed while it does so. Derive expressions for the vertical lift force \\(L\\) and the horizontal drag force \\(D_{I}\\) on the wing in terms of wing dimensions, \\(\\nu, \\varepsilon,\\) and the air density \\(\\rho.\\) Assume the direction of air flow is always parallel to the plane of the side-view diagram. (3 marks)  \n\n(b) There is an additional horizontal drag force \\(D_{2}\\) caused by the friction of air flowing over the surface of the wing. The air slows slightly, with a change of speed \\(\\nu \\left(<< 1\\%\\right.\\) of \\(\\nu\\)) given by:  \n\n$$\n\\frac{\\Delta\\nu}{\\nu}=\\frac{f}{A}\n$$  \n\nThe value of \\(f\\) is independent of \\(\\varepsilon.\\)  \n\nFind an expression (in terms of \\(M, f, A, S, \\rho\\) and \\(g_{r}\\) - the acceleration due to gravity) for the flight speed \\(\\nu_{\\theta}\\) corresponding to a minimum power being needed to maintain this aircraft in flight at constant altitude and velocity. Neglect terms of order \\((\\varepsilon^{2} f)\\) or higher. (3 marks)  \n\nYou may find the following small angle approximation useful:  \n\n$$\n1-\\cos\\varepsilon\\approx{\\frac{\\sin^{2}\\varepsilon}{2}}\n$$  \n\n(c) On the answer sheet, sketch a graph of power \\(P\\) versus flight speed \\(\\nu.\\) Show the separate contributions to the power needed from the two sources of drag. Find an expression (in terms of \\(M, f, A, S, \\rho\\) and \\(g\\)) for the minimum power, \\(P_{min}\\). (2 marks)",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Equational",
        "evidence_source": "equation",
        "evidence_context": "The air slows slightly, with a change of speed \\(\nu \\left(<< 1\\%\right.\\) of \\(\nu\\)) given by: \\(\frac{\\Delta\nu}{\nu}=\frac{f}{A}\\)",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/textbook_needrop_en_550",
        "ID": "0a9ffe96-fdf0-4605-ab7b-2370940ca324",
        "questions": "What is the simplified small-angle approximation for \\(1 - \\cos\u000barepsilon\\)?",
        "answers": "\\(\frac{\\sin^{2}\u000barepsilon}{2}\\)",
        "context": "Side view of wing (in a frame of reference moving with the aircraft):  \n\n![](images/edb5a905c54a5429adf8b7b5b2f2607c79ef6cf10feefaacbb028536de54fbf6.jpg)  \n\nIgnore the modification of the air flow due to the propeller.  \n\n(a) Consider the change in momentum of the air moving past the wing, with no change in speed while it does so. Derive expressions for the vertical lift force \\(L\\) and the horizontal drag force \\(D_{I}\\) on the wing in terms of wing dimensions, \\(\\nu, \\varepsilon,\\) and the air density \\(\\rho.\\) Assume the direction of air flow is always parallel to the plane of the side-view diagram. (3 marks)  \n\n(b) There is an additional horizontal drag force \\(D_{2}\\) caused by the friction of air flowing over the surface of the wing. The air slows slightly, with a change of speed \\(\\nu \\left(<< 1\\%\\right.\\) of \\(\\nu\\)) given by:  \n\n$$\n\\frac{\\Delta\\nu}{\\nu}=\\frac{f}{A}\n$$  \n\nThe value of \\(f\\) is independent of \\(\\varepsilon.\\)  \n\nFind an expression (in terms of \\(M, f, A, S, \\rho\\) and \\(g_{r}\\) - the acceleration due to gravity) for the flight speed \\(\\nu_{\\theta}\\) corresponding to a minimum power being needed to maintain this aircraft in flight at constant altitude and velocity. Neglect terms of order \\((\\varepsilon^{2} f)\\) or higher. (3 marks)  \n\nYou may find the following small angle approximation useful:  \n\n$$\n1-\\cos\\varepsilon\\approx{\\frac{\\sin^{2}\\varepsilon}{2}}\n$$  \n\n(c) On the answer sheet, sketch a graph of power \\(P\\) versus flight speed \\(\\nu.\\) Show the separate contributions to the power needed from the two sources of drag. Find an expression (in terms of \\(M, f, A, S, \\rho\\) and \\(g\\)) for the minimum power, \\(P_{min}\\). (2 marks)",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "You may find the following small angle approximation useful: \\(1 - \\cos\u000barepsilon \u0007pprox \frac{\\sin^{2}\u000barepsilon}{2}\\)",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/textbook_needrop_en_550",
        "ID": "0aa4e727-04f5-4749-aa3e-e0dd9054a516",
        "questions": "What are the terms that should be neglected in deriving the flight speed \\(\nu_{\theta}\\) for minimum power needed? Provide the order of magnitude to be ignored.",
        "answers": "\\((\u000barepsilon^{2} f)\\)",
        "context": "Side view of wing (in a frame of reference moving with the aircraft):  \n\n![](images/edb5a905c54a5429adf8b7b5b2f2607c79ef6cf10feefaacbb028536de54fbf6.jpg)  \n\nIgnore the modification of the air flow due to the propeller.  \n\n(a) Consider the change in momentum of the air moving past the wing, with no change in speed while it does so. Derive expressions for the vertical lift force \\(L\\) and the horizontal drag force \\(D_{I}\\) on the wing in terms of wing dimensions, \\(\\nu, \\varepsilon,\\) and the air density \\(\\rho.\\) Assume the direction of air flow is always parallel to the plane of the side-view diagram. (3 marks)  \n\n(b) There is an additional horizontal drag force \\(D_{2}\\) caused by the friction of air flowing over the surface of the wing. The air slows slightly, with a change of speed \\(\\nu \\left(<< 1\\%\\right.\\) of \\(\\nu\\)) given by:  \n\n$$\n\\frac{\\Delta\\nu}{\\nu}=\\frac{f}{A}\n$$  \n\nThe value of \\(f\\) is independent of \\(\\varepsilon.\\)  \n\nFind an expression (in terms of \\(M, f, A, S, \\rho\\) and \\(g_{r}\\) - the acceleration due to gravity) for the flight speed \\(\\nu_{\\theta}\\) corresponding to a minimum power being needed to maintain this aircraft in flight at constant altitude and velocity. Neglect terms of order \\((\\varepsilon^{2} f)\\) or higher. (3 marks)  \n\nYou may find the following small angle approximation useful:  \n\n$$\n1-\\cos\\varepsilon\\approx{\\frac{\\sin^{2}\\varepsilon}{2}}\n$$  \n\n(c) On the answer sheet, sketch a graph of power \\(P\\) versus flight speed \\(\\nu.\\) Show the separate contributions to the power needed from the two sources of drag. Find an expression (in terms of \\(M, f, A, S, \\rho\\) and \\(g\\)) for the minimum power, \\(P_{min}\\). (2 marks)",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Neglect terms of order \\((\u000barepsilon^{2} f)\\) or higher.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/(Universitext)_Freitag_E.-Complex_analysis_2._Riemann_surfaces,_several_complex_variables-Springer_(2011).pdf_410",
        "ID": "0aa99188-77ab-4bd4-93c8-a089a75eff8e",
        "questions": "What ensures the existence of the theta function h in the provided proof?",
        "answers": "the existence of h is ensured, since r Q - \\tilde{Q} leads to a nondegenerate Riemannian form.",
        "context": "Proof. As we know, every abelian function can be written in the form\n\n$$\n\\frac{f}{g},\\quad f,g\\in[\\tilde{Q},\\tilde{l},\\tilde{E}],\n$$\n\nfor a suitable triple $(\\tilde{Q},\\tilde{l},\\tilde{E})$.\n\nWe choose the natural number $r$ as in Lemma 9.1. Then we choose an arbitrary theta function\n\n$$\nh\\in[r Q-\\tilde{Q},r l-\\tilde{l},r E-\\tilde{E}],\\quad h\\neq0.\n$$\n\nThe existence of $h$ is ensured, since $r Q - \\tilde{Q}$ leads to a nondegenerate Riemannian form. We have\n\n$$\n{\\frac{f}{g}}={\\frac{f h}{g h}}{\\mathrm{~and~}}f h,g h\\in[r Q,r l,r E],\n$$\n\n# Exercises for Sect. VI.9\n\n1. The polynomial ring $A=\\mathbb{C}[X_{1},\\dots,X_{m}]$ admits the grading\n\n$$\nA_{r}:={\\{P\\in A;\\quad P\\mathrm{~homogeneous~of~degree~}r\\}}.\n$$\n\nCan there be an isomorphism from $A(Q,l,A)$ onto $A$ (for suitable $m$) which is compatible with this grading?\n\n2. Can there be an isomorphism from $A(Q,l,A)$ onto the graded ring of elliptic modular forms ([FB], Sect. V.3) which respects the gradings?\n\n# 10. An on degeneracy Theorem\n\nIn principle, it could be possible that every abelian function for a lattice $L$ is periodic with respect to a bigger lattice $\\tilde{L}$, even if $L$ admits a nondegenerate Riemannian form. Our next goal is to prove that such a pathological behavior is not possible, at least for theta functions. We start with some notation.\n\nLet $A$ be an alternating nondegenerate bilinear form on $\\mathbb{C}^{n}\\times\\mathbb{C}^{n}$ which takes only integral values on $L\\times L$. We can define the dual lattice with respect to $A$ (compare Remark 1.3):\n\n$$\nL_{*}:=\\{z\\in\\mathbb{C}^{n};\\quad A(z,a)\\in\\mathbb{Z}{\\mathrm{~for~all~}}a\\in L\\}.\n$$\n\nIt is easy to show that $L_{*}$ is a lattice and that $L\\subset L_{*}$.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "The existence of $h$ is ensured, since $r Q - \\tilde{Q}$ leads to a nondegenerate Riemannian form.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/(Universitext)_Freitag_E.-Complex_analysis_2._Riemann_surfaces,_several_complex_variables-Springer_(2011).pdf_410",
        "ID": "0aab3d43-d6f3-4903-ab28-422234cb41e1",
        "questions": "What is the defining characteristic of the dual lattice L* with respect to the alternating nondegenerate bilinear form A?",
        "answers": "L* is a set of elements z in $\\mathbb{C}^{n}$ such that A(z,a) is in $\\mathbb{Z}$ for all a in L.",
        "context": "Proof. As we know, every abelian function can be written in the form\n\n$$\n\\frac{f}{g},\\quad f,g\\in[\\tilde{Q},\\tilde{l},\\tilde{E}],\n$$\n\nfor a suitable triple $(\\tilde{Q},\\tilde{l},\\tilde{E})$.\n\nWe choose the natural number $r$ as in Lemma 9.1. Then we choose an arbitrary theta function\n\n$$\nh\\in[r Q-\\tilde{Q},r l-\\tilde{l},r E-\\tilde{E}],\\quad h\\neq0.\n$$\n\nThe existence of $h$ is ensured, since $r Q - \\tilde{Q}$ leads to a nondegenerate Riemannian form. We have\n\n$$\n{\\frac{f}{g}}={\\frac{f h}{g h}}{\\mathrm{~and~}}f h,g h\\in[r Q,r l,r E],\n$$\n\n# Exercises for Sect. VI.9\n\n1. The polynomial ring $A=\\mathbb{C}[X_{1},\\dots,X_{m}]$ admits the grading\n\n$$\nA_{r}:={\\{P\\in A;\\quad P\\mathrm{~homogeneous~of~degree~}r\\}}.\n$$\n\nCan there be an isomorphism from $A(Q,l,A)$ onto $A$ (for suitable $m$) which is compatible with this grading?\n\n2. Can there be an isomorphism from $A(Q,l,A)$ onto the graded ring of elliptic modular forms ([FB], Sect. V.3) which respects the gradings?\n\n# 10. An on degeneracy Theorem\n\nIn principle, it could be possible that every abelian function for a lattice $L$ is periodic with respect to a bigger lattice $\\tilde{L}$, even if $L$ admits a nondegenerate Riemannian form. Our next goal is to prove that such a pathological behavior is not possible, at least for theta functions. We start with some notation.\n\nLet $A$ be an alternating nondegenerate bilinear form on $\\mathbb{C}^{n}\\times\\mathbb{C}^{n}$ which takes only integral values on $L\\times L$. We can define the dual lattice with respect to $A$ (compare Remark 1.3):\n\n$$\nL_{*}:=\\{z\\in\\mathbb{C}^{n};\\quad A(z,a)\\in\\mathbb{Z}{\\mathrm{~for~all~}}a\\in L\\}.\n$$\n\nIt is easy to show that $L_{*}$ is a lattice and that $L\\subset L_{*}$.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Let $A$ be an alternating nondegenerate bilinear form on $\\mathbb{C}^{n}\\times\\mathbb{C}^{n}$ which takes only integral values on $L\\times L$. We can define the dual lattice with respect to $A$ (compare Remark 1.3): $$L_{*}:=\\{z\\in\\mathbb{C}^{n};\\quad A(z,a)\\in\\mathbb{Z}{\\mathrm{~for~all~}}a\\in L\\}.$$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/(Universitext)_Freitag_E.-Complex_analysis_2._Riemann_surfaces,_several_complex_variables-Springer_(2011).pdf_410",
        "ID": "0aacf91c-aa79-4d9b-ad17-e8d81231c521",
        "questions": "Can the polynomial ring A defined as $\\mathbb{C}[X_{1},\\dots,X_{m}]$ with the grading $A_{r}$ be isomorphic to $A(Q,l,A)$ while respecting the grading?",
        "answers": "Can there be an isomorphism from $A(Q,l,A)$ onto $A$ (for suitable m) which is compatible with this grading?",
        "context": "Proof. As we know, every abelian function can be written in the form\n\n$$\n\\frac{f}{g},\\quad f,g\\in[\\tilde{Q},\\tilde{l},\\tilde{E}],\n$$\n\nfor a suitable triple $(\\tilde{Q},\\tilde{l},\\tilde{E})$.\n\nWe choose the natural number $r$ as in Lemma 9.1. Then we choose an arbitrary theta function\n\n$$\nh\\in[r Q-\\tilde{Q},r l-\\tilde{l},r E-\\tilde{E}],\\quad h\\neq0.\n$$\n\nThe existence of $h$ is ensured, since $r Q - \\tilde{Q}$ leads to a nondegenerate Riemannian form. We have\n\n$$\n{\\frac{f}{g}}={\\frac{f h}{g h}}{\\mathrm{~and~}}f h,g h\\in[r Q,r l,r E],\n$$\n\n# Exercises for Sect. VI.9\n\n1. The polynomial ring $A=\\mathbb{C}[X_{1},\\dots,X_{m}]$ admits the grading\n\n$$\nA_{r}:={\\{P\\in A;\\quad P\\mathrm{~homogeneous~of~degree~}r\\}}.\n$$\n\nCan there be an isomorphism from $A(Q,l,A)$ onto $A$ (for suitable $m$) which is compatible with this grading?\n\n2. Can there be an isomorphism from $A(Q,l,A)$ onto the graded ring of elliptic modular forms ([FB], Sect. V.3) which respects the gradings?\n\n# 10. An on degeneracy Theorem\n\nIn principle, it could be possible that every abelian function for a lattice $L$ is periodic with respect to a bigger lattice $\\tilde{L}$, even if $L$ admits a nondegenerate Riemannian form. Our next goal is to prove that such a pathological behavior is not possible, at least for theta functions. We start with some notation.\n\nLet $A$ be an alternating nondegenerate bilinear form on $\\mathbb{C}^{n}\\times\\mathbb{C}^{n}$ which takes only integral values on $L\\times L$. We can define the dual lattice with respect to $A$ (compare Remark 1.3):\n\n$$\nL_{*}:=\\{z\\in\\mathbb{C}^{n};\\quad A(z,a)\\in\\mathbb{Z}{\\mathrm{~for~all~}}a\\in L\\}.\n$$\n\nIt is easy to show that $L_{*}$ is a lattice and that $L\\subset L_{*}$.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Yes/No",
        "evidence_source": "text",
        "evidence_context": "Can there be an isomorphism from $A(Q,l,A)$ onto $A$ (for suitable $m$) which is compatible with this grading?",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/(Universitext)_Freitag_E.-Complex_analysis_2._Riemann_surfaces,_several_complex_variables-Springer_(2011).pdf_410",
        "ID": "0ab3e9a0-8bfc-41e8-9768-f0e32d1122ea",
        "questions": "What is the form of an abelian function for a suitable triple $(\\tilde{Q},\\tilde{l},\\tilde{E})$?",
        "answers": "\\frac{f}{g},\\quad f,g\\in[\\tilde{Q},\\tilde{l},\\tilde{E}]",
        "context": "Proof. As we know, every abelian function can be written in the form\n\n$$\n\\frac{f}{g},\\quad f,g\\in[\\tilde{Q},\\tilde{l},\\tilde{E}],\n$$\n\nfor a suitable triple $(\\tilde{Q},\\tilde{l},\\tilde{E})$.\n\nWe choose the natural number $r$ as in Lemma 9.1. Then we choose an arbitrary theta function\n\n$$\nh\\in[r Q-\\tilde{Q},r l-\\tilde{l},r E-\\tilde{E}],\\quad h\\neq0.\n$$\n\nThe existence of $h$ is ensured, since $r Q - \\tilde{Q}$ leads to a nondegenerate Riemannian form. We have\n\n$$\n{\\frac{f}{g}}={\\frac{f h}{g h}}{\\mathrm{~and~}}f h,g h\\in[r Q,r l,r E],\n$$\n\n# Exercises for Sect. VI.9\n\n1. The polynomial ring $A=\\mathbb{C}[X_{1},\\dots,X_{m}]$ admits the grading\n\n$$\nA_{r}:={\\{P\\in A;\\quad P\\mathrm{~homogeneous~of~degree~}r\\}}.\n$$\n\nCan there be an isomorphism from $A(Q,l,A)$ onto $A$ (for suitable $m$) which is compatible with this grading?\n\n2. Can there be an isomorphism from $A(Q,l,A)$ onto the graded ring of elliptic modular forms ([FB], Sect. V.3) which respects the gradings?\n\n# 10. An on degeneracy Theorem\n\nIn principle, it could be possible that every abelian function for a lattice $L$ is periodic with respect to a bigger lattice $\\tilde{L}$, even if $L$ admits a nondegenerate Riemannian form. Our next goal is to prove that such a pathological behavior is not possible, at least for theta functions. We start with some notation.\n\nLet $A$ be an alternating nondegenerate bilinear form on $\\mathbb{C}^{n}\\times\\mathbb{C}^{n}$ which takes only integral values on $L\\times L$. We can define the dual lattice with respect to $A$ (compare Remark 1.3):\n\n$$\nL_{*}:=\\{z\\in\\mathbb{C}^{n};\\quad A(z,a)\\in\\mathbb{Z}{\\mathrm{~for~all~}}a\\in L\\}.\n$$\n\nIt is easy to show that $L_{*}$ is a lattice and that $L\\subset L_{*}$.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "every abelian function can be written in the form $$\\frac{f}{g},\\quad f,g\\in[\\tilde{Q},\\tilde{l},\\tilde{E}],$$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/(Universitext)_Freitag_E.-Complex_analysis_2._Riemann_surfaces,_several_complex_variables-Springer_(2011).pdf_410",
        "ID": "0ac1f2aa-9453-48a3-9d38-bed2c7c854e1",
        "questions": "What nondegenerate form is linked to the existence of the theta function $h$?",
        "answers": "$r Q - \\tilde{Q}$ leads to a nondegenerate Riemannian form",
        "context": "Proof. As we know, every abelian function can be written in the form\n\n$$\n\\frac{f}{g},\\quad f,g\\in[\\tilde{Q},\\tilde{l},\\tilde{E}],\n$$\n\nfor a suitable triple $(\\tilde{Q},\\tilde{l},\\tilde{E})$.\n\nWe choose the natural number $r$ as in Lemma 9.1. Then we choose an arbitrary theta function\n\n$$\nh\\in[r Q-\\tilde{Q},r l-\\tilde{l},r E-\\tilde{E}],\\quad h\\neq0.\n$$\n\nThe existence of $h$ is ensured, since $r Q - \\tilde{Q}$ leads to a nondegenerate Riemannian form. We have\n\n$$\n{\\frac{f}{g}}={\\frac{f h}{g h}}{\\mathrm{~and~}}f h,g h\\in[r Q,r l,r E],\n$$\n\n# Exercises for Sect. VI.9\n\n1. The polynomial ring $A=\\mathbb{C}[X_{1},\\dots,X_{m}]$ admits the grading\n\n$$\nA_{r}:={\\{P\\in A;\\quad P\\mathrm{~homogeneous~of~degree~}r\\}}.\n$$\n\nCan there be an isomorphism from $A(Q,l,A)$ onto $A$ (for suitable $m$) which is compatible with this grading?\n\n2. Can there be an isomorphism from $A(Q,l,A)$ onto the graded ring of elliptic modular forms ([FB], Sect. V.3) which respects the gradings?\n\n# 10. An on degeneracy Theorem\n\nIn principle, it could be possible that every abelian function for a lattice $L$ is periodic with respect to a bigger lattice $\\tilde{L}$, even if $L$ admits a nondegenerate Riemannian form. Our next goal is to prove that such a pathological behavior is not possible, at least for theta functions. We start with some notation.\n\nLet $A$ be an alternating nondegenerate bilinear form on $\\mathbb{C}^{n}\\times\\mathbb{C}^{n}$ which takes only integral values on $L\\times L$. We can define the dual lattice with respect to $A$ (compare Remark 1.3):\n\n$$\nL_{*}:=\\{z\\in\\mathbb{C}^{n};\\quad A(z,a)\\in\\mathbb{Z}{\\mathrm{~for~all~}}a\\in L\\}.\n$$\n\nIt is easy to show that $L_{*}$ is a lattice and that $L\\subset L_{*}$.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "The existence of $h$ is ensured, since $r Q - \\tilde{Q}$ leads to a nondegenerate Riemannian form.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/(Universitext)_Freitag_E.-Complex_analysis_2._Riemann_surfaces,_several_complex_variables-Springer_(2011).pdf_410",
        "ID": "0ac66d00-89e6-4011-8ae7-e8a3f8ac453c",
        "questions": "How is the dual lattice $L_{*}$ defined with respect to an alternating nondegenerate bilinear form $A$?",
        "answers": "$L_{*}:=\\{z\\in\\mathbb{C}^{n};\\quad A(z,a)\\in\\mathbb{Z}{\\mathrm{~for~all~}}a\\in L\\}$",
        "context": "Proof. As we know, every abelian function can be written in the form\n\n$$\n\\frac{f}{g},\\quad f,g\\in[\\tilde{Q},\\tilde{l},\\tilde{E}],\n$$\n\nfor a suitable triple $(\\tilde{Q},\\tilde{l},\\tilde{E})$.\n\nWe choose the natural number $r$ as in Lemma 9.1. Then we choose an arbitrary theta function\n\n$$\nh\\in[r Q-\\tilde{Q},r l-\\tilde{l},r E-\\tilde{E}],\\quad h\\neq0.\n$$\n\nThe existence of $h$ is ensured, since $r Q - \\tilde{Q}$ leads to a nondegenerate Riemannian form. We have\n\n$$\n{\\frac{f}{g}}={\\frac{f h}{g h}}{\\mathrm{~and~}}f h,g h\\in[r Q,r l,r E],\n$$\n\n# Exercises for Sect. VI.9\n\n1. The polynomial ring $A=\\mathbb{C}[X_{1},\\dots,X_{m}]$ admits the grading\n\n$$\nA_{r}:={\\{P\\in A;\\quad P\\mathrm{~homogeneous~of~degree~}r\\}}.\n$$\n\nCan there be an isomorphism from $A(Q,l,A)$ onto $A$ (for suitable $m$) which is compatible with this grading?\n\n2. Can there be an isomorphism from $A(Q,l,A)$ onto the graded ring of elliptic modular forms ([FB], Sect. V.3) which respects the gradings?\n\n# 10. An on degeneracy Theorem\n\nIn principle, it could be possible that every abelian function for a lattice $L$ is periodic with respect to a bigger lattice $\\tilde{L}$, even if $L$ admits a nondegenerate Riemannian form. Our next goal is to prove that such a pathological behavior is not possible, at least for theta functions. We start with some notation.\n\nLet $A$ be an alternating nondegenerate bilinear form on $\\mathbb{C}^{n}\\times\\mathbb{C}^{n}$ which takes only integral values on $L\\times L$. We can define the dual lattice with respect to $A$ (compare Remark 1.3):\n\n$$\nL_{*}:=\\{z\\in\\mathbb{C}^{n};\\quad A(z,a)\\in\\mathbb{Z}{\\mathrm{~for~all~}}a\\in L\\}.\n$$\n\nIt is easy to show that $L_{*}$ is a lattice and that $L\\subset L_{*}$.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Equation",
        "evidence_source": "equation",
        "evidence_context": "$$L_{*}:=\\{z\\in\\mathbb{C}^{n};\\quad A(z,a)\\in\\mathbb{Z}{\\mathrm{~for~all~}}a\\in L\\}.$$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/Functional_Analysis_Spectral_Theory(Sunder).pdf_104",
        "ID": "0ad75046-9ea4-446f-8857-cabee086f500",
        "questions": "What defines a genuine inner product on the quotient space V = A/N_\u03c6?",
        "answers": "The equation $\\langle x + N_{\\phi}, y + N_{\\phi} \rangle = \\phi(y^{\u0007st}x)$",
        "context": "The inequality 3.4.21 states that $x \\in N_{\\phi}$ if and only if $\\phi(y^{*}x) = 0$ for all $y \\in A$; this implies that $N_{\\phi}$ is a vector subspace of $A$, which is in fact a left-ideal (i.e., $x \\in N_{\\phi} \\implies zx \\in N_{\\phi}$ $\\forall z \\in A$).\n\nDeduce now that the equation  \n\n$$\n\\langle x + N_{\\phi}, y + N_{\\phi} \\rangle = \\phi(y^{\\ast}x)\n$$\n\ndefines a genuine inner product on the quotient space $V = A/N_{\\phi}$. For notational convenience, let us write $\\eta(x) = x + N_{\\phi}$ so that $\\eta: A \\rightarrow V$; since $N_{\\phi}$ is a left-ideal in $A$, it follows that each $x \\in A$ unambiguously defines a linear map $L_{x}: V \\to V$ by the prescription: $L_{x}\\eta(y) = \\eta(xy)$.\n\nWe claim now that each $L_{x}$ is a bounded operator on the inner product space $V$ and that $||L_{x}||_{\\mathcal{L}(V)} \\leq ||x||_{A}$. This amounts to the assertion that  \n\n$$\n\\phi(y^{*}x^{*}xy) = ||L_{x}\\eta(y)||^{2} \\leq ||x||^{2}||\\eta(y)||^{2} = ||x||^{2}\\phi(y^{*}y)\n$$  \n\nfor all $x, y \\in A$. Notice now that, for each fixed $y \\in A$, if we consider the functional $\\psi(z) = \\phi(y^{*}zy)$, then $\\psi$ is a positive linear functional; consequently, we find from Proposition 3.4.11 that $||\\psi|| = \\psi(1) = \\phi(y^{*}y)$; in particular, we find that for arbitrary $x, y \\in A$, we must have $\\phi(y^{*}x^{*}xy) = \\psi(x^{*}x) \\leq ||\\psi|| \\cdot ||x^{*}x||$, in other words, $\\phi(y^{*}x^{*}xy) \\leq ||x||^{2}\\phi(y^{*}y)$, as asserted.\n\nSince $V$ is a genuine inner product space, we may form its completion\u2014call it $\\mathcal{H}_{\\phi}$\u2014where we think of $V$ as a dense subspace of $\\mathcal{H}_{\\phi}$. We may deduce from the previous paragraph that each $L_{x}$ extends uniquely to a bounded operator on $\\mathcal{H}_{\\phi}$, which we will denote by $\\pi_{\\phi}(x)$; the operator $\\pi_{\\phi}(x)$ is defined by the requirement that $\\pi_{\\phi}(x)\\eta(y) = \\eta(xy)$; this immediately implies that $\\pi_{\\phi}$ is an unital algebra homomorphism of $A$ into $\\mathcal{L}(\\mathcal{H}_{\\phi})$. To see that $\\pi_{\\phi}$ preserves adjoints, note that if $x, y, z \\in A$ are arbitrary, then  \n\n$$\n\\begin{array}{l c l}\n{{\\langle\\pi_{\\phi}(x)\\eta(y), \\eta(z)\\rangle}} &{{=}} &{{\\phi(z^{\\ast}(xy))}}\\\\\n{{\\ }} &{{=}} &{{\\phi((x^{\\ast}z)^{\\ast}y)}}\\\\\n{{\\ }} &{{=}} &{{\\langle\\eta(y), \\pi_{\\phi}(x^{\\ast})\\eta(z)\\rangle,}}\n\\end{array}\n$$  \n\nwhich implies, in view of the density of $\\eta(A)$ in $\\mathcal{H}_{\\phi}$, that $\\pi_{\\phi}(x)^{*} = \\pi_{\\phi}(x^{*})$, so that $\\pi_{\\phi}$ is indeed a representation of $A$ on $\\mathcal{H}_{\\phi}$. Finally, it should be obvious that $\\xi_{\\phi} = \\eta(1)$ is a cyclic vector for this representation.\n\nConversely, if $({\\mathcal{H}}, \\pi, \\xi)$ is another triple which also \u201cworks\u201d for $\\phi$ as asserted in the statement of the second half of Theorem 3.4.13, observe that for arbitrary $x, y \\in A$, we have  \n\n$$\n\\langle\\pi(x)\\xi, \\pi(y)\\xi\\rangle_{\\mathcal{H}} = \\phi(y^{*}x) = \\langle\\pi_{\\phi}(x)\\xi_{\\phi}, \\pi_{\\phi}(y)\\xi_{\\phi}\\rangle_{\\mathcal{H}_{\\phi}}\n$$  \n\nfor all $x, y \\in A$; the assumptions that $\\xi$ and $\\xi_{\\phi}$ are cyclic vectors for the representations $\\pi$ and $\\pi_{\\phi}$ respectively imply, via Exercise 3.4.12, that there exists a unique unitary operator $U: \\mathcal{H} \\rightarrow \\mathcal{H}_{\\phi}$ with the property that $U(\\pi(x)\\xi) = \\pi_{\\phi}(x)\\xi_{\\phi}$ for all $x \\in A$; it is clear that $U$ has the properties asserted in Theorem 3.4.13.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Deduce now that the equation $\\langle x + N_{\\phi}, y + N_{\\phi} \rangle = \\phi(y^{\u0007st}x)$ defines a genuine inner product on the quotient space $V = A/N_{\\phi}$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Functional_Analysis_Spectral_Theory(Sunder).pdf_104",
        "ID": "0adf1c0a-7e3d-48a3-b1c1-096ecd6e3c6f",
        "questions": "What is the norm inequality for the bounded operator L_x on the inner product space V, expressed in terms of norms in A?",
        "answers": "||L_{x}||_{\\mathcal{L}(V)} \\leq ||x||_{A}",
        "context": "The inequality 3.4.21 states that $x \\in N_{\\phi}$ if and only if $\\phi(y^{*}x) = 0$ for all $y \\in A$; this implies that $N_{\\phi}$ is a vector subspace of $A$, which is in fact a left-ideal (i.e., $x \\in N_{\\phi} \\implies zx \\in N_{\\phi}$ $\\forall z \\in A$).\n\nDeduce now that the equation  \n\n$$\n\\langle x + N_{\\phi}, y + N_{\\phi} \\rangle = \\phi(y^{\\ast}x)\n$$\n\ndefines a genuine inner product on the quotient space $V = A/N_{\\phi}$. For notational convenience, let us write $\\eta(x) = x + N_{\\phi}$ so that $\\eta: A \\rightarrow V$; since $N_{\\phi}$ is a left-ideal in $A$, it follows that each $x \\in A$ unambiguously defines a linear map $L_{x}: V \\to V$ by the prescription: $L_{x}\\eta(y) = \\eta(xy)$.\n\nWe claim now that each $L_{x}$ is a bounded operator on the inner product space $V$ and that $||L_{x}||_{\\mathcal{L}(V)} \\leq ||x||_{A}$. This amounts to the assertion that  \n\n$$\n\\phi(y^{*}x^{*}xy) = ||L_{x}\\eta(y)||^{2} \\leq ||x||^{2}||\\eta(y)||^{2} = ||x||^{2}\\phi(y^{*}y)\n$$  \n\nfor all $x, y \\in A$. Notice now that, for each fixed $y \\in A$, if we consider the functional $\\psi(z) = \\phi(y^{*}zy)$, then $\\psi$ is a positive linear functional; consequently, we find from Proposition 3.4.11 that $||\\psi|| = \\psi(1) = \\phi(y^{*}y)$; in particular, we find that for arbitrary $x, y \\in A$, we must have $\\phi(y^{*}x^{*}xy) = \\psi(x^{*}x) \\leq ||\\psi|| \\cdot ||x^{*}x||$, in other words, $\\phi(y^{*}x^{*}xy) \\leq ||x||^{2}\\phi(y^{*}y)$, as asserted.\n\nSince $V$ is a genuine inner product space, we may form its completion\u2014call it $\\mathcal{H}_{\\phi}$\u2014where we think of $V$ as a dense subspace of $\\mathcal{H}_{\\phi}$. We may deduce from the previous paragraph that each $L_{x}$ extends uniquely to a bounded operator on $\\mathcal{H}_{\\phi}$, which we will denote by $\\pi_{\\phi}(x)$; the operator $\\pi_{\\phi}(x)$ is defined by the requirement that $\\pi_{\\phi}(x)\\eta(y) = \\eta(xy)$; this immediately implies that $\\pi_{\\phi}$ is an unital algebra homomorphism of $A$ into $\\mathcal{L}(\\mathcal{H}_{\\phi})$. To see that $\\pi_{\\phi}$ preserves adjoints, note that if $x, y, z \\in A$ are arbitrary, then  \n\n$$\n\\begin{array}{l c l}\n{{\\langle\\pi_{\\phi}(x)\\eta(y), \\eta(z)\\rangle}} &{{=}} &{{\\phi(z^{\\ast}(xy))}}\\\\\n{{\\ }} &{{=}} &{{\\phi((x^{\\ast}z)^{\\ast}y)}}\\\\\n{{\\ }} &{{=}} &{{\\langle\\eta(y), \\pi_{\\phi}(x^{\\ast})\\eta(z)\\rangle,}}\n\\end{array}\n$$  \n\nwhich implies, in view of the density of $\\eta(A)$ in $\\mathcal{H}_{\\phi}$, that $\\pi_{\\phi}(x)^{*} = \\pi_{\\phi}(x^{*})$, so that $\\pi_{\\phi}$ is indeed a representation of $A$ on $\\mathcal{H}_{\\phi}$. Finally, it should be obvious that $\\xi_{\\phi} = \\eta(1)$ is a cyclic vector for this representation.\n\nConversely, if $({\\mathcal{H}}, \\pi, \\xi)$ is another triple which also \u201cworks\u201d for $\\phi$ as asserted in the statement of the second half of Theorem 3.4.13, observe that for arbitrary $x, y \\in A$, we have  \n\n$$\n\\langle\\pi(x)\\xi, \\pi(y)\\xi\\rangle_{\\mathcal{H}} = \\phi(y^{*}x) = \\langle\\pi_{\\phi}(x)\\xi_{\\phi}, \\pi_{\\phi}(y)\\xi_{\\phi}\\rangle_{\\mathcal{H}_{\\phi}}\n$$  \n\nfor all $x, y \\in A$; the assumptions that $\\xi$ and $\\xi_{\\phi}$ are cyclic vectors for the representations $\\pi$ and $\\pi_{\\phi}$ respectively imply, via Exercise 3.4.12, that there exists a unique unitary operator $U: \\mathcal{H} \\rightarrow \\mathcal{H}_{\\phi}$ with the property that $U(\\pi(x)\\xi) = \\pi_{\\phi}(x)\\xi_{\\phi}$ for all $x \\in A$; it is clear that $U$ has the properties asserted in Theorem 3.4.13.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "We claim now that each $L_{x}$ is a bounded operator on the inner product space $V$ and that $||L_{x}||_{\\mathcal{L}(V)} \\leq ||x||_{A}$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Functional_Analysis_Spectral_Theory(Sunder).pdf_104",
        "ID": "0ae1f4ac-5bd2-4526-aaa6-897a213a6a4a",
        "questions": "Is the operator \u03c0_\u03c6 a unital algebra homomorphism of A into L(\u210b_\u03c6)?",
        "answers": "Yes",
        "context": "The inequality 3.4.21 states that $x \\in N_{\\phi}$ if and only if $\\phi(y^{*}x) = 0$ for all $y \\in A$; this implies that $N_{\\phi}$ is a vector subspace of $A$, which is in fact a left-ideal (i.e., $x \\in N_{\\phi} \\implies zx \\in N_{\\phi}$ $\\forall z \\in A$).\n\nDeduce now that the equation  \n\n$$\n\\langle x + N_{\\phi}, y + N_{\\phi} \\rangle = \\phi(y^{\\ast}x)\n$$\n\ndefines a genuine inner product on the quotient space $V = A/N_{\\phi}$. For notational convenience, let us write $\\eta(x) = x + N_{\\phi}$ so that $\\eta: A \\rightarrow V$; since $N_{\\phi}$ is a left-ideal in $A$, it follows that each $x \\in A$ unambiguously defines a linear map $L_{x}: V \\to V$ by the prescription: $L_{x}\\eta(y) = \\eta(xy)$.\n\nWe claim now that each $L_{x}$ is a bounded operator on the inner product space $V$ and that $||L_{x}||_{\\mathcal{L}(V)} \\leq ||x||_{A}$. This amounts to the assertion that  \n\n$$\n\\phi(y^{*}x^{*}xy) = ||L_{x}\\eta(y)||^{2} \\leq ||x||^{2}||\\eta(y)||^{2} = ||x||^{2}\\phi(y^{*}y)\n$$  \n\nfor all $x, y \\in A$. Notice now that, for each fixed $y \\in A$, if we consider the functional $\\psi(z) = \\phi(y^{*}zy)$, then $\\psi$ is a positive linear functional; consequently, we find from Proposition 3.4.11 that $||\\psi|| = \\psi(1) = \\phi(y^{*}y)$; in particular, we find that for arbitrary $x, y \\in A$, we must have $\\phi(y^{*}x^{*}xy) = \\psi(x^{*}x) \\leq ||\\psi|| \\cdot ||x^{*}x||$, in other words, $\\phi(y^{*}x^{*}xy) \\leq ||x||^{2}\\phi(y^{*}y)$, as asserted.\n\nSince $V$ is a genuine inner product space, we may form its completion\u2014call it $\\mathcal{H}_{\\phi}$\u2014where we think of $V$ as a dense subspace of $\\mathcal{H}_{\\phi}$. We may deduce from the previous paragraph that each $L_{x}$ extends uniquely to a bounded operator on $\\mathcal{H}_{\\phi}$, which we will denote by $\\pi_{\\phi}(x)$; the operator $\\pi_{\\phi}(x)$ is defined by the requirement that $\\pi_{\\phi}(x)\\eta(y) = \\eta(xy)$; this immediately implies that $\\pi_{\\phi}$ is an unital algebra homomorphism of $A$ into $\\mathcal{L}(\\mathcal{H}_{\\phi})$. To see that $\\pi_{\\phi}$ preserves adjoints, note that if $x, y, z \\in A$ are arbitrary, then  \n\n$$\n\\begin{array}{l c l}\n{{\\langle\\pi_{\\phi}(x)\\eta(y), \\eta(z)\\rangle}} &{{=}} &{{\\phi(z^{\\ast}(xy))}}\\\\\n{{\\ }} &{{=}} &{{\\phi((x^{\\ast}z)^{\\ast}y)}}\\\\\n{{\\ }} &{{=}} &{{\\langle\\eta(y), \\pi_{\\phi}(x^{\\ast})\\eta(z)\\rangle,}}\n\\end{array}\n$$  \n\nwhich implies, in view of the density of $\\eta(A)$ in $\\mathcal{H}_{\\phi}$, that $\\pi_{\\phi}(x)^{*} = \\pi_{\\phi}(x^{*})$, so that $\\pi_{\\phi}$ is indeed a representation of $A$ on $\\mathcal{H}_{\\phi}$. Finally, it should be obvious that $\\xi_{\\phi} = \\eta(1)$ is a cyclic vector for this representation.\n\nConversely, if $({\\mathcal{H}}, \\pi, \\xi)$ is another triple which also \u201cworks\u201d for $\\phi$ as asserted in the statement of the second half of Theorem 3.4.13, observe that for arbitrary $x, y \\in A$, we have  \n\n$$\n\\langle\\pi(x)\\xi, \\pi(y)\\xi\\rangle_{\\mathcal{H}} = \\phi(y^{*}x) = \\langle\\pi_{\\phi}(x)\\xi_{\\phi}, \\pi_{\\phi}(y)\\xi_{\\phi}\\rangle_{\\mathcal{H}_{\\phi}}\n$$  \n\nfor all $x, y \\in A$; the assumptions that $\\xi$ and $\\xi_{\\phi}$ are cyclic vectors for the representations $\\pi$ and $\\pi_{\\phi}$ respectively imply, via Exercise 3.4.12, that there exists a unique unitary operator $U: \\mathcal{H} \\rightarrow \\mathcal{H}_{\\phi}$ with the property that $U(\\pi(x)\\xi) = \\pi_{\\phi}(x)\\xi_{\\phi}$ for all $x \\in A$; it is clear that $U$ has the properties asserted in Theorem 3.4.13.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Yes/No",
        "evidence_source": "text",
        "evidence_context": "this immediately implies that $\\pi_{\\phi}$ is an unital algebra homomorphism of $A$ into $\\mathcal{L}(\\mathcal{H}_{\\phi})$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Functional_Analysis_Spectral_Theory(Sunder).pdf_104",
        "ID": "0ae5aba8-bd7d-4e3e-b8df-13d3470df9e6",
        "questions": "Under what conditions is $x$ in the null space $N_{\\phi}$ according to the inequality 3.4.21?",
        "answers": "$x \\in N_{\\phi}$ if and only if $\\phi(y^{*}x) = 0$ for all $y \\in A$",
        "context": "The inequality 3.4.21 states that $x \\in N_{\\phi}$ if and only if $\\phi(y^{*}x) = 0$ for all $y \\in A$; this implies that $N_{\\phi}$ is a vector subspace of $A$, which is in fact a left-ideal (i.e., $x \\in N_{\\phi} \\implies zx \\in N_{\\phi}$ $\\forall z \\in A$).\n\nDeduce now that the equation  \n\n$$\n\\langle x + N_{\\phi}, y + N_{\\phi} \\rangle = \\phi(y^{\\ast}x)\n$$\n\ndefines a genuine inner product on the quotient space $V = A/N_{\\phi}$. For notational convenience, let us write $\\eta(x) = x + N_{\\phi}$ so that $\\eta: A \\rightarrow V$; since $N_{\\phi}$ is a left-ideal in $A$, it follows that each $x \\in A$ unambiguously defines a linear map $L_{x}: V \\to V$ by the prescription: $L_{x}\\eta(y) = \\eta(xy)$.\n\nWe claim now that each $L_{x}$ is a bounded operator on the inner product space $V$ and that $||L_{x}||_{\\mathcal{L}(V)} \\leq ||x||_{A}$. This amounts to the assertion that  \n\n$$\n\\phi(y^{*}x^{*}xy) = ||L_{x}\\eta(y)||^{2} \\leq ||x||^{2}||\\eta(y)||^{2} = ||x||^{2}\\phi(y^{*}y)\n$$  \n\nfor all $x, y \\in A$. Notice now that, for each fixed $y \\in A$, if we consider the functional $\\psi(z) = \\phi(y^{*}zy)$, then $\\psi$ is a positive linear functional; consequently, we find from Proposition 3.4.11 that $||\\psi|| = \\psi(1) = \\phi(y^{*}y)$; in particular, we find that for arbitrary $x, y \\in A$, we must have $\\phi(y^{*}x^{*}xy) = \\psi(x^{*}x) \\leq ||\\psi|| \\cdot ||x^{*}x||$, in other words, $\\phi(y^{*}x^{*}xy) \\leq ||x||^{2}\\phi(y^{*}y)$, as asserted.\n\nSince $V$ is a genuine inner product space, we may form its completion\u2014call it $\\mathcal{H}_{\\phi}$\u2014where we think of $V$ as a dense subspace of $\\mathcal{H}_{\\phi}$. We may deduce from the previous paragraph that each $L_{x}$ extends uniquely to a bounded operator on $\\mathcal{H}_{\\phi}$, which we will denote by $\\pi_{\\phi}(x)$; the operator $\\pi_{\\phi}(x)$ is defined by the requirement that $\\pi_{\\phi}(x)\\eta(y) = \\eta(xy)$; this immediately implies that $\\pi_{\\phi}$ is an unital algebra homomorphism of $A$ into $\\mathcal{L}(\\mathcal{H}_{\\phi})$. To see that $\\pi_{\\phi}$ preserves adjoints, note that if $x, y, z \\in A$ are arbitrary, then  \n\n$$\n\\begin{array}{l c l}\n{{\\langle\\pi_{\\phi}(x)\\eta(y), \\eta(z)\\rangle}} &{{=}} &{{\\phi(z^{\\ast}(xy))}}\\\\\n{{\\ }} &{{=}} &{{\\phi((x^{\\ast}z)^{\\ast}y)}}\\\\\n{{\\ }} &{{=}} &{{\\langle\\eta(y), \\pi_{\\phi}(x^{\\ast})\\eta(z)\\rangle,}}\n\\end{array}\n$$  \n\nwhich implies, in view of the density of $\\eta(A)$ in $\\mathcal{H}_{\\phi}$, that $\\pi_{\\phi}(x)^{*} = \\pi_{\\phi}(x^{*})$, so that $\\pi_{\\phi}$ is indeed a representation of $A$ on $\\mathcal{H}_{\\phi}$. Finally, it should be obvious that $\\xi_{\\phi} = \\eta(1)$ is a cyclic vector for this representation.\n\nConversely, if $({\\mathcal{H}}, \\pi, \\xi)$ is another triple which also \u201cworks\u201d for $\\phi$ as asserted in the statement of the second half of Theorem 3.4.13, observe that for arbitrary $x, y \\in A$, we have  \n\n$$\n\\langle\\pi(x)\\xi, \\pi(y)\\xi\\rangle_{\\mathcal{H}} = \\phi(y^{*}x) = \\langle\\pi_{\\phi}(x)\\xi_{\\phi}, \\pi_{\\phi}(y)\\xi_{\\phi}\\rangle_{\\mathcal{H}_{\\phi}}\n$$  \n\nfor all $x, y \\in A$; the assumptions that $\\xi$ and $\\xi_{\\phi}$ are cyclic vectors for the representations $\\pi$ and $\\pi_{\\phi}$ respectively imply, via Exercise 3.4.12, that there exists a unique unitary operator $U: \\mathcal{H} \\rightarrow \\mathcal{H}_{\\phi}$ with the property that $U(\\pi(x)\\xi) = \\pi_{\\phi}(x)\\xi_{\\phi}$ for all $x \\in A$; it is clear that $U$ has the properties asserted in Theorem 3.4.13.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$x \\in N_{\\phi}$ if and only if $\\phi(y^{*}x) = 0$ for all $y \\in A$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/Functional_Analysis_Spectral_Theory(Sunder).pdf_104",
        "ID": "0ae9e2e6-adaa-41ca-b19b-701bd042c1c8",
        "questions": "What property of the operator $L_{x}$ is asserted by the equation $\\phi(y^{*}x^{*}xy) = ||L_{x}\\eta(y)||^{2} \\leq ||x||^{2}||\\eta(y)||^{2}$?",
        "answers": "Each $L_{x}$ is a bounded operator on the inner product space $V$ and that $||L_{x}||_{\\mathcal{L}(V)} \\leq ||x||_{A}$",
        "context": "The inequality 3.4.21 states that $x \\in N_{\\phi}$ if and only if $\\phi(y^{*}x) = 0$ for all $y \\in A$; this implies that $N_{\\phi}$ is a vector subspace of $A$, which is in fact a left-ideal (i.e., $x \\in N_{\\phi} \\implies zx \\in N_{\\phi}$ $\\forall z \\in A$).\n\nDeduce now that the equation  \n\n$$\n\\langle x + N_{\\phi}, y + N_{\\phi} \\rangle = \\phi(y^{\\ast}x)\n$$\n\ndefines a genuine inner product on the quotient space $V = A/N_{\\phi}$. For notational convenience, let us write $\\eta(x) = x + N_{\\phi}$ so that $\\eta: A \\rightarrow V$; since $N_{\\phi}$ is a left-ideal in $A$, it follows that each $x \\in A$ unambiguously defines a linear map $L_{x}: V \\to V$ by the prescription: $L_{x}\\eta(y) = \\eta(xy)$.\n\nWe claim now that each $L_{x}$ is a bounded operator on the inner product space $V$ and that $||L_{x}||_{\\mathcal{L}(V)} \\leq ||x||_{A}$. This amounts to the assertion that  \n\n$$\n\\phi(y^{*}x^{*}xy) = ||L_{x}\\eta(y)||^{2} \\leq ||x||^{2}||\\eta(y)||^{2} = ||x||^{2}\\phi(y^{*}y)\n$$  \n\nfor all $x, y \\in A$. Notice now that, for each fixed $y \\in A$, if we consider the functional $\\psi(z) = \\phi(y^{*}zy)$, then $\\psi$ is a positive linear functional; consequently, we find from Proposition 3.4.11 that $||\\psi|| = \\psi(1) = \\phi(y^{*}y)$; in particular, we find that for arbitrary $x, y \\in A$, we must have $\\phi(y^{*}x^{*}xy) = \\psi(x^{*}x) \\leq ||\\psi|| \\cdot ||x^{*}x||$, in other words, $\\phi(y^{*}x^{*}xy) \\leq ||x||^{2}\\phi(y^{*}y)$, as asserted.\n\nSince $V$ is a genuine inner product space, we may form its completion\u2014call it $\\mathcal{H}_{\\phi}$\u2014where we think of $V$ as a dense subspace of $\\mathcal{H}_{\\phi}$. We may deduce from the previous paragraph that each $L_{x}$ extends uniquely to a bounded operator on $\\mathcal{H}_{\\phi}$, which we will denote by $\\pi_{\\phi}(x)$; the operator $\\pi_{\\phi}(x)$ is defined by the requirement that $\\pi_{\\phi}(x)\\eta(y) = \\eta(xy)$; this immediately implies that $\\pi_{\\phi}$ is an unital algebra homomorphism of $A$ into $\\mathcal{L}(\\mathcal{H}_{\\phi})$. To see that $\\pi_{\\phi}$ preserves adjoints, note that if $x, y, z \\in A$ are arbitrary, then  \n\n$$\n\\begin{array}{l c l}\n{{\\langle\\pi_{\\phi}(x)\\eta(y), \\eta(z)\\rangle}} &{{=}} &{{\\phi(z^{\\ast}(xy))}}\\\\\n{{\\ }} &{{=}} &{{\\phi((x^{\\ast}z)^{\\ast}y)}}\\\\\n{{\\ }} &{{=}} &{{\\langle\\eta(y), \\pi_{\\phi}(x^{\\ast})\\eta(z)\\rangle,}}\n\\end{array}\n$$  \n\nwhich implies, in view of the density of $\\eta(A)$ in $\\mathcal{H}_{\\phi}$, that $\\pi_{\\phi}(x)^{*} = \\pi_{\\phi}(x^{*})$, so that $\\pi_{\\phi}$ is indeed a representation of $A$ on $\\mathcal{H}_{\\phi}$. Finally, it should be obvious that $\\xi_{\\phi} = \\eta(1)$ is a cyclic vector for this representation.\n\nConversely, if $({\\mathcal{H}}, \\pi, \\xi)$ is another triple which also \u201cworks\u201d for $\\phi$ as asserted in the statement of the second half of Theorem 3.4.13, observe that for arbitrary $x, y \\in A$, we have  \n\n$$\n\\langle\\pi(x)\\xi, \\pi(y)\\xi\\rangle_{\\mathcal{H}} = \\phi(y^{*}x) = \\langle\\pi_{\\phi}(x)\\xi_{\\phi}, \\pi_{\\phi}(y)\\xi_{\\phi}\\rangle_{\\mathcal{H}_{\\phi}}\n$$  \n\nfor all $x, y \\in A$; the assumptions that $\\xi$ and $\\xi_{\\phi}$ are cyclic vectors for the representations $\\pi$ and $\\pi_{\\phi}$ respectively imply, via Exercise 3.4.12, that there exists a unique unitary operator $U: \\mathcal{H} \\rightarrow \\mathcal{H}_{\\phi}$ with the property that $U(\\pi(x)\\xi) = \\pi_{\\phi}(x)\\xi_{\\phi}$ for all $x \\in A$; it is clear that $U$ has the properties asserted in Theorem 3.4.13.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "This amounts to the assertion that  $\\phi(y^{*}x^{*}xy) = ||L_{x}\\eta(y)||^{2} \\leq ||x||^{2}||\\eta(y)||^{2}$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/Functional_Analysis_Spectral_Theory(Sunder).pdf_104",
        "ID": "0aeade49-1276-40bc-a8eb-65950bc798ef",
        "questions": "What does the equation $\\langle x + N_{\\phi}, y + N_{\\phi} \\rangle = \\phi(y^{\\ast}x)$ define on the quotient space $V = A/N_{\\phi}$?",
        "answers": "The equation defines a genuine inner product on the quotient space $V = A/N_{\\phi}$.",
        "context": "The inequality 3.4.21 states that $x \\in N_{\\phi}$ if and only if $\\phi(y^{*}x) = 0$ for all $y \\in A$; this implies that $N_{\\phi}$ is a vector subspace of $A$, which is in fact a left-ideal (i.e., $x \\in N_{\\phi} \\implies zx \\in N_{\\phi}$ $\\forall z \\in A$).\n\nDeduce now that the equation  \n\n$$\n\\langle x + N_{\\phi}, y + N_{\\phi} \\rangle = \\phi(y^{\\ast}x)\n$$\n\ndefines a genuine inner product on the quotient space $V = A/N_{\\phi}$. For notational convenience, let us write $\\eta(x) = x + N_{\\phi}$ so that $\\eta: A \\rightarrow V$; since $N_{\\phi}$ is a left-ideal in $A$, it follows that each $x \\in A$ unambiguously defines a linear map $L_{x}: V \\to V$ by the prescription: $L_{x}\\eta(y) = \\eta(xy)$.\n\nWe claim now that each $L_{x}$ is a bounded operator on the inner product space $V$ and that $||L_{x}||_{\\mathcal{L}(V)} \\leq ||x||_{A}$. This amounts to the assertion that  \n\n$$\n\\phi(y^{*}x^{*}xy) = ||L_{x}\\eta(y)||^{2} \\leq ||x||^{2}||\\eta(y)||^{2} = ||x||^{2}\\phi(y^{*}y)\n$$  \n\nfor all $x, y \\in A$. Notice now that, for each fixed $y \\in A$, if we consider the functional $\\psi(z) = \\phi(y^{*}zy)$, then $\\psi$ is a positive linear functional; consequently, we find from Proposition 3.4.11 that $||\\psi|| = \\psi(1) = \\phi(y^{*}y)$; in particular, we find that for arbitrary $x, y \\in A$, we must have $\\phi(y^{*}x^{*}xy) = \\psi(x^{*}x) \\leq ||\\psi|| \\cdot ||x^{*}x||$, in other words, $\\phi(y^{*}x^{*}xy) \\leq ||x||^{2}\\phi(y^{*}y)$, as asserted.\n\nSince $V$ is a genuine inner product space, we may form its completion\u2014call it $\\mathcal{H}_{\\phi}$\u2014where we think of $V$ as a dense subspace of $\\mathcal{H}_{\\phi}$. We may deduce from the previous paragraph that each $L_{x}$ extends uniquely to a bounded operator on $\\mathcal{H}_{\\phi}$, which we will denote by $\\pi_{\\phi}(x)$; the operator $\\pi_{\\phi}(x)$ is defined by the requirement that $\\pi_{\\phi}(x)\\eta(y) = \\eta(xy)$; this immediately implies that $\\pi_{\\phi}$ is an unital algebra homomorphism of $A$ into $\\mathcal{L}(\\mathcal{H}_{\\phi})$. To see that $\\pi_{\\phi}$ preserves adjoints, note that if $x, y, z \\in A$ are arbitrary, then  \n\n$$\n\\begin{array}{l c l}\n{{\\langle\\pi_{\\phi}(x)\\eta(y), \\eta(z)\\rangle}} &{{=}} &{{\\phi(z^{\\ast}(xy))}}\\\\\n{{\\ }} &{{=}} &{{\\phi((x^{\\ast}z)^{\\ast}y)}}\\\\\n{{\\ }} &{{=}} &{{\\langle\\eta(y), \\pi_{\\phi}(x^{\\ast})\\eta(z)\\rangle,}}\n\\end{array}\n$$  \n\nwhich implies, in view of the density of $\\eta(A)$ in $\\mathcal{H}_{\\phi}$, that $\\pi_{\\phi}(x)^{*} = \\pi_{\\phi}(x^{*})$, so that $\\pi_{\\phi}$ is indeed a representation of $A$ on $\\mathcal{H}_{\\phi}$. Finally, it should be obvious that $\\xi_{\\phi} = \\eta(1)$ is a cyclic vector for this representation.\n\nConversely, if $({\\mathcal{H}}, \\pi, \\xi)$ is another triple which also \u201cworks\u201d for $\\phi$ as asserted in the statement of the second half of Theorem 3.4.13, observe that for arbitrary $x, y \\in A$, we have  \n\n$$\n\\langle\\pi(x)\\xi, \\pi(y)\\xi\\rangle_{\\mathcal{H}} = \\phi(y^{*}x) = \\langle\\pi_{\\phi}(x)\\xi_{\\phi}, \\pi_{\\phi}(y)\\xi_{\\phi}\\rangle_{\\mathcal{H}_{\\phi}}\n$$  \n\nfor all $x, y \\in A$; the assumptions that $\\xi$ and $\\xi_{\\phi}$ are cyclic vectors for the representations $\\pi$ and $\\pi_{\\phi}$ respectively imply, via Exercise 3.4.12, that there exists a unique unitary operator $U: \\mathcal{H} \\rightarrow \\mathcal{H}_{\\phi}$ with the property that $U(\\pi(x)\\xi) = \\pi_{\\phi}(x)\\xi_{\\phi}$ for all $x \\in A$; it is clear that $U$ has the properties asserted in Theorem 3.4.13.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Deduce now that the equation $$ \\langle x + N_{\\phi}, y + N_{\\phi} \\rangle = \\phi(y^{\\ast}x) $$ defines a genuine inner product on the quotient space $V = A/N_{\\phi}$.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/adventures-in-stochastic-processes.pdf_123",
        "ID": "0af3b8f2-1b74-4e30-b2a2-9e5708ff1966",
        "questions": "What is the inverse of the matrix expression (I-Q) in terms of the sum of a series?",
        "answers": "(I-Q)^{-1} = \\sum_{n=0}^{\\infty}Q^{n}",
        "context": "and it is easy to see from this that  \n\n$$\n(I-Q)^{-1}=\\sum_{n=0}^{\\infty}Q^{n}.\n$$  \n\nThis covers most of the elementary and usual applications. The rest of this section discusses the uniqueness of the solution to (2.1l.4) and the existence of the fundamental matrix in more general contexts. This discussion may contain more detail than is necessary for the beginning student; therefore, some readers may wish to skip the rest of this section and continue reading at the beginning of Section 2.12.  \n\nWhen $S$ is infinite, (2.11.4) need not have a unique solution, and this case will now be considered in some detail.  \n\nExample 2.11.2. Consider the transient success run chain with  \n\n$$\nP={\\left(\\begin{array}{ccccc}{q_{0}}&{p_{0}}&{0}&{}&{\\cdots}\\\\ {q_{1}}&{0}&{p_{1}}&{0}&{\\cdots}\\\\ {q_{2}}&{0}&{0}&{p_{2}\\cdots}\\\\ {\\vdots}&{}&{\\ddots}&{}\\\\ \\end{array}\\right)}\n$$  \n\nand $\\begin{array}{r}{\\prod_{i=0}^{\\infty}p_{i}\\;>\\;0,\\;\\;\\sum_{i}(1\\,-\\,p_{i})\\;<\\;\\infty}\\end{array}$ (Refer to Lemma 2.9.1.) Make 0 absorbing so the matrix becomes  \n\n$$\nP r=\\left(\\begin{array}{ccccc}{{1}}&{{0}}&{{0}}&{{0}}&{{\\cdots}}\\\\ {{q_{1}}}&{{0}}&{{p_{1}}}&{{0}}&{{\\cdots}}\\\\ {{q_{2}}}&{{0}}&{{0}}&{{p_{2}}}&{{\\cdots}}\\\\ {{\\vdots}}&{{\\ddots}}&{{}}&{{}}&{{}}\\end{array}\\right).\n$$  \n\nIgnoring the initial row and column gives  \n\n$$\nQ=\\left(\\begin{array}{ccccc}{{0}}&{{p_{1}}}&{{0}}&{{0}}&{{\\cdots}}\\\\ {{0}}&{{0}}&{{p_{2}}}&{{0}}&{{\\cdots}}\\\\ {{0}}&{{0}}&{{0}}&{{p_{3}}}&{{\\cdots}}\\\\ {{\\vdots}}&{{}}&{{\\ddots}}&{{}}&{{}}\\end{array}\\right)\\,.\n$$  \n\nThus the system (2.11.4) becomes $(i\\geq1,u_{i0}=u_{i})$  \n\n$$\nu_{i}=p_{i}u_{i+1}+q_{i}.\n$$  \n\nSet $\\overline{{u_{i}}}=1-u_{i}$ and we get  \n\n$$\n\\overline{{u_{i}}}=p_{i}\\overline{{u_{i+1}}}.\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "and it is easy to see from this that  $$(I-Q)^{-1} = \\sum_{n=0}^{\\infty}Q^{n}.$$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/adventures-in-stochastic-processes.pdf_123",
        "ID": "0b04ceb9-9fe0-4a14-bae2-a4d5bb03da5b",
        "questions": "How do you denote the system in equation form when considering the transient success run chain with matrix Q?",
        "answers": "u_{i} = p_{i}u_{i+1}+q_{i}",
        "context": "and it is easy to see from this that  \n\n$$\n(I-Q)^{-1}=\\sum_{n=0}^{\\infty}Q^{n}.\n$$  \n\nThis covers most of the elementary and usual applications. The rest of this section discusses the uniqueness of the solution to (2.1l.4) and the existence of the fundamental matrix in more general contexts. This discussion may contain more detail than is necessary for the beginning student; therefore, some readers may wish to skip the rest of this section and continue reading at the beginning of Section 2.12.  \n\nWhen $S$ is infinite, (2.11.4) need not have a unique solution, and this case will now be considered in some detail.  \n\nExample 2.11.2. Consider the transient success run chain with  \n\n$$\nP={\\left(\\begin{array}{ccccc}{q_{0}}&{p_{0}}&{0}&{}&{\\cdots}\\\\ {q_{1}}&{0}&{p_{1}}&{0}&{\\cdots}\\\\ {q_{2}}&{0}&{0}&{p_{2}\\cdots}\\\\ {\\vdots}&{}&{\\ddots}&{}\\\\ \\end{array}\\right)}\n$$  \n\nand $\\begin{array}{r}{\\prod_{i=0}^{\\infty}p_{i}\\;>\\;0,\\;\\;\\sum_{i}(1\\,-\\,p_{i})\\;<\\;\\infty}\\end{array}$ (Refer to Lemma 2.9.1.) Make 0 absorbing so the matrix becomes  \n\n$$\nP r=\\left(\\begin{array}{ccccc}{{1}}&{{0}}&{{0}}&{{0}}&{{\\cdots}}\\\\ {{q_{1}}}&{{0}}&{{p_{1}}}&{{0}}&{{\\cdots}}\\\\ {{q_{2}}}&{{0}}&{{0}}&{{p_{2}}}&{{\\cdots}}\\\\ {{\\vdots}}&{{\\ddots}}&{{}}&{{}}&{{}}\\end{array}\\right).\n$$  \n\nIgnoring the initial row and column gives  \n\n$$\nQ=\\left(\\begin{array}{ccccc}{{0}}&{{p_{1}}}&{{0}}&{{0}}&{{\\cdots}}\\\\ {{0}}&{{0}}&{{p_{2}}}&{{0}}&{{\\cdots}}\\\\ {{0}}&{{0}}&{{0}}&{{p_{3}}}&{{\\cdots}}\\\\ {{\\vdots}}&{{}}&{{\\ddots}}&{{}}&{{}}\\end{array}\\right)\\,.\n$$  \n\nThus the system (2.11.4) becomes $(i\\geq1,u_{i0}=u_{i})$  \n\n$$\nu_{i}=p_{i}u_{i+1}+q_{i}.\n$$  \n\nSet $\\overline{{u_{i}}}=1-u_{i}$ and we get  \n\n$$\n\\overline{{u_{i}}}=p_{i}\\overline{{u_{i+1}}}.\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Equation",
        "evidence_source": "equation",
        "evidence_context": "Thus the system (2.11.4) becomes $(i\\geq1,u_{i0}=u_{i})$  $$u_{i}=p_{i}u_{i+1}+q_{i}.$$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/adventures-in-stochastic-processes.pdf_123",
        "ID": "0b0727aa-e4e9-4de5-84a9-2db9360044f2",
        "questions": "What transformation is applied to $u_i$ to obtain $\\overline{{u_{i}}}$ in the given matrix system?",
        "answers": "\\overline{{u_{i}}} = 1 - u_{i}",
        "context": "and it is easy to see from this that  \n\n$$\n(I-Q)^{-1}=\\sum_{n=0}^{\\infty}Q^{n}.\n$$  \n\nThis covers most of the elementary and usual applications. The rest of this section discusses the uniqueness of the solution to (2.1l.4) and the existence of the fundamental matrix in more general contexts. This discussion may contain more detail than is necessary for the beginning student; therefore, some readers may wish to skip the rest of this section and continue reading at the beginning of Section 2.12.  \n\nWhen $S$ is infinite, (2.11.4) need not have a unique solution, and this case will now be considered in some detail.  \n\nExample 2.11.2. Consider the transient success run chain with  \n\n$$\nP={\\left(\\begin{array}{ccccc}{q_{0}}&{p_{0}}&{0}&{}&{\\cdots}\\\\ {q_{1}}&{0}&{p_{1}}&{0}&{\\cdots}\\\\ {q_{2}}&{0}&{0}&{p_{2}\\cdots}\\\\ {\\vdots}&{}&{\\ddots}&{}\\\\ \\end{array}\\right)}\n$$  \n\nand $\\begin{array}{r}{\\prod_{i=0}^{\\infty}p_{i}\\;>\\;0,\\;\\;\\sum_{i}(1\\,-\\,p_{i})\\;<\\;\\infty}\\end{array}$ (Refer to Lemma 2.9.1.) Make 0 absorbing so the matrix becomes  \n\n$$\nP r=\\left(\\begin{array}{ccccc}{{1}}&{{0}}&{{0}}&{{0}}&{{\\cdots}}\\\\ {{q_{1}}}&{{0}}&{{p_{1}}}&{{0}}&{{\\cdots}}\\\\ {{q_{2}}}&{{0}}&{{0}}&{{p_{2}}}&{{\\cdots}}\\\\ {{\\vdots}}&{{\\ddots}}&{{}}&{{}}&{{}}\\end{array}\\right).\n$$  \n\nIgnoring the initial row and column gives  \n\n$$\nQ=\\left(\\begin{array}{ccccc}{{0}}&{{p_{1}}}&{{0}}&{{0}}&{{\\cdots}}\\\\ {{0}}&{{0}}&{{p_{2}}}&{{0}}&{{\\cdots}}\\\\ {{0}}&{{0}}&{{0}}&{{p_{3}}}&{{\\cdots}}\\\\ {{\\vdots}}&{{}}&{{\\ddots}}&{{}}&{{}}\\end{array}\\right)\\,.\n$$  \n\nThus the system (2.11.4) becomes $(i\\geq1,u_{i0}=u_{i})$  \n\n$$\nu_{i}=p_{i}u_{i+1}+q_{i}.\n$$  \n\nSet $\\overline{{u_{i}}}=1-u_{i}$ and we get  \n\n$$\n\\overline{{u_{i}}}=p_{i}\\overline{{u_{i+1}}}.\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Equation",
        "evidence_source": "equation",
        "evidence_context": "Set $\\overline{{u_{i}}} = 1 - u_{i}$ and we get ...",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/adventures-in-stochastic-processes.pdf_123",
        "ID": "0b0a13d7-d42b-4d03-bd09-e9995e688624",
        "questions": "What is the expression for the inverse of (I-Q) in terms of summation when Q is given?",
        "answers": "(I-Q)^{-1} = \\sum_{n=0}^{\\infty}Q^{n}",
        "context": "and it is easy to see from this that  \n\n$$\n(I-Q)^{-1}=\\sum_{n=0}^{\\infty}Q^{n}.\n$$  \n\nThis covers most of the elementary and usual applications. The rest of this section discusses the uniqueness of the solution to (2.1l.4) and the existence of the fundamental matrix in more general contexts. This discussion may contain more detail than is necessary for the beginning student; therefore, some readers may wish to skip the rest of this section and continue reading at the beginning of Section 2.12.  \n\nWhen $S$ is infinite, (2.11.4) need not have a unique solution, and this case will now be considered in some detail.  \n\nExample 2.11.2. Consider the transient success run chain with  \n\n$$\nP={\\left(\\begin{array}{ccccc}{q_{0}}&{p_{0}}&{0}&{}&{\\cdots}\\\\ {q_{1}}&{0}&{p_{1}}&{0}&{\\cdots}\\\\ {q_{2}}&{0}&{0}&{p_{2}\\cdots}\\\\ {\\vdots}&{}&{\\ddots}&{}\\\\ \\end{array}\\right)}\n$$  \n\nand $\\begin{array}{r}{\\prod_{i=0}^{\\infty}p_{i}\\;>\\;0,\\;\\;\\sum_{i}(1\\,-\\,p_{i})\\;<\\;\\infty}\\end{array}$ (Refer to Lemma 2.9.1.) Make 0 absorbing so the matrix becomes  \n\n$$\nP r=\\left(\\begin{array}{ccccc}{{1}}&{{0}}&{{0}}&{{0}}&{{\\cdots}}\\\\ {{q_{1}}}&{{0}}&{{p_{1}}}&{{0}}&{{\\cdots}}\\\\ {{q_{2}}}&{{0}}&{{0}}&{{p_{2}}}&{{\\cdots}}\\\\ {{\\vdots}}&{{\\ddots}}&{{}}&{{}}&{{}}\\end{array}\\right).\n$$  \n\nIgnoring the initial row and column gives  \n\n$$\nQ=\\left(\\begin{array}{ccccc}{{0}}&{{p_{1}}}&{{0}}&{{0}}&{{\\cdots}}\\\\ {{0}}&{{0}}&{{p_{2}}}&{{0}}&{{\\cdots}}\\\\ {{0}}&{{0}}&{{0}}&{{p_{3}}}&{{\\cdots}}\\\\ {{\\vdots}}&{{}}&{{\\ddots}}&{{}}&{{}}\\end{array}\\right)\\,.\n$$  \n\nThus the system (2.11.4) becomes $(i\\geq1,u_{i0}=u_{i})$  \n\n$$\nu_{i}=p_{i}u_{i+1}+q_{i}.\n$$  \n\nSet $\\overline{{u_{i}}}=1-u_{i}$ and we get  \n\n$$\n\\overline{{u_{i}}}=p_{i}\\overline{{u_{i+1}}}.\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "it is easy to see from this that  $$(I-Q)^{-1}=\\sum_{n=0}^{\\infty}Q^{n}.$$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/adventures-in-stochastic-processes.pdf_123",
        "ID": "0b0c6abc-0159-4c81-8480-0e8d682f9440",
        "questions": "In the equation for the transient success run chain, what transformation is applied to make state 0 absorbing?",
        "answers": "Make 0 absorbing so the matrix becomes $$ P r=\\left(\\begin{array}{ccccc}{{1}}&{{0}}&{{0}}&{{0}}&{{\\cdots}}\\\\ {{q_{1}}}&{{0}}&{{p_{1}}}&{{0}}&{{\\cdots}}\\\\ {{q_{2}}}&{{0}}&{{0}}&{{p_{2}}}&{{\\cdots}}\\\\ {{\\vdots}}&{{\\ddots}}&{{}}&{{}}&{{}}\\end{array}\\right). $$",
        "context": "and it is easy to see from this that  \n\n$$\n(I-Q)^{-1}=\\sum_{n=0}^{\\infty}Q^{n}.\n$$  \n\nThis covers most of the elementary and usual applications. The rest of this section discusses the uniqueness of the solution to (2.1l.4) and the existence of the fundamental matrix in more general contexts. This discussion may contain more detail than is necessary for the beginning student; therefore, some readers may wish to skip the rest of this section and continue reading at the beginning of Section 2.12.  \n\nWhen $S$ is infinite, (2.11.4) need not have a unique solution, and this case will now be considered in some detail.  \n\nExample 2.11.2. Consider the transient success run chain with  \n\n$$\nP={\\left(\\begin{array}{ccccc}{q_{0}}&{p_{0}}&{0}&{}&{\\cdots}\\\\ {q_{1}}&{0}&{p_{1}}&{0}&{\\cdots}\\\\ {q_{2}}&{0}&{0}&{p_{2}\\cdots}\\\\ {\\vdots}&{}&{\\ddots}&{}\\\\ \\end{array}\\right)}\n$$  \n\nand $\\begin{array}{r}{\\prod_{i=0}^{\\infty}p_{i}\\;>\\;0,\\;\\;\\sum_{i}(1\\,-\\,p_{i})\\;<\\;\\infty}\\end{array}$ (Refer to Lemma 2.9.1.) Make 0 absorbing so the matrix becomes  \n\n$$\nP r=\\left(\\begin{array}{ccccc}{{1}}&{{0}}&{{0}}&{{0}}&{{\\cdots}}\\\\ {{q_{1}}}&{{0}}&{{p_{1}}}&{{0}}&{{\\cdots}}\\\\ {{q_{2}}}&{{0}}&{{0}}&{{p_{2}}}&{{\\cdots}}\\\\ {{\\vdots}}&{{\\ddots}}&{{}}&{{}}&{{}}\\end{array}\\right).\n$$  \n\nIgnoring the initial row and column gives  \n\n$$\nQ=\\left(\\begin{array}{ccccc}{{0}}&{{p_{1}}}&{{0}}&{{0}}&{{\\cdots}}\\\\ {{0}}&{{0}}&{{p_{2}}}&{{0}}&{{\\cdots}}\\\\ {{0}}&{{0}}&{{0}}&{{p_{3}}}&{{\\cdots}}\\\\ {{\\vdots}}&{{}}&{{\\ddots}}&{{}}&{{}}\\end{array}\\right)\\,.\n$$  \n\nThus the system (2.11.4) becomes $(i\\geq1,u_{i0}=u_{i})$  \n\n$$\nu_{i}=p_{i}u_{i+1}+q_{i}.\n$$  \n\nSet $\\overline{{u_{i}}}=1-u_{i}$ and we get  \n\n$$\n\\overline{{u_{i}}}=p_{i}\\overline{{u_{i+1}}}.\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Make 0 absorbing so the matrix becomes  $$ P r=\\left(\\begin{array}{ccccc}{{1}}&{{0}}&{{0}}&{{0}}&{{\\cdots}}\\\\ {{q_{1}}}&{{0}}&{{p_{1}}}&{{0}}&{{\\cdots}}\\\\ {{q_{2}}}&{{0}}&{{0}}&{{p_{2}}}&{{\\cdots}}\\\\ {{\\vdots}}&{{\\ddots}}&{{}}&{{}}&{{}}\\end{array}\\right). $$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/adventures-in-stochastic-processes.pdf_123",
        "ID": "0b0eab3c-2620-4321-bb93-3b849e996246",
        "questions": "What is the relationship between $\\overline{u_{i}}$ and $\\overline{u_{i+1}}$ in the transformed equation for the transient success run chain?",
        "answers": "$\\overline{{u_{i}}}=p_{i}\\overline{{u_{i+1}}}$",
        "context": "and it is easy to see from this that  \n\n$$\n(I-Q)^{-1}=\\sum_{n=0}^{\\infty}Q^{n}.\n$$  \n\nThis covers most of the elementary and usual applications. The rest of this section discusses the uniqueness of the solution to (2.1l.4) and the existence of the fundamental matrix in more general contexts. This discussion may contain more detail than is necessary for the beginning student; therefore, some readers may wish to skip the rest of this section and continue reading at the beginning of Section 2.12.  \n\nWhen $S$ is infinite, (2.11.4) need not have a unique solution, and this case will now be considered in some detail.  \n\nExample 2.11.2. Consider the transient success run chain with  \n\n$$\nP={\\left(\\begin{array}{ccccc}{q_{0}}&{p_{0}}&{0}&{}&{\\cdots}\\\\ {q_{1}}&{0}&{p_{1}}&{0}&{\\cdots}\\\\ {q_{2}}&{0}&{0}&{p_{2}\\cdots}\\\\ {\\vdots}&{}&{\\ddots}&{}\\\\ \\end{array}\\right)}\n$$  \n\nand $\\begin{array}{r}{\\prod_{i=0}^{\\infty}p_{i}\\;>\\;0,\\;\\;\\sum_{i}(1\\,-\\,p_{i})\\;<\\;\\infty}\\end{array}$ (Refer to Lemma 2.9.1.) Make 0 absorbing so the matrix becomes  \n\n$$\nP r=\\left(\\begin{array}{ccccc}{{1}}&{{0}}&{{0}}&{{0}}&{{\\cdots}}\\\\ {{q_{1}}}&{{0}}&{{p_{1}}}&{{0}}&{{\\cdots}}\\\\ {{q_{2}}}&{{0}}&{{0}}&{{p_{2}}}&{{\\cdots}}\\\\ {{\\vdots}}&{{\\ddots}}&{{}}&{{}}&{{}}\\end{array}\\right).\n$$  \n\nIgnoring the initial row and column gives  \n\n$$\nQ=\\left(\\begin{array}{ccccc}{{0}}&{{p_{1}}}&{{0}}&{{0}}&{{\\cdots}}\\\\ {{0}}&{{0}}&{{p_{2}}}&{{0}}&{{\\cdots}}\\\\ {{0}}&{{0}}&{{0}}&{{p_{3}}}&{{\\cdots}}\\\\ {{\\vdots}}&{{}}&{{\\ddots}}&{{}}&{{}}\\end{array}\\right)\\,.\n$$  \n\nThus the system (2.11.4) becomes $(i\\geq1,u_{i0}=u_{i})$  \n\n$$\nu_{i}=p_{i}u_{i+1}+q_{i}.\n$$  \n\nSet $\\overline{{u_{i}}}=1-u_{i}$ and we get  \n\n$$\n\\overline{{u_{i}}}=p_{i}\\overline{{u_{i+1}}}.\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Set $\\overline{{u_{i}}}=1-u_{i}$ and we get  $$ \\overline{{u_{i}}}=p_{i}\\overline{{u_{i+1}}}. $$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/math-4145.pdf_612",
        "ID": "0b10c800-2b07-4d36-aa6e-df80fb25a0f9",
        "questions": "What is the equation of the antiderivative for the acceleration of a falling object given as -32 ft/s\u00b2?",
        "answers": "$-32t+C$",
        "context": "$$\n{\\begin{array}{r l}{\\displaystyle\\int(3x^{2}+4x+5)\\,d x\\ =\\int3x^{2}\\,d x+\\int4x\\ d x+\\int5\\ d x}\\\\ {\\displaystyle}&{=3\\int x^{2}\\,d x+4\\int x\\ d x+\\int5\\ d x}\\\\ {\\displaystyle}&{=3\\cdot{\\cfrac{1}{3}}\\,x^{3}+4\\cdot{\\cfrac{1}{2}}\\,x^{2}+5x+C}\\\\ {\\displaystyle}&{=x^{3}+2x^{2}+5x+C}\\end{array}}\n$$  \n\nIn practice, we generally do not write out all these steps, but we demonstrate them here for completeness.  \n\n\u00b7Rule #5 is the Power Rule of indefinite integration. There are two important things to keep in mind: $n\\neq-1$   $\\textstyle\\int{\\frac{1}{x}}\\ d x\\neq\\cdots{\\frac{1}{0}}x^{0}+C!$  2. We are presenting antidifferentiation as the \"inverse operation\" of differentiation. Here is a useful quote to remember: \"Inverse operations do the opposite things in the opposite order.\" When taking a derivative using the Power Rule, we first multiply by the power, then second subtract 1 from the power. To find the antiderivative, do the opposite things in the opposite order: first add one to the power, then second divide by the power.\n\n\u00b7Note that Rule #14 incorporates the absolute value of  $\\mathbfit{x}$  . The exercises will work the reader through why this is the case; for now, know the absolute value is important and cannot be ignored.  \n\n# Initial Value Problems  \n\nIn Section 2.3, we saw that the derivative of a position function gave a velocity function, and the derivative of a velocity function describes acceleration. We can now go \"the other way\": the antiderivative of an acceleration function gives a velocity function, etc. While there is just one derivative of a given function, there are infinite antiderivatives. Therefore, we cannot ask \"what is the velocity of an object whose acceleration is $-32\\mathrm{ft}/s^{2}?\"$ since there is more than one answer.  \n\nWe can find the answer if we provide more information with the question, as done in the following example. Often, the additional information comes in the form of an initial value, a value of the function that one knows beforehand.  \n\n# Example 4.0.3: Solving initial value problems  \n\nThe acceleration due to gravity of a falling object is $-32\\;\\mathrm{ft}/\\mathrm{s}^{2}$ . At time $t=3$ , a falling object had a velocity of $-10$ ft/s. Find the equation of the object's velocity.  \n\n# Solution  \n\nWe want to know a velocity function, $v(t)$ . We know two things:  \n\n1. The acceleration, i.e., $v^{\\prime}(t)=-32$ , and 2. the velocity at a specific time, i.e., $v(3)=-10$  \n\nUsing the first piece of information, we know that $v(t)$ is an antiderivative of $v^{\\prime}(t)=-32$ . So we begin by finding the indefinite integral of $-32$  \n\n$$\n\\int(-32)\\;d t=-32t+C=v(t).\n$$  \n\nNow we use the fact that $v(3)=-10$ to find $C$  \n\n$$\n\\begin{array}{c}{v(t)=-32t+C}\\\\ {v(3)=-10}\\\\ {-32(3)+C=-10}\\\\ {C=86}\\end{array}\n$$  \n\nThus $v(t)=-32t+86$ . We can use this equation to understand the motion of the object: when $t=0$ , the object had a velocity of $86$ ft/s. Since the velocity is positive, the object was moving upward.  \n\nWhen did the object begin moving down? Immediately after $v(t)=0$.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Equation",
        "evidence_source": "text",
        "evidence_context": "$\\int(-32)\\;d t=-32t+C=v(t).$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/math-4145.pdf_612",
        "ID": "0b11354c-3a9e-4435-8a56-e0661be77a10",
        "questions": "Given that the velocity of a falling object at time t=3 is -10 ft/s and the acceleration due to gravity is -32 ft/s\u00b2, how do you determine the constant C in the velocity equation?",
        "answers": "$C=86$",
        "context": "$$\n{\\begin{array}{r l}{\\displaystyle\\int(3x^{2}+4x+5)\\,d x\\ =\\int3x^{2}\\,d x+\\int4x\\ d x+\\int5\\ d x}\\\\ {\\displaystyle}&{=3\\int x^{2}\\,d x+4\\int x\\ d x+\\int5\\ d x}\\\\ {\\displaystyle}&{=3\\cdot{\\cfrac{1}{3}}\\,x^{3}+4\\cdot{\\cfrac{1}{2}}\\,x^{2}+5x+C}\\\\ {\\displaystyle}&{=x^{3}+2x^{2}+5x+C}\\end{array}}\n$$  \n\nIn practice, we generally do not write out all these steps, but we demonstrate them here for completeness.  \n\n\u00b7Rule #5 is the Power Rule of indefinite integration. There are two important things to keep in mind: $n\\neq-1$   $\\textstyle\\int{\\frac{1}{x}}\\ d x\\neq\\cdots{\\frac{1}{0}}x^{0}+C!$  2. We are presenting antidifferentiation as the \"inverse operation\" of differentiation. Here is a useful quote to remember: \"Inverse operations do the opposite things in the opposite order.\" When taking a derivative using the Power Rule, we first multiply by the power, then second subtract 1 from the power. To find the antiderivative, do the opposite things in the opposite order: first add one to the power, then second divide by the power.\n\n\u00b7Note that Rule #14 incorporates the absolute value of  $\\mathbfit{x}$  . The exercises will work the reader through why this is the case; for now, know the absolute value is important and cannot be ignored.  \n\n# Initial Value Problems  \n\nIn Section 2.3, we saw that the derivative of a position function gave a velocity function, and the derivative of a velocity function describes acceleration. We can now go \"the other way\": the antiderivative of an acceleration function gives a velocity function, etc. While there is just one derivative of a given function, there are infinite antiderivatives. Therefore, we cannot ask \"what is the velocity of an object whose acceleration is $-32\\mathrm{ft}/s^{2}?\"$ since there is more than one answer.  \n\nWe can find the answer if we provide more information with the question, as done in the following example. Often, the additional information comes in the form of an initial value, a value of the function that one knows beforehand.  \n\n# Example 4.0.3: Solving initial value problems  \n\nThe acceleration due to gravity of a falling object is $-32\\;\\mathrm{ft}/\\mathrm{s}^{2}$ . At time $t=3$ , a falling object had a velocity of $-10$ ft/s. Find the equation of the object's velocity.  \n\n# Solution  \n\nWe want to know a velocity function, $v(t)$ . We know two things:  \n\n1. The acceleration, i.e., $v^{\\prime}(t)=-32$ , and 2. the velocity at a specific time, i.e., $v(3)=-10$  \n\nUsing the first piece of information, we know that $v(t)$ is an antiderivative of $v^{\\prime}(t)=-32$ . So we begin by finding the indefinite integral of $-32$  \n\n$$\n\\int(-32)\\;d t=-32t+C=v(t).\n$$  \n\nNow we use the fact that $v(3)=-10$ to find $C$  \n\n$$\n\\begin{array}{c}{v(t)=-32t+C}\\\\ {v(3)=-10}\\\\ {-32(3)+C=-10}\\\\ {C=86}\\end{array}\n$$  \n\nThus $v(t)=-32t+86$ . We can use this equation to understand the motion of the object: when $t=0$ , the object had a velocity of $86$ ft/s. Since the velocity is positive, the object was moving upward.  \n\nWhen did the object begin moving down? Immediately after $v(t)=0$.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Numeric",
        "evidence_source": "equation",
        "evidence_context": "Now we use the fact that $v(3)=-10$ to find $C$ $$\\begin{array}{c}{v(t)=-32t+C}\\ {v(3)=-10}\\ {-32(3)+C=-10}\\ {C=86}\\end{array}$$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/math-4145.pdf_612",
        "ID": "0b19f5b2-c38b-4a22-8809-dad9f97d975c",
        "questions": "Provide the complete steps to integrate the function $3x^2 + 4x + 5$ including each antiderivative and constant integration stages.",
        "answers": "$\\displaystyle \\int(3x^{2}+4x+5)\\,d x = \\int 3x^{2}\\,d x + \\int 4x\\ d x + \\int 5\\ d x = 3 \\int x^{2}\\,d x + 4 \\int x\\ d x + \\int 5\\ d x = 3 \\cdot \\cfrac{1}{3}\\,x^{3} + 4 \\cdot \\cfrac{1}{2}\\,x^{2} + 5x + C = x^{3} + 2x^{2} + 5x + C$",
        "context": "$$\n{\\begin{array}{r l}{\\displaystyle\\int(3x^{2}+4x+5)\\,d x\\ =\\int3x^{2}\\,d x+\\int4x\\ d x+\\int5\\ d x}\\\\ {\\displaystyle}&{=3\\int x^{2}\\,d x+4\\int x\\ d x+\\int5\\ d x}\\\\ {\\displaystyle}&{=3\\cdot{\\cfrac{1}{3}}\\,x^{3}+4\\cdot{\\cfrac{1}{2}}\\,x^{2}+5x+C}\\\\ {\\displaystyle}&{=x^{3}+2x^{2}+5x+C}\\end{array}}\n$$  \n\nIn practice, we generally do not write out all these steps, but we demonstrate them here for completeness.  \n\n\u00b7Rule #5 is the Power Rule of indefinite integration. There are two important things to keep in mind: $n\\neq-1$   $\\textstyle\\int{\\frac{1}{x}}\\ d x\\neq\\cdots{\\frac{1}{0}}x^{0}+C!$  2. We are presenting antidifferentiation as the \"inverse operation\" of differentiation. Here is a useful quote to remember: \"Inverse operations do the opposite things in the opposite order.\" When taking a derivative using the Power Rule, we first multiply by the power, then second subtract 1 from the power. To find the antiderivative, do the opposite things in the opposite order: first add one to the power, then second divide by the power.\n\n\u00b7Note that Rule #14 incorporates the absolute value of  $\\mathbfit{x}$  . The exercises will work the reader through why this is the case; for now, know the absolute value is important and cannot be ignored.  \n\n# Initial Value Problems  \n\nIn Section 2.3, we saw that the derivative of a position function gave a velocity function, and the derivative of a velocity function describes acceleration. We can now go \"the other way\": the antiderivative of an acceleration function gives a velocity function, etc. While there is just one derivative of a given function, there are infinite antiderivatives. Therefore, we cannot ask \"what is the velocity of an object whose acceleration is $-32\\mathrm{ft}/s^{2}?\"$ since there is more than one answer.  \n\nWe can find the answer if we provide more information with the question, as done in the following example. Often, the additional information comes in the form of an initial value, a value of the function that one knows beforehand.  \n\n# Example 4.0.3: Solving initial value problems  \n\nThe acceleration due to gravity of a falling object is $-32\\;\\mathrm{ft}/\\mathrm{s}^{2}$ . At time $t=3$ , a falling object had a velocity of $-10$ ft/s. Find the equation of the object's velocity.  \n\n# Solution  \n\nWe want to know a velocity function, $v(t)$ . We know two things:  \n\n1. The acceleration, i.e., $v^{\\prime}(t)=-32$ , and 2. the velocity at a specific time, i.e., $v(3)=-10$  \n\nUsing the first piece of information, we know that $v(t)$ is an antiderivative of $v^{\\prime}(t)=-32$ . So we begin by finding the indefinite integral of $-32$  \n\n$$\n\\int(-32)\\;d t=-32t+C=v(t).\n$$  \n\nNow we use the fact that $v(3)=-10$ to find $C$  \n\n$$\n\\begin{array}{c}{v(t)=-32t+C}\\\\ {v(3)=-10}\\\\ {-32(3)+C=-10}\\\\ {C=86}\\end{array}\n$$  \n\nThus $v(t)=-32t+86$ . We can use this equation to understand the motion of the object: when $t=0$ , the object had a velocity of $86$ ft/s. Since the velocity is positive, the object was moving upward.  \n\nWhen did the object begin moving down? Immediately after $v(t)=0$.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Equation",
        "evidence_source": "equation",
        "evidence_context": "$$\\begin{array}{r l}{\\displaystyle \\int(3x^{2}+4x+5)\\,d x = \\int 3x^{2}\\,d x + \\int 4x\\ d x + \\int 5\\ d x} \\\\ {\\displaystyle}&{=3\\int x^{2}\\,d x+4\\int x\\ d x+\\int 5\\ d x} \\\\ {\\displaystyle}&{=3\\cdot {\\cfrac{1}{3}}\\,x^{3}+4\\cdot {\\cfrac{1}{2}}\\,x^{2}+5x+C} \\\\ {\\displaystyle}&{=x^{3}+2x^{2}+5x+C}\\end{array}$$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/math-4145.pdf_612",
        "ID": "0b374e56-77d4-487e-93a9-917ffd19757d",
        "questions": "What is the indefinite integral of the function $f(x) = 3x^2 + 4x + 5$ with respect to $x$?",
        "answers": "$x^{3}+2x^{2}+5x+C$",
        "context": "$$\n{\\begin{array}{r l}{\\displaystyle\\int(3x^{2}+4x+5)\\,d x\\ =\\int3x^{2}\\,d x+\\int4x\\ d x+\\int5\\ d x}\\\\ {\\displaystyle}&{=3\\int x^{2}\\,d x+4\\int x\\ d x+\\int5\\ d x}\\\\ {\\displaystyle}&{=3\\cdot{\\cfrac{1}{3}}\\,x^{3}+4\\cdot{\\cfrac{1}{2}}\\,x^{2}+5x+C}\\\\ {\\displaystyle}&{=x^{3}+2x^{2}+5x+C}\\end{array}}\n$$  \n\nIn practice, we generally do not write out all these steps, but we demonstrate them here for completeness.  \n\n\u00b7Rule #5 is the Power Rule of indefinite integration. There are two important things to keep in mind: $n\\neq-1$   $\\textstyle\\int{\\frac{1}{x}}\\ d x\\neq\\cdots{\\frac{1}{0}}x^{0}+C!$  2. We are presenting antidifferentiation as the \"inverse operation\" of differentiation. Here is a useful quote to remember: \"Inverse operations do the opposite things in the opposite order.\" When taking a derivative using the Power Rule, we first multiply by the power, then second subtract 1 from the power. To find the antiderivative, do the opposite things in the opposite order: first add one to the power, then second divide by the power.\n\n\u00b7Note that Rule #14 incorporates the absolute value of  $\\mathbfit{x}$  . The exercises will work the reader through why this is the case; for now, know the absolute value is important and cannot be ignored.  \n\n# Initial Value Problems  \n\nIn Section 2.3, we saw that the derivative of a position function gave a velocity function, and the derivative of a velocity function describes acceleration. We can now go \"the other way\": the antiderivative of an acceleration function gives a velocity function, etc. While there is just one derivative of a given function, there are infinite antiderivatives. Therefore, we cannot ask \"what is the velocity of an object whose acceleration is $-32\\mathrm{ft}/s^{2}?\"$ since there is more than one answer.  \n\nWe can find the answer if we provide more information with the question, as done in the following example. Often, the additional information comes in the form of an initial value, a value of the function that one knows beforehand.  \n\n# Example 4.0.3: Solving initial value problems  \n\nThe acceleration due to gravity of a falling object is $-32\\;\\mathrm{ft}/\\mathrm{s}^{2}$ . At time $t=3$ , a falling object had a velocity of $-10$ ft/s. Find the equation of the object's velocity.  \n\n# Solution  \n\nWe want to know a velocity function, $v(t)$ . We know two things:  \n\n1. The acceleration, i.e., $v^{\\prime}(t)=-32$ , and 2. the velocity at a specific time, i.e., $v(3)=-10$  \n\nUsing the first piece of information, we know that $v(t)$ is an antiderivative of $v^{\\prime}(t)=-32$ . So we begin by finding the indefinite integral of $-32$  \n\n$$\n\\int(-32)\\;d t=-32t+C=v(t).\n$$  \n\nNow we use the fact that $v(3)=-10$ to find $C$  \n\n$$\n\\begin{array}{c}{v(t)=-32t+C}\\\\ {v(3)=-10}\\\\ {-32(3)+C=-10}\\\\ {C=86}\\end{array}\n$$  \n\nThus $v(t)=-32t+86$ . We can use this equation to understand the motion of the object: when $t=0$ , the object had a velocity of $86$ ft/s. Since the velocity is positive, the object was moving upward.  \n\nWhen did the object begin moving down? Immediately after $v(t)=0$.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "${\\displaystyle}&{=x^{3}+2x^{2}+5x+C}$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/math-4145.pdf_612",
        "ID": "0b3cdb8a-0d10-4bc4-98f9-ae8d505f367e",
        "questions": "What is the value of $C$ in the velocity equation of a falling object with initial conditions given as $v(t) = -32t + C$ and $v(3) = -10$?",
        "answers": "$86$",
        "context": "$$\n{\\begin{array}{r l}{\\displaystyle\\int(3x^{2}+4x+5)\\,d x\\ =\\int3x^{2}\\,d x+\\int4x\\ d x+\\int5\\ d x}\\\\ {\\displaystyle}&{=3\\int x^{2}\\,d x+4\\int x\\ d x+\\int5\\ d x}\\\\ {\\displaystyle}&{=3\\cdot{\\cfrac{1}{3}}\\,x^{3}+4\\cdot{\\cfrac{1}{2}}\\,x^{2}+5x+C}\\\\ {\\displaystyle}&{=x^{3}+2x^{2}+5x+C}\\end{array}}\n$$  \n\nIn practice, we generally do not write out all these steps, but we demonstrate them here for completeness.  \n\n\u00b7Rule #5 is the Power Rule of indefinite integration. There are two important things to keep in mind: $n\\neq-1$   $\\textstyle\\int{\\frac{1}{x}}\\ d x\\neq\\cdots{\\frac{1}{0}}x^{0}+C!$  2. We are presenting antidifferentiation as the \"inverse operation\" of differentiation. Here is a useful quote to remember: \"Inverse operations do the opposite things in the opposite order.\" When taking a derivative using the Power Rule, we first multiply by the power, then second subtract 1 from the power. To find the antiderivative, do the opposite things in the opposite order: first add one to the power, then second divide by the power.\n\n\u00b7Note that Rule #14 incorporates the absolute value of  $\\mathbfit{x}$  . The exercises will work the reader through why this is the case; for now, know the absolute value is important and cannot be ignored.  \n\n# Initial Value Problems  \n\nIn Section 2.3, we saw that the derivative of a position function gave a velocity function, and the derivative of a velocity function describes acceleration. We can now go \"the other way\": the antiderivative of an acceleration function gives a velocity function, etc. While there is just one derivative of a given function, there are infinite antiderivatives. Therefore, we cannot ask \"what is the velocity of an object whose acceleration is $-32\\mathrm{ft}/s^{2}?\"$ since there is more than one answer.  \n\nWe can find the answer if we provide more information with the question, as done in the following example. Often, the additional information comes in the form of an initial value, a value of the function that one knows beforehand.  \n\n# Example 4.0.3: Solving initial value problems  \n\nThe acceleration due to gravity of a falling object is $-32\\;\\mathrm{ft}/\\mathrm{s}^{2}$ . At time $t=3$ , a falling object had a velocity of $-10$ ft/s. Find the equation of the object's velocity.  \n\n# Solution  \n\nWe want to know a velocity function, $v(t)$ . We know two things:  \n\n1. The acceleration, i.e., $v^{\\prime}(t)=-32$ , and 2. the velocity at a specific time, i.e., $v(3)=-10$  \n\nUsing the first piece of information, we know that $v(t)$ is an antiderivative of $v^{\\prime}(t)=-32$ . So we begin by finding the indefinite integral of $-32$  \n\n$$\n\\int(-32)\\;d t=-32t+C=v(t).\n$$  \n\nNow we use the fact that $v(3)=-10$ to find $C$  \n\n$$\n\\begin{array}{c}{v(t)=-32t+C}\\\\ {v(3)=-10}\\\\ {-32(3)+C=-10}\\\\ {C=86}\\end{array}\n$$  \n\nThus $v(t)=-32t+86$ . We can use this equation to understand the motion of the object: when $t=0$ , the object had a velocity of $86$ ft/s. Since the velocity is positive, the object was moving upward.  \n\nWhen did the object begin moving down? Immediately after $v(t)=0$.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Numeric",
        "evidence_source": "equation",
        "evidence_context": "{C=86}",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/math-4145.pdf_612",
        "ID": "0b489eb1-ef93-44f7-a8be-ec6fab8802d4",
        "questions": "How can you express the velocity function $v(t)$ of a falling object, given that $v'(t) = -32$ and knowing $v(3) = -10$?",
        "answers": "$v(t)=-32t+86$",
        "context": "$$\n{\\begin{array}{r l}{\\displaystyle\\int(3x^{2}+4x+5)\\,d x\\ =\\int3x^{2}\\,d x+\\int4x\\ d x+\\int5\\ d x}\\\\ {\\displaystyle}&{=3\\int x^{2}\\,d x+4\\int x\\ d x+\\int5\\ d x}\\\\ {\\displaystyle}&{=3\\cdot{\\cfrac{1}{3}}\\,x^{3}+4\\cdot{\\cfrac{1}{2}}\\,x^{2}+5x+C}\\\\ {\\displaystyle}&{=x^{3}+2x^{2}+5x+C}\\end{array}}\n$$  \n\nIn practice, we generally do not write out all these steps, but we demonstrate them here for completeness.  \n\n\u00b7Rule #5 is the Power Rule of indefinite integration. There are two important things to keep in mind: $n\\neq-1$   $\\textstyle\\int{\\frac{1}{x}}\\ d x\\neq\\cdots{\\frac{1}{0}}x^{0}+C!$  2. We are presenting antidifferentiation as the \"inverse operation\" of differentiation. Here is a useful quote to remember: \"Inverse operations do the opposite things in the opposite order.\" When taking a derivative using the Power Rule, we first multiply by the power, then second subtract 1 from the power. To find the antiderivative, do the opposite things in the opposite order: first add one to the power, then second divide by the power.\n\n\u00b7Note that Rule #14 incorporates the absolute value of  $\\mathbfit{x}$  . The exercises will work the reader through why this is the case; for now, know the absolute value is important and cannot be ignored.  \n\n# Initial Value Problems  \n\nIn Section 2.3, we saw that the derivative of a position function gave a velocity function, and the derivative of a velocity function describes acceleration. We can now go \"the other way\": the antiderivative of an acceleration function gives a velocity function, etc. While there is just one derivative of a given function, there are infinite antiderivatives. Therefore, we cannot ask \"what is the velocity of an object whose acceleration is $-32\\mathrm{ft}/s^{2}?\"$ since there is more than one answer.  \n\nWe can find the answer if we provide more information with the question, as done in the following example. Often, the additional information comes in the form of an initial value, a value of the function that one knows beforehand.  \n\n# Example 4.0.3: Solving initial value problems  \n\nThe acceleration due to gravity of a falling object is $-32\\;\\mathrm{ft}/\\mathrm{s}^{2}$ . At time $t=3$ , a falling object had a velocity of $-10$ ft/s. Find the equation of the object's velocity.  \n\n# Solution  \n\nWe want to know a velocity function, $v(t)$ . We know two things:  \n\n1. The acceleration, i.e., $v^{\\prime}(t)=-32$ , and 2. the velocity at a specific time, i.e., $v(3)=-10$  \n\nUsing the first piece of information, we know that $v(t)$ is an antiderivative of $v^{\\prime}(t)=-32$ . So we begin by finding the indefinite integral of $-32$  \n\n$$\n\\int(-32)\\;d t=-32t+C=v(t).\n$$  \n\nNow we use the fact that $v(3)=-10$ to find $C$  \n\n$$\n\\begin{array}{c}{v(t)=-32t+C}\\\\ {v(3)=-10}\\\\ {-32(3)+C=-10}\\\\ {C=86}\\end{array}\n$$  \n\nThus $v(t)=-32t+86$ . We can use this equation to understand the motion of the object: when $t=0$ , the object had a velocity of $86$ ft/s. Since the velocity is positive, the object was moving upward.  \n\nWhen did the object begin moving down? Immediately after $v(t)=0$.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Thus $v(t)=-32t+86$.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/hw1-3solution.pdf_5",
        "ID": "0b4cba0a-317e-4b1d-9b83-acd5e2ccddd8",
        "questions": "What rule is used in step 5 of the proof involving the hypotheses and steps 1 to 4?",
        "answers": "Modus tollens",
        "context": "5. $r$ Disjunctive Syllogism using Step 3 and 4\n\n6. $r\\rightarrow s$ Hypothesis\n\n7. $s$ Modus ponens using Step 5 and 6\n\n(2)\n\n$\n\\begin{tabular}{ll}\nStep & Reason \\\\\n1\\. $\\neg(\\neg p)=p$ & Hypothesis \\\\\n2\\. $p\\rightarrow q$ & Hypothesis \\\\\n3\\. $q$ & Modus ponens using Steps 1 and 2 \\\\\n4\\. $s\\to\\neg q$ & Hypothesis \\\\\n5\\. $\\neg s$ & Modus tollens using Steps 3 and 4 \\\\\n6\\. $r\\vee s$ & Hypothesis \\\\\n7\\. $r$ & Disjunctive Syllogism using Steps 5 and 6 \\\\\n8\\. $r\\to-q$ & Hypothesis \\\\\n9\\. $\\neg q$ & Modus ponens using Steps 7 and 8 \\\\\n10\\. $q\\wedge\\neg q\\Leftrightarrow F$ & Conjunction of steps 3 and 9\n\\end{tabular}\n$\n\n-Contradiction!\n\n# HOMEWORK3\n\n# P47-50\n\n9. Let $P(x)$ be the statement $x$ can speak Russian, and let $Q(x)$ be the statement $x$ knows the computer language $C^{++}$. Express each of the following sentences in terms of $P(x), Q(x)$, quantifiers, and logical connectives. For the universe of discourse for quantifiers, use the set of all students at your school.\n\na) There is a student at your school who can speak Russian and who knows $C^{++}$.  \nb)a) There is a student at your school who can speak Russian but who does not know $C^{++}$.  \nc) Every student at your school either can speak Russian or knows $C^{++}$.  \nd) No student at your school speaks Russian or knows $C^{++}$.\n\n$$\n\\begin{array}{l l}{Solution:a)\\quad\\exists x(P(x)\\land Q(x))}\\\\ {b)\\quad\\exists x(P(x)\\land\\neg Q(x))}\\\\ {c)\\quad\\forall x(P(x)\\lor Q(x))}\\\\ {d)\\quad\\forall x\\neg(P(x)\\lor Q(x))}\\end{array}\n$$\n\n62. Let $P(x), Q(x), R(x)$ and $S(x)$ be the statements \"$x$ is a duck,\" \"$x$ is one of my poultry.\" \"$x$ is an officer,\u201d and \"$x$ is willing to waltz,\" respectively. Express the following statements using quantifiers; logical connectives; and $P(x), Q(x), R(x)$ and $S(x)$.\n\na) No ducks are willing to waltz.  \nb) No officers ever decline to waltz.  \nc) All my poultry are ducks.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "5. $\\neg s$ & Modus tollens using Steps 3 and 4",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/hw1-3solution.pdf_5",
        "ID": "0b5846c8-79e3-4aa0-a223-8f5548e422fd",
        "questions": "According to the homework solution, how can the statement 'There is a student at your school who can speak Russian but who does not know C++' be expressed using logical quantifiers and connectives?",
        "answers": "$\\exists x(P(x)\\land\\neg Q(x))$",
        "context": "5. $r$ Disjunctive Syllogism using Step 3 and 4\n\n6. $r\\rightarrow s$ Hypothesis\n\n7. $s$ Modus ponens using Step 5 and 6\n\n(2)\n\n$\n\\begin{tabular}{ll}\nStep & Reason \\\\\n1\\. $\\neg(\\neg p)=p$ & Hypothesis \\\\\n2\\. $p\\rightarrow q$ & Hypothesis \\\\\n3\\. $q$ & Modus ponens using Steps 1 and 2 \\\\\n4\\. $s\\to\\neg q$ & Hypothesis \\\\\n5\\. $\\neg s$ & Modus tollens using Steps 3 and 4 \\\\\n6\\. $r\\vee s$ & Hypothesis \\\\\n7\\. $r$ & Disjunctive Syllogism using Steps 5 and 6 \\\\\n8\\. $r\\to-q$ & Hypothesis \\\\\n9\\. $\\neg q$ & Modus ponens using Steps 7 and 8 \\\\\n10\\. $q\\wedge\\neg q\\Leftrightarrow F$ & Conjunction of steps 3 and 9\n\\end{tabular}\n$\n\n-Contradiction!\n\n# HOMEWORK3\n\n# P47-50\n\n9. Let $P(x)$ be the statement $x$ can speak Russian, and let $Q(x)$ be the statement $x$ knows the computer language $C^{++}$. Express each of the following sentences in terms of $P(x), Q(x)$, quantifiers, and logical connectives. For the universe of discourse for quantifiers, use the set of all students at your school.\n\na) There is a student at your school who can speak Russian and who knows $C^{++}$.  \nb)a) There is a student at your school who can speak Russian but who does not know $C^{++}$.  \nc) Every student at your school either can speak Russian or knows $C^{++}$.  \nd) No student at your school speaks Russian or knows $C^{++}$.\n\n$$\n\\begin{array}{l l}{Solution:a)\\quad\\exists x(P(x)\\land Q(x))}\\\\ {b)\\quad\\exists x(P(x)\\land\\neg Q(x))}\\\\ {c)\\quad\\forall x(P(x)\\lor Q(x))}\\\\ {d)\\quad\\forall x\\neg(P(x)\\lor Q(x))}\\end{array}\n$$\n\n62. Let $P(x), Q(x), R(x)$ and $S(x)$ be the statements \"$x$ is a duck,\" \"$x$ is one of my poultry.\" \"$x$ is an officer,\u201d and \"$x$ is willing to waltz,\" respectively. Express the following statements using quantifiers; logical connectives; and $P(x), Q(x), R(x)$ and $S(x)$.\n\na) No ducks are willing to waltz.  \nb) No officers ever decline to waltz.  \nc) All my poultry are ducks.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "b) $\\exists x(P(x)\\land\\neg Q(x))$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/hw1-3solution.pdf_5",
        "ID": "0b652dbd-a7e3-4bc5-8ef9-e157e439d480",
        "questions": "In the set of logical steps provided, what contradiction is illustrated by the conjunction of steps 3 and 9?",
        "answers": "$q\\wedge\\neg q\\Leftrightarrow F$",
        "context": "5. $r$ Disjunctive Syllogism using Step 3 and 4\n\n6. $r\\rightarrow s$ Hypothesis\n\n7. $s$ Modus ponens using Step 5 and 6\n\n(2)\n\n$\n\\begin{tabular}{ll}\nStep & Reason \\\\\n1\\. $\\neg(\\neg p)=p$ & Hypothesis \\\\\n2\\. $p\\rightarrow q$ & Hypothesis \\\\\n3\\. $q$ & Modus ponens using Steps 1 and 2 \\\\\n4\\. $s\\to\\neg q$ & Hypothesis \\\\\n5\\. $\\neg s$ & Modus tollens using Steps 3 and 4 \\\\\n6\\. $r\\vee s$ & Hypothesis \\\\\n7\\. $r$ & Disjunctive Syllogism using Steps 5 and 6 \\\\\n8\\. $r\\to-q$ & Hypothesis \\\\\n9\\. $\\neg q$ & Modus ponens using Steps 7 and 8 \\\\\n10\\. $q\\wedge\\neg q\\Leftrightarrow F$ & Conjunction of steps 3 and 9\n\\end{tabular}\n$\n\n-Contradiction!\n\n# HOMEWORK3\n\n# P47-50\n\n9. Let $P(x)$ be the statement $x$ can speak Russian, and let $Q(x)$ be the statement $x$ knows the computer language $C^{++}$. Express each of the following sentences in terms of $P(x), Q(x)$, quantifiers, and logical connectives. For the universe of discourse for quantifiers, use the set of all students at your school.\n\na) There is a student at your school who can speak Russian and who knows $C^{++}$.  \nb)a) There is a student at your school who can speak Russian but who does not know $C^{++}$.  \nc) Every student at your school either can speak Russian or knows $C^{++}$.  \nd) No student at your school speaks Russian or knows $C^{++}$.\n\n$$\n\\begin{array}{l l}{Solution:a)\\quad\\exists x(P(x)\\land Q(x))}\\\\ {b)\\quad\\exists x(P(x)\\land\\neg Q(x))}\\\\ {c)\\quad\\forall x(P(x)\\lor Q(x))}\\\\ {d)\\quad\\forall x\\neg(P(x)\\lor Q(x))}\\end{array}\n$$\n\n62. Let $P(x), Q(x), R(x)$ and $S(x)$ be the statements \"$x$ is a duck,\" \"$x$ is one of my poultry.\" \"$x$ is an officer,\u201d and \"$x$ is willing to waltz,\" respectively. Express the following statements using quantifiers; logical connectives; and $P(x), Q(x), R(x)$ and $S(x)$.\n\na) No ducks are willing to waltz.  \nb) No officers ever decline to waltz.  \nc) All my poultry are ducks.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "10. $q\\wedge\\neg q\\Leftrightarrow F$ & Conjunction of steps 3 and 9",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/hw1-3solution.pdf_5",
        "ID": "0b6ccca2-c907-4f5d-8a8f-08658fc929bd",
        "questions": "Which type of logical rule is used in the step that derives $\neg s$ from the steps $q$ and $s\to\neg q$ in the given proof?",
        "answers": "Modus tollens",
        "context": "5. $r$ Disjunctive Syllogism using Step 3 and 4\n\n6. $r\\rightarrow s$ Hypothesis\n\n7. $s$ Modus ponens using Step 5 and 6\n\n(2)\n\n$\n\\begin{tabular}{ll}\nStep & Reason \\\\\n1\\. $\\neg(\\neg p)=p$ & Hypothesis \\\\\n2\\. $p\\rightarrow q$ & Hypothesis \\\\\n3\\. $q$ & Modus ponens using Steps 1 and 2 \\\\\n4\\. $s\\to\\neg q$ & Hypothesis \\\\\n5\\. $\\neg s$ & Modus tollens using Steps 3 and 4 \\\\\n6\\. $r\\vee s$ & Hypothesis \\\\\n7\\. $r$ & Disjunctive Syllogism using Steps 5 and 6 \\\\\n8\\. $r\\to-q$ & Hypothesis \\\\\n9\\. $\\neg q$ & Modus ponens using Steps 7 and 8 \\\\\n10\\. $q\\wedge\\neg q\\Leftrightarrow F$ & Conjunction of steps 3 and 9\n\\end{tabular}\n$\n\n-Contradiction!\n\n# HOMEWORK3\n\n# P47-50\n\n9. Let $P(x)$ be the statement $x$ can speak Russian, and let $Q(x)$ be the statement $x$ knows the computer language $C^{++}$. Express each of the following sentences in terms of $P(x), Q(x)$, quantifiers, and logical connectives. For the universe of discourse for quantifiers, use the set of all students at your school.\n\na) There is a student at your school who can speak Russian and who knows $C^{++}$.  \nb)a) There is a student at your school who can speak Russian but who does not know $C^{++}$.  \nc) Every student at your school either can speak Russian or knows $C^{++}$.  \nd) No student at your school speaks Russian or knows $C^{++}$.\n\n$$\n\\begin{array}{l l}{Solution:a)\\quad\\exists x(P(x)\\land Q(x))}\\\\ {b)\\quad\\exists x(P(x)\\land\\neg Q(x))}\\\\ {c)\\quad\\forall x(P(x)\\lor Q(x))}\\\\ {d)\\quad\\forall x\\neg(P(x)\\lor Q(x))}\\end{array}\n$$\n\n62. Let $P(x), Q(x), R(x)$ and $S(x)$ be the statements \"$x$ is a duck,\" \"$x$ is one of my poultry.\" \"$x$ is an officer,\u201d and \"$x$ is willing to waltz,\" respectively. Express the following statements using quantifiers; logical connectives; and $P(x), Q(x), R(x)$ and $S(x)$.\n\na) No ducks are willing to waltz.  \nb) No officers ever decline to waltz.  \nc) All my poultry are ducks.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "5. $\neg s$ & Modus tollens using Steps 3 and 4",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/hw1-3solution.pdf_5",
        "ID": "0b738648-f0eb-4870-ae0b-e868e5a9ff7e",
        "questions": "How is the statement 'Every student at your school either can speak Russian or knows $C^{++}$' expressed using P(x), Q(x), quantifiers, and logical connectives?",
        "answers": "$\forall x(P(x)\\lor Q(x))$",
        "context": "5. $r$ Disjunctive Syllogism using Step 3 and 4\n\n6. $r\\rightarrow s$ Hypothesis\n\n7. $s$ Modus ponens using Step 5 and 6\n\n(2)\n\n$\n\\begin{tabular}{ll}\nStep & Reason \\\\\n1\\. $\\neg(\\neg p)=p$ & Hypothesis \\\\\n2\\. $p\\rightarrow q$ & Hypothesis \\\\\n3\\. $q$ & Modus ponens using Steps 1 and 2 \\\\\n4\\. $s\\to\\neg q$ & Hypothesis \\\\\n5\\. $\\neg s$ & Modus tollens using Steps 3 and 4 \\\\\n6\\. $r\\vee s$ & Hypothesis \\\\\n7\\. $r$ & Disjunctive Syllogism using Steps 5 and 6 \\\\\n8\\. $r\\to-q$ & Hypothesis \\\\\n9\\. $\\neg q$ & Modus ponens using Steps 7 and 8 \\\\\n10\\. $q\\wedge\\neg q\\Leftrightarrow F$ & Conjunction of steps 3 and 9\n\\end{tabular}\n$\n\n-Contradiction!\n\n# HOMEWORK3\n\n# P47-50\n\n9. Let $P(x)$ be the statement $x$ can speak Russian, and let $Q(x)$ be the statement $x$ knows the computer language $C^{++}$. Express each of the following sentences in terms of $P(x), Q(x)$, quantifiers, and logical connectives. For the universe of discourse for quantifiers, use the set of all students at your school.\n\na) There is a student at your school who can speak Russian and who knows $C^{++}$.  \nb)a) There is a student at your school who can speak Russian but who does not know $C^{++}$.  \nc) Every student at your school either can speak Russian or knows $C^{++}$.  \nd) No student at your school speaks Russian or knows $C^{++}$.\n\n$$\n\\begin{array}{l l}{Solution:a)\\quad\\exists x(P(x)\\land Q(x))}\\\\ {b)\\quad\\exists x(P(x)\\land\\neg Q(x))}\\\\ {c)\\quad\\forall x(P(x)\\lor Q(x))}\\\\ {d)\\quad\\forall x\\neg(P(x)\\lor Q(x))}\\end{array}\n$$\n\n62. Let $P(x), Q(x), R(x)$ and $S(x)$ be the statements \"$x$ is a duck,\" \"$x$ is one of my poultry.\" \"$x$ is an officer,\u201d and \"$x$ is willing to waltz,\" respectively. Express the following statements using quantifiers; logical connectives; and $P(x), Q(x), R(x)$ and $S(x)$.\n\na) No ducks are willing to waltz.  \nb) No officers ever decline to waltz.  \nc) All my poultry are ducks.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$\begin{array}{l l}{Solution:a)\\quad\\exists x (P(x) \\land Q(x))}\\{b)\\quad \\exists x (P(x) \\land \neg Q(x))}\\{c)\\quad \forall x (P(x) \\lor Q(x))}\\{d)\\quad \forall x \neg (P(x) \\lor Q(x))}\\end{array}$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/hw1-3solution.pdf_5",
        "ID": "0b7fc161-8c1d-46b2-8e33-4a4986cdf496",
        "questions": "What contradiction is shown at the end of the logical proof, and what steps are used to derive it?",
        "answers": "$q \\wedge \neg q \\Leftrightarrow F$ is derived by the conjunction of steps 3 and 9.",
        "context": "5. $r$ Disjunctive Syllogism using Step 3 and 4\n\n6. $r\\rightarrow s$ Hypothesis\n\n7. $s$ Modus ponens using Step 5 and 6\n\n(2)\n\n$\n\\begin{tabular}{ll}\nStep & Reason \\\\\n1\\. $\\neg(\\neg p)=p$ & Hypothesis \\\\\n2\\. $p\\rightarrow q$ & Hypothesis \\\\\n3\\. $q$ & Modus ponens using Steps 1 and 2 \\\\\n4\\. $s\\to\\neg q$ & Hypothesis \\\\\n5\\. $\\neg s$ & Modus tollens using Steps 3 and 4 \\\\\n6\\. $r\\vee s$ & Hypothesis \\\\\n7\\. $r$ & Disjunctive Syllogism using Steps 5 and 6 \\\\\n8\\. $r\\to-q$ & Hypothesis \\\\\n9\\. $\\neg q$ & Modus ponens using Steps 7 and 8 \\\\\n10\\. $q\\wedge\\neg q\\Leftrightarrow F$ & Conjunction of steps 3 and 9\n\\end{tabular}\n$\n\n-Contradiction!\n\n# HOMEWORK3\n\n# P47-50\n\n9. Let $P(x)$ be the statement $x$ can speak Russian, and let $Q(x)$ be the statement $x$ knows the computer language $C^{++}$. Express each of the following sentences in terms of $P(x), Q(x)$, quantifiers, and logical connectives. For the universe of discourse for quantifiers, use the set of all students at your school.\n\na) There is a student at your school who can speak Russian and who knows $C^{++}$.  \nb)a) There is a student at your school who can speak Russian but who does not know $C^{++}$.  \nc) Every student at your school either can speak Russian or knows $C^{++}$.  \nd) No student at your school speaks Russian or knows $C^{++}$.\n\n$$\n\\begin{array}{l l}{Solution:a)\\quad\\exists x(P(x)\\land Q(x))}\\\\ {b)\\quad\\exists x(P(x)\\land\\neg Q(x))}\\\\ {c)\\quad\\forall x(P(x)\\lor Q(x))}\\\\ {d)\\quad\\forall x\\neg(P(x)\\lor Q(x))}\\end{array}\n$$\n\n62. Let $P(x), Q(x), R(x)$ and $S(x)$ be the statements \"$x$ is a duck,\" \"$x$ is one of my poultry.\" \"$x$ is an officer,\u201d and \"$x$ is willing to waltz,\" respectively. Express the following statements using quantifiers; logical connectives; and $P(x), Q(x), R(x)$ and $S(x)$.\n\na) No ducks are willing to waltz.  \nb) No officers ever decline to waltz.  \nc) All my poultry are ducks.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "10\\. $q\\wedge\neg q\\Leftrightarrow F$ & Conjunction of steps 3 and 9",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/2_Intermediate_Counting_and_Probability_(the_essential_parts).pdf_187",
        "ID": "0b7ffede-c676-4324-b95c-e894fdeb26ef",
        "questions": "What is the value of the Fibonacci number for 10 stairs in the sequence described in the document?",
        "answers": "89",
        "context": "Now we can count the number of ways to climb larger staircases.\n\n$$\n\\begin{array}{r c r c l}{f(3)}&{=}&{f(2)+f(1)}&{=}&{2+1}&{=}&{3,}\\\\ {f(4)}&{=}&{f(3)+f(2)}&{=}&{3+2}&{=}&{5,}\\\\ {f(5)}&{=}&{f(4)+f(3)}&{=}&{5+3}&{=}&{8,}\\\\ {f(6)}&{=}&{f(5)+f(4)}&{=}&{8+5}&{=}&{13,}\\\\ {f(7)}&{=}&{f(6)+f(5)}&{=}&{13+8}&{=}&{21,}\\\\ {f(8)}&{=}&{f(7)+f(6)}&{=}&{21+13}&{=}&{34,}\\\\ {f(9)}&{=}&{f(8)+f(7)}&{=}&{34+21}&{=}&{55,}\\\\ {f(10)}&{=}&{f(9)+f(8)}&{=}&{55+34}&{=}&{89.}\\end{array}\n$$\n\nOnce again, we see that there are 89 ways to climb a 10-stair staircase.\n\nIf we list $f(1), f(2), f(3), \\ldots,$ then we (almost) get the sequence that opened this chapter:\n\n$$\n1, 2, 3, 5, 8, 13, 21, 34, 55, 89, \\ldots\n$$\n\nEach number in the sequence (after the first two) is the sum of the two numbers immediately before it: $2 = 1 + 1, 3 = 2 + 1, 5 = 3 + 2,$ and so on.\n\nThe only thing that's different from the sequence on page 172 is that the sequence on page 172 has an extra 1 at the start. We can add this 1 to our example, though, without any difficulty. If there are 0 stairs, then there's only 1 way to climb this staircase: do nothing! So $f(0) = 1$ makes sense. Also note that $f(2) = f(1) + f(0) = 1 + 1 = 2,$ so that our equation $f(n) = f(n-1) + f(n-2)$ holds for all positive integers $n \\geq 2$.\n\nWhen we add this first 1 to our sequence, we get the sequence that we first saw at the start of the chapter:\n\n$$\n1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, \\ldots\n$$\n\nThese numbers are called the Fibonacci numbers, in honor of the Italian mathematician Leonardo of Pisa, whose nickname was \"Fibonacci,\" and who first published the sequence of numbers in his Liber abaci in 1202.\n\nWe've seen that each Fibonacci number is the sum of the previous two Fibonacci numbers. We can write this using a more formal definition.\n\nWe typically denote sequences using a variable with a subscript, such as\n\n$$\na_{1}, a_{2}, a_{3}, \\dotsc.\n$$\n\nThus, $a_{1}$ is the first number in the sequence, $a_{2}$ is the second number in the sequence, and so on. Sometimes we'll start our lists with $a_{0}$ instead of $a_{1},$ so that our sequence would be\n\n$$\na_{0}, a_{1}, a_{2}, \\ldots.\n$$\n\nThe Fibonacci numbers are defined by $F_{1} = 1, F_{2} = 1,$ and $F_{n} = F_{n-1} + F_{n-2}$ for all positive integers $n > 2.$ So, for example,",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Numeric",
        "evidence_source": "text",
        "evidence_context": "Once again, we see that there are 89 ways to climb a 10-stair staircase.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/2_Intermediate_Counting_and_Probability_(the_essential_parts).pdf_187",
        "ID": "0b83a6e8-fef5-4551-87a9-51855166465b",
        "questions": "Who was the Italian mathematician that first published the sequence of numbers known as Fibonacci numbers in the Liber abaci in 1202?",
        "answers": "Leonardo of Pisa",
        "context": "Now we can count the number of ways to climb larger staircases.\n\n$$\n\\begin{array}{r c r c l}{f(3)}&{=}&{f(2)+f(1)}&{=}&{2+1}&{=}&{3,}\\\\ {f(4)}&{=}&{f(3)+f(2)}&{=}&{3+2}&{=}&{5,}\\\\ {f(5)}&{=}&{f(4)+f(3)}&{=}&{5+3}&{=}&{8,}\\\\ {f(6)}&{=}&{f(5)+f(4)}&{=}&{8+5}&{=}&{13,}\\\\ {f(7)}&{=}&{f(6)+f(5)}&{=}&{13+8}&{=}&{21,}\\\\ {f(8)}&{=}&{f(7)+f(6)}&{=}&{21+13}&{=}&{34,}\\\\ {f(9)}&{=}&{f(8)+f(7)}&{=}&{34+21}&{=}&{55,}\\\\ {f(10)}&{=}&{f(9)+f(8)}&{=}&{55+34}&{=}&{89.}\\end{array}\n$$\n\nOnce again, we see that there are 89 ways to climb a 10-stair staircase.\n\nIf we list $f(1), f(2), f(3), \\ldots,$ then we (almost) get the sequence that opened this chapter:\n\n$$\n1, 2, 3, 5, 8, 13, 21, 34, 55, 89, \\ldots\n$$\n\nEach number in the sequence (after the first two) is the sum of the two numbers immediately before it: $2 = 1 + 1, 3 = 2 + 1, 5 = 3 + 2,$ and so on.\n\nThe only thing that's different from the sequence on page 172 is that the sequence on page 172 has an extra 1 at the start. We can add this 1 to our example, though, without any difficulty. If there are 0 stairs, then there's only 1 way to climb this staircase: do nothing! So $f(0) = 1$ makes sense. Also note that $f(2) = f(1) + f(0) = 1 + 1 = 2,$ so that our equation $f(n) = f(n-1) + f(n-2)$ holds for all positive integers $n \\geq 2$.\n\nWhen we add this first 1 to our sequence, we get the sequence that we first saw at the start of the chapter:\n\n$$\n1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, \\ldots\n$$\n\nThese numbers are called the Fibonacci numbers, in honor of the Italian mathematician Leonardo of Pisa, whose nickname was \"Fibonacci,\" and who first published the sequence of numbers in his Liber abaci in 1202.\n\nWe've seen that each Fibonacci number is the sum of the previous two Fibonacci numbers. We can write this using a more formal definition.\n\nWe typically denote sequences using a variable with a subscript, such as\n\n$$\na_{1}, a_{2}, a_{3}, \\dotsc.\n$$\n\nThus, $a_{1}$ is the first number in the sequence, $a_{2}$ is the second number in the sequence, and so on. Sometimes we'll start our lists with $a_{0}$ instead of $a_{1},$ so that our sequence would be\n\n$$\na_{0}, a_{1}, a_{2}, \\ldots.\n$$\n\nThe Fibonacci numbers are defined by $F_{1} = 1, F_{2} = 1,$ and $F_{n} = F_{n-1} + F_{n-2}$ for all positive integers $n > 2.$ So, for example,",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "These numbers are called the Fibonacci numbers, in honor of the Italian mathematician Leonardo of Pisa, whose nickname was \"Fibonacci,\" and who first published the sequence of numbers in his Liber abaci in 1202.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/2_Intermediate_Counting_and_Probability_(the_essential_parts).pdf_187",
        "ID": "0b96eda5-e737-4ad2-97c6-dbbc77222ef6",
        "questions": "Is the equation $f(n) = f(n-1) + f(n-2)$ valid for non-positive integers according to the document?",
        "answers": "No",
        "context": "Now we can count the number of ways to climb larger staircases.\n\n$$\n\\begin{array}{r c r c l}{f(3)}&{=}&{f(2)+f(1)}&{=}&{2+1}&{=}&{3,}\\\\ {f(4)}&{=}&{f(3)+f(2)}&{=}&{3+2}&{=}&{5,}\\\\ {f(5)}&{=}&{f(4)+f(3)}&{=}&{5+3}&{=}&{8,}\\\\ {f(6)}&{=}&{f(5)+f(4)}&{=}&{8+5}&{=}&{13,}\\\\ {f(7)}&{=}&{f(6)+f(5)}&{=}&{13+8}&{=}&{21,}\\\\ {f(8)}&{=}&{f(7)+f(6)}&{=}&{21+13}&{=}&{34,}\\\\ {f(9)}&{=}&{f(8)+f(7)}&{=}&{34+21}&{=}&{55,}\\\\ {f(10)}&{=}&{f(9)+f(8)}&{=}&{55+34}&{=}&{89.}\\end{array}\n$$\n\nOnce again, we see that there are 89 ways to climb a 10-stair staircase.\n\nIf we list $f(1), f(2), f(3), \\ldots,$ then we (almost) get the sequence that opened this chapter:\n\n$$\n1, 2, 3, 5, 8, 13, 21, 34, 55, 89, \\ldots\n$$\n\nEach number in the sequence (after the first two) is the sum of the two numbers immediately before it: $2 = 1 + 1, 3 = 2 + 1, 5 = 3 + 2,$ and so on.\n\nThe only thing that's different from the sequence on page 172 is that the sequence on page 172 has an extra 1 at the start. We can add this 1 to our example, though, without any difficulty. If there are 0 stairs, then there's only 1 way to climb this staircase: do nothing! So $f(0) = 1$ makes sense. Also note that $f(2) = f(1) + f(0) = 1 + 1 = 2,$ so that our equation $f(n) = f(n-1) + f(n-2)$ holds for all positive integers $n \\geq 2$.\n\nWhen we add this first 1 to our sequence, we get the sequence that we first saw at the start of the chapter:\n\n$$\n1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, \\ldots\n$$\n\nThese numbers are called the Fibonacci numbers, in honor of the Italian mathematician Leonardo of Pisa, whose nickname was \"Fibonacci,\" and who first published the sequence of numbers in his Liber abaci in 1202.\n\nWe've seen that each Fibonacci number is the sum of the previous two Fibonacci numbers. We can write this using a more formal definition.\n\nWe typically denote sequences using a variable with a subscript, such as\n\n$$\na_{1}, a_{2}, a_{3}, \\dotsc.\n$$\n\nThus, $a_{1}$ is the first number in the sequence, $a_{2}$ is the second number in the sequence, and so on. Sometimes we'll start our lists with $a_{0}$ instead of $a_{1},$ so that our sequence would be\n\n$$\na_{0}, a_{1}, a_{2}, \\ldots.\n$$\n\nThe Fibonacci numbers are defined by $F_{1} = 1, F_{2} = 1,$ and $F_{n} = F_{n-1} + F_{n-2}$ for all positive integers $n > 2.$ So, for example,",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Yes/No",
        "evidence_source": "equation",
        "evidence_context": "Also note that $f(2) = f(1) + f(0) = 1 + 1 = 2,$ so that our equation $f(n) = f(n-1) + f(n-2)$ holds for all positive integers $n \\geq 2$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/2_Intermediate_Counting_and_Probability_(the_essential_parts).pdf_187",
        "ID": "0b972d0f-2059-4d20-a66e-d3eeb37f54c5",
        "questions": "How many ways are there to climb a 9-stair staircase, as per the sequence defined in the document?",
        "answers": "55",
        "context": "Now we can count the number of ways to climb larger staircases.\n\n$$\n\\begin{array}{r c r c l}{f(3)}&{=}&{f(2)+f(1)}&{=}&{2+1}&{=}&{3,}\\\\ {f(4)}&{=}&{f(3)+f(2)}&{=}&{3+2}&{=}&{5,}\\\\ {f(5)}&{=}&{f(4)+f(3)}&{=}&{5+3}&{=}&{8,}\\\\ {f(6)}&{=}&{f(5)+f(4)}&{=}&{8+5}&{=}&{13,}\\\\ {f(7)}&{=}&{f(6)+f(5)}&{=}&{13+8}&{=}&{21,}\\\\ {f(8)}&{=}&{f(7)+f(6)}&{=}&{21+13}&{=}&{34,}\\\\ {f(9)}&{=}&{f(8)+f(7)}&{=}&{34+21}&{=}&{55,}\\\\ {f(10)}&{=}&{f(9)+f(8)}&{=}&{55+34}&{=}&{89.}\\end{array}\n$$\n\nOnce again, we see that there are 89 ways to climb a 10-stair staircase.\n\nIf we list $f(1), f(2), f(3), \\ldots,$ then we (almost) get the sequence that opened this chapter:\n\n$$\n1, 2, 3, 5, 8, 13, 21, 34, 55, 89, \\ldots\n$$\n\nEach number in the sequence (after the first two) is the sum of the two numbers immediately before it: $2 = 1 + 1, 3 = 2 + 1, 5 = 3 + 2,$ and so on.\n\nThe only thing that's different from the sequence on page 172 is that the sequence on page 172 has an extra 1 at the start. We can add this 1 to our example, though, without any difficulty. If there are 0 stairs, then there's only 1 way to climb this staircase: do nothing! So $f(0) = 1$ makes sense. Also note that $f(2) = f(1) + f(0) = 1 + 1 = 2,$ so that our equation $f(n) = f(n-1) + f(n-2)$ holds for all positive integers $n \\geq 2$.\n\nWhen we add this first 1 to our sequence, we get the sequence that we first saw at the start of the chapter:\n\n$$\n1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, \\ldots\n$$\n\nThese numbers are called the Fibonacci numbers, in honor of the Italian mathematician Leonardo of Pisa, whose nickname was \"Fibonacci,\" and who first published the sequence of numbers in his Liber abaci in 1202.\n\nWe've seen that each Fibonacci number is the sum of the previous two Fibonacci numbers. We can write this using a more formal definition.\n\nWe typically denote sequences using a variable with a subscript, such as\n\n$$\na_{1}, a_{2}, a_{3}, \\dotsc.\n$$\n\nThus, $a_{1}$ is the first number in the sequence, $a_{2}$ is the second number in the sequence, and so on. Sometimes we'll start our lists with $a_{0}$ instead of $a_{1},$ so that our sequence would be\n\n$$\na_{0}, a_{1}, a_{2}, \\ldots.\n$$\n\nThe Fibonacci numbers are defined by $F_{1} = 1, F_{2} = 1,$ and $F_{n} = F_{n-1} + F_{n-2}$ for all positive integers $n > 2.$ So, for example,",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Numeric",
        "evidence_source": "equation",
        "evidence_context": "{f(9)}&{=}&{f(8)+f(7)}&{=}&{34+21}&{=}&{55,}",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/2_Intermediate_Counting_and_Probability_(the_essential_parts).pdf_187",
        "ID": "0b9b6968-9aa7-4bee-bdbb-adafa758fa63",
        "questions": "What is the equation for calculating the number of ways to climb a 4-stair staircase using the sequence defined?",
        "answers": "{f(4)}&{=}&{f(3)+f(2)}&{=}&{3+2}&{=}&{5,}",
        "context": "Now we can count the number of ways to climb larger staircases.\n\n$$\n\\begin{array}{r c r c l}{f(3)}&{=}&{f(2)+f(1)}&{=}&{2+1}&{=}&{3,}\\\\ {f(4)}&{=}&{f(3)+f(2)}&{=}&{3+2}&{=}&{5,}\\\\ {f(5)}&{=}&{f(4)+f(3)}&{=}&{5+3}&{=}&{8,}\\\\ {f(6)}&{=}&{f(5)+f(4)}&{=}&{8+5}&{=}&{13,}\\\\ {f(7)}&{=}&{f(6)+f(5)}&{=}&{13+8}&{=}&{21,}\\\\ {f(8)}&{=}&{f(7)+f(6)}&{=}&{21+13}&{=}&{34,}\\\\ {f(9)}&{=}&{f(8)+f(7)}&{=}&{34+21}&{=}&{55,}\\\\ {f(10)}&{=}&{f(9)+f(8)}&{=}&{55+34}&{=}&{89.}\\end{array}\n$$\n\nOnce again, we see that there are 89 ways to climb a 10-stair staircase.\n\nIf we list $f(1), f(2), f(3), \\ldots,$ then we (almost) get the sequence that opened this chapter:\n\n$$\n1, 2, 3, 5, 8, 13, 21, 34, 55, 89, \\ldots\n$$\n\nEach number in the sequence (after the first two) is the sum of the two numbers immediately before it: $2 = 1 + 1, 3 = 2 + 1, 5 = 3 + 2,$ and so on.\n\nThe only thing that's different from the sequence on page 172 is that the sequence on page 172 has an extra 1 at the start. We can add this 1 to our example, though, without any difficulty. If there are 0 stairs, then there's only 1 way to climb this staircase: do nothing! So $f(0) = 1$ makes sense. Also note that $f(2) = f(1) + f(0) = 1 + 1 = 2,$ so that our equation $f(n) = f(n-1) + f(n-2)$ holds for all positive integers $n \\geq 2$.\n\nWhen we add this first 1 to our sequence, we get the sequence that we first saw at the start of the chapter:\n\n$$\n1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, \\ldots\n$$\n\nThese numbers are called the Fibonacci numbers, in honor of the Italian mathematician Leonardo of Pisa, whose nickname was \"Fibonacci,\" and who first published the sequence of numbers in his Liber abaci in 1202.\n\nWe've seen that each Fibonacci number is the sum of the previous two Fibonacci numbers. We can write this using a more formal definition.\n\nWe typically denote sequences using a variable with a subscript, such as\n\n$$\na_{1}, a_{2}, a_{3}, \\dotsc.\n$$\n\nThus, $a_{1}$ is the first number in the sequence, $a_{2}$ is the second number in the sequence, and so on. Sometimes we'll start our lists with $a_{0}$ instead of $a_{1},$ so that our sequence would be\n\n$$\na_{0}, a_{1}, a_{2}, \\ldots.\n$$\n\nThe Fibonacci numbers are defined by $F_{1} = 1, F_{2} = 1,$ and $F_{n} = F_{n-1} + F_{n-2}$ for all positive integers $n > 2.$ So, for example,",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "{f(4)}&{=}&{f(3)+f(2)}&{=}&{3+2}&{=}&{5,}",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/2_Intermediate_Counting_and_Probability_(the_essential_parts).pdf_187",
        "ID": "0b9d7787-83cb-49e1-b964-9935cbe13ee9",
        "questions": "What is the recursive definition of Fibonacci numbers provided, including the specific values for the first two numbers?",
        "answers": "The Fibonacci numbers are defined by $F_{1} = 1, F_{2} = 1,$ and $F_{n} = F_{n-1} + F_{n-2}$ for all positive integers $n > 2.$",
        "context": "Now we can count the number of ways to climb larger staircases.\n\n$$\n\\begin{array}{r c r c l}{f(3)}&{=}&{f(2)+f(1)}&{=}&{2+1}&{=}&{3,}\\\\ {f(4)}&{=}&{f(3)+f(2)}&{=}&{3+2}&{=}&{5,}\\\\ {f(5)}&{=}&{f(4)+f(3)}&{=}&{5+3}&{=}&{8,}\\\\ {f(6)}&{=}&{f(5)+f(4)}&{=}&{8+5}&{=}&{13,}\\\\ {f(7)}&{=}&{f(6)+f(5)}&{=}&{13+8}&{=}&{21,}\\\\ {f(8)}&{=}&{f(7)+f(6)}&{=}&{21+13}&{=}&{34,}\\\\ {f(9)}&{=}&{f(8)+f(7)}&{=}&{34+21}&{=}&{55,}\\\\ {f(10)}&{=}&{f(9)+f(8)}&{=}&{55+34}&{=}&{89.}\\end{array}\n$$\n\nOnce again, we see that there are 89 ways to climb a 10-stair staircase.\n\nIf we list $f(1), f(2), f(3), \\ldots,$ then we (almost) get the sequence that opened this chapter:\n\n$$\n1, 2, 3, 5, 8, 13, 21, 34, 55, 89, \\ldots\n$$\n\nEach number in the sequence (after the first two) is the sum of the two numbers immediately before it: $2 = 1 + 1, 3 = 2 + 1, 5 = 3 + 2,$ and so on.\n\nThe only thing that's different from the sequence on page 172 is that the sequence on page 172 has an extra 1 at the start. We can add this 1 to our example, though, without any difficulty. If there are 0 stairs, then there's only 1 way to climb this staircase: do nothing! So $f(0) = 1$ makes sense. Also note that $f(2) = f(1) + f(0) = 1 + 1 = 2,$ so that our equation $f(n) = f(n-1) + f(n-2)$ holds for all positive integers $n \\geq 2$.\n\nWhen we add this first 1 to our sequence, we get the sequence that we first saw at the start of the chapter:\n\n$$\n1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, \\ldots\n$$\n\nThese numbers are called the Fibonacci numbers, in honor of the Italian mathematician Leonardo of Pisa, whose nickname was \"Fibonacci,\" and who first published the sequence of numbers in his Liber abaci in 1202.\n\nWe've seen that each Fibonacci number is the sum of the previous two Fibonacci numbers. We can write this using a more formal definition.\n\nWe typically denote sequences using a variable with a subscript, such as\n\n$$\na_{1}, a_{2}, a_{3}, \\dotsc.\n$$\n\nThus, $a_{1}$ is the first number in the sequence, $a_{2}$ is the second number in the sequence, and so on. Sometimes we'll start our lists with $a_{0}$ instead of $a_{1},$ so that our sequence would be\n\n$$\na_{0}, a_{1}, a_{2}, \\ldots.\n$$\n\nThe Fibonacci numbers are defined by $F_{1} = 1, F_{2} = 1,$ and $F_{n} = F_{n-1} + F_{n-2}$ for all positive integers $n > 2.$ So, for example,",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "The Fibonacci numbers are defined by $F_{1} = 1, F_{2} = 1,$ and $F_{n} = F_{n-1} + F_{n-2}$ for all positive integers $n > 2.$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/biz-821.pdf_543",
        "ID": "0ba04c24-970a-4251-bc1f-35ebc15b9b39",
        "questions": "What is the operating income for the Board Games Division in Game Products, Inc.'s segmented income statements for the current fiscal year?",
        "answers": "$4,925",
        "context": "$\n\\caption{Game Products, Inc. Segmented Income Statements for the Current Fiscal Year Ended December 31 (dollar amounts are in thousands)}\n\\begin{tabular}{l|c|c|c}\n& Sporting Goods Division & Board Games Division & Computer Games Division \\\\\nSales & \\$20,000 & \\$34,000 & \\$29,000 \\\\\nCost of goods sold & 6,000 & 11,000 & 10,000\\\\\nGross margin Cost of goods sold & \\$14,000 & \\$23,000 & \\$19,000 \\\\\nAllocated overhead (from corporate) & 1,205 & 2,048 & 1,747 \\\\\nResearch and development expenses & 500 & 1,500 & 3,000 \\\\\nSelling and administrative expenses & 9,000 & 14,500 & 12,000 \\\\\nOperating income & \\$3,295 & \\$4,925 & \\$2,253 \\\\\nIncome tax expense (30\\% rate) & 989 & 1,486 & 676 \\\\\nNet income & \\$2,306 & \\$3,466 & \\$1,577 \\\\\n\\end{tabular}\n$\n\n$\n\\caption{Game Products, Inc. Segmented Balance Sheets Average Balances December 31 (dollar amounts are in thousands)}\n\\begin{tabular}{|l|c|c|c|}\n     \n        & Sporting Goods Division & Board Games Division & Computer Games Division \\\\\n     \n    Assets & Average Balance & Average Balance & Average Balance \\\\\n     \n    Cash & \\$3,600 & \\$5,800 & \\$4,300 \\\\\n    Accounts receivable & 3,100 & 7,300 & 4,850 \\\\\n    Inventory & 2,950 & 6,850 & 3,850 \\\\\n    Total current assets & \\$9,650 & \\$19,950 & \\$13,000 \\\\\n    Property, plant and equipment (net) & 19,700 & 35,500 & 20,400 \\\\\n    Total assets & \\$29,350 & \\$55,450 & \\$33,400 \\\\\n     \n    Liabilities and owners' equity & & & \\\\\n     \n    Accounts payable & \\$2,300 & \\$3,400 & \\$2,500 \\\\\n    Other current liabilities &1,100 & 1,100 & 1,000 \\\\\n    Total current liabilities & 3,400 & 4,500 & 3,500 \\\\\n    Long-term liabilities & 0 & 0 & 0 \\\\\n    Total liabilities & \\$3,400 & \\$4,500 & \\$3,500 \\\\\n    Total owners' equity & 25,950 & 50,950 & 29,900 \\\\\n    Total liabilities and owners' equity & \\$29,350 & \\$55,450 & \\$33,400 \\\\\n     \n\\end{tabular}\n$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "table",
        "evidence_context": "Operating income & \\$3,295 & \\$4,925 & \\$2,253",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/biz-821.pdf_543",
        "ID": "0babd726-0932-43d4-b738-0d2837a5b39e",
        "questions": "What is the research and development expense for the Computer Games Division according to Game Products, Inc.\u2019s segmented income statements for the current fiscal year?",
        "answers": "3,000",
        "context": "$\n\\caption{Game Products, Inc. Segmented Income Statements for the Current Fiscal Year Ended December 31 (dollar amounts are in thousands)}\n\\begin{tabular}{l|c|c|c}\n& Sporting Goods Division & Board Games Division & Computer Games Division \\\\\nSales & \\$20,000 & \\$34,000 & \\$29,000 \\\\\nCost of goods sold & 6,000 & 11,000 & 10,000\\\\\nGross margin Cost of goods sold & \\$14,000 & \\$23,000 & \\$19,000 \\\\\nAllocated overhead (from corporate) & 1,205 & 2,048 & 1,747 \\\\\nResearch and development expenses & 500 & 1,500 & 3,000 \\\\\nSelling and administrative expenses & 9,000 & 14,500 & 12,000 \\\\\nOperating income & \\$3,295 & \\$4,925 & \\$2,253 \\\\\nIncome tax expense (30\\% rate) & 989 & 1,486 & 676 \\\\\nNet income & \\$2,306 & \\$3,466 & \\$1,577 \\\\\n\\end{tabular}\n$\n\n$\n\\caption{Game Products, Inc. Segmented Balance Sheets Average Balances December 31 (dollar amounts are in thousands)}\n\\begin{tabular}{|l|c|c|c|}\n     \n        & Sporting Goods Division & Board Games Division & Computer Games Division \\\\\n     \n    Assets & Average Balance & Average Balance & Average Balance \\\\\n     \n    Cash & \\$3,600 & \\$5,800 & \\$4,300 \\\\\n    Accounts receivable & 3,100 & 7,300 & 4,850 \\\\\n    Inventory & 2,950 & 6,850 & 3,850 \\\\\n    Total current assets & \\$9,650 & \\$19,950 & \\$13,000 \\\\\n    Property, plant and equipment (net) & 19,700 & 35,500 & 20,400 \\\\\n    Total assets & \\$29,350 & \\$55,450 & \\$33,400 \\\\\n     \n    Liabilities and owners' equity & & & \\\\\n     \n    Accounts payable & \\$2,300 & \\$3,400 & \\$2,500 \\\\\n    Other current liabilities &1,100 & 1,100 & 1,000 \\\\\n    Total current liabilities & 3,400 & 4,500 & 3,500 \\\\\n    Long-term liabilities & 0 & 0 & 0 \\\\\n    Total liabilities & \\$3,400 & \\$4,500 & \\$3,500 \\\\\n    Total owners' equity & 25,950 & 50,950 & 29,900 \\\\\n    Total liabilities and owners' equity & \\$29,350 & \\$55,450 & \\$33,400 \\\\\n     \n\\end{tabular}\n$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Numeric",
        "evidence_source": "table",
        "evidence_context": "Research and development expenses & 500 & 1,500 & 3,000",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/biz-821.pdf_543",
        "ID": "0bb4a483-e9b6-45fc-9b4f-a21f12ce40a3",
        "questions": "What is the total value of accounts receivable listed for the Sporting Goods Division and the Board Games Division in Game Products, Inc.\u2019s segmented balance sheets average balances?",
        "answers": "10,400",
        "context": "$\n\\caption{Game Products, Inc. Segmented Income Statements for the Current Fiscal Year Ended December 31 (dollar amounts are in thousands)}\n\\begin{tabular}{l|c|c|c}\n& Sporting Goods Division & Board Games Division & Computer Games Division \\\\\nSales & \\$20,000 & \\$34,000 & \\$29,000 \\\\\nCost of goods sold & 6,000 & 11,000 & 10,000\\\\\nGross margin Cost of goods sold & \\$14,000 & \\$23,000 & \\$19,000 \\\\\nAllocated overhead (from corporate) & 1,205 & 2,048 & 1,747 \\\\\nResearch and development expenses & 500 & 1,500 & 3,000 \\\\\nSelling and administrative expenses & 9,000 & 14,500 & 12,000 \\\\\nOperating income & \\$3,295 & \\$4,925 & \\$2,253 \\\\\nIncome tax expense (30\\% rate) & 989 & 1,486 & 676 \\\\\nNet income & \\$2,306 & \\$3,466 & \\$1,577 \\\\\n\\end{tabular}\n$\n\n$\n\\caption{Game Products, Inc. Segmented Balance Sheets Average Balances December 31 (dollar amounts are in thousands)}\n\\begin{tabular}{|l|c|c|c|}\n     \n        & Sporting Goods Division & Board Games Division & Computer Games Division \\\\\n     \n    Assets & Average Balance & Average Balance & Average Balance \\\\\n     \n    Cash & \\$3,600 & \\$5,800 & \\$4,300 \\\\\n    Accounts receivable & 3,100 & 7,300 & 4,850 \\\\\n    Inventory & 2,950 & 6,850 & 3,850 \\\\\n    Total current assets & \\$9,650 & \\$19,950 & \\$13,000 \\\\\n    Property, plant and equipment (net) & 19,700 & 35,500 & 20,400 \\\\\n    Total assets & \\$29,350 & \\$55,450 & \\$33,400 \\\\\n     \n    Liabilities and owners' equity & & & \\\\\n     \n    Accounts payable & \\$2,300 & \\$3,400 & \\$2,500 \\\\\n    Other current liabilities &1,100 & 1,100 & 1,000 \\\\\n    Total current liabilities & 3,400 & 4,500 & 3,500 \\\\\n    Long-term liabilities & 0 & 0 & 0 \\\\\n    Total liabilities & \\$3,400 & \\$4,500 & \\$3,500 \\\\\n    Total owners' equity & 25,950 & 50,950 & 29,900 \\\\\n    Total liabilities and owners' equity & \\$29,350 & \\$55,450 & \\$33,400 \\\\\n     \n\\end{tabular}\n$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Numeric",
        "evidence_source": "table",
        "evidence_context": "Accounts receivable & 3,100 & 7,300 & 4,850",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/biz-821.pdf_543",
        "ID": "0bba6c1b-aac4-4ad9-bd6e-53f2969a8b69",
        "questions": "What is the net income for the Board Games Division of Game Products, Inc.?",
        "answers": "$3,466",
        "context": "$\n\\caption{Game Products, Inc. Segmented Income Statements for the Current Fiscal Year Ended December 31 (dollar amounts are in thousands)}\n\\begin{tabular}{l|c|c|c}\n& Sporting Goods Division & Board Games Division & Computer Games Division \\\\\nSales & \\$20,000 & \\$34,000 & \\$29,000 \\\\\nCost of goods sold & 6,000 & 11,000 & 10,000\\\\\nGross margin Cost of goods sold & \\$14,000 & \\$23,000 & \\$19,000 \\\\\nAllocated overhead (from corporate) & 1,205 & 2,048 & 1,747 \\\\\nResearch and development expenses & 500 & 1,500 & 3,000 \\\\\nSelling and administrative expenses & 9,000 & 14,500 & 12,000 \\\\\nOperating income & \\$3,295 & \\$4,925 & \\$2,253 \\\\\nIncome tax expense (30\\% rate) & 989 & 1,486 & 676 \\\\\nNet income & \\$2,306 & \\$3,466 & \\$1,577 \\\\\n\\end{tabular}\n$\n\n$\n\\caption{Game Products, Inc. Segmented Balance Sheets Average Balances December 31 (dollar amounts are in thousands)}\n\\begin{tabular}{|l|c|c|c|}\n     \n        & Sporting Goods Division & Board Games Division & Computer Games Division \\\\\n     \n    Assets & Average Balance & Average Balance & Average Balance \\\\\n     \n    Cash & \\$3,600 & \\$5,800 & \\$4,300 \\\\\n    Accounts receivable & 3,100 & 7,300 & 4,850 \\\\\n    Inventory & 2,950 & 6,850 & 3,850 \\\\\n    Total current assets & \\$9,650 & \\$19,950 & \\$13,000 \\\\\n    Property, plant and equipment (net) & 19,700 & 35,500 & 20,400 \\\\\n    Total assets & \\$29,350 & \\$55,450 & \\$33,400 \\\\\n     \n    Liabilities and owners' equity & & & \\\\\n     \n    Accounts payable & \\$2,300 & \\$3,400 & \\$2,500 \\\\\n    Other current liabilities &1,100 & 1,100 & 1,000 \\\\\n    Total current liabilities & 3,400 & 4,500 & 3,500 \\\\\n    Long-term liabilities & 0 & 0 & 0 \\\\\n    Total liabilities & \\$3,400 & \\$4,500 & \\$3,500 \\\\\n    Total owners' equity & 25,950 & 50,950 & 29,900 \\\\\n    Total liabilities and owners' equity & \\$29,350 & \\$55,450 & \\$33,400 \\\\\n     \n\\end{tabular}\n$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Net income & \\$2,306 & \\$3,466 & \\$1,577 \\\\",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/biz-821.pdf_543",
        "ID": "0bbc5bf5-1ea8-45c3-b33b-de6e8cf37c70",
        "questions": "How much is the total assets balance for the Board Games Division as of December 31 according to the segmented balance sheets of Game Products, Inc.?",
        "answers": "$55,450",
        "context": "$\n\\caption{Game Products, Inc. Segmented Income Statements for the Current Fiscal Year Ended December 31 (dollar amounts are in thousands)}\n\\begin{tabular}{l|c|c|c}\n& Sporting Goods Division & Board Games Division & Computer Games Division \\\\\nSales & \\$20,000 & \\$34,000 & \\$29,000 \\\\\nCost of goods sold & 6,000 & 11,000 & 10,000\\\\\nGross margin Cost of goods sold & \\$14,000 & \\$23,000 & \\$19,000 \\\\\nAllocated overhead (from corporate) & 1,205 & 2,048 & 1,747 \\\\\nResearch and development expenses & 500 & 1,500 & 3,000 \\\\\nSelling and administrative expenses & 9,000 & 14,500 & 12,000 \\\\\nOperating income & \\$3,295 & \\$4,925 & \\$2,253 \\\\\nIncome tax expense (30\\% rate) & 989 & 1,486 & 676 \\\\\nNet income & \\$2,306 & \\$3,466 & \\$1,577 \\\\\n\\end{tabular}\n$\n\n$\n\\caption{Game Products, Inc. Segmented Balance Sheets Average Balances December 31 (dollar amounts are in thousands)}\n\\begin{tabular}{|l|c|c|c|}\n     \n        & Sporting Goods Division & Board Games Division & Computer Games Division \\\\\n     \n    Assets & Average Balance & Average Balance & Average Balance \\\\\n     \n    Cash & \\$3,600 & \\$5,800 & \\$4,300 \\\\\n    Accounts receivable & 3,100 & 7,300 & 4,850 \\\\\n    Inventory & 2,950 & 6,850 & 3,850 \\\\\n    Total current assets & \\$9,650 & \\$19,950 & \\$13,000 \\\\\n    Property, plant and equipment (net) & 19,700 & 35,500 & 20,400 \\\\\n    Total assets & \\$29,350 & \\$55,450 & \\$33,400 \\\\\n     \n    Liabilities and owners' equity & & & \\\\\n     \n    Accounts payable & \\$2,300 & \\$3,400 & \\$2,500 \\\\\n    Other current liabilities &1,100 & 1,100 & 1,000 \\\\\n    Total current liabilities & 3,400 & 4,500 & 3,500 \\\\\n    Long-term liabilities & 0 & 0 & 0 \\\\\n    Total liabilities & \\$3,400 & \\$4,500 & \\$3,500 \\\\\n    Total owners' equity & 25,950 & 50,950 & 29,900 \\\\\n    Total liabilities and owners' equity & \\$29,350 & \\$55,450 & \\$33,400 \\\\\n     \n\\end{tabular}\n$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Total assets & \\$29,350 & \\$55,450 & \\$33,400 \\\\",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/biz-821.pdf_543",
        "ID": "0bc6174e-d9cd-4b91-97e7-ea726a65113d",
        "questions": "What is the difference in sales between the Board Games Division and the Computer Games Division in Game Products, Inc.?",
        "answers": "$5,000",
        "context": "$\n\\caption{Game Products, Inc. Segmented Income Statements for the Current Fiscal Year Ended December 31 (dollar amounts are in thousands)}\n\\begin{tabular}{l|c|c|c}\n& Sporting Goods Division & Board Games Division & Computer Games Division \\\\\nSales & \\$20,000 & \\$34,000 & \\$29,000 \\\\\nCost of goods sold & 6,000 & 11,000 & 10,000\\\\\nGross margin Cost of goods sold & \\$14,000 & \\$23,000 & \\$19,000 \\\\\nAllocated overhead (from corporate) & 1,205 & 2,048 & 1,747 \\\\\nResearch and development expenses & 500 & 1,500 & 3,000 \\\\\nSelling and administrative expenses & 9,000 & 14,500 & 12,000 \\\\\nOperating income & \\$3,295 & \\$4,925 & \\$2,253 \\\\\nIncome tax expense (30\\% rate) & 989 & 1,486 & 676 \\\\\nNet income & \\$2,306 & \\$3,466 & \\$1,577 \\\\\n\\end{tabular}\n$\n\n$\n\\caption{Game Products, Inc. Segmented Balance Sheets Average Balances December 31 (dollar amounts are in thousands)}\n\\begin{tabular}{|l|c|c|c|}\n     \n        & Sporting Goods Division & Board Games Division & Computer Games Division \\\\\n     \n    Assets & Average Balance & Average Balance & Average Balance \\\\\n     \n    Cash & \\$3,600 & \\$5,800 & \\$4,300 \\\\\n    Accounts receivable & 3,100 & 7,300 & 4,850 \\\\\n    Inventory & 2,950 & 6,850 & 3,850 \\\\\n    Total current assets & \\$9,650 & \\$19,950 & \\$13,000 \\\\\n    Property, plant and equipment (net) & 19,700 & 35,500 & 20,400 \\\\\n    Total assets & \\$29,350 & \\$55,450 & \\$33,400 \\\\\n     \n    Liabilities and owners' equity & & & \\\\\n     \n    Accounts payable & \\$2,300 & \\$3,400 & \\$2,500 \\\\\n    Other current liabilities &1,100 & 1,100 & 1,000 \\\\\n    Total current liabilities & 3,400 & 4,500 & 3,500 \\\\\n    Long-term liabilities & 0 & 0 & 0 \\\\\n    Total liabilities & \\$3,400 & \\$4,500 & \\$3,500 \\\\\n    Total owners' equity & 25,950 & 50,950 & 29,900 \\\\\n    Total liabilities and owners' equity & \\$29,350 & \\$55,450 & \\$33,400 \\\\\n     \n\\end{tabular}\n$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Numeric",
        "evidence_source": "equation",
        "evidence_context": "Sales & \\$20,000 & \\$34,000 & \\$29,000 \\\\",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/UTX_-_Algebra_for_Computer_Science.pdf_19",
        "ID": "0bd357e1-d6bf-4828-9798-6708bb3dffe1",
        "questions": "According to the quadratic reciprocity theorem, what is the value of $(p|q)(q|p)$ when both p and q are equivalent to 3 modulo 4?",
        "answers": "-1",
        "context": "For $\\pmb{p}$ a prime and $(a, p) = 1$, let the Legendre symbol $\\left(a\\vert p\\right)$ (classical notation $\\scriptstyle\\left({\\frac{a}{p}}\\right)$) denote 1 when $\\pmb{a}$ is a square mod $\\pmb{p}$ and $^{-1}$ when $\\pmb{a}$ is not a square mod $\\pmb{p}$. With this notation, the previous theorem says that $a^{(p-1)/2}\\equiv(a|p)(p)$ when $\\pmb{p}$ is a prime and $\\pmb{a}$ is prime to $\\pmb{p}$. The following important result will be proved in the third section of chapter 4.\n\nTHE QUADRATIC RECIPROCITY THEOREM. Suppose that $p$ and $\\pmb q$ are odd primes. Then\n\n$$\n(p|q)(q|p)=(-1)^{(p-1)(q-1)/4}.\n$$\n\nNote. In other words, the product $(p|q)(q|p)$ equals 1 unless both $\\pmb{p}$ and $\\pmb q$ are $\\equiv 3$ mod 4, in which case it equals $^{-1}$.\n\nNote. This result, first proved by Gauss in 1801, is one of the most famous and beautiful results in number theory.\n\nR. Define $\\left(a\\vert p\\right)$ to be zero when $\\mathcal{P}$ divides $\\pmb{a}$. It is obvious that $\\left(a|p\\right)=\\left(b|p\\right)$ when $a\\equiv b\\,\\left(p\\right)$. Prove that $(a b|p)=(a|p)(b|p)$. (Hint: This amounts to the statement that the product of two squares mod $\\pmb{p}$ is a square mod $\\pmb{p}$, etc. At one point it is useful to know that there are as many squares as non-squares.)\n\nR. Verify that $(-1|p)=(-1)^{(p-1)/2}$ and that $(a|2)=1$ for all odd integers $\\pmb{a}$.\n\nExamples\n\nAny odd prime has the form $6k+\\epsilon$ where $\\epsilon\\,=\\,\\pm1$. Hence $(p|3) = (6k + \\epsilon | 3) = (\\epsilon | 3) = \\epsilon$, for 1 is a square mod 3 but not ${-1}$. Similarly $p\\equiv\\pm1$ or $\\pm2 {\\bmod{5}} $. In the first case, $(p|5)=1$, in the second $(p|5)=-1$.\n\nExercise\n\nDo the same computations with 7 taking the place of 5.\n\nThe quadratic reciprocity theorem has the following complement\n\nTHEOREM. When $p>2$ is a prime, $(2|p)=(-1)^{c}$, where $c={\\left(p^{2}-1\\right)}/{8}$.\n\nNote. The proof below is similar to one of Gauss's proofs of the quadratic reciprocity theorem.\n\nNote. Using this result and the quadratic reciprocity theorem, we can compute any $\\left(n|p\\right)$ with $\\pmb{p}$ prime. In fact, reducing $\\pmb{n}$ modulo $p_{i}$ we can assume that $1\\,\\leq\\,n\\,<\\,p$ and then factor $\\pmb{\\mathscr{n}}$ into powers of primes. Since $(a b|p)=(a|p)(b|p)$, this reduces the problem to the quadratic reciprocity theorem and the computation of $(2|p)$.\n\nProoF: We are going to consider the numbers $C=\\{1,2,\\ldots,(p-1)/2\\}$ whose sum is $c\\,=\\,(p^{2}\\,-\\,1)/8$, and the set $2C=\\{2,4,\\ldots,p-1\\}$. Let",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "In other words, the product $(p|q)(q|p)$ equals 1 unless both $\\pmb{p}$ and $\\pmb q$ are $\\equiv 3$ mod 4, in which case it equals $^{-1}$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTX_-_Algebra_for_Computer_Science.pdf_19",
        "ID": "0bd89c73-95c1-4122-8f9e-89ef7bc1ad83",
        "questions": "Who was the first to prove the quadratic reciprocity theorem and in which year?",
        "answers": "Gauss in 1801",
        "context": "For $\\pmb{p}$ a prime and $(a, p) = 1$, let the Legendre symbol $\\left(a\\vert p\\right)$ (classical notation $\\scriptstyle\\left({\\frac{a}{p}}\\right)$) denote 1 when $\\pmb{a}$ is a square mod $\\pmb{p}$ and $^{-1}$ when $\\pmb{a}$ is not a square mod $\\pmb{p}$. With this notation, the previous theorem says that $a^{(p-1)/2}\\equiv(a|p)(p)$ when $\\pmb{p}$ is a prime and $\\pmb{a}$ is prime to $\\pmb{p}$. The following important result will be proved in the third section of chapter 4.\n\nTHE QUADRATIC RECIPROCITY THEOREM. Suppose that $p$ and $\\pmb q$ are odd primes. Then\n\n$$\n(p|q)(q|p)=(-1)^{(p-1)(q-1)/4}.\n$$\n\nNote. In other words, the product $(p|q)(q|p)$ equals 1 unless both $\\pmb{p}$ and $\\pmb q$ are $\\equiv 3$ mod 4, in which case it equals $^{-1}$.\n\nNote. This result, first proved by Gauss in 1801, is one of the most famous and beautiful results in number theory.\n\nR. Define $\\left(a\\vert p\\right)$ to be zero when $\\mathcal{P}$ divides $\\pmb{a}$. It is obvious that $\\left(a|p\\right)=\\left(b|p\\right)$ when $a\\equiv b\\,\\left(p\\right)$. Prove that $(a b|p)=(a|p)(b|p)$. (Hint: This amounts to the statement that the product of two squares mod $\\pmb{p}$ is a square mod $\\pmb{p}$, etc. At one point it is useful to know that there are as many squares as non-squares.)\n\nR. Verify that $(-1|p)=(-1)^{(p-1)/2}$ and that $(a|2)=1$ for all odd integers $\\pmb{a}$.\n\nExamples\n\nAny odd prime has the form $6k+\\epsilon$ where $\\epsilon\\,=\\,\\pm1$. Hence $(p|3) = (6k + \\epsilon | 3) = (\\epsilon | 3) = \\epsilon$, for 1 is a square mod 3 but not ${-1}$. Similarly $p\\equiv\\pm1$ or $\\pm2 {\\bmod{5}} $. In the first case, $(p|5)=1$, in the second $(p|5)=-1$.\n\nExercise\n\nDo the same computations with 7 taking the place of 5.\n\nThe quadratic reciprocity theorem has the following complement\n\nTHEOREM. When $p>2$ is a prime, $(2|p)=(-1)^{c}$, where $c={\\left(p^{2}-1\\right)}/{8}$.\n\nNote. The proof below is similar to one of Gauss's proofs of the quadratic reciprocity theorem.\n\nNote. Using this result and the quadratic reciprocity theorem, we can compute any $\\left(n|p\\right)$ with $\\pmb{p}$ prime. In fact, reducing $\\pmb{n}$ modulo $p_{i}$ we can assume that $1\\,\\leq\\,n\\,<\\,p$ and then factor $\\pmb{\\mathscr{n}}$ into powers of primes. Since $(a b|p)=(a|p)(b|p)$, this reduces the problem to the quadratic reciprocity theorem and the computation of $(2|p)$.\n\nProoF: We are going to consider the numbers $C=\\{1,2,\\ldots,(p-1)/2\\}$ whose sum is $c\\,=\\,(p^{2}\\,-\\,1)/8$, and the set $2C=\\{2,4,\\ldots,p-1\\}$. Let",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "This result, first proved by Gauss in 1801, is one of the most famous and beautiful results in number theory.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTX_-_Algebra_for_Computer_Science.pdf_19",
        "ID": "0bde3249-cd06-43c9-9149-fe6377f141cd",
        "questions": "What is the value of $(2|p)$ when $p$ is a prime greater than 2?",
        "answers": "$(-1)^{c}$, where $c={\\left(p^{2}-1\right)}/{8}$",
        "context": "For $\\pmb{p}$ a prime and $(a, p) = 1$, let the Legendre symbol $\\left(a\\vert p\\right)$ (classical notation $\\scriptstyle\\left({\\frac{a}{p}}\\right)$) denote 1 when $\\pmb{a}$ is a square mod $\\pmb{p}$ and $^{-1}$ when $\\pmb{a}$ is not a square mod $\\pmb{p}$. With this notation, the previous theorem says that $a^{(p-1)/2}\\equiv(a|p)(p)$ when $\\pmb{p}$ is a prime and $\\pmb{a}$ is prime to $\\pmb{p}$. The following important result will be proved in the third section of chapter 4.\n\nTHE QUADRATIC RECIPROCITY THEOREM. Suppose that $p$ and $\\pmb q$ are odd primes. Then\n\n$$\n(p|q)(q|p)=(-1)^{(p-1)(q-1)/4}.\n$$\n\nNote. In other words, the product $(p|q)(q|p)$ equals 1 unless both $\\pmb{p}$ and $\\pmb q$ are $\\equiv 3$ mod 4, in which case it equals $^{-1}$.\n\nNote. This result, first proved by Gauss in 1801, is one of the most famous and beautiful results in number theory.\n\nR. Define $\\left(a\\vert p\\right)$ to be zero when $\\mathcal{P}$ divides $\\pmb{a}$. It is obvious that $\\left(a|p\\right)=\\left(b|p\\right)$ when $a\\equiv b\\,\\left(p\\right)$. Prove that $(a b|p)=(a|p)(b|p)$. (Hint: This amounts to the statement that the product of two squares mod $\\pmb{p}$ is a square mod $\\pmb{p}$, etc. At one point it is useful to know that there are as many squares as non-squares.)\n\nR. Verify that $(-1|p)=(-1)^{(p-1)/2}$ and that $(a|2)=1$ for all odd integers $\\pmb{a}$.\n\nExamples\n\nAny odd prime has the form $6k+\\epsilon$ where $\\epsilon\\,=\\,\\pm1$. Hence $(p|3) = (6k + \\epsilon | 3) = (\\epsilon | 3) = \\epsilon$, for 1 is a square mod 3 but not ${-1}$. Similarly $p\\equiv\\pm1$ or $\\pm2 {\\bmod{5}} $. In the first case, $(p|5)=1$, in the second $(p|5)=-1$.\n\nExercise\n\nDo the same computations with 7 taking the place of 5.\n\nThe quadratic reciprocity theorem has the following complement\n\nTHEOREM. When $p>2$ is a prime, $(2|p)=(-1)^{c}$, where $c={\\left(p^{2}-1\\right)}/{8}$.\n\nNote. The proof below is similar to one of Gauss's proofs of the quadratic reciprocity theorem.\n\nNote. Using this result and the quadratic reciprocity theorem, we can compute any $\\left(n|p\\right)$ with $\\pmb{p}$ prime. In fact, reducing $\\pmb{n}$ modulo $p_{i}$ we can assume that $1\\,\\leq\\,n\\,<\\,p$ and then factor $\\pmb{\\mathscr{n}}$ into powers of primes. Since $(a b|p)=(a|p)(b|p)$, this reduces the problem to the quadratic reciprocity theorem and the computation of $(2|p)$.\n\nProoF: We are going to consider the numbers $C=\\{1,2,\\ldots,(p-1)/2\\}$ whose sum is $c\\,=\\,(p^{2}\\,-\\,1)/8$, and the set $2C=\\{2,4,\\ldots,p-1\\}$. Let",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Equation",
        "evidence_source": "text",
        "evidence_context": "When $p>2$ is a prime, $(2|p)=(-1)^{c}$, where $c={\\left(p^{2}-1\right)}/{8}$. Note. The proof below is similar to one of Gauss's proofs of the quadratic reciprocity theorem.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTX_-_Algebra_for_Computer_Science.pdf_19",
        "ID": "0bded216-0863-4195-a960-a9f6b395bc69",
        "questions": "What is the quadratic reciprocity theorem for odd primes p and q?",
        "answers": "$(p|q)(q|p)=(-1)^{(p-1)(q-1)/4}$",
        "context": "For $\\pmb{p}$ a prime and $(a, p) = 1$, let the Legendre symbol $\\left(a\\vert p\\right)$ (classical notation $\\scriptstyle\\left({\\frac{a}{p}}\\right)$) denote 1 when $\\pmb{a}$ is a square mod $\\pmb{p}$ and $^{-1}$ when $\\pmb{a}$ is not a square mod $\\pmb{p}$. With this notation, the previous theorem says that $a^{(p-1)/2}\\equiv(a|p)(p)$ when $\\pmb{p}$ is a prime and $\\pmb{a}$ is prime to $\\pmb{p}$. The following important result will be proved in the third section of chapter 4.\n\nTHE QUADRATIC RECIPROCITY THEOREM. Suppose that $p$ and $\\pmb q$ are odd primes. Then\n\n$$\n(p|q)(q|p)=(-1)^{(p-1)(q-1)/4}.\n$$\n\nNote. In other words, the product $(p|q)(q|p)$ equals 1 unless both $\\pmb{p}$ and $\\pmb q$ are $\\equiv 3$ mod 4, in which case it equals $^{-1}$.\n\nNote. This result, first proved by Gauss in 1801, is one of the most famous and beautiful results in number theory.\n\nR. Define $\\left(a\\vert p\\right)$ to be zero when $\\mathcal{P}$ divides $\\pmb{a}$. It is obvious that $\\left(a|p\\right)=\\left(b|p\\right)$ when $a\\equiv b\\,\\left(p\\right)$. Prove that $(a b|p)=(a|p)(b|p)$. (Hint: This amounts to the statement that the product of two squares mod $\\pmb{p}$ is a square mod $\\pmb{p}$, etc. At one point it is useful to know that there are as many squares as non-squares.)\n\nR. Verify that $(-1|p)=(-1)^{(p-1)/2}$ and that $(a|2)=1$ for all odd integers $\\pmb{a}$.\n\nExamples\n\nAny odd prime has the form $6k+\\epsilon$ where $\\epsilon\\,=\\,\\pm1$. Hence $(p|3) = (6k + \\epsilon | 3) = (\\epsilon | 3) = \\epsilon$, for 1 is a square mod 3 but not ${-1}$. Similarly $p\\equiv\\pm1$ or $\\pm2 {\\bmod{5}} $. In the first case, $(p|5)=1$, in the second $(p|5)=-1$.\n\nExercise\n\nDo the same computations with 7 taking the place of 5.\n\nThe quadratic reciprocity theorem has the following complement\n\nTHEOREM. When $p>2$ is a prime, $(2|p)=(-1)^{c}$, where $c={\\left(p^{2}-1\\right)}/{8}$.\n\nNote. The proof below is similar to one of Gauss's proofs of the quadratic reciprocity theorem.\n\nNote. Using this result and the quadratic reciprocity theorem, we can compute any $\\left(n|p\\right)$ with $\\pmb{p}$ prime. In fact, reducing $\\pmb{n}$ modulo $p_{i}$ we can assume that $1\\,\\leq\\,n\\,<\\,p$ and then factor $\\pmb{\\mathscr{n}}$ into powers of primes. Since $(a b|p)=(a|p)(b|p)$, this reduces the problem to the quadratic reciprocity theorem and the computation of $(2|p)$.\n\nProoF: We are going to consider the numbers $C=\\{1,2,\\ldots,(p-1)/2\\}$ whose sum is $c\\,=\\,(p^{2}\\,-\\,1)/8$, and the set $2C=\\{2,4,\\ldots,p-1\\}$. Let",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Suppose that $p$ and $\\pmb q$ are odd primes. Then $$(p|q)(q|p)=(-1)^{(p-1)(q-1)/4}.$$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/UTX_-_Algebra_for_Computer_Science.pdf_19",
        "ID": "0be1a657-606a-432b-8987-7942eacef95f",
        "questions": "According to the quadratic reciprocity theorem, what is the product $(p|q)(q|p)$ if both p and q are congruent to 3 mod 4?",
        "answers": "$(-1)$",
        "context": "For $\\pmb{p}$ a prime and $(a, p) = 1$, let the Legendre symbol $\\left(a\\vert p\\right)$ (classical notation $\\scriptstyle\\left({\\frac{a}{p}}\\right)$) denote 1 when $\\pmb{a}$ is a square mod $\\pmb{p}$ and $^{-1}$ when $\\pmb{a}$ is not a square mod $\\pmb{p}$. With this notation, the previous theorem says that $a^{(p-1)/2}\\equiv(a|p)(p)$ when $\\pmb{p}$ is a prime and $\\pmb{a}$ is prime to $\\pmb{p}$. The following important result will be proved in the third section of chapter 4.\n\nTHE QUADRATIC RECIPROCITY THEOREM. Suppose that $p$ and $\\pmb q$ are odd primes. Then\n\n$$\n(p|q)(q|p)=(-1)^{(p-1)(q-1)/4}.\n$$\n\nNote. In other words, the product $(p|q)(q|p)$ equals 1 unless both $\\pmb{p}$ and $\\pmb q$ are $\\equiv 3$ mod 4, in which case it equals $^{-1}$.\n\nNote. This result, first proved by Gauss in 1801, is one of the most famous and beautiful results in number theory.\n\nR. Define $\\left(a\\vert p\\right)$ to be zero when $\\mathcal{P}$ divides $\\pmb{a}$. It is obvious that $\\left(a|p\\right)=\\left(b|p\\right)$ when $a\\equiv b\\,\\left(p\\right)$. Prove that $(a b|p)=(a|p)(b|p)$. (Hint: This amounts to the statement that the product of two squares mod $\\pmb{p}$ is a square mod $\\pmb{p}$, etc. At one point it is useful to know that there are as many squares as non-squares.)\n\nR. Verify that $(-1|p)=(-1)^{(p-1)/2}$ and that $(a|2)=1$ for all odd integers $\\pmb{a}$.\n\nExamples\n\nAny odd prime has the form $6k+\\epsilon$ where $\\epsilon\\,=\\,\\pm1$. Hence $(p|3) = (6k + \\epsilon | 3) = (\\epsilon | 3) = \\epsilon$, for 1 is a square mod 3 but not ${-1}$. Similarly $p\\equiv\\pm1$ or $\\pm2 {\\bmod{5}} $. In the first case, $(p|5)=1$, in the second $(p|5)=-1$.\n\nExercise\n\nDo the same computations with 7 taking the place of 5.\n\nThe quadratic reciprocity theorem has the following complement\n\nTHEOREM. When $p>2$ is a prime, $(2|p)=(-1)^{c}$, where $c={\\left(p^{2}-1\\right)}/{8}$.\n\nNote. The proof below is similar to one of Gauss's proofs of the quadratic reciprocity theorem.\n\nNote. Using this result and the quadratic reciprocity theorem, we can compute any $\\left(n|p\\right)$ with $\\pmb{p}$ prime. In fact, reducing $\\pmb{n}$ modulo $p_{i}$ we can assume that $1\\,\\leq\\,n\\,<\\,p$ and then factor $\\pmb{\\mathscr{n}}$ into powers of primes. Since $(a b|p)=(a|p)(b|p)$, this reduces the problem to the quadratic reciprocity theorem and the computation of $(2|p)$.\n\nProoF: We are going to consider the numbers $C=\\{1,2,\\ldots,(p-1)/2\\}$ whose sum is $c\\,=\\,(p^{2}\\,-\\,1)/8$, and the set $2C=\\{2,4,\\ldots,p-1\\}$. Let",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Note. In other words, the product $(p|q)(q|p)$ equals 1 unless both $\\pmb{p}$ and $\\pmb q$ are $\\equiv 3$ mod 4, in which case it equals $^{-1}$.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/UTX_-_Algebra_for_Computer_Science.pdf_19",
        "ID": "0be31109-a185-446d-9be9-d91857a798d8",
        "questions": "What is the equation for $(2|p)$ when p is a prime greater than 2?",
        "answers": "When $p>2$ is a prime, $(2|p)=(-1)^{c}$, where $c={\\left(p^{2}-1\right)}/{8}$.",
        "context": "For $\\pmb{p}$ a prime and $(a, p) = 1$, let the Legendre symbol $\\left(a\\vert p\\right)$ (classical notation $\\scriptstyle\\left({\\frac{a}{p}}\\right)$) denote 1 when $\\pmb{a}$ is a square mod $\\pmb{p}$ and $^{-1}$ when $\\pmb{a}$ is not a square mod $\\pmb{p}$. With this notation, the previous theorem says that $a^{(p-1)/2}\\equiv(a|p)(p)$ when $\\pmb{p}$ is a prime and $\\pmb{a}$ is prime to $\\pmb{p}$. The following important result will be proved in the third section of chapter 4.\n\nTHE QUADRATIC RECIPROCITY THEOREM. Suppose that $p$ and $\\pmb q$ are odd primes. Then\n\n$$\n(p|q)(q|p)=(-1)^{(p-1)(q-1)/4}.\n$$\n\nNote. In other words, the product $(p|q)(q|p)$ equals 1 unless both $\\pmb{p}$ and $\\pmb q$ are $\\equiv 3$ mod 4, in which case it equals $^{-1}$.\n\nNote. This result, first proved by Gauss in 1801, is one of the most famous and beautiful results in number theory.\n\nR. Define $\\left(a\\vert p\\right)$ to be zero when $\\mathcal{P}$ divides $\\pmb{a}$. It is obvious that $\\left(a|p\\right)=\\left(b|p\\right)$ when $a\\equiv b\\,\\left(p\\right)$. Prove that $(a b|p)=(a|p)(b|p)$. (Hint: This amounts to the statement that the product of two squares mod $\\pmb{p}$ is a square mod $\\pmb{p}$, etc. At one point it is useful to know that there are as many squares as non-squares.)\n\nR. Verify that $(-1|p)=(-1)^{(p-1)/2}$ and that $(a|2)=1$ for all odd integers $\\pmb{a}$.\n\nExamples\n\nAny odd prime has the form $6k+\\epsilon$ where $\\epsilon\\,=\\,\\pm1$. Hence $(p|3) = (6k + \\epsilon | 3) = (\\epsilon | 3) = \\epsilon$, for 1 is a square mod 3 but not ${-1}$. Similarly $p\\equiv\\pm1$ or $\\pm2 {\\bmod{5}} $. In the first case, $(p|5)=1$, in the second $(p|5)=-1$.\n\nExercise\n\nDo the same computations with 7 taking the place of 5.\n\nThe quadratic reciprocity theorem has the following complement\n\nTHEOREM. When $p>2$ is a prime, $(2|p)=(-1)^{c}$, where $c={\\left(p^{2}-1\\right)}/{8}$.\n\nNote. The proof below is similar to one of Gauss's proofs of the quadratic reciprocity theorem.\n\nNote. Using this result and the quadratic reciprocity theorem, we can compute any $\\left(n|p\\right)$ with $\\pmb{p}$ prime. In fact, reducing $\\pmb{n}$ modulo $p_{i}$ we can assume that $1\\,\\leq\\,n\\,<\\,p$ and then factor $\\pmb{\\mathscr{n}}$ into powers of primes. Since $(a b|p)=(a|p)(b|p)$, this reduces the problem to the quadratic reciprocity theorem and the computation of $(2|p)$.\n\nProoF: We are going to consider the numbers $C=\\{1,2,\\ldots,(p-1)/2\\}$ whose sum is $c\\,=\\,(p^{2}\\,-\\,1)/8$, and the set $2C=\\{2,4,\\ldots,p-1\\}$. Let",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "When $p>2$ is a prime, $(2|p)=(-1)^{c}$, where $c={\\left(p^{2}-1\right)}/{8}$.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/8s.pdf_5",
        "ID": "0bef89ce-1e0c-4de7-9cfc-3591349b64a9",
        "questions": "What happens to the tuples in $r_{2}$ referencing $r_{1}$ if the foreign key constraint is not enforced and a tuple is deleted from $r_{1}$?",
        "answers": "This would amount to simply setting the value of $\\alpha$ to null in some tuples.",
        "context": "a. $\\alpha$ should be a primary key for $r_{1},$ and $\\alpha$ should be the foreign key from $r_{2,i}$ referencing $r_{1}.$\n\nb. If the foreign key constraint is not enforced, then a deletion of a tuple from $r_{1}$ would not have a corresponding deletion from the referencing tuples in $r_{2}.$ Instead of deleting a tuple from $r,$ this would amount to simply setting the value of $\\alpha$ to null in some tuples.\n\nc. For every schema $r_{i}(\\alpha\\beta)$ added to the schema because of a rule $\\alpha\\rightarrow\\beta,\\alpha$ should be made the primary key. Also, a candidate key $\\gamma$ for the original relation is located in some newly created relation $r_{k},$ and is a primary key for that relation. Foreign key constraints are created as follows: for each relation $r_{i}$ created above, if the primary key attributes of $r_{i}$ also occur in any other relation $r_{j},$ then a foreign key constraint is created from those attributes in $r_{j},$ referencing (the primary key of) $r_{i}.$\n\n8.12 Let $R_{1}, R_{2}, \\ldots, R_{n}$ be a decomposition of schema $U.$ Let $u(U)$ be a relation, and let $r_{i} = \\Pi_{R_{i}}(u).$ Show that  \n\n$$\nu \\subseteq r_{1} \\bowtie r_{2} \\bowtie \\cdots \\bowtie r_{n}\n$$  \n\nAnswer: Consider some tuple $t$ in $u.$ Note that $r_{i} = \\Pi_{R_{i}}(u)$ implies that $t[R_{i}] \\in r_{i}, 1 \\leq i \\leq n.$ Thus,  \n\n$$\nt[R_{1}] \\bowtie t[R_{2}] \\bowtie \\ldots \\bowtie t[R_{n}] \\in r_{1} \\bowtie r_{2} \\bowtie \\ldots \\bowtie r_{n}\n$$  \n\nBy the definition of natural join  \n\n$$\nt[R_{1}] \\bowtie t[R_{2}] \\bowtie \\ldots \\bowtie t[R_{n}] = \\Pi_{\\alpha}\\left(\\sigma_{\\beta}\\left(t[R_{1}] \\times t[R_{2}] \\times \\ldots \\times t[R_{n}]\\right)\\right)\n$$  \n\nwhere the condition $\\beta$ is satisfied if values of attributes with the same name in a tuple are equal and where $\\alpha = U.$ The cartesian product of single tuples generates one tuple. The selection process is satisfied because all attributes with the same name must have the same value since they are projections from the same tuple. Finally, the projection clause removes duplicate attribute names.  \n\nBy the definition of decomposition, $U = R_{1} \\cup R_{2} \\cup \\ldots \\cup R_{n},$ which means that all attributes of $t$ are in $t[R_{1}] \\bowtie t[R_{2}] \\bowtie \\ldots \\bowtie t[R_{n}].$ That is, $t$ is equal to the result of this join.  \n\nSince $t$ is any arbitrary tuple in $u,$  \n\n$$\nu \\subseteq r_{1} \\bowtie r_{2} \\bowtie \\ldots \\bowtie r_{n}\n$$  \n\n8.13 Show that the decomposition in Practice Exercise 8.1 is not a dependency-preserving decomposition.  \n\nAnswer: The dependency $B \\rightarrow D$ is not preserved. $F_{1},$ the restriction of $F$ to $(A, B, C)$ is $A \\rightarrow A B C, A \\rightarrow A B, A \\rightarrow A C, A \\rightarrow B C,$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "If the foreign key constraint is not enforced, then a deletion of a tuple from $r_{1}$ would not have a corresponding deletion from the referencing tuples in $r_{2}.$ Instead of deleting a tuple from $r,$ this would amount to simply setting the value of $\\alpha$ to null in some tuples.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/8s.pdf_5",
        "ID": "0bf3d445-f87f-49b8-8b53-d1cdc35cd4c3",
        "questions": "Why is the decomposition in Practice Exercise 8.1 not a dependency-preserving decomposition?",
        "answers": "The dependency $B \\rightarrow D$ is not preserved.",
        "context": "a. $\\alpha$ should be a primary key for $r_{1},$ and $\\alpha$ should be the foreign key from $r_{2,i}$ referencing $r_{1}.$\n\nb. If the foreign key constraint is not enforced, then a deletion of a tuple from $r_{1}$ would not have a corresponding deletion from the referencing tuples in $r_{2}.$ Instead of deleting a tuple from $r,$ this would amount to simply setting the value of $\\alpha$ to null in some tuples.\n\nc. For every schema $r_{i}(\\alpha\\beta)$ added to the schema because of a rule $\\alpha\\rightarrow\\beta,\\alpha$ should be made the primary key. Also, a candidate key $\\gamma$ for the original relation is located in some newly created relation $r_{k},$ and is a primary key for that relation. Foreign key constraints are created as follows: for each relation $r_{i}$ created above, if the primary key attributes of $r_{i}$ also occur in any other relation $r_{j},$ then a foreign key constraint is created from those attributes in $r_{j},$ referencing (the primary key of) $r_{i}.$\n\n8.12 Let $R_{1}, R_{2}, \\ldots, R_{n}$ be a decomposition of schema $U.$ Let $u(U)$ be a relation, and let $r_{i} = \\Pi_{R_{i}}(u).$ Show that  \n\n$$\nu \\subseteq r_{1} \\bowtie r_{2} \\bowtie \\cdots \\bowtie r_{n}\n$$  \n\nAnswer: Consider some tuple $t$ in $u.$ Note that $r_{i} = \\Pi_{R_{i}}(u)$ implies that $t[R_{i}] \\in r_{i}, 1 \\leq i \\leq n.$ Thus,  \n\n$$\nt[R_{1}] \\bowtie t[R_{2}] \\bowtie \\ldots \\bowtie t[R_{n}] \\in r_{1} \\bowtie r_{2} \\bowtie \\ldots \\bowtie r_{n}\n$$  \n\nBy the definition of natural join  \n\n$$\nt[R_{1}] \\bowtie t[R_{2}] \\bowtie \\ldots \\bowtie t[R_{n}] = \\Pi_{\\alpha}\\left(\\sigma_{\\beta}\\left(t[R_{1}] \\times t[R_{2}] \\times \\ldots \\times t[R_{n}]\\right)\\right)\n$$  \n\nwhere the condition $\\beta$ is satisfied if values of attributes with the same name in a tuple are equal and where $\\alpha = U.$ The cartesian product of single tuples generates one tuple. The selection process is satisfied because all attributes with the same name must have the same value since they are projections from the same tuple. Finally, the projection clause removes duplicate attribute names.  \n\nBy the definition of decomposition, $U = R_{1} \\cup R_{2} \\cup \\ldots \\cup R_{n},$ which means that all attributes of $t$ are in $t[R_{1}] \\bowtie t[R_{2}] \\bowtie \\ldots \\bowtie t[R_{n}].$ That is, $t$ is equal to the result of this join.  \n\nSince $t$ is any arbitrary tuple in $u,$  \n\n$$\nu \\subseteq r_{1} \\bowtie r_{2} \\bowtie \\ldots \\bowtie r_{n}\n$$  \n\n8.13 Show that the decomposition in Practice Exercise 8.1 is not a dependency-preserving decomposition.  \n\nAnswer: The dependency $B \\rightarrow D$ is not preserved. $F_{1},$ the restriction of $F$ to $(A, B, C)$ is $A \\rightarrow A B C, A \\rightarrow A B, A \\rightarrow A C, A \\rightarrow B C,$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Show that the decomposition in Practice Exercise 8.1 is not a dependency-preserving decomposition.\n\nAnswer: The dependency $B \\rightarrow D$ is not preserved.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/8s.pdf_5",
        "ID": "0bf4dac5-5a35-4b4d-9781-7a56697bb880",
        "questions": "What is the implication of projecting a tuple $t$ from the relation $u$ onto $R_{i}$?",
        "answers": "$r_{i} = \\Pi_{R_{i}}(u)$ implies that $t[R_{i}] \\in r_{i}, 1 \\leq i \\leq n.$",
        "context": "a. $\\alpha$ should be a primary key for $r_{1},$ and $\\alpha$ should be the foreign key from $r_{2,i}$ referencing $r_{1}.$\n\nb. If the foreign key constraint is not enforced, then a deletion of a tuple from $r_{1}$ would not have a corresponding deletion from the referencing tuples in $r_{2}.$ Instead of deleting a tuple from $r,$ this would amount to simply setting the value of $\\alpha$ to null in some tuples.\n\nc. For every schema $r_{i}(\\alpha\\beta)$ added to the schema because of a rule $\\alpha\\rightarrow\\beta,\\alpha$ should be made the primary key. Also, a candidate key $\\gamma$ for the original relation is located in some newly created relation $r_{k},$ and is a primary key for that relation. Foreign key constraints are created as follows: for each relation $r_{i}$ created above, if the primary key attributes of $r_{i}$ also occur in any other relation $r_{j},$ then a foreign key constraint is created from those attributes in $r_{j},$ referencing (the primary key of) $r_{i}.$\n\n8.12 Let $R_{1}, R_{2}, \\ldots, R_{n}$ be a decomposition of schema $U.$ Let $u(U)$ be a relation, and let $r_{i} = \\Pi_{R_{i}}(u).$ Show that  \n\n$$\nu \\subseteq r_{1} \\bowtie r_{2} \\bowtie \\cdots \\bowtie r_{n}\n$$  \n\nAnswer: Consider some tuple $t$ in $u.$ Note that $r_{i} = \\Pi_{R_{i}}(u)$ implies that $t[R_{i}] \\in r_{i}, 1 \\leq i \\leq n.$ Thus,  \n\n$$\nt[R_{1}] \\bowtie t[R_{2}] \\bowtie \\ldots \\bowtie t[R_{n}] \\in r_{1} \\bowtie r_{2} \\bowtie \\ldots \\bowtie r_{n}\n$$  \n\nBy the definition of natural join  \n\n$$\nt[R_{1}] \\bowtie t[R_{2}] \\bowtie \\ldots \\bowtie t[R_{n}] = \\Pi_{\\alpha}\\left(\\sigma_{\\beta}\\left(t[R_{1}] \\times t[R_{2}] \\times \\ldots \\times t[R_{n}]\\right)\\right)\n$$  \n\nwhere the condition $\\beta$ is satisfied if values of attributes with the same name in a tuple are equal and where $\\alpha = U.$ The cartesian product of single tuples generates one tuple. The selection process is satisfied because all attributes with the same name must have the same value since they are projections from the same tuple. Finally, the projection clause removes duplicate attribute names.  \n\nBy the definition of decomposition, $U = R_{1} \\cup R_{2} \\cup \\ldots \\cup R_{n},$ which means that all attributes of $t$ are in $t[R_{1}] \\bowtie t[R_{2}] \\bowtie \\ldots \\bowtie t[R_{n}].$ That is, $t$ is equal to the result of this join.  \n\nSince $t$ is any arbitrary tuple in $u,$  \n\n$$\nu \\subseteq r_{1} \\bowtie r_{2} \\bowtie \\ldots \\bowtie r_{n}\n$$  \n\n8.13 Show that the decomposition in Practice Exercise 8.1 is not a dependency-preserving decomposition.  \n\nAnswer: The dependency $B \\rightarrow D$ is not preserved. $F_{1},$ the restriction of $F$ to $(A, B, C)$ is $A \\rightarrow A B C, A \\rightarrow A B, A \\rightarrow A C, A \\rightarrow B C,$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Consider some tuple $t$ in $u.$ Note that $r_{i} = \\Pi_{R_{i}}(u)$ implies that $t[R_{i}] \\in r_{i}, 1 \\leq i \\leq n.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/8s.pdf_5",
        "ID": "0c0e4763-d2b2-447a-8fcf-d418da7f22c1",
        "questions": "Explain why u is a subset of the natural join operation r_1 bowtie r_2 bowtie ... bowtie r_n, given that r_i = Pi_{R_i}(u).",
        "answers": "u \\subseteq r_{1} \\bowtie r_{2} \\bowtie \\ldots \\bowtie r_{n}",
        "context": "a. $\\alpha$ should be a primary key for $r_{1},$ and $\\alpha$ should be the foreign key from $r_{2,i}$ referencing $r_{1}.$\n\nb. If the foreign key constraint is not enforced, then a deletion of a tuple from $r_{1}$ would not have a corresponding deletion from the referencing tuples in $r_{2}.$ Instead of deleting a tuple from $r,$ this would amount to simply setting the value of $\\alpha$ to null in some tuples.\n\nc. For every schema $r_{i}(\\alpha\\beta)$ added to the schema because of a rule $\\alpha\\rightarrow\\beta,\\alpha$ should be made the primary key. Also, a candidate key $\\gamma$ for the original relation is located in some newly created relation $r_{k},$ and is a primary key for that relation. Foreign key constraints are created as follows: for each relation $r_{i}$ created above, if the primary key attributes of $r_{i}$ also occur in any other relation $r_{j},$ then a foreign key constraint is created from those attributes in $r_{j},$ referencing (the primary key of) $r_{i}.$\n\n8.12 Let $R_{1}, R_{2}, \\ldots, R_{n}$ be a decomposition of schema $U.$ Let $u(U)$ be a relation, and let $r_{i} = \\Pi_{R_{i}}(u).$ Show that  \n\n$$\nu \\subseteq r_{1} \\bowtie r_{2} \\bowtie \\cdots \\bowtie r_{n}\n$$  \n\nAnswer: Consider some tuple $t$ in $u.$ Note that $r_{i} = \\Pi_{R_{i}}(u)$ implies that $t[R_{i}] \\in r_{i}, 1 \\leq i \\leq n.$ Thus,  \n\n$$\nt[R_{1}] \\bowtie t[R_{2}] \\bowtie \\ldots \\bowtie t[R_{n}] \\in r_{1} \\bowtie r_{2} \\bowtie \\ldots \\bowtie r_{n}\n$$  \n\nBy the definition of natural join  \n\n$$\nt[R_{1}] \\bowtie t[R_{2}] \\bowtie \\ldots \\bowtie t[R_{n}] = \\Pi_{\\alpha}\\left(\\sigma_{\\beta}\\left(t[R_{1}] \\times t[R_{2}] \\times \\ldots \\times t[R_{n}]\\right)\\right)\n$$  \n\nwhere the condition $\\beta$ is satisfied if values of attributes with the same name in a tuple are equal and where $\\alpha = U.$ The cartesian product of single tuples generates one tuple. The selection process is satisfied because all attributes with the same name must have the same value since they are projections from the same tuple. Finally, the projection clause removes duplicate attribute names.  \n\nBy the definition of decomposition, $U = R_{1} \\cup R_{2} \\cup \\ldots \\cup R_{n},$ which means that all attributes of $t$ are in $t[R_{1}] \\bowtie t[R_{2}] \\bowtie \\ldots \\bowtie t[R_{n}].$ That is, $t$ is equal to the result of this join.  \n\nSince $t$ is any arbitrary tuple in $u,$  \n\n$$\nu \\subseteq r_{1} \\bowtie r_{2} \\bowtie \\ldots \\bowtie r_{n}\n$$  \n\n8.13 Show that the decomposition in Practice Exercise 8.1 is not a dependency-preserving decomposition.  \n\nAnswer: The dependency $B \\rightarrow D$ is not preserved. $F_{1},$ the restriction of $F$ to $(A, B, C)$ is $A \\rightarrow A B C, A \\rightarrow A B, A \\rightarrow A C, A \\rightarrow B C,$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "u \\subseteq r_{1} \\bowtie r_{2} \\bowtie \\cdots \\bowtie r_{n}",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/8s.pdf_5",
        "ID": "0c132eec-9b19-48d8-b961-464b2c7ff2ed",
        "questions": "What is the result of the natural join operation t[R1] bowtie t[R2] bowtie ... bowtie t[Rn], as defined by the selection and projection processes?",
        "answers": "\\Pi_{\\alpha}\\left(\\sigma_{\\beta}\\left(t[R_{1}] \\times t[R_{2}] \\times \\ldots \\times t[R_{n}]\\right)\\right)",
        "context": "a. $\\alpha$ should be a primary key for $r_{1},$ and $\\alpha$ should be the foreign key from $r_{2,i}$ referencing $r_{1}.$\n\nb. If the foreign key constraint is not enforced, then a deletion of a tuple from $r_{1}$ would not have a corresponding deletion from the referencing tuples in $r_{2}.$ Instead of deleting a tuple from $r,$ this would amount to simply setting the value of $\\alpha$ to null in some tuples.\n\nc. For every schema $r_{i}(\\alpha\\beta)$ added to the schema because of a rule $\\alpha\\rightarrow\\beta,\\alpha$ should be made the primary key. Also, a candidate key $\\gamma$ for the original relation is located in some newly created relation $r_{k},$ and is a primary key for that relation. Foreign key constraints are created as follows: for each relation $r_{i}$ created above, if the primary key attributes of $r_{i}$ also occur in any other relation $r_{j},$ then a foreign key constraint is created from those attributes in $r_{j},$ referencing (the primary key of) $r_{i}.$\n\n8.12 Let $R_{1}, R_{2}, \\ldots, R_{n}$ be a decomposition of schema $U.$ Let $u(U)$ be a relation, and let $r_{i} = \\Pi_{R_{i}}(u).$ Show that  \n\n$$\nu \\subseteq r_{1} \\bowtie r_{2} \\bowtie \\cdots \\bowtie r_{n}\n$$  \n\nAnswer: Consider some tuple $t$ in $u.$ Note that $r_{i} = \\Pi_{R_{i}}(u)$ implies that $t[R_{i}] \\in r_{i}, 1 \\leq i \\leq n.$ Thus,  \n\n$$\nt[R_{1}] \\bowtie t[R_{2}] \\bowtie \\ldots \\bowtie t[R_{n}] \\in r_{1} \\bowtie r_{2} \\bowtie \\ldots \\bowtie r_{n}\n$$  \n\nBy the definition of natural join  \n\n$$\nt[R_{1}] \\bowtie t[R_{2}] \\bowtie \\ldots \\bowtie t[R_{n}] = \\Pi_{\\alpha}\\left(\\sigma_{\\beta}\\left(t[R_{1}] \\times t[R_{2}] \\times \\ldots \\times t[R_{n}]\\right)\\right)\n$$  \n\nwhere the condition $\\beta$ is satisfied if values of attributes with the same name in a tuple are equal and where $\\alpha = U.$ The cartesian product of single tuples generates one tuple. The selection process is satisfied because all attributes with the same name must have the same value since they are projections from the same tuple. Finally, the projection clause removes duplicate attribute names.  \n\nBy the definition of decomposition, $U = R_{1} \\cup R_{2} \\cup \\ldots \\cup R_{n},$ which means that all attributes of $t$ are in $t[R_{1}] \\bowtie t[R_{2}] \\bowtie \\ldots \\bowtie t[R_{n}].$ That is, $t$ is equal to the result of this join.  \n\nSince $t$ is any arbitrary tuple in $u,$  \n\n$$\nu \\subseteq r_{1} \\bowtie r_{2} \\bowtie \\ldots \\bowtie r_{n}\n$$  \n\n8.13 Show that the decomposition in Practice Exercise 8.1 is not a dependency-preserving decomposition.  \n\nAnswer: The dependency $B \\rightarrow D$ is not preserved. $F_{1},$ the restriction of $F$ to $(A, B, C)$ is $A \\rightarrow A B C, A \\rightarrow A B, A \\rightarrow A C, A \\rightarrow B C,$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "t[R_{1}] \\bowtie t[R_{2}] \\bowtie \\ldots \\bowtie t[R_{n}] = \\Pi_{\\alpha}\\left(\\sigma_{\\beta}\\left(t[R_{1}] \\times t[R_{2}] \\times \\ldots \\times t[R_{n}]\\right)\\right)",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/8s.pdf_5",
        "ID": "0c18f41d-46ab-42d9-b256-9b532370539b",
        "questions": "What is the decomposition of the schema U, given that U = R1 union R2 union ... union Rn?",
        "answers": "U = R_{1} \\cup R_{2} \\cup \\ldots \\cup R_{n}",
        "context": "a. $\\alpha$ should be a primary key for $r_{1},$ and $\\alpha$ should be the foreign key from $r_{2,i}$ referencing $r_{1}.$\n\nb. If the foreign key constraint is not enforced, then a deletion of a tuple from $r_{1}$ would not have a corresponding deletion from the referencing tuples in $r_{2}.$ Instead of deleting a tuple from $r,$ this would amount to simply setting the value of $\\alpha$ to null in some tuples.\n\nc. For every schema $r_{i}(\\alpha\\beta)$ added to the schema because of a rule $\\alpha\\rightarrow\\beta,\\alpha$ should be made the primary key. Also, a candidate key $\\gamma$ for the original relation is located in some newly created relation $r_{k},$ and is a primary key for that relation. Foreign key constraints are created as follows: for each relation $r_{i}$ created above, if the primary key attributes of $r_{i}$ also occur in any other relation $r_{j},$ then a foreign key constraint is created from those attributes in $r_{j},$ referencing (the primary key of) $r_{i}.$\n\n8.12 Let $R_{1}, R_{2}, \\ldots, R_{n}$ be a decomposition of schema $U.$ Let $u(U)$ be a relation, and let $r_{i} = \\Pi_{R_{i}}(u).$ Show that  \n\n$$\nu \\subseteq r_{1} \\bowtie r_{2} \\bowtie \\cdots \\bowtie r_{n}\n$$  \n\nAnswer: Consider some tuple $t$ in $u.$ Note that $r_{i} = \\Pi_{R_{i}}(u)$ implies that $t[R_{i}] \\in r_{i}, 1 \\leq i \\leq n.$ Thus,  \n\n$$\nt[R_{1}] \\bowtie t[R_{2}] \\bowtie \\ldots \\bowtie t[R_{n}] \\in r_{1} \\bowtie r_{2} \\bowtie \\ldots \\bowtie r_{n}\n$$  \n\nBy the definition of natural join  \n\n$$\nt[R_{1}] \\bowtie t[R_{2}] \\bowtie \\ldots \\bowtie t[R_{n}] = \\Pi_{\\alpha}\\left(\\sigma_{\\beta}\\left(t[R_{1}] \\times t[R_{2}] \\times \\ldots \\times t[R_{n}]\\right)\\right)\n$$  \n\nwhere the condition $\\beta$ is satisfied if values of attributes with the same name in a tuple are equal and where $\\alpha = U.$ The cartesian product of single tuples generates one tuple. The selection process is satisfied because all attributes with the same name must have the same value since they are projections from the same tuple. Finally, the projection clause removes duplicate attribute names.  \n\nBy the definition of decomposition, $U = R_{1} \\cup R_{2} \\cup \\ldots \\cup R_{n},$ which means that all attributes of $t$ are in $t[R_{1}] \\bowtie t[R_{2}] \\bowtie \\ldots \\bowtie t[R_{n}].$ That is, $t$ is equal to the result of this join.  \n\nSince $t$ is any arbitrary tuple in $u,$  \n\n$$\nu \\subseteq r_{1} \\bowtie r_{2} \\bowtie \\ldots \\bowtie r_{n}\n$$  \n\n8.13 Show that the decomposition in Practice Exercise 8.1 is not a dependency-preserving decomposition.  \n\nAnswer: The dependency $B \\rightarrow D$ is not preserved. $F_{1},$ the restriction of $F$ to $(A, B, C)$ is $A \\rightarrow A B C, A \\rightarrow A B, A \\rightarrow A C, A \\rightarrow B C,$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "By the definition of decomposition, U = R_{1} \\cup R_{2} \\cup \\ldots \\cup R_{n}",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/UTX_-_An_Introduction_to_Manifolds,_Second_Edition.pdf_283",
        "ID": "0c20f65e-fcdc-410b-be30-f2329d2ceb6d",
        "questions": "What is the absolute value of the Jacobi determinant of the composition of maps \u03c6 and its inverse composed with \u03c6-bar?",
        "answers": "1",
        "context": "$$\n(\\phi\\circ\\bar{\\phi}^{-1})(a^{1},a^{2},\\ldots,a^{n})=(-a^{1},a^{2},\\ldots,a^{n}),\n$$  \n\nthe absolute value of its Jacobi an determinant is  \n\n$$\n|J(\\phi\\circ\\bar{\\phi}^{-1})|=|-1|=1.\n$$  \n\nTherefore  \n\n$$\n\\begin{array}{r l}&{\\displaystyle\\int_{\\bar{\\phi}(U)}\\left(\\bar{\\phi}^{-1}\\right)^{*}\\tau=-\\displaystyle\\int_{\\bar{\\phi}(U)}\\left(f\\circ\\bar{\\phi}^{-1}\\right)d r^{1}\\cdots d r^{n}\\quad\\mathrm{(by~(23.9))}}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad=-\\displaystyle\\int_{\\bar{\\phi}(U)}(f\\circ\\phi^{-1})\\circ(\\phi\\circ\\bar{\\phi}^{-1})|J(\\phi\\circ\\bar{\\phi}^{-1})|\\,d r^{1}\\cdots d r^{n}\\quad\\mathrm{(by~(23.9))}}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad=-\\displaystyle\\int_{\\phi(U)}(f\\circ\\phi^{-1})\\,d r^{1}\\cdots d r^{n}\\quad\\mathrm{(by~the~change-of-variables~for~\\phi~)}}\\\\ &{\\quad\\quad\\quad\\quad=-\\displaystyle\\int_{\\phi(U)}\\left(\\phi^{-1}\\right)^{*}\\tau.}\\end{array}\n$$  \n\nThe treatment of integration above can be extended almost word for word to oriented manifolds with boundary. It has the virtue of simplicity and is of great utility in proving theorems. However, it is not practical for actual computation of integrals; an $n$ -form multiplied by a partition of unity can rarely be integrated as a closed expression. To calculate explicitly integrals over an oriented $n$ -manifold $M$, it is best to consider integrals over a parametrized set.  \n\nDefinition 23.1o. A parametrized set in an oriented $n$ -manifold $M$ is a subset A together with a $C^{\\infty}$ map $F\\colon D\\to M$ from a compact domain of integration $D\\subset\\mathbb{R}^{n}$ to $M$ such that $A=F(D)$ and $F$ restricts to an orientation-preserving diffeomorphism from $\\operatorname{int}(D)$ to $F(\\mathrm{int}(D))$. Note that by smooth invariance of domain for manifolds (Remark 22.5), $F(\\mathrm{int}(D))$ is an open subset of $M$. The $C^{\\infty}$ map $F:D\\rightarrow A$ is called a parametrization of $A$.  \n\nIf $A$ is a parametrized set in $M$ with parametrization $F\\colon D\\rightarrow A$ and $\\omega$ is a $C^{\\infty}\\,n,$ form on $M$, not necessarily with compact support, then we define $\\textstyle\\int_{A}\\omega$ to be $\\scriptstyle\\int_{D}F^{*}\\omega$. It can be shown that the definition of $\\textstyle\\int_{A}\\omega$ is independent of the parametrization and that in case $A$ is a manifold, it agrees with the earlier definition of integration over a manifold. Subdividing an oriented manifold into a union of parametrized sets can be an effective method of calculating an integral over the manifold. We will not delve into this theory of integration (see [31, Theorem 25.4, p. 213] or [25 Proposition 14.7, p. 356]), but will content ourselves with an example.  \n\nExample 23.11 (Integral over a sphere). In spherical coordinates, $\\rho$ is the distance $\\sqrt{x^{2}+y^{2}+z^{2}}$ of the point $(x,y,z)\\in\\mathbb{R}^{3}$ to the origin, $\\varphi$ is the angle that the vector $\\langle x,y,z\\rangle$ makes with the positive $\\zeta$ -axis, and $\\theta$ is the angle that the vector $\\langle x,y\\rangle$ in the $(x,y)$ -plane makes with the positive $x$ -axis (Figure 23.3(a)). Let $\\omega$ be the 2-form on the unit sphere $S^{2}$ in $\\mathbb{R}^{3}$ given by",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Numeric",
        "evidence_source": "equation",
        "evidence_context": "$$|J(\\phi\\circ\\bar{\\phi}^{-1})|=|-1|=1.$$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTX_-_An_Introduction_to_Manifolds,_Second_Edition.pdf_283",
        "ID": "0c248f08-0cf1-4812-be78-f5953c62d604",
        "questions": "In the context of oriented manifolds, how can an effective method of calculating an integral over a manifold be achieved?",
        "answers": "Subdividing an oriented manifold into a union of parametrized sets can be an effective method of calculating an integral over the manifold.",
        "context": "$$\n(\\phi\\circ\\bar{\\phi}^{-1})(a^{1},a^{2},\\ldots,a^{n})=(-a^{1},a^{2},\\ldots,a^{n}),\n$$  \n\nthe absolute value of its Jacobi an determinant is  \n\n$$\n|J(\\phi\\circ\\bar{\\phi}^{-1})|=|-1|=1.\n$$  \n\nTherefore  \n\n$$\n\\begin{array}{r l}&{\\displaystyle\\int_{\\bar{\\phi}(U)}\\left(\\bar{\\phi}^{-1}\\right)^{*}\\tau=-\\displaystyle\\int_{\\bar{\\phi}(U)}\\left(f\\circ\\bar{\\phi}^{-1}\\right)d r^{1}\\cdots d r^{n}\\quad\\mathrm{(by~(23.9))}}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad=-\\displaystyle\\int_{\\bar{\\phi}(U)}(f\\circ\\phi^{-1})\\circ(\\phi\\circ\\bar{\\phi}^{-1})|J(\\phi\\circ\\bar{\\phi}^{-1})|\\,d r^{1}\\cdots d r^{n}\\quad\\mathrm{(by~(23.9))}}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad=-\\displaystyle\\int_{\\phi(U)}(f\\circ\\phi^{-1})\\,d r^{1}\\cdots d r^{n}\\quad\\mathrm{(by~the~change-of-variables~for~\\phi~)}}\\\\ &{\\quad\\quad\\quad\\quad=-\\displaystyle\\int_{\\phi(U)}\\left(\\phi^{-1}\\right)^{*}\\tau.}\\end{array}\n$$  \n\nThe treatment of integration above can be extended almost word for word to oriented manifolds with boundary. It has the virtue of simplicity and is of great utility in proving theorems. However, it is not practical for actual computation of integrals; an $n$ -form multiplied by a partition of unity can rarely be integrated as a closed expression. To calculate explicitly integrals over an oriented $n$ -manifold $M$, it is best to consider integrals over a parametrized set.  \n\nDefinition 23.1o. A parametrized set in an oriented $n$ -manifold $M$ is a subset A together with a $C^{\\infty}$ map $F\\colon D\\to M$ from a compact domain of integration $D\\subset\\mathbb{R}^{n}$ to $M$ such that $A=F(D)$ and $F$ restricts to an orientation-preserving diffeomorphism from $\\operatorname{int}(D)$ to $F(\\mathrm{int}(D))$. Note that by smooth invariance of domain for manifolds (Remark 22.5), $F(\\mathrm{int}(D))$ is an open subset of $M$. The $C^{\\infty}$ map $F:D\\rightarrow A$ is called a parametrization of $A$.  \n\nIf $A$ is a parametrized set in $M$ with parametrization $F\\colon D\\rightarrow A$ and $\\omega$ is a $C^{\\infty}\\,n,$ form on $M$, not necessarily with compact support, then we define $\\textstyle\\int_{A}\\omega$ to be $\\scriptstyle\\int_{D}F^{*}\\omega$. It can be shown that the definition of $\\textstyle\\int_{A}\\omega$ is independent of the parametrization and that in case $A$ is a manifold, it agrees with the earlier definition of integration over a manifold. Subdividing an oriented manifold into a union of parametrized sets can be an effective method of calculating an integral over the manifold. We will not delve into this theory of integration (see [31, Theorem 25.4, p. 213] or [25 Proposition 14.7, p. 356]), but will content ourselves with an example.  \n\nExample 23.11 (Integral over a sphere). In spherical coordinates, $\\rho$ is the distance $\\sqrt{x^{2}+y^{2}+z^{2}}$ of the point $(x,y,z)\\in\\mathbb{R}^{3}$ to the origin, $\\varphi$ is the angle that the vector $\\langle x,y,z\\rangle$ makes with the positive $\\zeta$ -axis, and $\\theta$ is the angle that the vector $\\langle x,y\\rangle$ in the $(x,y)$ -plane makes with the positive $x$ -axis (Figure 23.3(a)). Let $\\omega$ be the 2-form on the unit sphere $S^{2}$ in $\\mathbb{R}^{3}$ given by",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Subdividing an oriented manifold into a union of parametrized sets can be an effective method of calculating an integral over the manifold.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTX_-_An_Introduction_to_Manifolds,_Second_Edition.pdf_283",
        "ID": "0c35a424-a158-472b-b965-44a7834d88db",
        "questions": "What is the definition of a parametrized set in an oriented n-manifold M according to Definition 23.1o and what properties must the map F have?",
        "answers": "A parametrized set in an oriented n-manifold M is a subset A together with a \\(C^{\\infty}\\) map \\(F: D \to M\\) from a compact domain of integration \\(D \\subset \\mathbb{R}^{n}\\) to M such that \\(A = F(D)\\) and F restricts to an orientation-preserving diffeomorphism from \\(\\operatorname{int}(D)\\) to \\(F(\\mathrm{int}(D))\\)",
        "context": "$$\n(\\phi\\circ\\bar{\\phi}^{-1})(a^{1},a^{2},\\ldots,a^{n})=(-a^{1},a^{2},\\ldots,a^{n}),\n$$  \n\nthe absolute value of its Jacobi an determinant is  \n\n$$\n|J(\\phi\\circ\\bar{\\phi}^{-1})|=|-1|=1.\n$$  \n\nTherefore  \n\n$$\n\\begin{array}{r l}&{\\displaystyle\\int_{\\bar{\\phi}(U)}\\left(\\bar{\\phi}^{-1}\\right)^{*}\\tau=-\\displaystyle\\int_{\\bar{\\phi}(U)}\\left(f\\circ\\bar{\\phi}^{-1}\\right)d r^{1}\\cdots d r^{n}\\quad\\mathrm{(by~(23.9))}}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad=-\\displaystyle\\int_{\\bar{\\phi}(U)}(f\\circ\\phi^{-1})\\circ(\\phi\\circ\\bar{\\phi}^{-1})|J(\\phi\\circ\\bar{\\phi}^{-1})|\\,d r^{1}\\cdots d r^{n}\\quad\\mathrm{(by~(23.9))}}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad=-\\displaystyle\\int_{\\phi(U)}(f\\circ\\phi^{-1})\\,d r^{1}\\cdots d r^{n}\\quad\\mathrm{(by~the~change-of-variables~for~\\phi~)}}\\\\ &{\\quad\\quad\\quad\\quad=-\\displaystyle\\int_{\\phi(U)}\\left(\\phi^{-1}\\right)^{*}\\tau.}\\end{array}\n$$  \n\nThe treatment of integration above can be extended almost word for word to oriented manifolds with boundary. It has the virtue of simplicity and is of great utility in proving theorems. However, it is not practical for actual computation of integrals; an $n$ -form multiplied by a partition of unity can rarely be integrated as a closed expression. To calculate explicitly integrals over an oriented $n$ -manifold $M$, it is best to consider integrals over a parametrized set.  \n\nDefinition 23.1o. A parametrized set in an oriented $n$ -manifold $M$ is a subset A together with a $C^{\\infty}$ map $F\\colon D\\to M$ from a compact domain of integration $D\\subset\\mathbb{R}^{n}$ to $M$ such that $A=F(D)$ and $F$ restricts to an orientation-preserving diffeomorphism from $\\operatorname{int}(D)$ to $F(\\mathrm{int}(D))$. Note that by smooth invariance of domain for manifolds (Remark 22.5), $F(\\mathrm{int}(D))$ is an open subset of $M$. The $C^{\\infty}$ map $F:D\\rightarrow A$ is called a parametrization of $A$.  \n\nIf $A$ is a parametrized set in $M$ with parametrization $F\\colon D\\rightarrow A$ and $\\omega$ is a $C^{\\infty}\\,n,$ form on $M$, not necessarily with compact support, then we define $\\textstyle\\int_{A}\\omega$ to be $\\scriptstyle\\int_{D}F^{*}\\omega$. It can be shown that the definition of $\\textstyle\\int_{A}\\omega$ is independent of the parametrization and that in case $A$ is a manifold, it agrees with the earlier definition of integration over a manifold. Subdividing an oriented manifold into a union of parametrized sets can be an effective method of calculating an integral over the manifold. We will not delve into this theory of integration (see [31, Theorem 25.4, p. 213] or [25 Proposition 14.7, p. 356]), but will content ourselves with an example.  \n\nExample 23.11 (Integral over a sphere). In spherical coordinates, $\\rho$ is the distance $\\sqrt{x^{2}+y^{2}+z^{2}}$ of the point $(x,y,z)\\in\\mathbb{R}^{3}$ to the origin, $\\varphi$ is the angle that the vector $\\langle x,y,z\\rangle$ makes with the positive $\\zeta$ -axis, and $\\theta$ is the angle that the vector $\\langle x,y\\rangle$ in the $(x,y)$ -plane makes with the positive $x$ -axis (Figure 23.3(a)). Let $\\omega$ be the 2-form on the unit sphere $S^{2}$ in $\\mathbb{R}^{3}$ given by",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "A parametrized set in an oriented $n$ -manifold $M$ is a subset A together with a $C^{\\infty}$ map $F\\colon D\to M$ from a compact domain of integration $D\\subset\\mathbb{R}^{n}$ to $M$ such that $A=F(D)$ and $F$ restricts to an orientation-preserving diffeomorphism from $\\operatorname{int}(D)$ to $F(\\mathrm{int}(D))$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTX_-_An_Introduction_to_Manifolds,_Second_Edition.pdf_283",
        "ID": "0c377a52-6fed-4601-8d41-c1455a1a0983",
        "questions": "What is the absolute value of the Jacobi determinant of the function \\( \\phi \\circ \bar{\\phi}^{-1} \\)?",
        "answers": "|J(\\phi\\circ\bar{\\phi}^{-1})|=|-1|=1.",
        "context": "$$\n(\\phi\\circ\\bar{\\phi}^{-1})(a^{1},a^{2},\\ldots,a^{n})=(-a^{1},a^{2},\\ldots,a^{n}),\n$$  \n\nthe absolute value of its Jacobi an determinant is  \n\n$$\n|J(\\phi\\circ\\bar{\\phi}^{-1})|=|-1|=1.\n$$  \n\nTherefore  \n\n$$\n\\begin{array}{r l}&{\\displaystyle\\int_{\\bar{\\phi}(U)}\\left(\\bar{\\phi}^{-1}\\right)^{*}\\tau=-\\displaystyle\\int_{\\bar{\\phi}(U)}\\left(f\\circ\\bar{\\phi}^{-1}\\right)d r^{1}\\cdots d r^{n}\\quad\\mathrm{(by~(23.9))}}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad=-\\displaystyle\\int_{\\bar{\\phi}(U)}(f\\circ\\phi^{-1})\\circ(\\phi\\circ\\bar{\\phi}^{-1})|J(\\phi\\circ\\bar{\\phi}^{-1})|\\,d r^{1}\\cdots d r^{n}\\quad\\mathrm{(by~(23.9))}}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad=-\\displaystyle\\int_{\\phi(U)}(f\\circ\\phi^{-1})\\,d r^{1}\\cdots d r^{n}\\quad\\mathrm{(by~the~change-of-variables~for~\\phi~)}}\\\\ &{\\quad\\quad\\quad\\quad=-\\displaystyle\\int_{\\phi(U)}\\left(\\phi^{-1}\\right)^{*}\\tau.}\\end{array}\n$$  \n\nThe treatment of integration above can be extended almost word for word to oriented manifolds with boundary. It has the virtue of simplicity and is of great utility in proving theorems. However, it is not practical for actual computation of integrals; an $n$ -form multiplied by a partition of unity can rarely be integrated as a closed expression. To calculate explicitly integrals over an oriented $n$ -manifold $M$, it is best to consider integrals over a parametrized set.  \n\nDefinition 23.1o. A parametrized set in an oriented $n$ -manifold $M$ is a subset A together with a $C^{\\infty}$ map $F\\colon D\\to M$ from a compact domain of integration $D\\subset\\mathbb{R}^{n}$ to $M$ such that $A=F(D)$ and $F$ restricts to an orientation-preserving diffeomorphism from $\\operatorname{int}(D)$ to $F(\\mathrm{int}(D))$. Note that by smooth invariance of domain for manifolds (Remark 22.5), $F(\\mathrm{int}(D))$ is an open subset of $M$. The $C^{\\infty}$ map $F:D\\rightarrow A$ is called a parametrization of $A$.  \n\nIf $A$ is a parametrized set in $M$ with parametrization $F\\colon D\\rightarrow A$ and $\\omega$ is a $C^{\\infty}\\,n,$ form on $M$, not necessarily with compact support, then we define $\\textstyle\\int_{A}\\omega$ to be $\\scriptstyle\\int_{D}F^{*}\\omega$. It can be shown that the definition of $\\textstyle\\int_{A}\\omega$ is independent of the parametrization and that in case $A$ is a manifold, it agrees with the earlier definition of integration over a manifold. Subdividing an oriented manifold into a union of parametrized sets can be an effective method of calculating an integral over the manifold. We will not delve into this theory of integration (see [31, Theorem 25.4, p. 213] or [25 Proposition 14.7, p. 356]), but will content ourselves with an example.  \n\nExample 23.11 (Integral over a sphere). In spherical coordinates, $\\rho$ is the distance $\\sqrt{x^{2}+y^{2}+z^{2}}$ of the point $(x,y,z)\\in\\mathbb{R}^{3}$ to the origin, $\\varphi$ is the angle that the vector $\\langle x,y,z\\rangle$ makes with the positive $\\zeta$ -axis, and $\\theta$ is the angle that the vector $\\langle x,y\\rangle$ in the $(x,y)$ -plane makes with the positive $x$ -axis (Figure 23.3(a)). Let $\\omega$ be the 2-form on the unit sphere $S^{2}$ in $\\mathbb{R}^{3}$ given by",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Numeric",
        "evidence_source": "equation",
        "evidence_context": "|J(\\phi\\circ\bar{\\phi}^{-1})|=|-1|=1.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/UTX_-_An_Introduction_to_Manifolds,_Second_Edition.pdf_283",
        "ID": "0c45d498-dc4a-4227-a0c6-4521e94ba284",
        "questions": "Calculate the result of integrating \\((f \\circ \\phi^{-1}) \\circ (\\phi \\circ \bar{\\phi}^{-1}) |J(\\phi \\circ \bar{\\phi}^{-1})| d r^{1} \\cdots d r^{n} \\) over \\(\\phi(U)\\).",
        "answers": "-\\displaystyle\\int_{\\phi(U)}\\left(\\phi^{-1}\\right)^{*}\\tau.",
        "context": "$$\n(\\phi\\circ\\bar{\\phi}^{-1})(a^{1},a^{2},\\ldots,a^{n})=(-a^{1},a^{2},\\ldots,a^{n}),\n$$  \n\nthe absolute value of its Jacobi an determinant is  \n\n$$\n|J(\\phi\\circ\\bar{\\phi}^{-1})|=|-1|=1.\n$$  \n\nTherefore  \n\n$$\n\\begin{array}{r l}&{\\displaystyle\\int_{\\bar{\\phi}(U)}\\left(\\bar{\\phi}^{-1}\\right)^{*}\\tau=-\\displaystyle\\int_{\\bar{\\phi}(U)}\\left(f\\circ\\bar{\\phi}^{-1}\\right)d r^{1}\\cdots d r^{n}\\quad\\mathrm{(by~(23.9))}}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad=-\\displaystyle\\int_{\\bar{\\phi}(U)}(f\\circ\\phi^{-1})\\circ(\\phi\\circ\\bar{\\phi}^{-1})|J(\\phi\\circ\\bar{\\phi}^{-1})|\\,d r^{1}\\cdots d r^{n}\\quad\\mathrm{(by~(23.9))}}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad=-\\displaystyle\\int_{\\phi(U)}(f\\circ\\phi^{-1})\\,d r^{1}\\cdots d r^{n}\\quad\\mathrm{(by~the~change-of-variables~for~\\phi~)}}\\\\ &{\\quad\\quad\\quad\\quad=-\\displaystyle\\int_{\\phi(U)}\\left(\\phi^{-1}\\right)^{*}\\tau.}\\end{array}\n$$  \n\nThe treatment of integration above can be extended almost word for word to oriented manifolds with boundary. It has the virtue of simplicity and is of great utility in proving theorems. However, it is not practical for actual computation of integrals; an $n$ -form multiplied by a partition of unity can rarely be integrated as a closed expression. To calculate explicitly integrals over an oriented $n$ -manifold $M$, it is best to consider integrals over a parametrized set.  \n\nDefinition 23.1o. A parametrized set in an oriented $n$ -manifold $M$ is a subset A together with a $C^{\\infty}$ map $F\\colon D\\to M$ from a compact domain of integration $D\\subset\\mathbb{R}^{n}$ to $M$ such that $A=F(D)$ and $F$ restricts to an orientation-preserving diffeomorphism from $\\operatorname{int}(D)$ to $F(\\mathrm{int}(D))$. Note that by smooth invariance of domain for manifolds (Remark 22.5), $F(\\mathrm{int}(D))$ is an open subset of $M$. The $C^{\\infty}$ map $F:D\\rightarrow A$ is called a parametrization of $A$.  \n\nIf $A$ is a parametrized set in $M$ with parametrization $F\\colon D\\rightarrow A$ and $\\omega$ is a $C^{\\infty}\\,n,$ form on $M$, not necessarily with compact support, then we define $\\textstyle\\int_{A}\\omega$ to be $\\scriptstyle\\int_{D}F^{*}\\omega$. It can be shown that the definition of $\\textstyle\\int_{A}\\omega$ is independent of the parametrization and that in case $A$ is a manifold, it agrees with the earlier definition of integration over a manifold. Subdividing an oriented manifold into a union of parametrized sets can be an effective method of calculating an integral over the manifold. We will not delve into this theory of integration (see [31, Theorem 25.4, p. 213] or [25 Proposition 14.7, p. 356]), but will content ourselves with an example.  \n\nExample 23.11 (Integral over a sphere). In spherical coordinates, $\\rho$ is the distance $\\sqrt{x^{2}+y^{2}+z^{2}}$ of the point $(x,y,z)\\in\\mathbb{R}^{3}$ to the origin, $\\varphi$ is the angle that the vector $\\langle x,y,z\\rangle$ makes with the positive $\\zeta$ -axis, and $\\theta$ is the angle that the vector $\\langle x,y\\rangle$ in the $(x,y)$ -plane makes with the positive $x$ -axis (Figure 23.3(a)). Let $\\omega$ be the 2-form on the unit sphere $S^{2}$ in $\\mathbb{R}^{3}$ given by",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "&{\\quad\\quad\\quad\\quad=-\\displaystyle\\int_{\\phi(U)}\\left(\\phi^{-1}\\right)^{*}\\tau.}",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/UTX_-_An_Introduction_to_Manifolds,_Second_Edition.pdf_283",
        "ID": "0c4a3950-345d-4816-80ed-b229b6b54cde",
        "questions": "Describe the conditions under which the definition of \\( \\int_{A} \\omega \\) is shown to be independent of the parametrization and when it agrees with the earlier definition of integration over a manifold.",
        "answers": "It can be shown that the definition of \\( \\int_{A} \\omega \\) is independent of the parametrization and that in case A is a manifold, it agrees with the earlier definition of integration over a manifold.",
        "context": "$$\n(\\phi\\circ\\bar{\\phi}^{-1})(a^{1},a^{2},\\ldots,a^{n})=(-a^{1},a^{2},\\ldots,a^{n}),\n$$  \n\nthe absolute value of its Jacobi an determinant is  \n\n$$\n|J(\\phi\\circ\\bar{\\phi}^{-1})|=|-1|=1.\n$$  \n\nTherefore  \n\n$$\n\\begin{array}{r l}&{\\displaystyle\\int_{\\bar{\\phi}(U)}\\left(\\bar{\\phi}^{-1}\\right)^{*}\\tau=-\\displaystyle\\int_{\\bar{\\phi}(U)}\\left(f\\circ\\bar{\\phi}^{-1}\\right)d r^{1}\\cdots d r^{n}\\quad\\mathrm{(by~(23.9))}}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad=-\\displaystyle\\int_{\\bar{\\phi}(U)}(f\\circ\\phi^{-1})\\circ(\\phi\\circ\\bar{\\phi}^{-1})|J(\\phi\\circ\\bar{\\phi}^{-1})|\\,d r^{1}\\cdots d r^{n}\\quad\\mathrm{(by~(23.9))}}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad=-\\displaystyle\\int_{\\phi(U)}(f\\circ\\phi^{-1})\\,d r^{1}\\cdots d r^{n}\\quad\\mathrm{(by~the~change-of-variables~for~\\phi~)}}\\\\ &{\\quad\\quad\\quad\\quad=-\\displaystyle\\int_{\\phi(U)}\\left(\\phi^{-1}\\right)^{*}\\tau.}\\end{array}\n$$  \n\nThe treatment of integration above can be extended almost word for word to oriented manifolds with boundary. It has the virtue of simplicity and is of great utility in proving theorems. However, it is not practical for actual computation of integrals; an $n$ -form multiplied by a partition of unity can rarely be integrated as a closed expression. To calculate explicitly integrals over an oriented $n$ -manifold $M$, it is best to consider integrals over a parametrized set.  \n\nDefinition 23.1o. A parametrized set in an oriented $n$ -manifold $M$ is a subset A together with a $C^{\\infty}$ map $F\\colon D\\to M$ from a compact domain of integration $D\\subset\\mathbb{R}^{n}$ to $M$ such that $A=F(D)$ and $F$ restricts to an orientation-preserving diffeomorphism from $\\operatorname{int}(D)$ to $F(\\mathrm{int}(D))$. Note that by smooth invariance of domain for manifolds (Remark 22.5), $F(\\mathrm{int}(D))$ is an open subset of $M$. The $C^{\\infty}$ map $F:D\\rightarrow A$ is called a parametrization of $A$.  \n\nIf $A$ is a parametrized set in $M$ with parametrization $F\\colon D\\rightarrow A$ and $\\omega$ is a $C^{\\infty}\\,n,$ form on $M$, not necessarily with compact support, then we define $\\textstyle\\int_{A}\\omega$ to be $\\scriptstyle\\int_{D}F^{*}\\omega$. It can be shown that the definition of $\\textstyle\\int_{A}\\omega$ is independent of the parametrization and that in case $A$ is a manifold, it agrees with the earlier definition of integration over a manifold. Subdividing an oriented manifold into a union of parametrized sets can be an effective method of calculating an integral over the manifold. We will not delve into this theory of integration (see [31, Theorem 25.4, p. 213] or [25 Proposition 14.7, p. 356]), but will content ourselves with an example.  \n\nExample 23.11 (Integral over a sphere). In spherical coordinates, $\\rho$ is the distance $\\sqrt{x^{2}+y^{2}+z^{2}}$ of the point $(x,y,z)\\in\\mathbb{R}^{3}$ to the origin, $\\varphi$ is the angle that the vector $\\langle x,y,z\\rangle$ makes with the positive $\\zeta$ -axis, and $\\theta$ is the angle that the vector $\\langle x,y\\rangle$ in the $(x,y)$ -plane makes with the positive $x$ -axis (Figure 23.3(a)). Let $\\omega$ be the 2-form on the unit sphere $S^{2}$ in $\\mathbb{R}^{3}$ given by",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "It can be shown that the definition of \\( \\int_{A} \\omega \\) is independent of the parametrization and that in case A is a manifold, it agrees with the earlier definition of integration over a manifold.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/GTM5-Categories_for_the_Working_Mathematician1978.pdf_236",
        "ID": "0c4b6a95-c05b-4264-8ca3-6ecb40b7dbc2",
        "questions": "What is the isomorphism in the given diagram for the functor S: P^op x P x C^op x C to X called?",
        "answers": "theta",
        "context": "# 8. Iterated Ends and Limits  \n\nWe now describe when the \u201cdouble integral\u201d can be obtained as an \"iterated\" integral (Fubini!)  \n\nProposition. Let $S: P^{\\mathrm{op}} \\times P \\times C^{\\mathrm{op}} \\times C \\rightarrow X$ be a functor such that the end $\\int_{c} S(p, q, c, c)$ exists for all pairs $\\langle p, q \\rangle$ of objects of $P$; by the parameter theorems, regard these ends as a bifunctor $P^{\\mathrm{op}} \\times P \\rightarrow X$, and regard $s$ as a bifunctor $(P \\times C)^{\\mathrm{op}} \\times (P \\times C) \\rightarrow X$. Then there is an isomorphism  \n\n$$\n\\theta: \\int_{\\langle p, c \\rangle} S(p, c, p, c) \\cong \\int_{p} \\left[ \\int_{c} S(p, p, c, c) \\right].\n$$  \n\nIndeed, the \"double end\" on the left exists if and only if the end $\\int_{p}$ on the right exists, and then there is a unique arrow $\\theta$ in $X$ such that the diagram  \n\n$$\n\\begin{array}{ccccc}\n{\\int_{\\langle p, c \\rangle} S(p, p, c, c)}&{{}}&{\\xrightarrow{\\xi_{\\langle p, c \\rangle}}}&{{}}&{S(p, p, c, c)} \\\\\n\\theta \\downarrow&{{}}&{{}}&{{}}&{{\\parallel}}\\\\\n{\\int_{p}\\left[\\int_c S(p, p, c, c)\\right]}&{\\xrightarrow{\\varrho_{p}}}&{\\int_{c} S(p, p, c, c)}&{\\xrightarrow{\\omega_{p, p, c}}}&{S(p, p, c, c)}\n\\end{array}\n$$  \n\ncommutes, where the horizontal arrows $\\xi, \\varrho$ and $\\omega$ are the universal wedges belonging to the corresponding ends; moreover, the arrow $\\theta$ is an isomorphism.  \n\nProof. For each $\\langle p, q \\rangle \\in P \\times P$ we are given the end  \n\n$$\n\\omega_{p, q}: \\int_{c} S(p, q, c, c) \\rightarrow S(p, q, \\mathrm{-}, \\mathrm{-}).\n$$  \n\nFor any $x \\in X$, each $P$-indexed family $\\rho_{p}: x \\rightarrow \\int_{c} S(p, p, c, c)$ of arrows of $X$ determines a $(P \\times C)$-indexed family $\\xi_{p, c}$ as the composites  \n\n$$\n\\xi_{p, c}: x \\xrightarrow{\\varrho_{p}} \\int_c S(p, p, c, c) \\xrightarrow{\\omega_{p, p, c}} S(p, p, c, c);\n$$  \n\nfor $p$ fixed, $\\xi_{\\langle p, - \\rangle}$ is trivially a wedge in $c$. Conversely, since $\\omega_{p, p}$ is universal, every $(P \\times C)$-indexed family which is natural in $c$ for each $p$ is such a composite, for a unique family $\\varrho$. Now $\\varrho$ or $\\xi$ is extranatural in $p$ (the latter for some $c$) if and only if the corresponding square below  \n\n$$\n\\begin{array}{c c c}\n{{x}}&{{\\xrightarrow{\\varrho_{p}}}}&{{\\int_{c} S(p, p, c, c)}} \\\\\n{{\\varrho_{q} \\downarrow}}&{{}}&{{\\downarrow\\int_{c} S(p, s, c, c)}}\\\\\n{{\\int_{c} S(q, q, c, c)}}&{{\\xrightarrow[\\int_{c}-]{}}}&{{\\int_{c} S(p, q, c, c)}}\n\\end{array}\n$$\n\n$$\n\\begin{array}{c c c}\n{{x}}&{{\\xrightarrow{\\xi_{p, c}}}}&{{\\int_{c} S(p, p, c, c)}} \\\\\n{{\\xi_{p,c} \\downarrow}}&{{}}&{{\\downarrow\\int_{c} S(p, s, c, c)}}\\\\\n{{\\int_{c} S(q, q, c, c)}}&{{\\xrightarrow[\\int_{c} S(s, q, c, c)]{}}}&{{\\int_{c} S(p, q, c, c)}}\n\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Then there is an isomorphism $\n\\theta: \\int_{\\langle p, c \\rangle} S(p, c, p, c) \\cong \\int_{p} \\left[ \\int_{c} S(p, p, c, c) \\right].$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM5-Categories_for_the_Working_Mathematician1978.pdf_236",
        "ID": "0c5a9029-c335-433b-ab17-30fef11ea92e",
        "questions": "For which pairs of objects does the end integral exist within the context of the functor S?",
        "answers": "For all pairs \u27e8p, q\u27e9 of objects of P",
        "context": "# 8. Iterated Ends and Limits  \n\nWe now describe when the \u201cdouble integral\u201d can be obtained as an \"iterated\" integral (Fubini!)  \n\nProposition. Let $S: P^{\\mathrm{op}} \\times P \\times C^{\\mathrm{op}} \\times C \\rightarrow X$ be a functor such that the end $\\int_{c} S(p, q, c, c)$ exists for all pairs $\\langle p, q \\rangle$ of objects of $P$; by the parameter theorems, regard these ends as a bifunctor $P^{\\mathrm{op}} \\times P \\rightarrow X$, and regard $s$ as a bifunctor $(P \\times C)^{\\mathrm{op}} \\times (P \\times C) \\rightarrow X$. Then there is an isomorphism  \n\n$$\n\\theta: \\int_{\\langle p, c \\rangle} S(p, c, p, c) \\cong \\int_{p} \\left[ \\int_{c} S(p, p, c, c) \\right].\n$$  \n\nIndeed, the \"double end\" on the left exists if and only if the end $\\int_{p}$ on the right exists, and then there is a unique arrow $\\theta$ in $X$ such that the diagram  \n\n$$\n\\begin{array}{ccccc}\n{\\int_{\\langle p, c \\rangle} S(p, p, c, c)}&{{}}&{\\xrightarrow{\\xi_{\\langle p, c \\rangle}}}&{{}}&{S(p, p, c, c)} \\\\\n\\theta \\downarrow&{{}}&{{}}&{{}}&{{\\parallel}}\\\\\n{\\int_{p}\\left[\\int_c S(p, p, c, c)\\right]}&{\\xrightarrow{\\varrho_{p}}}&{\\int_{c} S(p, p, c, c)}&{\\xrightarrow{\\omega_{p, p, c}}}&{S(p, p, c, c)}\n\\end{array}\n$$  \n\ncommutes, where the horizontal arrows $\\xi, \\varrho$ and $\\omega$ are the universal wedges belonging to the corresponding ends; moreover, the arrow $\\theta$ is an isomorphism.  \n\nProof. For each $\\langle p, q \\rangle \\in P \\times P$ we are given the end  \n\n$$\n\\omega_{p, q}: \\int_{c} S(p, q, c, c) \\rightarrow S(p, q, \\mathrm{-}, \\mathrm{-}).\n$$  \n\nFor any $x \\in X$, each $P$-indexed family $\\rho_{p}: x \\rightarrow \\int_{c} S(p, p, c, c)$ of arrows of $X$ determines a $(P \\times C)$-indexed family $\\xi_{p, c}$ as the composites  \n\n$$\n\\xi_{p, c}: x \\xrightarrow{\\varrho_{p}} \\int_c S(p, p, c, c) \\xrightarrow{\\omega_{p, p, c}} S(p, p, c, c);\n$$  \n\nfor $p$ fixed, $\\xi_{\\langle p, - \\rangle}$ is trivially a wedge in $c$. Conversely, since $\\omega_{p, p}$ is universal, every $(P \\times C)$-indexed family which is natural in $c$ for each $p$ is such a composite, for a unique family $\\varrho$. Now $\\varrho$ or $\\xi$ is extranatural in $p$ (the latter for some $c$) if and only if the corresponding square below  \n\n$$\n\\begin{array}{c c c}\n{{x}}&{{\\xrightarrow{\\varrho_{p}}}}&{{\\int_{c} S(p, p, c, c)}} \\\\\n{{\\varrho_{q} \\downarrow}}&{{}}&{{\\downarrow\\int_{c} S(p, s, c, c)}}\\\\\n{{\\int_{c} S(q, q, c, c)}}&{{\\xrightarrow[\\int_{c}-]{}}}&{{\\int_{c} S(p, q, c, c)}}\n\\end{array}\n$$\n\n$$\n\\begin{array}{c c c}\n{{x}}&{{\\xrightarrow{\\xi_{p, c}}}}&{{\\int_{c} S(p, p, c, c)}} \\\\\n{{\\xi_{p,c} \\downarrow}}&{{}}&{{\\downarrow\\int_{c} S(p, s, c, c)}}\\\\\n{{\\int_{c} S(q, q, c, c)}}&{{\\xrightarrow[\\int_{c} S(s, q, c, c)]{}}}&{{\\int_{c} S(p, q, c, c)}}\n\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Proposition. Let $S: P^{\\mathrm{op}} \\times P \\times C^{\\mathrm{op}} \\times C \\rightarrow X$ be a functor such that the end $\\int_{c} S(p, q, c, c)$ exists for all pairs $\\langle p, q \\rangle$ of objects of $P$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM5-Categories_for_the_Working_Mathematician1978.pdf_236",
        "ID": "0c5f152b-db9f-499f-9ea7-917eb4e6889a",
        "questions": "How does the arrow theta relate to the commutative diagram involving the functor S?",
        "answers": "The arrow theta is an isomorphism",
        "context": "# 8. Iterated Ends and Limits  \n\nWe now describe when the \u201cdouble integral\u201d can be obtained as an \"iterated\" integral (Fubini!)  \n\nProposition. Let $S: P^{\\mathrm{op}} \\times P \\times C^{\\mathrm{op}} \\times C \\rightarrow X$ be a functor such that the end $\\int_{c} S(p, q, c, c)$ exists for all pairs $\\langle p, q \\rangle$ of objects of $P$; by the parameter theorems, regard these ends as a bifunctor $P^{\\mathrm{op}} \\times P \\rightarrow X$, and regard $s$ as a bifunctor $(P \\times C)^{\\mathrm{op}} \\times (P \\times C) \\rightarrow X$. Then there is an isomorphism  \n\n$$\n\\theta: \\int_{\\langle p, c \\rangle} S(p, c, p, c) \\cong \\int_{p} \\left[ \\int_{c} S(p, p, c, c) \\right].\n$$  \n\nIndeed, the \"double end\" on the left exists if and only if the end $\\int_{p}$ on the right exists, and then there is a unique arrow $\\theta$ in $X$ such that the diagram  \n\n$$\n\\begin{array}{ccccc}\n{\\int_{\\langle p, c \\rangle} S(p, p, c, c)}&{{}}&{\\xrightarrow{\\xi_{\\langle p, c \\rangle}}}&{{}}&{S(p, p, c, c)} \\\\\n\\theta \\downarrow&{{}}&{{}}&{{}}&{{\\parallel}}\\\\\n{\\int_{p}\\left[\\int_c S(p, p, c, c)\\right]}&{\\xrightarrow{\\varrho_{p}}}&{\\int_{c} S(p, p, c, c)}&{\\xrightarrow{\\omega_{p, p, c}}}&{S(p, p, c, c)}\n\\end{array}\n$$  \n\ncommutes, where the horizontal arrows $\\xi, \\varrho$ and $\\omega$ are the universal wedges belonging to the corresponding ends; moreover, the arrow $\\theta$ is an isomorphism.  \n\nProof. For each $\\langle p, q \\rangle \\in P \\times P$ we are given the end  \n\n$$\n\\omega_{p, q}: \\int_{c} S(p, q, c, c) \\rightarrow S(p, q, \\mathrm{-}, \\mathrm{-}).\n$$  \n\nFor any $x \\in X$, each $P$-indexed family $\\rho_{p}: x \\rightarrow \\int_{c} S(p, p, c, c)$ of arrows of $X$ determines a $(P \\times C)$-indexed family $\\xi_{p, c}$ as the composites  \n\n$$\n\\xi_{p, c}: x \\xrightarrow{\\varrho_{p}} \\int_c S(p, p, c, c) \\xrightarrow{\\omega_{p, p, c}} S(p, p, c, c);\n$$  \n\nfor $p$ fixed, $\\xi_{\\langle p, - \\rangle}$ is trivially a wedge in $c$. Conversely, since $\\omega_{p, p}$ is universal, every $(P \\times C)$-indexed family which is natural in $c$ for each $p$ is such a composite, for a unique family $\\varrho$. Now $\\varrho$ or $\\xi$ is extranatural in $p$ (the latter for some $c$) if and only if the corresponding square below  \n\n$$\n\\begin{array}{c c c}\n{{x}}&{{\\xrightarrow{\\varrho_{p}}}}&{{\\int_{c} S(p, p, c, c)}} \\\\\n{{\\varrho_{q} \\downarrow}}&{{}}&{{\\downarrow\\int_{c} S(p, s, c, c)}}\\\\\n{{\\int_{c} S(q, q, c, c)}}&{{\\xrightarrow[\\int_{c}-]{}}}&{{\\int_{c} S(p, q, c, c)}}\n\\end{array}\n$$\n\n$$\n\\begin{array}{c c c}\n{{x}}&{{\\xrightarrow{\\xi_{p, c}}}}&{{\\int_{c} S(p, p, c, c)}} \\\\\n{{\\xi_{p,c} \\downarrow}}&{{}}&{{\\downarrow\\int_{c} S(p, s, c, c)}}\\\\\n{{\\int_{c} S(q, q, c, c)}}&{{\\xrightarrow[\\int_{c} S(s, q, c, c)]{}}}&{{\\int_{c} S(p, q, c, c)}}\n\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "moreover, the arrow $\\theta$ is an isomorphism.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM5-Categories_for_the_Working_Mathematician1978.pdf_236",
        "ID": "0c60a98b-9bba-450a-969d-78309b08492e",
        "questions": "For a given functor $S: P^{\\mathrm{op}} \\times P \\times C^{\\mathrm{op}} \\times C \\rightarrow X$, what is the isomorphism involving the 'double end' $\\int_{\\langle p, c \\rangle} S(p, c, p, c)$?",
        "answers": "$\\theta: \\int_{\\langle p, c \\rangle} S(p, c, p, c) \\cong \\int_{p} \\left[ \\int_{c} S(p, p, c, c) \\right]$",
        "context": "# 8. Iterated Ends and Limits  \n\nWe now describe when the \u201cdouble integral\u201d can be obtained as an \"iterated\" integral (Fubini!)  \n\nProposition. Let $S: P^{\\mathrm{op}} \\times P \\times C^{\\mathrm{op}} \\times C \\rightarrow X$ be a functor such that the end $\\int_{c} S(p, q, c, c)$ exists for all pairs $\\langle p, q \\rangle$ of objects of $P$; by the parameter theorems, regard these ends as a bifunctor $P^{\\mathrm{op}} \\times P \\rightarrow X$, and regard $s$ as a bifunctor $(P \\times C)^{\\mathrm{op}} \\times (P \\times C) \\rightarrow X$. Then there is an isomorphism  \n\n$$\n\\theta: \\int_{\\langle p, c \\rangle} S(p, c, p, c) \\cong \\int_{p} \\left[ \\int_{c} S(p, p, c, c) \\right].\n$$  \n\nIndeed, the \"double end\" on the left exists if and only if the end $\\int_{p}$ on the right exists, and then there is a unique arrow $\\theta$ in $X$ such that the diagram  \n\n$$\n\\begin{array}{ccccc}\n{\\int_{\\langle p, c \\rangle} S(p, p, c, c)}&{{}}&{\\xrightarrow{\\xi_{\\langle p, c \\rangle}}}&{{}}&{S(p, p, c, c)} \\\\\n\\theta \\downarrow&{{}}&{{}}&{{}}&{{\\parallel}}\\\\\n{\\int_{p}\\left[\\int_c S(p, p, c, c)\\right]}&{\\xrightarrow{\\varrho_{p}}}&{\\int_{c} S(p, p, c, c)}&{\\xrightarrow{\\omega_{p, p, c}}}&{S(p, p, c, c)}\n\\end{array}\n$$  \n\ncommutes, where the horizontal arrows $\\xi, \\varrho$ and $\\omega$ are the universal wedges belonging to the corresponding ends; moreover, the arrow $\\theta$ is an isomorphism.  \n\nProof. For each $\\langle p, q \\rangle \\in P \\times P$ we are given the end  \n\n$$\n\\omega_{p, q}: \\int_{c} S(p, q, c, c) \\rightarrow S(p, q, \\mathrm{-}, \\mathrm{-}).\n$$  \n\nFor any $x \\in X$, each $P$-indexed family $\\rho_{p}: x \\rightarrow \\int_{c} S(p, p, c, c)$ of arrows of $X$ determines a $(P \\times C)$-indexed family $\\xi_{p, c}$ as the composites  \n\n$$\n\\xi_{p, c}: x \\xrightarrow{\\varrho_{p}} \\int_c S(p, p, c, c) \\xrightarrow{\\omega_{p, p, c}} S(p, p, c, c);\n$$  \n\nfor $p$ fixed, $\\xi_{\\langle p, - \\rangle}$ is trivially a wedge in $c$. Conversely, since $\\omega_{p, p}$ is universal, every $(P \\times C)$-indexed family which is natural in $c$ for each $p$ is such a composite, for a unique family $\\varrho$. Now $\\varrho$ or $\\xi$ is extranatural in $p$ (the latter for some $c$) if and only if the corresponding square below  \n\n$$\n\\begin{array}{c c c}\n{{x}}&{{\\xrightarrow{\\varrho_{p}}}}&{{\\int_{c} S(p, p, c, c)}} \\\\\n{{\\varrho_{q} \\downarrow}}&{{}}&{{\\downarrow\\int_{c} S(p, s, c, c)}}\\\\\n{{\\int_{c} S(q, q, c, c)}}&{{\\xrightarrow[\\int_{c}-]{}}}&{{\\int_{c} S(p, q, c, c)}}\n\\end{array}\n$$\n\n$$\n\\begin{array}{c c c}\n{{x}}&{{\\xrightarrow{\\xi_{p, c}}}}&{{\\int_{c} S(p, p, c, c)}} \\\\\n{{\\xi_{p,c} \\downarrow}}&{{}}&{{\\downarrow\\int_{c} S(p, s, c, c)}}\\\\\n{{\\int_{c} S(q, q, c, c)}}&{{\\xrightarrow[\\int_{c} S(s, q, c, c)]{}}}&{{\\int_{c} S(p, q, c, c)}}\n\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Then there is an isomorphism   $$ \\theta: \\int_{\\langle p, c \\rangle} S(p, c, p, c) \\cong \\int_{p} \\left[ \\int_{c} S(p, p, c, c) \\right]. $$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/GTM5-Categories_for_the_Working_Mathematician1978.pdf_236",
        "ID": "0c614595-9d7c-4882-9ce3-2ac34a1e1ea7",
        "questions": "What is the composite used to determine the $(P \\times C)$-indexed family $\\xi_{p, c}$ for a given $x \\in X$?",
        "answers": "$\\xi_{p, c}: x \\xrightarrow{\\varrho_{p}} \\int_c S(p, p, c, c) \\xrightarrow{\\omega_{p, p, c}} S(p, p, c, c);$",
        "context": "# 8. Iterated Ends and Limits  \n\nWe now describe when the \u201cdouble integral\u201d can be obtained as an \"iterated\" integral (Fubini!)  \n\nProposition. Let $S: P^{\\mathrm{op}} \\times P \\times C^{\\mathrm{op}} \\times C \\rightarrow X$ be a functor such that the end $\\int_{c} S(p, q, c, c)$ exists for all pairs $\\langle p, q \\rangle$ of objects of $P$; by the parameter theorems, regard these ends as a bifunctor $P^{\\mathrm{op}} \\times P \\rightarrow X$, and regard $s$ as a bifunctor $(P \\times C)^{\\mathrm{op}} \\times (P \\times C) \\rightarrow X$. Then there is an isomorphism  \n\n$$\n\\theta: \\int_{\\langle p, c \\rangle} S(p, c, p, c) \\cong \\int_{p} \\left[ \\int_{c} S(p, p, c, c) \\right].\n$$  \n\nIndeed, the \"double end\" on the left exists if and only if the end $\\int_{p}$ on the right exists, and then there is a unique arrow $\\theta$ in $X$ such that the diagram  \n\n$$\n\\begin{array}{ccccc}\n{\\int_{\\langle p, c \\rangle} S(p, p, c, c)}&{{}}&{\\xrightarrow{\\xi_{\\langle p, c \\rangle}}}&{{}}&{S(p, p, c, c)} \\\\\n\\theta \\downarrow&{{}}&{{}}&{{}}&{{\\parallel}}\\\\\n{\\int_{p}\\left[\\int_c S(p, p, c, c)\\right]}&{\\xrightarrow{\\varrho_{p}}}&{\\int_{c} S(p, p, c, c)}&{\\xrightarrow{\\omega_{p, p, c}}}&{S(p, p, c, c)}\n\\end{array}\n$$  \n\ncommutes, where the horizontal arrows $\\xi, \\varrho$ and $\\omega$ are the universal wedges belonging to the corresponding ends; moreover, the arrow $\\theta$ is an isomorphism.  \n\nProof. For each $\\langle p, q \\rangle \\in P \\times P$ we are given the end  \n\n$$\n\\omega_{p, q}: \\int_{c} S(p, q, c, c) \\rightarrow S(p, q, \\mathrm{-}, \\mathrm{-}).\n$$  \n\nFor any $x \\in X$, each $P$-indexed family $\\rho_{p}: x \\rightarrow \\int_{c} S(p, p, c, c)$ of arrows of $X$ determines a $(P \\times C)$-indexed family $\\xi_{p, c}$ as the composites  \n\n$$\n\\xi_{p, c}: x \\xrightarrow{\\varrho_{p}} \\int_c S(p, p, c, c) \\xrightarrow{\\omega_{p, p, c}} S(p, p, c, c);\n$$  \n\nfor $p$ fixed, $\\xi_{\\langle p, - \\rangle}$ is trivially a wedge in $c$. Conversely, since $\\omega_{p, p}$ is universal, every $(P \\times C)$-indexed family which is natural in $c$ for each $p$ is such a composite, for a unique family $\\varrho$. Now $\\varrho$ or $\\xi$ is extranatural in $p$ (the latter for some $c$) if and only if the corresponding square below  \n\n$$\n\\begin{array}{c c c}\n{{x}}&{{\\xrightarrow{\\varrho_{p}}}}&{{\\int_{c} S(p, p, c, c)}} \\\\\n{{\\varrho_{q} \\downarrow}}&{{}}&{{\\downarrow\\int_{c} S(p, s, c, c)}}\\\\\n{{\\int_{c} S(q, q, c, c)}}&{{\\xrightarrow[\\int_{c}-]{}}}&{{\\int_{c} S(p, q, c, c)}}\n\\end{array}\n$$\n\n$$\n\\begin{array}{c c c}\n{{x}}&{{\\xrightarrow{\\xi_{p, c}}}}&{{\\int_{c} S(p, p, c, c)}} \\\\\n{{\\xi_{p,c} \\downarrow}}&{{}}&{{\\downarrow\\int_{c} S(p, s, c, c)}}\\\\\n{{\\int_{c} S(q, q, c, c)}}&{{\\xrightarrow[\\int_{c} S(s, q, c, c)]{}}}&{{\\int_{c} S(p, q, c, c)}}\n\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "each $P$-indexed family $\\rho_{p}: x \\rightarrow \\int_{c} S(p, p, c, c)$ of arrows of $X$ determines a $(P \\times C)$-indexed family $\\xi_{p, c}$ as the composites   $$ \\xi_{p, c}: x \\xrightarrow{\\varrho_{p}} \\int_c S(p, p, c, c) \\xrightarrow{\\omega_{p, p, c}} S(p, p, c, c); $$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/GTM5-Categories_for_the_Working_Mathematician1978.pdf_236",
        "ID": "0c64db4b-516c-4ae3-8535-245897b0d1e2",
        "questions": "In a commutative diagram involving arrows $\\xi$, $\\varrho$, and $\\omega$ for a functor $S$, what are the horizontal arrows and their roles?",
        "answers": "The horizontal arrows $\\xi$, $\\varrho$, and $\\omega$ are the universal wedges belonging to the corresponding ends.",
        "context": "# 8. Iterated Ends and Limits  \n\nWe now describe when the \u201cdouble integral\u201d can be obtained as an \"iterated\" integral (Fubini!)  \n\nProposition. Let $S: P^{\\mathrm{op}} \\times P \\times C^{\\mathrm{op}} \\times C \\rightarrow X$ be a functor such that the end $\\int_{c} S(p, q, c, c)$ exists for all pairs $\\langle p, q \\rangle$ of objects of $P$; by the parameter theorems, regard these ends as a bifunctor $P^{\\mathrm{op}} \\times P \\rightarrow X$, and regard $s$ as a bifunctor $(P \\times C)^{\\mathrm{op}} \\times (P \\times C) \\rightarrow X$. Then there is an isomorphism  \n\n$$\n\\theta: \\int_{\\langle p, c \\rangle} S(p, c, p, c) \\cong \\int_{p} \\left[ \\int_{c} S(p, p, c, c) \\right].\n$$  \n\nIndeed, the \"double end\" on the left exists if and only if the end $\\int_{p}$ on the right exists, and then there is a unique arrow $\\theta$ in $X$ such that the diagram  \n\n$$\n\\begin{array}{ccccc}\n{\\int_{\\langle p, c \\rangle} S(p, p, c, c)}&{{}}&{\\xrightarrow{\\xi_{\\langle p, c \\rangle}}}&{{}}&{S(p, p, c, c)} \\\\\n\\theta \\downarrow&{{}}&{{}}&{{}}&{{\\parallel}}\\\\\n{\\int_{p}\\left[\\int_c S(p, p, c, c)\\right]}&{\\xrightarrow{\\varrho_{p}}}&{\\int_{c} S(p, p, c, c)}&{\\xrightarrow{\\omega_{p, p, c}}}&{S(p, p, c, c)}\n\\end{array}\n$$  \n\ncommutes, where the horizontal arrows $\\xi, \\varrho$ and $\\omega$ are the universal wedges belonging to the corresponding ends; moreover, the arrow $\\theta$ is an isomorphism.  \n\nProof. For each $\\langle p, q \\rangle \\in P \\times P$ we are given the end  \n\n$$\n\\omega_{p, q}: \\int_{c} S(p, q, c, c) \\rightarrow S(p, q, \\mathrm{-}, \\mathrm{-}).\n$$  \n\nFor any $x \\in X$, each $P$-indexed family $\\rho_{p}: x \\rightarrow \\int_{c} S(p, p, c, c)$ of arrows of $X$ determines a $(P \\times C)$-indexed family $\\xi_{p, c}$ as the composites  \n\n$$\n\\xi_{p, c}: x \\xrightarrow{\\varrho_{p}} \\int_c S(p, p, c, c) \\xrightarrow{\\omega_{p, p, c}} S(p, p, c, c);\n$$  \n\nfor $p$ fixed, $\\xi_{\\langle p, - \\rangle}$ is trivially a wedge in $c$. Conversely, since $\\omega_{p, p}$ is universal, every $(P \\times C)$-indexed family which is natural in $c$ for each $p$ is such a composite, for a unique family $\\varrho$. Now $\\varrho$ or $\\xi$ is extranatural in $p$ (the latter for some $c$) if and only if the corresponding square below  \n\n$$\n\\begin{array}{c c c}\n{{x}}&{{\\xrightarrow{\\varrho_{p}}}}&{{\\int_{c} S(p, p, c, c)}} \\\\\n{{\\varrho_{q} \\downarrow}}&{{}}&{{\\downarrow\\int_{c} S(p, s, c, c)}}\\\\\n{{\\int_{c} S(q, q, c, c)}}&{{\\xrightarrow[\\int_{c}-]{}}}&{{\\int_{c} S(p, q, c, c)}}\n\\end{array}\n$$\n\n$$\n\\begin{array}{c c c}\n{{x}}&{{\\xrightarrow{\\xi_{p, c}}}}&{{\\int_{c} S(p, p, c, c)}} \\\\\n{{\\xi_{p,c} \\downarrow}}&{{}}&{{\\downarrow\\int_{c} S(p, s, c, c)}}\\\\\n{{\\int_{c} S(q, q, c, c)}}&{{\\xrightarrow[\\int_{c} S(s, q, c, c)]{}}}&{{\\int_{c} S(p, q, c, c)}}\n\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "...where the horizontal arrows $\\xi, \\varrho$ and $\\omega$ are the universal wedges belonging to the corresponding ends...",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/GTM076.Algebraic.Geometry.An.Introduction.to.Birational.Geometry.of.Algebraic.Varieties.pdf_167",
        "ID": "0c7233c7-febd-4778-9327-c6610d54f5bd",
        "questions": "What is the logarithmic m-genus of $\bar{V}$ when $\bar{V}$ is a smooth completion of a nonsingular variety $V$ with a smooth boundary $D$?",
        "answers": "$\bar{P}_{m}(\bar{V})=l_{\bar{V}}(m(K(\bar{V})+\bar{D}))$",
        "context": "When $\\bar{{V}}$ is a smooth completion of a nonsingular variety $V$ with smooth boundary $D$, the logarithmic m-genus $\\bar{P}_{m}(\\bar{V})=l_{\\bar{V}}(m(K(\\bar{V})+\\bar{D}))$ for each $m$.\n\nDefinition. The logarithmic Kodaira dimension of $V$ is defined to be $\\kappa\\{K(V)$ $+~D,~\\bar{V})_{z}$, and is denoted by $\\bar{\\kappa}(V)$.\n\nIf $\\bar{\\kappa}(V)\\geq0$, then one has $m_{0}$ with $\\bar{P}_{m_{0}(V)>0$, and $\\alpha,\\,\\beta>0$ such that\n\n$$\n\\alpha m^{\\bar{\\kappa}(V)}\\leq\\bar{P}_{m m_{0}}(V)\\leq\\beta m^{\\bar{\\kappa}(V)}\\quad\\mathrm{for}\\quad m\\gg0\n$$\n\nby Theorem 10.2. Thus $\\bar{\\kappa}(V)$ is a proper birational invariant. As a corollary to Theorem 11.2.(i), one obtains the following result\n\n# Proposition 11.4\n\n(i) If $f:$ $V\\rightarrow W$ is a strictly rational dominating morphism, then $\\bar{P}_{M}(V)\\geq\\bar{P}_{M}(W)$ and $\\bar{q}_{i}(V)\\geq\\bar{q}_{i}(W).$ for all $M$ and $i$.\n\n(ii) In addition, if $\\dim V=\\dim W$, then $\\bar{P}_{m}(V)\\geq\\bar{P}_{m}(W)$ for all $m$ and so $\\bar{\\kappa}(V)\\geq\\bar{\\kappa}(W)$.\n\n(iii) If $V_{0}$ is a dense open subset of $V$, then\n\n$$\n\\bar{q}_{i}(V_{0})\\geq\\bar{q}_{i}(V),\\quad\\bar{P}_{m}(V_{0})\\geq\\bar{P}_{m}(V),\\quad \\mathrm{and} \\quad\\bar{\\kappa}(V_{0})\\geq\\bar{\\kappa}(V).\n$$\n\nd. If $C$ is a curve, then. $\\bar{q}(C)=\\bar{p}_{g}(C),$ which is denoted by $\\bar{g}(C)$. Let $\\bar{C}$ be a nonsingular complete curve with $g=g(\\bar{{C}})$, and let $D$ be $p_{0}+\\cdots+p_{t}$ on $\\bar{C}$ such that $C=\\bar{C}\\backslash D$. Then\n\n$$\n\\bar{g}(C)=l(K(\\bar{C})+D)=1-g+2g-2+t+1-l(-D).\n$$\n\nIf $D\\neq 0$, i.e., if $C$ is not complete, then $\\bar{g}(C)=g+t$. Thus\n\n$$\n\\bar{g}(C)=0\\!\\Leftrightarrow\\!g=t=0\\!\\Leftrightarrow\\!C\\cong{\\bf A}_{k}^{1}\\!\\Leftrightarrow\\!\\bar{\\kappa}(C)=-\\infty.\n$$\n\nFurthermore, if $\\bar{g}(C)=1$, then $g=1,\\,t=0$ or $g=0,\\,t=1.$ If $g=1$, one has $\\bar{P}_{2}(C)=2(t+1)$. Hence,\n\n$$\n\\bar{g}(C)=\\bar{P}_{2}(C)=1\\!\\Leftrightarrow\\!g=0,\\;\\;\\;t=1\\!\\Leftrightarrow\\!C\\cong G_{m}\\!\\Leftrightarrow\\!\\bar{\\kappa}(C)=0.\n$$\n\nHere, $G_{m}$ denotes $\\mathrm{Spec~}k[\\mathsf{X},\\mathsf{X}^{-1}],$ called the 1-dimensional algebraic torus over $k$. Thus, one obtains the next table.\n\n$\n\\begin{tabular}{|c|c|c|}\n     \n    type & $\\bar{\\kappa}(C)$ & C \\\\\n     \n    I & $-\\infty$ & $P_k, A_k^1$ \\\\\n     \n    II & $0$ & elliptic curves, $G_m$ \\\\\n     \n    III & $1$ & the others \\\\\n     \n\\end{tabular}\n$\n\nEXAMPLE 11.4. Let $F$ be a nonconstant polynomial in n variables ${\\sf X}_{1},\\ldots,$ ${\\sf X}_{n}$. If $R$ is the integral closure of $k[F]$ in $k({\\mathsf{X}}_{1}\\,,\\,\\ldots\\,,{\\mathsf{X}}_{n}),$ then $R=k[\\psi]$ for some polynomial $\\psi$ and $F$ can be written as a polynomial in $\\psi$. In particular, $k({\\sf X}_{1},\\dots,\\,{\\sf X}_{n})/k(\\psi)$ is an algebraically closed extension of fields.\n\nThis can be easily shown as follows: $F$ determines a dominating morphism $f$ from ${\\bf A}_{k}^{n}$ to $\\mathbf{A}_{k}^{1}=C$. Then one has the Stein factorization of $f$ in the form: $\\mathbf{A}_{k}^{n}\\to\\operatorname{Spec}\\;R\\to C$. $\\operatorname{Spec}\\;R$ is a nonsingular affine curve and $\\bar{g}\\big(\\operatorname{Spec}\\;R\\big)\\leq\\bar{q}\\big(\\mathbf{A}_{k}^{n}\\big)=0$ by Proposition 11.3.(i). Thus ${\\bar{g}}(\\operatorname{Spec}\\;R)=0$, which implies $\\operatorname{Spec}\\;R\\cong\\mathbf{A}_{k}^{1}$; hence $R=k[\\psi]$\n\ne. Proposition 11.5. Let $V_{0}$ be an open subset of a nonsingular variety $V$ such that $\\operatorname{codim} (V\\backslash V_{0}^{\\ast})\\geq2.$ Then $\\bar{P}_{\\mathit{M}}(V_{0})=\\bar{P}_{\\mathit{M}}(V)$ for all $M$.\n\nPROOF. Let $j\\colon V_{0}\\longrightarrow V$ be the inclusion map. Take smooth completions $\\bar{V}_{0}$ and $\\bar{V}$ of $V_{0}$ and $V$ with smooth boundaries $D_{0}$ and $D$, respectively, such that $j$ defines a morphism $\\mu\\colon\\bar{V}_{0}\\to\\bar{V}$. Let $F$ be the closure of $V\\backslash V_{0}$ in $\\bar{V}$. Then $\\operatorname{codim}(F)\\geq2$ and so by Lemma 2.32 one has\n\n$$\n\\Gamma(\\bar{V}\\backslash F,\\,\\Omega(\\log D)^{M})=\\Gamma(\\bar{V},\\,\\Omega(\\log D)^{M})=T_{M}(V).\n$$\n\nSince $\\mu\\,|_{\\bar{{{V}}}_{0}\\backslash\\mu^{-1}(F)}:\\,\\bar{V}_{0}\\backslash\\mu^{-1}(F){\\to}\\,\\bar{V}\\backslash F$ is a proper birational morphism, $\\mu^{*}$ gives rise to an isomorphism:\n\n$$\n\\Gamma(\\bar{V}\\backslash F,\\,\\Omega(\\log\\,D)^{M})\\cong\\Gamma(\\bar{V}_{0}\\backslash\\mu^{-1}(F),\\,\\Omega(\\log\\,D)^{M}).\n$$\n\nHowever, since $\\Gamma(\\bar{V}_{0}\\backslash\\mu^{-1}(F),~\\Omega(\\log~D_{0})^{M})\\supseteq\\Gamma(\\bar{V}_{0}\\,,~\\Omega(\\log~D_{0})^{M})=T_{M}(V_{0}),$ one has $\\bar{P}_{M}(V)\\geq\\bar{P}_{M}(V_{0})$ and hence $\\bar{{\\bar{P}}}_{M}(V)=\\bar{{\\bar{P}}}_{M}(V_{0})$ by Proposition 11.4.(ii).\u53e3\n\nTheorem 11.3. Let $V$ and W be varieties with dim $V=n$ and dim $W=r$. Then $\\bar{q}(V\\,\\times\\,W)=\\bar{q}(V)+\\bar{q}(W),\\;\\bar{P}_{m}(V\\,\\times\\,W)=\\bar{P}_{m}(V)\\cdot\\bar{P}_{m}(W)$ for all $m\\geq 1$, and $\\bar{\\kappa}(V\\times W)=\\bar{\\kappa}(V)+\\bar{\\kappa}(W)$.\n\nPROOF. We can assume that both $V$ and $W$ are nonsingular. As usual, take smooth completions $\\bar{V}$ and $\\bar{W}$ of $V$ and $W$ with smooth boundaries $D$ and $B$, respectively. Then $\\mathfrak{D}=\\bar{V}\\times B+D\\times\\bar{W}$ has only simple normal crossings and $\\bar{Z}=\\bar{V}\\times\\bar{W}$ is a smooth completion of $V\\times V$ with smooth boundary $\\mathfrak{D}$. Letting $p\\colon\\bar{V}\\times\\bar{W}\\to\\bar{V}$ and $q\\colon \\bar{V}\\times \\bar{W}\\to \\bar{W}$ be projections, one has\n\n$\\Omega{\\frac{1}{\\bar{Z}}}(\\log\\mathfrak{D})=p^{*}(\\Omega{\\frac{1}{V}}(\\log D))\\oplus q^{*}(\\Omega{\\frac{1}{W}}(\\log B))$ and so $\\Omega\\frac{n+r}{Z}(\\log\\,\\mathfrak{D})=p^{\\ast}(\\Omega{\\frac{n}{V}}(\\log D))\\otimes q^{*}(\\Omega{W}(\\log\\,B))$. Therefore,\n\n$$\n\\begin{array}{r l}{\\bar{q}\\big(V\\times W\\big)}&{=\\dim_{k}\\Gamma\\big(\\bar{Z},\\,\\Omega{\\frac{1}{Z}}(\\log\\,\\mathfrak{D})\\big)}\\\\ &{=\\dim_{k}\\Gamma(\\bar{V},\\,\\Omega\\frac{1}{V}(\\log\\,D))+\\dim_{k}\\,\\Gamma(\\bar{W},\\,\\Omega\\frac{1}{W}(\\log\\,B))}\\\\ &{=\\bar{q}(V)+\\bar{q}(W).}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Equation",
        "evidence_source": "text",
        "evidence_context": "When $\bar{{V}}$ is a smooth completion of a nonsingular variety $V$ with smooth boundary $D$, the logarithmic m-genus $\bar{P}_{m}(\bar{V})=l_{\bar{V}}(m(K(\bar{V})+\bar{D}))$ for each $m$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM076.Algebraic.Geometry.An.Introduction.to.Birational.Geometry.of.Algebraic.Varieties.pdf_167",
        "ID": "0c921259-2ae8-465e-8aff-bab8c60e85a7",
        "questions": "If $V_{0}$ is a dense open subset of a nonsingular variety $V$, what is the relationship between $\bar{P}_{m}(V_{0})$ and $\bar{P}_{m}(V)$ for all $m$?",
        "answers": "$\bar{P}_{m}(V_{0})\\geq\bar{P}_{m}(V)$",
        "context": "When $\\bar{{V}}$ is a smooth completion of a nonsingular variety $V$ with smooth boundary $D$, the logarithmic m-genus $\\bar{P}_{m}(\\bar{V})=l_{\\bar{V}}(m(K(\\bar{V})+\\bar{D}))$ for each $m$.\n\nDefinition. The logarithmic Kodaira dimension of $V$ is defined to be $\\kappa\\{K(V)$ $+~D,~\\bar{V})_{z}$, and is denoted by $\\bar{\\kappa}(V)$.\n\nIf $\\bar{\\kappa}(V)\\geq0$, then one has $m_{0}$ with $\\bar{P}_{m_{0}(V)>0$, and $\\alpha,\\,\\beta>0$ such that\n\n$$\n\\alpha m^{\\bar{\\kappa}(V)}\\leq\\bar{P}_{m m_{0}}(V)\\leq\\beta m^{\\bar{\\kappa}(V)}\\quad\\mathrm{for}\\quad m\\gg0\n$$\n\nby Theorem 10.2. Thus $\\bar{\\kappa}(V)$ is a proper birational invariant. As a corollary to Theorem 11.2.(i), one obtains the following result\n\n# Proposition 11.4\n\n(i) If $f:$ $V\\rightarrow W$ is a strictly rational dominating morphism, then $\\bar{P}_{M}(V)\\geq\\bar{P}_{M}(W)$ and $\\bar{q}_{i}(V)\\geq\\bar{q}_{i}(W).$ for all $M$ and $i$.\n\n(ii) In addition, if $\\dim V=\\dim W$, then $\\bar{P}_{m}(V)\\geq\\bar{P}_{m}(W)$ for all $m$ and so $\\bar{\\kappa}(V)\\geq\\bar{\\kappa}(W)$.\n\n(iii) If $V_{0}$ is a dense open subset of $V$, then\n\n$$\n\\bar{q}_{i}(V_{0})\\geq\\bar{q}_{i}(V),\\quad\\bar{P}_{m}(V_{0})\\geq\\bar{P}_{m}(V),\\quad \\mathrm{and} \\quad\\bar{\\kappa}(V_{0})\\geq\\bar{\\kappa}(V).\n$$\n\nd. If $C$ is a curve, then. $\\bar{q}(C)=\\bar{p}_{g}(C),$ which is denoted by $\\bar{g}(C)$. Let $\\bar{C}$ be a nonsingular complete curve with $g=g(\\bar{{C}})$, and let $D$ be $p_{0}+\\cdots+p_{t}$ on $\\bar{C}$ such that $C=\\bar{C}\\backslash D$. Then\n\n$$\n\\bar{g}(C)=l(K(\\bar{C})+D)=1-g+2g-2+t+1-l(-D).\n$$\n\nIf $D\\neq 0$, i.e., if $C$ is not complete, then $\\bar{g}(C)=g+t$. Thus\n\n$$\n\\bar{g}(C)=0\\!\\Leftrightarrow\\!g=t=0\\!\\Leftrightarrow\\!C\\cong{\\bf A}_{k}^{1}\\!\\Leftrightarrow\\!\\bar{\\kappa}(C)=-\\infty.\n$$\n\nFurthermore, if $\\bar{g}(C)=1$, then $g=1,\\,t=0$ or $g=0,\\,t=1.$ If $g=1$, one has $\\bar{P}_{2}(C)=2(t+1)$. Hence,\n\n$$\n\\bar{g}(C)=\\bar{P}_{2}(C)=1\\!\\Leftrightarrow\\!g=0,\\;\\;\\;t=1\\!\\Leftrightarrow\\!C\\cong G_{m}\\!\\Leftrightarrow\\!\\bar{\\kappa}(C)=0.\n$$\n\nHere, $G_{m}$ denotes $\\mathrm{Spec~}k[\\mathsf{X},\\mathsf{X}^{-1}],$ called the 1-dimensional algebraic torus over $k$. Thus, one obtains the next table.\n\n$\n\\begin{tabular}{|c|c|c|}\n     \n    type & $\\bar{\\kappa}(C)$ & C \\\\\n     \n    I & $-\\infty$ & $P_k, A_k^1$ \\\\\n     \n    II & $0$ & elliptic curves, $G_m$ \\\\\n     \n    III & $1$ & the others \\\\\n     \n\\end{tabular}\n$\n\nEXAMPLE 11.4. Let $F$ be a nonconstant polynomial in n variables ${\\sf X}_{1},\\ldots,$ ${\\sf X}_{n}$. If $R$ is the integral closure of $k[F]$ in $k({\\mathsf{X}}_{1}\\,,\\,\\ldots\\,,{\\mathsf{X}}_{n}),$ then $R=k[\\psi]$ for some polynomial $\\psi$ and $F$ can be written as a polynomial in $\\psi$. In particular, $k({\\sf X}_{1},\\dots,\\,{\\sf X}_{n})/k(\\psi)$ is an algebraically closed extension of fields.\n\nThis can be easily shown as follows: $F$ determines a dominating morphism $f$ from ${\\bf A}_{k}^{n}$ to $\\mathbf{A}_{k}^{1}=C$. Then one has the Stein factorization of $f$ in the form: $\\mathbf{A}_{k}^{n}\\to\\operatorname{Spec}\\;R\\to C$. $\\operatorname{Spec}\\;R$ is a nonsingular affine curve and $\\bar{g}\\big(\\operatorname{Spec}\\;R\\big)\\leq\\bar{q}\\big(\\mathbf{A}_{k}^{n}\\big)=0$ by Proposition 11.3.(i). Thus ${\\bar{g}}(\\operatorname{Spec}\\;R)=0$, which implies $\\operatorname{Spec}\\;R\\cong\\mathbf{A}_{k}^{1}$; hence $R=k[\\psi]$\n\ne. Proposition 11.5. Let $V_{0}$ be an open subset of a nonsingular variety $V$ such that $\\operatorname{codim} (V\\backslash V_{0}^{\\ast})\\geq2.$ Then $\\bar{P}_{\\mathit{M}}(V_{0})=\\bar{P}_{\\mathit{M}}(V)$ for all $M$.\n\nPROOF. Let $j\\colon V_{0}\\longrightarrow V$ be the inclusion map. Take smooth completions $\\bar{V}_{0}$ and $\\bar{V}$ of $V_{0}$ and $V$ with smooth boundaries $D_{0}$ and $D$, respectively, such that $j$ defines a morphism $\\mu\\colon\\bar{V}_{0}\\to\\bar{V}$. Let $F$ be the closure of $V\\backslash V_{0}$ in $\\bar{V}$. Then $\\operatorname{codim}(F)\\geq2$ and so by Lemma 2.32 one has\n\n$$\n\\Gamma(\\bar{V}\\backslash F,\\,\\Omega(\\log D)^{M})=\\Gamma(\\bar{V},\\,\\Omega(\\log D)^{M})=T_{M}(V).\n$$\n\nSince $\\mu\\,|_{\\bar{{{V}}}_{0}\\backslash\\mu^{-1}(F)}:\\,\\bar{V}_{0}\\backslash\\mu^{-1}(F){\\to}\\,\\bar{V}\\backslash F$ is a proper birational morphism, $\\mu^{*}$ gives rise to an isomorphism:\n\n$$\n\\Gamma(\\bar{V}\\backslash F,\\,\\Omega(\\log\\,D)^{M})\\cong\\Gamma(\\bar{V}_{0}\\backslash\\mu^{-1}(F),\\,\\Omega(\\log\\,D)^{M}).\n$$\n\nHowever, since $\\Gamma(\\bar{V}_{0}\\backslash\\mu^{-1}(F),~\\Omega(\\log~D_{0})^{M})\\supseteq\\Gamma(\\bar{V}_{0}\\,,~\\Omega(\\log~D_{0})^{M})=T_{M}(V_{0}),$ one has $\\bar{P}_{M}(V)\\geq\\bar{P}_{M}(V_{0})$ and hence $\\bar{{\\bar{P}}}_{M}(V)=\\bar{{\\bar{P}}}_{M}(V_{0})$ by Proposition 11.4.(ii).\u53e3\n\nTheorem 11.3. Let $V$ and W be varieties with dim $V=n$ and dim $W=r$. Then $\\bar{q}(V\\,\\times\\,W)=\\bar{q}(V)+\\bar{q}(W),\\;\\bar{P}_{m}(V\\,\\times\\,W)=\\bar{P}_{m}(V)\\cdot\\bar{P}_{m}(W)$ for all $m\\geq 1$, and $\\bar{\\kappa}(V\\times W)=\\bar{\\kappa}(V)+\\bar{\\kappa}(W)$.\n\nPROOF. We can assume that both $V$ and $W$ are nonsingular. As usual, take smooth completions $\\bar{V}$ and $\\bar{W}$ of $V$ and $W$ with smooth boundaries $D$ and $B$, respectively. Then $\\mathfrak{D}=\\bar{V}\\times B+D\\times\\bar{W}$ has only simple normal crossings and $\\bar{Z}=\\bar{V}\\times\\bar{W}$ is a smooth completion of $V\\times V$ with smooth boundary $\\mathfrak{D}$. Letting $p\\colon\\bar{V}\\times\\bar{W}\\to\\bar{V}$ and $q\\colon \\bar{V}\\times \\bar{W}\\to \\bar{W}$ be projections, one has\n\n$\\Omega{\\frac{1}{\\bar{Z}}}(\\log\\mathfrak{D})=p^{*}(\\Omega{\\frac{1}{V}}(\\log D))\\oplus q^{*}(\\Omega{\\frac{1}{W}}(\\log B))$ and so $\\Omega\\frac{n+r}{Z}(\\log\\,\\mathfrak{D})=p^{\\ast}(\\Omega{\\frac{n}{V}}(\\log D))\\otimes q^{*}(\\Omega{W}(\\log\\,B))$. Therefore,\n\n$$\n\\begin{array}{r l}{\\bar{q}\\big(V\\times W\\big)}&{=\\dim_{k}\\Gamma\\big(\\bar{Z},\\,\\Omega{\\frac{1}{Z}}(\\log\\,\\mathfrak{D})\\big)}\\\\ &{=\\dim_{k}\\Gamma(\\bar{V},\\,\\Omega\\frac{1}{V}(\\log\\,D))+\\dim_{k}\\,\\Gamma(\\bar{W},\\,\\Omega\\frac{1}{W}(\\log\\,B))}\\\\ &{=\\bar{q}(V)+\\bar{q}(W).}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "If $V_{0}$ is a dense open subset of $V$, then $ \bar{P}_{m}(V_{0})\\geq\bar{P}_{m}(V),$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM076.Algebraic.Geometry.An.Introduction.to.Birational.Geometry.of.Algebraic.Varieties.pdf_167",
        "ID": "0c962c3c-4e7c-4463-b908-b06c0a5d8c19",
        "questions": "According to the table of curve types, what type and Kodaira dimension does a curve $C$ have if it is an elliptic curve?",
        "answers": "Type II and $\bar{\\kappa}(C) = 0$",
        "context": "When $\\bar{{V}}$ is a smooth completion of a nonsingular variety $V$ with smooth boundary $D$, the logarithmic m-genus $\\bar{P}_{m}(\\bar{V})=l_{\\bar{V}}(m(K(\\bar{V})+\\bar{D}))$ for each $m$.\n\nDefinition. The logarithmic Kodaira dimension of $V$ is defined to be $\\kappa\\{K(V)$ $+~D,~\\bar{V})_{z}$, and is denoted by $\\bar{\\kappa}(V)$.\n\nIf $\\bar{\\kappa}(V)\\geq0$, then one has $m_{0}$ with $\\bar{P}_{m_{0}(V)>0$, and $\\alpha,\\,\\beta>0$ such that\n\n$$\n\\alpha m^{\\bar{\\kappa}(V)}\\leq\\bar{P}_{m m_{0}}(V)\\leq\\beta m^{\\bar{\\kappa}(V)}\\quad\\mathrm{for}\\quad m\\gg0\n$$\n\nby Theorem 10.2. Thus $\\bar{\\kappa}(V)$ is a proper birational invariant. As a corollary to Theorem 11.2.(i), one obtains the following result\n\n# Proposition 11.4\n\n(i) If $f:$ $V\\rightarrow W$ is a strictly rational dominating morphism, then $\\bar{P}_{M}(V)\\geq\\bar{P}_{M}(W)$ and $\\bar{q}_{i}(V)\\geq\\bar{q}_{i}(W).$ for all $M$ and $i$.\n\n(ii) In addition, if $\\dim V=\\dim W$, then $\\bar{P}_{m}(V)\\geq\\bar{P}_{m}(W)$ for all $m$ and so $\\bar{\\kappa}(V)\\geq\\bar{\\kappa}(W)$.\n\n(iii) If $V_{0}$ is a dense open subset of $V$, then\n\n$$\n\\bar{q}_{i}(V_{0})\\geq\\bar{q}_{i}(V),\\quad\\bar{P}_{m}(V_{0})\\geq\\bar{P}_{m}(V),\\quad \\mathrm{and} \\quad\\bar{\\kappa}(V_{0})\\geq\\bar{\\kappa}(V).\n$$\n\nd. If $C$ is a curve, then. $\\bar{q}(C)=\\bar{p}_{g}(C),$ which is denoted by $\\bar{g}(C)$. Let $\\bar{C}$ be a nonsingular complete curve with $g=g(\\bar{{C}})$, and let $D$ be $p_{0}+\\cdots+p_{t}$ on $\\bar{C}$ such that $C=\\bar{C}\\backslash D$. Then\n\n$$\n\\bar{g}(C)=l(K(\\bar{C})+D)=1-g+2g-2+t+1-l(-D).\n$$\n\nIf $D\\neq 0$, i.e., if $C$ is not complete, then $\\bar{g}(C)=g+t$. Thus\n\n$$\n\\bar{g}(C)=0\\!\\Leftrightarrow\\!g=t=0\\!\\Leftrightarrow\\!C\\cong{\\bf A}_{k}^{1}\\!\\Leftrightarrow\\!\\bar{\\kappa}(C)=-\\infty.\n$$\n\nFurthermore, if $\\bar{g}(C)=1$, then $g=1,\\,t=0$ or $g=0,\\,t=1.$ If $g=1$, one has $\\bar{P}_{2}(C)=2(t+1)$. Hence,\n\n$$\n\\bar{g}(C)=\\bar{P}_{2}(C)=1\\!\\Leftrightarrow\\!g=0,\\;\\;\\;t=1\\!\\Leftrightarrow\\!C\\cong G_{m}\\!\\Leftrightarrow\\!\\bar{\\kappa}(C)=0.\n$$\n\nHere, $G_{m}$ denotes $\\mathrm{Spec~}k[\\mathsf{X},\\mathsf{X}^{-1}],$ called the 1-dimensional algebraic torus over $k$. Thus, one obtains the next table.\n\n$\n\\begin{tabular}{|c|c|c|}\n     \n    type & $\\bar{\\kappa}(C)$ & C \\\\\n     \n    I & $-\\infty$ & $P_k, A_k^1$ \\\\\n     \n    II & $0$ & elliptic curves, $G_m$ \\\\\n     \n    III & $1$ & the others \\\\\n     \n\\end{tabular}\n$\n\nEXAMPLE 11.4. Let $F$ be a nonconstant polynomial in n variables ${\\sf X}_{1},\\ldots,$ ${\\sf X}_{n}$. If $R$ is the integral closure of $k[F]$ in $k({\\mathsf{X}}_{1}\\,,\\,\\ldots\\,,{\\mathsf{X}}_{n}),$ then $R=k[\\psi]$ for some polynomial $\\psi$ and $F$ can be written as a polynomial in $\\psi$. In particular, $k({\\sf X}_{1},\\dots,\\,{\\sf X}_{n})/k(\\psi)$ is an algebraically closed extension of fields.\n\nThis can be easily shown as follows: $F$ determines a dominating morphism $f$ from ${\\bf A}_{k}^{n}$ to $\\mathbf{A}_{k}^{1}=C$. Then one has the Stein factorization of $f$ in the form: $\\mathbf{A}_{k}^{n}\\to\\operatorname{Spec}\\;R\\to C$. $\\operatorname{Spec}\\;R$ is a nonsingular affine curve and $\\bar{g}\\big(\\operatorname{Spec}\\;R\\big)\\leq\\bar{q}\\big(\\mathbf{A}_{k}^{n}\\big)=0$ by Proposition 11.3.(i). Thus ${\\bar{g}}(\\operatorname{Spec}\\;R)=0$, which implies $\\operatorname{Spec}\\;R\\cong\\mathbf{A}_{k}^{1}$; hence $R=k[\\psi]$\n\ne. Proposition 11.5. Let $V_{0}$ be an open subset of a nonsingular variety $V$ such that $\\operatorname{codim} (V\\backslash V_{0}^{\\ast})\\geq2.$ Then $\\bar{P}_{\\mathit{M}}(V_{0})=\\bar{P}_{\\mathit{M}}(V)$ for all $M$.\n\nPROOF. Let $j\\colon V_{0}\\longrightarrow V$ be the inclusion map. Take smooth completions $\\bar{V}_{0}$ and $\\bar{V}$ of $V_{0}$ and $V$ with smooth boundaries $D_{0}$ and $D$, respectively, such that $j$ defines a morphism $\\mu\\colon\\bar{V}_{0}\\to\\bar{V}$. Let $F$ be the closure of $V\\backslash V_{0}$ in $\\bar{V}$. Then $\\operatorname{codim}(F)\\geq2$ and so by Lemma 2.32 one has\n\n$$\n\\Gamma(\\bar{V}\\backslash F,\\,\\Omega(\\log D)^{M})=\\Gamma(\\bar{V},\\,\\Omega(\\log D)^{M})=T_{M}(V).\n$$\n\nSince $\\mu\\,|_{\\bar{{{V}}}_{0}\\backslash\\mu^{-1}(F)}:\\,\\bar{V}_{0}\\backslash\\mu^{-1}(F){\\to}\\,\\bar{V}\\backslash F$ is a proper birational morphism, $\\mu^{*}$ gives rise to an isomorphism:\n\n$$\n\\Gamma(\\bar{V}\\backslash F,\\,\\Omega(\\log\\,D)^{M})\\cong\\Gamma(\\bar{V}_{0}\\backslash\\mu^{-1}(F),\\,\\Omega(\\log\\,D)^{M}).\n$$\n\nHowever, since $\\Gamma(\\bar{V}_{0}\\backslash\\mu^{-1}(F),~\\Omega(\\log~D_{0})^{M})\\supseteq\\Gamma(\\bar{V}_{0}\\,,~\\Omega(\\log~D_{0})^{M})=T_{M}(V_{0}),$ one has $\\bar{P}_{M}(V)\\geq\\bar{P}_{M}(V_{0})$ and hence $\\bar{{\\bar{P}}}_{M}(V)=\\bar{{\\bar{P}}}_{M}(V_{0})$ by Proposition 11.4.(ii).\u53e3\n\nTheorem 11.3. Let $V$ and W be varieties with dim $V=n$ and dim $W=r$. Then $\\bar{q}(V\\,\\times\\,W)=\\bar{q}(V)+\\bar{q}(W),\\;\\bar{P}_{m}(V\\,\\times\\,W)=\\bar{P}_{m}(V)\\cdot\\bar{P}_{m}(W)$ for all $m\\geq 1$, and $\\bar{\\kappa}(V\\times W)=\\bar{\\kappa}(V)+\\bar{\\kappa}(W)$.\n\nPROOF. We can assume that both $V$ and $W$ are nonsingular. As usual, take smooth completions $\\bar{V}$ and $\\bar{W}$ of $V$ and $W$ with smooth boundaries $D$ and $B$, respectively. Then $\\mathfrak{D}=\\bar{V}\\times B+D\\times\\bar{W}$ has only simple normal crossings and $\\bar{Z}=\\bar{V}\\times\\bar{W}$ is a smooth completion of $V\\times V$ with smooth boundary $\\mathfrak{D}$. Letting $p\\colon\\bar{V}\\times\\bar{W}\\to\\bar{V}$ and $q\\colon \\bar{V}\\times \\bar{W}\\to \\bar{W}$ be projections, one has\n\n$\\Omega{\\frac{1}{\\bar{Z}}}(\\log\\mathfrak{D})=p^{*}(\\Omega{\\frac{1}{V}}(\\log D))\\oplus q^{*}(\\Omega{\\frac{1}{W}}(\\log B))$ and so $\\Omega\\frac{n+r}{Z}(\\log\\,\\mathfrak{D})=p^{\\ast}(\\Omega{\\frac{n}{V}}(\\log D))\\otimes q^{*}(\\Omega{W}(\\log\\,B))$. Therefore,\n\n$$\n\\begin{array}{r l}{\\bar{q}\\big(V\\times W\\big)}&{=\\dim_{k}\\Gamma\\big(\\bar{Z},\\,\\Omega{\\frac{1}{Z}}(\\log\\,\\mathfrak{D})\\big)}\\\\ &{=\\dim_{k}\\Gamma(\\bar{V},\\,\\Omega\\frac{1}{V}(\\log\\,D))+\\dim_{k}\\,\\Gamma(\\bar{W},\\,\\Omega\\frac{1}{W}(\\log\\,B))}\\\\ &{=\\bar{q}(V)+\\bar{q}(W).}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "table",
        "evidence_context": "$\\begin{tabular}{|c|c|c|}\\hline type & \\bar{\\kappa}(C) & C \\\\ \\hline I & -\\infty & P_k, A_k^1 \\\\ \\hline II & 0 & elliptic curves, G_m \\\\ \\hline III & 1 & the others \\\\ \\hline\\end{tabular}$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM076.Algebraic.Geometry.An.Introduction.to.Birational.Geometry.of.Algebraic.Varieties.pdf_167",
        "ID": "0c9a7fec-92a5-4895-9745-c170d7bcafdf",
        "questions": "What is the inequality involving the logarithmic m-genus \\( \\bar{P}_{m m_{0}}(V) \\) when the logarithmic Kodaira dimension \\( \\bar{\\kappa}(V) \\) is greater than or equal to zero?",
        "answers": "\\( \\alpha m^{\\bar{\\kappa}(V)}\\leq\\bar{P}_{m m_{0}}(V)\\leq\\beta m^{\\bar{\\kappa}(V)} \\)",
        "context": "When $\\bar{{V}}$ is a smooth completion of a nonsingular variety $V$ with smooth boundary $D$, the logarithmic m-genus $\\bar{P}_{m}(\\bar{V})=l_{\\bar{V}}(m(K(\\bar{V})+\\bar{D}))$ for each $m$.\n\nDefinition. The logarithmic Kodaira dimension of $V$ is defined to be $\\kappa\\{K(V)$ $+~D,~\\bar{V})_{z}$, and is denoted by $\\bar{\\kappa}(V)$.\n\nIf $\\bar{\\kappa}(V)\\geq0$, then one has $m_{0}$ with $\\bar{P}_{m_{0}(V)>0$, and $\\alpha,\\,\\beta>0$ such that\n\n$$\n\\alpha m^{\\bar{\\kappa}(V)}\\leq\\bar{P}_{m m_{0}}(V)\\leq\\beta m^{\\bar{\\kappa}(V)}\\quad\\mathrm{for}\\quad m\\gg0\n$$\n\nby Theorem 10.2. Thus $\\bar{\\kappa}(V)$ is a proper birational invariant. As a corollary to Theorem 11.2.(i), one obtains the following result\n\n# Proposition 11.4\n\n(i) If $f:$ $V\\rightarrow W$ is a strictly rational dominating morphism, then $\\bar{P}_{M}(V)\\geq\\bar{P}_{M}(W)$ and $\\bar{q}_{i}(V)\\geq\\bar{q}_{i}(W).$ for all $M$ and $i$.\n\n(ii) In addition, if $\\dim V=\\dim W$, then $\\bar{P}_{m}(V)\\geq\\bar{P}_{m}(W)$ for all $m$ and so $\\bar{\\kappa}(V)\\geq\\bar{\\kappa}(W)$.\n\n(iii) If $V_{0}$ is a dense open subset of $V$, then\n\n$$\n\\bar{q}_{i}(V_{0})\\geq\\bar{q}_{i}(V),\\quad\\bar{P}_{m}(V_{0})\\geq\\bar{P}_{m}(V),\\quad \\mathrm{and} \\quad\\bar{\\kappa}(V_{0})\\geq\\bar{\\kappa}(V).\n$$\n\nd. If $C$ is a curve, then. $\\bar{q}(C)=\\bar{p}_{g}(C),$ which is denoted by $\\bar{g}(C)$. Let $\\bar{C}$ be a nonsingular complete curve with $g=g(\\bar{{C}})$, and let $D$ be $p_{0}+\\cdots+p_{t}$ on $\\bar{C}$ such that $C=\\bar{C}\\backslash D$. Then\n\n$$\n\\bar{g}(C)=l(K(\\bar{C})+D)=1-g+2g-2+t+1-l(-D).\n$$\n\nIf $D\\neq 0$, i.e., if $C$ is not complete, then $\\bar{g}(C)=g+t$. Thus\n\n$$\n\\bar{g}(C)=0\\!\\Leftrightarrow\\!g=t=0\\!\\Leftrightarrow\\!C\\cong{\\bf A}_{k}^{1}\\!\\Leftrightarrow\\!\\bar{\\kappa}(C)=-\\infty.\n$$\n\nFurthermore, if $\\bar{g}(C)=1$, then $g=1,\\,t=0$ or $g=0,\\,t=1.$ If $g=1$, one has $\\bar{P}_{2}(C)=2(t+1)$. Hence,\n\n$$\n\\bar{g}(C)=\\bar{P}_{2}(C)=1\\!\\Leftrightarrow\\!g=0,\\;\\;\\;t=1\\!\\Leftrightarrow\\!C\\cong G_{m}\\!\\Leftrightarrow\\!\\bar{\\kappa}(C)=0.\n$$\n\nHere, $G_{m}$ denotes $\\mathrm{Spec~}k[\\mathsf{X},\\mathsf{X}^{-1}],$ called the 1-dimensional algebraic torus over $k$. Thus, one obtains the next table.\n\n$\n\\begin{tabular}{|c|c|c|}\n     \n    type & $\\bar{\\kappa}(C)$ & C \\\\\n     \n    I & $-\\infty$ & $P_k, A_k^1$ \\\\\n     \n    II & $0$ & elliptic curves, $G_m$ \\\\\n     \n    III & $1$ & the others \\\\\n     \n\\end{tabular}\n$\n\nEXAMPLE 11.4. Let $F$ be a nonconstant polynomial in n variables ${\\sf X}_{1},\\ldots,$ ${\\sf X}_{n}$. If $R$ is the integral closure of $k[F]$ in $k({\\mathsf{X}}_{1}\\,,\\,\\ldots\\,,{\\mathsf{X}}_{n}),$ then $R=k[\\psi]$ for some polynomial $\\psi$ and $F$ can be written as a polynomial in $\\psi$. In particular, $k({\\sf X}_{1},\\dots,\\,{\\sf X}_{n})/k(\\psi)$ is an algebraically closed extension of fields.\n\nThis can be easily shown as follows: $F$ determines a dominating morphism $f$ from ${\\bf A}_{k}^{n}$ to $\\mathbf{A}_{k}^{1}=C$. Then one has the Stein factorization of $f$ in the form: $\\mathbf{A}_{k}^{n}\\to\\operatorname{Spec}\\;R\\to C$. $\\operatorname{Spec}\\;R$ is a nonsingular affine curve and $\\bar{g}\\big(\\operatorname{Spec}\\;R\\big)\\leq\\bar{q}\\big(\\mathbf{A}_{k}^{n}\\big)=0$ by Proposition 11.3.(i). Thus ${\\bar{g}}(\\operatorname{Spec}\\;R)=0$, which implies $\\operatorname{Spec}\\;R\\cong\\mathbf{A}_{k}^{1}$; hence $R=k[\\psi]$\n\ne. Proposition 11.5. Let $V_{0}$ be an open subset of a nonsingular variety $V$ such that $\\operatorname{codim} (V\\backslash V_{0}^{\\ast})\\geq2.$ Then $\\bar{P}_{\\mathit{M}}(V_{0})=\\bar{P}_{\\mathit{M}}(V)$ for all $M$.\n\nPROOF. Let $j\\colon V_{0}\\longrightarrow V$ be the inclusion map. Take smooth completions $\\bar{V}_{0}$ and $\\bar{V}$ of $V_{0}$ and $V$ with smooth boundaries $D_{0}$ and $D$, respectively, such that $j$ defines a morphism $\\mu\\colon\\bar{V}_{0}\\to\\bar{V}$. Let $F$ be the closure of $V\\backslash V_{0}$ in $\\bar{V}$. Then $\\operatorname{codim}(F)\\geq2$ and so by Lemma 2.32 one has\n\n$$\n\\Gamma(\\bar{V}\\backslash F,\\,\\Omega(\\log D)^{M})=\\Gamma(\\bar{V},\\,\\Omega(\\log D)^{M})=T_{M}(V).\n$$\n\nSince $\\mu\\,|_{\\bar{{{V}}}_{0}\\backslash\\mu^{-1}(F)}:\\,\\bar{V}_{0}\\backslash\\mu^{-1}(F){\\to}\\,\\bar{V}\\backslash F$ is a proper birational morphism, $\\mu^{*}$ gives rise to an isomorphism:\n\n$$\n\\Gamma(\\bar{V}\\backslash F,\\,\\Omega(\\log\\,D)^{M})\\cong\\Gamma(\\bar{V}_{0}\\backslash\\mu^{-1}(F),\\,\\Omega(\\log\\,D)^{M}).\n$$\n\nHowever, since $\\Gamma(\\bar{V}_{0}\\backslash\\mu^{-1}(F),~\\Omega(\\log~D_{0})^{M})\\supseteq\\Gamma(\\bar{V}_{0}\\,,~\\Omega(\\log~D_{0})^{M})=T_{M}(V_{0}),$ one has $\\bar{P}_{M}(V)\\geq\\bar{P}_{M}(V_{0})$ and hence $\\bar{{\\bar{P}}}_{M}(V)=\\bar{{\\bar{P}}}_{M}(V_{0})$ by Proposition 11.4.(ii).\u53e3\n\nTheorem 11.3. Let $V$ and W be varieties with dim $V=n$ and dim $W=r$. Then $\\bar{q}(V\\,\\times\\,W)=\\bar{q}(V)+\\bar{q}(W),\\;\\bar{P}_{m}(V\\,\\times\\,W)=\\bar{P}_{m}(V)\\cdot\\bar{P}_{m}(W)$ for all $m\\geq 1$, and $\\bar{\\kappa}(V\\times W)=\\bar{\\kappa}(V)+\\bar{\\kappa}(W)$.\n\nPROOF. We can assume that both $V$ and $W$ are nonsingular. As usual, take smooth completions $\\bar{V}$ and $\\bar{W}$ of $V$ and $W$ with smooth boundaries $D$ and $B$, respectively. Then $\\mathfrak{D}=\\bar{V}\\times B+D\\times\\bar{W}$ has only simple normal crossings and $\\bar{Z}=\\bar{V}\\times\\bar{W}$ is a smooth completion of $V\\times V$ with smooth boundary $\\mathfrak{D}$. Letting $p\\colon\\bar{V}\\times\\bar{W}\\to\\bar{V}$ and $q\\colon \\bar{V}\\times \\bar{W}\\to \\bar{W}$ be projections, one has\n\n$\\Omega{\\frac{1}{\\bar{Z}}}(\\log\\mathfrak{D})=p^{*}(\\Omega{\\frac{1}{V}}(\\log D))\\oplus q^{*}(\\Omega{\\frac{1}{W}}(\\log B))$ and so $\\Omega\\frac{n+r}{Z}(\\log\\,\\mathfrak{D})=p^{\\ast}(\\Omega{\\frac{n}{V}}(\\log D))\\otimes q^{*}(\\Omega{W}(\\log\\,B))$. Therefore,\n\n$$\n\\begin{array}{r l}{\\bar{q}\\big(V\\times W\\big)}&{=\\dim_{k}\\Gamma\\big(\\bar{Z},\\,\\Omega{\\frac{1}{Z}}(\\log\\,\\mathfrak{D})\\big)}\\\\ &{=\\dim_{k}\\Gamma(\\bar{V},\\,\\Omega\\frac{1}{V}(\\log\\,D))+\\dim_{k}\\,\\Gamma(\\bar{W},\\,\\Omega\\frac{1}{W}(\\log\\,B))}\\\\ &{=\\bar{q}(V)+\\bar{q}(W).}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Numeric",
        "evidence_source": "equation",
        "evidence_context": "\\( \\alpha m^{\\bar{\\kappa}(V)}\\leq\\bar{P}_{m m_{0}}(V)\\leq\\beta m^{\\bar{\\kappa}(V)}\\quad\\mathrm{for}\\quad m\\gg0 \\)",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/GTM076.Algebraic.Geometry.An.Introduction.to.Birational.Geometry.of.Algebraic.Varieties.pdf_167",
        "ID": "0ca97c64-02bc-4d78-a13e-13e71ea0f50f",
        "questions": "If \\( R \\) is the integral closure of \\( k[F] \\) in \\( k({\\mathsf{X}}_{1}, ..., {\\mathsf{X}}_{n}) \\), what is the relation between \\( R \\) and \\( \\psi \\)?",
        "answers": "\\( R=k[\\psi] \\)",
        "context": "When $\\bar{{V}}$ is a smooth completion of a nonsingular variety $V$ with smooth boundary $D$, the logarithmic m-genus $\\bar{P}_{m}(\\bar{V})=l_{\\bar{V}}(m(K(\\bar{V})+\\bar{D}))$ for each $m$.\n\nDefinition. The logarithmic Kodaira dimension of $V$ is defined to be $\\kappa\\{K(V)$ $+~D,~\\bar{V})_{z}$, and is denoted by $\\bar{\\kappa}(V)$.\n\nIf $\\bar{\\kappa}(V)\\geq0$, then one has $m_{0}$ with $\\bar{P}_{m_{0}(V)>0$, and $\\alpha,\\,\\beta>0$ such that\n\n$$\n\\alpha m^{\\bar{\\kappa}(V)}\\leq\\bar{P}_{m m_{0}}(V)\\leq\\beta m^{\\bar{\\kappa}(V)}\\quad\\mathrm{for}\\quad m\\gg0\n$$\n\nby Theorem 10.2. Thus $\\bar{\\kappa}(V)$ is a proper birational invariant. As a corollary to Theorem 11.2.(i), one obtains the following result\n\n# Proposition 11.4\n\n(i) If $f:$ $V\\rightarrow W$ is a strictly rational dominating morphism, then $\\bar{P}_{M}(V)\\geq\\bar{P}_{M}(W)$ and $\\bar{q}_{i}(V)\\geq\\bar{q}_{i}(W).$ for all $M$ and $i$.\n\n(ii) In addition, if $\\dim V=\\dim W$, then $\\bar{P}_{m}(V)\\geq\\bar{P}_{m}(W)$ for all $m$ and so $\\bar{\\kappa}(V)\\geq\\bar{\\kappa}(W)$.\n\n(iii) If $V_{0}$ is a dense open subset of $V$, then\n\n$$\n\\bar{q}_{i}(V_{0})\\geq\\bar{q}_{i}(V),\\quad\\bar{P}_{m}(V_{0})\\geq\\bar{P}_{m}(V),\\quad \\mathrm{and} \\quad\\bar{\\kappa}(V_{0})\\geq\\bar{\\kappa}(V).\n$$\n\nd. If $C$ is a curve, then. $\\bar{q}(C)=\\bar{p}_{g}(C),$ which is denoted by $\\bar{g}(C)$. Let $\\bar{C}$ be a nonsingular complete curve with $g=g(\\bar{{C}})$, and let $D$ be $p_{0}+\\cdots+p_{t}$ on $\\bar{C}$ such that $C=\\bar{C}\\backslash D$. Then\n\n$$\n\\bar{g}(C)=l(K(\\bar{C})+D)=1-g+2g-2+t+1-l(-D).\n$$\n\nIf $D\\neq 0$, i.e., if $C$ is not complete, then $\\bar{g}(C)=g+t$. Thus\n\n$$\n\\bar{g}(C)=0\\!\\Leftrightarrow\\!g=t=0\\!\\Leftrightarrow\\!C\\cong{\\bf A}_{k}^{1}\\!\\Leftrightarrow\\!\\bar{\\kappa}(C)=-\\infty.\n$$\n\nFurthermore, if $\\bar{g}(C)=1$, then $g=1,\\,t=0$ or $g=0,\\,t=1.$ If $g=1$, one has $\\bar{P}_{2}(C)=2(t+1)$. Hence,\n\n$$\n\\bar{g}(C)=\\bar{P}_{2}(C)=1\\!\\Leftrightarrow\\!g=0,\\;\\;\\;t=1\\!\\Leftrightarrow\\!C\\cong G_{m}\\!\\Leftrightarrow\\!\\bar{\\kappa}(C)=0.\n$$\n\nHere, $G_{m}$ denotes $\\mathrm{Spec~}k[\\mathsf{X},\\mathsf{X}^{-1}],$ called the 1-dimensional algebraic torus over $k$. Thus, one obtains the next table.\n\n$\n\\begin{tabular}{|c|c|c|}\n     \n    type & $\\bar{\\kappa}(C)$ & C \\\\\n     \n    I & $-\\infty$ & $P_k, A_k^1$ \\\\\n     \n    II & $0$ & elliptic curves, $G_m$ \\\\\n     \n    III & $1$ & the others \\\\\n     \n\\end{tabular}\n$\n\nEXAMPLE 11.4. Let $F$ be a nonconstant polynomial in n variables ${\\sf X}_{1},\\ldots,$ ${\\sf X}_{n}$. If $R$ is the integral closure of $k[F]$ in $k({\\mathsf{X}}_{1}\\,,\\,\\ldots\\,,{\\mathsf{X}}_{n}),$ then $R=k[\\psi]$ for some polynomial $\\psi$ and $F$ can be written as a polynomial in $\\psi$. In particular, $k({\\sf X}_{1},\\dots,\\,{\\sf X}_{n})/k(\\psi)$ is an algebraically closed extension of fields.\n\nThis can be easily shown as follows: $F$ determines a dominating morphism $f$ from ${\\bf A}_{k}^{n}$ to $\\mathbf{A}_{k}^{1}=C$. Then one has the Stein factorization of $f$ in the form: $\\mathbf{A}_{k}^{n}\\to\\operatorname{Spec}\\;R\\to C$. $\\operatorname{Spec}\\;R$ is a nonsingular affine curve and $\\bar{g}\\big(\\operatorname{Spec}\\;R\\big)\\leq\\bar{q}\\big(\\mathbf{A}_{k}^{n}\\big)=0$ by Proposition 11.3.(i). Thus ${\\bar{g}}(\\operatorname{Spec}\\;R)=0$, which implies $\\operatorname{Spec}\\;R\\cong\\mathbf{A}_{k}^{1}$; hence $R=k[\\psi]$\n\ne. Proposition 11.5. Let $V_{0}$ be an open subset of a nonsingular variety $V$ such that $\\operatorname{codim} (V\\backslash V_{0}^{\\ast})\\geq2.$ Then $\\bar{P}_{\\mathit{M}}(V_{0})=\\bar{P}_{\\mathit{M}}(V)$ for all $M$.\n\nPROOF. Let $j\\colon V_{0}\\longrightarrow V$ be the inclusion map. Take smooth completions $\\bar{V}_{0}$ and $\\bar{V}$ of $V_{0}$ and $V$ with smooth boundaries $D_{0}$ and $D$, respectively, such that $j$ defines a morphism $\\mu\\colon\\bar{V}_{0}\\to\\bar{V}$. Let $F$ be the closure of $V\\backslash V_{0}$ in $\\bar{V}$. Then $\\operatorname{codim}(F)\\geq2$ and so by Lemma 2.32 one has\n\n$$\n\\Gamma(\\bar{V}\\backslash F,\\,\\Omega(\\log D)^{M})=\\Gamma(\\bar{V},\\,\\Omega(\\log D)^{M})=T_{M}(V).\n$$\n\nSince $\\mu\\,|_{\\bar{{{V}}}_{0}\\backslash\\mu^{-1}(F)}:\\,\\bar{V}_{0}\\backslash\\mu^{-1}(F){\\to}\\,\\bar{V}\\backslash F$ is a proper birational morphism, $\\mu^{*}$ gives rise to an isomorphism:\n\n$$\n\\Gamma(\\bar{V}\\backslash F,\\,\\Omega(\\log\\,D)^{M})\\cong\\Gamma(\\bar{V}_{0}\\backslash\\mu^{-1}(F),\\,\\Omega(\\log\\,D)^{M}).\n$$\n\nHowever, since $\\Gamma(\\bar{V}_{0}\\backslash\\mu^{-1}(F),~\\Omega(\\log~D_{0})^{M})\\supseteq\\Gamma(\\bar{V}_{0}\\,,~\\Omega(\\log~D_{0})^{M})=T_{M}(V_{0}),$ one has $\\bar{P}_{M}(V)\\geq\\bar{P}_{M}(V_{0})$ and hence $\\bar{{\\bar{P}}}_{M}(V)=\\bar{{\\bar{P}}}_{M}(V_{0})$ by Proposition 11.4.(ii).\u53e3\n\nTheorem 11.3. Let $V$ and W be varieties with dim $V=n$ and dim $W=r$. Then $\\bar{q}(V\\,\\times\\,W)=\\bar{q}(V)+\\bar{q}(W),\\;\\bar{P}_{m}(V\\,\\times\\,W)=\\bar{P}_{m}(V)\\cdot\\bar{P}_{m}(W)$ for all $m\\geq 1$, and $\\bar{\\kappa}(V\\times W)=\\bar{\\kappa}(V)+\\bar{\\kappa}(W)$.\n\nPROOF. We can assume that both $V$ and $W$ are nonsingular. As usual, take smooth completions $\\bar{V}$ and $\\bar{W}$ of $V$ and $W$ with smooth boundaries $D$ and $B$, respectively. Then $\\mathfrak{D}=\\bar{V}\\times B+D\\times\\bar{W}$ has only simple normal crossings and $\\bar{Z}=\\bar{V}\\times\\bar{W}$ is a smooth completion of $V\\times V$ with smooth boundary $\\mathfrak{D}$. Letting $p\\colon\\bar{V}\\times\\bar{W}\\to\\bar{V}$ and $q\\colon \\bar{V}\\times \\bar{W}\\to \\bar{W}$ be projections, one has\n\n$\\Omega{\\frac{1}{\\bar{Z}}}(\\log\\mathfrak{D})=p^{*}(\\Omega{\\frac{1}{V}}(\\log D))\\oplus q^{*}(\\Omega{\\frac{1}{W}}(\\log B))$ and so $\\Omega\\frac{n+r}{Z}(\\log\\,\\mathfrak{D})=p^{\\ast}(\\Omega{\\frac{n}{V}}(\\log D))\\otimes q^{*}(\\Omega{W}(\\log\\,B))$. Therefore,\n\n$$\n\\begin{array}{r l}{\\bar{q}\\big(V\\times W\\big)}&{=\\dim_{k}\\Gamma\\big(\\bar{Z},\\,\\Omega{\\frac{1}{Z}}(\\log\\,\\mathfrak{D})\\big)}\\\\ &{=\\dim_{k}\\Gamma(\\bar{V},\\,\\Omega\\frac{1}{V}(\\log\\,D))+\\dim_{k}\\,\\Gamma(\\bar{W},\\,\\Omega\\frac{1}{W}(\\log\\,B))}\\\\ &{=\\bar{q}(V)+\\bar{q}(W).}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "If \\( R \\) is the integral closure of \\( k[F] \\) in \\( k({\\mathsf{X}}_{1},...,{\\mathsf{X}}_{n}), \\) then \\( R=k[\\psi] \\) for some polynomial \\( \\psi \\)",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/GTM076.Algebraic.Geometry.An.Introduction.to.Birational.Geometry.of.Algebraic.Varieties.pdf_167",
        "ID": "0ca97ff3-a2cf-4f86-bae0-072f39fc7c2d",
        "questions": "How is the function \\( \\Omega\\frac{n+r}{Z}(\\log\\,\\mathfrak{D}) \\) expressed in terms of the projections \\( p^* \\) and \\( q^* \\) of the varieties \\( V \\) and \\( W \\)?",
        "answers": "\\( \\Omega\\frac{n+r}{Z}(\\log\\,\\mathfrak{D})=p^{\\ast}(\\Omega\\frac{n}{V}(\\log D))\\otimes q^{*}(\\Omega{W}(\\log\\,B)) \\)",
        "context": "When $\\bar{{V}}$ is a smooth completion of a nonsingular variety $V$ with smooth boundary $D$, the logarithmic m-genus $\\bar{P}_{m}(\\bar{V})=l_{\\bar{V}}(m(K(\\bar{V})+\\bar{D}))$ for each $m$.\n\nDefinition. The logarithmic Kodaira dimension of $V$ is defined to be $\\kappa\\{K(V)$ $+~D,~\\bar{V})_{z}$, and is denoted by $\\bar{\\kappa}(V)$.\n\nIf $\\bar{\\kappa}(V)\\geq0$, then one has $m_{0}$ with $\\bar{P}_{m_{0}(V)>0$, and $\\alpha,\\,\\beta>0$ such that\n\n$$\n\\alpha m^{\\bar{\\kappa}(V)}\\leq\\bar{P}_{m m_{0}}(V)\\leq\\beta m^{\\bar{\\kappa}(V)}\\quad\\mathrm{for}\\quad m\\gg0\n$$\n\nby Theorem 10.2. Thus $\\bar{\\kappa}(V)$ is a proper birational invariant. As a corollary to Theorem 11.2.(i), one obtains the following result\n\n# Proposition 11.4\n\n(i) If $f:$ $V\\rightarrow W$ is a strictly rational dominating morphism, then $\\bar{P}_{M}(V)\\geq\\bar{P}_{M}(W)$ and $\\bar{q}_{i}(V)\\geq\\bar{q}_{i}(W).$ for all $M$ and $i$.\n\n(ii) In addition, if $\\dim V=\\dim W$, then $\\bar{P}_{m}(V)\\geq\\bar{P}_{m}(W)$ for all $m$ and so $\\bar{\\kappa}(V)\\geq\\bar{\\kappa}(W)$.\n\n(iii) If $V_{0}$ is a dense open subset of $V$, then\n\n$$\n\\bar{q}_{i}(V_{0})\\geq\\bar{q}_{i}(V),\\quad\\bar{P}_{m}(V_{0})\\geq\\bar{P}_{m}(V),\\quad \\mathrm{and} \\quad\\bar{\\kappa}(V_{0})\\geq\\bar{\\kappa}(V).\n$$\n\nd. If $C$ is a curve, then. $\\bar{q}(C)=\\bar{p}_{g}(C),$ which is denoted by $\\bar{g}(C)$. Let $\\bar{C}$ be a nonsingular complete curve with $g=g(\\bar{{C}})$, and let $D$ be $p_{0}+\\cdots+p_{t}$ on $\\bar{C}$ such that $C=\\bar{C}\\backslash D$. Then\n\n$$\n\\bar{g}(C)=l(K(\\bar{C})+D)=1-g+2g-2+t+1-l(-D).\n$$\n\nIf $D\\neq 0$, i.e., if $C$ is not complete, then $\\bar{g}(C)=g+t$. Thus\n\n$$\n\\bar{g}(C)=0\\!\\Leftrightarrow\\!g=t=0\\!\\Leftrightarrow\\!C\\cong{\\bf A}_{k}^{1}\\!\\Leftrightarrow\\!\\bar{\\kappa}(C)=-\\infty.\n$$\n\nFurthermore, if $\\bar{g}(C)=1$, then $g=1,\\,t=0$ or $g=0,\\,t=1.$ If $g=1$, one has $\\bar{P}_{2}(C)=2(t+1)$. Hence,\n\n$$\n\\bar{g}(C)=\\bar{P}_{2}(C)=1\\!\\Leftrightarrow\\!g=0,\\;\\;\\;t=1\\!\\Leftrightarrow\\!C\\cong G_{m}\\!\\Leftrightarrow\\!\\bar{\\kappa}(C)=0.\n$$\n\nHere, $G_{m}$ denotes $\\mathrm{Spec~}k[\\mathsf{X},\\mathsf{X}^{-1}],$ called the 1-dimensional algebraic torus over $k$. Thus, one obtains the next table.\n\n$\n\\begin{tabular}{|c|c|c|}\n     \n    type & $\\bar{\\kappa}(C)$ & C \\\\\n     \n    I & $-\\infty$ & $P_k, A_k^1$ \\\\\n     \n    II & $0$ & elliptic curves, $G_m$ \\\\\n     \n    III & $1$ & the others \\\\\n     \n\\end{tabular}\n$\n\nEXAMPLE 11.4. Let $F$ be a nonconstant polynomial in n variables ${\\sf X}_{1},\\ldots,$ ${\\sf X}_{n}$. If $R$ is the integral closure of $k[F]$ in $k({\\mathsf{X}}_{1}\\,,\\,\\ldots\\,,{\\mathsf{X}}_{n}),$ then $R=k[\\psi]$ for some polynomial $\\psi$ and $F$ can be written as a polynomial in $\\psi$. In particular, $k({\\sf X}_{1},\\dots,\\,{\\sf X}_{n})/k(\\psi)$ is an algebraically closed extension of fields.\n\nThis can be easily shown as follows: $F$ determines a dominating morphism $f$ from ${\\bf A}_{k}^{n}$ to $\\mathbf{A}_{k}^{1}=C$. Then one has the Stein factorization of $f$ in the form: $\\mathbf{A}_{k}^{n}\\to\\operatorname{Spec}\\;R\\to C$. $\\operatorname{Spec}\\;R$ is a nonsingular affine curve and $\\bar{g}\\big(\\operatorname{Spec}\\;R\\big)\\leq\\bar{q}\\big(\\mathbf{A}_{k}^{n}\\big)=0$ by Proposition 11.3.(i). Thus ${\\bar{g}}(\\operatorname{Spec}\\;R)=0$, which implies $\\operatorname{Spec}\\;R\\cong\\mathbf{A}_{k}^{1}$; hence $R=k[\\psi]$\n\ne. Proposition 11.5. Let $V_{0}$ be an open subset of a nonsingular variety $V$ such that $\\operatorname{codim} (V\\backslash V_{0}^{\\ast})\\geq2.$ Then $\\bar{P}_{\\mathit{M}}(V_{0})=\\bar{P}_{\\mathit{M}}(V)$ for all $M$.\n\nPROOF. Let $j\\colon V_{0}\\longrightarrow V$ be the inclusion map. Take smooth completions $\\bar{V}_{0}$ and $\\bar{V}$ of $V_{0}$ and $V$ with smooth boundaries $D_{0}$ and $D$, respectively, such that $j$ defines a morphism $\\mu\\colon\\bar{V}_{0}\\to\\bar{V}$. Let $F$ be the closure of $V\\backslash V_{0}$ in $\\bar{V}$. Then $\\operatorname{codim}(F)\\geq2$ and so by Lemma 2.32 one has\n\n$$\n\\Gamma(\\bar{V}\\backslash F,\\,\\Omega(\\log D)^{M})=\\Gamma(\\bar{V},\\,\\Omega(\\log D)^{M})=T_{M}(V).\n$$\n\nSince $\\mu\\,|_{\\bar{{{V}}}_{0}\\backslash\\mu^{-1}(F)}:\\,\\bar{V}_{0}\\backslash\\mu^{-1}(F){\\to}\\,\\bar{V}\\backslash F$ is a proper birational morphism, $\\mu^{*}$ gives rise to an isomorphism:\n\n$$\n\\Gamma(\\bar{V}\\backslash F,\\,\\Omega(\\log\\,D)^{M})\\cong\\Gamma(\\bar{V}_{0}\\backslash\\mu^{-1}(F),\\,\\Omega(\\log\\,D)^{M}).\n$$\n\nHowever, since $\\Gamma(\\bar{V}_{0}\\backslash\\mu^{-1}(F),~\\Omega(\\log~D_{0})^{M})\\supseteq\\Gamma(\\bar{V}_{0}\\,,~\\Omega(\\log~D_{0})^{M})=T_{M}(V_{0}),$ one has $\\bar{P}_{M}(V)\\geq\\bar{P}_{M}(V_{0})$ and hence $\\bar{{\\bar{P}}}_{M}(V)=\\bar{{\\bar{P}}}_{M}(V_{0})$ by Proposition 11.4.(ii).\u53e3\n\nTheorem 11.3. Let $V$ and W be varieties with dim $V=n$ and dim $W=r$. Then $\\bar{q}(V\\,\\times\\,W)=\\bar{q}(V)+\\bar{q}(W),\\;\\bar{P}_{m}(V\\,\\times\\,W)=\\bar{P}_{m}(V)\\cdot\\bar{P}_{m}(W)$ for all $m\\geq 1$, and $\\bar{\\kappa}(V\\times W)=\\bar{\\kappa}(V)+\\bar{\\kappa}(W)$.\n\nPROOF. We can assume that both $V$ and $W$ are nonsingular. As usual, take smooth completions $\\bar{V}$ and $\\bar{W}$ of $V$ and $W$ with smooth boundaries $D$ and $B$, respectively. Then $\\mathfrak{D}=\\bar{V}\\times B+D\\times\\bar{W}$ has only simple normal crossings and $\\bar{Z}=\\bar{V}\\times\\bar{W}$ is a smooth completion of $V\\times V$ with smooth boundary $\\mathfrak{D}$. Letting $p\\colon\\bar{V}\\times\\bar{W}\\to\\bar{V}$ and $q\\colon \\bar{V}\\times \\bar{W}\\to \\bar{W}$ be projections, one has\n\n$\\Omega{\\frac{1}{\\bar{Z}}}(\\log\\mathfrak{D})=p^{*}(\\Omega{\\frac{1}{V}}(\\log D))\\oplus q^{*}(\\Omega{\\frac{1}{W}}(\\log B))$ and so $\\Omega\\frac{n+r}{Z}(\\log\\,\\mathfrak{D})=p^{\\ast}(\\Omega{\\frac{n}{V}}(\\log D))\\otimes q^{*}(\\Omega{W}(\\log\\,B))$. Therefore,\n\n$$\n\\begin{array}{r l}{\\bar{q}\\big(V\\times W\\big)}&{=\\dim_{k}\\Gamma\\big(\\bar{Z},\\,\\Omega{\\frac{1}{Z}}(\\log\\,\\mathfrak{D})\\big)}\\\\ &{=\\dim_{k}\\Gamma(\\bar{V},\\,\\Omega\\frac{1}{V}(\\log\\,D))+\\dim_{k}\\,\\Gamma(\\bar{W},\\,\\Omega\\frac{1}{W}(\\log\\,B))}\\\\ &{=\\bar{q}(V)+\\bar{q}(W).}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "\\( \\Omega\\frac{n+r}{Z}(\\log\\,\\mathfrak{D})=p^{\\ast}(\\Omega\\frac{n}{V}(\\log D))\\otimes q^{*}(\\Omega{W}(\\log\\,B)) \\)",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/(Graduate_Studies_in_Mathematics,114)_Rotman,_Joseph_Jonah_-_Advanced_Modern_Algebra_(2010,_American_Mathematical_Society).pdf_314",
        "ID": "0cb1cb5a-68ec-4e22-89fa-67816f79e82c",
        "questions": "What type of bijection does the Correspondence Theorem for Rings provide between the set of all ideals in a commutative ring containing a proper ideal I and the set of all ideals in the quotient ring R/I?",
        "answers": "inclusion-preserving bijection",
        "context": "Proposition 5.1 (Correspondence Theorem for Rings). If $I$ is a proper ideal in a commutative ring $R$ , then there is an inclusion-preserving bijection $\\varphi$ from the set of all ideals $J$ in $R$ containing $I$ to the set of all ideals in $R/I$, given by\n\n$$\n\\varphi\\colon J\\mapsto J/I=\\{a+I\\colon a\\in J\\}.\n$$\n\nProof. If we forget its multiplication, the commutative ring $R$ is merely an additive abelian group and its ideal $I$ is a (normal) subgroup. The Correspondence Theorem for Groups, Theorem 1.82, now applies to the natural map $\\pi\\colon R\\to R/I$ , and it gives an inclusion-preserving bijection\n\n$\\Phi$ : {all subgroups of $R$ containing $I$ } $\\to$ {all subgroups of $R/I$}\n\nwhere $\\Phi(J)=\\pi(J)=J/I$\n\nIf $J$ is an ideal, then $\\Phi(J)$ is also an ideal, for if $r\\in R$ and $a\\in J$, then $r a\\in J$ and\n\n$$\n(r+I)(a+I)=r a+I\\in J/I.\n$$\n\nLet $\\varphi$ be the restriction of $\\Phi$ to the set of intermediate ideals; $\\varphi$ is an injection because $\\Phi$ is an injection. To see that $\\varphi$ is surjective, let $J^{*}$ be an ideal in $R/I$. Now $\\pi^{-1}(J^{*})$ is an intermediate ideal in $R$ , for it contains $I\\,=\\,\\pi^{-1}((0))$ , and $\\varphi(\\pi^{-1}(J^{*}))=\\pi(\\pi^{-1}(J^{*}))=J^{*}$.$^1$\n\n![](images/1b755787cc6e81b130a9af729091c620ff3d5c829140861469217d0e7580d4cd.jpg)  \nFigure 5.1. Correspondence Theorem.\n\nUsually, the Correspondence Theorem for Rings is invoked, tacitly, by saying that every ideal in the quotient ring $R/I$ has the form $J/I$ for some unique ideal $J$ with $I\\subseteq J\\subseteq R$\n\nExample 5.2. Let $I=(m)$ be a nonzero ideal in $\\mathbb{Z}$. If $J$ is an ideal in $\\mathbb{Z}$ containing $I$ , then $J=\\left(a\\right)$ for some $a\\in\\mathbb{Z}$ (because $\\mathbb{Z}$ is a PID). Since $(m)\\subseteq(a)$ if and only if $a\\mid m$ , the Correspondence Theorem for Rings shows that every ideal in the ring $\\mathbb{Z}/I=\\mathbb{I}_{m}$ has the form $J/I=\\left([a]\\right)$ for some divisor $a$ of $m$.\n\nDefinition. An ideal $I$ in a commutative ring $R$ is called a prime ideal if it is a proper ideal, that is, $I\\neq R,$ and $a b\\in I$ implies that $a\\in I$ or $b\\in I$\n\n# Example 5.3.\n\n(i) The ideal $(0)$ is a prime ideal in a ring $R$ if and only if $R$ is a domain.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Proposition 5.1 (Correspondence Theorem for Rings). If $I$ is a proper ideal in a commutative ring $R$ , then there is an inclusion-preserving bijection $\u000barphi$ from the set of all ideals $J$ in $R$ containing $I$ to the set of all ideals in $R/I$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/(Graduate_Studies_in_Mathematics,114)_Rotman,_Joseph_Jonah_-_Advanced_Modern_Algebra_(2010,_American_Mathematical_Society).pdf_314",
        "ID": "0cb22049-7ec9-4efc-a8c7-00b57379f4cc",
        "questions": "In the context of the Correspondence Theorem for Rings, how is the injection $\u000barphi$ related to $\\Phi$?",
        "answers": "$\u000barphi$ is the restriction of $\\Phi$ to the set of intermediate ideals",
        "context": "Proposition 5.1 (Correspondence Theorem for Rings). If $I$ is a proper ideal in a commutative ring $R$ , then there is an inclusion-preserving bijection $\\varphi$ from the set of all ideals $J$ in $R$ containing $I$ to the set of all ideals in $R/I$, given by\n\n$$\n\\varphi\\colon J\\mapsto J/I=\\{a+I\\colon a\\in J\\}.\n$$\n\nProof. If we forget its multiplication, the commutative ring $R$ is merely an additive abelian group and its ideal $I$ is a (normal) subgroup. The Correspondence Theorem for Groups, Theorem 1.82, now applies to the natural map $\\pi\\colon R\\to R/I$ , and it gives an inclusion-preserving bijection\n\n$\\Phi$ : {all subgroups of $R$ containing $I$ } $\\to$ {all subgroups of $R/I$}\n\nwhere $\\Phi(J)=\\pi(J)=J/I$\n\nIf $J$ is an ideal, then $\\Phi(J)$ is also an ideal, for if $r\\in R$ and $a\\in J$, then $r a\\in J$ and\n\n$$\n(r+I)(a+I)=r a+I\\in J/I.\n$$\n\nLet $\\varphi$ be the restriction of $\\Phi$ to the set of intermediate ideals; $\\varphi$ is an injection because $\\Phi$ is an injection. To see that $\\varphi$ is surjective, let $J^{*}$ be an ideal in $R/I$. Now $\\pi^{-1}(J^{*})$ is an intermediate ideal in $R$ , for it contains $I\\,=\\,\\pi^{-1}((0))$ , and $\\varphi(\\pi^{-1}(J^{*}))=\\pi(\\pi^{-1}(J^{*}))=J^{*}$.$^1$\n\n![](images/1b755787cc6e81b130a9af729091c620ff3d5c829140861469217d0e7580d4cd.jpg)  \nFigure 5.1. Correspondence Theorem.\n\nUsually, the Correspondence Theorem for Rings is invoked, tacitly, by saying that every ideal in the quotient ring $R/I$ has the form $J/I$ for some unique ideal $J$ with $I\\subseteq J\\subseteq R$\n\nExample 5.2. Let $I=(m)$ be a nonzero ideal in $\\mathbb{Z}$. If $J$ is an ideal in $\\mathbb{Z}$ containing $I$ , then $J=\\left(a\\right)$ for some $a\\in\\mathbb{Z}$ (because $\\mathbb{Z}$ is a PID). Since $(m)\\subseteq(a)$ if and only if $a\\mid m$ , the Correspondence Theorem for Rings shows that every ideal in the ring $\\mathbb{Z}/I=\\mathbb{I}_{m}$ has the form $J/I=\\left([a]\\right)$ for some divisor $a$ of $m$.\n\nDefinition. An ideal $I$ in a commutative ring $R$ is called a prime ideal if it is a proper ideal, that is, $I\\neq R,$ and $a b\\in I$ implies that $a\\in I$ or $b\\in I$\n\n# Example 5.3.\n\n(i) The ideal $(0)$ is a prime ideal in a ring $R$ if and only if $R$ is a domain.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Let $\u000barphi$ be the restriction of $\\Phi$ to the set of intermediate ideals; $\u000barphi$ is an injection because $\\Phi$ is an injection.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/(Graduate_Studies_in_Mathematics,114)_Rotman,_Joseph_Jonah_-_Advanced_Modern_Algebra_(2010,_American_Mathematical_Society).pdf_314",
        "ID": "0cb6021e-afe6-4875-b98d-086d18401176",
        "questions": "If I is a nonzero ideal in the ring of integers $\\mathbb{Z}$ denoted by (m), what condition must be satisfied for an ideal J in $\\mathbb{Z}$ to contain I according to the Correspondence Theorem for Rings?",
        "answers": "$a$ must be a divisor of $m$",
        "context": "Proposition 5.1 (Correspondence Theorem for Rings). If $I$ is a proper ideal in a commutative ring $R$ , then there is an inclusion-preserving bijection $\\varphi$ from the set of all ideals $J$ in $R$ containing $I$ to the set of all ideals in $R/I$, given by\n\n$$\n\\varphi\\colon J\\mapsto J/I=\\{a+I\\colon a\\in J\\}.\n$$\n\nProof. If we forget its multiplication, the commutative ring $R$ is merely an additive abelian group and its ideal $I$ is a (normal) subgroup. The Correspondence Theorem for Groups, Theorem 1.82, now applies to the natural map $\\pi\\colon R\\to R/I$ , and it gives an inclusion-preserving bijection\n\n$\\Phi$ : {all subgroups of $R$ containing $I$ } $\\to$ {all subgroups of $R/I$}\n\nwhere $\\Phi(J)=\\pi(J)=J/I$\n\nIf $J$ is an ideal, then $\\Phi(J)$ is also an ideal, for if $r\\in R$ and $a\\in J$, then $r a\\in J$ and\n\n$$\n(r+I)(a+I)=r a+I\\in J/I.\n$$\n\nLet $\\varphi$ be the restriction of $\\Phi$ to the set of intermediate ideals; $\\varphi$ is an injection because $\\Phi$ is an injection. To see that $\\varphi$ is surjective, let $J^{*}$ be an ideal in $R/I$. Now $\\pi^{-1}(J^{*})$ is an intermediate ideal in $R$ , for it contains $I\\,=\\,\\pi^{-1}((0))$ , and $\\varphi(\\pi^{-1}(J^{*}))=\\pi(\\pi^{-1}(J^{*}))=J^{*}$.$^1$\n\n![](images/1b755787cc6e81b130a9af729091c620ff3d5c829140861469217d0e7580d4cd.jpg)  \nFigure 5.1. Correspondence Theorem.\n\nUsually, the Correspondence Theorem for Rings is invoked, tacitly, by saying that every ideal in the quotient ring $R/I$ has the form $J/I$ for some unique ideal $J$ with $I\\subseteq J\\subseteq R$\n\nExample 5.2. Let $I=(m)$ be a nonzero ideal in $\\mathbb{Z}$. If $J$ is an ideal in $\\mathbb{Z}$ containing $I$ , then $J=\\left(a\\right)$ for some $a\\in\\mathbb{Z}$ (because $\\mathbb{Z}$ is a PID). Since $(m)\\subseteq(a)$ if and only if $a\\mid m$ , the Correspondence Theorem for Rings shows that every ideal in the ring $\\mathbb{Z}/I=\\mathbb{I}_{m}$ has the form $J/I=\\left([a]\\right)$ for some divisor $a$ of $m$.\n\nDefinition. An ideal $I$ in a commutative ring $R$ is called a prime ideal if it is a proper ideal, that is, $I\\neq R,$ and $a b\\in I$ implies that $a\\in I$ or $b\\in I$\n\n# Example 5.3.\n\n(i) The ideal $(0)$ is a prime ideal in a ring $R$ if and only if $R$ is a domain.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Since $(m)\\subseteq(a)$ if and only if $a\\mid m$, the Correspondence Theorem for Rings shows that every ideal in the ring $\\mathbb{Z}/I=\\mathbb{I}_{m}$ has the form $J/I=\\left([a]\right)$ for some divisor $a$ of $m$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/(Graduate_Studies_in_Mathematics,114)_Rotman,_Joseph_Jonah_-_Advanced_Modern_Algebra_(2010,_American_Mathematical_Society).pdf_314",
        "ID": "0cbdc014-dbed-442e-ada3-13e783e9973b",
        "questions": "What form does the ideal $J/I$ take in a commutative ring $\\mathbb{Z}/I$ according to Example 5.2 when $I=(m)$ is a nonzero ideal?",
        "answers": "$J/I=([a])$ for some divisor $a$ of $m$",
        "context": "Proposition 5.1 (Correspondence Theorem for Rings). If $I$ is a proper ideal in a commutative ring $R$ , then there is an inclusion-preserving bijection $\\varphi$ from the set of all ideals $J$ in $R$ containing $I$ to the set of all ideals in $R/I$, given by\n\n$$\n\\varphi\\colon J\\mapsto J/I=\\{a+I\\colon a\\in J\\}.\n$$\n\nProof. If we forget its multiplication, the commutative ring $R$ is merely an additive abelian group and its ideal $I$ is a (normal) subgroup. The Correspondence Theorem for Groups, Theorem 1.82, now applies to the natural map $\\pi\\colon R\\to R/I$ , and it gives an inclusion-preserving bijection\n\n$\\Phi$ : {all subgroups of $R$ containing $I$ } $\\to$ {all subgroups of $R/I$}\n\nwhere $\\Phi(J)=\\pi(J)=J/I$\n\nIf $J$ is an ideal, then $\\Phi(J)$ is also an ideal, for if $r\\in R$ and $a\\in J$, then $r a\\in J$ and\n\n$$\n(r+I)(a+I)=r a+I\\in J/I.\n$$\n\nLet $\\varphi$ be the restriction of $\\Phi$ to the set of intermediate ideals; $\\varphi$ is an injection because $\\Phi$ is an injection. To see that $\\varphi$ is surjective, let $J^{*}$ be an ideal in $R/I$. Now $\\pi^{-1}(J^{*})$ is an intermediate ideal in $R$ , for it contains $I\\,=\\,\\pi^{-1}((0))$ , and $\\varphi(\\pi^{-1}(J^{*}))=\\pi(\\pi^{-1}(J^{*}))=J^{*}$.$^1$\n\n![](images/1b755787cc6e81b130a9af729091c620ff3d5c829140861469217d0e7580d4cd.jpg)  \nFigure 5.1. Correspondence Theorem.\n\nUsually, the Correspondence Theorem for Rings is invoked, tacitly, by saying that every ideal in the quotient ring $R/I$ has the form $J/I$ for some unique ideal $J$ with $I\\subseteq J\\subseteq R$\n\nExample 5.2. Let $I=(m)$ be a nonzero ideal in $\\mathbb{Z}$. If $J$ is an ideal in $\\mathbb{Z}$ containing $I$ , then $J=\\left(a\\right)$ for some $a\\in\\mathbb{Z}$ (because $\\mathbb{Z}$ is a PID). Since $(m)\\subseteq(a)$ if and only if $a\\mid m$ , the Correspondence Theorem for Rings shows that every ideal in the ring $\\mathbb{Z}/I=\\mathbb{I}_{m}$ has the form $J/I=\\left([a]\\right)$ for some divisor $a$ of $m$.\n\nDefinition. An ideal $I$ in a commutative ring $R$ is called a prime ideal if it is a proper ideal, that is, $I\\neq R,$ and $a b\\in I$ implies that $a\\in I$ or $b\\in I$\n\n# Example 5.3.\n\n(i) The ideal $(0)$ is a prime ideal in a ring $R$ if and only if $R$ is a domain.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "the Correspondence Theorem for Rings shows that every ideal in the ring $\\mathbb{Z}/I=\\mathbb{I}_{m}$ has the form $J/I=\\left([a]\right)$ for some divisor $a$ of $m$.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/(Graduate_Studies_in_Mathematics,114)_Rotman,_Joseph_Jonah_-_Advanced_Modern_Algebra_(2010,_American_Mathematical_Society).pdf_314",
        "ID": "0cc458db-4700-4f81-ab9f-f7cfdc99c42c",
        "questions": "How does the ideal $\u000barphi(J)$ behave if $r \\in R$ and $a \\in J$ in the context of the Correspondence Theorem for Rings?",
        "answers": "$(r+I)(a+I)=r a+I$",
        "context": "Proposition 5.1 (Correspondence Theorem for Rings). If $I$ is a proper ideal in a commutative ring $R$ , then there is an inclusion-preserving bijection $\\varphi$ from the set of all ideals $J$ in $R$ containing $I$ to the set of all ideals in $R/I$, given by\n\n$$\n\\varphi\\colon J\\mapsto J/I=\\{a+I\\colon a\\in J\\}.\n$$\n\nProof. If we forget its multiplication, the commutative ring $R$ is merely an additive abelian group and its ideal $I$ is a (normal) subgroup. The Correspondence Theorem for Groups, Theorem 1.82, now applies to the natural map $\\pi\\colon R\\to R/I$ , and it gives an inclusion-preserving bijection\n\n$\\Phi$ : {all subgroups of $R$ containing $I$ } $\\to$ {all subgroups of $R/I$}\n\nwhere $\\Phi(J)=\\pi(J)=J/I$\n\nIf $J$ is an ideal, then $\\Phi(J)$ is also an ideal, for if $r\\in R$ and $a\\in J$, then $r a\\in J$ and\n\n$$\n(r+I)(a+I)=r a+I\\in J/I.\n$$\n\nLet $\\varphi$ be the restriction of $\\Phi$ to the set of intermediate ideals; $\\varphi$ is an injection because $\\Phi$ is an injection. To see that $\\varphi$ is surjective, let $J^{*}$ be an ideal in $R/I$. Now $\\pi^{-1}(J^{*})$ is an intermediate ideal in $R$ , for it contains $I\\,=\\,\\pi^{-1}((0))$ , and $\\varphi(\\pi^{-1}(J^{*}))=\\pi(\\pi^{-1}(J^{*}))=J^{*}$.$^1$\n\n![](images/1b755787cc6e81b130a9af729091c620ff3d5c829140861469217d0e7580d4cd.jpg)  \nFigure 5.1. Correspondence Theorem.\n\nUsually, the Correspondence Theorem for Rings is invoked, tacitly, by saying that every ideal in the quotient ring $R/I$ has the form $J/I$ for some unique ideal $J$ with $I\\subseteq J\\subseteq R$\n\nExample 5.2. Let $I=(m)$ be a nonzero ideal in $\\mathbb{Z}$. If $J$ is an ideal in $\\mathbb{Z}$ containing $I$ , then $J=\\left(a\\right)$ for some $a\\in\\mathbb{Z}$ (because $\\mathbb{Z}$ is a PID). Since $(m)\\subseteq(a)$ if and only if $a\\mid m$ , the Correspondence Theorem for Rings shows that every ideal in the ring $\\mathbb{Z}/I=\\mathbb{I}_{m}$ has the form $J/I=\\left([a]\\right)$ for some divisor $a$ of $m$.\n\nDefinition. An ideal $I$ in a commutative ring $R$ is called a prime ideal if it is a proper ideal, that is, $I\\neq R,$ and $a b\\in I$ implies that $a\\in I$ or $b\\in I$\n\n# Example 5.3.\n\n(i) The ideal $(0)$ is a prime ideal in a ring $R$ if and only if $R$ is a domain.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Numeric",
        "evidence_source": "equation",
        "evidence_context": "if $r\\in R$ and $a\\in J$, then $r a\\in J$ and $(r+I)(a+I)=r a+I\\in J/I$.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/(Graduate_Studies_in_Mathematics,114)_Rotman,_Joseph_Jonah_-_Advanced_Modern_Algebra_(2010,_American_Mathematical_Society).pdf_314",
        "ID": "0cce0637-c7ff-40a1-8239-4ef28c184ba0",
        "questions": "What is the relationship between $m$ and $a$ for the inclusion $(m) \\subseteq (a)$ to hold in the context of the Correspondence Theorem applied to $\\mathbb{Z}$?",
        "answers": "$a\\mid m$",
        "context": "Proposition 5.1 (Correspondence Theorem for Rings). If $I$ is a proper ideal in a commutative ring $R$ , then there is an inclusion-preserving bijection $\\varphi$ from the set of all ideals $J$ in $R$ containing $I$ to the set of all ideals in $R/I$, given by\n\n$$\n\\varphi\\colon J\\mapsto J/I=\\{a+I\\colon a\\in J\\}.\n$$\n\nProof. If we forget its multiplication, the commutative ring $R$ is merely an additive abelian group and its ideal $I$ is a (normal) subgroup. The Correspondence Theorem for Groups, Theorem 1.82, now applies to the natural map $\\pi\\colon R\\to R/I$ , and it gives an inclusion-preserving bijection\n\n$\\Phi$ : {all subgroups of $R$ containing $I$ } $\\to$ {all subgroups of $R/I$}\n\nwhere $\\Phi(J)=\\pi(J)=J/I$\n\nIf $J$ is an ideal, then $\\Phi(J)$ is also an ideal, for if $r\\in R$ and $a\\in J$, then $r a\\in J$ and\n\n$$\n(r+I)(a+I)=r a+I\\in J/I.\n$$\n\nLet $\\varphi$ be the restriction of $\\Phi$ to the set of intermediate ideals; $\\varphi$ is an injection because $\\Phi$ is an injection. To see that $\\varphi$ is surjective, let $J^{*}$ be an ideal in $R/I$. Now $\\pi^{-1}(J^{*})$ is an intermediate ideal in $R$ , for it contains $I\\,=\\,\\pi^{-1}((0))$ , and $\\varphi(\\pi^{-1}(J^{*}))=\\pi(\\pi^{-1}(J^{*}))=J^{*}$.$^1$\n\n![](images/1b755787cc6e81b130a9af729091c620ff3d5c829140861469217d0e7580d4cd.jpg)  \nFigure 5.1. Correspondence Theorem.\n\nUsually, the Correspondence Theorem for Rings is invoked, tacitly, by saying that every ideal in the quotient ring $R/I$ has the form $J/I$ for some unique ideal $J$ with $I\\subseteq J\\subseteq R$\n\nExample 5.2. Let $I=(m)$ be a nonzero ideal in $\\mathbb{Z}$. If $J$ is an ideal in $\\mathbb{Z}$ containing $I$ , then $J=\\left(a\\right)$ for some $a\\in\\mathbb{Z}$ (because $\\mathbb{Z}$ is a PID). Since $(m)\\subseteq(a)$ if and only if $a\\mid m$ , the Correspondence Theorem for Rings shows that every ideal in the ring $\\mathbb{Z}/I=\\mathbb{I}_{m}$ has the form $J/I=\\left([a]\\right)$ for some divisor $a$ of $m$.\n\nDefinition. An ideal $I$ in a commutative ring $R$ is called a prime ideal if it is a proper ideal, that is, $I\\neq R,$ and $a b\\in I$ implies that $a\\in I$ or $b\\in I$\n\n# Example 5.3.\n\n(i) The ideal $(0)$ is a prime ideal in a ring $R$ if and only if $R$ is a domain.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$(m)\\subseteq(a)$ if and only if $a\\mid m$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/c18a8ad752fb7e649161dcabed2d1fb96fa38265866c1e8d123ba292aa23f1de.pdf_3",
        "ID": "0cda520b-9aaf-4a93-a0f2-10f006ade140",
        "questions": "How many participants identified Marketing/Media Ads as an access point for their program?",
        "answers": "67",
        "context": "# Program Access Points  \n\nWhen participants were asked, \"What are the access points for your program?\", a wide range of answers were given. After examining responses, 8 major themes were identified. In addition to the eight specific access points and their corresponding sub-categories, a few miscellaneous answers have been listed.  \n\n# Points of Access  \n\n$\n\\begin{tabular}{|l|l|c|}\n \n & Definition & Frequency \\\\\n \nMarketing/Media Ads & Marketing or advertising efforts disseminated through media outlets like newspapers, magazines, TV, radio, phone book, newsletters, and church bulletins. Examples include On the Town, Grand Rapids Press, East Grand Rapids Cadence, Forest Hills Advance, El Vocero, and Women's Lifestyle Magazine. & 67 \\\\\n \nWord of Mouth & -- & 61 \\\\\n \nMailers/Flyers/Brochures & Print resources such as flyers, brochures, or postcards that are distributed to potential or recurring clients via direct mail or in person. & 45 \\\\\n \nWebsite/Internet & Organization's website or other Internet listing & 42 \\\\\n \nReferrals & - & 36 \\\\\n \nNetworking & Contact with individuals or organizations that could lead to increased participation in programs. Includes recruiting, indirect referrals, etc. & 19 \\\\\n \nNewsletter & Includes school newsletters. & 14 \\\\\n \nWalk-ins & - & 2 \\\\\n \n\\end{tabular}\n$\n\n# Miscellaneous Access Points  \n\n- Promotional materials available through the organization itself or related agencies. \n- Past experience with this or related programs. \n- Calls to the agency or hotline. \n- Signage or location of program. \n- Trade expo. Contracts. \n- Through Avon.\n- Presentations, seminars, public sessions.  \n\n- Give-a-ways. \n- Best checks. \n- Brochures sent to appropriate agencies who then redistribute them to clients that may be eligible. \n- Wic coupons. \n- Entire classes participate. \n- Teachers help identify at-risk kids; kids can sign-up if they're interested.\n- Food pantries.\n\n- Libraries.\n- United Way's 2-1-1.\n- Charity auctions.\n- Outreach posters.\n- Senior Millage.\n- Guide to healthy living.\n- Community gathering points.\n- When signing up for membership.\n- Annual advertised open house.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Numeric",
        "evidence_source": "table",
        "evidence_context": "Marketing/Media Ads & Marketing or advertising efforts disseminated through media outlets like newspapers, magazines, TV, radio, phone book, newsletters, and church bulletins. Examples include On the Town, Grand Rapids Press, East Grand Rapids Cadence, Forest Hills Advance, El Vocero, and Women's Lifestyle Magazine. & 67",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/c18a8ad752fb7e649161dcabed2d1fb96fa38265866c1e8d123ba292aa23f1de.pdf_3",
        "ID": "0cdff20e-c1e7-4ade-858e-8dfb98468947",
        "questions": "Which access point is defined as 'print resources such as flyers, brochures, or postcards that are distributed to potential or recurring clients via direct mail or in person'?",
        "answers": "Mailers/Flyers/Brochures",
        "context": "# Program Access Points  \n\nWhen participants were asked, \"What are the access points for your program?\", a wide range of answers were given. After examining responses, 8 major themes were identified. In addition to the eight specific access points and their corresponding sub-categories, a few miscellaneous answers have been listed.  \n\n# Points of Access  \n\n$\n\\begin{tabular}{|l|l|c|}\n \n & Definition & Frequency \\\\\n \nMarketing/Media Ads & Marketing or advertising efforts disseminated through media outlets like newspapers, magazines, TV, radio, phone book, newsletters, and church bulletins. Examples include On the Town, Grand Rapids Press, East Grand Rapids Cadence, Forest Hills Advance, El Vocero, and Women's Lifestyle Magazine. & 67 \\\\\n \nWord of Mouth & -- & 61 \\\\\n \nMailers/Flyers/Brochures & Print resources such as flyers, brochures, or postcards that are distributed to potential or recurring clients via direct mail or in person. & 45 \\\\\n \nWebsite/Internet & Organization's website or other Internet listing & 42 \\\\\n \nReferrals & - & 36 \\\\\n \nNetworking & Contact with individuals or organizations that could lead to increased participation in programs. Includes recruiting, indirect referrals, etc. & 19 \\\\\n \nNewsletter & Includes school newsletters. & 14 \\\\\n \nWalk-ins & - & 2 \\\\\n \n\\end{tabular}\n$\n\n# Miscellaneous Access Points  \n\n- Promotional materials available through the organization itself or related agencies. \n- Past experience with this or related programs. \n- Calls to the agency or hotline. \n- Signage or location of program. \n- Trade expo. Contracts. \n- Through Avon.\n- Presentations, seminars, public sessions.  \n\n- Give-a-ways. \n- Best checks. \n- Brochures sent to appropriate agencies who then redistribute them to clients that may be eligible. \n- Wic coupons. \n- Entire classes participate. \n- Teachers help identify at-risk kids; kids can sign-up if they're interested.\n- Food pantries.\n\n- Libraries.\n- United Way's 2-1-1.\n- Charity auctions.\n- Outreach posters.\n- Senior Millage.\n- Guide to healthy living.\n- Community gathering points.\n- When signing up for membership.\n- Annual advertised open house.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "table",
        "evidence_context": "Mailers/Flyers/Brochures & Print resources such as flyers, brochures, or postcards that are distributed to potential or recurring clients via direct mail or in person. & 45",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/c18a8ad752fb7e649161dcabed2d1fb96fa38265866c1e8d123ba292aa23f1de.pdf_3",
        "ID": "0ce19926-aaad-4b0d-a55c-cf51f3e77c60",
        "questions": "Which miscellaneous access points are mentioned for organizations promoting programs?",
        "answers": "calls to the agency or hotline, signage or location of program, trade expo, contracts",
        "context": "# Program Access Points  \n\nWhen participants were asked, \"What are the access points for your program?\", a wide range of answers were given. After examining responses, 8 major themes were identified. In addition to the eight specific access points and their corresponding sub-categories, a few miscellaneous answers have been listed.  \n\n# Points of Access  \n\n$\n\\begin{tabular}{|l|l|c|}\n \n & Definition & Frequency \\\\\n \nMarketing/Media Ads & Marketing or advertising efforts disseminated through media outlets like newspapers, magazines, TV, radio, phone book, newsletters, and church bulletins. Examples include On the Town, Grand Rapids Press, East Grand Rapids Cadence, Forest Hills Advance, El Vocero, and Women's Lifestyle Magazine. & 67 \\\\\n \nWord of Mouth & -- & 61 \\\\\n \nMailers/Flyers/Brochures & Print resources such as flyers, brochures, or postcards that are distributed to potential or recurring clients via direct mail or in person. & 45 \\\\\n \nWebsite/Internet & Organization's website or other Internet listing & 42 \\\\\n \nReferrals & - & 36 \\\\\n \nNetworking & Contact with individuals or organizations that could lead to increased participation in programs. Includes recruiting, indirect referrals, etc. & 19 \\\\\n \nNewsletter & Includes school newsletters. & 14 \\\\\n \nWalk-ins & - & 2 \\\\\n \n\\end{tabular}\n$\n\n# Miscellaneous Access Points  \n\n- Promotional materials available through the organization itself or related agencies. \n- Past experience with this or related programs. \n- Calls to the agency or hotline. \n- Signage or location of program. \n- Trade expo. Contracts. \n- Through Avon.\n- Presentations, seminars, public sessions.  \n\n- Give-a-ways. \n- Best checks. \n- Brochures sent to appropriate agencies who then redistribute them to clients that may be eligible. \n- Wic coupons. \n- Entire classes participate. \n- Teachers help identify at-risk kids; kids can sign-up if they're interested.\n- Food pantries.\n\n- Libraries.\n- United Way's 2-1-1.\n- Charity auctions.\n- Outreach posters.\n- Senior Millage.\n- Guide to healthy living.\n- Community gathering points.\n- When signing up for membership.\n- Annual advertised open house.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Miscellaneous Access Points\n- Calls to the agency or hotline.\n- Signage or location of program.\n- Trade expo. Contracts.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Oxford_University_Press_-_A_First_Course_in_Logic_-_An_Introduction_to_Model,_Proof_Theory,_Computability,_and_Complexity_-_2006.pdf_186",
        "ID": "0ce22c82-6262-402c-af46-d003d2cc42b1",
        "questions": "What can be inferred about $T_{\\gamma}$ if $T_{\beta}$ is not a successor ordinal?",
        "answers": "If $T_{\beta}$ is not a successor ordinal, it is a limit ordinal.",
        "context": "(ii) Otherwise $\\varphi_{\\gamma}$ has the form $\\exists x\\theta(x)$. In this case, let $T_{\\gamma+1}$ be $T_{\\gamma}\\cup\\{\\varphi_{\\gamma}\\}\\cup$ $\\{\\theta(c)\\}$ where $c$ is a constant in $C$ that does not occur in $T_{\\gamma}\\cup\\{\\varphi_{\\gamma}\\}$. Since $T_{\\gamma}$ contains fewer than $\\kappa$ constants of $C$, such a $c$ exists.  \n\nSo if $\\beta=\\gamma+1$, then $T_{\\beta}=T_{\\gamma+1}$ is obtained by adding at most a sentence or two to $T_{\\gamma}$. Since $T_{\\gamma}$ contains at most $|\\gamma|+\\aleph_{0}$ of the constants in $C$, so does $T_{\\beta}$. Moreover, $T_{\\beta}$ can be shown to be consistent in the same manner that $T_{m+1}$ was shown to be consistent in the first claim in the proof of Theorem 4.2.  \n\nNow suppose that $\\beta$ is not a successor ordinal. Then it is a limit ordinal. In this case, define $T_{\\beta}$ as the set of all $\\nu^{+}$ -sentences that occur in $T_{\\gamma}$ for some $\\gamma<\\beta$. Again, we claim that $T_{\\beta}$ is consistent and contains at most $|\\beta|+\\aleph_{0}$ of the constants in $C$.  \n\n# Claim 1: $T_{\\beta}$ is consistent.  \n\nProof: Suppose $T_{\\beta}$ is not consistent. Then $T_{\\beta}\\vdash\\bot$ for some contradiction $\\perp$. Since formal proofs are finite, $\\Delta\\vdash\\bot$ for some finite subset $\\Delta$ of $T_{\\beta}$. Since it is finite, $\\Delta\\subset T_{\\gamma}$ for some $\\gamma<\\beta$. But this contradicts our assumption that any such $T_{\\gamma}$ is consistent. We conclude that $T_{\\beta}$ must be consistent as was claimed.  \n\nClaim 2: $T_{\\beta}$ contains at most $|\\beta|$ of the constants in $C$.  \n\nProof: For each $\\gamma<\\beta$, let $C_{\\gamma}$ be the set of constants in $C$ that occur in $T_{\\gamma}$. Then $T_{\\beta}$ $U_{\\gamma<\\beta}\\,C_{\\gamma}$. $|C_{\\gamma}|\\leq|\\gamma|+\\aleph_{0}\\leq$ $|\\beta|+\\aleph_{0}$. Since we are assuming that $\\beta$ is a limit ordinal, $\\beta$ is infinite. In particular, $\\left|\\beta\\right|+\\aleph_{0}=\\left|\\beta\\right|$. So each $|C_{\\gamma}|\\leq|\\beta|$. It follows that the number of constants from $C$ occurring in $T_{\\beta}$ is  \n\n$$\n\\left|\\bigcup_{\\gamma<\\beta}C_{\\gamma}\\right|\\leq\\sum_{\\gamma<\\beta}|C_{\\gamma}|\\leq\\sum_{\\gamma<\\beta}|\\beta|=|\\beta|\\cdot|\\beta|=|\\beta|.\n$$  \n\nThis completes the proof of the claim.  \n\nSo for each $\\beta<\\alpha$, we have successfully defined a $\\nu^{+}$ -theory $T_{\\beta}$. These have been defined in such a way that $T_{\\beta_{1}}\\subset T_{\\beta_{2}}$ for $\\beta_{1}<\\beta_{2}<\\alpha$.  \n\nWe now define $T_{\\alpha}$ as the set of all $\\nu^{+}$ -sentences that occur in $T_{\\beta}$ for some $\\beta<\\alpha$. Like each $T_{\\beta}$, $T_{\\alpha}$ is a theory. This can be proved in the same manner as Claim 1 above. Unlike $T_{\\beta}$ for $\\beta<\\alpha$, $T_{\\alpha}$ is a complete theory. This is because each $\\nu^{+}$ -sentence is enumerated as $\\varphi_{\\ell}$ for some $\\iota<\\alpha$. Either $\\varphi_{t}$ or $\\neg\\varphi_{\\iota}$ is in $T_{t+1}$ and, hence, in $T_{\\alpha}$ as well.  \n\nSince $\\Gamma=T_{0}\\subset T_{\\alpha}$, $T_{\\alpha}$ has Property 1. Moreover, part (b)ii of the definition of $T_{\\gamma+1}\\subset T_{\\alpha}$ guarantees that $T_{\\alpha}$ has Property 2. It was shown in the proof of Theorem 4.2 that any complete theory with Property 2 has a model. Therefore, $T_{\\alpha}$ has a model and $\\Gamma$ is satisfiable.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Now suppose that $\\beta$ is not a successor ordinal. Then it is a limit ordinal.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Oxford_University_Press_-_A_First_Course_in_Logic_-_An_Introduction_to_Model,_Proof_Theory,_Computability,_and_Complexity_-_2006.pdf_186",
        "ID": "0ce72660-40b7-4fa8-ba92-f71ca40573b3",
        "questions": "If $T_{\beta}$ is supposed to be consistent, which condition would lead to a contradiction based on $T_{\beta} \\vdash \\bot$?",
        "answers": "$\\Delta \\subset T_{\\gamma}$ for some $\\gamma<\\beta$ would contradict this assumption.",
        "context": "(ii) Otherwise $\\varphi_{\\gamma}$ has the form $\\exists x\\theta(x)$. In this case, let $T_{\\gamma+1}$ be $T_{\\gamma}\\cup\\{\\varphi_{\\gamma}\\}\\cup$ $\\{\\theta(c)\\}$ where $c$ is a constant in $C$ that does not occur in $T_{\\gamma}\\cup\\{\\varphi_{\\gamma}\\}$. Since $T_{\\gamma}$ contains fewer than $\\kappa$ constants of $C$, such a $c$ exists.  \n\nSo if $\\beta=\\gamma+1$, then $T_{\\beta}=T_{\\gamma+1}$ is obtained by adding at most a sentence or two to $T_{\\gamma}$. Since $T_{\\gamma}$ contains at most $|\\gamma|+\\aleph_{0}$ of the constants in $C$, so does $T_{\\beta}$. Moreover, $T_{\\beta}$ can be shown to be consistent in the same manner that $T_{m+1}$ was shown to be consistent in the first claim in the proof of Theorem 4.2.  \n\nNow suppose that $\\beta$ is not a successor ordinal. Then it is a limit ordinal. In this case, define $T_{\\beta}$ as the set of all $\\nu^{+}$ -sentences that occur in $T_{\\gamma}$ for some $\\gamma<\\beta$. Again, we claim that $T_{\\beta}$ is consistent and contains at most $|\\beta|+\\aleph_{0}$ of the constants in $C$.  \n\n# Claim 1: $T_{\\beta}$ is consistent.  \n\nProof: Suppose $T_{\\beta}$ is not consistent. Then $T_{\\beta}\\vdash\\bot$ for some contradiction $\\perp$. Since formal proofs are finite, $\\Delta\\vdash\\bot$ for some finite subset $\\Delta$ of $T_{\\beta}$. Since it is finite, $\\Delta\\subset T_{\\gamma}$ for some $\\gamma<\\beta$. But this contradicts our assumption that any such $T_{\\gamma}$ is consistent. We conclude that $T_{\\beta}$ must be consistent as was claimed.  \n\nClaim 2: $T_{\\beta}$ contains at most $|\\beta|$ of the constants in $C$.  \n\nProof: For each $\\gamma<\\beta$, let $C_{\\gamma}$ be the set of constants in $C$ that occur in $T_{\\gamma}$. Then $T_{\\beta}$ $U_{\\gamma<\\beta}\\,C_{\\gamma}$. $|C_{\\gamma}|\\leq|\\gamma|+\\aleph_{0}\\leq$ $|\\beta|+\\aleph_{0}$. Since we are assuming that $\\beta$ is a limit ordinal, $\\beta$ is infinite. In particular, $\\left|\\beta\\right|+\\aleph_{0}=\\left|\\beta\\right|$. So each $|C_{\\gamma}|\\leq|\\beta|$. It follows that the number of constants from $C$ occurring in $T_{\\beta}$ is  \n\n$$\n\\left|\\bigcup_{\\gamma<\\beta}C_{\\gamma}\\right|\\leq\\sum_{\\gamma<\\beta}|C_{\\gamma}|\\leq\\sum_{\\gamma<\\beta}|\\beta|=|\\beta|\\cdot|\\beta|=|\\beta|.\n$$  \n\nThis completes the proof of the claim.  \n\nSo for each $\\beta<\\alpha$, we have successfully defined a $\\nu^{+}$ -theory $T_{\\beta}$. These have been defined in such a way that $T_{\\beta_{1}}\\subset T_{\\beta_{2}}$ for $\\beta_{1}<\\beta_{2}<\\alpha$.  \n\nWe now define $T_{\\alpha}$ as the set of all $\\nu^{+}$ -sentences that occur in $T_{\\beta}$ for some $\\beta<\\alpha$. Like each $T_{\\beta}$, $T_{\\alpha}$ is a theory. This can be proved in the same manner as Claim 1 above. Unlike $T_{\\beta}$ for $\\beta<\\alpha$, $T_{\\alpha}$ is a complete theory. This is because each $\\nu^{+}$ -sentence is enumerated as $\\varphi_{\\ell}$ for some $\\iota<\\alpha$. Either $\\varphi_{t}$ or $\\neg\\varphi_{\\iota}$ is in $T_{t+1}$ and, hence, in $T_{\\alpha}$ as well.  \n\nSince $\\Gamma=T_{0}\\subset T_{\\alpha}$, $T_{\\alpha}$ has Property 1. Moreover, part (b)ii of the definition of $T_{\\gamma+1}\\subset T_{\\alpha}$ guarantees that $T_{\\alpha}$ has Property 2. It was shown in the proof of Theorem 4.2 that any complete theory with Property 2 has a model. Therefore, $T_{\\alpha}$ has a model and $\\Gamma$ is satisfiable.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Since it is finite, $\\Delta\\subset T_{\\gamma}$ for some $\\gamma<\\beta$. But this contradicts our assumption that any such $T_{\\gamma}$ is consistent.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Oxford_University_Press_-_A_First_Course_in_Logic_-_An_Introduction_to_Model,_Proof_Theory,_Computability,_and_Complexity_-_2006.pdf_186",
        "ID": "0d08f653-9d76-4420-a4aa-f2b63602fef9",
        "questions": "How many constants from $C$ are expected in theory $T_{\\beta}$ for $\\beta$ as a limit ordinal?",
        "answers": "$|\\beta|$",
        "context": "(ii) Otherwise $\\varphi_{\\gamma}$ has the form $\\exists x\\theta(x)$. In this case, let $T_{\\gamma+1}$ be $T_{\\gamma}\\cup\\{\\varphi_{\\gamma}\\}\\cup$ $\\{\\theta(c)\\}$ where $c$ is a constant in $C$ that does not occur in $T_{\\gamma}\\cup\\{\\varphi_{\\gamma}\\}$. Since $T_{\\gamma}$ contains fewer than $\\kappa$ constants of $C$, such a $c$ exists.  \n\nSo if $\\beta=\\gamma+1$, then $T_{\\beta}=T_{\\gamma+1}$ is obtained by adding at most a sentence or two to $T_{\\gamma}$. Since $T_{\\gamma}$ contains at most $|\\gamma|+\\aleph_{0}$ of the constants in $C$, so does $T_{\\beta}$. Moreover, $T_{\\beta}$ can be shown to be consistent in the same manner that $T_{m+1}$ was shown to be consistent in the first claim in the proof of Theorem 4.2.  \n\nNow suppose that $\\beta$ is not a successor ordinal. Then it is a limit ordinal. In this case, define $T_{\\beta}$ as the set of all $\\nu^{+}$ -sentences that occur in $T_{\\gamma}$ for some $\\gamma<\\beta$. Again, we claim that $T_{\\beta}$ is consistent and contains at most $|\\beta|+\\aleph_{0}$ of the constants in $C$.  \n\n# Claim 1: $T_{\\beta}$ is consistent.  \n\nProof: Suppose $T_{\\beta}$ is not consistent. Then $T_{\\beta}\\vdash\\bot$ for some contradiction $\\perp$. Since formal proofs are finite, $\\Delta\\vdash\\bot$ for some finite subset $\\Delta$ of $T_{\\beta}$. Since it is finite, $\\Delta\\subset T_{\\gamma}$ for some $\\gamma<\\beta$. But this contradicts our assumption that any such $T_{\\gamma}$ is consistent. We conclude that $T_{\\beta}$ must be consistent as was claimed.  \n\nClaim 2: $T_{\\beta}$ contains at most $|\\beta|$ of the constants in $C$.  \n\nProof: For each $\\gamma<\\beta$, let $C_{\\gamma}$ be the set of constants in $C$ that occur in $T_{\\gamma}$. Then $T_{\\beta}$ $U_{\\gamma<\\beta}\\,C_{\\gamma}$. $|C_{\\gamma}|\\leq|\\gamma|+\\aleph_{0}\\leq$ $|\\beta|+\\aleph_{0}$. Since we are assuming that $\\beta$ is a limit ordinal, $\\beta$ is infinite. In particular, $\\left|\\beta\\right|+\\aleph_{0}=\\left|\\beta\\right|$. So each $|C_{\\gamma}|\\leq|\\beta|$. It follows that the number of constants from $C$ occurring in $T_{\\beta}$ is  \n\n$$\n\\left|\\bigcup_{\\gamma<\\beta}C_{\\gamma}\\right|\\leq\\sum_{\\gamma<\\beta}|C_{\\gamma}|\\leq\\sum_{\\gamma<\\beta}|\\beta|=|\\beta|\\cdot|\\beta|=|\\beta|.\n$$  \n\nThis completes the proof of the claim.  \n\nSo for each $\\beta<\\alpha$, we have successfully defined a $\\nu^{+}$ -theory $T_{\\beta}$. These have been defined in such a way that $T_{\\beta_{1}}\\subset T_{\\beta_{2}}$ for $\\beta_{1}<\\beta_{2}<\\alpha$.  \n\nWe now define $T_{\\alpha}$ as the set of all $\\nu^{+}$ -sentences that occur in $T_{\\beta}$ for some $\\beta<\\alpha$. Like each $T_{\\beta}$, $T_{\\alpha}$ is a theory. This can be proved in the same manner as Claim 1 above. Unlike $T_{\\beta}$ for $\\beta<\\alpha$, $T_{\\alpha}$ is a complete theory. This is because each $\\nu^{+}$ -sentence is enumerated as $\\varphi_{\\ell}$ for some $\\iota<\\alpha$. Either $\\varphi_{t}$ or $\\neg\\varphi_{\\iota}$ is in $T_{t+1}$ and, hence, in $T_{\\alpha}$ as well.  \n\nSince $\\Gamma=T_{0}\\subset T_{\\alpha}$, $T_{\\alpha}$ has Property 1. Moreover, part (b)ii of the definition of $T_{\\gamma+1}\\subset T_{\\alpha}$ guarantees that $T_{\\alpha}$ has Property 2. It was shown in the proof of Theorem 4.2 that any complete theory with Property 2 has a model. Therefore, $T_{\\alpha}$ has a model and $\\Gamma$ is satisfiable.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Numeric",
        "evidence_source": "equation",
        "evidence_context": "It follows that the number of constants from $C$ occurring in $T_{\\beta}$ is $\\left|\\bigcup_{\\gamma<\\beta}C_{\\gamma}\\right|\\leq\\sum_{\\gamma<\\beta}|C_{\\gamma}|\\leq\\sum_{\\gamma<\\beta}|\\beta|=|\\beta|\\cdot|\\beta|=|\\beta|.$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTX_-_Nonlinear_Elliptic_Partial_Differential_Equations.pdf_97",
        "ID": "0d0bb530-85a9-4ac4-97bb-f4d15fb16a54",
        "questions": "Under what condition is the function $T_{k}(u)$ equal to $u$ for $p = +\\infty$?",
        "answers": "$T_{k}(u)=u$ as soon as $k\\geq\\|u\\|_{L^{\\infty}(\\Omega)}$",
        "context": "Proof. Let us start with the $L^{p}$ case, $p<+\\infty$. There holds  \n\n$$\n\\begin{array}{l}{{\\displaystyle\\|u-T_{k}(u)\\|_{L^{p}(\\Omega)}^{p}=\\int_{\\{u<-k\\}}|u+k|^{p}\\,d x+\\int_{\\{u>k\\}}|u-k|^{p}\\,d x}}\\\\ {{\\displaystyle\\qquad\\qquad\\leq\\int_{\\{u<-k\\}}|u|^{p}\\,d x+\\int_{\\{u>k\\}}|u|^{p}\\,d x}}\\\\ {{\\displaystyle\\qquad\\qquad=\\int_{\\Omega}|u|^{p}\\mathbf{1}_{|u|>k}\\,d x\\,\\longrightarrow0}}\\end{array}\n$$  \n\nwhen $k \\to +\\infty$ by monotone convergence. Concerning gradients, if $u$ is in $W^{1,p}(\\Omega)$, we similarly have  \n\n$$\n\\|\\nabla u-\\nabla(T_{k}(u))\\|_{L^{p}(\\Omega)}^{p}=\\int_{\\Omega}|1-T_{k}^{\\prime}(u)|^{p}|\\nabla u|^{p}\\,d x=\\int_{\\Omega}|\\nabla u|^{p}\\mathbf{1}_{|u|>k}\\,d x\\,\\longrightarrow\\,0,\n$$  \n\nwhen $k \\to +\\infty$.  \n\nFinally, when $p=+\\infty, \\, T_{k}(u)=u$ as soon as $k\\geq\\|u\\|_{L^{\\infty}(\\Omega)}$.  \n\nRemark 3.10. i) In all cases, there holds $T_{k}(u)\\in L^{\\infty}(\\Omega)$ with $\\|T_{k}(u)\\|_{L^{\\infty}(\\Omega)}\\leq k$. ii) If $u\\in W_{0}^{1,p}(\\Omega)$ then $T_{k}(u)\\in W_{0}^{1,p}(\\Omega)$ since $T_{k}(0)=0$.  \n\nWe conclude this general study with a few remarks.  \n\nRemark 3.11. i) The superposition operators do not in general operate on Sobolev spaces of order higher than 1. Thus, for example, if $u\\in H^{2}(\\Omega)$, it is not necessarily the case that $u_{+} \\in H^{2}(\\Omega)$. This is obvious in one dimension of space, since $H^{2}(\\Omega) \\hookrightarrow C^{1}(\\bar{\\Omega})$ in this case. The problem, however, is not only connected to a lack of regularity of the function $T$. Thus, even if $T$ is of class $C^{\\infty}$ with $T^{\\prime}$ and $T^{\\prime\\prime}$ bounded, and $u\\in C^{\\infty}(\\Omega)\\cap H^{2}(\\Omega)$, we do not always have $T(u)\\in H^{2}(\\Omega)$.  \n\nIn effect, by the classical chain rule, $\\partial_{i}(T(u)) = T^{\\prime}(u)\\partial_{i}u$ and $\\partial_{i j}(T(u)) = T^{\\prime\\prime}(u)\\partial_{i}u\\partial_{j}u+T^{\\prime}(u)\\partial_{i j}u$. The second term in the expression of second derivatives actually belongs to $L^{2}(\\Omega)$. However, for the first term, in general $\\partial_{i}u \\partial_{j}u \\not\\in L^{2}(\\Omega)$ (except when $d\\leq 4$ by the Sobolev embeddings). Let us mention a more general result in this direction: if $T$ is $C^{\\infty}$, then for real $s$, if $u \\in W^{s,p}(\\Omega)$, then $T(u) \\in W^{s,p}(\\Omega)$ as soon as $s - \\frac{d}{p} > 0$, see for example [51].  \n\nii) The vector-valued case is comparable to the scalar case. If $T\\colon\\mathbb{R}^{m} \\rightarrow \\mathbb{R}$ is globally Lipschitz, then for all $u \\in W^{1,p}(\\Omega;\\mathbb{R}^{m}), \\, T(u) \\in W^{1,p}(\\Omega)$. On the other hand, the chain rule formula is not valid as such, because $D T(u)\\nabla u$ makes no sense in general. Consider, for example, for $m=2$, $T(u_{1},u_{2})=\\operatorname*{max}(u_{1},u_{2})$. If $u \\in H^{1}(\\Omega;\\mathbb{R}^{2})$ is of the form $u=(v,v)$ with $\\boldsymbol{v}\\in H^{1}(\\Omega)$, then $D T(u)$ is nowhere defined on $\\Omega$ whereas $\\nabla u$ is not zero almost everywhere on $\\Omega$. So we would be hard pressed to give a reasonable definition of such a product as $D T(u)\\nabla u$. There are, however, more complicated formulas to describe this gradient.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Finally, when $p=+\\infty, \\, T_{k}(u)=u as soon as $k\\geq \\|u\\|_{L^{\\infty}(\\Omega)}$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTX_-_Nonlinear_Elliptic_Partial_Differential_Equations.pdf_97",
        "ID": "0d0bd1c4-921a-4d1c-9408-ebd5e17425e7",
        "questions": "What is the inequality for the norm $\\|T_{k}(u)\\|_{L^{\\infty}(\\Omega)}$ if $T_{k}(u)$ belongs to $L^{\\infty}(\\Omega)$ and u belongs to $W_{0}^{1,p}(\\Omega)$?",
        "answers": "$\\|T_{k}(u)\\|_{L^{\\infty}(\\Omega)}\\leq k$",
        "context": "Proof. Let us start with the $L^{p}$ case, $p<+\\infty$. There holds  \n\n$$\n\\begin{array}{l}{{\\displaystyle\\|u-T_{k}(u)\\|_{L^{p}(\\Omega)}^{p}=\\int_{\\{u<-k\\}}|u+k|^{p}\\,d x+\\int_{\\{u>k\\}}|u-k|^{p}\\,d x}}\\\\ {{\\displaystyle\\qquad\\qquad\\leq\\int_{\\{u<-k\\}}|u|^{p}\\,d x+\\int_{\\{u>k\\}}|u|^{p}\\,d x}}\\\\ {{\\displaystyle\\qquad\\qquad=\\int_{\\Omega}|u|^{p}\\mathbf{1}_{|u|>k}\\,d x\\,\\longrightarrow0}}\\end{array}\n$$  \n\nwhen $k \\to +\\infty$ by monotone convergence. Concerning gradients, if $u$ is in $W^{1,p}(\\Omega)$, we similarly have  \n\n$$\n\\|\\nabla u-\\nabla(T_{k}(u))\\|_{L^{p}(\\Omega)}^{p}=\\int_{\\Omega}|1-T_{k}^{\\prime}(u)|^{p}|\\nabla u|^{p}\\,d x=\\int_{\\Omega}|\\nabla u|^{p}\\mathbf{1}_{|u|>k}\\,d x\\,\\longrightarrow\\,0,\n$$  \n\nwhen $k \\to +\\infty$.  \n\nFinally, when $p=+\\infty, \\, T_{k}(u)=u$ as soon as $k\\geq\\|u\\|_{L^{\\infty}(\\Omega)}$.  \n\nRemark 3.10. i) In all cases, there holds $T_{k}(u)\\in L^{\\infty}(\\Omega)$ with $\\|T_{k}(u)\\|_{L^{\\infty}(\\Omega)}\\leq k$. ii) If $u\\in W_{0}^{1,p}(\\Omega)$ then $T_{k}(u)\\in W_{0}^{1,p}(\\Omega)$ since $T_{k}(0)=0$.  \n\nWe conclude this general study with a few remarks.  \n\nRemark 3.11. i) The superposition operators do not in general operate on Sobolev spaces of order higher than 1. Thus, for example, if $u\\in H^{2}(\\Omega)$, it is not necessarily the case that $u_{+} \\in H^{2}(\\Omega)$. This is obvious in one dimension of space, since $H^{2}(\\Omega) \\hookrightarrow C^{1}(\\bar{\\Omega})$ in this case. The problem, however, is not only connected to a lack of regularity of the function $T$. Thus, even if $T$ is of class $C^{\\infty}$ with $T^{\\prime}$ and $T^{\\prime\\prime}$ bounded, and $u\\in C^{\\infty}(\\Omega)\\cap H^{2}(\\Omega)$, we do not always have $T(u)\\in H^{2}(\\Omega)$.  \n\nIn effect, by the classical chain rule, $\\partial_{i}(T(u)) = T^{\\prime}(u)\\partial_{i}u$ and $\\partial_{i j}(T(u)) = T^{\\prime\\prime}(u)\\partial_{i}u\\partial_{j}u+T^{\\prime}(u)\\partial_{i j}u$. The second term in the expression of second derivatives actually belongs to $L^{2}(\\Omega)$. However, for the first term, in general $\\partial_{i}u \\partial_{j}u \\not\\in L^{2}(\\Omega)$ (except when $d\\leq 4$ by the Sobolev embeddings). Let us mention a more general result in this direction: if $T$ is $C^{\\infty}$, then for real $s$, if $u \\in W^{s,p}(\\Omega)$, then $T(u) \\in W^{s,p}(\\Omega)$ as soon as $s - \\frac{d}{p} > 0$, see for example [51].  \n\nii) The vector-valued case is comparable to the scalar case. If $T\\colon\\mathbb{R}^{m} \\rightarrow \\mathbb{R}$ is globally Lipschitz, then for all $u \\in W^{1,p}(\\Omega;\\mathbb{R}^{m}), \\, T(u) \\in W^{1,p}(\\Omega)$. On the other hand, the chain rule formula is not valid as such, because $D T(u)\\nabla u$ makes no sense in general. Consider, for example, for $m=2$, $T(u_{1},u_{2})=\\operatorname*{max}(u_{1},u_{2})$. If $u \\in H^{1}(\\Omega;\\mathbb{R}^{2})$ is of the form $u=(v,v)$ with $\\boldsymbol{v}\\in H^{1}(\\Omega)$, then $D T(u)$ is nowhere defined on $\\Omega$ whereas $\\nabla u$ is not zero almost everywhere on $\\Omega$. So we would be hard pressed to give a reasonable definition of such a product as $D T(u)\\nabla u$. There are, however, more complicated formulas to describe this gradient.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "In all cases, there holds $T_{k}(u)\\in L^{\\infty}(\\Omega)$ with $\\|T_{k}(u)\\|_{L^{\\infty}(\\Omega)}\\leq k.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTX_-_Nonlinear_Elliptic_Partial_Differential_Equations.pdf_97",
        "ID": "0d0c61fd-4700-4eb8-b408-850e0fdc26f4",
        "questions": "Does $T(u)$ necessarily belong to $H^{2}(\\Omega)$ if $u$ belongs to $H^{2}(\\Omega)$ and $T$ is a class $C^{\\infty}$ function with bounded first and second derivatives?",
        "answers": "No",
        "context": "Proof. Let us start with the $L^{p}$ case, $p<+\\infty$. There holds  \n\n$$\n\\begin{array}{l}{{\\displaystyle\\|u-T_{k}(u)\\|_{L^{p}(\\Omega)}^{p}=\\int_{\\{u<-k\\}}|u+k|^{p}\\,d x+\\int_{\\{u>k\\}}|u-k|^{p}\\,d x}}\\\\ {{\\displaystyle\\qquad\\qquad\\leq\\int_{\\{u<-k\\}}|u|^{p}\\,d x+\\int_{\\{u>k\\}}|u|^{p}\\,d x}}\\\\ {{\\displaystyle\\qquad\\qquad=\\int_{\\Omega}|u|^{p}\\mathbf{1}_{|u|>k}\\,d x\\,\\longrightarrow0}}\\end{array}\n$$  \n\nwhen $k \\to +\\infty$ by monotone convergence. Concerning gradients, if $u$ is in $W^{1,p}(\\Omega)$, we similarly have  \n\n$$\n\\|\\nabla u-\\nabla(T_{k}(u))\\|_{L^{p}(\\Omega)}^{p}=\\int_{\\Omega}|1-T_{k}^{\\prime}(u)|^{p}|\\nabla u|^{p}\\,d x=\\int_{\\Omega}|\\nabla u|^{p}\\mathbf{1}_{|u|>k}\\,d x\\,\\longrightarrow\\,0,\n$$  \n\nwhen $k \\to +\\infty$.  \n\nFinally, when $p=+\\infty, \\, T_{k}(u)=u$ as soon as $k\\geq\\|u\\|_{L^{\\infty}(\\Omega)}$.  \n\nRemark 3.10. i) In all cases, there holds $T_{k}(u)\\in L^{\\infty}(\\Omega)$ with $\\|T_{k}(u)\\|_{L^{\\infty}(\\Omega)}\\leq k$. ii) If $u\\in W_{0}^{1,p}(\\Omega)$ then $T_{k}(u)\\in W_{0}^{1,p}(\\Omega)$ since $T_{k}(0)=0$.  \n\nWe conclude this general study with a few remarks.  \n\nRemark 3.11. i) The superposition operators do not in general operate on Sobolev spaces of order higher than 1. Thus, for example, if $u\\in H^{2}(\\Omega)$, it is not necessarily the case that $u_{+} \\in H^{2}(\\Omega)$. This is obvious in one dimension of space, since $H^{2}(\\Omega) \\hookrightarrow C^{1}(\\bar{\\Omega})$ in this case. The problem, however, is not only connected to a lack of regularity of the function $T$. Thus, even if $T$ is of class $C^{\\infty}$ with $T^{\\prime}$ and $T^{\\prime\\prime}$ bounded, and $u\\in C^{\\infty}(\\Omega)\\cap H^{2}(\\Omega)$, we do not always have $T(u)\\in H^{2}(\\Omega)$.  \n\nIn effect, by the classical chain rule, $\\partial_{i}(T(u)) = T^{\\prime}(u)\\partial_{i}u$ and $\\partial_{i j}(T(u)) = T^{\\prime\\prime}(u)\\partial_{i}u\\partial_{j}u+T^{\\prime}(u)\\partial_{i j}u$. The second term in the expression of second derivatives actually belongs to $L^{2}(\\Omega)$. However, for the first term, in general $\\partial_{i}u \\partial_{j}u \\not\\in L^{2}(\\Omega)$ (except when $d\\leq 4$ by the Sobolev embeddings). Let us mention a more general result in this direction: if $T$ is $C^{\\infty}$, then for real $s$, if $u \\in W^{s,p}(\\Omega)$, then $T(u) \\in W^{s,p}(\\Omega)$ as soon as $s - \\frac{d}{p} > 0$, see for example [51].  \n\nii) The vector-valued case is comparable to the scalar case. If $T\\colon\\mathbb{R}^{m} \\rightarrow \\mathbb{R}$ is globally Lipschitz, then for all $u \\in W^{1,p}(\\Omega;\\mathbb{R}^{m}), \\, T(u) \\in W^{1,p}(\\Omega)$. On the other hand, the chain rule formula is not valid as such, because $D T(u)\\nabla u$ makes no sense in general. Consider, for example, for $m=2$, $T(u_{1},u_{2})=\\operatorname*{max}(u_{1},u_{2})$. If $u \\in H^{1}(\\Omega;\\mathbb{R}^{2})$ is of the form $u=(v,v)$ with $\\boldsymbol{v}\\in H^{1}(\\Omega)$, then $D T(u)$ is nowhere defined on $\\Omega$ whereas $\\nabla u$ is not zero almost everywhere on $\\Omega$. So we would be hard pressed to give a reasonable definition of such a product as $D T(u)\\nabla u$. There are, however, more complicated formulas to describe this gradient.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Yes/No",
        "evidence_source": "text",
        "evidence_context": "even if $T$ is of class $C^{\\infty}$ with $T^{\\prime}$ and $T^{\\prime\\prime}$ bounded, and $u\\in C^{\\infty}(\\Omega)\\cap H^{2}(\\Omega)$, we do not always have $T(u)\\in H^{2}(\\Omega).",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTX_-_Nonlinear_Elliptic_Partial_Differential_Equations.pdf_97",
        "ID": "0d0d82f9-1b13-4405-b484-db42e58000cf",
        "questions": "What is the limit of the integral expression involving $|u|^{p}$ and the indicator function $\\mathbf{1}_{|u|>k}$ when $k \to +\\infty$ for a function $u$ in $L^p(\\Omega)$?",
        "answers": "0",
        "context": "Proof. Let us start with the $L^{p}$ case, $p<+\\infty$. There holds  \n\n$$\n\\begin{array}{l}{{\\displaystyle\\|u-T_{k}(u)\\|_{L^{p}(\\Omega)}^{p}=\\int_{\\{u<-k\\}}|u+k|^{p}\\,d x+\\int_{\\{u>k\\}}|u-k|^{p}\\,d x}}\\\\ {{\\displaystyle\\qquad\\qquad\\leq\\int_{\\{u<-k\\}}|u|^{p}\\,d x+\\int_{\\{u>k\\}}|u|^{p}\\,d x}}\\\\ {{\\displaystyle\\qquad\\qquad=\\int_{\\Omega}|u|^{p}\\mathbf{1}_{|u|>k}\\,d x\\,\\longrightarrow0}}\\end{array}\n$$  \n\nwhen $k \\to +\\infty$ by monotone convergence. Concerning gradients, if $u$ is in $W^{1,p}(\\Omega)$, we similarly have  \n\n$$\n\\|\\nabla u-\\nabla(T_{k}(u))\\|_{L^{p}(\\Omega)}^{p}=\\int_{\\Omega}|1-T_{k}^{\\prime}(u)|^{p}|\\nabla u|^{p}\\,d x=\\int_{\\Omega}|\\nabla u|^{p}\\mathbf{1}_{|u|>k}\\,d x\\,\\longrightarrow\\,0,\n$$  \n\nwhen $k \\to +\\infty$.  \n\nFinally, when $p=+\\infty, \\, T_{k}(u)=u$ as soon as $k\\geq\\|u\\|_{L^{\\infty}(\\Omega)}$.  \n\nRemark 3.10. i) In all cases, there holds $T_{k}(u)\\in L^{\\infty}(\\Omega)$ with $\\|T_{k}(u)\\|_{L^{\\infty}(\\Omega)}\\leq k$. ii) If $u\\in W_{0}^{1,p}(\\Omega)$ then $T_{k}(u)\\in W_{0}^{1,p}(\\Omega)$ since $T_{k}(0)=0$.  \n\nWe conclude this general study with a few remarks.  \n\nRemark 3.11. i) The superposition operators do not in general operate on Sobolev spaces of order higher than 1. Thus, for example, if $u\\in H^{2}(\\Omega)$, it is not necessarily the case that $u_{+} \\in H^{2}(\\Omega)$. This is obvious in one dimension of space, since $H^{2}(\\Omega) \\hookrightarrow C^{1}(\\bar{\\Omega})$ in this case. The problem, however, is not only connected to a lack of regularity of the function $T$. Thus, even if $T$ is of class $C^{\\infty}$ with $T^{\\prime}$ and $T^{\\prime\\prime}$ bounded, and $u\\in C^{\\infty}(\\Omega)\\cap H^{2}(\\Omega)$, we do not always have $T(u)\\in H^{2}(\\Omega)$.  \n\nIn effect, by the classical chain rule, $\\partial_{i}(T(u)) = T^{\\prime}(u)\\partial_{i}u$ and $\\partial_{i j}(T(u)) = T^{\\prime\\prime}(u)\\partial_{i}u\\partial_{j}u+T^{\\prime}(u)\\partial_{i j}u$. The second term in the expression of second derivatives actually belongs to $L^{2}(\\Omega)$. However, for the first term, in general $\\partial_{i}u \\partial_{j}u \\not\\in L^{2}(\\Omega)$ (except when $d\\leq 4$ by the Sobolev embeddings). Let us mention a more general result in this direction: if $T$ is $C^{\\infty}$, then for real $s$, if $u \\in W^{s,p}(\\Omega)$, then $T(u) \\in W^{s,p}(\\Omega)$ as soon as $s - \\frac{d}{p} > 0$, see for example [51].  \n\nii) The vector-valued case is comparable to the scalar case. If $T\\colon\\mathbb{R}^{m} \\rightarrow \\mathbb{R}$ is globally Lipschitz, then for all $u \\in W^{1,p}(\\Omega;\\mathbb{R}^{m}), \\, T(u) \\in W^{1,p}(\\Omega)$. On the other hand, the chain rule formula is not valid as such, because $D T(u)\\nabla u$ makes no sense in general. Consider, for example, for $m=2$, $T(u_{1},u_{2})=\\operatorname*{max}(u_{1},u_{2})$. If $u \\in H^{1}(\\Omega;\\mathbb{R}^{2})$ is of the form $u=(v,v)$ with $\\boldsymbol{v}\\in H^{1}(\\Omega)$, then $D T(u)$ is nowhere defined on $\\Omega$ whereas $\\nabla u$ is not zero almost everywhere on $\\Omega$. So we would be hard pressed to give a reasonable definition of such a product as $D T(u)\\nabla u$. There are, however, more complicated formulas to describe this gradient.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Numeric",
        "evidence_source": "equation",
        "evidence_context": "$\\int_{\\Omega}|u|^{p}\\mathbf{1}_{|u|>k}\\,d x\\,\\longrightarrow0",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/UTX_-_Nonlinear_Elliptic_Partial_Differential_Equations.pdf_97",
        "ID": "0d0da057-270a-4e47-b278-3dc3691712fc",
        "questions": "What is the condition for the second derivatives $\\partial_{ij}(T(u))$ to belong to $L^{2}(\\Omega)$ given $T$ is a $C^{\\infty}$ function and $u \\in C^{\\infty}(\\Omega) \\cap H^{2}(\\Omega)$?",
        "answers": "$s - \\frac{d}{p} > 0$",
        "context": "Proof. Let us start with the $L^{p}$ case, $p<+\\infty$. There holds  \n\n$$\n\\begin{array}{l}{{\\displaystyle\\|u-T_{k}(u)\\|_{L^{p}(\\Omega)}^{p}=\\int_{\\{u<-k\\}}|u+k|^{p}\\,d x+\\int_{\\{u>k\\}}|u-k|^{p}\\,d x}}\\\\ {{\\displaystyle\\qquad\\qquad\\leq\\int_{\\{u<-k\\}}|u|^{p}\\,d x+\\int_{\\{u>k\\}}|u|^{p}\\,d x}}\\\\ {{\\displaystyle\\qquad\\qquad=\\int_{\\Omega}|u|^{p}\\mathbf{1}_{|u|>k}\\,d x\\,\\longrightarrow0}}\\end{array}\n$$  \n\nwhen $k \\to +\\infty$ by monotone convergence. Concerning gradients, if $u$ is in $W^{1,p}(\\Omega)$, we similarly have  \n\n$$\n\\|\\nabla u-\\nabla(T_{k}(u))\\|_{L^{p}(\\Omega)}^{p}=\\int_{\\Omega}|1-T_{k}^{\\prime}(u)|^{p}|\\nabla u|^{p}\\,d x=\\int_{\\Omega}|\\nabla u|^{p}\\mathbf{1}_{|u|>k}\\,d x\\,\\longrightarrow\\,0,\n$$  \n\nwhen $k \\to +\\infty$.  \n\nFinally, when $p=+\\infty, \\, T_{k}(u)=u$ as soon as $k\\geq\\|u\\|_{L^{\\infty}(\\Omega)}$.  \n\nRemark 3.10. i) In all cases, there holds $T_{k}(u)\\in L^{\\infty}(\\Omega)$ with $\\|T_{k}(u)\\|_{L^{\\infty}(\\Omega)}\\leq k$. ii) If $u\\in W_{0}^{1,p}(\\Omega)$ then $T_{k}(u)\\in W_{0}^{1,p}(\\Omega)$ since $T_{k}(0)=0$.  \n\nWe conclude this general study with a few remarks.  \n\nRemark 3.11. i) The superposition operators do not in general operate on Sobolev spaces of order higher than 1. Thus, for example, if $u\\in H^{2}(\\Omega)$, it is not necessarily the case that $u_{+} \\in H^{2}(\\Omega)$. This is obvious in one dimension of space, since $H^{2}(\\Omega) \\hookrightarrow C^{1}(\\bar{\\Omega})$ in this case. The problem, however, is not only connected to a lack of regularity of the function $T$. Thus, even if $T$ is of class $C^{\\infty}$ with $T^{\\prime}$ and $T^{\\prime\\prime}$ bounded, and $u\\in C^{\\infty}(\\Omega)\\cap H^{2}(\\Omega)$, we do not always have $T(u)\\in H^{2}(\\Omega)$.  \n\nIn effect, by the classical chain rule, $\\partial_{i}(T(u)) = T^{\\prime}(u)\\partial_{i}u$ and $\\partial_{i j}(T(u)) = T^{\\prime\\prime}(u)\\partial_{i}u\\partial_{j}u+T^{\\prime}(u)\\partial_{i j}u$. The second term in the expression of second derivatives actually belongs to $L^{2}(\\Omega)$. However, for the first term, in general $\\partial_{i}u \\partial_{j}u \\not\\in L^{2}(\\Omega)$ (except when $d\\leq 4$ by the Sobolev embeddings). Let us mention a more general result in this direction: if $T$ is $C^{\\infty}$, then for real $s$, if $u \\in W^{s,p}(\\Omega)$, then $T(u) \\in W^{s,p}(\\Omega)$ as soon as $s - \\frac{d}{p} > 0$, see for example [51].  \n\nii) The vector-valued case is comparable to the scalar case. If $T\\colon\\mathbb{R}^{m} \\rightarrow \\mathbb{R}$ is globally Lipschitz, then for all $u \\in W^{1,p}(\\Omega;\\mathbb{R}^{m}), \\, T(u) \\in W^{1,p}(\\Omega)$. On the other hand, the chain rule formula is not valid as such, because $D T(u)\\nabla u$ makes no sense in general. Consider, for example, for $m=2$, $T(u_{1},u_{2})=\\operatorname*{max}(u_{1},u_{2})$. If $u \\in H^{1}(\\Omega;\\mathbb{R}^{2})$ is of the form $u=(v,v)$ with $\\boldsymbol{v}\\in H^{1}(\\Omega)$, then $D T(u)$ is nowhere defined on $\\Omega$ whereas $\\nabla u$ is not zero almost everywhere on $\\Omega$. So we would be hard pressed to give a reasonable definition of such a product as $D T(u)\\nabla u$. There are, however, more complicated formulas to describe this gradient.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "if $T$ is $C^{\\infty}$, then for real $s$, if $u \\in W^{s,p}(\\Omega)$, then $T(u) \\in W^{s,p}(\\Omega)$ as soon as $s - \\frac{d}{p} > 0$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/UTX_-_Nonlinear_Elliptic_Partial_Differential_Equations.pdf_97",
        "ID": "0d148001-3440-4f39-a66f-6fa04289e5b6",
        "questions": "Why does the chain rule formula not apply for certain vector-valued functions $T(u_1, u_2)$ defined as $\\operatorname*{max}(u_1, u_2)$ in a domain $u \\in H^{1}(\\Omega;\\mathbb{R}^{2})$ with $u=(v,v)$?",
        "answers": "Because $D T(u)$ is nowhere defined on $\\Omega$ whereas $\\nabla u$ is not zero almost everywhere on $\\Omega$.",
        "context": "Proof. Let us start with the $L^{p}$ case, $p<+\\infty$. There holds  \n\n$$\n\\begin{array}{l}{{\\displaystyle\\|u-T_{k}(u)\\|_{L^{p}(\\Omega)}^{p}=\\int_{\\{u<-k\\}}|u+k|^{p}\\,d x+\\int_{\\{u>k\\}}|u-k|^{p}\\,d x}}\\\\ {{\\displaystyle\\qquad\\qquad\\leq\\int_{\\{u<-k\\}}|u|^{p}\\,d x+\\int_{\\{u>k\\}}|u|^{p}\\,d x}}\\\\ {{\\displaystyle\\qquad\\qquad=\\int_{\\Omega}|u|^{p}\\mathbf{1}_{|u|>k}\\,d x\\,\\longrightarrow0}}\\end{array}\n$$  \n\nwhen $k \\to +\\infty$ by monotone convergence. Concerning gradients, if $u$ is in $W^{1,p}(\\Omega)$, we similarly have  \n\n$$\n\\|\\nabla u-\\nabla(T_{k}(u))\\|_{L^{p}(\\Omega)}^{p}=\\int_{\\Omega}|1-T_{k}^{\\prime}(u)|^{p}|\\nabla u|^{p}\\,d x=\\int_{\\Omega}|\\nabla u|^{p}\\mathbf{1}_{|u|>k}\\,d x\\,\\longrightarrow\\,0,\n$$  \n\nwhen $k \\to +\\infty$.  \n\nFinally, when $p=+\\infty, \\, T_{k}(u)=u$ as soon as $k\\geq\\|u\\|_{L^{\\infty}(\\Omega)}$.  \n\nRemark 3.10. i) In all cases, there holds $T_{k}(u)\\in L^{\\infty}(\\Omega)$ with $\\|T_{k}(u)\\|_{L^{\\infty}(\\Omega)}\\leq k$. ii) If $u\\in W_{0}^{1,p}(\\Omega)$ then $T_{k}(u)\\in W_{0}^{1,p}(\\Omega)$ since $T_{k}(0)=0$.  \n\nWe conclude this general study with a few remarks.  \n\nRemark 3.11. i) The superposition operators do not in general operate on Sobolev spaces of order higher than 1. Thus, for example, if $u\\in H^{2}(\\Omega)$, it is not necessarily the case that $u_{+} \\in H^{2}(\\Omega)$. This is obvious in one dimension of space, since $H^{2}(\\Omega) \\hookrightarrow C^{1}(\\bar{\\Omega})$ in this case. The problem, however, is not only connected to a lack of regularity of the function $T$. Thus, even if $T$ is of class $C^{\\infty}$ with $T^{\\prime}$ and $T^{\\prime\\prime}$ bounded, and $u\\in C^{\\infty}(\\Omega)\\cap H^{2}(\\Omega)$, we do not always have $T(u)\\in H^{2}(\\Omega)$.  \n\nIn effect, by the classical chain rule, $\\partial_{i}(T(u)) = T^{\\prime}(u)\\partial_{i}u$ and $\\partial_{i j}(T(u)) = T^{\\prime\\prime}(u)\\partial_{i}u\\partial_{j}u+T^{\\prime}(u)\\partial_{i j}u$. The second term in the expression of second derivatives actually belongs to $L^{2}(\\Omega)$. However, for the first term, in general $\\partial_{i}u \\partial_{j}u \\not\\in L^{2}(\\Omega)$ (except when $d\\leq 4$ by the Sobolev embeddings). Let us mention a more general result in this direction: if $T$ is $C^{\\infty}$, then for real $s$, if $u \\in W^{s,p}(\\Omega)$, then $T(u) \\in W^{s,p}(\\Omega)$ as soon as $s - \\frac{d}{p} > 0$, see for example [51].  \n\nii) The vector-valued case is comparable to the scalar case. If $T\\colon\\mathbb{R}^{m} \\rightarrow \\mathbb{R}$ is globally Lipschitz, then for all $u \\in W^{1,p}(\\Omega;\\mathbb{R}^{m}), \\, T(u) \\in W^{1,p}(\\Omega)$. On the other hand, the chain rule formula is not valid as such, because $D T(u)\\nabla u$ makes no sense in general. Consider, for example, for $m=2$, $T(u_{1},u_{2})=\\operatorname*{max}(u_{1},u_{2})$. If $u \\in H^{1}(\\Omega;\\mathbb{R}^{2})$ is of the form $u=(v,v)$ with $\\boldsymbol{v}\\in H^{1}(\\Omega)$, then $D T(u)$ is nowhere defined on $\\Omega$ whereas $\\nabla u$ is not zero almost everywhere on $\\Omega$. So we would be hard pressed to give a reasonable definition of such a product as $D T(u)\\nabla u$. There are, however, more complicated formulas to describe this gradient.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "then $D T(u)$ is nowhere defined on $\\Omega$ whereas $\\nabla u$ is not zero almost everywhere on $\\Omega$.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/Weak_Convergence_Of_Measures_Applications_In_.pdf_22",
        "ID": "0d16422e-94db-4613-9fb5-559e8b9e1fb2",
        "questions": "What does the document state about the convergence of finite-dimensional distributions and weak convergence of $P_{n}$ to $P$?",
        "answers": "If there is convergence of the finite-dimensional distributions, it does not follow that there is weak convergence of $P_{n}$ to $P$.",
        "context": "let $P$ be a unit mass at $x$ (that is, $P(A)$ is $^{1}$ or 0 according as $x$ lies in $A$ or not) and let $P_{n}$ be a unit mass at $x_{n}$. Now if $2/n$ is less than the smallest nonzero $t_{i}$, $x$, $x_{n}$, $\\pi_{t_{1}\\cdots t_{k}}^{-1}H$, $P\\pi_{t_{1}\\cdots t_{k}}^{-1}(H)$, $=P_{n}\\pi_{t_{1}\\cdots t_{k}}^{-1}(H)$, $P_{n}\\pi_{t_{1}\\cdots t_{k}}^{-1}\\Rightarrow P\\pi_{t_{1}\\cdots t_{k}}^{-1}$, $R^{k}$ for each $t_{1},\\cdots,t_{k}$. On the other hand, the set $\\{y:|y(t)|\\,\\leq\\,1/2,0\\,\\leqq t\\leqq1\\}$, the sphere of radius $1/2$ about $\\mathbf{x}$, is a $P$ -continuity set and $P_{n}(A)=1$ does not converge to $P(A)=0$. Thus $P_{n}$ does not converge weakly to $P$.\n\nThis example shows that if there is convergence of the finite-dimensional distributions, that is, if\n\n$$\nP_{n}\\pi_{t_{1}\\cdots t_{k}}^{-1}\\Rightarrow P\\pi_{t_{1}\\cdots t_{k}}^{-1}\n$$\n\nfor all $k$ and $t_{1},\\cdots,t_{k}$, it does not follow that there is weak convergence of $P_{n}$ to $P$.\n\n$$\nP_{n}\\Rightarrow P_{\\cdot}\n$$\n\n(The converse proposition of course does hold because of Corollary 2 to Theorem 3.3.) Thus weak convergence in $c$ involves considerations going beyond finite dimensional ones, which is why it is useful (see the introduction).\n\nOn the other hand, (5.1) does imply (5.2) in the presence of relative compactness.\n\nTHEOREM 5.1. If (5.1) holds for all $k$ and $t_{1},\\dots,t_{k}$ and if $\\left\\{{{\\cal P}}_{n}\\right\\}$ is relatively compact, then (5.2) holds.\n\nProof. Since $\\{P_{n}\\}$ is relatively compact, each subsequence $\\{P_{n_{i}}\\}$ contains a $\\{P_{n_{i_{m}}}\\}$ such that $P_{n_{i_{m}}}\\Rightarrow Q$ as $m\\to\\infty$. For each $Q$ in $C$, $P_{n_{i_{m}}}\\pi_{t_{1}\\cdots t_{k}}^{-1}\\Rightarrow\\hat{Q\\pi}_{t_{1}\\cdots t_{k}}^{-1}$, and $Q\\pi_{t_{1}\\cdots t_{k}}^{-1}$ is $\\mathbf{\\alpha}=P\\pi_{t_{1}\\cdots t_{k}}^{-1}$. Since $P$ and $Q$ are equal as observed above, this implies $P=Q$. Thus each subsequence of $\\{P_{n}\\}$ contains a further subsequence converging weakly to $P$, and (5.2) follows by Theorem 2.2.\n\nTheorem 4.1 characterizes relative compactness by tightness. In order to apply Theorem 5.1 in concrete cases, we shall in turn characterize tightness by means of the Arzela-Ascoli theorem.\n\nFor $x\\in C$ and $\\delta>0$ the modulus of continuity is defined by\n\n$$\nw_{x}(\\delta)=\\operatorname*{sup}\\{|x(s)-x(t)|\\,{:}0\\leq s,t\\leq1,|s-t|<\\delta\\}\\,.\n$$\n\nAccording to the Arzela-Ascoli theorem, a set $A$ in $c$ has compact closure if and only if\n\n$$\n\\operatorname*{sup}_{x\\in C}\\lvert x(0)\\rvert<\\infty\n$$\n\nand\n\n$$\n\\operatorname*{lim}_{\\delta\\to0}\\ \\operatorname*{sup}_{x\\in C}\\ w_{x}(\\delta)=0.\n$$\n\nTHEOREM 5.2. A family $\\Pi$ of probability measures on $c$ is tight (hence relatively compact) if and only if, for each $\\eta$, there exists an $a$ such that\n\n$$\nP\\{x\\!:\\!|x(0)|\\,>\\,a\\}\\,<\\eta\\,,\\ \\ \\ \\ \\ P\\in\\Pi\\,,\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "This example shows that if there is convergence of the finite-dimensional distributions, that is, if $$ P_{n}\\pi_{t_{1}\\cdots t_{k}}^{-1}\\Rightarrow P\\pi_{t_{1}\\cdots t_{k}}^{-1} $$ for all $k$ and $t_{1},\\cdots,t_{k}$, it does not follow that there is weak convergence of $P_{n}$ to $P$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Weak_Convergence_Of_Measures_Applications_In_.pdf_22",
        "ID": "0d270777-8762-4cc3-a724-c1fd5e1641ef",
        "questions": "What is needed for a set $A$ in $c$ to have compact closure according to the Arzela-Ascoli theorem?",
        "answers": "A set $A$ in $c$ has compact closure if and only if $$ \\operatorname*{sup}_{x\\in C}\\lvert x(0)\\rvert<\\infty $$ and $$ \\operatorname*{lim}_{\\delta\\to0}\\ \\operatorname*{sup}_{x\\in C}\\ w_{x}(\\delta)=0.$$",
        "context": "let $P$ be a unit mass at $x$ (that is, $P(A)$ is $^{1}$ or 0 according as $x$ lies in $A$ or not) and let $P_{n}$ be a unit mass at $x_{n}$. Now if $2/n$ is less than the smallest nonzero $t_{i}$, $x$, $x_{n}$, $\\pi_{t_{1}\\cdots t_{k}}^{-1}H$, $P\\pi_{t_{1}\\cdots t_{k}}^{-1}(H)$, $=P_{n}\\pi_{t_{1}\\cdots t_{k}}^{-1}(H)$, $P_{n}\\pi_{t_{1}\\cdots t_{k}}^{-1}\\Rightarrow P\\pi_{t_{1}\\cdots t_{k}}^{-1}$, $R^{k}$ for each $t_{1},\\cdots,t_{k}$. On the other hand, the set $\\{y:|y(t)|\\,\\leq\\,1/2,0\\,\\leqq t\\leqq1\\}$, the sphere of radius $1/2$ about $\\mathbf{x}$, is a $P$ -continuity set and $P_{n}(A)=1$ does not converge to $P(A)=0$. Thus $P_{n}$ does not converge weakly to $P$.\n\nThis example shows that if there is convergence of the finite-dimensional distributions, that is, if\n\n$$\nP_{n}\\pi_{t_{1}\\cdots t_{k}}^{-1}\\Rightarrow P\\pi_{t_{1}\\cdots t_{k}}^{-1}\n$$\n\nfor all $k$ and $t_{1},\\cdots,t_{k}$, it does not follow that there is weak convergence of $P_{n}$ to $P$.\n\n$$\nP_{n}\\Rightarrow P_{\\cdot}\n$$\n\n(The converse proposition of course does hold because of Corollary 2 to Theorem 3.3.) Thus weak convergence in $c$ involves considerations going beyond finite dimensional ones, which is why it is useful (see the introduction).\n\nOn the other hand, (5.1) does imply (5.2) in the presence of relative compactness.\n\nTHEOREM 5.1. If (5.1) holds for all $k$ and $t_{1},\\dots,t_{k}$ and if $\\left\\{{{\\cal P}}_{n}\\right\\}$ is relatively compact, then (5.2) holds.\n\nProof. Since $\\{P_{n}\\}$ is relatively compact, each subsequence $\\{P_{n_{i}}\\}$ contains a $\\{P_{n_{i_{m}}}\\}$ such that $P_{n_{i_{m}}}\\Rightarrow Q$ as $m\\to\\infty$. For each $Q$ in $C$, $P_{n_{i_{m}}}\\pi_{t_{1}\\cdots t_{k}}^{-1}\\Rightarrow\\hat{Q\\pi}_{t_{1}\\cdots t_{k}}^{-1}$, and $Q\\pi_{t_{1}\\cdots t_{k}}^{-1}$ is $\\mathbf{\\alpha}=P\\pi_{t_{1}\\cdots t_{k}}^{-1}$. Since $P$ and $Q$ are equal as observed above, this implies $P=Q$. Thus each subsequence of $\\{P_{n}\\}$ contains a further subsequence converging weakly to $P$, and (5.2) follows by Theorem 2.2.\n\nTheorem 4.1 characterizes relative compactness by tightness. In order to apply Theorem 5.1 in concrete cases, we shall in turn characterize tightness by means of the Arzela-Ascoli theorem.\n\nFor $x\\in C$ and $\\delta>0$ the modulus of continuity is defined by\n\n$$\nw_{x}(\\delta)=\\operatorname*{sup}\\{|x(s)-x(t)|\\,{:}0\\leq s,t\\leq1,|s-t|<\\delta\\}\\,.\n$$\n\nAccording to the Arzela-Ascoli theorem, a set $A$ in $c$ has compact closure if and only if\n\n$$\n\\operatorname*{sup}_{x\\in C}\\lvert x(0)\\rvert<\\infty\n$$\n\nand\n\n$$\n\\operatorname*{lim}_{\\delta\\to0}\\ \\operatorname*{sup}_{x\\in C}\\ w_{x}(\\delta)=0.\n$$\n\nTHEOREM 5.2. A family $\\Pi$ of probability measures on $c$ is tight (hence relatively compact) if and only if, for each $\\eta$, there exists an $a$ such that\n\n$$\nP\\{x\\!:\\!|x(0)|\\,>\\,a\\}\\,<\\eta\\,,\\ \\ \\ \\ \\ P\\in\\Pi\\,,\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "According to the Arzela-Ascoli theorem, a set $A$ in $c$ has compact closure if and only if $$ \\operatorname*{sup}_{x\\in C}\\lvert x(0)\\rvert<\\infty $$ and $$ \\operatorname*{lim}_{\\delta\\to0}\\ \\operatorname*{sup}_{x\\in C}\\ w_{x}(\\delta)=0.$$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Weak_Convergence_Of_Measures_Applications_In_.pdf_22",
        "ID": "0d38bf6e-86a2-49d7-be35-ea22fd1b285d",
        "questions": "Under what conditions does Theorem 5.1 state that weak convergence follows from finite-dimensional distribution convergence?",
        "answers": "If $$ P_{n}\\pi_{t_{1}\\cdots t_{k}}^{-1}\\Rightarrow P\\pi_{t_{1}\\cdots t_{k}}^{-1} $$ holds for all $k$ and $t_{1},\\dots,t_{k}$ and if $\\left\\{{{\\cal P}}_{n}\\right\\}$ is relatively compact.",
        "context": "let $P$ be a unit mass at $x$ (that is, $P(A)$ is $^{1}$ or 0 according as $x$ lies in $A$ or not) and let $P_{n}$ be a unit mass at $x_{n}$. Now if $2/n$ is less than the smallest nonzero $t_{i}$, $x$, $x_{n}$, $\\pi_{t_{1}\\cdots t_{k}}^{-1}H$, $P\\pi_{t_{1}\\cdots t_{k}}^{-1}(H)$, $=P_{n}\\pi_{t_{1}\\cdots t_{k}}^{-1}(H)$, $P_{n}\\pi_{t_{1}\\cdots t_{k}}^{-1}\\Rightarrow P\\pi_{t_{1}\\cdots t_{k}}^{-1}$, $R^{k}$ for each $t_{1},\\cdots,t_{k}$. On the other hand, the set $\\{y:|y(t)|\\,\\leq\\,1/2,0\\,\\leqq t\\leqq1\\}$, the sphere of radius $1/2$ about $\\mathbf{x}$, is a $P$ -continuity set and $P_{n}(A)=1$ does not converge to $P(A)=0$. Thus $P_{n}$ does not converge weakly to $P$.\n\nThis example shows that if there is convergence of the finite-dimensional distributions, that is, if\n\n$$\nP_{n}\\pi_{t_{1}\\cdots t_{k}}^{-1}\\Rightarrow P\\pi_{t_{1}\\cdots t_{k}}^{-1}\n$$\n\nfor all $k$ and $t_{1},\\cdots,t_{k}$, it does not follow that there is weak convergence of $P_{n}$ to $P$.\n\n$$\nP_{n}\\Rightarrow P_{\\cdot}\n$$\n\n(The converse proposition of course does hold because of Corollary 2 to Theorem 3.3.) Thus weak convergence in $c$ involves considerations going beyond finite dimensional ones, which is why it is useful (see the introduction).\n\nOn the other hand, (5.1) does imply (5.2) in the presence of relative compactness.\n\nTHEOREM 5.1. If (5.1) holds for all $k$ and $t_{1},\\dots,t_{k}$ and if $\\left\\{{{\\cal P}}_{n}\\right\\}$ is relatively compact, then (5.2) holds.\n\nProof. Since $\\{P_{n}\\}$ is relatively compact, each subsequence $\\{P_{n_{i}}\\}$ contains a $\\{P_{n_{i_{m}}}\\}$ such that $P_{n_{i_{m}}}\\Rightarrow Q$ as $m\\to\\infty$. For each $Q$ in $C$, $P_{n_{i_{m}}}\\pi_{t_{1}\\cdots t_{k}}^{-1}\\Rightarrow\\hat{Q\\pi}_{t_{1}\\cdots t_{k}}^{-1}$, and $Q\\pi_{t_{1}\\cdots t_{k}}^{-1}$ is $\\mathbf{\\alpha}=P\\pi_{t_{1}\\cdots t_{k}}^{-1}$. Since $P$ and $Q$ are equal as observed above, this implies $P=Q$. Thus each subsequence of $\\{P_{n}\\}$ contains a further subsequence converging weakly to $P$, and (5.2) follows by Theorem 2.2.\n\nTheorem 4.1 characterizes relative compactness by tightness. In order to apply Theorem 5.1 in concrete cases, we shall in turn characterize tightness by means of the Arzela-Ascoli theorem.\n\nFor $x\\in C$ and $\\delta>0$ the modulus of continuity is defined by\n\n$$\nw_{x}(\\delta)=\\operatorname*{sup}\\{|x(s)-x(t)|\\,{:}0\\leq s,t\\leq1,|s-t|<\\delta\\}\\,.\n$$\n\nAccording to the Arzela-Ascoli theorem, a set $A$ in $c$ has compact closure if and only if\n\n$$\n\\operatorname*{sup}_{x\\in C}\\lvert x(0)\\rvert<\\infty\n$$\n\nand\n\n$$\n\\operatorname*{lim}_{\\delta\\to0}\\ \\operatorname*{sup}_{x\\in C}\\ w_{x}(\\delta)=0.\n$$\n\nTHEOREM 5.2. A family $\\Pi$ of probability measures on $c$ is tight (hence relatively compact) if and only if, for each $\\eta$, there exists an $a$ such that\n\n$$\nP\\{x\\!:\\!|x(0)|\\,>\\,a\\}\\,<\\eta\\,,\\ \\ \\ \\ \\ P\\in\\Pi\\,,\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "THEOREM 5.1. If (5.1) holds for all $k$ and $t_{1},\\dots,t_{k}$ and if $\\left\\{{{\\cal P}}_{n}\\right\\}$ is relatively compact, then (5.2) holds.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Weak_Convergence_Of_Measures_Applications_In_.pdf_22",
        "ID": "0d58f90a-6eb8-4594-a47b-7b4da46dfd05",
        "questions": "What condition is expressed by the equation $P_{n}\\pi_{t_{1}\\cdots t_{k}}^{-1}\\Rightarrow P\\pi_{t_{1}\\cdots t_{k}}^{-1}$?",
        "answers": "convergence of the finite-dimensional distributions",
        "context": "let $P$ be a unit mass at $x$ (that is, $P(A)$ is $^{1}$ or 0 according as $x$ lies in $A$ or not) and let $P_{n}$ be a unit mass at $x_{n}$. Now if $2/n$ is less than the smallest nonzero $t_{i}$, $x$, $x_{n}$, $\\pi_{t_{1}\\cdots t_{k}}^{-1}H$, $P\\pi_{t_{1}\\cdots t_{k}}^{-1}(H)$, $=P_{n}\\pi_{t_{1}\\cdots t_{k}}^{-1}(H)$, $P_{n}\\pi_{t_{1}\\cdots t_{k}}^{-1}\\Rightarrow P\\pi_{t_{1}\\cdots t_{k}}^{-1}$, $R^{k}$ for each $t_{1},\\cdots,t_{k}$. On the other hand, the set $\\{y:|y(t)|\\,\\leq\\,1/2,0\\,\\leqq t\\leqq1\\}$, the sphere of radius $1/2$ about $\\mathbf{x}$, is a $P$ -continuity set and $P_{n}(A)=1$ does not converge to $P(A)=0$. Thus $P_{n}$ does not converge weakly to $P$.\n\nThis example shows that if there is convergence of the finite-dimensional distributions, that is, if\n\n$$\nP_{n}\\pi_{t_{1}\\cdots t_{k}}^{-1}\\Rightarrow P\\pi_{t_{1}\\cdots t_{k}}^{-1}\n$$\n\nfor all $k$ and $t_{1},\\cdots,t_{k}$, it does not follow that there is weak convergence of $P_{n}$ to $P$.\n\n$$\nP_{n}\\Rightarrow P_{\\cdot}\n$$\n\n(The converse proposition of course does hold because of Corollary 2 to Theorem 3.3.) Thus weak convergence in $c$ involves considerations going beyond finite dimensional ones, which is why it is useful (see the introduction).\n\nOn the other hand, (5.1) does imply (5.2) in the presence of relative compactness.\n\nTHEOREM 5.1. If (5.1) holds for all $k$ and $t_{1},\\dots,t_{k}$ and if $\\left\\{{{\\cal P}}_{n}\\right\\}$ is relatively compact, then (5.2) holds.\n\nProof. Since $\\{P_{n}\\}$ is relatively compact, each subsequence $\\{P_{n_{i}}\\}$ contains a $\\{P_{n_{i_{m}}}\\}$ such that $P_{n_{i_{m}}}\\Rightarrow Q$ as $m\\to\\infty$. For each $Q$ in $C$, $P_{n_{i_{m}}}\\pi_{t_{1}\\cdots t_{k}}^{-1}\\Rightarrow\\hat{Q\\pi}_{t_{1}\\cdots t_{k}}^{-1}$, and $Q\\pi_{t_{1}\\cdots t_{k}}^{-1}$ is $\\mathbf{\\alpha}=P\\pi_{t_{1}\\cdots t_{k}}^{-1}$. Since $P$ and $Q$ are equal as observed above, this implies $P=Q$. Thus each subsequence of $\\{P_{n}\\}$ contains a further subsequence converging weakly to $P$, and (5.2) follows by Theorem 2.2.\n\nTheorem 4.1 characterizes relative compactness by tightness. In order to apply Theorem 5.1 in concrete cases, we shall in turn characterize tightness by means of the Arzela-Ascoli theorem.\n\nFor $x\\in C$ and $\\delta>0$ the modulus of continuity is defined by\n\n$$\nw_{x}(\\delta)=\\operatorname*{sup}\\{|x(s)-x(t)|\\,{:}0\\leq s,t\\leq1,|s-t|<\\delta\\}\\,.\n$$\n\nAccording to the Arzela-Ascoli theorem, a set $A$ in $c$ has compact closure if and only if\n\n$$\n\\operatorname*{sup}_{x\\in C}\\lvert x(0)\\rvert<\\infty\n$$\n\nand\n\n$$\n\\operatorname*{lim}_{\\delta\\to0}\\ \\operatorname*{sup}_{x\\in C}\\ w_{x}(\\delta)=0.\n$$\n\nTHEOREM 5.2. A family $\\Pi$ of probability measures on $c$ is tight (hence relatively compact) if and only if, for each $\\eta$, there exists an $a$ such that\n\n$$\nP\\{x\\!:\\!|x(0)|\\,>\\,a\\}\\,<\\eta\\,,\\ \\ \\ \\ \\ P\\in\\Pi\\,,\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "This example shows that if there is convergence of the finite-dimensional distributions, that is, if $P_{n}\\pi_{t_{1}\\cdots t_{k}}^{-1}\\Rightarrow P\\pi_{t_{1}\\cdots t_{k}}^{-1}$ for all $k$ and $t_{1},\\cdots,t_{k}$, it does not follow that there is weak convergence of $P_{n}$ to $P$.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/Weak_Convergence_Of_Measures_Applications_In_.pdf_22",
        "ID": "0d5e0895-d751-4fe6-983f-c86afad2873a",
        "questions": "According to Theorem 5.1, what two conditions must hold for (5.2) to follow from (5.1)?",
        "answers": "If (5.1) holds for all $k$ and $t_{1},\\dots,t_{k}$ and if $\\left\\{{{\\cal P}}_{n}\right\\}$ is relatively compact, then (5.2) holds.",
        "context": "let $P$ be a unit mass at $x$ (that is, $P(A)$ is $^{1}$ or 0 according as $x$ lies in $A$ or not) and let $P_{n}$ be a unit mass at $x_{n}$. Now if $2/n$ is less than the smallest nonzero $t_{i}$, $x$, $x_{n}$, $\\pi_{t_{1}\\cdots t_{k}}^{-1}H$, $P\\pi_{t_{1}\\cdots t_{k}}^{-1}(H)$, $=P_{n}\\pi_{t_{1}\\cdots t_{k}}^{-1}(H)$, $P_{n}\\pi_{t_{1}\\cdots t_{k}}^{-1}\\Rightarrow P\\pi_{t_{1}\\cdots t_{k}}^{-1}$, $R^{k}$ for each $t_{1},\\cdots,t_{k}$. On the other hand, the set $\\{y:|y(t)|\\,\\leq\\,1/2,0\\,\\leqq t\\leqq1\\}$, the sphere of radius $1/2$ about $\\mathbf{x}$, is a $P$ -continuity set and $P_{n}(A)=1$ does not converge to $P(A)=0$. Thus $P_{n}$ does not converge weakly to $P$.\n\nThis example shows that if there is convergence of the finite-dimensional distributions, that is, if\n\n$$\nP_{n}\\pi_{t_{1}\\cdots t_{k}}^{-1}\\Rightarrow P\\pi_{t_{1}\\cdots t_{k}}^{-1}\n$$\n\nfor all $k$ and $t_{1},\\cdots,t_{k}$, it does not follow that there is weak convergence of $P_{n}$ to $P$.\n\n$$\nP_{n}\\Rightarrow P_{\\cdot}\n$$\n\n(The converse proposition of course does hold because of Corollary 2 to Theorem 3.3.) Thus weak convergence in $c$ involves considerations going beyond finite dimensional ones, which is why it is useful (see the introduction).\n\nOn the other hand, (5.1) does imply (5.2) in the presence of relative compactness.\n\nTHEOREM 5.1. If (5.1) holds for all $k$ and $t_{1},\\dots,t_{k}$ and if $\\left\\{{{\\cal P}}_{n}\\right\\}$ is relatively compact, then (5.2) holds.\n\nProof. Since $\\{P_{n}\\}$ is relatively compact, each subsequence $\\{P_{n_{i}}\\}$ contains a $\\{P_{n_{i_{m}}}\\}$ such that $P_{n_{i_{m}}}\\Rightarrow Q$ as $m\\to\\infty$. For each $Q$ in $C$, $P_{n_{i_{m}}}\\pi_{t_{1}\\cdots t_{k}}^{-1}\\Rightarrow\\hat{Q\\pi}_{t_{1}\\cdots t_{k}}^{-1}$, and $Q\\pi_{t_{1}\\cdots t_{k}}^{-1}$ is $\\mathbf{\\alpha}=P\\pi_{t_{1}\\cdots t_{k}}^{-1}$. Since $P$ and $Q$ are equal as observed above, this implies $P=Q$. Thus each subsequence of $\\{P_{n}\\}$ contains a further subsequence converging weakly to $P$, and (5.2) follows by Theorem 2.2.\n\nTheorem 4.1 characterizes relative compactness by tightness. In order to apply Theorem 5.1 in concrete cases, we shall in turn characterize tightness by means of the Arzela-Ascoli theorem.\n\nFor $x\\in C$ and $\\delta>0$ the modulus of continuity is defined by\n\n$$\nw_{x}(\\delta)=\\operatorname*{sup}\\{|x(s)-x(t)|\\,{:}0\\leq s,t\\leq1,|s-t|<\\delta\\}\\,.\n$$\n\nAccording to the Arzela-Ascoli theorem, a set $A$ in $c$ has compact closure if and only if\n\n$$\n\\operatorname*{sup}_{x\\in C}\\lvert x(0)\\rvert<\\infty\n$$\n\nand\n\n$$\n\\operatorname*{lim}_{\\delta\\to0}\\ \\operatorname*{sup}_{x\\in C}\\ w_{x}(\\delta)=0.\n$$\n\nTHEOREM 5.2. A family $\\Pi$ of probability measures on $c$ is tight (hence relatively compact) if and only if, for each $\\eta$, there exists an $a$ such that\n\n$$\nP\\{x\\!:\\!|x(0)|\\,>\\,a\\}\\,<\\eta\\,,\\ \\ \\ \\ \\ P\\in\\Pi\\,,\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "THEOREM 5.1. If (5.1) holds for all $k$ and $t_{1},\\dots,t_{k}$ and if $\\left\\{{{\\cal P}}_{n}\right\\}$ is relatively compact, then (5.2) holds.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/Weak_Convergence_Of_Measures_Applications_In_.pdf_22",
        "ID": "0d7198d2-b6c7-4c17-8ea9-39c51a2ae07f",
        "questions": "What definition does Theorem 5.2 give for a family \u03a0 of probability measures on $c$ to be tight and relatively compact?",
        "answers": "A family $\\Pi$ of probability measures on $c$ is tight (hence relatively compact) if and only if, for each $\\eta$, there exists an $a$ such that $P\\{x:|x(0)|>a\\}<\\eta$, $P\\in\\Pi$",
        "context": "let $P$ be a unit mass at $x$ (that is, $P(A)$ is $^{1}$ or 0 according as $x$ lies in $A$ or not) and let $P_{n}$ be a unit mass at $x_{n}$. Now if $2/n$ is less than the smallest nonzero $t_{i}$, $x$, $x_{n}$, $\\pi_{t_{1}\\cdots t_{k}}^{-1}H$, $P\\pi_{t_{1}\\cdots t_{k}}^{-1}(H)$, $=P_{n}\\pi_{t_{1}\\cdots t_{k}}^{-1}(H)$, $P_{n}\\pi_{t_{1}\\cdots t_{k}}^{-1}\\Rightarrow P\\pi_{t_{1}\\cdots t_{k}}^{-1}$, $R^{k}$ for each $t_{1},\\cdots,t_{k}$. On the other hand, the set $\\{y:|y(t)|\\,\\leq\\,1/2,0\\,\\leqq t\\leqq1\\}$, the sphere of radius $1/2$ about $\\mathbf{x}$, is a $P$ -continuity set and $P_{n}(A)=1$ does not converge to $P(A)=0$. Thus $P_{n}$ does not converge weakly to $P$.\n\nThis example shows that if there is convergence of the finite-dimensional distributions, that is, if\n\n$$\nP_{n}\\pi_{t_{1}\\cdots t_{k}}^{-1}\\Rightarrow P\\pi_{t_{1}\\cdots t_{k}}^{-1}\n$$\n\nfor all $k$ and $t_{1},\\cdots,t_{k}$, it does not follow that there is weak convergence of $P_{n}$ to $P$.\n\n$$\nP_{n}\\Rightarrow P_{\\cdot}\n$$\n\n(The converse proposition of course does hold because of Corollary 2 to Theorem 3.3.) Thus weak convergence in $c$ involves considerations going beyond finite dimensional ones, which is why it is useful (see the introduction).\n\nOn the other hand, (5.1) does imply (5.2) in the presence of relative compactness.\n\nTHEOREM 5.1. If (5.1) holds for all $k$ and $t_{1},\\dots,t_{k}$ and if $\\left\\{{{\\cal P}}_{n}\\right\\}$ is relatively compact, then (5.2) holds.\n\nProof. Since $\\{P_{n}\\}$ is relatively compact, each subsequence $\\{P_{n_{i}}\\}$ contains a $\\{P_{n_{i_{m}}}\\}$ such that $P_{n_{i_{m}}}\\Rightarrow Q$ as $m\\to\\infty$. For each $Q$ in $C$, $P_{n_{i_{m}}}\\pi_{t_{1}\\cdots t_{k}}^{-1}\\Rightarrow\\hat{Q\\pi}_{t_{1}\\cdots t_{k}}^{-1}$, and $Q\\pi_{t_{1}\\cdots t_{k}}^{-1}$ is $\\mathbf{\\alpha}=P\\pi_{t_{1}\\cdots t_{k}}^{-1}$. Since $P$ and $Q$ are equal as observed above, this implies $P=Q$. Thus each subsequence of $\\{P_{n}\\}$ contains a further subsequence converging weakly to $P$, and (5.2) follows by Theorem 2.2.\n\nTheorem 4.1 characterizes relative compactness by tightness. In order to apply Theorem 5.1 in concrete cases, we shall in turn characterize tightness by means of the Arzela-Ascoli theorem.\n\nFor $x\\in C$ and $\\delta>0$ the modulus of continuity is defined by\n\n$$\nw_{x}(\\delta)=\\operatorname*{sup}\\{|x(s)-x(t)|\\,{:}0\\leq s,t\\leq1,|s-t|<\\delta\\}\\,.\n$$\n\nAccording to the Arzela-Ascoli theorem, a set $A$ in $c$ has compact closure if and only if\n\n$$\n\\operatorname*{sup}_{x\\in C}\\lvert x(0)\\rvert<\\infty\n$$\n\nand\n\n$$\n\\operatorname*{lim}_{\\delta\\to0}\\ \\operatorname*{sup}_{x\\in C}\\ w_{x}(\\delta)=0.\n$$\n\nTHEOREM 5.2. A family $\\Pi$ of probability measures on $c$ is tight (hence relatively compact) if and only if, for each $\\eta$, there exists an $a$ such that\n\n$$\nP\\{x\\!:\\!|x(0)|\\,>\\,a\\}\\,<\\eta\\,,\\ \\ \\ \\ \\ P\\in\\Pi\\,,\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "THEOREM 5.2. A family $\\Pi$ of probability measures on $c$ is tight (hence relatively compact) if and only if, for each $\\eta$, there exists an $a$ such that $P\\{x:|x(0)|>a\\}<\\eta$, $P\\in\\Pi$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/textbook_needrop_en_745",
        "ID": "0d742256-0b36-43cd-8acf-eba4441030ae",
        "questions": "What assumption about the function $\u000barphi(z,t)$ is made regarding its continuity and analyticity in the document?",
        "answers": "The function $\u000barphi(z,t)$ is continuous as a function of both variables when $\\mathcal{Z}$ lies in a region $\\Omega$ and $a\\leq t\\leq b$, and analytic as a function of $z\\in\\Omega$ for any fixed $t$.",
        "context": "Let $\\textstyle a_{n}=f^{(n)}(a)/n!$, so that for any $\\alpha$ we have $|a_{n}|>n^{n}$. By Hadamard\u2019s formula, the radius of convergence is given by  \n\n$$\n{\\frac{1}{R}}=\\operatorname*{lim sup}_{n\\to\\infty}|a_{n}|^{1/n}=\\operatorname*{lim sup}_{n\\to\\infty}n=\\infty\n$$  \n\nso that the power series defined in the right hand side is valid only at $a$. Yet, as an analytic function, it should be analytic in some radius of convergence for $R>0$. Of course, if $g(n)$ is any increasing function (instead of $n^{n}$) such that $g(n)\\to\\infty$, then we arrive at the same conclusion.  \n\nHere's another way to go about the problem, which seems to be more of what Ahlfors intended by putting this problem here. Cauchy's estimate tells us that if $R>0$  \n\n$$\n|f^{(n)}(z)|\\leq\\frac{n!M}{R^{n}}\n$$  \n\nwhere $M=\\mathrm{max}_{|z|=R}\\left|f(z)\\right|$. Note that $M$ is finite since $f(z)$ is continuous and $|z|=R$ is compact. If also $|f^{(n)}(z)|>n!n^{n}$, then $n^{n}\\,\\leq\\,M/R^{n}$ for all $n\\geq0$. For $\\mathcal{n}$ large enough, this inequality fails since we can rearrange it to $(n R)^{n}\\leq M$, and the left hand side is unbounded for every $R>0$.  \n\n4.2.3.6. A more general form of Lemma 3 reads as follows  \n\nLet the function $\\varphi(z,t)$ be continuous as a function of both variables when $\\mathcal{Z}$ lies in a region $\\Omega$ and $a\\leq t\\leq b$. Suppose further that $\\varphi(z,t)$ is analytic as a function of $z\\in\\Omega$ for any fixed $t$. Then  \n\n$$\nF(z)=\\int_{\\alpha}^{\\beta}\\varphi(z,t)\\ d t\n$$  \n\nis analytic in $\\mathcal{L}$ and  \n\n$$\nF^{\\prime}(z)=\\int_{\\alpha}^{\\beta}{\\frac{\\partial\\varphi(z,t)}{\\partial z}}\\ d t\\qquad\\qquad(\\star).\n$$  \n\nTo prove this, represent $\\varphi(z,t)$ as a Cauchy integral  \n\n$$\n\\varphi(z,t)=\\frac{1}{2\\pi i}\\int_{C}\\frac{\\varphi(\\zeta,t)}{\\zeta-z}\\ d\\zeta.\n$$  \n\nFill in the necessary details to obtain  \n\n$$\nF(z)=\\int_{C}\\left({\\frac{1}{2\\pi i}}\\int_{\\alpha}^{\\beta}\\varphi(\\zeta,t)\\;d t\\right){\\frac{d\\zeta}{\\zeta-z}}.\n$$  \n\nand use Lemma 3 to prove $(\\star)$.  \n\nSolution: Recall that Cauchy's integral formula tells us that  \n\n$$\nf(z)={\\frac{1}{2\\pi i}}\\int_{C}{\\frac{f(\\zeta)\\ d\\zeta}{\\zeta-z}}\n$$  \n\nfor $\\mathcal{Z}$ in the bounded region determined by $C$. Applying this with $F(z)$ gives  \n\n$$\nF(z)={\\frac{1}{2\\pi i}}\\int_{C}{\\frac{F(\\zeta)\\ d\\zeta}{\\zeta-z}}={\\frac{1}{2\\pi i}}\\int_{C}\\left(\\int_{\\alpha}^{\\beta}\\varphi(\\zeta,t)\\ d t\\right){\\frac{d\\zeta}{\\zeta-z}}=\\int_{C}\\left({\\frac{1}{2\\pi i}}\\int_{\\alpha}^{\\beta}\\varphi(\\zeta,t)\\ d t\\right){\\frac{d\\zeta}{\\zeta-z}}\n$$  \n\n(one may also view it as a consequence of Fubini's theorem). Defining $\\begin{array}{r}{\\Phi(\\zeta)=1/2\\pi i\\int_{\\alpha}^{\\beta}\\varphi(\\zeta,t)\\ d t,}\\end{array}$ Lemma 3 tells us that  \n\n$$\nF^{\\prime}(z)=\\int_{C}\\frac{\\Phi(\\zeta)~d\\zeta}{(\\zeta-z)^{2}}=\\int_{C}\\left(\\frac{1}{2\\pi i}\\int_{\\alpha}^{\\beta}\\varphi(\\zeta,t)~d t\\right)\\frac{d\\zeta}{(\\zeta-z)^{2}}.\n$$  \n\nNow apply Lemma 3 once more to $\\varphi(z,t)$ directly  \n\n$$\n\\frac{\\partial\\varphi(z,t)}{\\partial z}=\\frac{1}{2\\pi i}\\int_{C}\\frac{\\varphi(\\zeta,t)\\;d\\zeta}{(\\zeta-z)^{2}}.\n$$  \n\nIntegrating this over $\\alpha\\leq t\\leq\\beta$ and using Fubini's theorem to switch integrals gives the result.  \n\n4.3. Local Properties of Analytical Functions.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Let the function $\u000barphi(z,t)$ be continuous as a function of both variables when $\\mathcal{Z}$ lies in a region $\\Omega$ and $a\\leq t\\leq b. Suppose further that $\u000barphi(z,t)$ is analytic as a function of $z\\in\\Omega$ for any fixed $t$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/textbook_needrop_en_745",
        "ID": "0d76aa16-2605-4ad2-9e4b-45b57cbb6187",
        "questions": "According to Hadamard\u2019s formula in the document, what is the radius of convergence (R) for the power series if the limit superior is infinity?",
        "answers": "0",
        "context": "Let $\\textstyle a_{n}=f^{(n)}(a)/n!$, so that for any $\\alpha$ we have $|a_{n}|>n^{n}$. By Hadamard\u2019s formula, the radius of convergence is given by  \n\n$$\n{\\frac{1}{R}}=\\operatorname*{lim sup}_{n\\to\\infty}|a_{n}|^{1/n}=\\operatorname*{lim sup}_{n\\to\\infty}n=\\infty\n$$  \n\nso that the power series defined in the right hand side is valid only at $a$. Yet, as an analytic function, it should be analytic in some radius of convergence for $R>0$. Of course, if $g(n)$ is any increasing function (instead of $n^{n}$) such that $g(n)\\to\\infty$, then we arrive at the same conclusion.  \n\nHere's another way to go about the problem, which seems to be more of what Ahlfors intended by putting this problem here. Cauchy's estimate tells us that if $R>0$  \n\n$$\n|f^{(n)}(z)|\\leq\\frac{n!M}{R^{n}}\n$$  \n\nwhere $M=\\mathrm{max}_{|z|=R}\\left|f(z)\\right|$. Note that $M$ is finite since $f(z)$ is continuous and $|z|=R$ is compact. If also $|f^{(n)}(z)|>n!n^{n}$, then $n^{n}\\,\\leq\\,M/R^{n}$ for all $n\\geq0$. For $\\mathcal{n}$ large enough, this inequality fails since we can rearrange it to $(n R)^{n}\\leq M$, and the left hand side is unbounded for every $R>0$.  \n\n4.2.3.6. A more general form of Lemma 3 reads as follows  \n\nLet the function $\\varphi(z,t)$ be continuous as a function of both variables when $\\mathcal{Z}$ lies in a region $\\Omega$ and $a\\leq t\\leq b$. Suppose further that $\\varphi(z,t)$ is analytic as a function of $z\\in\\Omega$ for any fixed $t$. Then  \n\n$$\nF(z)=\\int_{\\alpha}^{\\beta}\\varphi(z,t)\\ d t\n$$  \n\nis analytic in $\\mathcal{L}$ and  \n\n$$\nF^{\\prime}(z)=\\int_{\\alpha}^{\\beta}{\\frac{\\partial\\varphi(z,t)}{\\partial z}}\\ d t\\qquad\\qquad(\\star).\n$$  \n\nTo prove this, represent $\\varphi(z,t)$ as a Cauchy integral  \n\n$$\n\\varphi(z,t)=\\frac{1}{2\\pi i}\\int_{C}\\frac{\\varphi(\\zeta,t)}{\\zeta-z}\\ d\\zeta.\n$$  \n\nFill in the necessary details to obtain  \n\n$$\nF(z)=\\int_{C}\\left({\\frac{1}{2\\pi i}}\\int_{\\alpha}^{\\beta}\\varphi(\\zeta,t)\\;d t\\right){\\frac{d\\zeta}{\\zeta-z}}.\n$$  \n\nand use Lemma 3 to prove $(\\star)$.  \n\nSolution: Recall that Cauchy's integral formula tells us that  \n\n$$\nf(z)={\\frac{1}{2\\pi i}}\\int_{C}{\\frac{f(\\zeta)\\ d\\zeta}{\\zeta-z}}\n$$  \n\nfor $\\mathcal{Z}$ in the bounded region determined by $C$. Applying this with $F(z)$ gives  \n\n$$\nF(z)={\\frac{1}{2\\pi i}}\\int_{C}{\\frac{F(\\zeta)\\ d\\zeta}{\\zeta-z}}={\\frac{1}{2\\pi i}}\\int_{C}\\left(\\int_{\\alpha}^{\\beta}\\varphi(\\zeta,t)\\ d t\\right){\\frac{d\\zeta}{\\zeta-z}}=\\int_{C}\\left({\\frac{1}{2\\pi i}}\\int_{\\alpha}^{\\beta}\\varphi(\\zeta,t)\\ d t\\right){\\frac{d\\zeta}{\\zeta-z}}\n$$  \n\n(one may also view it as a consequence of Fubini's theorem). Defining $\\begin{array}{r}{\\Phi(\\zeta)=1/2\\pi i\\int_{\\alpha}^{\\beta}\\varphi(\\zeta,t)\\ d t,}\\end{array}$ Lemma 3 tells us that  \n\n$$\nF^{\\prime}(z)=\\int_{C}\\frac{\\Phi(\\zeta)~d\\zeta}{(\\zeta-z)^{2}}=\\int_{C}\\left(\\frac{1}{2\\pi i}\\int_{\\alpha}^{\\beta}\\varphi(\\zeta,t)~d t\\right)\\frac{d\\zeta}{(\\zeta-z)^{2}}.\n$$  \n\nNow apply Lemma 3 once more to $\\varphi(z,t)$ directly  \n\n$$\n\\frac{\\partial\\varphi(z,t)}{\\partial z}=\\frac{1}{2\\pi i}\\int_{C}\\frac{\\varphi(\\zeta,t)\\;d\\zeta}{(\\zeta-z)^{2}}.\n$$  \n\nIntegrating this over $\\alpha\\leq t\\leq\\beta$ and using Fubini's theorem to switch integrals gives the result.  \n\n4.3. Local Properties of Analytical Functions.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Numeric",
        "evidence_source": "equation",
        "evidence_context": "By Hadamard\u2019s formula, the radius of convergence is given by ${\frac{1}{R}}=\\operatorname*{lim sup}_{n\to\\infty}|a_{n}|^{1/n}=\\operatorname*{lim sup}_{n\to\\infty}n=\\infty so that the power series defined in the right hand side is valid only at $a$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/textbook_needrop_en_745",
        "ID": "0d898ef3-c657-44eb-a9e9-4d344dfa119e",
        "questions": "Using Cauchy's estimate in the document, explain why the inequality $n^{n}\\,\\leq\\,M/R^{n}$ fails for large enough n if $|f^{(n)}(z)|>n!n^{n}$.",
        "answers": "The inequality fails because for $\\mathcal{n}$ large enough, $(n R)^{n}\\leq M$, and the left hand side is unbounded for every $R>0$.",
        "context": "Let $\\textstyle a_{n}=f^{(n)}(a)/n!$, so that for any $\\alpha$ we have $|a_{n}|>n^{n}$. By Hadamard\u2019s formula, the radius of convergence is given by  \n\n$$\n{\\frac{1}{R}}=\\operatorname*{lim sup}_{n\\to\\infty}|a_{n}|^{1/n}=\\operatorname*{lim sup}_{n\\to\\infty}n=\\infty\n$$  \n\nso that the power series defined in the right hand side is valid only at $a$. Yet, as an analytic function, it should be analytic in some radius of convergence for $R>0$. Of course, if $g(n)$ is any increasing function (instead of $n^{n}$) such that $g(n)\\to\\infty$, then we arrive at the same conclusion.  \n\nHere's another way to go about the problem, which seems to be more of what Ahlfors intended by putting this problem here. Cauchy's estimate tells us that if $R>0$  \n\n$$\n|f^{(n)}(z)|\\leq\\frac{n!M}{R^{n}}\n$$  \n\nwhere $M=\\mathrm{max}_{|z|=R}\\left|f(z)\\right|$. Note that $M$ is finite since $f(z)$ is continuous and $|z|=R$ is compact. If also $|f^{(n)}(z)|>n!n^{n}$, then $n^{n}\\,\\leq\\,M/R^{n}$ for all $n\\geq0$. For $\\mathcal{n}$ large enough, this inequality fails since we can rearrange it to $(n R)^{n}\\leq M$, and the left hand side is unbounded for every $R>0$.  \n\n4.2.3.6. A more general form of Lemma 3 reads as follows  \n\nLet the function $\\varphi(z,t)$ be continuous as a function of both variables when $\\mathcal{Z}$ lies in a region $\\Omega$ and $a\\leq t\\leq b$. Suppose further that $\\varphi(z,t)$ is analytic as a function of $z\\in\\Omega$ for any fixed $t$. Then  \n\n$$\nF(z)=\\int_{\\alpha}^{\\beta}\\varphi(z,t)\\ d t\n$$  \n\nis analytic in $\\mathcal{L}$ and  \n\n$$\nF^{\\prime}(z)=\\int_{\\alpha}^{\\beta}{\\frac{\\partial\\varphi(z,t)}{\\partial z}}\\ d t\\qquad\\qquad(\\star).\n$$  \n\nTo prove this, represent $\\varphi(z,t)$ as a Cauchy integral  \n\n$$\n\\varphi(z,t)=\\frac{1}{2\\pi i}\\int_{C}\\frac{\\varphi(\\zeta,t)}{\\zeta-z}\\ d\\zeta.\n$$  \n\nFill in the necessary details to obtain  \n\n$$\nF(z)=\\int_{C}\\left({\\frac{1}{2\\pi i}}\\int_{\\alpha}^{\\beta}\\varphi(\\zeta,t)\\;d t\\right){\\frac{d\\zeta}{\\zeta-z}}.\n$$  \n\nand use Lemma 3 to prove $(\\star)$.  \n\nSolution: Recall that Cauchy's integral formula tells us that  \n\n$$\nf(z)={\\frac{1}{2\\pi i}}\\int_{C}{\\frac{f(\\zeta)\\ d\\zeta}{\\zeta-z}}\n$$  \n\nfor $\\mathcal{Z}$ in the bounded region determined by $C$. Applying this with $F(z)$ gives  \n\n$$\nF(z)={\\frac{1}{2\\pi i}}\\int_{C}{\\frac{F(\\zeta)\\ d\\zeta}{\\zeta-z}}={\\frac{1}{2\\pi i}}\\int_{C}\\left(\\int_{\\alpha}^{\\beta}\\varphi(\\zeta,t)\\ d t\\right){\\frac{d\\zeta}{\\zeta-z}}=\\int_{C}\\left({\\frac{1}{2\\pi i}}\\int_{\\alpha}^{\\beta}\\varphi(\\zeta,t)\\ d t\\right){\\frac{d\\zeta}{\\zeta-z}}\n$$  \n\n(one may also view it as a consequence of Fubini's theorem). Defining $\\begin{array}{r}{\\Phi(\\zeta)=1/2\\pi i\\int_{\\alpha}^{\\beta}\\varphi(\\zeta,t)\\ d t,}\\end{array}$ Lemma 3 tells us that  \n\n$$\nF^{\\prime}(z)=\\int_{C}\\frac{\\Phi(\\zeta)~d\\zeta}{(\\zeta-z)^{2}}=\\int_{C}\\left(\\frac{1}{2\\pi i}\\int_{\\alpha}^{\\beta}\\varphi(\\zeta,t)~d t\\right)\\frac{d\\zeta}{(\\zeta-z)^{2}}.\n$$  \n\nNow apply Lemma 3 once more to $\\varphi(z,t)$ directly  \n\n$$\n\\frac{\\partial\\varphi(z,t)}{\\partial z}=\\frac{1}{2\\pi i}\\int_{C}\\frac{\\varphi(\\zeta,t)\\;d\\zeta}{(\\zeta-z)^{2}}.\n$$  \n\nIntegrating this over $\\alpha\\leq t\\leq\\beta$ and using Fubini's theorem to switch integrals gives the result.  \n\n4.3. Local Properties of Analytical Functions.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "If also $|f^{(n)}(z)|>n!n^{n}$, then $n^{n}\\,\\leq\\,M/R^{n}$ for all $n\\geq0$. For $\\mathcal{n}$ large enough, this inequality fails since we can rearrange it to $(n R)^{n}\\leq M$, and the left hand side is unbounded for every $R>0$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/textbook_needrop_en_745",
        "ID": "0d9b598a-ec57-4e06-8e7e-fc7e2568533e",
        "questions": "What is the value of the radius of convergence for the function when the limit supremum of the sequence $|a_{n}|^{1/n}$ equals infinity?",
        "answers": "$\\infty$",
        "context": "Let $\\textstyle a_{n}=f^{(n)}(a)/n!$, so that for any $\\alpha$ we have $|a_{n}|>n^{n}$. By Hadamard\u2019s formula, the radius of convergence is given by  \n\n$$\n{\\frac{1}{R}}=\\operatorname*{lim sup}_{n\\to\\infty}|a_{n}|^{1/n}=\\operatorname*{lim sup}_{n\\to\\infty}n=\\infty\n$$  \n\nso that the power series defined in the right hand side is valid only at $a$. Yet, as an analytic function, it should be analytic in some radius of convergence for $R>0$. Of course, if $g(n)$ is any increasing function (instead of $n^{n}$) such that $g(n)\\to\\infty$, then we arrive at the same conclusion.  \n\nHere's another way to go about the problem, which seems to be more of what Ahlfors intended by putting this problem here. Cauchy's estimate tells us that if $R>0$  \n\n$$\n|f^{(n)}(z)|\\leq\\frac{n!M}{R^{n}}\n$$  \n\nwhere $M=\\mathrm{max}_{|z|=R}\\left|f(z)\\right|$. Note that $M$ is finite since $f(z)$ is continuous and $|z|=R$ is compact. If also $|f^{(n)}(z)|>n!n^{n}$, then $n^{n}\\,\\leq\\,M/R^{n}$ for all $n\\geq0$. For $\\mathcal{n}$ large enough, this inequality fails since we can rearrange it to $(n R)^{n}\\leq M$, and the left hand side is unbounded for every $R>0$.  \n\n4.2.3.6. A more general form of Lemma 3 reads as follows  \n\nLet the function $\\varphi(z,t)$ be continuous as a function of both variables when $\\mathcal{Z}$ lies in a region $\\Omega$ and $a\\leq t\\leq b$. Suppose further that $\\varphi(z,t)$ is analytic as a function of $z\\in\\Omega$ for any fixed $t$. Then  \n\n$$\nF(z)=\\int_{\\alpha}^{\\beta}\\varphi(z,t)\\ d t\n$$  \n\nis analytic in $\\mathcal{L}$ and  \n\n$$\nF^{\\prime}(z)=\\int_{\\alpha}^{\\beta}{\\frac{\\partial\\varphi(z,t)}{\\partial z}}\\ d t\\qquad\\qquad(\\star).\n$$  \n\nTo prove this, represent $\\varphi(z,t)$ as a Cauchy integral  \n\n$$\n\\varphi(z,t)=\\frac{1}{2\\pi i}\\int_{C}\\frac{\\varphi(\\zeta,t)}{\\zeta-z}\\ d\\zeta.\n$$  \n\nFill in the necessary details to obtain  \n\n$$\nF(z)=\\int_{C}\\left({\\frac{1}{2\\pi i}}\\int_{\\alpha}^{\\beta}\\varphi(\\zeta,t)\\;d t\\right){\\frac{d\\zeta}{\\zeta-z}}.\n$$  \n\nand use Lemma 3 to prove $(\\star)$.  \n\nSolution: Recall that Cauchy's integral formula tells us that  \n\n$$\nf(z)={\\frac{1}{2\\pi i}}\\int_{C}{\\frac{f(\\zeta)\\ d\\zeta}{\\zeta-z}}\n$$  \n\nfor $\\mathcal{Z}$ in the bounded region determined by $C$. Applying this with $F(z)$ gives  \n\n$$\nF(z)={\\frac{1}{2\\pi i}}\\int_{C}{\\frac{F(\\zeta)\\ d\\zeta}{\\zeta-z}}={\\frac{1}{2\\pi i}}\\int_{C}\\left(\\int_{\\alpha}^{\\beta}\\varphi(\\zeta,t)\\ d t\\right){\\frac{d\\zeta}{\\zeta-z}}=\\int_{C}\\left({\\frac{1}{2\\pi i}}\\int_{\\alpha}^{\\beta}\\varphi(\\zeta,t)\\ d t\\right){\\frac{d\\zeta}{\\zeta-z}}\n$$  \n\n(one may also view it as a consequence of Fubini's theorem). Defining $\\begin{array}{r}{\\Phi(\\zeta)=1/2\\pi i\\int_{\\alpha}^{\\beta}\\varphi(\\zeta,t)\\ d t,}\\end{array}$ Lemma 3 tells us that  \n\n$$\nF^{\\prime}(z)=\\int_{C}\\frac{\\Phi(\\zeta)~d\\zeta}{(\\zeta-z)^{2}}=\\int_{C}\\left(\\frac{1}{2\\pi i}\\int_{\\alpha}^{\\beta}\\varphi(\\zeta,t)~d t\\right)\\frac{d\\zeta}{(\\zeta-z)^{2}}.\n$$  \n\nNow apply Lemma 3 once more to $\\varphi(z,t)$ directly  \n\n$$\n\\frac{\\partial\\varphi(z,t)}{\\partial z}=\\frac{1}{2\\pi i}\\int_{C}\\frac{\\varphi(\\zeta,t)\\;d\\zeta}{(\\zeta-z)^{2}}.\n$$  \n\nIntegrating this over $\\alpha\\leq t\\leq\\beta$ and using Fubini's theorem to switch integrals gives the result.  \n\n4.3. Local Properties of Analytical Functions.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Numeric",
        "evidence_source": "equation",
        "evidence_context": "$\\frac{1}{R}=\\operatorname*{lim sup}_{n\\to\\infty}|a_{n}|^{1/n}=\\operatorname*{lim sup}_{n\\to\\infty}n=\\infty$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/textbook_needrop_en_745",
        "ID": "0d9ecdf1-29eb-4c72-a19e-a432f78c9f9b",
        "questions": "How is the function $F(z)$ expressed as a Cauchy integral using the function $\\varphi(z, t)$ in terms of a double integral?",
        "answers": "$F(z)=\\int_{C}\\left({\\frac{1}{2\\pi i}}\\int_{\\alpha}^{\\beta}\\varphi(\\zeta,t)\\;d t\\right){\\frac{d\\zeta}{\\zeta-z}}$",
        "context": "Let $\\textstyle a_{n}=f^{(n)}(a)/n!$, so that for any $\\alpha$ we have $|a_{n}|>n^{n}$. By Hadamard\u2019s formula, the radius of convergence is given by  \n\n$$\n{\\frac{1}{R}}=\\operatorname*{lim sup}_{n\\to\\infty}|a_{n}|^{1/n}=\\operatorname*{lim sup}_{n\\to\\infty}n=\\infty\n$$  \n\nso that the power series defined in the right hand side is valid only at $a$. Yet, as an analytic function, it should be analytic in some radius of convergence for $R>0$. Of course, if $g(n)$ is any increasing function (instead of $n^{n}$) such that $g(n)\\to\\infty$, then we arrive at the same conclusion.  \n\nHere's another way to go about the problem, which seems to be more of what Ahlfors intended by putting this problem here. Cauchy's estimate tells us that if $R>0$  \n\n$$\n|f^{(n)}(z)|\\leq\\frac{n!M}{R^{n}}\n$$  \n\nwhere $M=\\mathrm{max}_{|z|=R}\\left|f(z)\\right|$. Note that $M$ is finite since $f(z)$ is continuous and $|z|=R$ is compact. If also $|f^{(n)}(z)|>n!n^{n}$, then $n^{n}\\,\\leq\\,M/R^{n}$ for all $n\\geq0$. For $\\mathcal{n}$ large enough, this inequality fails since we can rearrange it to $(n R)^{n}\\leq M$, and the left hand side is unbounded for every $R>0$.  \n\n4.2.3.6. A more general form of Lemma 3 reads as follows  \n\nLet the function $\\varphi(z,t)$ be continuous as a function of both variables when $\\mathcal{Z}$ lies in a region $\\Omega$ and $a\\leq t\\leq b$. Suppose further that $\\varphi(z,t)$ is analytic as a function of $z\\in\\Omega$ for any fixed $t$. Then  \n\n$$\nF(z)=\\int_{\\alpha}^{\\beta}\\varphi(z,t)\\ d t\n$$  \n\nis analytic in $\\mathcal{L}$ and  \n\n$$\nF^{\\prime}(z)=\\int_{\\alpha}^{\\beta}{\\frac{\\partial\\varphi(z,t)}{\\partial z}}\\ d t\\qquad\\qquad(\\star).\n$$  \n\nTo prove this, represent $\\varphi(z,t)$ as a Cauchy integral  \n\n$$\n\\varphi(z,t)=\\frac{1}{2\\pi i}\\int_{C}\\frac{\\varphi(\\zeta,t)}{\\zeta-z}\\ d\\zeta.\n$$  \n\nFill in the necessary details to obtain  \n\n$$\nF(z)=\\int_{C}\\left({\\frac{1}{2\\pi i}}\\int_{\\alpha}^{\\beta}\\varphi(\\zeta,t)\\;d t\\right){\\frac{d\\zeta}{\\zeta-z}}.\n$$  \n\nand use Lemma 3 to prove $(\\star)$.  \n\nSolution: Recall that Cauchy's integral formula tells us that  \n\n$$\nf(z)={\\frac{1}{2\\pi i}}\\int_{C}{\\frac{f(\\zeta)\\ d\\zeta}{\\zeta-z}}\n$$  \n\nfor $\\mathcal{Z}$ in the bounded region determined by $C$. Applying this with $F(z)$ gives  \n\n$$\nF(z)={\\frac{1}{2\\pi i}}\\int_{C}{\\frac{F(\\zeta)\\ d\\zeta}{\\zeta-z}}={\\frac{1}{2\\pi i}}\\int_{C}\\left(\\int_{\\alpha}^{\\beta}\\varphi(\\zeta,t)\\ d t\\right){\\frac{d\\zeta}{\\zeta-z}}=\\int_{C}\\left({\\frac{1}{2\\pi i}}\\int_{\\alpha}^{\\beta}\\varphi(\\zeta,t)\\ d t\\right){\\frac{d\\zeta}{\\zeta-z}}\n$$  \n\n(one may also view it as a consequence of Fubini's theorem). Defining $\\begin{array}{r}{\\Phi(\\zeta)=1/2\\pi i\\int_{\\alpha}^{\\beta}\\varphi(\\zeta,t)\\ d t,}\\end{array}$ Lemma 3 tells us that  \n\n$$\nF^{\\prime}(z)=\\int_{C}\\frac{\\Phi(\\zeta)~d\\zeta}{(\\zeta-z)^{2}}=\\int_{C}\\left(\\frac{1}{2\\pi i}\\int_{\\alpha}^{\\beta}\\varphi(\\zeta,t)~d t\\right)\\frac{d\\zeta}{(\\zeta-z)^{2}}.\n$$  \n\nNow apply Lemma 3 once more to $\\varphi(z,t)$ directly  \n\n$$\n\\frac{\\partial\\varphi(z,t)}{\\partial z}=\\frac{1}{2\\pi i}\\int_{C}\\frac{\\varphi(\\zeta,t)\\;d\\zeta}{(\\zeta-z)^{2}}.\n$$  \n\nIntegrating this over $\\alpha\\leq t\\leq\\beta$ and using Fubini's theorem to switch integrals gives the result.  \n\n4.3. Local Properties of Analytical Functions.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$F(z)=\\int_{C}\\left({\\frac{1}{2\\pi i}}\\int_{\\alpha}^{\\beta}\\varphi(\\zeta,t)\\;d t\\right){\\frac{d\\zeta}{\\zeta-z}}.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/textbook_needrop_en_745",
        "ID": "0db11439-213a-4a5f-b985-0730c5df290b",
        "questions": "For a function $f(z)$, under what condition does the Cauchy's estimate inequality $n^{n}\\,\\leq\\,M/R^{n}$ fail for large $n$? Provide the rearranged inequality involved.",
        "answers": "$(n R)^{n}\\leq M$",
        "context": "Let $\\textstyle a_{n}=f^{(n)}(a)/n!$, so that for any $\\alpha$ we have $|a_{n}|>n^{n}$. By Hadamard\u2019s formula, the radius of convergence is given by  \n\n$$\n{\\frac{1}{R}}=\\operatorname*{lim sup}_{n\\to\\infty}|a_{n}|^{1/n}=\\operatorname*{lim sup}_{n\\to\\infty}n=\\infty\n$$  \n\nso that the power series defined in the right hand side is valid only at $a$. Yet, as an analytic function, it should be analytic in some radius of convergence for $R>0$. Of course, if $g(n)$ is any increasing function (instead of $n^{n}$) such that $g(n)\\to\\infty$, then we arrive at the same conclusion.  \n\nHere's another way to go about the problem, which seems to be more of what Ahlfors intended by putting this problem here. Cauchy's estimate tells us that if $R>0$  \n\n$$\n|f^{(n)}(z)|\\leq\\frac{n!M}{R^{n}}\n$$  \n\nwhere $M=\\mathrm{max}_{|z|=R}\\left|f(z)\\right|$. Note that $M$ is finite since $f(z)$ is continuous and $|z|=R$ is compact. If also $|f^{(n)}(z)|>n!n^{n}$, then $n^{n}\\,\\leq\\,M/R^{n}$ for all $n\\geq0$. For $\\mathcal{n}$ large enough, this inequality fails since we can rearrange it to $(n R)^{n}\\leq M$, and the left hand side is unbounded for every $R>0$.  \n\n4.2.3.6. A more general form of Lemma 3 reads as follows  \n\nLet the function $\\varphi(z,t)$ be continuous as a function of both variables when $\\mathcal{Z}$ lies in a region $\\Omega$ and $a\\leq t\\leq b$. Suppose further that $\\varphi(z,t)$ is analytic as a function of $z\\in\\Omega$ for any fixed $t$. Then  \n\n$$\nF(z)=\\int_{\\alpha}^{\\beta}\\varphi(z,t)\\ d t\n$$  \n\nis analytic in $\\mathcal{L}$ and  \n\n$$\nF^{\\prime}(z)=\\int_{\\alpha}^{\\beta}{\\frac{\\partial\\varphi(z,t)}{\\partial z}}\\ d t\\qquad\\qquad(\\star).\n$$  \n\nTo prove this, represent $\\varphi(z,t)$ as a Cauchy integral  \n\n$$\n\\varphi(z,t)=\\frac{1}{2\\pi i}\\int_{C}\\frac{\\varphi(\\zeta,t)}{\\zeta-z}\\ d\\zeta.\n$$  \n\nFill in the necessary details to obtain  \n\n$$\nF(z)=\\int_{C}\\left({\\frac{1}{2\\pi i}}\\int_{\\alpha}^{\\beta}\\varphi(\\zeta,t)\\;d t\\right){\\frac{d\\zeta}{\\zeta-z}}.\n$$  \n\nand use Lemma 3 to prove $(\\star)$.  \n\nSolution: Recall that Cauchy's integral formula tells us that  \n\n$$\nf(z)={\\frac{1}{2\\pi i}}\\int_{C}{\\frac{f(\\zeta)\\ d\\zeta}{\\zeta-z}}\n$$  \n\nfor $\\mathcal{Z}$ in the bounded region determined by $C$. Applying this with $F(z)$ gives  \n\n$$\nF(z)={\\frac{1}{2\\pi i}}\\int_{C}{\\frac{F(\\zeta)\\ d\\zeta}{\\zeta-z}}={\\frac{1}{2\\pi i}}\\int_{C}\\left(\\int_{\\alpha}^{\\beta}\\varphi(\\zeta,t)\\ d t\\right){\\frac{d\\zeta}{\\zeta-z}}=\\int_{C}\\left({\\frac{1}{2\\pi i}}\\int_{\\alpha}^{\\beta}\\varphi(\\zeta,t)\\ d t\\right){\\frac{d\\zeta}{\\zeta-z}}\n$$  \n\n(one may also view it as a consequence of Fubini's theorem). Defining $\\begin{array}{r}{\\Phi(\\zeta)=1/2\\pi i\\int_{\\alpha}^{\\beta}\\varphi(\\zeta,t)\\ d t,}\\end{array}$ Lemma 3 tells us that  \n\n$$\nF^{\\prime}(z)=\\int_{C}\\frac{\\Phi(\\zeta)~d\\zeta}{(\\zeta-z)^{2}}=\\int_{C}\\left(\\frac{1}{2\\pi i}\\int_{\\alpha}^{\\beta}\\varphi(\\zeta,t)~d t\\right)\\frac{d\\zeta}{(\\zeta-z)^{2}}.\n$$  \n\nNow apply Lemma 3 once more to $\\varphi(z,t)$ directly  \n\n$$\n\\frac{\\partial\\varphi(z,t)}{\\partial z}=\\frac{1}{2\\pi i}\\int_{C}\\frac{\\varphi(\\zeta,t)\\;d\\zeta}{(\\zeta-z)^{2}}.\n$$  \n\nIntegrating this over $\\alpha\\leq t\\leq\\beta$ and using Fubini's theorem to switch integrals gives the result.  \n\n4.3. Local Properties of Analytical Functions.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "for $R>0$. If also $|f^{(n)}(z)|>n!n^{n}$, then $n^{n}\\,\\leq\\,M/R^{n}$ for all $n\\geq0$.... $(n R)^{n}\\leq M$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/textbook_needrop_en_3004",
        "ID": "0db5d5b3-0286-4463-85d1-feeb9f493357",
        "questions": "What does Corollary 10.17 state about the structure of \\( A_n \\) when \\( p \nmid h^(\\mathbb{Q}(\\zeta_{p})^{+}) \\) and the conditions involving Bernoulli numbers are fulfilled?",
        "answers": "\\( A_{n}\\simeq(\\mathbb{Z}/p^{n+1}\\mathbb{Z})^{s} \\)",
        "context": "# hence  \n\n$$\ng\\equiv g_{n}\\,{\\bmod{(f,P_{n})}},\\text{for all }n\n$$  \n\nThis proves that  $\\phi$  is surjective. Therefore  \n\n$$\n\\mathbb{Z}_{p}[[T]]/(f)\\simeq\\varprojlim\\mathbb{Z}_{p}[[T]]/(f,P_{n})\\simeq\\varprojlim\\varepsilon_{i}A_{n}.\n$$  \n\nThis completes the proof of Theorem 10.16.  \n\nRemark. This result is rather amazing since it enables us to define an analytic object, namely the $p\\cdot$ -adic $L$ -function, in terms of algebraic objects, namely ideal class groups. A similar situation exists for function fields (see Chapter 13).  \n\nA slightly weaker form of this theorem has been proved by Mazur and Wiles, without the assumption  $p \\nmid h^+\n$  . See Section 13.6.  \n\nCorollary 10.17. Suppose  $p \\nmid h^(\\mathbb{Q}(\\zeta_{p})^{+})$  . Let iy,...,is be the even indices l such that  $2\\leq i\\leq p\\mathrm{~-~}3$  and  $p\\,|\\,B_{i}.\\,I f$  \n\n$$\nB_{1,\\,\\omega^{i\\;-\\;1}}\\not\\equiv0\\;\\mathrm{mod}\\;p^{2}\n$$  \n\nand  \n\n$$\n\\frac{B_{i}}{i}\\not\\equiv\\frac{B_{i\\,+\\,p\\,-\\,1}}{i\\,+\\,p\\,-\\,1}\\,{\\bmod}\\ p^{2}\\quad f o r\\ a l l\\ i\\in\\{i_{1},.\\,.\\,.\\,\\,i_{s}\\}\n$$  \n\nthen  \n\n$$\nA_{n}\\simeq(\\mathbb{Z}/p^{n+1}\\mathbb{Z})^{s}\n$$  \n\n$f o r\\;a l l\\;n\\geq0.$  \n\nRemark. The above Bernoulli numbers are always divisible by $p$, but the above incongruences hold mod $p^{2}$ for all $p<125000$. But there does not seem to be any reason to believe this in general. The above yields, for $p$ as above,  \n\n$$\n\\mu=0,\\,\\,\\,\\lambda=\\,\\nu=i(p)\n$$  \n\nwhere  $\\lambda,\\mu,\\nu$  are the Iwasawa invariants (see Theorem 7.14 or Chapter 13) and  $i(p)=s$  is the index of irregularity.  \n\nPROOF  $\\begin{array}{r}{\\mathrm{:}\\,\\mathrm{Let}\\,f(T,\\omega^{i})=\\,a_{0}\\,+\\,a_{1}\\,T\\,+\\,\\cdot\\cdot\\mathrm{,}\\,\\mathrm{with}\\,a_{j}\\in\\mathbb{Z}_{p}\\,\\mathrm{for}\\,\\,\\mathrm{all}\\,p.\\,\\mathrm{Then}}\\end{array}$  , for  $s\\in\\mathbb Z_{p}$  \n\n$$\nL_{p}(s,\\omega^{i})=f((1+p)^{s}-1,\\omega^{i})\\equiv a_{0}+a_{1}s p\\bmod p^{2}.\n$$  \n\nSince  $\\textstyle B_{2}={\\frac{1}{6}}$  we must have  $i\\geq4$  , SO  \n\n$$\n\\frac{B_{i}}{i}\\equiv(1\\,-\\,p^{i\\,-\\,1})\\,\\frac{B_{i}}{i}=\\,-\\,L_{p}(1\\,-\\,i,\\omega^{i})\\equiv\\,-\\,a_{0}\\,-\\,a_{1}(1\\,-\\,i)p\n$$  \n\nand  \n\n$$\n\\frac{B_{i\\,+\\,p\\,-\\,1}}{i\\,+\\,p\\,-\\,1}\\equiv\\,-\\,a_{0}\\,-\\,a_{1}(2\\,-\\,p\\,-\\,i)p\\equiv\\,-\\,a_{0}\\,-\\,a_{1}(2\\,-\\,i)p.\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "then  $$ A_{n}\\simeq(\\mathbb{Z}/p^{n+1}\\mathbb{Z})^{s} $$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/textbook_needrop_en_3004",
        "ID": "0dbcad25-daac-43a3-82f8-9ef40b9bcb7e",
        "questions": "According to the document, for which range of primes \\( p \\) do the above incongruences hold mod \\( p^2 \\)?",
        "answers": "for all \\( p < 125000 \\)",
        "context": "# hence  \n\n$$\ng\\equiv g_{n}\\,{\\bmod{(f,P_{n})}},\\text{for all }n\n$$  \n\nThis proves that  $\\phi$  is surjective. Therefore  \n\n$$\n\\mathbb{Z}_{p}[[T]]/(f)\\simeq\\varprojlim\\mathbb{Z}_{p}[[T]]/(f,P_{n})\\simeq\\varprojlim\\varepsilon_{i}A_{n}.\n$$  \n\nThis completes the proof of Theorem 10.16.  \n\nRemark. This result is rather amazing since it enables us to define an analytic object, namely the $p\\cdot$ -adic $L$ -function, in terms of algebraic objects, namely ideal class groups. A similar situation exists for function fields (see Chapter 13).  \n\nA slightly weaker form of this theorem has been proved by Mazur and Wiles, without the assumption  $p \\nmid h^+\n$  . See Section 13.6.  \n\nCorollary 10.17. Suppose  $p \\nmid h^(\\mathbb{Q}(\\zeta_{p})^{+})$  . Let iy,...,is be the even indices l such that  $2\\leq i\\leq p\\mathrm{~-~}3$  and  $p\\,|\\,B_{i}.\\,I f$  \n\n$$\nB_{1,\\,\\omega^{i\\;-\\;1}}\\not\\equiv0\\;\\mathrm{mod}\\;p^{2}\n$$  \n\nand  \n\n$$\n\\frac{B_{i}}{i}\\not\\equiv\\frac{B_{i\\,+\\,p\\,-\\,1}}{i\\,+\\,p\\,-\\,1}\\,{\\bmod}\\ p^{2}\\quad f o r\\ a l l\\ i\\in\\{i_{1},.\\,.\\,.\\,\\,i_{s}\\}\n$$  \n\nthen  \n\n$$\nA_{n}\\simeq(\\mathbb{Z}/p^{n+1}\\mathbb{Z})^{s}\n$$  \n\n$f o r\\;a l l\\;n\\geq0.$  \n\nRemark. The above Bernoulli numbers are always divisible by $p$, but the above incongruences hold mod $p^{2}$ for all $p<125000$. But there does not seem to be any reason to believe this in general. The above yields, for $p$ as above,  \n\n$$\n\\mu=0,\\,\\,\\,\\lambda=\\,\\nu=i(p)\n$$  \n\nwhere  $\\lambda,\\mu,\\nu$  are the Iwasawa invariants (see Theorem 7.14 or Chapter 13) and  $i(p)=s$  is the index of irregularity.  \n\nPROOF  $\\begin{array}{r}{\\mathrm{:}\\,\\mathrm{Let}\\,f(T,\\omega^{i})=\\,a_{0}\\,+\\,a_{1}\\,T\\,+\\,\\cdot\\cdot\\mathrm{,}\\,\\mathrm{with}\\,a_{j}\\in\\mathbb{Z}_{p}\\,\\mathrm{for}\\,\\,\\mathrm{all}\\,p.\\,\\mathrm{Then}}\\end{array}$  , for  $s\\in\\mathbb Z_{p}$  \n\n$$\nL_{p}(s,\\omega^{i})=f((1+p)^{s}-1,\\omega^{i})\\equiv a_{0}+a_{1}s p\\bmod p^{2}.\n$$  \n\nSince  $\\textstyle B_{2}={\\frac{1}{6}}$  we must have  $i\\geq4$  , SO  \n\n$$\n\\frac{B_{i}}{i}\\equiv(1\\,-\\,p^{i\\,-\\,1})\\,\\frac{B_{i}}{i}=\\,-\\,L_{p}(1\\,-\\,i,\\omega^{i})\\equiv\\,-\\,a_{0}\\,-\\,a_{1}(1\\,-\\,i)p\n$$  \n\nand  \n\n$$\n\\frac{B_{i\\,+\\,p\\,-\\,1}}{i\\,+\\,p\\,-\\,1}\\equiv\\,-\\,a_{0}\\,-\\,a_{1}(2\\,-\\,p\\,-\\,i)p\\equiv\\,-\\,a_{0}\\,-\\,a_{1}(2\\,-\\,i)p.\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "the above incongruences hold mod \\( p^{2} \\) for all \\( p < 125000 \\).",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/textbook_needrop_en_3004",
        "ID": "0dbed695-5bcf-4ce1-96f0-e0606aca8118",
        "questions": "What is the index of irregularity \\( i(p) \\) in terms of the number of even indices satisfying the conditions in Corollary 10.17?",
        "answers": "\\( i(p) = s \\)",
        "context": "# hence  \n\n$$\ng\\equiv g_{n}\\,{\\bmod{(f,P_{n})}},\\text{for all }n\n$$  \n\nThis proves that  $\\phi$  is surjective. Therefore  \n\n$$\n\\mathbb{Z}_{p}[[T]]/(f)\\simeq\\varprojlim\\mathbb{Z}_{p}[[T]]/(f,P_{n})\\simeq\\varprojlim\\varepsilon_{i}A_{n}.\n$$  \n\nThis completes the proof of Theorem 10.16.  \n\nRemark. This result is rather amazing since it enables us to define an analytic object, namely the $p\\cdot$ -adic $L$ -function, in terms of algebraic objects, namely ideal class groups. A similar situation exists for function fields (see Chapter 13).  \n\nA slightly weaker form of this theorem has been proved by Mazur and Wiles, without the assumption  $p \\nmid h^+\n$  . See Section 13.6.  \n\nCorollary 10.17. Suppose  $p \\nmid h^(\\mathbb{Q}(\\zeta_{p})^{+})$  . Let iy,...,is be the even indices l such that  $2\\leq i\\leq p\\mathrm{~-~}3$  and  $p\\,|\\,B_{i}.\\,I f$  \n\n$$\nB_{1,\\,\\omega^{i\\;-\\;1}}\\not\\equiv0\\;\\mathrm{mod}\\;p^{2}\n$$  \n\nand  \n\n$$\n\\frac{B_{i}}{i}\\not\\equiv\\frac{B_{i\\,+\\,p\\,-\\,1}}{i\\,+\\,p\\,-\\,1}\\,{\\bmod}\\ p^{2}\\quad f o r\\ a l l\\ i\\in\\{i_{1},.\\,.\\,.\\,\\,i_{s}\\}\n$$  \n\nthen  \n\n$$\nA_{n}\\simeq(\\mathbb{Z}/p^{n+1}\\mathbb{Z})^{s}\n$$  \n\n$f o r\\;a l l\\;n\\geq0.$  \n\nRemark. The above Bernoulli numbers are always divisible by $p$, but the above incongruences hold mod $p^{2}$ for all $p<125000$. But there does not seem to be any reason to believe this in general. The above yields, for $p$ as above,  \n\n$$\n\\mu=0,\\,\\,\\,\\lambda=\\,\\nu=i(p)\n$$  \n\nwhere  $\\lambda,\\mu,\\nu$  are the Iwasawa invariants (see Theorem 7.14 or Chapter 13) and  $i(p)=s$  is the index of irregularity.  \n\nPROOF  $\\begin{array}{r}{\\mathrm{:}\\,\\mathrm{Let}\\,f(T,\\omega^{i})=\\,a_{0}\\,+\\,a_{1}\\,T\\,+\\,\\cdot\\cdot\\mathrm{,}\\,\\mathrm{with}\\,a_{j}\\in\\mathbb{Z}_{p}\\,\\mathrm{for}\\,\\,\\mathrm{all}\\,p.\\,\\mathrm{Then}}\\end{array}$  , for  $s\\in\\mathbb Z_{p}$  \n\n$$\nL_{p}(s,\\omega^{i})=f((1+p)^{s}-1,\\omega^{i})\\equiv a_{0}+a_{1}s p\\bmod p^{2}.\n$$  \n\nSince  $\\textstyle B_{2}={\\frac{1}{6}}$  we must have  $i\\geq4$  , SO  \n\n$$\n\\frac{B_{i}}{i}\\equiv(1\\,-\\,p^{i\\,-\\,1})\\,\\frac{B_{i}}{i}=\\,-\\,L_{p}(1\\,-\\,i,\\omega^{i})\\equiv\\,-\\,a_{0}\\,-\\,a_{1}(1\\,-\\,i)p\n$$  \n\nand  \n\n$$\n\\frac{B_{i\\,+\\,p\\,-\\,1}}{i\\,+\\,p\\,-\\,1}\\equiv\\,-\\,a_{0}\\,-\\,a_{1}(2\\,-\\,p\\,-\\,i)p\\equiv\\,-\\,a_{0}\\,-\\,a_{1}(2\\,-\\,i)p.\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "where  \\( \\lambda, \\mu, \nu \\)  are the Iwasawa invariants (see Theorem 7.14 or Chapter 13) and  \\( i(p) = s \\)  is the index of irregularity.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/textbook_needrop_en_3004",
        "ID": "0dbee2ce-8fda-48e3-99b0-91e91f43f2bd",
        "questions": "What congruence condition must hold for the Bernoulli numbers $B_{1,\\,\\omega^{i-1}}$ according to Corollary 10.17?",
        "answers": "$B_{1,\\,\\omega^{i\\;-\\;1}}\not\\equiv0\\;\\mathrm{mod}\\;p^{2}$",
        "context": "# hence  \n\n$$\ng\\equiv g_{n}\\,{\\bmod{(f,P_{n})}},\\text{for all }n\n$$  \n\nThis proves that  $\\phi$  is surjective. Therefore  \n\n$$\n\\mathbb{Z}_{p}[[T]]/(f)\\simeq\\varprojlim\\mathbb{Z}_{p}[[T]]/(f,P_{n})\\simeq\\varprojlim\\varepsilon_{i}A_{n}.\n$$  \n\nThis completes the proof of Theorem 10.16.  \n\nRemark. This result is rather amazing since it enables us to define an analytic object, namely the $p\\cdot$ -adic $L$ -function, in terms of algebraic objects, namely ideal class groups. A similar situation exists for function fields (see Chapter 13).  \n\nA slightly weaker form of this theorem has been proved by Mazur and Wiles, without the assumption  $p \\nmid h^+\n$  . See Section 13.6.  \n\nCorollary 10.17. Suppose  $p \\nmid h^(\\mathbb{Q}(\\zeta_{p})^{+})$  . Let iy,...,is be the even indices l such that  $2\\leq i\\leq p\\mathrm{~-~}3$  and  $p\\,|\\,B_{i}.\\,I f$  \n\n$$\nB_{1,\\,\\omega^{i\\;-\\;1}}\\not\\equiv0\\;\\mathrm{mod}\\;p^{2}\n$$  \n\nand  \n\n$$\n\\frac{B_{i}}{i}\\not\\equiv\\frac{B_{i\\,+\\,p\\,-\\,1}}{i\\,+\\,p\\,-\\,1}\\,{\\bmod}\\ p^{2}\\quad f o r\\ a l l\\ i\\in\\{i_{1},.\\,.\\,.\\,\\,i_{s}\\}\n$$  \n\nthen  \n\n$$\nA_{n}\\simeq(\\mathbb{Z}/p^{n+1}\\mathbb{Z})^{s}\n$$  \n\n$f o r\\;a l l\\;n\\geq0.$  \n\nRemark. The above Bernoulli numbers are always divisible by $p$, but the above incongruences hold mod $p^{2}$ for all $p<125000$. But there does not seem to be any reason to believe this in general. The above yields, for $p$ as above,  \n\n$$\n\\mu=0,\\,\\,\\,\\lambda=\\,\\nu=i(p)\n$$  \n\nwhere  $\\lambda,\\mu,\\nu$  are the Iwasawa invariants (see Theorem 7.14 or Chapter 13) and  $i(p)=s$  is the index of irregularity.  \n\nPROOF  $\\begin{array}{r}{\\mathrm{:}\\,\\mathrm{Let}\\,f(T,\\omega^{i})=\\,a_{0}\\,+\\,a_{1}\\,T\\,+\\,\\cdot\\cdot\\mathrm{,}\\,\\mathrm{with}\\,a_{j}\\in\\mathbb{Z}_{p}\\,\\mathrm{for}\\,\\,\\mathrm{all}\\,p.\\,\\mathrm{Then}}\\end{array}$  , for  $s\\in\\mathbb Z_{p}$  \n\n$$\nL_{p}(s,\\omega^{i})=f((1+p)^{s}-1,\\omega^{i})\\equiv a_{0}+a_{1}s p\\bmod p^{2}.\n$$  \n\nSince  $\\textstyle B_{2}={\\frac{1}{6}}$  we must have  $i\\geq4$  , SO  \n\n$$\n\\frac{B_{i}}{i}\\equiv(1\\,-\\,p^{i\\,-\\,1})\\,\\frac{B_{i}}{i}=\\,-\\,L_{p}(1\\,-\\,i,\\omega^{i})\\equiv\\,-\\,a_{0}\\,-\\,a_{1}(1\\,-\\,i)p\n$$  \n\nand  \n\n$$\n\\frac{B_{i\\,+\\,p\\,-\\,1}}{i\\,+\\,p\\,-\\,1}\\equiv\\,-\\,a_{0}\\,-\\,a_{1}(2\\,-\\,p\\,-\\,i)p\\equiv\\,-\\,a_{0}\\,-\\,a_{1}(2\\,-\\,i)p.\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$B_{1,\\,\\omega^{i\\;-\\;1}}\not\\equiv0\\;\\mathrm{mod}\\;p^{2}$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/textbook_needrop_en_3004",
        "ID": "0dcf035b-7552-46e8-a953-a1155a62ddc4",
        "questions": "What is the relationship between $A_{n}$ and $(\\mathbb{Z}/p^{n+1}\\mathbb{Z})^{s}$ when $n \\geq 0$?",
        "answers": "$A_{n}\\simeq(\\mathbb{Z}/p^{n+1}\\mathbb{Z})^{s}$",
        "context": "# hence  \n\n$$\ng\\equiv g_{n}\\,{\\bmod{(f,P_{n})}},\\text{for all }n\n$$  \n\nThis proves that  $\\phi$  is surjective. Therefore  \n\n$$\n\\mathbb{Z}_{p}[[T]]/(f)\\simeq\\varprojlim\\mathbb{Z}_{p}[[T]]/(f,P_{n})\\simeq\\varprojlim\\varepsilon_{i}A_{n}.\n$$  \n\nThis completes the proof of Theorem 10.16.  \n\nRemark. This result is rather amazing since it enables us to define an analytic object, namely the $p\\cdot$ -adic $L$ -function, in terms of algebraic objects, namely ideal class groups. A similar situation exists for function fields (see Chapter 13).  \n\nA slightly weaker form of this theorem has been proved by Mazur and Wiles, without the assumption  $p \\nmid h^+\n$  . See Section 13.6.  \n\nCorollary 10.17. Suppose  $p \\nmid h^(\\mathbb{Q}(\\zeta_{p})^{+})$  . Let iy,...,is be the even indices l such that  $2\\leq i\\leq p\\mathrm{~-~}3$  and  $p\\,|\\,B_{i}.\\,I f$  \n\n$$\nB_{1,\\,\\omega^{i\\;-\\;1}}\\not\\equiv0\\;\\mathrm{mod}\\;p^{2}\n$$  \n\nand  \n\n$$\n\\frac{B_{i}}{i}\\not\\equiv\\frac{B_{i\\,+\\,p\\,-\\,1}}{i\\,+\\,p\\,-\\,1}\\,{\\bmod}\\ p^{2}\\quad f o r\\ a l l\\ i\\in\\{i_{1},.\\,.\\,.\\,\\,i_{s}\\}\n$$  \n\nthen  \n\n$$\nA_{n}\\simeq(\\mathbb{Z}/p^{n+1}\\mathbb{Z})^{s}\n$$  \n\n$f o r\\;a l l\\;n\\geq0.$  \n\nRemark. The above Bernoulli numbers are always divisible by $p$, but the above incongruences hold mod $p^{2}$ for all $p<125000$. But there does not seem to be any reason to believe this in general. The above yields, for $p$ as above,  \n\n$$\n\\mu=0,\\,\\,\\,\\lambda=\\,\\nu=i(p)\n$$  \n\nwhere  $\\lambda,\\mu,\\nu$  are the Iwasawa invariants (see Theorem 7.14 or Chapter 13) and  $i(p)=s$  is the index of irregularity.  \n\nPROOF  $\\begin{array}{r}{\\mathrm{:}\\,\\mathrm{Let}\\,f(T,\\omega^{i})=\\,a_{0}\\,+\\,a_{1}\\,T\\,+\\,\\cdot\\cdot\\mathrm{,}\\,\\mathrm{with}\\,a_{j}\\in\\mathbb{Z}_{p}\\,\\mathrm{for}\\,\\,\\mathrm{all}\\,p.\\,\\mathrm{Then}}\\end{array}$  , for  $s\\in\\mathbb Z_{p}$  \n\n$$\nL_{p}(s,\\omega^{i})=f((1+p)^{s}-1,\\omega^{i})\\equiv a_{0}+a_{1}s p\\bmod p^{2}.\n$$  \n\nSince  $\\textstyle B_{2}={\\frac{1}{6}}$  we must have  $i\\geq4$  , SO  \n\n$$\n\\frac{B_{i}}{i}\\equiv(1\\,-\\,p^{i\\,-\\,1})\\,\\frac{B_{i}}{i}=\\,-\\,L_{p}(1\\,-\\,i,\\omega^{i})\\equiv\\,-\\,a_{0}\\,-\\,a_{1}(1\\,-\\,i)p\n$$  \n\nand  \n\n$$\n\\frac{B_{i\\,+\\,p\\,-\\,1}}{i\\,+\\,p\\,-\\,1}\\equiv\\,-\\,a_{0}\\,-\\,a_{1}(2\\,-\\,p\\,-\\,i)p\\equiv\\,-\\,a_{0}\\,-\\,a_{1}(2\\,-\\,i)p.\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$A_{n}\\simeq(\\mathbb{Z}/p^{n+1}\\mathbb{Z})^{s}\\,\\,\\,\\,f\\,o\\,r\\,\\,a\\,l\\,l\\,\\,n\\geq0.$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/textbook_needrop_en_3004",
        "ID": "0de63c6d-92b0-4864-a8d4-c57ed379f377",
        "questions": "In the proof involving $L_{p}(s,\\omega^{i})$, what must the Bernoulli number $B_{i}$ satisfy for even indices $i\\geq 4$?",
        "answers": "$\\frac{B_{i}}{i}\\equiv(1\\,-\\,p^{i\\,-\\,1})\\,\\frac{B_{i}}{i}=\\,-\\,L_{p}(1\\,-\\,i,\\omega^{i})\\equiv\\,-\\,a_{0}\\,-\\,a_{1}(1\\,-\\,i)p$",
        "context": "# hence  \n\n$$\ng\\equiv g_{n}\\,{\\bmod{(f,P_{n})}},\\text{for all }n\n$$  \n\nThis proves that  $\\phi$  is surjective. Therefore  \n\n$$\n\\mathbb{Z}_{p}[[T]]/(f)\\simeq\\varprojlim\\mathbb{Z}_{p}[[T]]/(f,P_{n})\\simeq\\varprojlim\\varepsilon_{i}A_{n}.\n$$  \n\nThis completes the proof of Theorem 10.16.  \n\nRemark. This result is rather amazing since it enables us to define an analytic object, namely the $p\\cdot$ -adic $L$ -function, in terms of algebraic objects, namely ideal class groups. A similar situation exists for function fields (see Chapter 13).  \n\nA slightly weaker form of this theorem has been proved by Mazur and Wiles, without the assumption  $p \\nmid h^+\n$  . See Section 13.6.  \n\nCorollary 10.17. Suppose  $p \\nmid h^(\\mathbb{Q}(\\zeta_{p})^{+})$  . Let iy,...,is be the even indices l such that  $2\\leq i\\leq p\\mathrm{~-~}3$  and  $p\\,|\\,B_{i}.\\,I f$  \n\n$$\nB_{1,\\,\\omega^{i\\;-\\;1}}\\not\\equiv0\\;\\mathrm{mod}\\;p^{2}\n$$  \n\nand  \n\n$$\n\\frac{B_{i}}{i}\\not\\equiv\\frac{B_{i\\,+\\,p\\,-\\,1}}{i\\,+\\,p\\,-\\,1}\\,{\\bmod}\\ p^{2}\\quad f o r\\ a l l\\ i\\in\\{i_{1},.\\,.\\,.\\,\\,i_{s}\\}\n$$  \n\nthen  \n\n$$\nA_{n}\\simeq(\\mathbb{Z}/p^{n+1}\\mathbb{Z})^{s}\n$$  \n\n$f o r\\;a l l\\;n\\geq0.$  \n\nRemark. The above Bernoulli numbers are always divisible by $p$, but the above incongruences hold mod $p^{2}$ for all $p<125000$. But there does not seem to be any reason to believe this in general. The above yields, for $p$ as above,  \n\n$$\n\\mu=0,\\,\\,\\,\\lambda=\\,\\nu=i(p)\n$$  \n\nwhere  $\\lambda,\\mu,\\nu$  are the Iwasawa invariants (see Theorem 7.14 or Chapter 13) and  $i(p)=s$  is the index of irregularity.  \n\nPROOF  $\\begin{array}{r}{\\mathrm{:}\\,\\mathrm{Let}\\,f(T,\\omega^{i})=\\,a_{0}\\,+\\,a_{1}\\,T\\,+\\,\\cdot\\cdot\\mathrm{,}\\,\\mathrm{with}\\,a_{j}\\in\\mathbb{Z}_{p}\\,\\mathrm{for}\\,\\,\\mathrm{all}\\,p.\\,\\mathrm{Then}}\\end{array}$  , for  $s\\in\\mathbb Z_{p}$  \n\n$$\nL_{p}(s,\\omega^{i})=f((1+p)^{s}-1,\\omega^{i})\\equiv a_{0}+a_{1}s p\\bmod p^{2}.\n$$  \n\nSince  $\\textstyle B_{2}={\\frac{1}{6}}$  we must have  $i\\geq4$  , SO  \n\n$$\n\\frac{B_{i}}{i}\\equiv(1\\,-\\,p^{i\\,-\\,1})\\,\\frac{B_{i}}{i}=\\,-\\,L_{p}(1\\,-\\,i,\\omega^{i})\\equiv\\,-\\,a_{0}\\,-\\,a_{1}(1\\,-\\,i)p\n$$  \n\nand  \n\n$$\n\\frac{B_{i\\,+\\,p\\,-\\,1}}{i\\,+\\,p\\,-\\,1}\\equiv\\,-\\,a_{0}\\,-\\,a_{1}(2\\,-\\,p\\,-\\,i)p\\equiv\\,-\\,a_{0}\\,-\\,a_{1}(2\\,-\\,i)p.\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$\\frac{B_{i}}{i}\\equiv(1\\,-\\,p^{i\\,-\\,1})\\,\\frac{B_{i}}{i}=\\,-\\,L_{p}(1\\,-\\,i,\\omega^{i})\\equiv\\,-\\,a_{0}\\,-\\,a_{1}(1\\,-\\,i)p$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/2003_Book_ReadingWritingAndProving.pdf_325",
        "ID": "0de90230-6ba7-4a7e-a282-90c0b7ddeba8",
        "questions": "What is the greatest common divisor of two integers m and n if m equals n?",
        "answers": "|m|",
        "context": "# Problem 25.18.  \n\nHere's a brief explanation of the Euclidean algorithm, which is an effective way to find the greatest common divisor of two integers m and n, not both zero. This algorithm is in the seventh book of Euclid's Elements, but was likely known earlier.  \n\nThere are two trivial cases that must be considered before moving to the interesting one. If $m = n$, then the greatest common divisor is obviously |m|. If one of the integers is zero (remember that both can't be zero), then the greatest common divisor is the absolute value of the non-zero integer. Now for the main case, note that the positive divisors of an integer m are the same as the ones of -m. For this reason, we may assume that both m and $n$ are positive. After possible relabelling of the two numbers, we may further assume that $m > n > 0$.  \n\nThe Euclidean algorithm is a repeated application of the division algorithm, Theorem 25.3. Each line is obtained from the previous one by shifting the divisor to the spot previously occupied by the dividend, and the remainder to the spot previously occupied by the divisor. It's easier to see than to say. Here is the way to see it:  \n\n$$\n\\begin{array}{l c l}{m}&{=}&{q_{1}n+r_{1},}\\\\ {n}&{=}&{q_{2}r_{1}+r_{2},}\\\\ {r_{1}}&{=}&{q_{3}r_{2}+r_{3},}\\\\ {\\cdots}&{}&\\\\ {r_{k-3}}&{=}&{q_{k-1}r_{k-2}+r_{k-1},}\\\\ {r_{k-2}}&{=}&{q_{k}r_{k-1}+r_{k},}\\\\ {r_{k-1}}&{=}&{q_{k+1}r_{k}.}\\end{array}\n$$  \n\nBy the division algorithm, the remainders satisfy the inequalities $n > r_{1} > \\ldots > r_{i} > r_{i+1} > \\ldots > 0$. This guarantees that the algorithm comes to a halt after finitely many steps. We label the last non-zero remainder $r_{k}$ and solve for $r_{k}$ as follows:  \n\n$$\n\\begin{array}{l c l}{r_{k}}&{=}&{r_{k-2}-q_{k}r_{k-1}}\\\\ &{=}&{r_{k-2}-q_{k}(r_{k-3}-q_{k-1}r_{k-2})\\,\\,\\,\\,=}&{-q_{k}r_{k-3}+(1+q_{k}q_{k-1})r_{k-2}}\\\\ &&{\\,\\,\\,\\cdot\\,\\cdot}\\\\ &{=}&{x_{0}m+y_{0}n}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "If $m = n$, then the greatest common divisor is obviously |m|.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/2003_Book_ReadingWritingAndProving.pdf_325",
        "ID": "0df099c5-62a7-4dc7-b273-38fcdfa69923",
        "questions": "If one of the integers m or n is zero, what is the greatest common divisor of m and n?",
        "answers": "the absolute value of the non-zero integer",
        "context": "# Problem 25.18.  \n\nHere's a brief explanation of the Euclidean algorithm, which is an effective way to find the greatest common divisor of two integers m and n, not both zero. This algorithm is in the seventh book of Euclid's Elements, but was likely known earlier.  \n\nThere are two trivial cases that must be considered before moving to the interesting one. If $m = n$, then the greatest common divisor is obviously |m|. If one of the integers is zero (remember that both can't be zero), then the greatest common divisor is the absolute value of the non-zero integer. Now for the main case, note that the positive divisors of an integer m are the same as the ones of -m. For this reason, we may assume that both m and $n$ are positive. After possible relabelling of the two numbers, we may further assume that $m > n > 0$.  \n\nThe Euclidean algorithm is a repeated application of the division algorithm, Theorem 25.3. Each line is obtained from the previous one by shifting the divisor to the spot previously occupied by the dividend, and the remainder to the spot previously occupied by the divisor. It's easier to see than to say. Here is the way to see it:  \n\n$$\n\\begin{array}{l c l}{m}&{=}&{q_{1}n+r_{1},}\\\\ {n}&{=}&{q_{2}r_{1}+r_{2},}\\\\ {r_{1}}&{=}&{q_{3}r_{2}+r_{3},}\\\\ {\\cdots}&{}&\\\\ {r_{k-3}}&{=}&{q_{k-1}r_{k-2}+r_{k-1},}\\\\ {r_{k-2}}&{=}&{q_{k}r_{k-1}+r_{k},}\\\\ {r_{k-1}}&{=}&{q_{k+1}r_{k}.}\\end{array}\n$$  \n\nBy the division algorithm, the remainders satisfy the inequalities $n > r_{1} > \\ldots > r_{i} > r_{i+1} > \\ldots > 0$. This guarantees that the algorithm comes to a halt after finitely many steps. We label the last non-zero remainder $r_{k}$ and solve for $r_{k}$ as follows:  \n\n$$\n\\begin{array}{l c l}{r_{k}}&{=}&{r_{k-2}-q_{k}r_{k-1}}\\\\ &{=}&{r_{k-2}-q_{k}(r_{k-3}-q_{k-1}r_{k-2})\\,\\,\\,\\,=}&{-q_{k}r_{k-3}+(1+q_{k}q_{k-1})r_{k-2}}\\\\ &&{\\,\\,\\,\\cdot\\,\\cdot}\\\\ &{=}&{x_{0}m+y_{0}n}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "If one of the integers is zero (remember that both can't be zero), then the greatest common divisor is the absolute value of the non-zero integer.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/2003_Book_ReadingWritingAndProving.pdf_325",
        "ID": "0df23548-2c12-429c-887b-0acfc535c13d",
        "questions": "What is the inequality satisfied by the remainders in the Euclidean algorithm for the integers m and n?",
        "answers": "n > r_{1} > \u2026 > r_{i} > r_{i+1} > \u2026 > 0",
        "context": "# Problem 25.18.  \n\nHere's a brief explanation of the Euclidean algorithm, which is an effective way to find the greatest common divisor of two integers m and n, not both zero. This algorithm is in the seventh book of Euclid's Elements, but was likely known earlier.  \n\nThere are two trivial cases that must be considered before moving to the interesting one. If $m = n$, then the greatest common divisor is obviously |m|. If one of the integers is zero (remember that both can't be zero), then the greatest common divisor is the absolute value of the non-zero integer. Now for the main case, note that the positive divisors of an integer m are the same as the ones of -m. For this reason, we may assume that both m and $n$ are positive. After possible relabelling of the two numbers, we may further assume that $m > n > 0$.  \n\nThe Euclidean algorithm is a repeated application of the division algorithm, Theorem 25.3. Each line is obtained from the previous one by shifting the divisor to the spot previously occupied by the dividend, and the remainder to the spot previously occupied by the divisor. It's easier to see than to say. Here is the way to see it:  \n\n$$\n\\begin{array}{l c l}{m}&{=}&{q_{1}n+r_{1},}\\\\ {n}&{=}&{q_{2}r_{1}+r_{2},}\\\\ {r_{1}}&{=}&{q_{3}r_{2}+r_{3},}\\\\ {\\cdots}&{}&\\\\ {r_{k-3}}&{=}&{q_{k-1}r_{k-2}+r_{k-1},}\\\\ {r_{k-2}}&{=}&{q_{k}r_{k-1}+r_{k},}\\\\ {r_{k-1}}&{=}&{q_{k+1}r_{k}.}\\end{array}\n$$  \n\nBy the division algorithm, the remainders satisfy the inequalities $n > r_{1} > \\ldots > r_{i} > r_{i+1} > \\ldots > 0$. This guarantees that the algorithm comes to a halt after finitely many steps. We label the last non-zero remainder $r_{k}$ and solve for $r_{k}$ as follows:  \n\n$$\n\\begin{array}{l c l}{r_{k}}&{=}&{r_{k-2}-q_{k}r_{k-1}}\\\\ &{=}&{r_{k-2}-q_{k}(r_{k-3}-q_{k-1}r_{k-2})\\,\\,\\,\\,=}&{-q_{k}r_{k-3}+(1+q_{k}q_{k-1})r_{k-2}}\\\\ &&{\\,\\,\\,\\cdot\\,\\cdot}\\\\ &{=}&{x_{0}m+y_{0}n}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "By the division algorithm, the remainders satisfy the inequalities $n > r_{1} > \\ldots > r_{i} > r_{i+1} > \\ldots > 0$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/2003_Book_ReadingWritingAndProving.pdf_325",
        "ID": "0dfb75cf-59d8-4ac1-b3d1-f783e311da73",
        "questions": "What are the possible values for the last non-zero remainder \\(r_k\\) in the Euclidean algorithm?",
        "answers": "0 < r_{k} < r_{i} < ... < r_{1} < n",
        "context": "# Problem 25.18.  \n\nHere's a brief explanation of the Euclidean algorithm, which is an effective way to find the greatest common divisor of two integers m and n, not both zero. This algorithm is in the seventh book of Euclid's Elements, but was likely known earlier.  \n\nThere are two trivial cases that must be considered before moving to the interesting one. If $m = n$, then the greatest common divisor is obviously |m|. If one of the integers is zero (remember that both can't be zero), then the greatest common divisor is the absolute value of the non-zero integer. Now for the main case, note that the positive divisors of an integer m are the same as the ones of -m. For this reason, we may assume that both m and $n$ are positive. After possible relabelling of the two numbers, we may further assume that $m > n > 0$.  \n\nThe Euclidean algorithm is a repeated application of the division algorithm, Theorem 25.3. Each line is obtained from the previous one by shifting the divisor to the spot previously occupied by the dividend, and the remainder to the spot previously occupied by the divisor. It's easier to see than to say. Here is the way to see it:  \n\n$$\n\\begin{array}{l c l}{m}&{=}&{q_{1}n+r_{1},}\\\\ {n}&{=}&{q_{2}r_{1}+r_{2},}\\\\ {r_{1}}&{=}&{q_{3}r_{2}+r_{3},}\\\\ {\\cdots}&{}&\\\\ {r_{k-3}}&{=}&{q_{k-1}r_{k-2}+r_{k-1},}\\\\ {r_{k-2}}&{=}&{q_{k}r_{k-1}+r_{k},}\\\\ {r_{k-1}}&{=}&{q_{k+1}r_{k}.}\\end{array}\n$$  \n\nBy the division algorithm, the remainders satisfy the inequalities $n > r_{1} > \\ldots > r_{i} > r_{i+1} > \\ldots > 0$. This guarantees that the algorithm comes to a halt after finitely many steps. We label the last non-zero remainder $r_{k}$ and solve for $r_{k}$ as follows:  \n\n$$\n\\begin{array}{l c l}{r_{k}}&{=}&{r_{k-2}-q_{k}r_{k-1}}\\\\ &{=}&{r_{k-2}-q_{k}(r_{k-3}-q_{k-1}r_{k-2})\\,\\,\\,\\,=}&{-q_{k}r_{k-3}+(1+q_{k}q_{k-1})r_{k-2}}\\\\ &&{\\,\\,\\,\\cdot\\,\\cdot}\\\\ &{=}&{x_{0}m+y_{0}n}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "By the division algorithm, the remainders satisfy the inequalities \\(n > r_{1} > ... > r_{i} > r_{i+1} > ... > 0\\).",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/2003_Book_ReadingWritingAndProving.pdf_325",
        "ID": "0e011113-15f3-4777-a63c-32210c099d16",
        "questions": "What is the expression for the last non-zero remainder \\(r_k\\) when computed recursively in the Euclidean algorithm?",
        "answers": "r_{k} = x_{0}m + y_{0}n",
        "context": "# Problem 25.18.  \n\nHere's a brief explanation of the Euclidean algorithm, which is an effective way to find the greatest common divisor of two integers m and n, not both zero. This algorithm is in the seventh book of Euclid's Elements, but was likely known earlier.  \n\nThere are two trivial cases that must be considered before moving to the interesting one. If $m = n$, then the greatest common divisor is obviously |m|. If one of the integers is zero (remember that both can't be zero), then the greatest common divisor is the absolute value of the non-zero integer. Now for the main case, note that the positive divisors of an integer m are the same as the ones of -m. For this reason, we may assume that both m and $n$ are positive. After possible relabelling of the two numbers, we may further assume that $m > n > 0$.  \n\nThe Euclidean algorithm is a repeated application of the division algorithm, Theorem 25.3. Each line is obtained from the previous one by shifting the divisor to the spot previously occupied by the dividend, and the remainder to the spot previously occupied by the divisor. It's easier to see than to say. Here is the way to see it:  \n\n$$\n\\begin{array}{l c l}{m}&{=}&{q_{1}n+r_{1},}\\\\ {n}&{=}&{q_{2}r_{1}+r_{2},}\\\\ {r_{1}}&{=}&{q_{3}r_{2}+r_{3},}\\\\ {\\cdots}&{}&\\\\ {r_{k-3}}&{=}&{q_{k-1}r_{k-2}+r_{k-1},}\\\\ {r_{k-2}}&{=}&{q_{k}r_{k-1}+r_{k},}\\\\ {r_{k-1}}&{=}&{q_{k+1}r_{k}.}\\end{array}\n$$  \n\nBy the division algorithm, the remainders satisfy the inequalities $n > r_{1} > \\ldots > r_{i} > r_{i+1} > \\ldots > 0$. This guarantees that the algorithm comes to a halt after finitely many steps. We label the last non-zero remainder $r_{k}$ and solve for $r_{k}$ as follows:  \n\n$$\n\\begin{array}{l c l}{r_{k}}&{=}&{r_{k-2}-q_{k}r_{k-1}}\\\\ &{=}&{r_{k-2}-q_{k}(r_{k-3}-q_{k-1}r_{k-2})\\,\\,\\,\\,=}&{-q_{k}r_{k-3}+(1+q_{k}q_{k-1})r_{k-2}}\\\\ &&{\\,\\,\\,\\cdot\\,\\cdot}\\\\ &{=}&{x_{0}m+y_{0}n}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "We label the last non-zero remainder \\(r_{k}\\) and solve for \\(r_{k}\\) as follows: \\(r_{k} = x_{0}m + y_{0}n\\)",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/2003_Book_ReadingWritingAndProving.pdf_325",
        "ID": "0e061345-1afd-44a1-ad50-9b48156377d9",
        "questions": "How would you compute the remainder \\(r_{k}\\) in terms of earlier remainders and quotients in the Euclidean algorithm?",
        "answers": "-q_{k}r_{k-3}+(1+q_{k}q_{k-1})r_{k-2}",
        "context": "# Problem 25.18.  \n\nHere's a brief explanation of the Euclidean algorithm, which is an effective way to find the greatest common divisor of two integers m and n, not both zero. This algorithm is in the seventh book of Euclid's Elements, but was likely known earlier.  \n\nThere are two trivial cases that must be considered before moving to the interesting one. If $m = n$, then the greatest common divisor is obviously |m|. If one of the integers is zero (remember that both can't be zero), then the greatest common divisor is the absolute value of the non-zero integer. Now for the main case, note that the positive divisors of an integer m are the same as the ones of -m. For this reason, we may assume that both m and $n$ are positive. After possible relabelling of the two numbers, we may further assume that $m > n > 0$.  \n\nThe Euclidean algorithm is a repeated application of the division algorithm, Theorem 25.3. Each line is obtained from the previous one by shifting the divisor to the spot previously occupied by the dividend, and the remainder to the spot previously occupied by the divisor. It's easier to see than to say. Here is the way to see it:  \n\n$$\n\\begin{array}{l c l}{m}&{=}&{q_{1}n+r_{1},}\\\\ {n}&{=}&{q_{2}r_{1}+r_{2},}\\\\ {r_{1}}&{=}&{q_{3}r_{2}+r_{3},}\\\\ {\\cdots}&{}&\\\\ {r_{k-3}}&{=}&{q_{k-1}r_{k-2}+r_{k-1},}\\\\ {r_{k-2}}&{=}&{q_{k}r_{k-1}+r_{k},}\\\\ {r_{k-1}}&{=}&{q_{k+1}r_{k}.}\\end{array}\n$$  \n\nBy the division algorithm, the remainders satisfy the inequalities $n > r_{1} > \\ldots > r_{i} > r_{i+1} > \\ldots > 0$. This guarantees that the algorithm comes to a halt after finitely many steps. We label the last non-zero remainder $r_{k}$ and solve for $r_{k}$ as follows:  \n\n$$\n\\begin{array}{l c l}{r_{k}}&{=}&{r_{k-2}-q_{k}r_{k-1}}\\\\ &{=}&{r_{k-2}-q_{k}(r_{k-3}-q_{k-1}r_{k-2})\\,\\,\\,\\,=}&{-q_{k}r_{k-3}+(1+q_{k}q_{k-1})r_{k-2}}\\\\ &&{\\,\\,\\,\\cdot\\,\\cdot}\\\\ &{=}&{x_{0}m+y_{0}n}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "We label the last non-zero remainder \\(r_{k}\\) and solve for \\(r_{k}\\) as follows: \\(r_{k} = r_{k-2}-q_{k}(r_{k-3}-q_{k-1}r_{k-2}) = -q_{k}r_{k-3}+(1+q_{k}q_{k-1})r_{k-2}\\) ...",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/Measure-Valued_Branching_Markov_Processes(Li).pdf_256",
        "ID": "0e1654b8-1e96-4b89-b7ac-aa5628826512",
        "questions": "What is the expected behavior of the superprocess denoted by \\( \\{Y_{t}:t\\geq0\\} \\)?",
        "answers": "Superprocess with an extra interactive non-local branching mechanism.",
        "context": "$$\n\\begin{array}{l l}{\\displaystyle+\\int_{E}Y_{s}(\\mathrm{d}x)\\int_{M(E)^{\\circ}}\\Big[G(\\langle Y_{s},f\\rangle+\\langle\\nu,f\\rangle)-G(\\langle Y_{s},f\\rangle)}\\\\ {\\displaystyle-\\,\\langle\\nu,f\\rangle G^{\\prime}(\\langle Y_{s},f\\rangle)\\Big]H(x,\\mathrm{d}\\nu)+G^{\\prime\\prime}(\\langle Y_{s},f\\rangle)\\langle Y_{s},c f^{2}\\rangle}\\\\ {\\displaystyle+\\,G^{\\prime}(\\langle Y_{s},f\\rangle)\\langle Y_{s},\\kappa_{0}(Y_{s},\\cdot,f)\\rangle\\Big\\}\\mathrm{d}s+(\\bar{\\mathcal{G}}_{t+})\\mathrm{-local\\;part}.}\\end{array}\n$$  \n\nfor  $G\\in C^{2}(\\mathbb{R})$  and  $f\\in D(A)$  , where  \n\n$$\n\\kappa_{0}(\\nu,x,f)=\\int_{F}r(\\nu,y)p(x,y)\\kappa f(y)\\lambda(\\mathrm{d}y).\n$$  \n\nWe can interpret  $\\left\\{Y_{t}:t\\geq0\\right\\}$  as a superprocess with an extra interactive non-local branching mechanism given by (10.27).  \n\n# 10.4 General Interactive Immigration  \n\nIn this section, we give some generalizations of the immigration models considered in the previous sections. Suppose that  $F_{0}$  and  $F_{1}$  are Lusin topological spaces. Let  $\\lambda_{0}(\\mathrm{d}y)$  and  $\\lambda_{1}(\\mathrm{d}y)$  be  $\\sigma$  -finite Borel measures on  $F_{0}$  and  $F_{1}$  , respectively. Let  $\\kappa(y,\\mathrm{d}x)$  be a bounded kernel from  $F_{0}$  to  $E$  and let  $K(y,\\mathrm{d}\\nu)$  be a kernel from  $F_{1}$  to  $M(E)^{\\circ}$  satisfying  \n\n$$\n\\operatorname*{sup}_{y\\in F_{1}}\\int_{M(E)^{\\circ}}\\langle\\nu,1\\rangle K(y,\\mathrm{d}\\nu)<\\infty.\n$$  \n\nSuppose that  $(D_{0},\\mathcal{A}^{0},\\mathcal{A}_{t}^{0},\\mathbf{Q}_{\\nu})$  is the canonical cadlag realization of the  $(\\xi,\\phi)$  superprocess. Let  $\\{(X_{t},{\\mathcal{F}}_{t})\\ :\\ t\\ \\geq\\ 0\\}$  be a cadlag  $(\\xi,\\phi)$  -super process with deterministic initial state  $X_{0}\\,=\\,\\mu\\,\\in\\,M(E)$  . For  $i\\,=\\,0,1$  let  $\\{N_{i}(\\mathrm{d}s,\\mathrm{d}y,\\mathrm{d}u,\\mathrm{d}w)\\}$  be a Poisson random measure on  $(0,\\infty)\\,\\times\\,F_{i}\\,\\times\\,(0,\\infty)\\,\\times\\,D_{0}$  with intensity  $\\mathrm{d}s\\lambda_{i}(\\mathrm{d}y)\\mathrm{d}u\\mathbf{Q}_{i}(y,\\mathrm{d}w)$  , where  \n\n$$\n\\mathbf{Q}_{0}(y,\\mathrm{d}w)=\\int_{E}\\kappa(y,\\mathrm{d}x)\\mathbf{Q}_{L(x)}(\\mathrm{d}w),\\quad y\\in F_{0},w\\in D_{0},\n$$  \n\nand  \n\n$$\n\\mathbf{Q}_{1}(y,\\mathrm{d}w)=\\int_{M(E)^{\\circ}}K(y,\\mathrm{d}\\nu)\\mathbf{Q}_{\\nu}(\\mathrm{d}w),\\quad y\\in F_{1},w\\in D_{0}.\n$$  \n\nWe assume that the process  $\\{(X_{t},{\\mathcal{F}}_{t}):t\\geq0\\}$  and the Poisson random measures  $\\{N_{0}(\\mathrm{d}s,\\mathrm{d}y,\\mathrm{d}u,\\mathrm{d}w)\\}$  and  $\\{N_{1}(\\mathrm{d}s,\\mathrm{d}y,\\mathrm{d}u,\\mathrm{d}w)\\}$  are defined on a complete probability space  $(\\Omega,\\mathcal{G},\\mathbf{P})$  and are independent of each other. For  $t\\geq0$  let  $\\mathcal{G}_{t}$  be the  $\\sigma$  -algebra generated by  $\\mathcal{F}_{t}$  and the collection of random variables.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "We can interpret \\( \\{Y_{t}:t\\geq0\\} \\) as a superprocess with an extra interactive non-local branching mechanism given by (10.27).",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Measure-Valued_Branching_Markov_Processes(Li).pdf_256",
        "ID": "0e19967b-8102-4e40-9b93-5e6128d1af89",
        "questions": "What is the condition on the kernel \\( K(y,\\mathrm{d}\\nu) \\) from \\( F_{1} \\) to \\( M(E)^{\\circ} \\) in the document?",
        "answers": "The supremum of the integral of \\( \\langle\\nu,1\\rangle K(y,\\mathrm{d}\\nu) \\) over \\( y \\in F_{1} \\) is finite.",
        "context": "$$\n\\begin{array}{l l}{\\displaystyle+\\int_{E}Y_{s}(\\mathrm{d}x)\\int_{M(E)^{\\circ}}\\Big[G(\\langle Y_{s},f\\rangle+\\langle\\nu,f\\rangle)-G(\\langle Y_{s},f\\rangle)}\\\\ {\\displaystyle-\\,\\langle\\nu,f\\rangle G^{\\prime}(\\langle Y_{s},f\\rangle)\\Big]H(x,\\mathrm{d}\\nu)+G^{\\prime\\prime}(\\langle Y_{s},f\\rangle)\\langle Y_{s},c f^{2}\\rangle}\\\\ {\\displaystyle+\\,G^{\\prime}(\\langle Y_{s},f\\rangle)\\langle Y_{s},\\kappa_{0}(Y_{s},\\cdot,f)\\rangle\\Big\\}\\mathrm{d}s+(\\bar{\\mathcal{G}}_{t+})\\mathrm{-local\\;part}.}\\end{array}\n$$  \n\nfor  $G\\in C^{2}(\\mathbb{R})$  and  $f\\in D(A)$  , where  \n\n$$\n\\kappa_{0}(\\nu,x,f)=\\int_{F}r(\\nu,y)p(x,y)\\kappa f(y)\\lambda(\\mathrm{d}y).\n$$  \n\nWe can interpret  $\\left\\{Y_{t}:t\\geq0\\right\\}$  as a superprocess with an extra interactive non-local branching mechanism given by (10.27).  \n\n# 10.4 General Interactive Immigration  \n\nIn this section, we give some generalizations of the immigration models considered in the previous sections. Suppose that  $F_{0}$  and  $F_{1}$  are Lusin topological spaces. Let  $\\lambda_{0}(\\mathrm{d}y)$  and  $\\lambda_{1}(\\mathrm{d}y)$  be  $\\sigma$  -finite Borel measures on  $F_{0}$  and  $F_{1}$  , respectively. Let  $\\kappa(y,\\mathrm{d}x)$  be a bounded kernel from  $F_{0}$  to  $E$  and let  $K(y,\\mathrm{d}\\nu)$  be a kernel from  $F_{1}$  to  $M(E)^{\\circ}$  satisfying  \n\n$$\n\\operatorname*{sup}_{y\\in F_{1}}\\int_{M(E)^{\\circ}}\\langle\\nu,1\\rangle K(y,\\mathrm{d}\\nu)<\\infty.\n$$  \n\nSuppose that  $(D_{0},\\mathcal{A}^{0},\\mathcal{A}_{t}^{0},\\mathbf{Q}_{\\nu})$  is the canonical cadlag realization of the  $(\\xi,\\phi)$  superprocess. Let  $\\{(X_{t},{\\mathcal{F}}_{t})\\ :\\ t\\ \\geq\\ 0\\}$  be a cadlag  $(\\xi,\\phi)$  -super process with deterministic initial state  $X_{0}\\,=\\,\\mu\\,\\in\\,M(E)$  . For  $i\\,=\\,0,1$  let  $\\{N_{i}(\\mathrm{d}s,\\mathrm{d}y,\\mathrm{d}u,\\mathrm{d}w)\\}$  be a Poisson random measure on  $(0,\\infty)\\,\\times\\,F_{i}\\,\\times\\,(0,\\infty)\\,\\times\\,D_{0}$  with intensity  $\\mathrm{d}s\\lambda_{i}(\\mathrm{d}y)\\mathrm{d}u\\mathbf{Q}_{i}(y,\\mathrm{d}w)$  , where  \n\n$$\n\\mathbf{Q}_{0}(y,\\mathrm{d}w)=\\int_{E}\\kappa(y,\\mathrm{d}x)\\mathbf{Q}_{L(x)}(\\mathrm{d}w),\\quad y\\in F_{0},w\\in D_{0},\n$$  \n\nand  \n\n$$\n\\mathbf{Q}_{1}(y,\\mathrm{d}w)=\\int_{M(E)^{\\circ}}K(y,\\mathrm{d}\\nu)\\mathbf{Q}_{\\nu}(\\mathrm{d}w),\\quad y\\in F_{1},w\\in D_{0}.\n$$  \n\nWe assume that the process  $\\{(X_{t},{\\mathcal{F}}_{t}):t\\geq0\\}$  and the Poisson random measures  $\\{N_{0}(\\mathrm{d}s,\\mathrm{d}y,\\mathrm{d}u,\\mathrm{d}w)\\}$  and  $\\{N_{1}(\\mathrm{d}s,\\mathrm{d}y,\\mathrm{d}u,\\mathrm{d}w)\\}$  are defined on a complete probability space  $(\\Omega,\\mathcal{G},\\mathbf{P})$  and are independent of each other. For  $t\\geq0$  let  $\\mathcal{G}_{t}$  be the  $\\sigma$  -algebra generated by  $\\mathcal{F}_{t}$  and the collection of random variables.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Let \\( K(y,\\mathrm{d}\\nu) \\) be a kernel from \\( F_{1} \\) to \\( M(E)^{\\circ} \\) satisfying \\( \\operatorname*{sup}_{y\\in F_{1}}\\int_{M(E)^{\\circ}}\\langle\\nu,1\\rangle K(y,\\mathrm{d}\\nu)<\\infty. \\)",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Measure-Valued_Branching_Markov_Processes(Li).pdf_256",
        "ID": "0e1bebee-5052-4fb0-b33a-463cd3e01f89",
        "questions": "What kind of measure is \\( N_{i}(\\mathrm{d}s,\\mathrm{d}y,\\mathrm{d}u,\\mathrm{d}w) \\) and what is its intensity for \\( i=0,1 \\)?",
        "answers": "It is a Poisson random measure with intensity \\( \\mathrm{d}s\\lambda_{i}(\\mathrm{d}y)\\mathrm{d}u\\mathbf{Q}_{i}(y,\\mathrm{d}w) \\).",
        "context": "$$\n\\begin{array}{l l}{\\displaystyle+\\int_{E}Y_{s}(\\mathrm{d}x)\\int_{M(E)^{\\circ}}\\Big[G(\\langle Y_{s},f\\rangle+\\langle\\nu,f\\rangle)-G(\\langle Y_{s},f\\rangle)}\\\\ {\\displaystyle-\\,\\langle\\nu,f\\rangle G^{\\prime}(\\langle Y_{s},f\\rangle)\\Big]H(x,\\mathrm{d}\\nu)+G^{\\prime\\prime}(\\langle Y_{s},f\\rangle)\\langle Y_{s},c f^{2}\\rangle}\\\\ {\\displaystyle+\\,G^{\\prime}(\\langle Y_{s},f\\rangle)\\langle Y_{s},\\kappa_{0}(Y_{s},\\cdot,f)\\rangle\\Big\\}\\mathrm{d}s+(\\bar{\\mathcal{G}}_{t+})\\mathrm{-local\\;part}.}\\end{array}\n$$  \n\nfor  $G\\in C^{2}(\\mathbb{R})$  and  $f\\in D(A)$  , where  \n\n$$\n\\kappa_{0}(\\nu,x,f)=\\int_{F}r(\\nu,y)p(x,y)\\kappa f(y)\\lambda(\\mathrm{d}y).\n$$  \n\nWe can interpret  $\\left\\{Y_{t}:t\\geq0\\right\\}$  as a superprocess with an extra interactive non-local branching mechanism given by (10.27).  \n\n# 10.4 General Interactive Immigration  \n\nIn this section, we give some generalizations of the immigration models considered in the previous sections. Suppose that  $F_{0}$  and  $F_{1}$  are Lusin topological spaces. Let  $\\lambda_{0}(\\mathrm{d}y)$  and  $\\lambda_{1}(\\mathrm{d}y)$  be  $\\sigma$  -finite Borel measures on  $F_{0}$  and  $F_{1}$  , respectively. Let  $\\kappa(y,\\mathrm{d}x)$  be a bounded kernel from  $F_{0}$  to  $E$  and let  $K(y,\\mathrm{d}\\nu)$  be a kernel from  $F_{1}$  to  $M(E)^{\\circ}$  satisfying  \n\n$$\n\\operatorname*{sup}_{y\\in F_{1}}\\int_{M(E)^{\\circ}}\\langle\\nu,1\\rangle K(y,\\mathrm{d}\\nu)<\\infty.\n$$  \n\nSuppose that  $(D_{0},\\mathcal{A}^{0},\\mathcal{A}_{t}^{0},\\mathbf{Q}_{\\nu})$  is the canonical cadlag realization of the  $(\\xi,\\phi)$  superprocess. Let  $\\{(X_{t},{\\mathcal{F}}_{t})\\ :\\ t\\ \\geq\\ 0\\}$  be a cadlag  $(\\xi,\\phi)$  -super process with deterministic initial state  $X_{0}\\,=\\,\\mu\\,\\in\\,M(E)$  . For  $i\\,=\\,0,1$  let  $\\{N_{i}(\\mathrm{d}s,\\mathrm{d}y,\\mathrm{d}u,\\mathrm{d}w)\\}$  be a Poisson random measure on  $(0,\\infty)\\,\\times\\,F_{i}\\,\\times\\,(0,\\infty)\\,\\times\\,D_{0}$  with intensity  $\\mathrm{d}s\\lambda_{i}(\\mathrm{d}y)\\mathrm{d}u\\mathbf{Q}_{i}(y,\\mathrm{d}w)$  , where  \n\n$$\n\\mathbf{Q}_{0}(y,\\mathrm{d}w)=\\int_{E}\\kappa(y,\\mathrm{d}x)\\mathbf{Q}_{L(x)}(\\mathrm{d}w),\\quad y\\in F_{0},w\\in D_{0},\n$$  \n\nand  \n\n$$\n\\mathbf{Q}_{1}(y,\\mathrm{d}w)=\\int_{M(E)^{\\circ}}K(y,\\mathrm{d}\\nu)\\mathbf{Q}_{\\nu}(\\mathrm{d}w),\\quad y\\in F_{1},w\\in D_{0}.\n$$  \n\nWe assume that the process  $\\{(X_{t},{\\mathcal{F}}_{t}):t\\geq0\\}$  and the Poisson random measures  $\\{N_{0}(\\mathrm{d}s,\\mathrm{d}y,\\mathrm{d}u,\\mathrm{d}w)\\}$  and  $\\{N_{1}(\\mathrm{d}s,\\mathrm{d}y,\\mathrm{d}u,\\mathrm{d}w)\\}$  are defined on a complete probability space  $(\\Omega,\\mathcal{G},\\mathbf{P})$  and are independent of each other. For  $t\\geq0$  let  $\\mathcal{G}_{t}$  be the  $\\sigma$  -algebra generated by  $\\mathcal{F}_{t}$  and the collection of random variables.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "For \\( i\\,=\\,0,1 \\) let \\( \\{N_{i}(\\mathrm{d}s,\\mathrm{d}y,\\mathrm{d}u,\\mathrm{d}w)\\} \\) be a Poisson random measure on \\( (0,\\infty)\\,\\times\\,F_{i}\\,\\times\\,(0,\\infty)\\,\\times\\,D_{0} \\) with intensity \\( \\mathrm{d}s\\lambda_{i}(\\mathrm{d}y)\\mathrm{d}u\\mathbf{Q}_{i}(y,\\mathrm{d}w) \\).",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Measure-Valued_Branching_Markov_Processes(Li).pdf_256",
        "ID": "0e1d0ad4-2fe4-45cc-beb5-31cce23e4a50",
        "questions": "What is the bounded kernel from \\( F_0 \\) to \\( E \\) denoted as in the immigration model?",
        "answers": "\\(\\kappa(y,\\mathrm{d}x)\\)",
        "context": "$$\n\\begin{array}{l l}{\\displaystyle+\\int_{E}Y_{s}(\\mathrm{d}x)\\int_{M(E)^{\\circ}}\\Big[G(\\langle Y_{s},f\\rangle+\\langle\\nu,f\\rangle)-G(\\langle Y_{s},f\\rangle)}\\\\ {\\displaystyle-\\,\\langle\\nu,f\\rangle G^{\\prime}(\\langle Y_{s},f\\rangle)\\Big]H(x,\\mathrm{d}\\nu)+G^{\\prime\\prime}(\\langle Y_{s},f\\rangle)\\langle Y_{s},c f^{2}\\rangle}\\\\ {\\displaystyle+\\,G^{\\prime}(\\langle Y_{s},f\\rangle)\\langle Y_{s},\\kappa_{0}(Y_{s},\\cdot,f)\\rangle\\Big\\}\\mathrm{d}s+(\\bar{\\mathcal{G}}_{t+})\\mathrm{-local\\;part}.}\\end{array}\n$$  \n\nfor  $G\\in C^{2}(\\mathbb{R})$  and  $f\\in D(A)$  , where  \n\n$$\n\\kappa_{0}(\\nu,x,f)=\\int_{F}r(\\nu,y)p(x,y)\\kappa f(y)\\lambda(\\mathrm{d}y).\n$$  \n\nWe can interpret  $\\left\\{Y_{t}:t\\geq0\\right\\}$  as a superprocess with an extra interactive non-local branching mechanism given by (10.27).  \n\n# 10.4 General Interactive Immigration  \n\nIn this section, we give some generalizations of the immigration models considered in the previous sections. Suppose that  $F_{0}$  and  $F_{1}$  are Lusin topological spaces. Let  $\\lambda_{0}(\\mathrm{d}y)$  and  $\\lambda_{1}(\\mathrm{d}y)$  be  $\\sigma$  -finite Borel measures on  $F_{0}$  and  $F_{1}$  , respectively. Let  $\\kappa(y,\\mathrm{d}x)$  be a bounded kernel from  $F_{0}$  to  $E$  and let  $K(y,\\mathrm{d}\\nu)$  be a kernel from  $F_{1}$  to  $M(E)^{\\circ}$  satisfying  \n\n$$\n\\operatorname*{sup}_{y\\in F_{1}}\\int_{M(E)^{\\circ}}\\langle\\nu,1\\rangle K(y,\\mathrm{d}\\nu)<\\infty.\n$$  \n\nSuppose that  $(D_{0},\\mathcal{A}^{0},\\mathcal{A}_{t}^{0},\\mathbf{Q}_{\\nu})$  is the canonical cadlag realization of the  $(\\xi,\\phi)$  superprocess. Let  $\\{(X_{t},{\\mathcal{F}}_{t})\\ :\\ t\\ \\geq\\ 0\\}$  be a cadlag  $(\\xi,\\phi)$  -super process with deterministic initial state  $X_{0}\\,=\\,\\mu\\,\\in\\,M(E)$  . For  $i\\,=\\,0,1$  let  $\\{N_{i}(\\mathrm{d}s,\\mathrm{d}y,\\mathrm{d}u,\\mathrm{d}w)\\}$  be a Poisson random measure on  $(0,\\infty)\\,\\times\\,F_{i}\\,\\times\\,(0,\\infty)\\,\\times\\,D_{0}$  with intensity  $\\mathrm{d}s\\lambda_{i}(\\mathrm{d}y)\\mathrm{d}u\\mathbf{Q}_{i}(y,\\mathrm{d}w)$  , where  \n\n$$\n\\mathbf{Q}_{0}(y,\\mathrm{d}w)=\\int_{E}\\kappa(y,\\mathrm{d}x)\\mathbf{Q}_{L(x)}(\\mathrm{d}w),\\quad y\\in F_{0},w\\in D_{0},\n$$  \n\nand  \n\n$$\n\\mathbf{Q}_{1}(y,\\mathrm{d}w)=\\int_{M(E)^{\\circ}}K(y,\\mathrm{d}\\nu)\\mathbf{Q}_{\\nu}(\\mathrm{d}w),\\quad y\\in F_{1},w\\in D_{0}.\n$$  \n\nWe assume that the process  $\\{(X_{t},{\\mathcal{F}}_{t}):t\\geq0\\}$  and the Poisson random measures  $\\{N_{0}(\\mathrm{d}s,\\mathrm{d}y,\\mathrm{d}u,\\mathrm{d}w)\\}$  and  $\\{N_{1}(\\mathrm{d}s,\\mathrm{d}y,\\mathrm{d}u,\\mathrm{d}w)\\}$  are defined on a complete probability space  $(\\Omega,\\mathcal{G},\\mathbf{P})$  and are independent of each other. For  $t\\geq0$  let  $\\mathcal{G}_{t}$  be the  $\\sigma$  -algebra generated by  $\\mathcal{F}_{t}$  and the collection of random variables.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Let  $\\kappa(y,\\mathrm{d}x)$  be a bounded kernel from  $F_{0}$  to  $E$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/Measure-Valued_Branching_Markov_Processes(Li).pdf_256",
        "ID": "0e1ee981-43e3-4f49-b4bd-ba0d8e4a5806",
        "questions": "According to the given document, what are the \\( \\mathbf{Q}_0(y,\\mathrm{d}w) \\) and \\( \\mathbf{Q}_1(y,\\mathrm{d}w) \\) formulas in the immigration models?",
        "answers": "\\(\\mathbf{Q}_{0}(y,\\mathrm{d}w)=\\int_{E}\\kappa(y,\\mathrm{d}x)\\mathbf{Q}_{L(x)}(\\mathrm{d}w),\\quad y\\in F_{0},w\\in D_{0},\\) and \\(\\mathbf{Q}_{1}(y,\\mathrm{d}w)=\\int_{M(E)^{\\circ}}K(y,\\mathrm{d}\nu)\\mathbf{Q}_{\nu}(\\mathrm{d}w),\\quad y\\in F_{1},w\\in D_{0}.\\)",
        "context": "$$\n\\begin{array}{l l}{\\displaystyle+\\int_{E}Y_{s}(\\mathrm{d}x)\\int_{M(E)^{\\circ}}\\Big[G(\\langle Y_{s},f\\rangle+\\langle\\nu,f\\rangle)-G(\\langle Y_{s},f\\rangle)}\\\\ {\\displaystyle-\\,\\langle\\nu,f\\rangle G^{\\prime}(\\langle Y_{s},f\\rangle)\\Big]H(x,\\mathrm{d}\\nu)+G^{\\prime\\prime}(\\langle Y_{s},f\\rangle)\\langle Y_{s},c f^{2}\\rangle}\\\\ {\\displaystyle+\\,G^{\\prime}(\\langle Y_{s},f\\rangle)\\langle Y_{s},\\kappa_{0}(Y_{s},\\cdot,f)\\rangle\\Big\\}\\mathrm{d}s+(\\bar{\\mathcal{G}}_{t+})\\mathrm{-local\\;part}.}\\end{array}\n$$  \n\nfor  $G\\in C^{2}(\\mathbb{R})$  and  $f\\in D(A)$  , where  \n\n$$\n\\kappa_{0}(\\nu,x,f)=\\int_{F}r(\\nu,y)p(x,y)\\kappa f(y)\\lambda(\\mathrm{d}y).\n$$  \n\nWe can interpret  $\\left\\{Y_{t}:t\\geq0\\right\\}$  as a superprocess with an extra interactive non-local branching mechanism given by (10.27).  \n\n# 10.4 General Interactive Immigration  \n\nIn this section, we give some generalizations of the immigration models considered in the previous sections. Suppose that  $F_{0}$  and  $F_{1}$  are Lusin topological spaces. Let  $\\lambda_{0}(\\mathrm{d}y)$  and  $\\lambda_{1}(\\mathrm{d}y)$  be  $\\sigma$  -finite Borel measures on  $F_{0}$  and  $F_{1}$  , respectively. Let  $\\kappa(y,\\mathrm{d}x)$  be a bounded kernel from  $F_{0}$  to  $E$  and let  $K(y,\\mathrm{d}\\nu)$  be a kernel from  $F_{1}$  to  $M(E)^{\\circ}$  satisfying  \n\n$$\n\\operatorname*{sup}_{y\\in F_{1}}\\int_{M(E)^{\\circ}}\\langle\\nu,1\\rangle K(y,\\mathrm{d}\\nu)<\\infty.\n$$  \n\nSuppose that  $(D_{0},\\mathcal{A}^{0},\\mathcal{A}_{t}^{0},\\mathbf{Q}_{\\nu})$  is the canonical cadlag realization of the  $(\\xi,\\phi)$  superprocess. Let  $\\{(X_{t},{\\mathcal{F}}_{t})\\ :\\ t\\ \\geq\\ 0\\}$  be a cadlag  $(\\xi,\\phi)$  -super process with deterministic initial state  $X_{0}\\,=\\,\\mu\\,\\in\\,M(E)$  . For  $i\\,=\\,0,1$  let  $\\{N_{i}(\\mathrm{d}s,\\mathrm{d}y,\\mathrm{d}u,\\mathrm{d}w)\\}$  be a Poisson random measure on  $(0,\\infty)\\,\\times\\,F_{i}\\,\\times\\,(0,\\infty)\\,\\times\\,D_{0}$  with intensity  $\\mathrm{d}s\\lambda_{i}(\\mathrm{d}y)\\mathrm{d}u\\mathbf{Q}_{i}(y,\\mathrm{d}w)$  , where  \n\n$$\n\\mathbf{Q}_{0}(y,\\mathrm{d}w)=\\int_{E}\\kappa(y,\\mathrm{d}x)\\mathbf{Q}_{L(x)}(\\mathrm{d}w),\\quad y\\in F_{0},w\\in D_{0},\n$$  \n\nand  \n\n$$\n\\mathbf{Q}_{1}(y,\\mathrm{d}w)=\\int_{M(E)^{\\circ}}K(y,\\mathrm{d}\\nu)\\mathbf{Q}_{\\nu}(\\mathrm{d}w),\\quad y\\in F_{1},w\\in D_{0}.\n$$  \n\nWe assume that the process  $\\{(X_{t},{\\mathcal{F}}_{t}):t\\geq0\\}$  and the Poisson random measures  $\\{N_{0}(\\mathrm{d}s,\\mathrm{d}y,\\mathrm{d}u,\\mathrm{d}w)\\}$  and  $\\{N_{1}(\\mathrm{d}s,\\mathrm{d}y,\\mathrm{d}u,\\mathrm{d}w)\\}$  are defined on a complete probability space  $(\\Omega,\\mathcal{G},\\mathbf{P})$  and are independent of each other. For  $t\\geq0$  let  $\\mathcal{G}_{t}$  be the  $\\sigma$  -algebra generated by  $\\mathcal{F}_{t}$  and the collection of random variables.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$$\\mathbf{Q}_{0}(y,\\mathrm{d}w)=\\int_{E}\\kappa(y,\\mathrm{d}x)\\mathbf{Q}_{L(x)}(\\mathrm{d}w),\\quad y\\in F_{0},w\\in D_{0},$$ and $$\\mathbf{Q}_{1}(y,\\mathrm{d}w)=\\int_{M(E)^{\\circ}}K(y,\\mathrm{d}\nu)\\mathbf{Q}_{\nu}(\\mathrm{d}w),\\quad y\\in F_{1},w\\in D_{0}.$$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/Measure-Valued_Branching_Markov_Processes(Li).pdf_256",
        "ID": "0e21a2af-357c-402d-b49e-f679c1611767",
        "questions": "What is the integrand in the formula for \\(\\kappa_{0}(\nu,x,f)\\) as depicted in the equation in the document involving \\( r(\nu,y) \\) and \\( \\lambda(\\mathrm{d}y) \\)?",
        "answers": "r(\nu,y)p(x,y)\\kappa f(y)",
        "context": "$$\n\\begin{array}{l l}{\\displaystyle+\\int_{E}Y_{s}(\\mathrm{d}x)\\int_{M(E)^{\\circ}}\\Big[G(\\langle Y_{s},f\\rangle+\\langle\\nu,f\\rangle)-G(\\langle Y_{s},f\\rangle)}\\\\ {\\displaystyle-\\,\\langle\\nu,f\\rangle G^{\\prime}(\\langle Y_{s},f\\rangle)\\Big]H(x,\\mathrm{d}\\nu)+G^{\\prime\\prime}(\\langle Y_{s},f\\rangle)\\langle Y_{s},c f^{2}\\rangle}\\\\ {\\displaystyle+\\,G^{\\prime}(\\langle Y_{s},f\\rangle)\\langle Y_{s},\\kappa_{0}(Y_{s},\\cdot,f)\\rangle\\Big\\}\\mathrm{d}s+(\\bar{\\mathcal{G}}_{t+})\\mathrm{-local\\;part}.}\\end{array}\n$$  \n\nfor  $G\\in C^{2}(\\mathbb{R})$  and  $f\\in D(A)$  , where  \n\n$$\n\\kappa_{0}(\\nu,x,f)=\\int_{F}r(\\nu,y)p(x,y)\\kappa f(y)\\lambda(\\mathrm{d}y).\n$$  \n\nWe can interpret  $\\left\\{Y_{t}:t\\geq0\\right\\}$  as a superprocess with an extra interactive non-local branching mechanism given by (10.27).  \n\n# 10.4 General Interactive Immigration  \n\nIn this section, we give some generalizations of the immigration models considered in the previous sections. Suppose that  $F_{0}$  and  $F_{1}$  are Lusin topological spaces. Let  $\\lambda_{0}(\\mathrm{d}y)$  and  $\\lambda_{1}(\\mathrm{d}y)$  be  $\\sigma$  -finite Borel measures on  $F_{0}$  and  $F_{1}$  , respectively. Let  $\\kappa(y,\\mathrm{d}x)$  be a bounded kernel from  $F_{0}$  to  $E$  and let  $K(y,\\mathrm{d}\\nu)$  be a kernel from  $F_{1}$  to  $M(E)^{\\circ}$  satisfying  \n\n$$\n\\operatorname*{sup}_{y\\in F_{1}}\\int_{M(E)^{\\circ}}\\langle\\nu,1\\rangle K(y,\\mathrm{d}\\nu)<\\infty.\n$$  \n\nSuppose that  $(D_{0},\\mathcal{A}^{0},\\mathcal{A}_{t}^{0},\\mathbf{Q}_{\\nu})$  is the canonical cadlag realization of the  $(\\xi,\\phi)$  superprocess. Let  $\\{(X_{t},{\\mathcal{F}}_{t})\\ :\\ t\\ \\geq\\ 0\\}$  be a cadlag  $(\\xi,\\phi)$  -super process with deterministic initial state  $X_{0}\\,=\\,\\mu\\,\\in\\,M(E)$  . For  $i\\,=\\,0,1$  let  $\\{N_{i}(\\mathrm{d}s,\\mathrm{d}y,\\mathrm{d}u,\\mathrm{d}w)\\}$  be a Poisson random measure on  $(0,\\infty)\\,\\times\\,F_{i}\\,\\times\\,(0,\\infty)\\,\\times\\,D_{0}$  with intensity  $\\mathrm{d}s\\lambda_{i}(\\mathrm{d}y)\\mathrm{d}u\\mathbf{Q}_{i}(y,\\mathrm{d}w)$  , where  \n\n$$\n\\mathbf{Q}_{0}(y,\\mathrm{d}w)=\\int_{E}\\kappa(y,\\mathrm{d}x)\\mathbf{Q}_{L(x)}(\\mathrm{d}w),\\quad y\\in F_{0},w\\in D_{0},\n$$  \n\nand  \n\n$$\n\\mathbf{Q}_{1}(y,\\mathrm{d}w)=\\int_{M(E)^{\\circ}}K(y,\\mathrm{d}\\nu)\\mathbf{Q}_{\\nu}(\\mathrm{d}w),\\quad y\\in F_{1},w\\in D_{0}.\n$$  \n\nWe assume that the process  $\\{(X_{t},{\\mathcal{F}}_{t}):t\\geq0\\}$  and the Poisson random measures  $\\{N_{0}(\\mathrm{d}s,\\mathrm{d}y,\\mathrm{d}u,\\mathrm{d}w)\\}$  and  $\\{N_{1}(\\mathrm{d}s,\\mathrm{d}y,\\mathrm{d}u,\\mathrm{d}w)\\}$  are defined on a complete probability space  $(\\Omega,\\mathcal{G},\\mathbf{P})$  and are independent of each other. For  $t\\geq0$  let  $\\mathcal{G}_{t}$  be the  $\\sigma$  -algebra generated by  $\\mathcal{F}_{t}$  and the collection of random variables.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$$\\kappa_{0}(\nu,x,f)=\\int_{F}r(\nu,y)p(x,y)\\kappa f(y)\\lambda(\\mathrm{d}y).$$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/SMM_Buildings_By_Kenneth.pdf_136",
        "ID": "0e2a04bd-3c16-40af-b3be-516709463e6f",
        "questions": "What field is the residue field associated with the $\\pmb{p}$-adic valuation on the field of rational numbers $\\mathbf{Q}$?",
        "answers": "$\\mathbf{F}_{p}$",
        "context": "The principal ideal $\\pi A$ generated by $\\pi$ can be described in terms of $\\pmb{v}$ as\n\n$\\{\\,x\\in K:v(x)>0\\,\\}$. It is a maximal ideal, since every element of $A$ not in\n\n$\\pi A$ is a unit. The quotient ring $k=A/\\pi A$ is therefore a field, called the residue field associated to the valuation $\\pmb{v}$.\n\nExample. Let $K$ be the field $\\mathbf{Q}$ of rational numbers, and let $\\pmb{p}$ be a prime number. The $\\pmb{p}$-adic valuation on $\\mathbf{Q}$ is defined by setting $v(x)$ equal to the exponent of $\\pmb{p}$ in the prime factorization of $\\pmb{x}$. More precisely, given $\\pmb{x}\\in\\mathbf{Q}^{*}$ write ${\\pmb x}={\\pmb p}^{n}{\\pmb u}$, where $\\pmb{n}$ is a (possibly negative) integer and $\\pmb{u}$ is a rational number whose numerator and denominator are not divisible by $\\pmb{p}$, then ${\\pmb v}({\\pmb x})=n$. The valuation ring $A$ is the ring of fractions $a/b$ with ${\\pmb a},{\\pmb b}\\in{\\bf Z}$ and $b$ not divisible by $\\pmb{p}$. [The ring $A$ happens to be the localization of $\\mathbf{z}$ at $\\pmb{p}$, but we will not make any use of this.] The residue field $\\pmb{k}$ is the field $\\mathbf{F}_{p}$ of integers mod $p$, one sees this by using the homomorphism $A\\nrightarrow\\mathbf{F}_{p}$ given by $a/b\\mapsto{\\big(}a{\\mathrm{~mod~}}p{\\big)}(b{\\mathrm{~mod~}}p)^{-1}$, where $\\pmb{a}$ and $b$ are as above.\n\nThe valuation ring $A$ in this example can be described informally as the largest subring of $\\mathbf{Q}$ on which reduction mod $\\pmb{p}$ makes sense. It is thus the natural ring to introduce if one wants to relate the field $\\mathbf{Q}$ to the field $\\mathbf{F}_{p}$. This illustrates our point of view toward valuations: We will be interested in studying things (namely, matrix groups) defined over a field $K$, and we wish to \u201creduce\u201d to a simpler field $\\pmb{k}$ as an aid in this study; a discrete valuation makes this possible by providing us with a nice ring $A$ to serve as intermediary between $K$ and $\\pmb{k}$.\n\n$$\n\\begin{array}{l l l}{A}&{\\hookrightarrow}&{K}\\\\ {\\downarrow}&{}&{}\\\\ k&{}&{}\\end{array}\n$$\n\nReturning now to the general theory, we note that the study of the arithmetic of $A$ (e.g., ideals and prime factorization) is fairly trivial:\n\nProposition 1. A discrete valuation ring $A$ is a principal ideal domain and every non-zero ideal is generated by $\\pi^{n}$ for some $n\\geq0$. In particular, $\\pi A$ is the unique non-zero prime ideal of $A$.\n\nPROOF: Let $I$ be a non-zero ideal and let $n=\\operatorname*{min}\\{v(a):a\\in I\\}$. Then $I$ contains $\\pi^{n}$, and every element of $I$ is divisible by $\\pi^{n}$; hence $I=\\pi^{n}A$. \u53e3\n\nOne consequence of this is that we can apply the basic facts about modules over a principal ideal domain (e.g., a submodule of a free module is free). Let's recall some of these facts, in the form in which we'll need them later. Let $V$ be the vector space $K^{n}$. By a lattice (or A-lattice) in $V$ we will mean an $A$-submodule $L\\subset V$ of the form $L=A e_{1}\\oplus\\cdot\\cdot\\oplus A e_{n}$ for some basis $\\boldsymbol{e}_{1},\\ldots,\\boldsymbol{e}_{n}$ of $V$. In particular, $L$ is a free $A$-module of rank $\\pmb{n}$. If we take $\\boldsymbol{e}_{1},\\ldots,\\boldsymbol{e}_{n}$ to be the standard basis of $V$, then the resulting lattice is $A^{n}$, which we call the standard lattice.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "The residue field $\\pmb{k}$ is the field $\\mathbf{F}_{p}$ of integers mod $p$, one sees this by using the homomorphism $A\\rightarrow\\mathbf{F}_{p}$ given by $a/b\\mapsto\\big(a\\mathrm{\\mod~}p\\big)(b\\mathrm{~mod~}p)^{-1}$, where $\\pmb{a}$ and $b$ are as above.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/SMM_Buildings_By_Kenneth.pdf_136",
        "ID": "0e31b19d-3b3a-4486-97d6-0b863d43582a",
        "questions": "What is the form of a non-zero ideal in a discrete valuation ring $A$ according to Proposition 1?",
        "answers": "$I=\\pi^{n}A$",
        "context": "The principal ideal $\\pi A$ generated by $\\pi$ can be described in terms of $\\pmb{v}$ as\n\n$\\{\\,x\\in K:v(x)>0\\,\\}$. It is a maximal ideal, since every element of $A$ not in\n\n$\\pi A$ is a unit. The quotient ring $k=A/\\pi A$ is therefore a field, called the residue field associated to the valuation $\\pmb{v}$.\n\nExample. Let $K$ be the field $\\mathbf{Q}$ of rational numbers, and let $\\pmb{p}$ be a prime number. The $\\pmb{p}$-adic valuation on $\\mathbf{Q}$ is defined by setting $v(x)$ equal to the exponent of $\\pmb{p}$ in the prime factorization of $\\pmb{x}$. More precisely, given $\\pmb{x}\\in\\mathbf{Q}^{*}$ write ${\\pmb x}={\\pmb p}^{n}{\\pmb u}$, where $\\pmb{n}$ is a (possibly negative) integer and $\\pmb{u}$ is a rational number whose numerator and denominator are not divisible by $\\pmb{p}$, then ${\\pmb v}({\\pmb x})=n$. The valuation ring $A$ is the ring of fractions $a/b$ with ${\\pmb a},{\\pmb b}\\in{\\bf Z}$ and $b$ not divisible by $\\pmb{p}$. [The ring $A$ happens to be the localization of $\\mathbf{z}$ at $\\pmb{p}$, but we will not make any use of this.] The residue field $\\pmb{k}$ is the field $\\mathbf{F}_{p}$ of integers mod $p$, one sees this by using the homomorphism $A\\nrightarrow\\mathbf{F}_{p}$ given by $a/b\\mapsto{\\big(}a{\\mathrm{~mod~}}p{\\big)}(b{\\mathrm{~mod~}}p)^{-1}$, where $\\pmb{a}$ and $b$ are as above.\n\nThe valuation ring $A$ in this example can be described informally as the largest subring of $\\mathbf{Q}$ on which reduction mod $\\pmb{p}$ makes sense. It is thus the natural ring to introduce if one wants to relate the field $\\mathbf{Q}$ to the field $\\mathbf{F}_{p}$. This illustrates our point of view toward valuations: We will be interested in studying things (namely, matrix groups) defined over a field $K$, and we wish to \u201creduce\u201d to a simpler field $\\pmb{k}$ as an aid in this study; a discrete valuation makes this possible by providing us with a nice ring $A$ to serve as intermediary between $K$ and $\\pmb{k}$.\n\n$$\n\\begin{array}{l l l}{A}&{\\hookrightarrow}&{K}\\\\ {\\downarrow}&{}&{}\\\\ k&{}&{}\\end{array}\n$$\n\nReturning now to the general theory, we note that the study of the arithmetic of $A$ (e.g., ideals and prime factorization) is fairly trivial:\n\nProposition 1. A discrete valuation ring $A$ is a principal ideal domain and every non-zero ideal is generated by $\\pi^{n}$ for some $n\\geq0$. In particular, $\\pi A$ is the unique non-zero prime ideal of $A$.\n\nPROOF: Let $I$ be a non-zero ideal and let $n=\\operatorname*{min}\\{v(a):a\\in I\\}$. Then $I$ contains $\\pi^{n}$, and every element of $I$ is divisible by $\\pi^{n}$; hence $I=\\pi^{n}A$. \u53e3\n\nOne consequence of this is that we can apply the basic facts about modules over a principal ideal domain (e.g., a submodule of a free module is free). Let's recall some of these facts, in the form in which we'll need them later. Let $V$ be the vector space $K^{n}$. By a lattice (or A-lattice) in $V$ we will mean an $A$-submodule $L\\subset V$ of the form $L=A e_{1}\\oplus\\cdot\\cdot\\oplus A e_{n}$ for some basis $\\boldsymbol{e}_{1},\\ldots,\\boldsymbol{e}_{n}$ of $V$. In particular, $L$ is a free $A$-module of rank $\\pmb{n}$. If we take $\\boldsymbol{e}_{1},\\ldots,\\boldsymbol{e}_{n}$ to be the standard basis of $V$, then the resulting lattice is $A^{n}$, which we call the standard lattice.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Equation",
        "evidence_source": "text",
        "evidence_context": "Proposition 1. A discrete valuation ring $A$ is a principal ideal domain and every non-zero ideal is generated by $\\pi^{n}$ for some $n\\geq0$. In particular, $\\pi A$ is the unique non-zero prime ideal of $A$. PROOF: Let $I$ be a non-zero ideal and let $n=\\operatorname*{min}\\{v(a):a\\in I\\}. Then $I$ contains $\\pi^{n}$, and every element of $I$ is divisible by $\\pi^{n}$; hence $I=\\pi^{n}A$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/SMM_Buildings_By_Kenneth.pdf_136",
        "ID": "0e4bbca8-986c-4bc7-ab91-5f36014340b1",
        "questions": "What type of module is a submodule of a free module over a principal ideal domain?",
        "answers": "Free module",
        "context": "The principal ideal $\\pi A$ generated by $\\pi$ can be described in terms of $\\pmb{v}$ as\n\n$\\{\\,x\\in K:v(x)>0\\,\\}$. It is a maximal ideal, since every element of $A$ not in\n\n$\\pi A$ is a unit. The quotient ring $k=A/\\pi A$ is therefore a field, called the residue field associated to the valuation $\\pmb{v}$.\n\nExample. Let $K$ be the field $\\mathbf{Q}$ of rational numbers, and let $\\pmb{p}$ be a prime number. The $\\pmb{p}$-adic valuation on $\\mathbf{Q}$ is defined by setting $v(x)$ equal to the exponent of $\\pmb{p}$ in the prime factorization of $\\pmb{x}$. More precisely, given $\\pmb{x}\\in\\mathbf{Q}^{*}$ write ${\\pmb x}={\\pmb p}^{n}{\\pmb u}$, where $\\pmb{n}$ is a (possibly negative) integer and $\\pmb{u}$ is a rational number whose numerator and denominator are not divisible by $\\pmb{p}$, then ${\\pmb v}({\\pmb x})=n$. The valuation ring $A$ is the ring of fractions $a/b$ with ${\\pmb a},{\\pmb b}\\in{\\bf Z}$ and $b$ not divisible by $\\pmb{p}$. [The ring $A$ happens to be the localization of $\\mathbf{z}$ at $\\pmb{p}$, but we will not make any use of this.] The residue field $\\pmb{k}$ is the field $\\mathbf{F}_{p}$ of integers mod $p$, one sees this by using the homomorphism $A\\nrightarrow\\mathbf{F}_{p}$ given by $a/b\\mapsto{\\big(}a{\\mathrm{~mod~}}p{\\big)}(b{\\mathrm{~mod~}}p)^{-1}$, where $\\pmb{a}$ and $b$ are as above.\n\nThe valuation ring $A$ in this example can be described informally as the largest subring of $\\mathbf{Q}$ on which reduction mod $\\pmb{p}$ makes sense. It is thus the natural ring to introduce if one wants to relate the field $\\mathbf{Q}$ to the field $\\mathbf{F}_{p}$. This illustrates our point of view toward valuations: We will be interested in studying things (namely, matrix groups) defined over a field $K$, and we wish to \u201creduce\u201d to a simpler field $\\pmb{k}$ as an aid in this study; a discrete valuation makes this possible by providing us with a nice ring $A$ to serve as intermediary between $K$ and $\\pmb{k}$.\n\n$$\n\\begin{array}{l l l}{A}&{\\hookrightarrow}&{K}\\\\ {\\downarrow}&{}&{}\\\\ k&{}&{}\\end{array}\n$$\n\nReturning now to the general theory, we note that the study of the arithmetic of $A$ (e.g., ideals and prime factorization) is fairly trivial:\n\nProposition 1. A discrete valuation ring $A$ is a principal ideal domain and every non-zero ideal is generated by $\\pi^{n}$ for some $n\\geq0$. In particular, $\\pi A$ is the unique non-zero prime ideal of $A$.\n\nPROOF: Let $I$ be a non-zero ideal and let $n=\\operatorname*{min}\\{v(a):a\\in I\\}$. Then $I$ contains $\\pi^{n}$, and every element of $I$ is divisible by $\\pi^{n}$; hence $I=\\pi^{n}A$. \u53e3\n\nOne consequence of this is that we can apply the basic facts about modules over a principal ideal domain (e.g., a submodule of a free module is free). Let's recall some of these facts, in the form in which we'll need them later. Let $V$ be the vector space $K^{n}$. By a lattice (or A-lattice) in $V$ we will mean an $A$-submodule $L\\subset V$ of the form $L=A e_{1}\\oplus\\cdot\\cdot\\oplus A e_{n}$ for some basis $\\boldsymbol{e}_{1},\\ldots,\\boldsymbol{e}_{n}$ of $V$. In particular, $L$ is a free $A$-module of rank $\\pmb{n}$. If we take $\\boldsymbol{e}_{1},\\ldots,\\boldsymbol{e}_{n}$ to be the standard basis of $V$, then the resulting lattice is $A^{n}$, which we call the standard lattice.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "One consequence of this is that we can apply the basic facts about modules over a principal ideal domain (e.g., a submodule of a free module is free).",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/SMM_Buildings_By_Kenneth.pdf_136",
        "ID": "0e5bc44c-98de-4bf6-8273-4d1c23d83f22",
        "questions": "What generates a non-zero ideal in a discrete valuation ring $A$ as stated in Proposition 1?",
        "answers": "$\\pi^{n}$",
        "context": "The principal ideal $\\pi A$ generated by $\\pi$ can be described in terms of $\\pmb{v}$ as\n\n$\\{\\,x\\in K:v(x)>0\\,\\}$. It is a maximal ideal, since every element of $A$ not in\n\n$\\pi A$ is a unit. The quotient ring $k=A/\\pi A$ is therefore a field, called the residue field associated to the valuation $\\pmb{v}$.\n\nExample. Let $K$ be the field $\\mathbf{Q}$ of rational numbers, and let $\\pmb{p}$ be a prime number. The $\\pmb{p}$-adic valuation on $\\mathbf{Q}$ is defined by setting $v(x)$ equal to the exponent of $\\pmb{p}$ in the prime factorization of $\\pmb{x}$. More precisely, given $\\pmb{x}\\in\\mathbf{Q}^{*}$ write ${\\pmb x}={\\pmb p}^{n}{\\pmb u}$, where $\\pmb{n}$ is a (possibly negative) integer and $\\pmb{u}$ is a rational number whose numerator and denominator are not divisible by $\\pmb{p}$, then ${\\pmb v}({\\pmb x})=n$. The valuation ring $A$ is the ring of fractions $a/b$ with ${\\pmb a},{\\pmb b}\\in{\\bf Z}$ and $b$ not divisible by $\\pmb{p}$. [The ring $A$ happens to be the localization of $\\mathbf{z}$ at $\\pmb{p}$, but we will not make any use of this.] The residue field $\\pmb{k}$ is the field $\\mathbf{F}_{p}$ of integers mod $p$, one sees this by using the homomorphism $A\\nrightarrow\\mathbf{F}_{p}$ given by $a/b\\mapsto{\\big(}a{\\mathrm{~mod~}}p{\\big)}(b{\\mathrm{~mod~}}p)^{-1}$, where $\\pmb{a}$ and $b$ are as above.\n\nThe valuation ring $A$ in this example can be described informally as the largest subring of $\\mathbf{Q}$ on which reduction mod $\\pmb{p}$ makes sense. It is thus the natural ring to introduce if one wants to relate the field $\\mathbf{Q}$ to the field $\\mathbf{F}_{p}$. This illustrates our point of view toward valuations: We will be interested in studying things (namely, matrix groups) defined over a field $K$, and we wish to \u201creduce\u201d to a simpler field $\\pmb{k}$ as an aid in this study; a discrete valuation makes this possible by providing us with a nice ring $A$ to serve as intermediary between $K$ and $\\pmb{k}$.\n\n$$\n\\begin{array}{l l l}{A}&{\\hookrightarrow}&{K}\\\\ {\\downarrow}&{}&{}\\\\ k&{}&{}\\end{array}\n$$\n\nReturning now to the general theory, we note that the study of the arithmetic of $A$ (e.g., ideals and prime factorization) is fairly trivial:\n\nProposition 1. A discrete valuation ring $A$ is a principal ideal domain and every non-zero ideal is generated by $\\pi^{n}$ for some $n\\geq0$. In particular, $\\pi A$ is the unique non-zero prime ideal of $A$.\n\nPROOF: Let $I$ be a non-zero ideal and let $n=\\operatorname*{min}\\{v(a):a\\in I\\}$. Then $I$ contains $\\pi^{n}$, and every element of $I$ is divisible by $\\pi^{n}$; hence $I=\\pi^{n}A$. \u53e3\n\nOne consequence of this is that we can apply the basic facts about modules over a principal ideal domain (e.g., a submodule of a free module is free). Let's recall some of these facts, in the form in which we'll need them later. Let $V$ be the vector space $K^{n}$. By a lattice (or A-lattice) in $V$ we will mean an $A$-submodule $L\\subset V$ of the form $L=A e_{1}\\oplus\\cdot\\cdot\\oplus A e_{n}$ for some basis $\\boldsymbol{e}_{1},\\ldots,\\boldsymbol{e}_{n}$ of $V$. In particular, $L$ is a free $A$-module of rank $\\pmb{n}$. If we take $\\boldsymbol{e}_{1},\\ldots,\\boldsymbol{e}_{n}$ to be the standard basis of $V$, then the resulting lattice is $A^{n}$, which we call the standard lattice.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "A discrete valuation ring $A$ is a principal ideal domain and every non-zero ideal is generated by $\\pi^{n}$ for some $n \\geq 0$.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/SMM_Buildings_By_Kenneth.pdf_136",
        "ID": "0e6b21f3-213a-486e-b22c-feb1026d44c2",
        "questions": "What is the form of a lattice in the vector space $V=K^{n}$ as described by the document?",
        "answers": "$L=A e_{1} \\\\oplus \\cdot \\cdot \\oplus A e_{n}$",
        "context": "The principal ideal $\\pi A$ generated by $\\pi$ can be described in terms of $\\pmb{v}$ as\n\n$\\{\\,x\\in K:v(x)>0\\,\\}$. It is a maximal ideal, since every element of $A$ not in\n\n$\\pi A$ is a unit. The quotient ring $k=A/\\pi A$ is therefore a field, called the residue field associated to the valuation $\\pmb{v}$.\n\nExample. Let $K$ be the field $\\mathbf{Q}$ of rational numbers, and let $\\pmb{p}$ be a prime number. The $\\pmb{p}$-adic valuation on $\\mathbf{Q}$ is defined by setting $v(x)$ equal to the exponent of $\\pmb{p}$ in the prime factorization of $\\pmb{x}$. More precisely, given $\\pmb{x}\\in\\mathbf{Q}^{*}$ write ${\\pmb x}={\\pmb p}^{n}{\\pmb u}$, where $\\pmb{n}$ is a (possibly negative) integer and $\\pmb{u}$ is a rational number whose numerator and denominator are not divisible by $\\pmb{p}$, then ${\\pmb v}({\\pmb x})=n$. The valuation ring $A$ is the ring of fractions $a/b$ with ${\\pmb a},{\\pmb b}\\in{\\bf Z}$ and $b$ not divisible by $\\pmb{p}$. [The ring $A$ happens to be the localization of $\\mathbf{z}$ at $\\pmb{p}$, but we will not make any use of this.] The residue field $\\pmb{k}$ is the field $\\mathbf{F}_{p}$ of integers mod $p$, one sees this by using the homomorphism $A\\nrightarrow\\mathbf{F}_{p}$ given by $a/b\\mapsto{\\big(}a{\\mathrm{~mod~}}p{\\big)}(b{\\mathrm{~mod~}}p)^{-1}$, where $\\pmb{a}$ and $b$ are as above.\n\nThe valuation ring $A$ in this example can be described informally as the largest subring of $\\mathbf{Q}$ on which reduction mod $\\pmb{p}$ makes sense. It is thus the natural ring to introduce if one wants to relate the field $\\mathbf{Q}$ to the field $\\mathbf{F}_{p}$. This illustrates our point of view toward valuations: We will be interested in studying things (namely, matrix groups) defined over a field $K$, and we wish to \u201creduce\u201d to a simpler field $\\pmb{k}$ as an aid in this study; a discrete valuation makes this possible by providing us with a nice ring $A$ to serve as intermediary between $K$ and $\\pmb{k}$.\n\n$$\n\\begin{array}{l l l}{A}&{\\hookrightarrow}&{K}\\\\ {\\downarrow}&{}&{}\\\\ k&{}&{}\\end{array}\n$$\n\nReturning now to the general theory, we note that the study of the arithmetic of $A$ (e.g., ideals and prime factorization) is fairly trivial:\n\nProposition 1. A discrete valuation ring $A$ is a principal ideal domain and every non-zero ideal is generated by $\\pi^{n}$ for some $n\\geq0$. In particular, $\\pi A$ is the unique non-zero prime ideal of $A$.\n\nPROOF: Let $I$ be a non-zero ideal and let $n=\\operatorname*{min}\\{v(a):a\\in I\\}$. Then $I$ contains $\\pi^{n}$, and every element of $I$ is divisible by $\\pi^{n}$; hence $I=\\pi^{n}A$. \u53e3\n\nOne consequence of this is that we can apply the basic facts about modules over a principal ideal domain (e.g., a submodule of a free module is free). Let's recall some of these facts, in the form in which we'll need them later. Let $V$ be the vector space $K^{n}$. By a lattice (or A-lattice) in $V$ we will mean an $A$-submodule $L\\subset V$ of the form $L=A e_{1}\\oplus\\cdot\\cdot\\oplus A e_{n}$ for some basis $\\boldsymbol{e}_{1},\\ldots,\\boldsymbol{e}_{n}$ of $V$. In particular, $L$ is a free $A$-module of rank $\\pmb{n}$. If we take $\\boldsymbol{e}_{1},\\ldots,\\boldsymbol{e}_{n}$ to be the standard basis of $V$, then the resulting lattice is $A^{n}$, which we call the standard lattice.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "By a lattice (or A-lattice) in $V$ we will mean an $A$-submodule $L\\\\subset V$ of the form $L=A e_{1}\\\\oplus \\cdot \\cdot \\oplus A e_{n}$ for some basis $\\\\boldsymbol{e}_{1},\\\\ldots,\\\\boldsymbol{e}_{n}$ of $V$.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/SMM_Buildings_By_Kenneth.pdf_136",
        "ID": "0e71af64-f01b-4b96-b9b7-7be65968b4b7",
        "questions": "How is the ring $A$ defined in the example when $K$ is the field $\\\\mathbf{Q}$ and $\\\\pmb{p}$ is a prime number?",
        "answers": "The ring of fractions $a/b$ with ${\\\\pmb a},{\\\\pmb b}\\\\in {\\\\bf Z}$ and $b$ not divisible by $\\\\pmb{p}$.",
        "context": "The principal ideal $\\pi A$ generated by $\\pi$ can be described in terms of $\\pmb{v}$ as\n\n$\\{\\,x\\in K:v(x)>0\\,\\}$. It is a maximal ideal, since every element of $A$ not in\n\n$\\pi A$ is a unit. The quotient ring $k=A/\\pi A$ is therefore a field, called the residue field associated to the valuation $\\pmb{v}$.\n\nExample. Let $K$ be the field $\\mathbf{Q}$ of rational numbers, and let $\\pmb{p}$ be a prime number. The $\\pmb{p}$-adic valuation on $\\mathbf{Q}$ is defined by setting $v(x)$ equal to the exponent of $\\pmb{p}$ in the prime factorization of $\\pmb{x}$. More precisely, given $\\pmb{x}\\in\\mathbf{Q}^{*}$ write ${\\pmb x}={\\pmb p}^{n}{\\pmb u}$, where $\\pmb{n}$ is a (possibly negative) integer and $\\pmb{u}$ is a rational number whose numerator and denominator are not divisible by $\\pmb{p}$, then ${\\pmb v}({\\pmb x})=n$. The valuation ring $A$ is the ring of fractions $a/b$ with ${\\pmb a},{\\pmb b}\\in{\\bf Z}$ and $b$ not divisible by $\\pmb{p}$. [The ring $A$ happens to be the localization of $\\mathbf{z}$ at $\\pmb{p}$, but we will not make any use of this.] The residue field $\\pmb{k}$ is the field $\\mathbf{F}_{p}$ of integers mod $p$, one sees this by using the homomorphism $A\\nrightarrow\\mathbf{F}_{p}$ given by $a/b\\mapsto{\\big(}a{\\mathrm{~mod~}}p{\\big)}(b{\\mathrm{~mod~}}p)^{-1}$, where $\\pmb{a}$ and $b$ are as above.\n\nThe valuation ring $A$ in this example can be described informally as the largest subring of $\\mathbf{Q}$ on which reduction mod $\\pmb{p}$ makes sense. It is thus the natural ring to introduce if one wants to relate the field $\\mathbf{Q}$ to the field $\\mathbf{F}_{p}$. This illustrates our point of view toward valuations: We will be interested in studying things (namely, matrix groups) defined over a field $K$, and we wish to \u201creduce\u201d to a simpler field $\\pmb{k}$ as an aid in this study; a discrete valuation makes this possible by providing us with a nice ring $A$ to serve as intermediary between $K$ and $\\pmb{k}$.\n\n$$\n\\begin{array}{l l l}{A}&{\\hookrightarrow}&{K}\\\\ {\\downarrow}&{}&{}\\\\ k&{}&{}\\end{array}\n$$\n\nReturning now to the general theory, we note that the study of the arithmetic of $A$ (e.g., ideals and prime factorization) is fairly trivial:\n\nProposition 1. A discrete valuation ring $A$ is a principal ideal domain and every non-zero ideal is generated by $\\pi^{n}$ for some $n\\geq0$. In particular, $\\pi A$ is the unique non-zero prime ideal of $A$.\n\nPROOF: Let $I$ be a non-zero ideal and let $n=\\operatorname*{min}\\{v(a):a\\in I\\}$. Then $I$ contains $\\pi^{n}$, and every element of $I$ is divisible by $\\pi^{n}$; hence $I=\\pi^{n}A$. \u53e3\n\nOne consequence of this is that we can apply the basic facts about modules over a principal ideal domain (e.g., a submodule of a free module is free). Let's recall some of these facts, in the form in which we'll need them later. Let $V$ be the vector space $K^{n}$. By a lattice (or A-lattice) in $V$ we will mean an $A$-submodule $L\\subset V$ of the form $L=A e_{1}\\oplus\\cdot\\cdot\\oplus A e_{n}$ for some basis $\\boldsymbol{e}_{1},\\ldots,\\boldsymbol{e}_{n}$ of $V$. In particular, $L$ is a free $A$-module of rank $\\pmb{n}$. If we take $\\boldsymbol{e}_{1},\\ldots,\\boldsymbol{e}_{n}$ to be the standard basis of $V$, then the resulting lattice is $A^{n}$, which we call the standard lattice.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "The valuation ring $A$ is the ring of fractions $a/b$ with ${\\\\pmb a},{\\\\pmb b}\\\\in {\\\\bf Z}$ and $b$ not divisible by $\\\\pmb{p}$. [The ring $A$ happens to be the localization of $\\\\mathbf{z}$ at $\\\\pmb{p}$, but we will not make any use of this.]",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/8b80f49ec2822cb3cdbe97d9405e39ae40ba418b084c06604b51e2a5af11a7f8.pdf_11",
        "ID": "0e75601d-3e14-472e-85c6-554712c8431d",
        "questions": "In the genomic regions analyzed, which Drosophila species shows the highest frequency of 13-mers?",
        "answers": "D. mojavensis",
        "context": "![](images/b36bffa5ef8fb92d6e0e0e5970366a32319f23aac0cac3763f1b18d971e587db.jpg)\nFigure 4 Distributions of 13-mers and dinucleotide repeats in the regions analyzed. (A) Consistent with the Window Masker results, more 13-mers are found to be repeated (present at a higher frequency) on the D. mojavensis F element (dark blue line) than the other analysis regions. The genomic sequence in each analysis region is partitioned into overlapping 13-mers and the frequency of each 13-mer is tabulated using Tallymer. The values on the x-axis correspond to the number of times that a particular 13-mer is found in the analysis region, whereas the y-axis corresponds to the total number of 13-mers (of all sequences) that appear at each frequency. For example, approximately $10^{6}$ 13-mers appear only once in each analysis region. (B) Cumulative dinucleotide repeats analysis shows a higher frequency of dinucleotide repeats on the D. mojavensis and D. grimshawi F elements (dark blue and purple lines, respectively) than on the D. melanogaster and D. erecta F elements (dark red and orange lines, respectively). A pseudocount of one has been added to the cumulative distribution plots in order to show a continuous distribution in the semi-log plot.\n\ncandidate is shown in Figure S5. (See File S1 for a more detailed description of this analysis.)  \n\nOverall repeat distribution on the F element: Collectively, the repeat analysis shows the F elements have a higher repeat density than the euchromatic reference regions in all four Drosophila species. It also shows that although the D. mojavensis and D. grimshawi F elements have similar total repeat densities, they have strikingly different repeat compositions. A total of $75\\%$ of the repeats that overlap with a repeat identified by WindowMasker on the D. mojavensis F element are transposons (particularly DINE-1 elements) compared to only $27\\%$ on the D. grimshawi F element, whereas the D. grimshawi F element shows a greater density of simple and low complexity repeats than the D. mojavensis F element $39\\%$ vs. $20\\%$ These differences in repeat composition could impact the local chromatin structure and thus the evolution of the resident genes.  \n\n# Evolution of F element genes  \n\nDespite its high repeat density, the distal arm of the D. melanogaster F element contains 79 genes, many of which have important developmental and housekeeping functions (Riddle et al. 2012). Our manual gene annotations (described previously) show that the D. melanogaster, D. erecta, D. mojavensis, and D. grimshawi F elements all have approximately 80 genes. The gene density of the F element is lower than that of the euchromatic reference regions from the D element ($\\sim$60 genes/Mb vs. $\\sim$80 genes/Mb) for these four species (Table S6). Among the four species, the D. mojavensis F element has the lowest gene density (48 genes/Mb compared with 60-66 genes/Mb in the other F elements). This reflects the increased size of the D. mojavensis F element due to the expansion of repetitious elements (1.7 Mb vs. 1.2-1.3 Mb in the other F elements) (Table S6 and Figure 3).  \n\nAlthough we have produced annotations for all isoforms, our analysis below is based only on the isoform with the largest coding region (i.e., the most comprehensive isoform) for each gene. Restricting our analysis to the most comprehensive isoform allows us to avoid counting the same region multiple times because of alternative splicing. We initially examined genes at the base, extended, and telomeric regions (described previously) of the D. erecta D element. Since the genes in these three euchromatic regions exhibit similar characteristics, the primary focus of the following analysis is on the comparison of genes between the F element and the base of the D element (results for all of the analysis regions are available in Figure S6). Summary statistics for all of the gene characteristics, and results of multiple comparison tests after the Kruskal-Wallis (KW) rank sum tests (Kruskal and Wallis 1952), are available in File S6.  \n\nF element genes are larger because they have larger introns and more coding exons: Comparisons of the distribution of gene characteristics using violin plots (Hintze and Nelson 1998) show that the coding span (i.e., the region that spans from the start codon to the stop codon, including introns) for F element genes is much larger (median 5156-7569 bp) than for genes at the base of the D elements (median 1028-1736 bp) (Figure 5, top left). The KW test shows that this difference is statistically significant (p-value: 2.12E-48).  \n\nPart of this difference in the coding span can be attributed to the significantly higher transposon density (KW test p-value: 2.40E-82) within the introns of F element genes (Figure 5, top center; \u201crepeat size is the total size of the transposon fragments within the introns of a gene, in bp). Among the four species analyzed in this study, $71\u201383\\%$ of the F element genes contain at least one transposon fragment in an intron. In contrast, only $20\u201346\\%$ of the D element genes contain at least one transposon fragment. Consistent with the results of the",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "more 13-mers are found to be repeated (present at a higher frequency) on the D. mojavensis F element (dark blue line) than the other analysis regions.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/8b80f49ec2822cb3cdbe97d9405e39ae40ba418b084c06604b51e2a5af11a7f8.pdf_11",
        "ID": "0e7cd3cf-9067-4465-a98b-bb3ae69fc01b",
        "questions": "What is the gene density of the D. mojavensis F element?",
        "answers": "48 genes/Mb",
        "context": "![](images/b36bffa5ef8fb92d6e0e0e5970366a32319f23aac0cac3763f1b18d971e587db.jpg)\nFigure 4 Distributions of 13-mers and dinucleotide repeats in the regions analyzed. (A) Consistent with the Window Masker results, more 13-mers are found to be repeated (present at a higher frequency) on the D. mojavensis F element (dark blue line) than the other analysis regions. The genomic sequence in each analysis region is partitioned into overlapping 13-mers and the frequency of each 13-mer is tabulated using Tallymer. The values on the x-axis correspond to the number of times that a particular 13-mer is found in the analysis region, whereas the y-axis corresponds to the total number of 13-mers (of all sequences) that appear at each frequency. For example, approximately $10^{6}$ 13-mers appear only once in each analysis region. (B) Cumulative dinucleotide repeats analysis shows a higher frequency of dinucleotide repeats on the D. mojavensis and D. grimshawi F elements (dark blue and purple lines, respectively) than on the D. melanogaster and D. erecta F elements (dark red and orange lines, respectively). A pseudocount of one has been added to the cumulative distribution plots in order to show a continuous distribution in the semi-log plot.\n\ncandidate is shown in Figure S5. (See File S1 for a more detailed description of this analysis.)  \n\nOverall repeat distribution on the F element: Collectively, the repeat analysis shows the F elements have a higher repeat density than the euchromatic reference regions in all four Drosophila species. It also shows that although the D. mojavensis and D. grimshawi F elements have similar total repeat densities, they have strikingly different repeat compositions. A total of $75\\%$ of the repeats that overlap with a repeat identified by WindowMasker on the D. mojavensis F element are transposons (particularly DINE-1 elements) compared to only $27\\%$ on the D. grimshawi F element, whereas the D. grimshawi F element shows a greater density of simple and low complexity repeats than the D. mojavensis F element $39\\%$ vs. $20\\%$ These differences in repeat composition could impact the local chromatin structure and thus the evolution of the resident genes.  \n\n# Evolution of F element genes  \n\nDespite its high repeat density, the distal arm of the D. melanogaster F element contains 79 genes, many of which have important developmental and housekeeping functions (Riddle et al. 2012). Our manual gene annotations (described previously) show that the D. melanogaster, D. erecta, D. mojavensis, and D. grimshawi F elements all have approximately 80 genes. The gene density of the F element is lower than that of the euchromatic reference regions from the D element ($\\sim$60 genes/Mb vs. $\\sim$80 genes/Mb) for these four species (Table S6). Among the four species, the D. mojavensis F element has the lowest gene density (48 genes/Mb compared with 60-66 genes/Mb in the other F elements). This reflects the increased size of the D. mojavensis F element due to the expansion of repetitious elements (1.7 Mb vs. 1.2-1.3 Mb in the other F elements) (Table S6 and Figure 3).  \n\nAlthough we have produced annotations for all isoforms, our analysis below is based only on the isoform with the largest coding region (i.e., the most comprehensive isoform) for each gene. Restricting our analysis to the most comprehensive isoform allows us to avoid counting the same region multiple times because of alternative splicing. We initially examined genes at the base, extended, and telomeric regions (described previously) of the D. erecta D element. Since the genes in these three euchromatic regions exhibit similar characteristics, the primary focus of the following analysis is on the comparison of genes between the F element and the base of the D element (results for all of the analysis regions are available in Figure S6). Summary statistics for all of the gene characteristics, and results of multiple comparison tests after the Kruskal-Wallis (KW) rank sum tests (Kruskal and Wallis 1952), are available in File S6.  \n\nF element genes are larger because they have larger introns and more coding exons: Comparisons of the distribution of gene characteristics using violin plots (Hintze and Nelson 1998) show that the coding span (i.e., the region that spans from the start codon to the stop codon, including introns) for F element genes is much larger (median 5156-7569 bp) than for genes at the base of the D elements (median 1028-1736 bp) (Figure 5, top left). The KW test shows that this difference is statistically significant (p-value: 2.12E-48).  \n\nPart of this difference in the coding span can be attributed to the significantly higher transposon density (KW test p-value: 2.40E-82) within the introns of F element genes (Figure 5, top center; \u201crepeat size is the total size of the transposon fragments within the introns of a gene, in bp). Among the four species analyzed in this study, $71\u201383\\%$ of the F element genes contain at least one transposon fragment in an intron. In contrast, only $20\u201346\\%$ of the D element genes contain at least one transposon fragment. Consistent with the results of the",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Among the four species, the D. mojavensis F element has the lowest gene density (48 genes/Mb compared with 60-66 genes/Mb in the other F elements).",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/8b80f49ec2822cb3cdbe97d9405e39ae40ba418b084c06604b51e2a5af11a7f8.pdf_11",
        "ID": "0e831ee8-51b1-47c5-a814-4468fa588902",
        "questions": "What percentage of repeats overlapped with WindowMasker on the D. mojavensis F element are transposons?",
        "answers": "75%",
        "context": "![](images/b36bffa5ef8fb92d6e0e0e5970366a32319f23aac0cac3763f1b18d971e587db.jpg)\nFigure 4 Distributions of 13-mers and dinucleotide repeats in the regions analyzed. (A) Consistent with the Window Masker results, more 13-mers are found to be repeated (present at a higher frequency) on the D. mojavensis F element (dark blue line) than the other analysis regions. The genomic sequence in each analysis region is partitioned into overlapping 13-mers and the frequency of each 13-mer is tabulated using Tallymer. The values on the x-axis correspond to the number of times that a particular 13-mer is found in the analysis region, whereas the y-axis corresponds to the total number of 13-mers (of all sequences) that appear at each frequency. For example, approximately $10^{6}$ 13-mers appear only once in each analysis region. (B) Cumulative dinucleotide repeats analysis shows a higher frequency of dinucleotide repeats on the D. mojavensis and D. grimshawi F elements (dark blue and purple lines, respectively) than on the D. melanogaster and D. erecta F elements (dark red and orange lines, respectively). A pseudocount of one has been added to the cumulative distribution plots in order to show a continuous distribution in the semi-log plot.\n\ncandidate is shown in Figure S5. (See File S1 for a more detailed description of this analysis.)  \n\nOverall repeat distribution on the F element: Collectively, the repeat analysis shows the F elements have a higher repeat density than the euchromatic reference regions in all four Drosophila species. It also shows that although the D. mojavensis and D. grimshawi F elements have similar total repeat densities, they have strikingly different repeat compositions. A total of $75\\%$ of the repeats that overlap with a repeat identified by WindowMasker on the D. mojavensis F element are transposons (particularly DINE-1 elements) compared to only $27\\%$ on the D. grimshawi F element, whereas the D. grimshawi F element shows a greater density of simple and low complexity repeats than the D. mojavensis F element $39\\%$ vs. $20\\%$ These differences in repeat composition could impact the local chromatin structure and thus the evolution of the resident genes.  \n\n# Evolution of F element genes  \n\nDespite its high repeat density, the distal arm of the D. melanogaster F element contains 79 genes, many of which have important developmental and housekeeping functions (Riddle et al. 2012). Our manual gene annotations (described previously) show that the D. melanogaster, D. erecta, D. mojavensis, and D. grimshawi F elements all have approximately 80 genes. The gene density of the F element is lower than that of the euchromatic reference regions from the D element ($\\sim$60 genes/Mb vs. $\\sim$80 genes/Mb) for these four species (Table S6). Among the four species, the D. mojavensis F element has the lowest gene density (48 genes/Mb compared with 60-66 genes/Mb in the other F elements). This reflects the increased size of the D. mojavensis F element due to the expansion of repetitious elements (1.7 Mb vs. 1.2-1.3 Mb in the other F elements) (Table S6 and Figure 3).  \n\nAlthough we have produced annotations for all isoforms, our analysis below is based only on the isoform with the largest coding region (i.e., the most comprehensive isoform) for each gene. Restricting our analysis to the most comprehensive isoform allows us to avoid counting the same region multiple times because of alternative splicing. We initially examined genes at the base, extended, and telomeric regions (described previously) of the D. erecta D element. Since the genes in these three euchromatic regions exhibit similar characteristics, the primary focus of the following analysis is on the comparison of genes between the F element and the base of the D element (results for all of the analysis regions are available in Figure S6). Summary statistics for all of the gene characteristics, and results of multiple comparison tests after the Kruskal-Wallis (KW) rank sum tests (Kruskal and Wallis 1952), are available in File S6.  \n\nF element genes are larger because they have larger introns and more coding exons: Comparisons of the distribution of gene characteristics using violin plots (Hintze and Nelson 1998) show that the coding span (i.e., the region that spans from the start codon to the stop codon, including introns) for F element genes is much larger (median 5156-7569 bp) than for genes at the base of the D elements (median 1028-1736 bp) (Figure 5, top left). The KW test shows that this difference is statistically significant (p-value: 2.12E-48).  \n\nPart of this difference in the coding span can be attributed to the significantly higher transposon density (KW test p-value: 2.40E-82) within the introns of F element genes (Figure 5, top center; \u201crepeat size is the total size of the transposon fragments within the introns of a gene, in bp). Among the four species analyzed in this study, $71\u201383\\%$ of the F element genes contain at least one transposon fragment in an intron. In contrast, only $20\u201346\\%$ of the D element genes contain at least one transposon fragment. Consistent with the results of the",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Numeric",
        "evidence_source": "equation",
        "evidence_context": "A total of $75\\%$ of the repeats that overlap with a repeat identified by WindowMasker on the D. mojavensis F element are transposons (particularly DINE-1 elements)",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/24fd7e2735af185459f293eb8704789722c8e46ef86c880322577fe019bb829c.pdf_99",
        "ID": "0e8472a7-dd33-4379-a88f-58c1237d7b90",
        "questions": "What are the first steps to ensure a patient's environment is properly set up at Grand Valley State University?",
        "answers": "Ensures call light is within reach, tray table is close/appropriate height, water-cup is full, arranges cards on shelf",
        "context": "# GRAND VALLEY STATE UNIVERSITY  \n\n$\n \\begin{tabular}{|ll|}{ } & Ensures call light is within reach, ray table is close/appropriate height, water-cup is full, arranges cards on shelf\\\\& Orientation board\\\\& Updates orientation board with missing items: Name and date\\\\& One on One time\\\\&Pulls up chair is it bedside, communicates clearly with reviewing schedule with patient\\\\&Listens to patient and how they are doing\\\\& Current events\\\\&Reads a headline in the newspaper and issues actively\\\\& Menu assist\\\\&Assist patient with opening the menu and reviewing options for lunch that they would like to order\\\\& Model environment\\\\&Sit patient weight (if needed)\\\\& Adjust try table. Tray is delivered by staff\\\\&Drape napkin across chess\\\\& Partial med assist\\\\&Allow patient to feed themselves after getting the food onto the spoon - offer $\\frac{1}{2}$ spoonful at a time, offer frequent liquids\\\\&*Give two bins/ons sp of water\\\\& End of med\\\\&Assist with wiping hands/mouth when completed\\\\& Prior to mobility\\\\&Ensure walking aid and non-skid footwear are in place\\\\&Clear obstacles\\\\&Place gait belt on, ensure walker is in from of patient, verbal coaching:\\\\& Get out of bed\\\\&Lan forward, push on hands, push feet on floor\\\\&Ensure patient is standing fully upright and assess balance before walking. \\\\&Assist with walking to bed while holding gait belt, follow to one side and never leave\\\\&*Walk to door and back to bed\\\\&Assist to bed\\\\&Stand patient near the head of the bed with the back of legs touching the bed.\\\\&Have the patient reach back to the bed, bed at the waist and lower themselves down. Scoot to center of bed\\\\&Push with feet to lift into bed, ensure the patient is comfortable, replace overs, put side rails up ($\\frac{3}{4}$) and ensure the call bell is within reach.\\\\&Relaxation/sleep enhancement\\\\&Assist with relaxation: music, relaxation script, breathing exercises, body relaxation points, visualization, float in space, wake each body point\\\\&Offer bathroom, warm milk/herbal tea, music, backrub\\  \\end{tabular}\n$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Ensures call light is within reach, tray table is close/appropriate height, water-cup is full, arranges cards on shelf",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/24fd7e2735af185459f293eb8704789722c8e46ef86c880322577fe019bb829c.pdf_99",
        "ID": "0e935f4e-83ed-484f-bb35-2b98cfe87700",
        "questions": "What should be done after a patient completes their meal at Grand Valley State University?",
        "answers": "Assist with wiping hands/mouth when completed",
        "context": "# GRAND VALLEY STATE UNIVERSITY  \n\n$\n \\begin{tabular}{|ll|}{ } & Ensures call light is within reach, ray table is close/appropriate height, water-cup is full, arranges cards on shelf\\\\& Orientation board\\\\& Updates orientation board with missing items: Name and date\\\\& One on One time\\\\&Pulls up chair is it bedside, communicates clearly with reviewing schedule with patient\\\\&Listens to patient and how they are doing\\\\& Current events\\\\&Reads a headline in the newspaper and issues actively\\\\& Menu assist\\\\&Assist patient with opening the menu and reviewing options for lunch that they would like to order\\\\& Model environment\\\\&Sit patient weight (if needed)\\\\& Adjust try table. Tray is delivered by staff\\\\&Drape napkin across chess\\\\& Partial med assist\\\\&Allow patient to feed themselves after getting the food onto the spoon - offer $\\frac{1}{2}$ spoonful at a time, offer frequent liquids\\\\&*Give two bins/ons sp of water\\\\& End of med\\\\&Assist with wiping hands/mouth when completed\\\\& Prior to mobility\\\\&Ensure walking aid and non-skid footwear are in place\\\\&Clear obstacles\\\\&Place gait belt on, ensure walker is in from of patient, verbal coaching:\\\\& Get out of bed\\\\&Lan forward, push on hands, push feet on floor\\\\&Ensure patient is standing fully upright and assess balance before walking. \\\\&Assist with walking to bed while holding gait belt, follow to one side and never leave\\\\&*Walk to door and back to bed\\\\&Assist to bed\\\\&Stand patient near the head of the bed with the back of legs touching the bed.\\\\&Have the patient reach back to the bed, bed at the waist and lower themselves down. Scoot to center of bed\\\\&Push with feet to lift into bed, ensure the patient is comfortable, replace overs, put side rails up ($\\frac{3}{4}$) and ensure the call bell is within reach.\\\\&Relaxation/sleep enhancement\\\\&Assist with relaxation: music, relaxation script, breathing exercises, body relaxation points, visualization, float in space, wake each body point\\\\&Offer bathroom, warm milk/herbal tea, music, backrub\\  \\end{tabular}\n$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Assist with wiping hands/mouth when completed",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/24fd7e2735af185459f293eb8704789722c8e46ef86c880322577fe019bb829c.pdf_99",
        "ID": "0ea39958-fe3b-44f9-89c9-5e12141c7bda",
        "questions": "What activities are included in assisting a patient with relaxation and sleep enhancement at Grand Valley State University?",
        "answers": "Assist with relaxation: music, relaxation script, breathing exercises, body relaxation points, visualization, float in space, wake each body point; Offer bathroom, warm milk/herbal tea, music, backrub",
        "context": "# GRAND VALLEY STATE UNIVERSITY  \n\n$\n \\begin{tabular}{|ll|}{ } & Ensures call light is within reach, ray table is close/appropriate height, water-cup is full, arranges cards on shelf\\\\& Orientation board\\\\& Updates orientation board with missing items: Name and date\\\\& One on One time\\\\&Pulls up chair is it bedside, communicates clearly with reviewing schedule with patient\\\\&Listens to patient and how they are doing\\\\& Current events\\\\&Reads a headline in the newspaper and issues actively\\\\& Menu assist\\\\&Assist patient with opening the menu and reviewing options for lunch that they would like to order\\\\& Model environment\\\\&Sit patient weight (if needed)\\\\& Adjust try table. Tray is delivered by staff\\\\&Drape napkin across chess\\\\& Partial med assist\\\\&Allow patient to feed themselves after getting the food onto the spoon - offer $\\frac{1}{2}$ spoonful at a time, offer frequent liquids\\\\&*Give two bins/ons sp of water\\\\& End of med\\\\&Assist with wiping hands/mouth when completed\\\\& Prior to mobility\\\\&Ensure walking aid and non-skid footwear are in place\\\\&Clear obstacles\\\\&Place gait belt on, ensure walker is in from of patient, verbal coaching:\\\\& Get out of bed\\\\&Lan forward, push on hands, push feet on floor\\\\&Ensure patient is standing fully upright and assess balance before walking. \\\\&Assist with walking to bed while holding gait belt, follow to one side and never leave\\\\&*Walk to door and back to bed\\\\&Assist to bed\\\\&Stand patient near the head of the bed with the back of legs touching the bed.\\\\&Have the patient reach back to the bed, bed at the waist and lower themselves down. Scoot to center of bed\\\\&Push with feet to lift into bed, ensure the patient is comfortable, replace overs, put side rails up ($\\frac{3}{4}$) and ensure the call bell is within reach.\\\\&Relaxation/sleep enhancement\\\\&Assist with relaxation: music, relaxation script, breathing exercises, body relaxation points, visualization, float in space, wake each body point\\\\&Offer bathroom, warm milk/herbal tea, music, backrub\\  \\end{tabular}\n$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Assist with relaxation: music, relaxation script, breathing exercises, body relaxation points, visualization, float in space, wake each body point; Offer bathroom, warm milk/herbal tea, music, backrub",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/textbook_needrop_en_569",
        "ID": "0ea7150e-5115-49b1-ac56-0538c497b5a1",
        "questions": "What are the expressions for the parallel equivalent capacitance and inductance in the given circuit?",
        "answers": "C = C1 + C2; L = L1L2 / (L1 + L2)",
        "context": "$$\n\\begin{array}{l}{\\displaystyle\\left\\{\\overline{{Y}}=\\frac{1}{R}+\\frac{1}{L_{1}\\cdot\\omega\\cdot j}+\\frac{1}{L_{2}\\cdot\\omega\\cdot j}-\\frac{C_{1}\\cdot\\omega}{j}-\\frac{C_{2}\\cdot\\omega}{j}\\right.}\\\\ {\\displaystyle\\left.\\overline{{Y}}=\\frac{1}{R}+j\\cdot\\left[(C_{1}+C_{2})-\\left(\\frac{1}{L_{1}}+\\frac{1}{L_{2}}\\right)\\right]\\right.}\\end{array}\n$$  \n\nThe circuit behaves as if it has a parallel equivalent capacity \\( C \\)  \n\n$$\n\\mathsf{C}=\\mathsf{C}_{1}+\\mathsf{C}_{2}\n$$  \n\nand a parallel equivalent inductance \\( L \\)  \n\n$$\n\\begin{array}{l}{\\displaystyle\\left\\{\\frac{1}{L}=\\frac{1}{L_{1}}+\\frac{1}{L_{2}}\\right.}\\\\ {\\displaystyle\\left.L=\\frac{L_{1}L_{2}}{L_{1}+L_{2}}\\right.}\\end{array}\n$$  \n\nThe complex admittance of the circuit may be written as  \n\n$$\n\\overline{{\\mathsf{Y}}}=\\frac{1}{R}\\!+\\!j\\cdot\\!\\left(C\\cdot\\omega\\!-\\!\\frac{1}{L\\!\\cdot\\!\\omega}\\right)\n$$  \n\nand the complex impedance of the circuit will be  \n\n$$\n\\left\\{\\begin{array}{l l}{\\overline{{Z}}\\!=\\!\\displaystyle\\frac{1}{\\overline{{Y}}}}\\\\ {\\overline{{Z}}\\!=\\!\\displaystyle\\frac{\\displaystyle\\frac{1}{R}\\!+\\!j\\!\\cdot\\!\\left(\\displaystyle\\frac{1}{L\\!\\cdot\\!\\omega}\\!-\\!C\\!\\cdot\\!\\omega\\right)}{\\sqrt{\\left(\\displaystyle\\frac{1}{R}\\right)^{2}+\\left(C\\!\\cdot\\!\\omega\\!-\\!\\displaystyle\\frac{1}{L\\!\\cdot\\!\\omega}\\right)^{2}}}}\\end{array}\\right.\n$$  \n\nThe impedance \\( Z \\) of the circuit, the inverse of the admittance of the circuit \\( Y \\), is the modulus of the complex impedance \\( Z \\)  \n\n$$\nZ\\!=\\!\\overline{{{\\cal\\overline{{{Z}}}}}}\\!=\\!\\frac{1}{\\sqrt{\\!\\left(\\displaystyle\\frac{1}{R}\\right)^{2}\\!+\\!\\left(C\\!\\cdot\\!\\omega\\!-\\!\\displaystyle\\frac{1}{L\\!\\cdot\\!\\omega}\\right)^{2}}}\\!=\\!\\frac{1}{\\sf Y}\n$$  \n\nThe constant current source supplying the circuit furnishes a current having a momentary value \\( i(t) \\)  \n\n$$\n\\dot{\\cal I}(t)\\!=\\!{\\cal I}\\!\\cdot\\!\\sqrt{2}\\cdot\\!\\sin\\!\\big(\\omega\\!\\cdot\\!t\\big),\n$$  \n\nwhere \\( I \\) is the effective intensity (constant), of the current and \\( \\omega \\) is the current pulsation (that can vary). The potential difference at the jacks of the circuit has the momentary value \\( u(t) \\)  \n\n$$\nu(t)\\!=\\!U\\!\\cdot\\!\\sqrt{2}\\cdot\\!\\sin\\!\\left(\\omega\\!\\cdot\\!t+\\varphi\\right)\n$$  \n\nwhere \\( U \\) is the effective value of the tension and \\( \\varphi \\) is the phase difference between tension and current.  \n\nThe effective values of the current and tension obey the relation",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "The circuit behaves as if it has a parallel equivalent capacity C: C = C1 + C2, and a parallel equivalent inductance L: L = L1L2 / (L1 + L2).",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/textbook_needrop_en_569",
        "ID": "0ea8ea20-8b8e-4c1f-b540-49d682ba7396",
        "questions": "How is the complex impedance of the circuit expressed in terms of the complex admittance?",
        "answers": "The complex impedance of the circuit will be \\( \\overline{Z} = \\left\\( \\frac{\\frac{1}{R} + j \\cdot \\left( \\frac{1}{L \\cdot \\omega} - C \\cdot \\omega \\right)}{\\sqrt{\\left( \\frac{1}{R}\\right)^{2} + \\left( C \\cdot \\omega - \\frac{1}{L \\cdot \\omega} \\right)^{2}}} \\right\\) \\)",
        "context": "$$\n\\begin{array}{l}{\\displaystyle\\left\\{\\overline{{Y}}=\\frac{1}{R}+\\frac{1}{L_{1}\\cdot\\omega\\cdot j}+\\frac{1}{L_{2}\\cdot\\omega\\cdot j}-\\frac{C_{1}\\cdot\\omega}{j}-\\frac{C_{2}\\cdot\\omega}{j}\\right.}\\\\ {\\displaystyle\\left.\\overline{{Y}}=\\frac{1}{R}+j\\cdot\\left[(C_{1}+C_{2})-\\left(\\frac{1}{L_{1}}+\\frac{1}{L_{2}}\\right)\\right]\\right.}\\end{array}\n$$  \n\nThe circuit behaves as if it has a parallel equivalent capacity \\( C \\)  \n\n$$\n\\mathsf{C}=\\mathsf{C}_{1}+\\mathsf{C}_{2}\n$$  \n\nand a parallel equivalent inductance \\( L \\)  \n\n$$\n\\begin{array}{l}{\\displaystyle\\left\\{\\frac{1}{L}=\\frac{1}{L_{1}}+\\frac{1}{L_{2}}\\right.}\\\\ {\\displaystyle\\left.L=\\frac{L_{1}L_{2}}{L_{1}+L_{2}}\\right.}\\end{array}\n$$  \n\nThe complex admittance of the circuit may be written as  \n\n$$\n\\overline{{\\mathsf{Y}}}=\\frac{1}{R}\\!+\\!j\\cdot\\!\\left(C\\cdot\\omega\\!-\\!\\frac{1}{L\\!\\cdot\\!\\omega}\\right)\n$$  \n\nand the complex impedance of the circuit will be  \n\n$$\n\\left\\{\\begin{array}{l l}{\\overline{{Z}}\\!=\\!\\displaystyle\\frac{1}{\\overline{{Y}}}}\\\\ {\\overline{{Z}}\\!=\\!\\displaystyle\\frac{\\displaystyle\\frac{1}{R}\\!+\\!j\\!\\cdot\\!\\left(\\displaystyle\\frac{1}{L\\!\\cdot\\!\\omega}\\!-\\!C\\!\\cdot\\!\\omega\\right)}{\\sqrt{\\left(\\displaystyle\\frac{1}{R}\\right)^{2}+\\left(C\\!\\cdot\\!\\omega\\!-\\!\\displaystyle\\frac{1}{L\\!\\cdot\\!\\omega}\\right)^{2}}}}\\end{array}\\right.\n$$  \n\nThe impedance \\( Z \\) of the circuit, the inverse of the admittance of the circuit \\( Y \\), is the modulus of the complex impedance \\( Z \\)  \n\n$$\nZ\\!=\\!\\overline{{{\\cal\\overline{{{Z}}}}}}\\!=\\!\\frac{1}{\\sqrt{\\!\\left(\\displaystyle\\frac{1}{R}\\right)^{2}\\!+\\!\\left(C\\!\\cdot\\!\\omega\\!-\\!\\displaystyle\\frac{1}{L\\!\\cdot\\!\\omega}\\right)^{2}}}\\!=\\!\\frac{1}{\\sf Y}\n$$  \n\nThe constant current source supplying the circuit furnishes a current having a momentary value \\( i(t) \\)  \n\n$$\n\\dot{\\cal I}(t)\\!=\\!{\\cal I}\\!\\cdot\\!\\sqrt{2}\\cdot\\!\\sin\\!\\big(\\omega\\!\\cdot\\!t\\big),\n$$  \n\nwhere \\( I \\) is the effective intensity (constant), of the current and \\( \\omega \\) is the current pulsation (that can vary). The potential difference at the jacks of the circuit has the momentary value \\( u(t) \\)  \n\n$$\nu(t)\\!=\\!U\\!\\cdot\\!\\sqrt{2}\\cdot\\!\\sin\\!\\left(\\omega\\!\\cdot\\!t+\\varphi\\right)\n$$  \n\nwhere \\( U \\) is the effective value of the tension and \\( \\varphi \\) is the phase difference between tension and current.  \n\nThe effective values of the current and tension obey the relation",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "The complex impedance of the circuit will be \\( \\overline{Z} = \\left\\( \\frac{\\frac{1}{R} + j \\cdot \\left( \\frac{1}{L \\cdot \\omega} - C \\cdot \\omega \\right)}{\\sqrt{\\left( \\frac{1}{R}\\right)^{2} + \\left( C \\cdot \\omega - \\frac{1}{L \\cdot \\omega} \\right)^{2}}} \\right\\) \\).",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/textbook_needrop_en_569",
        "ID": "0eb23a8c-6de8-422d-b610-7a8789cd4710",
        "questions": "What is the formula for the effective momentary current supplied by the constant current source in the circuit, and how is it expressed as a function of time?",
        "answers": "i(t) = I * sqrt(2) * sin(omega * t)",
        "context": "$$\n\\begin{array}{l}{\\displaystyle\\left\\{\\overline{{Y}}=\\frac{1}{R}+\\frac{1}{L_{1}\\cdot\\omega\\cdot j}+\\frac{1}{L_{2}\\cdot\\omega\\cdot j}-\\frac{C_{1}\\cdot\\omega}{j}-\\frac{C_{2}\\cdot\\omega}{j}\\right.}\\\\ {\\displaystyle\\left.\\overline{{Y}}=\\frac{1}{R}+j\\cdot\\left[(C_{1}+C_{2})-\\left(\\frac{1}{L_{1}}+\\frac{1}{L_{2}}\\right)\\right]\\right.}\\end{array}\n$$  \n\nThe circuit behaves as if it has a parallel equivalent capacity \\( C \\)  \n\n$$\n\\mathsf{C}=\\mathsf{C}_{1}+\\mathsf{C}_{2}\n$$  \n\nand a parallel equivalent inductance \\( L \\)  \n\n$$\n\\begin{array}{l}{\\displaystyle\\left\\{\\frac{1}{L}=\\frac{1}{L_{1}}+\\frac{1}{L_{2}}\\right.}\\\\ {\\displaystyle\\left.L=\\frac{L_{1}L_{2}}{L_{1}+L_{2}}\\right.}\\end{array}\n$$  \n\nThe complex admittance of the circuit may be written as  \n\n$$\n\\overline{{\\mathsf{Y}}}=\\frac{1}{R}\\!+\\!j\\cdot\\!\\left(C\\cdot\\omega\\!-\\!\\frac{1}{L\\!\\cdot\\!\\omega}\\right)\n$$  \n\nand the complex impedance of the circuit will be  \n\n$$\n\\left\\{\\begin{array}{l l}{\\overline{{Z}}\\!=\\!\\displaystyle\\frac{1}{\\overline{{Y}}}}\\\\ {\\overline{{Z}}\\!=\\!\\displaystyle\\frac{\\displaystyle\\frac{1}{R}\\!+\\!j\\!\\cdot\\!\\left(\\displaystyle\\frac{1}{L\\!\\cdot\\!\\omega}\\!-\\!C\\!\\cdot\\!\\omega\\right)}{\\sqrt{\\left(\\displaystyle\\frac{1}{R}\\right)^{2}+\\left(C\\!\\cdot\\!\\omega\\!-\\!\\displaystyle\\frac{1}{L\\!\\cdot\\!\\omega}\\right)^{2}}}}\\end{array}\\right.\n$$  \n\nThe impedance \\( Z \\) of the circuit, the inverse of the admittance of the circuit \\( Y \\), is the modulus of the complex impedance \\( Z \\)  \n\n$$\nZ\\!=\\!\\overline{{{\\cal\\overline{{{Z}}}}}}\\!=\\!\\frac{1}{\\sqrt{\\!\\left(\\displaystyle\\frac{1}{R}\\right)^{2}\\!+\\!\\left(C\\!\\cdot\\!\\omega\\!-\\!\\displaystyle\\frac{1}{L\\!\\cdot\\!\\omega}\\right)^{2}}}\\!=\\!\\frac{1}{\\sf Y}\n$$  \n\nThe constant current source supplying the circuit furnishes a current having a momentary value \\( i(t) \\)  \n\n$$\n\\dot{\\cal I}(t)\\!=\\!{\\cal I}\\!\\cdot\\!\\sqrt{2}\\cdot\\!\\sin\\!\\big(\\omega\\!\\cdot\\!t\\big),\n$$  \n\nwhere \\( I \\) is the effective intensity (constant), of the current and \\( \\omega \\) is the current pulsation (that can vary). The potential difference at the jacks of the circuit has the momentary value \\( u(t) \\)  \n\n$$\nu(t)\\!=\\!U\\!\\cdot\\!\\sqrt{2}\\cdot\\!\\sin\\!\\left(\\omega\\!\\cdot\\!t+\\varphi\\right)\n$$  \n\nwhere \\( U \\) is the effective value of the tension and \\( \\varphi \\) is the phase difference between tension and current.  \n\nThe effective values of the current and tension obey the relation",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Equation",
        "evidence_source": "equation",
        "evidence_context": "The constant current source supplying the circuit furnishes a current having a momentary value \\(i(t) = I * sqrt(2) * sin(omega * t)\\), where \\(I\\) is the effective intensity (constant), of the current and \\( omega \\) is the current pulsation (that can vary).",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/textbook_needrop_en_569",
        "ID": "0eb8bdbd-227b-402a-905c-4c31a4dd5b19",
        "questions": "Using the given equations, what is the formula for calculating the parallel equivalent inductance (L) in terms of \\( L_1 \\) and \\( L_2 \\)?",
        "answers": "L = \\frac{L_{1}L_{2}}{L_{1}+L_{2}}",
        "context": "$$\n\\begin{array}{l}{\\displaystyle\\left\\{\\overline{{Y}}=\\frac{1}{R}+\\frac{1}{L_{1}\\cdot\\omega\\cdot j}+\\frac{1}{L_{2}\\cdot\\omega\\cdot j}-\\frac{C_{1}\\cdot\\omega}{j}-\\frac{C_{2}\\cdot\\omega}{j}\\right.}\\\\ {\\displaystyle\\left.\\overline{{Y}}=\\frac{1}{R}+j\\cdot\\left[(C_{1}+C_{2})-\\left(\\frac{1}{L_{1}}+\\frac{1}{L_{2}}\\right)\\right]\\right.}\\end{array}\n$$  \n\nThe circuit behaves as if it has a parallel equivalent capacity \\( C \\)  \n\n$$\n\\mathsf{C}=\\mathsf{C}_{1}+\\mathsf{C}_{2}\n$$  \n\nand a parallel equivalent inductance \\( L \\)  \n\n$$\n\\begin{array}{l}{\\displaystyle\\left\\{\\frac{1}{L}=\\frac{1}{L_{1}}+\\frac{1}{L_{2}}\\right.}\\\\ {\\displaystyle\\left.L=\\frac{L_{1}L_{2}}{L_{1}+L_{2}}\\right.}\\end{array}\n$$  \n\nThe complex admittance of the circuit may be written as  \n\n$$\n\\overline{{\\mathsf{Y}}}=\\frac{1}{R}\\!+\\!j\\cdot\\!\\left(C\\cdot\\omega\\!-\\!\\frac{1}{L\\!\\cdot\\!\\omega}\\right)\n$$  \n\nand the complex impedance of the circuit will be  \n\n$$\n\\left\\{\\begin{array}{l l}{\\overline{{Z}}\\!=\\!\\displaystyle\\frac{1}{\\overline{{Y}}}}\\\\ {\\overline{{Z}}\\!=\\!\\displaystyle\\frac{\\displaystyle\\frac{1}{R}\\!+\\!j\\!\\cdot\\!\\left(\\displaystyle\\frac{1}{L\\!\\cdot\\!\\omega}\\!-\\!C\\!\\cdot\\!\\omega\\right)}{\\sqrt{\\left(\\displaystyle\\frac{1}{R}\\right)^{2}+\\left(C\\!\\cdot\\!\\omega\\!-\\!\\displaystyle\\frac{1}{L\\!\\cdot\\!\\omega}\\right)^{2}}}}\\end{array}\\right.\n$$  \n\nThe impedance \\( Z \\) of the circuit, the inverse of the admittance of the circuit \\( Y \\), is the modulus of the complex impedance \\( Z \\)  \n\n$$\nZ\\!=\\!\\overline{{{\\cal\\overline{{{Z}}}}}}\\!=\\!\\frac{1}{\\sqrt{\\!\\left(\\displaystyle\\frac{1}{R}\\right)^{2}\\!+\\!\\left(C\\!\\cdot\\!\\omega\\!-\\!\\displaystyle\\frac{1}{L\\!\\cdot\\!\\omega}\\right)^{2}}}\\!=\\!\\frac{1}{\\sf Y}\n$$  \n\nThe constant current source supplying the circuit furnishes a current having a momentary value \\( i(t) \\)  \n\n$$\n\\dot{\\cal I}(t)\\!=\\!{\\cal I}\\!\\cdot\\!\\sqrt{2}\\cdot\\!\\sin\\!\\big(\\omega\\!\\cdot\\!t\\big),\n$$  \n\nwhere \\( I \\) is the effective intensity (constant), of the current and \\( \\omega \\) is the current pulsation (that can vary). The potential difference at the jacks of the circuit has the momentary value \\( u(t) \\)  \n\n$$\nu(t)\\!=\\!U\\!\\cdot\\!\\sqrt{2}\\cdot\\!\\sin\\!\\left(\\omega\\!\\cdot\\!t+\\varphi\\right)\n$$  \n\nwhere \\( U \\) is the effective value of the tension and \\( \\varphi \\) is the phase difference between tension and current.  \n\nThe effective values of the current and tension obey the relation",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "{\\displaystyle\\left.L=\\frac{L_{1}L_{2}}{L_{1}+L_{2}}\right.}",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/textbook_needrop_en_569",
        "ID": "0ebb9133-0376-4795-873c-238bd9d013b8",
        "questions": "If a circuit has the admittance \\( Y \\), the absolute magnitude of the impedance Z is the inverse of the admittance. Based on this concept and the provided equations, express \\( Z \\) in terms of \\( R \\), \\( C \\), \\( \\omega \\), and \\( L \\).",
        "answers": "Z = \\frac{1}{\\sqrt{\\left(\\frac{1}{R}\\right)^{2}+\\left(C\\cdot\\omega - \\frac{1}{L\\cdot\\omega}\\right)^{2}}}",
        "context": "$$\n\\begin{array}{l}{\\displaystyle\\left\\{\\overline{{Y}}=\\frac{1}{R}+\\frac{1}{L_{1}\\cdot\\omega\\cdot j}+\\frac{1}{L_{2}\\cdot\\omega\\cdot j}-\\frac{C_{1}\\cdot\\omega}{j}-\\frac{C_{2}\\cdot\\omega}{j}\\right.}\\\\ {\\displaystyle\\left.\\overline{{Y}}=\\frac{1}{R}+j\\cdot\\left[(C_{1}+C_{2})-\\left(\\frac{1}{L_{1}}+\\frac{1}{L_{2}}\\right)\\right]\\right.}\\end{array}\n$$  \n\nThe circuit behaves as if it has a parallel equivalent capacity \\( C \\)  \n\n$$\n\\mathsf{C}=\\mathsf{C}_{1}+\\mathsf{C}_{2}\n$$  \n\nand a parallel equivalent inductance \\( L \\)  \n\n$$\n\\begin{array}{l}{\\displaystyle\\left\\{\\frac{1}{L}=\\frac{1}{L_{1}}+\\frac{1}{L_{2}}\\right.}\\\\ {\\displaystyle\\left.L=\\frac{L_{1}L_{2}}{L_{1}+L_{2}}\\right.}\\end{array}\n$$  \n\nThe complex admittance of the circuit may be written as  \n\n$$\n\\overline{{\\mathsf{Y}}}=\\frac{1}{R}\\!+\\!j\\cdot\\!\\left(C\\cdot\\omega\\!-\\!\\frac{1}{L\\!\\cdot\\!\\omega}\\right)\n$$  \n\nand the complex impedance of the circuit will be  \n\n$$\n\\left\\{\\begin{array}{l l}{\\overline{{Z}}\\!=\\!\\displaystyle\\frac{1}{\\overline{{Y}}}}\\\\ {\\overline{{Z}}\\!=\\!\\displaystyle\\frac{\\displaystyle\\frac{1}{R}\\!+\\!j\\!\\cdot\\!\\left(\\displaystyle\\frac{1}{L\\!\\cdot\\!\\omega}\\!-\\!C\\!\\cdot\\!\\omega\\right)}{\\sqrt{\\left(\\displaystyle\\frac{1}{R}\\right)^{2}+\\left(C\\!\\cdot\\!\\omega\\!-\\!\\displaystyle\\frac{1}{L\\!\\cdot\\!\\omega}\\right)^{2}}}}\\end{array}\\right.\n$$  \n\nThe impedance \\( Z \\) of the circuit, the inverse of the admittance of the circuit \\( Y \\), is the modulus of the complex impedance \\( Z \\)  \n\n$$\nZ\\!=\\!\\overline{{{\\cal\\overline{{{Z}}}}}}\\!=\\!\\frac{1}{\\sqrt{\\!\\left(\\displaystyle\\frac{1}{R}\\right)^{2}\\!+\\!\\left(C\\!\\cdot\\!\\omega\\!-\\!\\displaystyle\\frac{1}{L\\!\\cdot\\!\\omega}\\right)^{2}}}\\!=\\!\\frac{1}{\\sf Y}\n$$  \n\nThe constant current source supplying the circuit furnishes a current having a momentary value \\( i(t) \\)  \n\n$$\n\\dot{\\cal I}(t)\\!=\\!{\\cal I}\\!\\cdot\\!\\sqrt{2}\\cdot\\!\\sin\\!\\big(\\omega\\!\\cdot\\!t\\big),\n$$  \n\nwhere \\( I \\) is the effective intensity (constant), of the current and \\( \\omega \\) is the current pulsation (that can vary). The potential difference at the jacks of the circuit has the momentary value \\( u(t) \\)  \n\n$$\nu(t)\\!=\\!U\\!\\cdot\\!\\sqrt{2}\\cdot\\!\\sin\\!\\left(\\omega\\!\\cdot\\!t+\\varphi\\right)\n$$  \n\nwhere \\( U \\) is the effective value of the tension and \\( \\varphi \\) is the phase difference between tension and current.  \n\nThe effective values of the current and tension obey the relation",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Z=\\overline{{{cal\\overline{{{Z}}}}}}=\\frac{1}{\\sqrt{\\left(\\displaystyle\\frac{1}{R}\\right)^{2}+\\left(C\\cdot\\omega-\\displaystyle\\frac{1}{L\\cdot\\omega}\\right)^{2}}}=\\frac{1}{\\sf Y}",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/textbook_needrop_en_569",
        "ID": "0ebbc767-692e-4c14-9d36-70f55a1e6984",
        "questions": "Determine the expression for the complex impedance \\( \\overline{Z} \\) of the circuit when given the complex admittance \\( \\overline{Y} \\) as \\( \frac{1}{R} + j \\cdot (C \\cdot \\omega - \\frac{1}{L \\cdot \\omega}) \\).",
        "answers": "\\overline{{Z}} = \\frac{\\displaystyle \\frac{1}{R} + j \\cdot \\left(\\frac{1}{L \\cdot \\omega} - C \\cdot \\omega \\right)}{\\sqrt{\\left(\\displaystyle \\frac{1}{R}\\right)^{2} + \\left(C \\cdot \\omega - \\displaystyle \\frac{1}{L \\cdot \\omega}\\right)^{2}}}",
        "context": "$$\n\\begin{array}{l}{\\displaystyle\\left\\{\\overline{{Y}}=\\frac{1}{R}+\\frac{1}{L_{1}\\cdot\\omega\\cdot j}+\\frac{1}{L_{2}\\cdot\\omega\\cdot j}-\\frac{C_{1}\\cdot\\omega}{j}-\\frac{C_{2}\\cdot\\omega}{j}\\right.}\\\\ {\\displaystyle\\left.\\overline{{Y}}=\\frac{1}{R}+j\\cdot\\left[(C_{1}+C_{2})-\\left(\\frac{1}{L_{1}}+\\frac{1}{L_{2}}\\right)\\right]\\right.}\\end{array}\n$$  \n\nThe circuit behaves as if it has a parallel equivalent capacity \\( C \\)  \n\n$$\n\\mathsf{C}=\\mathsf{C}_{1}+\\mathsf{C}_{2}\n$$  \n\nand a parallel equivalent inductance \\( L \\)  \n\n$$\n\\begin{array}{l}{\\displaystyle\\left\\{\\frac{1}{L}=\\frac{1}{L_{1}}+\\frac{1}{L_{2}}\\right.}\\\\ {\\displaystyle\\left.L=\\frac{L_{1}L_{2}}{L_{1}+L_{2}}\\right.}\\end{array}\n$$  \n\nThe complex admittance of the circuit may be written as  \n\n$$\n\\overline{{\\mathsf{Y}}}=\\frac{1}{R}\\!+\\!j\\cdot\\!\\left(C\\cdot\\omega\\!-\\!\\frac{1}{L\\!\\cdot\\!\\omega}\\right)\n$$  \n\nand the complex impedance of the circuit will be  \n\n$$\n\\left\\{\\begin{array}{l l}{\\overline{{Z}}\\!=\\!\\displaystyle\\frac{1}{\\overline{{Y}}}}\\\\ {\\overline{{Z}}\\!=\\!\\displaystyle\\frac{\\displaystyle\\frac{1}{R}\\!+\\!j\\!\\cdot\\!\\left(\\displaystyle\\frac{1}{L\\!\\cdot\\!\\omega}\\!-\\!C\\!\\cdot\\!\\omega\\right)}{\\sqrt{\\left(\\displaystyle\\frac{1}{R}\\right)^{2}+\\left(C\\!\\cdot\\!\\omega\\!-\\!\\displaystyle\\frac{1}{L\\!\\cdot\\!\\omega}\\right)^{2}}}}\\end{array}\\right.\n$$  \n\nThe impedance \\( Z \\) of the circuit, the inverse of the admittance of the circuit \\( Y \\), is the modulus of the complex impedance \\( Z \\)  \n\n$$\nZ\\!=\\!\\overline{{{\\cal\\overline{{{Z}}}}}}\\!=\\!\\frac{1}{\\sqrt{\\!\\left(\\displaystyle\\frac{1}{R}\\right)^{2}\\!+\\!\\left(C\\!\\cdot\\!\\omega\\!-\\!\\displaystyle\\frac{1}{L\\!\\cdot\\!\\omega}\\right)^{2}}}\\!=\\!\\frac{1}{\\sf Y}\n$$  \n\nThe constant current source supplying the circuit furnishes a current having a momentary value \\( i(t) \\)  \n\n$$\n\\dot{\\cal I}(t)\\!=\\!{\\cal I}\\!\\cdot\\!\\sqrt{2}\\cdot\\!\\sin\\!\\big(\\omega\\!\\cdot\\!t\\big),\n$$  \n\nwhere \\( I \\) is the effective intensity (constant), of the current and \\( \\omega \\) is the current pulsation (that can vary). The potential difference at the jacks of the circuit has the momentary value \\( u(t) \\)  \n\n$$\nu(t)\\!=\\!U\\!\\cdot\\!\\sqrt{2}\\cdot\\!\\sin\\!\\left(\\omega\\!\\cdot\\!t+\\varphi\\right)\n$$  \n\nwhere \\( U \\) is the effective value of the tension and \\( \\varphi \\) is the phase difference between tension and current.  \n\nThe effective values of the current and tension obey the relation",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "The complex impedance of the circuit will be \\{\\overline{{Z}}=!\\displaystyle\\frac{\\displaystyle\\frac{1}{R}!+!j!\\cdot!\\left(\\displaystyle\\frac{1}{L!\\cdot!\\omega}!\u2212!C!\\cdot!\\omega\\right)}{\\sqrt{\\left(\\displaystyle\\frac{1}{R}\\right)^{2}+\\left(C!\\cdot!\\omega!\u2212!\\displaystyle\\frac{1}{L!\\cdot!\\omega}\\right)^{2}}}}",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/phys-14735.pdf_158",
        "ID": "0ebbe39e-7904-44d6-bd92-71964c43bc46",
        "questions": "Who proposed that particles might exhibit wave-like properties in his Ph.D. thesis at the University of Paris?",
        "answers": "de Broglie",
        "context": "# 13.18: Wave-Particle Duality  \n\n# QUOTABLE QUOTES  \n\n1. Common sense is the deposit of prejudice laid down in the mind before the age of 18. A. Einstein  \n\n2. God is a mathematician of a very high order and He used very advanced mathematics in constructing the Universe. P.A.M. Dirac  \n\n3. If you are not confused by Quantum Physics then you haven't really understood it. N. Bohr  \n\n# What is the Photo-Electric Effect?  \n\nIn the Photo-Electric effect, a metal is illuminated with light. Under certain circumstances, electrons are emitted from the illuminated surface. We can vary the intensity of the light and its frequency (its colour).  \n\n![](images/c34a0e96b4e5668aec1b89c2be9be69d606d48f83ea531e546e02c020c9084d7.jpg)  \n\n# Expectations of Classical Physics.  \n\nThese expectations are based on the belief that light is an electromagnetic wave; if we increase the intensity of the light, this is equivalent to increasing the amplitude of the oscillating electric field of which the light wave is composed. Since the energy of the light beam is spread uniformly over the beam, it is transferred continuously to the electrons, which require a certain minimum of energy to escape the attractive forces of the metal. In the following, \"The maximum energy of the electrons\" means \"The energy of the most energetic electrons\".  \n\n- c. There may be a time delay between the switching on of the light and the appearance of the first electrons; the lower the light intensity, the longer will be this time delay.  \n\n# Experimental Observations.  \n\n- c. No matter how weak the light, as long as its frequency is above the threshold frequency, the emission of electrons starts IMMEDIATELY the light is switched on.  \n\n(In case you were wondering; an increase in the light intensity increases the number of electrons emitted per second, while leaving the energy of each electron unchanged).  \n\n# Einstein's Explanation  \n\n- c. The interaction between a photon and an electron in the metal is a unique, elemental act, in which the photon can give up some, or all of its energy to the electron, which then might have enough energy to escape from the metal.  \n\nWhy does this explain the observations?  \n\nThe electron is kept in the metal by the electric forces, and can only escape if a certain minimum amount of energy is given to it. If the photon energy (i.e. frequency) is too low to overcome this attractive force between the electrons and the metal, the electron can't escape. Thus, the frequency of the photon must be above a certain value (which depends on the particular metal). Once we are above this threshold, the photon either hits an electron or it doesn't. If it does, and if enough energy is transferred to the electron from the photon, the electron will have enough energy to escape IMMEDIATELY, with no time delay. Also, if we increase the energy of the photon by increasing its frequency, the electrons which interact with these electrons can come off with increased energy.  \n\n$\\mathbf{E_{photon}=h\\Delta f}$   $\\mathbf{h}$ constant.  \n\n# Particles are also Waves.  \n\nThe great success of Einstein's theory for the photoelectric effect stimulated de Broglie to postulate in his Ph.D. thesis at the University of Paris, that particles might exhibit wave-like properties. Starting from Einstein's relation, $\\mathbf{E_{photon}=h\\Delta f}$ and using the relation given by Maxwell's equations for the momentum of a light wave, $\\mathbf{Elight}=\\mathbf{pc}$ (where $\\mathbf{p}$ is the momentum of the light, and c",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "The great success of Einstein's theory for the photoelectric effect stimulated de Broglie to postulate in his Ph.D. thesis at the University of Paris, that particles might exhibit wave-like properties.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/phys-14735.pdf_158",
        "ID": "0ec1e80e-5586-4fd8-bd41-ebd5df1c57ef",
        "questions": "Does an increase in light intensity affect the energy of each electron in the photoelectric effect?",
        "answers": "No",
        "context": "# 13.18: Wave-Particle Duality  \n\n# QUOTABLE QUOTES  \n\n1. Common sense is the deposit of prejudice laid down in the mind before the age of 18. A. Einstein  \n\n2. God is a mathematician of a very high order and He used very advanced mathematics in constructing the Universe. P.A.M. Dirac  \n\n3. If you are not confused by Quantum Physics then you haven't really understood it. N. Bohr  \n\n# What is the Photo-Electric Effect?  \n\nIn the Photo-Electric effect, a metal is illuminated with light. Under certain circumstances, electrons are emitted from the illuminated surface. We can vary the intensity of the light and its frequency (its colour).  \n\n![](images/c34a0e96b4e5668aec1b89c2be9be69d606d48f83ea531e546e02c020c9084d7.jpg)  \n\n# Expectations of Classical Physics.  \n\nThese expectations are based on the belief that light is an electromagnetic wave; if we increase the intensity of the light, this is equivalent to increasing the amplitude of the oscillating electric field of which the light wave is composed. Since the energy of the light beam is spread uniformly over the beam, it is transferred continuously to the electrons, which require a certain minimum of energy to escape the attractive forces of the metal. In the following, \"The maximum energy of the electrons\" means \"The energy of the most energetic electrons\".  \n\n- c. There may be a time delay between the switching on of the light and the appearance of the first electrons; the lower the light intensity, the longer will be this time delay.  \n\n# Experimental Observations.  \n\n- c. No matter how weak the light, as long as its frequency is above the threshold frequency, the emission of electrons starts IMMEDIATELY the light is switched on.  \n\n(In case you were wondering; an increase in the light intensity increases the number of electrons emitted per second, while leaving the energy of each electron unchanged).  \n\n# Einstein's Explanation  \n\n- c. The interaction between a photon and an electron in the metal is a unique, elemental act, in which the photon can give up some, or all of its energy to the electron, which then might have enough energy to escape from the metal.  \n\nWhy does this explain the observations?  \n\nThe electron is kept in the metal by the electric forces, and can only escape if a certain minimum amount of energy is given to it. If the photon energy (i.e. frequency) is too low to overcome this attractive force between the electrons and the metal, the electron can't escape. Thus, the frequency of the photon must be above a certain value (which depends on the particular metal). Once we are above this threshold, the photon either hits an electron or it doesn't. If it does, and if enough energy is transferred to the electron from the photon, the electron will have enough energy to escape IMMEDIATELY, with no time delay. Also, if we increase the energy of the photon by increasing its frequency, the electrons which interact with these electrons can come off with increased energy.  \n\n$\\mathbf{E_{photon}=h\\Delta f}$   $\\mathbf{h}$ constant.  \n\n# Particles are also Waves.  \n\nThe great success of Einstein's theory for the photoelectric effect stimulated de Broglie to postulate in his Ph.D. thesis at the University of Paris, that particles might exhibit wave-like properties. Starting from Einstein's relation, $\\mathbf{E_{photon}=h\\Delta f}$ and using the relation given by Maxwell's equations for the momentum of a light wave, $\\mathbf{Elight}=\\mathbf{pc}$ (where $\\mathbf{p}$ is the momentum of the light, and c",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Yes/No",
        "evidence_source": "text",
        "evidence_context": "In case you were wondering; an increase in the light intensity increases the number of electrons emitted per second, while leaving the energy of each electron unchanged.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/phys-14735.pdf_158",
        "ID": "0ec37460-527f-4bc2-9577-7894468bc959",
        "questions": "What is the equation for photon energy according to Einstein's relation in the context of the photoelectric effect?",
        "answers": "E_photon = h\u0394f",
        "context": "# 13.18: Wave-Particle Duality  \n\n# QUOTABLE QUOTES  \n\n1. Common sense is the deposit of prejudice laid down in the mind before the age of 18. A. Einstein  \n\n2. God is a mathematician of a very high order and He used very advanced mathematics in constructing the Universe. P.A.M. Dirac  \n\n3. If you are not confused by Quantum Physics then you haven't really understood it. N. Bohr  \n\n# What is the Photo-Electric Effect?  \n\nIn the Photo-Electric effect, a metal is illuminated with light. Under certain circumstances, electrons are emitted from the illuminated surface. We can vary the intensity of the light and its frequency (its colour).  \n\n![](images/c34a0e96b4e5668aec1b89c2be9be69d606d48f83ea531e546e02c020c9084d7.jpg)  \n\n# Expectations of Classical Physics.  \n\nThese expectations are based on the belief that light is an electromagnetic wave; if we increase the intensity of the light, this is equivalent to increasing the amplitude of the oscillating electric field of which the light wave is composed. Since the energy of the light beam is spread uniformly over the beam, it is transferred continuously to the electrons, which require a certain minimum of energy to escape the attractive forces of the metal. In the following, \"The maximum energy of the electrons\" means \"The energy of the most energetic electrons\".  \n\n- c. There may be a time delay between the switching on of the light and the appearance of the first electrons; the lower the light intensity, the longer will be this time delay.  \n\n# Experimental Observations.  \n\n- c. No matter how weak the light, as long as its frequency is above the threshold frequency, the emission of electrons starts IMMEDIATELY the light is switched on.  \n\n(In case you were wondering; an increase in the light intensity increases the number of electrons emitted per second, while leaving the energy of each electron unchanged).  \n\n# Einstein's Explanation  \n\n- c. The interaction between a photon and an electron in the metal is a unique, elemental act, in which the photon can give up some, or all of its energy to the electron, which then might have enough energy to escape from the metal.  \n\nWhy does this explain the observations?  \n\nThe electron is kept in the metal by the electric forces, and can only escape if a certain minimum amount of energy is given to it. If the photon energy (i.e. frequency) is too low to overcome this attractive force between the electrons and the metal, the electron can't escape. Thus, the frequency of the photon must be above a certain value (which depends on the particular metal). Once we are above this threshold, the photon either hits an electron or it doesn't. If it does, and if enough energy is transferred to the electron from the photon, the electron will have enough energy to escape IMMEDIATELY, with no time delay. Also, if we increase the energy of the photon by increasing its frequency, the electrons which interact with these electrons can come off with increased energy.  \n\n$\\mathbf{E_{photon}=h\\Delta f}$   $\\mathbf{h}$ constant.  \n\n# Particles are also Waves.  \n\nThe great success of Einstein's theory for the photoelectric effect stimulated de Broglie to postulate in his Ph.D. thesis at the University of Paris, that particles might exhibit wave-like properties. Starting from Einstein's relation, $\\mathbf{E_{photon}=h\\Delta f}$ and using the relation given by Maxwell's equations for the momentum of a light wave, $\\mathbf{Elight}=\\mathbf{pc}$ (where $\\mathbf{p}$ is the momentum of the light, and c",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Starting from Einstein's relation, $E_{photon}=h\\Delta f$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/phys-14735.pdf_158",
        "ID": "0ec7c92e-b36d-4c16-a3cc-0cc1274e9b70",
        "questions": "What is the energy equation for a photon in Einstein's explanation of the photoelectric effect?",
        "answers": "E_{photon}=h\\Delta f",
        "context": "# 13.18: Wave-Particle Duality  \n\n# QUOTABLE QUOTES  \n\n1. Common sense is the deposit of prejudice laid down in the mind before the age of 18. A. Einstein  \n\n2. God is a mathematician of a very high order and He used very advanced mathematics in constructing the Universe. P.A.M. Dirac  \n\n3. If you are not confused by Quantum Physics then you haven't really understood it. N. Bohr  \n\n# What is the Photo-Electric Effect?  \n\nIn the Photo-Electric effect, a metal is illuminated with light. Under certain circumstances, electrons are emitted from the illuminated surface. We can vary the intensity of the light and its frequency (its colour).  \n\n![](images/c34a0e96b4e5668aec1b89c2be9be69d606d48f83ea531e546e02c020c9084d7.jpg)  \n\n# Expectations of Classical Physics.  \n\nThese expectations are based on the belief that light is an electromagnetic wave; if we increase the intensity of the light, this is equivalent to increasing the amplitude of the oscillating electric field of which the light wave is composed. Since the energy of the light beam is spread uniformly over the beam, it is transferred continuously to the electrons, which require a certain minimum of energy to escape the attractive forces of the metal. In the following, \"The maximum energy of the electrons\" means \"The energy of the most energetic electrons\".  \n\n- c. There may be a time delay between the switching on of the light and the appearance of the first electrons; the lower the light intensity, the longer will be this time delay.  \n\n# Experimental Observations.  \n\n- c. No matter how weak the light, as long as its frequency is above the threshold frequency, the emission of electrons starts IMMEDIATELY the light is switched on.  \n\n(In case you were wondering; an increase in the light intensity increases the number of electrons emitted per second, while leaving the energy of each electron unchanged).  \n\n# Einstein's Explanation  \n\n- c. The interaction between a photon and an electron in the metal is a unique, elemental act, in which the photon can give up some, or all of its energy to the electron, which then might have enough energy to escape from the metal.  \n\nWhy does this explain the observations?  \n\nThe electron is kept in the metal by the electric forces, and can only escape if a certain minimum amount of energy is given to it. If the photon energy (i.e. frequency) is too low to overcome this attractive force between the electrons and the metal, the electron can't escape. Thus, the frequency of the photon must be above a certain value (which depends on the particular metal). Once we are above this threshold, the photon either hits an electron or it doesn't. If it does, and if enough energy is transferred to the electron from the photon, the electron will have enough energy to escape IMMEDIATELY, with no time delay. Also, if we increase the energy of the photon by increasing its frequency, the electrons which interact with these electrons can come off with increased energy.  \n\n$\\mathbf{E_{photon}=h\\Delta f}$   $\\mathbf{h}$ constant.  \n\n# Particles are also Waves.  \n\nThe great success of Einstein's theory for the photoelectric effect stimulated de Broglie to postulate in his Ph.D. thesis at the University of Paris, that particles might exhibit wave-like properties. Starting from Einstein's relation, $\\mathbf{E_{photon}=h\\Delta f}$ and using the relation given by Maxwell's equations for the momentum of a light wave, $\\mathbf{Elight}=\\mathbf{pc}$ (where $\\mathbf{p}$ is the momentum of the light, and c",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "E_{photon}=h\\Delta f",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/phys-14735.pdf_158",
        "ID": "0ed5be73-6d3a-48e8-bbec-7debf136f64e",
        "questions": "According to Maxwell's equations, what relationship is given for the momentum of a light wave?",
        "answers": "Elight=pc",
        "context": "# 13.18: Wave-Particle Duality  \n\n# QUOTABLE QUOTES  \n\n1. Common sense is the deposit of prejudice laid down in the mind before the age of 18. A. Einstein  \n\n2. God is a mathematician of a very high order and He used very advanced mathematics in constructing the Universe. P.A.M. Dirac  \n\n3. If you are not confused by Quantum Physics then you haven't really understood it. N. Bohr  \n\n# What is the Photo-Electric Effect?  \n\nIn the Photo-Electric effect, a metal is illuminated with light. Under certain circumstances, electrons are emitted from the illuminated surface. We can vary the intensity of the light and its frequency (its colour).  \n\n![](images/c34a0e96b4e5668aec1b89c2be9be69d606d48f83ea531e546e02c020c9084d7.jpg)  \n\n# Expectations of Classical Physics.  \n\nThese expectations are based on the belief that light is an electromagnetic wave; if we increase the intensity of the light, this is equivalent to increasing the amplitude of the oscillating electric field of which the light wave is composed. Since the energy of the light beam is spread uniformly over the beam, it is transferred continuously to the electrons, which require a certain minimum of energy to escape the attractive forces of the metal. In the following, \"The maximum energy of the electrons\" means \"The energy of the most energetic electrons\".  \n\n- c. There may be a time delay between the switching on of the light and the appearance of the first electrons; the lower the light intensity, the longer will be this time delay.  \n\n# Experimental Observations.  \n\n- c. No matter how weak the light, as long as its frequency is above the threshold frequency, the emission of electrons starts IMMEDIATELY the light is switched on.  \n\n(In case you were wondering; an increase in the light intensity increases the number of electrons emitted per second, while leaving the energy of each electron unchanged).  \n\n# Einstein's Explanation  \n\n- c. The interaction between a photon and an electron in the metal is a unique, elemental act, in which the photon can give up some, or all of its energy to the electron, which then might have enough energy to escape from the metal.  \n\nWhy does this explain the observations?  \n\nThe electron is kept in the metal by the electric forces, and can only escape if a certain minimum amount of energy is given to it. If the photon energy (i.e. frequency) is too low to overcome this attractive force between the electrons and the metal, the electron can't escape. Thus, the frequency of the photon must be above a certain value (which depends on the particular metal). Once we are above this threshold, the photon either hits an electron or it doesn't. If it does, and if enough energy is transferred to the electron from the photon, the electron will have enough energy to escape IMMEDIATELY, with no time delay. Also, if we increase the energy of the photon by increasing its frequency, the electrons which interact with these electrons can come off with increased energy.  \n\n$\\mathbf{E_{photon}=h\\Delta f}$   $\\mathbf{h}$ constant.  \n\n# Particles are also Waves.  \n\nThe great success of Einstein's theory for the photoelectric effect stimulated de Broglie to postulate in his Ph.D. thesis at the University of Paris, that particles might exhibit wave-like properties. Starting from Einstein's relation, $\\mathbf{E_{photon}=h\\Delta f}$ and using the relation given by Maxwell's equations for the momentum of a light wave, $\\mathbf{Elight}=\\mathbf{pc}$ (where $\\mathbf{p}$ is the momentum of the light, and c",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "using the relation given by Maxwell's equations for the momentum of a light wave, Elight=pc",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/phys-14735.pdf_158",
        "ID": "0ee7aed3-f04a-4b9d-a14b-3ebb3845b6bd",
        "questions": "Utilizing Einstein's and Maxwell's equations, how would you express the energy of light in terms of its momentum?",
        "answers": "Elight = h\\Delta f",
        "context": "# 13.18: Wave-Particle Duality  \n\n# QUOTABLE QUOTES  \n\n1. Common sense is the deposit of prejudice laid down in the mind before the age of 18. A. Einstein  \n\n2. God is a mathematician of a very high order and He used very advanced mathematics in constructing the Universe. P.A.M. Dirac  \n\n3. If you are not confused by Quantum Physics then you haven't really understood it. N. Bohr  \n\n# What is the Photo-Electric Effect?  \n\nIn the Photo-Electric effect, a metal is illuminated with light. Under certain circumstances, electrons are emitted from the illuminated surface. We can vary the intensity of the light and its frequency (its colour).  \n\n![](images/c34a0e96b4e5668aec1b89c2be9be69d606d48f83ea531e546e02c020c9084d7.jpg)  \n\n# Expectations of Classical Physics.  \n\nThese expectations are based on the belief that light is an electromagnetic wave; if we increase the intensity of the light, this is equivalent to increasing the amplitude of the oscillating electric field of which the light wave is composed. Since the energy of the light beam is spread uniformly over the beam, it is transferred continuously to the electrons, which require a certain minimum of energy to escape the attractive forces of the metal. In the following, \"The maximum energy of the electrons\" means \"The energy of the most energetic electrons\".  \n\n- c. There may be a time delay between the switching on of the light and the appearance of the first electrons; the lower the light intensity, the longer will be this time delay.  \n\n# Experimental Observations.  \n\n- c. No matter how weak the light, as long as its frequency is above the threshold frequency, the emission of electrons starts IMMEDIATELY the light is switched on.  \n\n(In case you were wondering; an increase in the light intensity increases the number of electrons emitted per second, while leaving the energy of each electron unchanged).  \n\n# Einstein's Explanation  \n\n- c. The interaction between a photon and an electron in the metal is a unique, elemental act, in which the photon can give up some, or all of its energy to the electron, which then might have enough energy to escape from the metal.  \n\nWhy does this explain the observations?  \n\nThe electron is kept in the metal by the electric forces, and can only escape if a certain minimum amount of energy is given to it. If the photon energy (i.e. frequency) is too low to overcome this attractive force between the electrons and the metal, the electron can't escape. Thus, the frequency of the photon must be above a certain value (which depends on the particular metal). Once we are above this threshold, the photon either hits an electron or it doesn't. If it does, and if enough energy is transferred to the electron from the photon, the electron will have enough energy to escape IMMEDIATELY, with no time delay. Also, if we increase the energy of the photon by increasing its frequency, the electrons which interact with these electrons can come off with increased energy.  \n\n$\\mathbf{E_{photon}=h\\Delta f}$   $\\mathbf{h}$ constant.  \n\n# Particles are also Waves.  \n\nThe great success of Einstein's theory for the photoelectric effect stimulated de Broglie to postulate in his Ph.D. thesis at the University of Paris, that particles might exhibit wave-like properties. Starting from Einstein's relation, $\\mathbf{E_{photon}=h\\Delta f}$ and using the relation given by Maxwell's equations for the momentum of a light wave, $\\mathbf{Elight}=\\mathbf{pc}$ (where $\\mathbf{p}$ is the momentum of the light, and c",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Starting from Einstein's relation, E_{photon}=h\\Delta f and using the relation given by Maxwell's equations for the momentum of a light wave, Elight=pc",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/GTM40-Denumerable_Markov_Chains-with_a_chapter_of_Markov_Random_Fields_by_David_Griffeath1976.pdf_256",
        "ID": "0ef2f527-30c4-4834-8dcf-681d449d215d",
        "questions": "What condition must be satisfied for the inequality involving |bn - bn-1| in the proof?",
        "answers": "for all n \u2265 N\u2032, |bn - b(n-1)| \u2264 \u03b5/(2a N)",
        "context": "PROOF: Let $\\epsilon > 0$ be given. Choose $N$ sufficiently large that $\\textstyle\\sum_{k\\,>\\,N}a_{k}\\,<\\,\\epsilon/(4B)$ and pick $N^{\\prime}$ large enough so that for all $n \\geq N^{\\prime}$  \n\n$$\n\\left|b_{n}\\,-\\,b_{n\\,-1}\\right|\\,\\leq\\,\\frac{\\epsilon}{2a N}.\n$$  \n\nThen for $\\pmb{n} \\geq N + N^{\\prime}$, we have  \n\n$$\n\\begin{array}{r l}{\\bigg|\\displaystyle\\sum_{k=0}^{n}a_{k}(b_{n}\\,-\\,b_{n-k})\\bigg|\\,}&{\\le\\,\\displaystyle\\sum_{k=0}^{N}a_{k}\\big|b_{n}\\,-\\,b_{n-k}\\big|\\,+\\,\\displaystyle\\sum_{k=N+1}^{n}a_{k}\\big(\\big|b_{n}\\big|\\,+\\,\\big|b_{n-k}\\big|\\big)\\,}\\\\ &{\\le\\,\\displaystyle\\sum_{k=0}^{N}a_{k}\\,\\displaystyle\\sum_{j=0}^{k-1}\\big|b_{n-j}\\,-\\,b_{n-j-1}\\big|\\,+\\,2B\\,\\displaystyle\\sum_{k=N+1}^{n}a_{k}\\,}\\\\ &{\\le\\,\\displaystyle\\sum_{k=0}^{N}a_{k}\\,\\displaystyle\\sum_{j=0}^{k-1}\\frac{\\epsilon}{2a N}\\,+\\,\\frac{\\epsilon}{4B}\\cdot2B,\\quad\\mathrm{since}\\,\\,\\,n\\,-\\,j\\,\\ge\\,N^{\\prime}\\,}\\\\ &{\\le\\,\\displaystyle\\frac{\\epsilon}{2a}\\,\\displaystyle\\sum_{k=0}^{N}a_{k}\\,+\\,\\frac{\\epsilon}{2}\\,}\\\\ &{\\le\\,\\epsilon.}&\\end{array}\n$$  \n\nTheorem 9-7: Let $i, j$ and $k$ be arbitrary states in a current Markov chain which is either null or noncyclic ergodic. Then  \n\n$$\n\\operatorname*{lim}_{n\\,\\rightarrow\\,\\infty}\\,[(N_{k k}^{(n)}\\,-\\,N_{i k}^{(n)})\\alpha_{j}/\\alpha_{k}\\,+\\,N_{i j}^{(n)}\\,-\\,N_{k j}^{(n)}]\\,=\\,{^k N}_{i j}.\n$$  \n\nPROOF: We may assume that neither $i$ nor $j$ equals $k$ since otherwise both sides are clearly zero. We begin by establishing four equations:  \n\n$$\n\\begin{array}{l l}{{(1)}}&{{N_{k k}^{(n)}=\\displaystyle\\sum_{\\nu=0}^{\\infty}F_{i k}^{(\\nu)}N_{k k}^{(n)}}}\\\\ {{(2)}}&{{N_{i k}^{(n)}=\\displaystyle\\sum_{\\nu=0}^{n}F_{i k}^{(\\nu)}N_{k k}^{(n-\\nu)}}}\\\\ {{(3)}}&{{N_{k j}^{(n)}=\\displaystyle\\sum_{\\nu=0}^{\\infty}F_{i k}^{(\\nu)}N_{k j}^{(n)}}}\\\\ {{(4)}}&{{N_{i j}^{(n)}=\\displaystyle\\sum_{\\nu=0}^{n}F_{i k}^{(\\nu)}N_{k j}^{(n-\\nu)}\\,+\\,{^k}N_{i j}^{(n)}.}}\\end{array}\n$$  \n\nEquations (1) and (3) follow the fact that $\\sum\\,F_{i k}^{(v)}\\,=\\,H_{i k}\\,=\\,1\\,$ Equation (2) comes from Theorem 4-11 with the random time $\\mathbf t = \\operatorname*{min} (\\mathbf{t}_{k},\\,n)$, and equation (4) is a similar result, except that the sum has been broken into two parts representing what happens after and before state $k$ is reached for the first time.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Choose N sufficiently large that \u2211k>N ak < \u03b5/(4B) and pick N\u2032 large enough so that for all n \u2265 N\u2032, |bn - bn-1| \u2264 \u03b5/(2a N)",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM40-Denumerable_Markov_Chains-with_a_chapter_of_Markov_Random_Fields_by_David_Griffeath1976.pdf_256",
        "ID": "0f0ac134-2e0d-44ad-8888-d15e7eb7a8f3",
        "questions": "For arbitrary states i, j, and k in a current Markov chain, what expression does Theorem 9-7 state reaches a limit as n approaches infinity?",
        "answers": "lim_{n\u2192\u221e} [(N(kk)^(n) - N(ik)^(n))\u03b1j/\u03b1k + N(ij)^(n) - N(kj)^(n)]",
        "context": "PROOF: Let $\\epsilon > 0$ be given. Choose $N$ sufficiently large that $\\textstyle\\sum_{k\\,>\\,N}a_{k}\\,<\\,\\epsilon/(4B)$ and pick $N^{\\prime}$ large enough so that for all $n \\geq N^{\\prime}$  \n\n$$\n\\left|b_{n}\\,-\\,b_{n\\,-1}\\right|\\,\\leq\\,\\frac{\\epsilon}{2a N}.\n$$  \n\nThen for $\\pmb{n} \\geq N + N^{\\prime}$, we have  \n\n$$\n\\begin{array}{r l}{\\bigg|\\displaystyle\\sum_{k=0}^{n}a_{k}(b_{n}\\,-\\,b_{n-k})\\bigg|\\,}&{\\le\\,\\displaystyle\\sum_{k=0}^{N}a_{k}\\big|b_{n}\\,-\\,b_{n-k}\\big|\\,+\\,\\displaystyle\\sum_{k=N+1}^{n}a_{k}\\big(\\big|b_{n}\\big|\\,+\\,\\big|b_{n-k}\\big|\\big)\\,}\\\\ &{\\le\\,\\displaystyle\\sum_{k=0}^{N}a_{k}\\,\\displaystyle\\sum_{j=0}^{k-1}\\big|b_{n-j}\\,-\\,b_{n-j-1}\\big|\\,+\\,2B\\,\\displaystyle\\sum_{k=N+1}^{n}a_{k}\\,}\\\\ &{\\le\\,\\displaystyle\\sum_{k=0}^{N}a_{k}\\,\\displaystyle\\sum_{j=0}^{k-1}\\frac{\\epsilon}{2a N}\\,+\\,\\frac{\\epsilon}{4B}\\cdot2B,\\quad\\mathrm{since}\\,\\,\\,n\\,-\\,j\\,\\ge\\,N^{\\prime}\\,}\\\\ &{\\le\\,\\displaystyle\\frac{\\epsilon}{2a}\\,\\displaystyle\\sum_{k=0}^{N}a_{k}\\,+\\,\\frac{\\epsilon}{2}\\,}\\\\ &{\\le\\,\\epsilon.}&\\end{array}\n$$  \n\nTheorem 9-7: Let $i, j$ and $k$ be arbitrary states in a current Markov chain which is either null or noncyclic ergodic. Then  \n\n$$\n\\operatorname*{lim}_{n\\,\\rightarrow\\,\\infty}\\,[(N_{k k}^{(n)}\\,-\\,N_{i k}^{(n)})\\alpha_{j}/\\alpha_{k}\\,+\\,N_{i j}^{(n)}\\,-\\,N_{k j}^{(n)}]\\,=\\,{^k N}_{i j}.\n$$  \n\nPROOF: We may assume that neither $i$ nor $j$ equals $k$ since otherwise both sides are clearly zero. We begin by establishing four equations:  \n\n$$\n\\begin{array}{l l}{{(1)}}&{{N_{k k}^{(n)}=\\displaystyle\\sum_{\\nu=0}^{\\infty}F_{i k}^{(\\nu)}N_{k k}^{(n)}}}\\\\ {{(2)}}&{{N_{i k}^{(n)}=\\displaystyle\\sum_{\\nu=0}^{n}F_{i k}^{(\\nu)}N_{k k}^{(n-\\nu)}}}\\\\ {{(3)}}&{{N_{k j}^{(n)}=\\displaystyle\\sum_{\\nu=0}^{\\infty}F_{i k}^{(\\nu)}N_{k j}^{(n)}}}\\\\ {{(4)}}&{{N_{i j}^{(n)}=\\displaystyle\\sum_{\\nu=0}^{n}F_{i k}^{(\\nu)}N_{k j}^{(n-\\nu)}\\,+\\,{^k}N_{i j}^{(n)}.}}\\end{array}\n$$  \n\nEquations (1) and (3) follow the fact that $\\sum\\,F_{i k}^{(v)}\\,=\\,H_{i k}\\,=\\,1\\,$ Equation (2) comes from Theorem 4-11 with the random time $\\mathbf t = \\operatorname*{min} (\\mathbf{t}_{k},\\,n)$, and equation (4) is a similar result, except that the sum has been broken into two parts representing what happens after and before state $k$ is reached for the first time.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Theorem 9-7: Let i, j and k be arbitrary states in a current Markov chain which is either null or noncyclic ergodic. Then lim_{n\u2192\u221e} [(N(kk)^(n) - N(ik)^(n))\u03b1j/\u03b1k + N(ij)^(n) - N(kj)^(n)] = ^k N(ij)",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM40-Denumerable_Markov_Chains-with_a_chapter_of_Markov_Random_Fields_by_David_Griffeath1976.pdf_256",
        "ID": "0f0e6955-9775-4eaf-aac4-559668c44e05",
        "questions": "What assumption is made about states i and j in the proof of Theorem 9-7?",
        "answers": "We may assume that neither i nor j equals k since otherwise both sides are clearly zero.",
        "context": "PROOF: Let $\\epsilon > 0$ be given. Choose $N$ sufficiently large that $\\textstyle\\sum_{k\\,>\\,N}a_{k}\\,<\\,\\epsilon/(4B)$ and pick $N^{\\prime}$ large enough so that for all $n \\geq N^{\\prime}$  \n\n$$\n\\left|b_{n}\\,-\\,b_{n\\,-1}\\right|\\,\\leq\\,\\frac{\\epsilon}{2a N}.\n$$  \n\nThen for $\\pmb{n} \\geq N + N^{\\prime}$, we have  \n\n$$\n\\begin{array}{r l}{\\bigg|\\displaystyle\\sum_{k=0}^{n}a_{k}(b_{n}\\,-\\,b_{n-k})\\bigg|\\,}&{\\le\\,\\displaystyle\\sum_{k=0}^{N}a_{k}\\big|b_{n}\\,-\\,b_{n-k}\\big|\\,+\\,\\displaystyle\\sum_{k=N+1}^{n}a_{k}\\big(\\big|b_{n}\\big|\\,+\\,\\big|b_{n-k}\\big|\\big)\\,}\\\\ &{\\le\\,\\displaystyle\\sum_{k=0}^{N}a_{k}\\,\\displaystyle\\sum_{j=0}^{k-1}\\big|b_{n-j}\\,-\\,b_{n-j-1}\\big|\\,+\\,2B\\,\\displaystyle\\sum_{k=N+1}^{n}a_{k}\\,}\\\\ &{\\le\\,\\displaystyle\\sum_{k=0}^{N}a_{k}\\,\\displaystyle\\sum_{j=0}^{k-1}\\frac{\\epsilon}{2a N}\\,+\\,\\frac{\\epsilon}{4B}\\cdot2B,\\quad\\mathrm{since}\\,\\,\\,n\\,-\\,j\\,\\ge\\,N^{\\prime}\\,}\\\\ &{\\le\\,\\displaystyle\\frac{\\epsilon}{2a}\\,\\displaystyle\\sum_{k=0}^{N}a_{k}\\,+\\,\\frac{\\epsilon}{2}\\,}\\\\ &{\\le\\,\\epsilon.}&\\end{array}\n$$  \n\nTheorem 9-7: Let $i, j$ and $k$ be arbitrary states in a current Markov chain which is either null or noncyclic ergodic. Then  \n\n$$\n\\operatorname*{lim}_{n\\,\\rightarrow\\,\\infty}\\,[(N_{k k}^{(n)}\\,-\\,N_{i k}^{(n)})\\alpha_{j}/\\alpha_{k}\\,+\\,N_{i j}^{(n)}\\,-\\,N_{k j}^{(n)}]\\,=\\,{^k N}_{i j}.\n$$  \n\nPROOF: We may assume that neither $i$ nor $j$ equals $k$ since otherwise both sides are clearly zero. We begin by establishing four equations:  \n\n$$\n\\begin{array}{l l}{{(1)}}&{{N_{k k}^{(n)}=\\displaystyle\\sum_{\\nu=0}^{\\infty}F_{i k}^{(\\nu)}N_{k k}^{(n)}}}\\\\ {{(2)}}&{{N_{i k}^{(n)}=\\displaystyle\\sum_{\\nu=0}^{n}F_{i k}^{(\\nu)}N_{k k}^{(n-\\nu)}}}\\\\ {{(3)}}&{{N_{k j}^{(n)}=\\displaystyle\\sum_{\\nu=0}^{\\infty}F_{i k}^{(\\nu)}N_{k j}^{(n)}}}\\\\ {{(4)}}&{{N_{i j}^{(n)}=\\displaystyle\\sum_{\\nu=0}^{n}F_{i k}^{(\\nu)}N_{k j}^{(n-\\nu)}\\,+\\,{^k}N_{i j}^{(n)}.}}\\end{array}\n$$  \n\nEquations (1) and (3) follow the fact that $\\sum\\,F_{i k}^{(v)}\\,=\\,H_{i k}\\,=\\,1\\,$ Equation (2) comes from Theorem 4-11 with the random time $\\mathbf t = \\operatorname*{min} (\\mathbf{t}_{k},\\,n)$, and equation (4) is a similar result, except that the sum has been broken into two parts representing what happens after and before state $k$ is reached for the first time.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "PROOF: We may assume that neither i nor j equals k since otherwise both sides are clearly zero.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM40-Denumerable_Markov_Chains-with_a_chapter_of_Markov_Random_Fields_by_David_Griffeath1976.pdf_256",
        "ID": "0f128210-703f-49ef-94fe-a8e677f8e9a5",
        "questions": "What theorem is used to derive Equation (2) in the proof of Theorem 9-7?",
        "answers": "Theorem 4-11 with the random time t = min (t_k, n).",
        "context": "PROOF: Let $\\epsilon > 0$ be given. Choose $N$ sufficiently large that $\\textstyle\\sum_{k\\,>\\,N}a_{k}\\,<\\,\\epsilon/(4B)$ and pick $N^{\\prime}$ large enough so that for all $n \\geq N^{\\prime}$  \n\n$$\n\\left|b_{n}\\,-\\,b_{n\\,-1}\\right|\\,\\leq\\,\\frac{\\epsilon}{2a N}.\n$$  \n\nThen for $\\pmb{n} \\geq N + N^{\\prime}$, we have  \n\n$$\n\\begin{array}{r l}{\\bigg|\\displaystyle\\sum_{k=0}^{n}a_{k}(b_{n}\\,-\\,b_{n-k})\\bigg|\\,}&{\\le\\,\\displaystyle\\sum_{k=0}^{N}a_{k}\\big|b_{n}\\,-\\,b_{n-k}\\big|\\,+\\,\\displaystyle\\sum_{k=N+1}^{n}a_{k}\\big(\\big|b_{n}\\big|\\,+\\,\\big|b_{n-k}\\big|\\big)\\,}\\\\ &{\\le\\,\\displaystyle\\sum_{k=0}^{N}a_{k}\\,\\displaystyle\\sum_{j=0}^{k-1}\\big|b_{n-j}\\,-\\,b_{n-j-1}\\big|\\,+\\,2B\\,\\displaystyle\\sum_{k=N+1}^{n}a_{k}\\,}\\\\ &{\\le\\,\\displaystyle\\sum_{k=0}^{N}a_{k}\\,\\displaystyle\\sum_{j=0}^{k-1}\\frac{\\epsilon}{2a N}\\,+\\,\\frac{\\epsilon}{4B}\\cdot2B,\\quad\\mathrm{since}\\,\\,\\,n\\,-\\,j\\,\\ge\\,N^{\\prime}\\,}\\\\ &{\\le\\,\\displaystyle\\frac{\\epsilon}{2a}\\,\\displaystyle\\sum_{k=0}^{N}a_{k}\\,+\\,\\frac{\\epsilon}{2}\\,}\\\\ &{\\le\\,\\epsilon.}&\\end{array}\n$$  \n\nTheorem 9-7: Let $i, j$ and $k$ be arbitrary states in a current Markov chain which is either null or noncyclic ergodic. Then  \n\n$$\n\\operatorname*{lim}_{n\\,\\rightarrow\\,\\infty}\\,[(N_{k k}^{(n)}\\,-\\,N_{i k}^{(n)})\\alpha_{j}/\\alpha_{k}\\,+\\,N_{i j}^{(n)}\\,-\\,N_{k j}^{(n)}]\\,=\\,{^k N}_{i j}.\n$$  \n\nPROOF: We may assume that neither $i$ nor $j$ equals $k$ since otherwise both sides are clearly zero. We begin by establishing four equations:  \n\n$$\n\\begin{array}{l l}{{(1)}}&{{N_{k k}^{(n)}=\\displaystyle\\sum_{\\nu=0}^{\\infty}F_{i k}^{(\\nu)}N_{k k}^{(n)}}}\\\\ {{(2)}}&{{N_{i k}^{(n)}=\\displaystyle\\sum_{\\nu=0}^{n}F_{i k}^{(\\nu)}N_{k k}^{(n-\\nu)}}}\\\\ {{(3)}}&{{N_{k j}^{(n)}=\\displaystyle\\sum_{\\nu=0}^{\\infty}F_{i k}^{(\\nu)}N_{k j}^{(n)}}}\\\\ {{(4)}}&{{N_{i j}^{(n)}=\\displaystyle\\sum_{\\nu=0}^{n}F_{i k}^{(\\nu)}N_{k j}^{(n-\\nu)}\\,+\\,{^k}N_{i j}^{(n)}.}}\\end{array}\n$$  \n\nEquations (1) and (3) follow the fact that $\\sum\\,F_{i k}^{(v)}\\,=\\,H_{i k}\\,=\\,1\\,$ Equation (2) comes from Theorem 4-11 with the random time $\\mathbf t = \\operatorname*{min} (\\mathbf{t}_{k},\\,n)$, and equation (4) is a similar result, except that the sum has been broken into two parts representing what happens after and before state $k$ is reached for the first time.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Equation (2) comes from Theorem 4-11 with the random time t = min (t_k, n), and equation (4) is a similar result, except that the sum has been broken into two parts",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM40-Denumerable_Markov_Chains-with_a_chapter_of_Markov_Random_Fields_by_David_Griffeath1976.pdf_256",
        "ID": "0f1b88df-b61c-44e4-aa74-cb72810bd9bd",
        "questions": "In the given proof, what is the purpose of choosing N sufficiently large?",
        "answers": "to ensure that \u2211k>N ak < \u03b5/(4B)",
        "context": "PROOF: Let $\\epsilon > 0$ be given. Choose $N$ sufficiently large that $\\textstyle\\sum_{k\\,>\\,N}a_{k}\\,<\\,\\epsilon/(4B)$ and pick $N^{\\prime}$ large enough so that for all $n \\geq N^{\\prime}$  \n\n$$\n\\left|b_{n}\\,-\\,b_{n\\,-1}\\right|\\,\\leq\\,\\frac{\\epsilon}{2a N}.\n$$  \n\nThen for $\\pmb{n} \\geq N + N^{\\prime}$, we have  \n\n$$\n\\begin{array}{r l}{\\bigg|\\displaystyle\\sum_{k=0}^{n}a_{k}(b_{n}\\,-\\,b_{n-k})\\bigg|\\,}&{\\le\\,\\displaystyle\\sum_{k=0}^{N}a_{k}\\big|b_{n}\\,-\\,b_{n-k}\\big|\\,+\\,\\displaystyle\\sum_{k=N+1}^{n}a_{k}\\big(\\big|b_{n}\\big|\\,+\\,\\big|b_{n-k}\\big|\\big)\\,}\\\\ &{\\le\\,\\displaystyle\\sum_{k=0}^{N}a_{k}\\,\\displaystyle\\sum_{j=0}^{k-1}\\big|b_{n-j}\\,-\\,b_{n-j-1}\\big|\\,+\\,2B\\,\\displaystyle\\sum_{k=N+1}^{n}a_{k}\\,}\\\\ &{\\le\\,\\displaystyle\\sum_{k=0}^{N}a_{k}\\,\\displaystyle\\sum_{j=0}^{k-1}\\frac{\\epsilon}{2a N}\\,+\\,\\frac{\\epsilon}{4B}\\cdot2B,\\quad\\mathrm{since}\\,\\,\\,n\\,-\\,j\\,\\ge\\,N^{\\prime}\\,}\\\\ &{\\le\\,\\displaystyle\\frac{\\epsilon}{2a}\\,\\displaystyle\\sum_{k=0}^{N}a_{k}\\,+\\,\\frac{\\epsilon}{2}\\,}\\\\ &{\\le\\,\\epsilon.}&\\end{array}\n$$  \n\nTheorem 9-7: Let $i, j$ and $k$ be arbitrary states in a current Markov chain which is either null or noncyclic ergodic. Then  \n\n$$\n\\operatorname*{lim}_{n\\,\\rightarrow\\,\\infty}\\,[(N_{k k}^{(n)}\\,-\\,N_{i k}^{(n)})\\alpha_{j}/\\alpha_{k}\\,+\\,N_{i j}^{(n)}\\,-\\,N_{k j}^{(n)}]\\,=\\,{^k N}_{i j}.\n$$  \n\nPROOF: We may assume that neither $i$ nor $j$ equals $k$ since otherwise both sides are clearly zero. We begin by establishing four equations:  \n\n$$\n\\begin{array}{l l}{{(1)}}&{{N_{k k}^{(n)}=\\displaystyle\\sum_{\\nu=0}^{\\infty}F_{i k}^{(\\nu)}N_{k k}^{(n)}}}\\\\ {{(2)}}&{{N_{i k}^{(n)}=\\displaystyle\\sum_{\\nu=0}^{n}F_{i k}^{(\\nu)}N_{k k}^{(n-\\nu)}}}\\\\ {{(3)}}&{{N_{k j}^{(n)}=\\displaystyle\\sum_{\\nu=0}^{\\infty}F_{i k}^{(\\nu)}N_{k j}^{(n)}}}\\\\ {{(4)}}&{{N_{i j}^{(n)}=\\displaystyle\\sum_{\\nu=0}^{n}F_{i k}^{(\\nu)}N_{k j}^{(n-\\nu)}\\,+\\,{^k}N_{i j}^{(n)}.}}\\end{array}\n$$  \n\nEquations (1) and (3) follow the fact that $\\sum\\,F_{i k}^{(v)}\\,=\\,H_{i k}\\,=\\,1\\,$ Equation (2) comes from Theorem 4-11 with the random time $\\mathbf t = \\operatorname*{min} (\\mathbf{t}_{k},\\,n)$, and equation (4) is a similar result, except that the sum has been broken into two parts representing what happens after and before state $k$ is reached for the first time.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Choose N sufficiently large that \u2211k>N ak < \u03b5/(4B)",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM40-Denumerable_Markov_Chains-with_a_chapter_of_Markov_Random_Fields_by_David_Griffeath1976.pdf_256",
        "ID": "0f204c42-32eb-473d-9210-917fa3838004",
        "questions": "What is the summation upper limit used in the first key equation for $N_{k k}^{(n)}$ in the proof of Theorem 9-7 regarding a current Markov chain?",
        "answers": "$\\sum_{\\nu=0}^{\\infty}F_{i k}^{(\\nu)} N_{k k}^{(n)}$",
        "context": "PROOF: Let $\\epsilon > 0$ be given. Choose $N$ sufficiently large that $\\textstyle\\sum_{k\\,>\\,N}a_{k}\\,<\\,\\epsilon/(4B)$ and pick $N^{\\prime}$ large enough so that for all $n \\geq N^{\\prime}$  \n\n$$\n\\left|b_{n}\\,-\\,b_{n\\,-1}\\right|\\,\\leq\\,\\frac{\\epsilon}{2a N}.\n$$  \n\nThen for $\\pmb{n} \\geq N + N^{\\prime}$, we have  \n\n$$\n\\begin{array}{r l}{\\bigg|\\displaystyle\\sum_{k=0}^{n}a_{k}(b_{n}\\,-\\,b_{n-k})\\bigg|\\,}&{\\le\\,\\displaystyle\\sum_{k=0}^{N}a_{k}\\big|b_{n}\\,-\\,b_{n-k}\\big|\\,+\\,\\displaystyle\\sum_{k=N+1}^{n}a_{k}\\big(\\big|b_{n}\\big|\\,+\\,\\big|b_{n-k}\\big|\\big)\\,}\\\\ &{\\le\\,\\displaystyle\\sum_{k=0}^{N}a_{k}\\,\\displaystyle\\sum_{j=0}^{k-1}\\big|b_{n-j}\\,-\\,b_{n-j-1}\\big|\\,+\\,2B\\,\\displaystyle\\sum_{k=N+1}^{n}a_{k}\\,}\\\\ &{\\le\\,\\displaystyle\\sum_{k=0}^{N}a_{k}\\,\\displaystyle\\sum_{j=0}^{k-1}\\frac{\\epsilon}{2a N}\\,+\\,\\frac{\\epsilon}{4B}\\cdot2B,\\quad\\mathrm{since}\\,\\,\\,n\\,-\\,j\\,\\ge\\,N^{\\prime}\\,}\\\\ &{\\le\\,\\displaystyle\\frac{\\epsilon}{2a}\\,\\displaystyle\\sum_{k=0}^{N}a_{k}\\,+\\,\\frac{\\epsilon}{2}\\,}\\\\ &{\\le\\,\\epsilon.}&\\end{array}\n$$  \n\nTheorem 9-7: Let $i, j$ and $k$ be arbitrary states in a current Markov chain which is either null or noncyclic ergodic. Then  \n\n$$\n\\operatorname*{lim}_{n\\,\\rightarrow\\,\\infty}\\,[(N_{k k}^{(n)}\\,-\\,N_{i k}^{(n)})\\alpha_{j}/\\alpha_{k}\\,+\\,N_{i j}^{(n)}\\,-\\,N_{k j}^{(n)}]\\,=\\,{^k N}_{i j}.\n$$  \n\nPROOF: We may assume that neither $i$ nor $j$ equals $k$ since otherwise both sides are clearly zero. We begin by establishing four equations:  \n\n$$\n\\begin{array}{l l}{{(1)}}&{{N_{k k}^{(n)}=\\displaystyle\\sum_{\\nu=0}^{\\infty}F_{i k}^{(\\nu)}N_{k k}^{(n)}}}\\\\ {{(2)}}&{{N_{i k}^{(n)}=\\displaystyle\\sum_{\\nu=0}^{n}F_{i k}^{(\\nu)}N_{k k}^{(n-\\nu)}}}\\\\ {{(3)}}&{{N_{k j}^{(n)}=\\displaystyle\\sum_{\\nu=0}^{\\infty}F_{i k}^{(\\nu)}N_{k j}^{(n)}}}\\\\ {{(4)}}&{{N_{i j}^{(n)}=\\displaystyle\\sum_{\\nu=0}^{n}F_{i k}^{(\\nu)}N_{k j}^{(n-\\nu)}\\,+\\,{^k}N_{i j}^{(n)}.}}\\end{array}\n$$  \n\nEquations (1) and (3) follow the fact that $\\sum\\,F_{i k}^{(v)}\\,=\\,H_{i k}\\,=\\,1\\,$ Equation (2) comes from Theorem 4-11 with the random time $\\mathbf t = \\operatorname*{min} (\\mathbf{t}_{k},\\,n)$, and equation (4) is a similar result, except that the sum has been broken into two parts representing what happens after and before state $k$ is reached for the first time.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "{N_{k k}^{(n)}=\\displaystyle\\sum_{\\nu=0}^{\\infty}F_{i k}^{(\\nu)}N_{k k}^{(n)}}",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/GTM40-Denumerable_Markov_Chains-with_a_chapter_of_Markov_Random_Fields_by_David_Griffeath1976.pdf_256",
        "ID": "0f266902-f574-455f-8e85-6b8622c66d8e",
        "questions": "In the provided proof involving Markov chains, what is the technical difference between equations (2) and (4) in terms of their summation and additional terms?",
        "answers": "Equation (2) uses $\\sum_{\\nu=0}^{n} F_{i k}^{(\\nu)} N_{k k}^{(n-\\nu)}$ whereas equation (4) includes an additional term $+ {^k}N_{i j}^{(n)}$",
        "context": "PROOF: Let $\\epsilon > 0$ be given. Choose $N$ sufficiently large that $\\textstyle\\sum_{k\\,>\\,N}a_{k}\\,<\\,\\epsilon/(4B)$ and pick $N^{\\prime}$ large enough so that for all $n \\geq N^{\\prime}$  \n\n$$\n\\left|b_{n}\\,-\\,b_{n\\,-1}\\right|\\,\\leq\\,\\frac{\\epsilon}{2a N}.\n$$  \n\nThen for $\\pmb{n} \\geq N + N^{\\prime}$, we have  \n\n$$\n\\begin{array}{r l}{\\bigg|\\displaystyle\\sum_{k=0}^{n}a_{k}(b_{n}\\,-\\,b_{n-k})\\bigg|\\,}&{\\le\\,\\displaystyle\\sum_{k=0}^{N}a_{k}\\big|b_{n}\\,-\\,b_{n-k}\\big|\\,+\\,\\displaystyle\\sum_{k=N+1}^{n}a_{k}\\big(\\big|b_{n}\\big|\\,+\\,\\big|b_{n-k}\\big|\\big)\\,}\\\\ &{\\le\\,\\displaystyle\\sum_{k=0}^{N}a_{k}\\,\\displaystyle\\sum_{j=0}^{k-1}\\big|b_{n-j}\\,-\\,b_{n-j-1}\\big|\\,+\\,2B\\,\\displaystyle\\sum_{k=N+1}^{n}a_{k}\\,}\\\\ &{\\le\\,\\displaystyle\\sum_{k=0}^{N}a_{k}\\,\\displaystyle\\sum_{j=0}^{k-1}\\frac{\\epsilon}{2a N}\\,+\\,\\frac{\\epsilon}{4B}\\cdot2B,\\quad\\mathrm{since}\\,\\,\\,n\\,-\\,j\\,\\ge\\,N^{\\prime}\\,}\\\\ &{\\le\\,\\displaystyle\\frac{\\epsilon}{2a}\\,\\displaystyle\\sum_{k=0}^{N}a_{k}\\,+\\,\\frac{\\epsilon}{2}\\,}\\\\ &{\\le\\,\\epsilon.}&\\end{array}\n$$  \n\nTheorem 9-7: Let $i, j$ and $k$ be arbitrary states in a current Markov chain which is either null or noncyclic ergodic. Then  \n\n$$\n\\operatorname*{lim}_{n\\,\\rightarrow\\,\\infty}\\,[(N_{k k}^{(n)}\\,-\\,N_{i k}^{(n)})\\alpha_{j}/\\alpha_{k}\\,+\\,N_{i j}^{(n)}\\,-\\,N_{k j}^{(n)}]\\,=\\,{^k N}_{i j}.\n$$  \n\nPROOF: We may assume that neither $i$ nor $j$ equals $k$ since otherwise both sides are clearly zero. We begin by establishing four equations:  \n\n$$\n\\begin{array}{l l}{{(1)}}&{{N_{k k}^{(n)}=\\displaystyle\\sum_{\\nu=0}^{\\infty}F_{i k}^{(\\nu)}N_{k k}^{(n)}}}\\\\ {{(2)}}&{{N_{i k}^{(n)}=\\displaystyle\\sum_{\\nu=0}^{n}F_{i k}^{(\\nu)}N_{k k}^{(n-\\nu)}}}\\\\ {{(3)}}&{{N_{k j}^{(n)}=\\displaystyle\\sum_{\\nu=0}^{\\infty}F_{i k}^{(\\nu)}N_{k j}^{(n)}}}\\\\ {{(4)}}&{{N_{i j}^{(n)}=\\displaystyle\\sum_{\\nu=0}^{n}F_{i k}^{(\\nu)}N_{k j}^{(n-\\nu)}\\,+\\,{^k}N_{i j}^{(n)}.}}\\end{array}\n$$  \n\nEquations (1) and (3) follow the fact that $\\sum\\,F_{i k}^{(v)}\\,=\\,H_{i k}\\,=\\,1\\,$ Equation (2) comes from Theorem 4-11 with the random time $\\mathbf t = \\operatorname*{min} (\\mathbf{t}_{k},\\,n)$, and equation (4) is a similar result, except that the sum has been broken into two parts representing what happens after and before state $k$ is reached for the first time.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "{N_{i k}^{(n)}=\\displaystyle\\sum_{\\nu=0}^{n}F_{i k}^{(\\nu)}N_{k k}^{(n-\\nu)}}\n{N_{i j}^{(n)}=\\displaystyle\\sum_{\\nu=0}^{n}F_{i k}^{(\\nu)}N_{k j}^{(n-\\nu)}\\,+\\,{^k}N_{i j}^{(n)}.}",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/GTM40-Denumerable_Markov_Chains-with_a_chapter_of_Markov_Random_Fields_by_David_Griffeath1976.pdf_256",
        "ID": "0f29ad2b-e8f6-477b-93c8-aca1d8ffd19e",
        "questions": "How does the proof of convergence in the given document ensure that for $n \\geq N + N^{\\prime}$, the sum involving small differences in $b$ terms remains bounded by $\\epsilon$?",
        "answers": "By constructing the proof such that the sum $\\displaystyle\\sum_{k=0}^{N}a_{k}\\,\\displaystyle\\sum_{j=0}^{k-1}\\frac{\\epsilon}{2a N}$ and $\\displaystyle\\frac{\\epsilon}{2a}\\,\\displaystyle\\sum_{k=0}^{N}a_{k}\\,+\\,\\frac{\\epsilon}{2}$ collectively stay within $\\epsilon$",
        "context": "PROOF: Let $\\epsilon > 0$ be given. Choose $N$ sufficiently large that $\\textstyle\\sum_{k\\,>\\,N}a_{k}\\,<\\,\\epsilon/(4B)$ and pick $N^{\\prime}$ large enough so that for all $n \\geq N^{\\prime}$  \n\n$$\n\\left|b_{n}\\,-\\,b_{n\\,-1}\\right|\\,\\leq\\,\\frac{\\epsilon}{2a N}.\n$$  \n\nThen for $\\pmb{n} \\geq N + N^{\\prime}$, we have  \n\n$$\n\\begin{array}{r l}{\\bigg|\\displaystyle\\sum_{k=0}^{n}a_{k}(b_{n}\\,-\\,b_{n-k})\\bigg|\\,}&{\\le\\,\\displaystyle\\sum_{k=0}^{N}a_{k}\\big|b_{n}\\,-\\,b_{n-k}\\big|\\,+\\,\\displaystyle\\sum_{k=N+1}^{n}a_{k}\\big(\\big|b_{n}\\big|\\,+\\,\\big|b_{n-k}\\big|\\big)\\,}\\\\ &{\\le\\,\\displaystyle\\sum_{k=0}^{N}a_{k}\\,\\displaystyle\\sum_{j=0}^{k-1}\\big|b_{n-j}\\,-\\,b_{n-j-1}\\big|\\,+\\,2B\\,\\displaystyle\\sum_{k=N+1}^{n}a_{k}\\,}\\\\ &{\\le\\,\\displaystyle\\sum_{k=0}^{N}a_{k}\\,\\displaystyle\\sum_{j=0}^{k-1}\\frac{\\epsilon}{2a N}\\,+\\,\\frac{\\epsilon}{4B}\\cdot2B,\\quad\\mathrm{since}\\,\\,\\,n\\,-\\,j\\,\\ge\\,N^{\\prime}\\,}\\\\ &{\\le\\,\\displaystyle\\frac{\\epsilon}{2a}\\,\\displaystyle\\sum_{k=0}^{N}a_{k}\\,+\\,\\frac{\\epsilon}{2}\\,}\\\\ &{\\le\\,\\epsilon.}&\\end{array}\n$$  \n\nTheorem 9-7: Let $i, j$ and $k$ be arbitrary states in a current Markov chain which is either null or noncyclic ergodic. Then  \n\n$$\n\\operatorname*{lim}_{n\\,\\rightarrow\\,\\infty}\\,[(N_{k k}^{(n)}\\,-\\,N_{i k}^{(n)})\\alpha_{j}/\\alpha_{k}\\,+\\,N_{i j}^{(n)}\\,-\\,N_{k j}^{(n)}]\\,=\\,{^k N}_{i j}.\n$$  \n\nPROOF: We may assume that neither $i$ nor $j$ equals $k$ since otherwise both sides are clearly zero. We begin by establishing four equations:  \n\n$$\n\\begin{array}{l l}{{(1)}}&{{N_{k k}^{(n)}=\\displaystyle\\sum_{\\nu=0}^{\\infty}F_{i k}^{(\\nu)}N_{k k}^{(n)}}}\\\\ {{(2)}}&{{N_{i k}^{(n)}=\\displaystyle\\sum_{\\nu=0}^{n}F_{i k}^{(\\nu)}N_{k k}^{(n-\\nu)}}}\\\\ {{(3)}}&{{N_{k j}^{(n)}=\\displaystyle\\sum_{\\nu=0}^{\\infty}F_{i k}^{(\\nu)}N_{k j}^{(n)}}}\\\\ {{(4)}}&{{N_{i j}^{(n)}=\\displaystyle\\sum_{\\nu=0}^{n}F_{i k}^{(\\nu)}N_{k j}^{(n-\\nu)}\\,+\\,{^k}N_{i j}^{(n)}.}}\\end{array}\n$$  \n\nEquations (1) and (3) follow the fact that $\\sum\\,F_{i k}^{(v)}\\,=\\,H_{i k}\\,=\\,1\\,$ Equation (2) comes from Theorem 4-11 with the random time $\\mathbf t = \\operatorname*{min} (\\mathbf{t}_{k},\\,n)$, and equation (4) is a similar result, except that the sum has been broken into two parts representing what happens after and before state $k$ is reached for the first time.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "{\\bigg|\\displaystyle\\sum_{k=0}^{n}a_{k}(b_{n}\\,-\\,b_{n-k})\\bigg|\\,}&{\\le\\,\\displaystyle\\sum_{k=0}^{N}a_{k}\\big|b_{n}\\,-\\,b_{n-k}\\big|\\,+\\,\\displaystyle\\sum_{k=N+1}^{n}a_{k}\\big(\\big|b_{n}\\big|\\,+\\,\\big|b_{n-k}\\big|\\big)\\,}\\ &{\\le\\,\\displaystyle\\sum_{k=0}^{N}a_{k}\\,\\displaystyle\\sum_{j=0}^{k-1}\\big|b_{n-j}\\,-\\,b_{n-j-1}\\big|\\,+\\,2B\\,\\displaystyle\\sum_{k=N+1}^{n}a_{k}\\,}\\ &{\\le\\,\\displaystyle\\sum_{k=0}^{N}a_{k}\\,\\displaystyle\\sum_{j=0}^{k-1}\\frac{\\epsilon}{2a N}\\,+\\,\\frac{\\epsilon}{4B}\\cdot2B,\\quad\\mathrm{since}\\,\\,\\,n\\,-\\,j\\,\\ge\\,N^{\\prime}\\,}\\ &{\\le\\,\\displaystyle\\frac{\\epsilon}{2a}\\,\\displaystyle\\sum_{k=0}^{N}a_{k}\\,+\\,\\frac{\\epsilon}{2}\\,}\\ &{\\le\\,\\epsilon.}",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/fa7aec4efb728534ef32c172197c9560097c6d0e4893fe6b20242a566ef033d1.pdf_4",
        "ID": "0f2a4e48-453d-4e11-b3a6-13e8a01c26cd",
        "questions": "What was the presence percentage of Schizachyrium scoparium in 2012 at Bass River Recreation Area, Ottawa County, MI, US?",
        "answers": "100.0%",
        "context": "$\n\\caption{Table 2. Seeded species presence as a percent of the 48 total treatment plots as Bass River Recreation Area, Ottawa County, MI, US. Species are ordered in terms of presence during 2011. Column C corresponds to the coefficient of conservation for each species specific to Michigan (MDNR 2001)}\n\\begin{tabular}{|l|l|l|c|c|c|}\n \nFamily & Species & Common Name & c & 2011 & 2012 \\\\\n \nPoaceae & Andropogon gerardii & Big Bluestem & 5 & 100.0\\% & 97.9\\% \\\\\n \nPoaceae & Schizachyrium scoparium & Little Bluestem & 5 & 100.0\\% & 100.0\\% \\\\\n \nPoaceae & Sorghastrum nutans & Indiangrass & 6 & 100.0\\% & 100.0\\% \\\\\n \nLamiaceae & Monarda fistulosa & Wild Bergamot & 2 & 97.9\\% & 95.8\\% \\\\\n \nAsteraceae & Coreopsis lanceolata & Lanceleaf Tickseed & 8 & 93.8\\% & 93.8\\% \\\\\n \nLamiaceae & Monarda punctata & Spotted Beebalm & 4 & 87.5\\% & 66.7\\% \\\\\n \nAsteraceae & Rudbeckia hirta & Blackeyed Susan & 1 & 83.3\\% & 85.4\\% \\\\\n \nApocynaceae & Asclepias tuberosa & Butterfly Milkweed & 5 & 77.1\\% & 62.5\\% \\\\\n \nPoaceae & Elymus canadensis & Canada Wildrye & 4 & 43.8\\% & 16.7\\% \\\\\n \nAsteraceae & Ratibida pinnata & Pinnate Prairie Coneflower & 4 & 39.6\\% & 29.2\\% \\\\\n \nAsteraceae & Pseudognaphalium helleri & Heller's Cudweed & 2 & 12.5\\% & 18.8\\% \\\\\n \nFabaceae & Lupinus perennis & Sundial Lupine & 7 & 12.5\\% & 0.0\\% \\\\\n \nPoaceae & Panicum virgatum & Switchgrass & 4 & 12.5\\% & 8.3\\% \\\\\n \nAsteraceae & Solidago nemoralis & Gray Goldenrod & 2 & 10.4\\% & 8.3\\% \\\\\n \nAsteraceae & Coreopsis tripteris & Tall Tickseed & 7 & 8.3\\% & 2.1\\% \\\\\n \nFabaceae & Lespedeza capitata & Roundhead Lespedeza & 5 & 6.3\\% & 8.3\\% \\\\\n \nVerbenaceae & Verbena stricta & Hoary Verbena & 4 & 2.1\\% & 4.2\\% \\\\\n \nAsteraceae & Coreopsis palmata & Stiff Tickseed & 10 & 2.1\\% & 2.1\\% \\\\\n \nAsteraceae & Helianthus occidentalis & Fewleaf Sunflower & 8 & 2.1\\% & 2.1\\% \\\\\n \nAsteraceae & Solidago speciosa & Showy Goldenrod & 5 & 2.1\\% & 0.0\\% \\\\\n \nAsteraceae & Solidago juncea & Early Goldenrod & 3 & 0.0\\% & 0.0\\% \\\\\n \nFabaceae & Tephrosia virginiana & Virginia Tephrosia & 10 & 0.0\\% & 0.0\\% \\\\\n \nCommelinaceae & Tradescantia ohiensis & Bluejacket & 5 & 0.0\\% & 0.0\\% \\\\\n \n\\end{tabular}\n$\n\nEntailed dividing each $5\\,\\textrm{m}$ by $5\\,\\textrm{m}$ plot into quarters, with two researchers each estimating the cover of two quarters. During both years, each researcher consistently examined the same two quarters within each plot. To standardize visual estimates among researchers, we referred to published area charts (Anderson 1986), and used $0.1\\;\\mathrm{m}^{2}$ PVC frames as a standard area reference. Following data collection, we calculated the relative percent cover $(p_{i})$ of each species on each plot by dividing the summed total cover of each species by the summed total cover of the plot.  \n\n# Data Analysis  \n\nUsing the relative percent cover calculated for each year, we determined plot diversity using the Shannon index of diversity:  \n\n$$\n1)\\;{\\mathrm{H}}^{\\prime}=-\\Sigma\\,p_{i}\\log p_{i}\n$$  \n\nand Simpson's index of diversity:  \n\n$$\n\\mathbf{D}=1\\!-\\!\\Sigma\\,p_{i}^{2}\n$$  \n\n(McCune and Grace 2002). As recommended by Peet (1974), we used the exponential of $\\mathrm{H}^{\\prime}$ for analysis, as this indicates the functional number of species in the sample. Interpretations of the results remain the same, with higher values indicating higher diversity. Simpson\u2019s index has a range from zero, with a single species present, to one, maximum diversity (Peet 1974). Estimates of percent cover have been used successfully in previous studies to calculate these diversity indices (Potvin and Vasseur 1997, Tilman et al. 1997), and avoid errors resulting from miscounting clonal species if density had been used.  \n\nTo evaluate community quality, we calculated the mean coefficient of conservatism ($\\overline{{\\mathbf{C}}}$) , and a floristic quality index (FQI) for each plot to distinguish among treatment combinations containing ubiquitous native plants and those containing species more likely to occur in undisturbed native plant communities. These methods rely on coefficients of conservatism specific to Michigan (MDNR 2001), ranging from zero, representing ubiquitous native species, to ten, representing highly conserved native species (Taft et al. 1997). FQI was calculated for each plot by multiplying the $\\overline{{\\mathbf{C}}}$ for the plot by the square root of the number of native species on the plot (Packard and Mutel 1997). Native tree and shrub species are not part of the target prairie community and were excluded from FQI and $\\overline{{\\mathbf{C}}}$ analysis.  \n\nFor analyses of community composition, we classified species into one of six groups: non-native forbs, knapweed, non-native grasses, native graminoids, native forbs, and tree/shrub species. The non-native forbs group does not include knapweed. As the dominant invasive species and a focus of our research, knapweed was classified independently. Following this classification, we calculated the by summing the relative percent",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "table",
        "evidence_context": "Poaceae & Schizachyrium scoparium & Little Bluestem & 5 & 100.0\\% & 100.0\\%",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/fa7aec4efb728534ef32c172197c9560097c6d0e4893fe6b20242a566ef033d1.pdf_4",
        "ID": "0f2f6ba7-0166-472f-a41c-d0b73aa086f4",
        "questions": "What coefficient of conservation is assigned to Asclepias tuberosa specific to Michigan according to MDNR 2001?",
        "answers": "5",
        "context": "$\n\\caption{Table 2. Seeded species presence as a percent of the 48 total treatment plots as Bass River Recreation Area, Ottawa County, MI, US. Species are ordered in terms of presence during 2011. Column C corresponds to the coefficient of conservation for each species specific to Michigan (MDNR 2001)}\n\\begin{tabular}{|l|l|l|c|c|c|}\n \nFamily & Species & Common Name & c & 2011 & 2012 \\\\\n \nPoaceae & Andropogon gerardii & Big Bluestem & 5 & 100.0\\% & 97.9\\% \\\\\n \nPoaceae & Schizachyrium scoparium & Little Bluestem & 5 & 100.0\\% & 100.0\\% \\\\\n \nPoaceae & Sorghastrum nutans & Indiangrass & 6 & 100.0\\% & 100.0\\% \\\\\n \nLamiaceae & Monarda fistulosa & Wild Bergamot & 2 & 97.9\\% & 95.8\\% \\\\\n \nAsteraceae & Coreopsis lanceolata & Lanceleaf Tickseed & 8 & 93.8\\% & 93.8\\% \\\\\n \nLamiaceae & Monarda punctata & Spotted Beebalm & 4 & 87.5\\% & 66.7\\% \\\\\n \nAsteraceae & Rudbeckia hirta & Blackeyed Susan & 1 & 83.3\\% & 85.4\\% \\\\\n \nApocynaceae & Asclepias tuberosa & Butterfly Milkweed & 5 & 77.1\\% & 62.5\\% \\\\\n \nPoaceae & Elymus canadensis & Canada Wildrye & 4 & 43.8\\% & 16.7\\% \\\\\n \nAsteraceae & Ratibida pinnata & Pinnate Prairie Coneflower & 4 & 39.6\\% & 29.2\\% \\\\\n \nAsteraceae & Pseudognaphalium helleri & Heller's Cudweed & 2 & 12.5\\% & 18.8\\% \\\\\n \nFabaceae & Lupinus perennis & Sundial Lupine & 7 & 12.5\\% & 0.0\\% \\\\\n \nPoaceae & Panicum virgatum & Switchgrass & 4 & 12.5\\% & 8.3\\% \\\\\n \nAsteraceae & Solidago nemoralis & Gray Goldenrod & 2 & 10.4\\% & 8.3\\% \\\\\n \nAsteraceae & Coreopsis tripteris & Tall Tickseed & 7 & 8.3\\% & 2.1\\% \\\\\n \nFabaceae & Lespedeza capitata & Roundhead Lespedeza & 5 & 6.3\\% & 8.3\\% \\\\\n \nVerbenaceae & Verbena stricta & Hoary Verbena & 4 & 2.1\\% & 4.2\\% \\\\\n \nAsteraceae & Coreopsis palmata & Stiff Tickseed & 10 & 2.1\\% & 2.1\\% \\\\\n \nAsteraceae & Helianthus occidentalis & Fewleaf Sunflower & 8 & 2.1\\% & 2.1\\% \\\\\n \nAsteraceae & Solidago speciosa & Showy Goldenrod & 5 & 2.1\\% & 0.0\\% \\\\\n \nAsteraceae & Solidago juncea & Early Goldenrod & 3 & 0.0\\% & 0.0\\% \\\\\n \nFabaceae & Tephrosia virginiana & Virginia Tephrosia & 10 & 0.0\\% & 0.0\\% \\\\\n \nCommelinaceae & Tradescantia ohiensis & Bluejacket & 5 & 0.0\\% & 0.0\\% \\\\\n \n\\end{tabular}\n$\n\nEntailed dividing each $5\\,\\textrm{m}$ by $5\\,\\textrm{m}$ plot into quarters, with two researchers each estimating the cover of two quarters. During both years, each researcher consistently examined the same two quarters within each plot. To standardize visual estimates among researchers, we referred to published area charts (Anderson 1986), and used $0.1\\;\\mathrm{m}^{2}$ PVC frames as a standard area reference. Following data collection, we calculated the relative percent cover $(p_{i})$ of each species on each plot by dividing the summed total cover of each species by the summed total cover of the plot.  \n\n# Data Analysis  \n\nUsing the relative percent cover calculated for each year, we determined plot diversity using the Shannon index of diversity:  \n\n$$\n1)\\;{\\mathrm{H}}^{\\prime}=-\\Sigma\\,p_{i}\\log p_{i}\n$$  \n\nand Simpson's index of diversity:  \n\n$$\n\\mathbf{D}=1\\!-\\!\\Sigma\\,p_{i}^{2}\n$$  \n\n(McCune and Grace 2002). As recommended by Peet (1974), we used the exponential of $\\mathrm{H}^{\\prime}$ for analysis, as this indicates the functional number of species in the sample. Interpretations of the results remain the same, with higher values indicating higher diversity. Simpson\u2019s index has a range from zero, with a single species present, to one, maximum diversity (Peet 1974). Estimates of percent cover have been used successfully in previous studies to calculate these diversity indices (Potvin and Vasseur 1997, Tilman et al. 1997), and avoid errors resulting from miscounting clonal species if density had been used.  \n\nTo evaluate community quality, we calculated the mean coefficient of conservatism ($\\overline{{\\mathbf{C}}}$) , and a floristic quality index (FQI) for each plot to distinguish among treatment combinations containing ubiquitous native plants and those containing species more likely to occur in undisturbed native plant communities. These methods rely on coefficients of conservatism specific to Michigan (MDNR 2001), ranging from zero, representing ubiquitous native species, to ten, representing highly conserved native species (Taft et al. 1997). FQI was calculated for each plot by multiplying the $\\overline{{\\mathbf{C}}}$ for the plot by the square root of the number of native species on the plot (Packard and Mutel 1997). Native tree and shrub species are not part of the target prairie community and were excluded from FQI and $\\overline{{\\mathbf{C}}}$ analysis.  \n\nFor analyses of community composition, we classified species into one of six groups: non-native forbs, knapweed, non-native grasses, native graminoids, native forbs, and tree/shrub species. The non-native forbs group does not include knapweed. As the dominant invasive species and a focus of our research, knapweed was classified independently. Following this classification, we calculated the by summing the relative percent",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Numeric",
        "evidence_source": "table",
        "evidence_context": "Apocynaceae & Asclepias tuberosa & Butterfly Milkweed & 5 & 77.1\\% & 62.5\\%",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/fa7aec4efb728534ef32c172197c9560097c6d0e4893fe6b20242a566ef033d1.pdf_4",
        "ID": "0f3ae7b3-dbe1-4b6e-9513-31f884f15545",
        "questions": "According to the research analysis at Bass River Recreation Area, what formula is used to calculate Simpson's index of diversity?",
        "answers": "1-\u03a3p_i^2",
        "context": "$\n\\caption{Table 2. Seeded species presence as a percent of the 48 total treatment plots as Bass River Recreation Area, Ottawa County, MI, US. Species are ordered in terms of presence during 2011. Column C corresponds to the coefficient of conservation for each species specific to Michigan (MDNR 2001)}\n\\begin{tabular}{|l|l|l|c|c|c|}\n \nFamily & Species & Common Name & c & 2011 & 2012 \\\\\n \nPoaceae & Andropogon gerardii & Big Bluestem & 5 & 100.0\\% & 97.9\\% \\\\\n \nPoaceae & Schizachyrium scoparium & Little Bluestem & 5 & 100.0\\% & 100.0\\% \\\\\n \nPoaceae & Sorghastrum nutans & Indiangrass & 6 & 100.0\\% & 100.0\\% \\\\\n \nLamiaceae & Monarda fistulosa & Wild Bergamot & 2 & 97.9\\% & 95.8\\% \\\\\n \nAsteraceae & Coreopsis lanceolata & Lanceleaf Tickseed & 8 & 93.8\\% & 93.8\\% \\\\\n \nLamiaceae & Monarda punctata & Spotted Beebalm & 4 & 87.5\\% & 66.7\\% \\\\\n \nAsteraceae & Rudbeckia hirta & Blackeyed Susan & 1 & 83.3\\% & 85.4\\% \\\\\n \nApocynaceae & Asclepias tuberosa & Butterfly Milkweed & 5 & 77.1\\% & 62.5\\% \\\\\n \nPoaceae & Elymus canadensis & Canada Wildrye & 4 & 43.8\\% & 16.7\\% \\\\\n \nAsteraceae & Ratibida pinnata & Pinnate Prairie Coneflower & 4 & 39.6\\% & 29.2\\% \\\\\n \nAsteraceae & Pseudognaphalium helleri & Heller's Cudweed & 2 & 12.5\\% & 18.8\\% \\\\\n \nFabaceae & Lupinus perennis & Sundial Lupine & 7 & 12.5\\% & 0.0\\% \\\\\n \nPoaceae & Panicum virgatum & Switchgrass & 4 & 12.5\\% & 8.3\\% \\\\\n \nAsteraceae & Solidago nemoralis & Gray Goldenrod & 2 & 10.4\\% & 8.3\\% \\\\\n \nAsteraceae & Coreopsis tripteris & Tall Tickseed & 7 & 8.3\\% & 2.1\\% \\\\\n \nFabaceae & Lespedeza capitata & Roundhead Lespedeza & 5 & 6.3\\% & 8.3\\% \\\\\n \nVerbenaceae & Verbena stricta & Hoary Verbena & 4 & 2.1\\% & 4.2\\% \\\\\n \nAsteraceae & Coreopsis palmata & Stiff Tickseed & 10 & 2.1\\% & 2.1\\% \\\\\n \nAsteraceae & Helianthus occidentalis & Fewleaf Sunflower & 8 & 2.1\\% & 2.1\\% \\\\\n \nAsteraceae & Solidago speciosa & Showy Goldenrod & 5 & 2.1\\% & 0.0\\% \\\\\n \nAsteraceae & Solidago juncea & Early Goldenrod & 3 & 0.0\\% & 0.0\\% \\\\\n \nFabaceae & Tephrosia virginiana & Virginia Tephrosia & 10 & 0.0\\% & 0.0\\% \\\\\n \nCommelinaceae & Tradescantia ohiensis & Bluejacket & 5 & 0.0\\% & 0.0\\% \\\\\n \n\\end{tabular}\n$\n\nEntailed dividing each $5\\,\\textrm{m}$ by $5\\,\\textrm{m}$ plot into quarters, with two researchers each estimating the cover of two quarters. During both years, each researcher consistently examined the same two quarters within each plot. To standardize visual estimates among researchers, we referred to published area charts (Anderson 1986), and used $0.1\\;\\mathrm{m}^{2}$ PVC frames as a standard area reference. Following data collection, we calculated the relative percent cover $(p_{i})$ of each species on each plot by dividing the summed total cover of each species by the summed total cover of the plot.  \n\n# Data Analysis  \n\nUsing the relative percent cover calculated for each year, we determined plot diversity using the Shannon index of diversity:  \n\n$$\n1)\\;{\\mathrm{H}}^{\\prime}=-\\Sigma\\,p_{i}\\log p_{i}\n$$  \n\nand Simpson's index of diversity:  \n\n$$\n\\mathbf{D}=1\\!-\\!\\Sigma\\,p_{i}^{2}\n$$  \n\n(McCune and Grace 2002). As recommended by Peet (1974), we used the exponential of $\\mathrm{H}^{\\prime}$ for analysis, as this indicates the functional number of species in the sample. Interpretations of the results remain the same, with higher values indicating higher diversity. Simpson\u2019s index has a range from zero, with a single species present, to one, maximum diversity (Peet 1974). Estimates of percent cover have been used successfully in previous studies to calculate these diversity indices (Potvin and Vasseur 1997, Tilman et al. 1997), and avoid errors resulting from miscounting clonal species if density had been used.  \n\nTo evaluate community quality, we calculated the mean coefficient of conservatism ($\\overline{{\\mathbf{C}}}$) , and a floristic quality index (FQI) for each plot to distinguish among treatment combinations containing ubiquitous native plants and those containing species more likely to occur in undisturbed native plant communities. These methods rely on coefficients of conservatism specific to Michigan (MDNR 2001), ranging from zero, representing ubiquitous native species, to ten, representing highly conserved native species (Taft et al. 1997). FQI was calculated for each plot by multiplying the $\\overline{{\\mathbf{C}}}$ for the plot by the square root of the number of native species on the plot (Packard and Mutel 1997). Native tree and shrub species are not part of the target prairie community and were excluded from FQI and $\\overline{{\\mathbf{C}}}$ analysis.  \n\nFor analyses of community composition, we classified species into one of six groups: non-native forbs, knapweed, non-native grasses, native graminoids, native forbs, and tree/shrub species. The non-native forbs group does not include knapweed. As the dominant invasive species and a focus of our research, knapweed was classified independently. Following this classification, we calculated the by summing the relative percent",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Equation",
        "evidence_source": "equation",
        "evidence_context": "Simpson's index of diversity: $$ \\mathbf{D}=1\\!-\\!\\Sigma\\,p_{i}^{2} $$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/fa7aec4efb728534ef32c172197c9560097c6d0e4893fe6b20242a566ef033d1.pdf_4",
        "ID": "0f3b07e3-9d7a-474c-bcb2-8b77f5d2e1e6",
        "questions": "What are the coefficients of conservation for Coreopsis lanceolata and Coreopsis tripteris?",
        "answers": "8, 7",
        "context": "$\n\\caption{Table 2. Seeded species presence as a percent of the 48 total treatment plots as Bass River Recreation Area, Ottawa County, MI, US. Species are ordered in terms of presence during 2011. Column C corresponds to the coefficient of conservation for each species specific to Michigan (MDNR 2001)}\n\\begin{tabular}{|l|l|l|c|c|c|}\n \nFamily & Species & Common Name & c & 2011 & 2012 \\\\\n \nPoaceae & Andropogon gerardii & Big Bluestem & 5 & 100.0\\% & 97.9\\% \\\\\n \nPoaceae & Schizachyrium scoparium & Little Bluestem & 5 & 100.0\\% & 100.0\\% \\\\\n \nPoaceae & Sorghastrum nutans & Indiangrass & 6 & 100.0\\% & 100.0\\% \\\\\n \nLamiaceae & Monarda fistulosa & Wild Bergamot & 2 & 97.9\\% & 95.8\\% \\\\\n \nAsteraceae & Coreopsis lanceolata & Lanceleaf Tickseed & 8 & 93.8\\% & 93.8\\% \\\\\n \nLamiaceae & Monarda punctata & Spotted Beebalm & 4 & 87.5\\% & 66.7\\% \\\\\n \nAsteraceae & Rudbeckia hirta & Blackeyed Susan & 1 & 83.3\\% & 85.4\\% \\\\\n \nApocynaceae & Asclepias tuberosa & Butterfly Milkweed & 5 & 77.1\\% & 62.5\\% \\\\\n \nPoaceae & Elymus canadensis & Canada Wildrye & 4 & 43.8\\% & 16.7\\% \\\\\n \nAsteraceae & Ratibida pinnata & Pinnate Prairie Coneflower & 4 & 39.6\\% & 29.2\\% \\\\\n \nAsteraceae & Pseudognaphalium helleri & Heller's Cudweed & 2 & 12.5\\% & 18.8\\% \\\\\n \nFabaceae & Lupinus perennis & Sundial Lupine & 7 & 12.5\\% & 0.0\\% \\\\\n \nPoaceae & Panicum virgatum & Switchgrass & 4 & 12.5\\% & 8.3\\% \\\\\n \nAsteraceae & Solidago nemoralis & Gray Goldenrod & 2 & 10.4\\% & 8.3\\% \\\\\n \nAsteraceae & Coreopsis tripteris & Tall Tickseed & 7 & 8.3\\% & 2.1\\% \\\\\n \nFabaceae & Lespedeza capitata & Roundhead Lespedeza & 5 & 6.3\\% & 8.3\\% \\\\\n \nVerbenaceae & Verbena stricta & Hoary Verbena & 4 & 2.1\\% & 4.2\\% \\\\\n \nAsteraceae & Coreopsis palmata & Stiff Tickseed & 10 & 2.1\\% & 2.1\\% \\\\\n \nAsteraceae & Helianthus occidentalis & Fewleaf Sunflower & 8 & 2.1\\% & 2.1\\% \\\\\n \nAsteraceae & Solidago speciosa & Showy Goldenrod & 5 & 2.1\\% & 0.0\\% \\\\\n \nAsteraceae & Solidago juncea & Early Goldenrod & 3 & 0.0\\% & 0.0\\% \\\\\n \nFabaceae & Tephrosia virginiana & Virginia Tephrosia & 10 & 0.0\\% & 0.0\\% \\\\\n \nCommelinaceae & Tradescantia ohiensis & Bluejacket & 5 & 0.0\\% & 0.0\\% \\\\\n \n\\end{tabular}\n$\n\nEntailed dividing each $5\\,\\textrm{m}$ by $5\\,\\textrm{m}$ plot into quarters, with two researchers each estimating the cover of two quarters. During both years, each researcher consistently examined the same two quarters within each plot. To standardize visual estimates among researchers, we referred to published area charts (Anderson 1986), and used $0.1\\;\\mathrm{m}^{2}$ PVC frames as a standard area reference. Following data collection, we calculated the relative percent cover $(p_{i})$ of each species on each plot by dividing the summed total cover of each species by the summed total cover of the plot.  \n\n# Data Analysis  \n\nUsing the relative percent cover calculated for each year, we determined plot diversity using the Shannon index of diversity:  \n\n$$\n1)\\;{\\mathrm{H}}^{\\prime}=-\\Sigma\\,p_{i}\\log p_{i}\n$$  \n\nand Simpson's index of diversity:  \n\n$$\n\\mathbf{D}=1\\!-\\!\\Sigma\\,p_{i}^{2}\n$$  \n\n(McCune and Grace 2002). As recommended by Peet (1974), we used the exponential of $\\mathrm{H}^{\\prime}$ for analysis, as this indicates the functional number of species in the sample. Interpretations of the results remain the same, with higher values indicating higher diversity. Simpson\u2019s index has a range from zero, with a single species present, to one, maximum diversity (Peet 1974). Estimates of percent cover have been used successfully in previous studies to calculate these diversity indices (Potvin and Vasseur 1997, Tilman et al. 1997), and avoid errors resulting from miscounting clonal species if density had been used.  \n\nTo evaluate community quality, we calculated the mean coefficient of conservatism ($\\overline{{\\mathbf{C}}}$) , and a floristic quality index (FQI) for each plot to distinguish among treatment combinations containing ubiquitous native plants and those containing species more likely to occur in undisturbed native plant communities. These methods rely on coefficients of conservatism specific to Michigan (MDNR 2001), ranging from zero, representing ubiquitous native species, to ten, representing highly conserved native species (Taft et al. 1997). FQI was calculated for each plot by multiplying the $\\overline{{\\mathbf{C}}}$ for the plot by the square root of the number of native species on the plot (Packard and Mutel 1997). Native tree and shrub species are not part of the target prairie community and were excluded from FQI and $\\overline{{\\mathbf{C}}}$ analysis.  \n\nFor analyses of community composition, we classified species into one of six groups: non-native forbs, knapweed, non-native grasses, native graminoids, native forbs, and tree/shrub species. The non-native forbs group does not include knapweed. As the dominant invasive species and a focus of our research, knapweed was classified independently. Following this classification, we calculated the by summing the relative percent",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Asteraceae & Coreopsis lanceolata & Lanceleaf Tickseed & 8 & 93.8\\% & 93.8\\% \\ ... Asteraceae & Coreopsis tripteris & Tall Tickseed & 7 & 8.3\\% & 2.1\\% \\",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/fa7aec4efb728534ef32c172197c9560097c6d0e4893fe6b20242a566ef033d1.pdf_4",
        "ID": "0f424ffa-8abb-472c-8aae-0c3ad31224e0",
        "questions": "Calculate the change in presence percentage for Monarda punctata from 2011 to 2012?",
        "answers": "20.8%",
        "context": "$\n\\caption{Table 2. Seeded species presence as a percent of the 48 total treatment plots as Bass River Recreation Area, Ottawa County, MI, US. Species are ordered in terms of presence during 2011. Column C corresponds to the coefficient of conservation for each species specific to Michigan (MDNR 2001)}\n\\begin{tabular}{|l|l|l|c|c|c|}\n \nFamily & Species & Common Name & c & 2011 & 2012 \\\\\n \nPoaceae & Andropogon gerardii & Big Bluestem & 5 & 100.0\\% & 97.9\\% \\\\\n \nPoaceae & Schizachyrium scoparium & Little Bluestem & 5 & 100.0\\% & 100.0\\% \\\\\n \nPoaceae & Sorghastrum nutans & Indiangrass & 6 & 100.0\\% & 100.0\\% \\\\\n \nLamiaceae & Monarda fistulosa & Wild Bergamot & 2 & 97.9\\% & 95.8\\% \\\\\n \nAsteraceae & Coreopsis lanceolata & Lanceleaf Tickseed & 8 & 93.8\\% & 93.8\\% \\\\\n \nLamiaceae & Monarda punctata & Spotted Beebalm & 4 & 87.5\\% & 66.7\\% \\\\\n \nAsteraceae & Rudbeckia hirta & Blackeyed Susan & 1 & 83.3\\% & 85.4\\% \\\\\n \nApocynaceae & Asclepias tuberosa & Butterfly Milkweed & 5 & 77.1\\% & 62.5\\% \\\\\n \nPoaceae & Elymus canadensis & Canada Wildrye & 4 & 43.8\\% & 16.7\\% \\\\\n \nAsteraceae & Ratibida pinnata & Pinnate Prairie Coneflower & 4 & 39.6\\% & 29.2\\% \\\\\n \nAsteraceae & Pseudognaphalium helleri & Heller's Cudweed & 2 & 12.5\\% & 18.8\\% \\\\\n \nFabaceae & Lupinus perennis & Sundial Lupine & 7 & 12.5\\% & 0.0\\% \\\\\n \nPoaceae & Panicum virgatum & Switchgrass & 4 & 12.5\\% & 8.3\\% \\\\\n \nAsteraceae & Solidago nemoralis & Gray Goldenrod & 2 & 10.4\\% & 8.3\\% \\\\\n \nAsteraceae & Coreopsis tripteris & Tall Tickseed & 7 & 8.3\\% & 2.1\\% \\\\\n \nFabaceae & Lespedeza capitata & Roundhead Lespedeza & 5 & 6.3\\% & 8.3\\% \\\\\n \nVerbenaceae & Verbena stricta & Hoary Verbena & 4 & 2.1\\% & 4.2\\% \\\\\n \nAsteraceae & Coreopsis palmata & Stiff Tickseed & 10 & 2.1\\% & 2.1\\% \\\\\n \nAsteraceae & Helianthus occidentalis & Fewleaf Sunflower & 8 & 2.1\\% & 2.1\\% \\\\\n \nAsteraceae & Solidago speciosa & Showy Goldenrod & 5 & 2.1\\% & 0.0\\% \\\\\n \nAsteraceae & Solidago juncea & Early Goldenrod & 3 & 0.0\\% & 0.0\\% \\\\\n \nFabaceae & Tephrosia virginiana & Virginia Tephrosia & 10 & 0.0\\% & 0.0\\% \\\\\n \nCommelinaceae & Tradescantia ohiensis & Bluejacket & 5 & 0.0\\% & 0.0\\% \\\\\n \n\\end{tabular}\n$\n\nEntailed dividing each $5\\,\\textrm{m}$ by $5\\,\\textrm{m}$ plot into quarters, with two researchers each estimating the cover of two quarters. During both years, each researcher consistently examined the same two quarters within each plot. To standardize visual estimates among researchers, we referred to published area charts (Anderson 1986), and used $0.1\\;\\mathrm{m}^{2}$ PVC frames as a standard area reference. Following data collection, we calculated the relative percent cover $(p_{i})$ of each species on each plot by dividing the summed total cover of each species by the summed total cover of the plot.  \n\n# Data Analysis  \n\nUsing the relative percent cover calculated for each year, we determined plot diversity using the Shannon index of diversity:  \n\n$$\n1)\\;{\\mathrm{H}}^{\\prime}=-\\Sigma\\,p_{i}\\log p_{i}\n$$  \n\nand Simpson's index of diversity:  \n\n$$\n\\mathbf{D}=1\\!-\\!\\Sigma\\,p_{i}^{2}\n$$  \n\n(McCune and Grace 2002). As recommended by Peet (1974), we used the exponential of $\\mathrm{H}^{\\prime}$ for analysis, as this indicates the functional number of species in the sample. Interpretations of the results remain the same, with higher values indicating higher diversity. Simpson\u2019s index has a range from zero, with a single species present, to one, maximum diversity (Peet 1974). Estimates of percent cover have been used successfully in previous studies to calculate these diversity indices (Potvin and Vasseur 1997, Tilman et al. 1997), and avoid errors resulting from miscounting clonal species if density had been used.  \n\nTo evaluate community quality, we calculated the mean coefficient of conservatism ($\\overline{{\\mathbf{C}}}$) , and a floristic quality index (FQI) for each plot to distinguish among treatment combinations containing ubiquitous native plants and those containing species more likely to occur in undisturbed native plant communities. These methods rely on coefficients of conservatism specific to Michigan (MDNR 2001), ranging from zero, representing ubiquitous native species, to ten, representing highly conserved native species (Taft et al. 1997). FQI was calculated for each plot by multiplying the $\\overline{{\\mathbf{C}}}$ for the plot by the square root of the number of native species on the plot (Packard and Mutel 1997). Native tree and shrub species are not part of the target prairie community and were excluded from FQI and $\\overline{{\\mathbf{C}}}$ analysis.  \n\nFor analyses of community composition, we classified species into one of six groups: non-native forbs, knapweed, non-native grasses, native graminoids, native forbs, and tree/shrub species. The non-native forbs group does not include knapweed. As the dominant invasive species and a focus of our research, knapweed was classified independently. Following this classification, we calculated the by summing the relative percent",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Numeric",
        "evidence_source": "equation",
        "evidence_context": "Lamiaceae & Monarda punctata & Spotted Beebalm & 4 & 87.5% & 66.7%",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/fa7aec4efb728534ef32c172197c9560097c6d0e4893fe6b20242a566ef033d1.pdf_4",
        "ID": "0f45d01a-3b8e-4413-808e-1b9882dade1d",
        "questions": "Among all the species, which ones had the maximum and minimum coefficients of conservation, and what were their values?",
        "answers": "Coreopsis palmata and Virginia Tephrosia had the maximum coefficient of conservation of 10, while Rudbeckia hirta had the minimum coefficient of conservation of 1.",
        "context": "$\n\\caption{Table 2. Seeded species presence as a percent of the 48 total treatment plots as Bass River Recreation Area, Ottawa County, MI, US. Species are ordered in terms of presence during 2011. Column C corresponds to the coefficient of conservation for each species specific to Michigan (MDNR 2001)}\n\\begin{tabular}{|l|l|l|c|c|c|}\n \nFamily & Species & Common Name & c & 2011 & 2012 \\\\\n \nPoaceae & Andropogon gerardii & Big Bluestem & 5 & 100.0\\% & 97.9\\% \\\\\n \nPoaceae & Schizachyrium scoparium & Little Bluestem & 5 & 100.0\\% & 100.0\\% \\\\\n \nPoaceae & Sorghastrum nutans & Indiangrass & 6 & 100.0\\% & 100.0\\% \\\\\n \nLamiaceae & Monarda fistulosa & Wild Bergamot & 2 & 97.9\\% & 95.8\\% \\\\\n \nAsteraceae & Coreopsis lanceolata & Lanceleaf Tickseed & 8 & 93.8\\% & 93.8\\% \\\\\n \nLamiaceae & Monarda punctata & Spotted Beebalm & 4 & 87.5\\% & 66.7\\% \\\\\n \nAsteraceae & Rudbeckia hirta & Blackeyed Susan & 1 & 83.3\\% & 85.4\\% \\\\\n \nApocynaceae & Asclepias tuberosa & Butterfly Milkweed & 5 & 77.1\\% & 62.5\\% \\\\\n \nPoaceae & Elymus canadensis & Canada Wildrye & 4 & 43.8\\% & 16.7\\% \\\\\n \nAsteraceae & Ratibida pinnata & Pinnate Prairie Coneflower & 4 & 39.6\\% & 29.2\\% \\\\\n \nAsteraceae & Pseudognaphalium helleri & Heller's Cudweed & 2 & 12.5\\% & 18.8\\% \\\\\n \nFabaceae & Lupinus perennis & Sundial Lupine & 7 & 12.5\\% & 0.0\\% \\\\\n \nPoaceae & Panicum virgatum & Switchgrass & 4 & 12.5\\% & 8.3\\% \\\\\n \nAsteraceae & Solidago nemoralis & Gray Goldenrod & 2 & 10.4\\% & 8.3\\% \\\\\n \nAsteraceae & Coreopsis tripteris & Tall Tickseed & 7 & 8.3\\% & 2.1\\% \\\\\n \nFabaceae & Lespedeza capitata & Roundhead Lespedeza & 5 & 6.3\\% & 8.3\\% \\\\\n \nVerbenaceae & Verbena stricta & Hoary Verbena & 4 & 2.1\\% & 4.2\\% \\\\\n \nAsteraceae & Coreopsis palmata & Stiff Tickseed & 10 & 2.1\\% & 2.1\\% \\\\\n \nAsteraceae & Helianthus occidentalis & Fewleaf Sunflower & 8 & 2.1\\% & 2.1\\% \\\\\n \nAsteraceae & Solidago speciosa & Showy Goldenrod & 5 & 2.1\\% & 0.0\\% \\\\\n \nAsteraceae & Solidago juncea & Early Goldenrod & 3 & 0.0\\% & 0.0\\% \\\\\n \nFabaceae & Tephrosia virginiana & Virginia Tephrosia & 10 & 0.0\\% & 0.0\\% \\\\\n \nCommelinaceae & Tradescantia ohiensis & Bluejacket & 5 & 0.0\\% & 0.0\\% \\\\\n \n\\end{tabular}\n$\n\nEntailed dividing each $5\\,\\textrm{m}$ by $5\\,\\textrm{m}$ plot into quarters, with two researchers each estimating the cover of two quarters. During both years, each researcher consistently examined the same two quarters within each plot. To standardize visual estimates among researchers, we referred to published area charts (Anderson 1986), and used $0.1\\;\\mathrm{m}^{2}$ PVC frames as a standard area reference. Following data collection, we calculated the relative percent cover $(p_{i})$ of each species on each plot by dividing the summed total cover of each species by the summed total cover of the plot.  \n\n# Data Analysis  \n\nUsing the relative percent cover calculated for each year, we determined plot diversity using the Shannon index of diversity:  \n\n$$\n1)\\;{\\mathrm{H}}^{\\prime}=-\\Sigma\\,p_{i}\\log p_{i}\n$$  \n\nand Simpson's index of diversity:  \n\n$$\n\\mathbf{D}=1\\!-\\!\\Sigma\\,p_{i}^{2}\n$$  \n\n(McCune and Grace 2002). As recommended by Peet (1974), we used the exponential of $\\mathrm{H}^{\\prime}$ for analysis, as this indicates the functional number of species in the sample. Interpretations of the results remain the same, with higher values indicating higher diversity. Simpson\u2019s index has a range from zero, with a single species present, to one, maximum diversity (Peet 1974). Estimates of percent cover have been used successfully in previous studies to calculate these diversity indices (Potvin and Vasseur 1997, Tilman et al. 1997), and avoid errors resulting from miscounting clonal species if density had been used.  \n\nTo evaluate community quality, we calculated the mean coefficient of conservatism ($\\overline{{\\mathbf{C}}}$) , and a floristic quality index (FQI) for each plot to distinguish among treatment combinations containing ubiquitous native plants and those containing species more likely to occur in undisturbed native plant communities. These methods rely on coefficients of conservatism specific to Michigan (MDNR 2001), ranging from zero, representing ubiquitous native species, to ten, representing highly conserved native species (Taft et al. 1997). FQI was calculated for each plot by multiplying the $\\overline{{\\mathbf{C}}}$ for the plot by the square root of the number of native species on the plot (Packard and Mutel 1997). Native tree and shrub species are not part of the target prairie community and were excluded from FQI and $\\overline{{\\mathbf{C}}}$ analysis.  \n\nFor analyses of community composition, we classified species into one of six groups: non-native forbs, knapweed, non-native grasses, native graminoids, native forbs, and tree/shrub species. The non-native forbs group does not include knapweed. As the dominant invasive species and a focus of our research, knapweed was classified independently. Following this classification, we calculated the by summing the relative percent",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Asteraceae & Coreopsis palmata & Stiff Tickseed & 10 & 2.1\\% & 2.1\\% ... Fabaceae & Tephrosia virginiana & Virginia Tephrosia & 10 & 0.0\\% & 0.0\\% ... Asteraceae & Rudbeckia hirta & Blackeyed Susan & 1 & 83.3\\% & 85.4\\%",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/ch03.pdf_28",
        "ID": "0f493112-bc03-4879-abb7-6a3232975fbc",
        "questions": "What amendment allowed residents of Washington, D.C., to vote for president and vice president?",
        "answers": "The Twenty-third Amendment",
        "context": "Such outgoing officials had little influence and accomplished little, and they were called lame ducks because they were so inactive. The amendment addressed and, in most cases, solved this problem by ending the terms of senators and representatives on January 3, and the term of the president on January 20 in the year following their November elections.\n\nThe Twenty-first Amendment (1933) repeals the unsuccessful Eighteenth Amendment. The Twenty-first Amendment, however, continued to ban the transport of alcohol into any state where its possession violated state law.\n\nThe Twenty-second Amendment (1951) limits presidents to a maximum of two elected terms. It was passed largely as a reaction to Franklin D. Roosevelt's election to four terms between 1933 and 1945.\n\nThe Twenty-third Amendment (1961) allows citizens living in Washington, D.C., to vote for president and vice president, a right previously denied residents of the nation's capital. The District of Columbia now has three presidential electors, the number to which it would be entitled if it were a state.\n\nThe Twenty-fourth Amendment (1964) prohibits poll taxes in federal elections\u2014taxes paid in order to vote. Prior to the passage of this amendment, some states had used such taxes to keep low-income African Americans from voting.\n\nThe Twenty-fifth Amendment (1967) establishes a process for the vice president to take over leadership of the nation when a president is disabled. It also sets procedures for filling a vacancy in the office of the vice president. This amendment addresses a delicate issue: when should a president be considered unable to perform the duties of the office? A few times in the nation's history, illness prevented a president from performing his official duties. Should the vice president be considered president during this time? The amendment says that when a president or vice president, with the support of the majority of the cabinet, writes to the president pro tem of the Senate and the Speaker of the House expressing the inability of the president to perform the duties of the office, the vice president immediately becomes the acting president. In a conflict between the president and the vice president over this issue, Congress must decide who will perform the duties of the office.\n\nThe Twenty-sixth Amendment (1971) lowers the voting age in both federal and state elections to 18.\n\nThe Twenty-seventh Amendment (1992) makes congressional pay raises effective during the term following their passage. Originally proposed by James Madison in 1789, this amendment lingered in obscurity for more than 200 years until it was discovered by a university student.\n\n# Section 4 Assessment\n\n# Checking for Understanding\n\n1. Main Idea In a table, categorize the 27 amendments into the three major groups described in this section.\n\n$\n\\begin{tabular}{|c|c|c|}\n \n\\multicolumn{3}{|c|}{Constitutional Amendments}\\\\\n \n&&\\\\\n \n\\end{tabular}\n$\n\n2. Define prior restraint, probable cause, search warrant, arrest warrant, due process of law, eminent domain, lame duck, poll tax.\n\n3. Identify Bill of Rights, Chisholm v. Georgia. \n\n4. What rights are listed in the First Amendment?\n\n5. Identify the twentieth-century amendments that deal with voting rights.\n\n# Critical Thinking\n\n6. Analyzing Information How do the amendments to the Constitution preserve individual rights?\n\nGrowth of Democracy Amendments often reflect a change in society or a need for change in the structure and power of government. Write a report that identifies the reasons and events that led to the adoption of one of the 27 amendments. Present your findings to the class.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "The Twenty-third Amendment (1961) allows citizens living in Washington, D.C., to vote for president and vice president, a right previously denied residents of the nation's capital.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/ch03.pdf_28",
        "ID": "0f4b3930-1768-4fd9-9950-c9b19762c946",
        "questions": "Which amendment limits U.S. Presidents to two elected terms as a reaction to Franklin D. Roosevelt's presidency?",
        "answers": "The Twenty-second Amendment",
        "context": "Such outgoing officials had little influence and accomplished little, and they were called lame ducks because they were so inactive. The amendment addressed and, in most cases, solved this problem by ending the terms of senators and representatives on January 3, and the term of the president on January 20 in the year following their November elections.\n\nThe Twenty-first Amendment (1933) repeals the unsuccessful Eighteenth Amendment. The Twenty-first Amendment, however, continued to ban the transport of alcohol into any state where its possession violated state law.\n\nThe Twenty-second Amendment (1951) limits presidents to a maximum of two elected terms. It was passed largely as a reaction to Franklin D. Roosevelt's election to four terms between 1933 and 1945.\n\nThe Twenty-third Amendment (1961) allows citizens living in Washington, D.C., to vote for president and vice president, a right previously denied residents of the nation's capital. The District of Columbia now has three presidential electors, the number to which it would be entitled if it were a state.\n\nThe Twenty-fourth Amendment (1964) prohibits poll taxes in federal elections\u2014taxes paid in order to vote. Prior to the passage of this amendment, some states had used such taxes to keep low-income African Americans from voting.\n\nThe Twenty-fifth Amendment (1967) establishes a process for the vice president to take over leadership of the nation when a president is disabled. It also sets procedures for filling a vacancy in the office of the vice president. This amendment addresses a delicate issue: when should a president be considered unable to perform the duties of the office? A few times in the nation's history, illness prevented a president from performing his official duties. Should the vice president be considered president during this time? The amendment says that when a president or vice president, with the support of the majority of the cabinet, writes to the president pro tem of the Senate and the Speaker of the House expressing the inability of the president to perform the duties of the office, the vice president immediately becomes the acting president. In a conflict between the president and the vice president over this issue, Congress must decide who will perform the duties of the office.\n\nThe Twenty-sixth Amendment (1971) lowers the voting age in both federal and state elections to 18.\n\nThe Twenty-seventh Amendment (1992) makes congressional pay raises effective during the term following their passage. Originally proposed by James Madison in 1789, this amendment lingered in obscurity for more than 200 years until it was discovered by a university student.\n\n# Section 4 Assessment\n\n# Checking for Understanding\n\n1. Main Idea In a table, categorize the 27 amendments into the three major groups described in this section.\n\n$\n\\begin{tabular}{|c|c|c|}\n \n\\multicolumn{3}{|c|}{Constitutional Amendments}\\\\\n \n&&\\\\\n \n\\end{tabular}\n$\n\n2. Define prior restraint, probable cause, search warrant, arrest warrant, due process of law, eminent domain, lame duck, poll tax.\n\n3. Identify Bill of Rights, Chisholm v. Georgia. \n\n4. What rights are listed in the First Amendment?\n\n5. Identify the twentieth-century amendments that deal with voting rights.\n\n# Critical Thinking\n\n6. Analyzing Information How do the amendments to the Constitution preserve individual rights?\n\nGrowth of Democracy Amendments often reflect a change in society or a need for change in the structure and power of government. Write a report that identifies the reasons and events that led to the adoption of one of the 27 amendments. Present your findings to the class.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "The Twenty-second Amendment (1951) limits presidents to a maximum of two elected terms. It was passed largely as a reaction to Franklin D. Roosevelt's election to four terms between 1933 and 1945.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/ch03.pdf_28",
        "ID": "0f53ffa5-eb8b-45d3-8c1a-98c1f5b546e6",
        "questions": "What is the procedure established by the Twenty-fifth Amendment for when a president is incapacitated?",
        "answers": "The vice president immediately becomes the acting president when a president or vice president, with the support of the majority of the cabinet, writes to the president pro tem of the Senate and the Speaker of the House expressing the inability of the president to perform the duties of the office.",
        "context": "Such outgoing officials had little influence and accomplished little, and they were called lame ducks because they were so inactive. The amendment addressed and, in most cases, solved this problem by ending the terms of senators and representatives on January 3, and the term of the president on January 20 in the year following their November elections.\n\nThe Twenty-first Amendment (1933) repeals the unsuccessful Eighteenth Amendment. The Twenty-first Amendment, however, continued to ban the transport of alcohol into any state where its possession violated state law.\n\nThe Twenty-second Amendment (1951) limits presidents to a maximum of two elected terms. It was passed largely as a reaction to Franklin D. Roosevelt's election to four terms between 1933 and 1945.\n\nThe Twenty-third Amendment (1961) allows citizens living in Washington, D.C., to vote for president and vice president, a right previously denied residents of the nation's capital. The District of Columbia now has three presidential electors, the number to which it would be entitled if it were a state.\n\nThe Twenty-fourth Amendment (1964) prohibits poll taxes in federal elections\u2014taxes paid in order to vote. Prior to the passage of this amendment, some states had used such taxes to keep low-income African Americans from voting.\n\nThe Twenty-fifth Amendment (1967) establishes a process for the vice president to take over leadership of the nation when a president is disabled. It also sets procedures for filling a vacancy in the office of the vice president. This amendment addresses a delicate issue: when should a president be considered unable to perform the duties of the office? A few times in the nation's history, illness prevented a president from performing his official duties. Should the vice president be considered president during this time? The amendment says that when a president or vice president, with the support of the majority of the cabinet, writes to the president pro tem of the Senate and the Speaker of the House expressing the inability of the president to perform the duties of the office, the vice president immediately becomes the acting president. In a conflict between the president and the vice president over this issue, Congress must decide who will perform the duties of the office.\n\nThe Twenty-sixth Amendment (1971) lowers the voting age in both federal and state elections to 18.\n\nThe Twenty-seventh Amendment (1992) makes congressional pay raises effective during the term following their passage. Originally proposed by James Madison in 1789, this amendment lingered in obscurity for more than 200 years until it was discovered by a university student.\n\n# Section 4 Assessment\n\n# Checking for Understanding\n\n1. Main Idea In a table, categorize the 27 amendments into the three major groups described in this section.\n\n$\n\\begin{tabular}{|c|c|c|}\n \n\\multicolumn{3}{|c|}{Constitutional Amendments}\\\\\n \n&&\\\\\n \n\\end{tabular}\n$\n\n2. Define prior restraint, probable cause, search warrant, arrest warrant, due process of law, eminent domain, lame duck, poll tax.\n\n3. Identify Bill of Rights, Chisholm v. Georgia. \n\n4. What rights are listed in the First Amendment?\n\n5. Identify the twentieth-century amendments that deal with voting rights.\n\n# Critical Thinking\n\n6. Analyzing Information How do the amendments to the Constitution preserve individual rights?\n\nGrowth of Democracy Amendments often reflect a change in society or a need for change in the structure and power of government. Write a report that identifies the reasons and events that led to the adoption of one of the 27 amendments. Present your findings to the class.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "The amendment says that when a president or vice president, with the support of the majority of the cabinet, writes to the president pro tem of the Senate and the Speaker of the House expressing the inability of the president to perform the duties of the office, the vice president immediately becomes the acting president.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Mathematical_Methods_in_the_Physical_Sciences-Third_Edition.pdf_301",
        "ID": "0f541ff5-1ece-4ac1-b27a-1ff4b45bdd37",
        "questions": "What expression represents the vector \\(\\mathbf{A}\\) in terms of the partial derivatives of \\(x\\), \\(y\\), and \\(z\\) with respect to \\(u\\) for a change of variables in a multiple integral?",
        "answers": "\\(\\mathbf{A} = \frac{\\partial \\mathbf{r}}{\\partial u} \\, d u = \\left( \\mathbf{i} \\, \frac{\\partial x}{\\partial u} + \\mathbf{j} \\, \frac{\\partial y}{\\partial u} + \\mathbf{k} \\, \frac{\\partial z}{\\partial u} \right) \\, d u.\\)",
        "context": "Example 2. As another application of the triple scalar product, let's find the Jacobian we used in Chapter 5, Section 4 for changing variables in a multiple integral. As you know, in rectangular coordinates the volume element is a rectangular box of volume \\(d x \\, d y \\, d z\\). In other coordinate systems, the volume element may be approximately a parallelpiped as in Figure 3.1. We want a formula for the volume element in this case. (See, for example, the cylindrical and spherical coordinate volume elements in Chapter 5, Figures 4.4 and 4.5.)\n\nSuppose we are given formulas for \\(x\\), \\(y\\), \\(\\mathcal{L}\\) as functions of new variables \\(u\\), \\(v\\), \\(w\\). Then we want to find the vectors along the edges of the volume element in the \\(\\mathcal{U}\\), \\(v\\), \\(w\\) system. Suppose vector \\(\\mathbf{A}\\) in Figure 3.1 is along the direction in which \\(\\mathcal{U}\\) increases while \\(v\\) and \\(w\\) remain constant. Then if \\(d \\mathbf{r} = \\mathbf{i} \\, d x + \\mathbf{j} \\, d y + \\mathbf{k} \\, d z\\) is a vector in this direction, we have\n\n\\[\n\\mathbf{A} = \\frac{\\partial \\mathbf{r}}{\\partial u} \\, d u = \\left( \\mathbf{i} \\, \\frac{\\partial x}{\\partial u} + \\mathbf{j} \\, \\frac{\\partial y}{\\partial u} + \\mathbf{k} \\, \\frac{\\partial z}{\\partial u} \\right) \\, d u.\n\\]\n\nSimilarly, if \\(\\mathbf{B}\\) is along the increasing \\(v\\) edge of the volume element and \\(\\mathbf{C}\\) is along the increasing \\(w\\) edge, we have\n\n\\[\n\\begin{array}{l}\n{\\displaystyle{\\mathbf{B} = \\frac{\\partial \\mathbf{r}}{\\partial v} \\, d v = \\left( \\mathbf{i} \\, \\frac{\\partial x}{\\partial v} + \\mathbf{j} \\, \\frac{\\partial y}{\\partial v} + \\mathbf{k} \\, \\frac{\\partial z}{\\partial v} \\right) \\, d v,}} \\\\\n{\\displaystyle{\\mathbf{C} = \\frac{\\partial \\mathbf{r}}{\\partial w} \\, d w = \\left( \\mathbf{i} \\, \\frac{\\partial x}{\\partial w} + \\mathbf{j} \\, \\frac{\\partial y}{\\partial w} + \\mathbf{k} \\, \\frac{\\partial z}{\\partial w} \\right) \\, d w.}}\n\\end{array}\n\\]\n\nThen by (3.2)\n\n\\[\n\\mathbf{A} \\cdot (\\mathbf{B} \\times \\mathbf{C}) = \\left| \\frac{\\partial x}{\\partial u} \\quad \\frac{\\partial y}{\\partial u} \\quad \\frac{\\partial z}{\\partial u} \\right| \\, d u \\, d v \\, d w = J \\, d u \\, d v \\, d w\n\\]\n\nwhere \\(J\\) is the Jacobian of the transformation from \\(x\\), \\(y\\), \\(\\mathcal{Z}\\) to \\(u\\), \\(v\\), \\(w\\). Recall from the discussion of (3.2) that the triple scalar product may turn out to be positive or negative. Since we want a volume element to be positive, we use the absolute value of \\(J\\). Thus, the \\(u\\), \\(v\\), \\(w\\) volume element is \\(|J| \\, d u \\, d v \\, d w\\) as stated in Chapter 5, Section 4.\n\nApplications of the Triple Vector Product In Figure 3.8 (compare Figure 2.6), suppose the particle \\(_{T L}\\) is at rest on a rotating rigid body (for example, the earth). Then the angular momentum \\(\\mathbf{L}\\) of \\(_{f f t}\\) about point \\(O\\) is defined by the equation \\(\\mathbf{L} = \\mathbf{r} \\times (m \\mathbf{v}) = m \\mathbf{r} \\times \\mathbf{v}\\). In the discussion of Figure 2.6, we showed that \\(\\mathbf{v} = \\boldsymbol{\\omega} \\times \\mathbf{r}\\). Thus, \\(\\mathbf{L} = m \\mathbf{r} \\times (\\boldsymbol{\\omega} \\times \\mathbf{r})\\). See Problem 16 and also Chapter 10, Section 4.\n\nAs another example, it is shown in mechanics that the centripetal acceleration of \\(m\\) in Figure 3.8 is \\(\\mathbf{a} = \\boldsymbol{\\omega} \\times (\\boldsymbol{\\omega} \\times \\mathbf{r})\\). See Problem 17.\n\n![](images/f193a52234022a272488809d61a0ad5a333deefb4bce93f1bee538df9f2d9eee.jpg)\nFigure 3.8",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "\\(\\mathbf{A} = \frac{\\partial \\mathbf{r}}{\\partial u} \\, d u = \\left( \\mathbf{i} \\, \frac{\\partial x}{\\partial u} + \\mathbf{j} \\, \frac{\\partial y}{\\partial u} + \\mathbf{k} \\, \frac{\\partial z}{\\partial u} \right) \\, d u.\\)",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Mathematical_Methods_in_the_Physical_Sciences-Third_Edition.pdf_301",
        "ID": "0f65fa0f-1d1c-4f46-87f8-2dcafc84d803",
        "questions": "For a rotating rigid body as described in the document, what is the formula for the angular momentum \\(\\mathbf{L}\\) of a particle about point \\(O\\)?",
        "answers": "\\(\\mathbf{L} = m \\mathbf{r} \times (\boldsymbol{\\omega} \times \\mathbf{r})\\)",
        "context": "Example 2. As another application of the triple scalar product, let's find the Jacobian we used in Chapter 5, Section 4 for changing variables in a multiple integral. As you know, in rectangular coordinates the volume element is a rectangular box of volume \\(d x \\, d y \\, d z\\). In other coordinate systems, the volume element may be approximately a parallelpiped as in Figure 3.1. We want a formula for the volume element in this case. (See, for example, the cylindrical and spherical coordinate volume elements in Chapter 5, Figures 4.4 and 4.5.)\n\nSuppose we are given formulas for \\(x\\), \\(y\\), \\(\\mathcal{L}\\) as functions of new variables \\(u\\), \\(v\\), \\(w\\). Then we want to find the vectors along the edges of the volume element in the \\(\\mathcal{U}\\), \\(v\\), \\(w\\) system. Suppose vector \\(\\mathbf{A}\\) in Figure 3.1 is along the direction in which \\(\\mathcal{U}\\) increases while \\(v\\) and \\(w\\) remain constant. Then if \\(d \\mathbf{r} = \\mathbf{i} \\, d x + \\mathbf{j} \\, d y + \\mathbf{k} \\, d z\\) is a vector in this direction, we have\n\n\\[\n\\mathbf{A} = \\frac{\\partial \\mathbf{r}}{\\partial u} \\, d u = \\left( \\mathbf{i} \\, \\frac{\\partial x}{\\partial u} + \\mathbf{j} \\, \\frac{\\partial y}{\\partial u} + \\mathbf{k} \\, \\frac{\\partial z}{\\partial u} \\right) \\, d u.\n\\]\n\nSimilarly, if \\(\\mathbf{B}\\) is along the increasing \\(v\\) edge of the volume element and \\(\\mathbf{C}\\) is along the increasing \\(w\\) edge, we have\n\n\\[\n\\begin{array}{l}\n{\\displaystyle{\\mathbf{B} = \\frac{\\partial \\mathbf{r}}{\\partial v} \\, d v = \\left( \\mathbf{i} \\, \\frac{\\partial x}{\\partial v} + \\mathbf{j} \\, \\frac{\\partial y}{\\partial v} + \\mathbf{k} \\, \\frac{\\partial z}{\\partial v} \\right) \\, d v,}} \\\\\n{\\displaystyle{\\mathbf{C} = \\frac{\\partial \\mathbf{r}}{\\partial w} \\, d w = \\left( \\mathbf{i} \\, \\frac{\\partial x}{\\partial w} + \\mathbf{j} \\, \\frac{\\partial y}{\\partial w} + \\mathbf{k} \\, \\frac{\\partial z}{\\partial w} \\right) \\, d w.}}\n\\end{array}\n\\]\n\nThen by (3.2)\n\n\\[\n\\mathbf{A} \\cdot (\\mathbf{B} \\times \\mathbf{C}) = \\left| \\frac{\\partial x}{\\partial u} \\quad \\frac{\\partial y}{\\partial u} \\quad \\frac{\\partial z}{\\partial u} \\right| \\, d u \\, d v \\, d w = J \\, d u \\, d v \\, d w\n\\]\n\nwhere \\(J\\) is the Jacobian of the transformation from \\(x\\), \\(y\\), \\(\\mathcal{Z}\\) to \\(u\\), \\(v\\), \\(w\\). Recall from the discussion of (3.2) that the triple scalar product may turn out to be positive or negative. Since we want a volume element to be positive, we use the absolute value of \\(J\\). Thus, the \\(u\\), \\(v\\), \\(w\\) volume element is \\(|J| \\, d u \\, d v \\, d w\\) as stated in Chapter 5, Section 4.\n\nApplications of the Triple Vector Product In Figure 3.8 (compare Figure 2.6), suppose the particle \\(_{T L}\\) is at rest on a rotating rigid body (for example, the earth). Then the angular momentum \\(\\mathbf{L}\\) of \\(_{f f t}\\) about point \\(O\\) is defined by the equation \\(\\mathbf{L} = \\mathbf{r} \\times (m \\mathbf{v}) = m \\mathbf{r} \\times \\mathbf{v}\\). In the discussion of Figure 2.6, we showed that \\(\\mathbf{v} = \\boldsymbol{\\omega} \\times \\mathbf{r}\\). Thus, \\(\\mathbf{L} = m \\mathbf{r} \\times (\\boldsymbol{\\omega} \\times \\mathbf{r})\\). See Problem 16 and also Chapter 10, Section 4.\n\nAs another example, it is shown in mechanics that the centripetal acceleration of \\(m\\) in Figure 3.8 is \\(\\mathbf{a} = \\boldsymbol{\\omega} \\times (\\boldsymbol{\\omega} \\times \\mathbf{r})\\). See Problem 17.\n\n![](images/f193a52234022a272488809d61a0ad5a333deefb4bce93f1bee538df9f2d9eee.jpg)\nFigure 3.8",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "\\(\\mathbf{L} = m \\mathbf{r} \times (\boldsymbol{\\omega} \times \\mathbf{r})\\).",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Mathematical_Methods_in_the_Physical_Sciences-Third_Edition.pdf_301",
        "ID": "0f66b32d-e19b-4837-9c6a-4b5e7d859725",
        "questions": "What is the mathematical expression for centripetal acceleration \\(\\mathbf{a}\\) in terms of angular velocity \\(\boldsymbol{\\omega}\\) and position vector \\(\\mathbf{r}\\) as given for a particle on a rotating rigid body?",
        "answers": "\\(\\mathbf{a} = \boldsymbol{\\omega} \times (\boldsymbol{\\omega} \times \\mathbf{r})\\)",
        "context": "Example 2. As another application of the triple scalar product, let's find the Jacobian we used in Chapter 5, Section 4 for changing variables in a multiple integral. As you know, in rectangular coordinates the volume element is a rectangular box of volume \\(d x \\, d y \\, d z\\). In other coordinate systems, the volume element may be approximately a parallelpiped as in Figure 3.1. We want a formula for the volume element in this case. (See, for example, the cylindrical and spherical coordinate volume elements in Chapter 5, Figures 4.4 and 4.5.)\n\nSuppose we are given formulas for \\(x\\), \\(y\\), \\(\\mathcal{L}\\) as functions of new variables \\(u\\), \\(v\\), \\(w\\). Then we want to find the vectors along the edges of the volume element in the \\(\\mathcal{U}\\), \\(v\\), \\(w\\) system. Suppose vector \\(\\mathbf{A}\\) in Figure 3.1 is along the direction in which \\(\\mathcal{U}\\) increases while \\(v\\) and \\(w\\) remain constant. Then if \\(d \\mathbf{r} = \\mathbf{i} \\, d x + \\mathbf{j} \\, d y + \\mathbf{k} \\, d z\\) is a vector in this direction, we have\n\n\\[\n\\mathbf{A} = \\frac{\\partial \\mathbf{r}}{\\partial u} \\, d u = \\left( \\mathbf{i} \\, \\frac{\\partial x}{\\partial u} + \\mathbf{j} \\, \\frac{\\partial y}{\\partial u} + \\mathbf{k} \\, \\frac{\\partial z}{\\partial u} \\right) \\, d u.\n\\]\n\nSimilarly, if \\(\\mathbf{B}\\) is along the increasing \\(v\\) edge of the volume element and \\(\\mathbf{C}\\) is along the increasing \\(w\\) edge, we have\n\n\\[\n\\begin{array}{l}\n{\\displaystyle{\\mathbf{B} = \\frac{\\partial \\mathbf{r}}{\\partial v} \\, d v = \\left( \\mathbf{i} \\, \\frac{\\partial x}{\\partial v} + \\mathbf{j} \\, \\frac{\\partial y}{\\partial v} + \\mathbf{k} \\, \\frac{\\partial z}{\\partial v} \\right) \\, d v,}} \\\\\n{\\displaystyle{\\mathbf{C} = \\frac{\\partial \\mathbf{r}}{\\partial w} \\, d w = \\left( \\mathbf{i} \\, \\frac{\\partial x}{\\partial w} + \\mathbf{j} \\, \\frac{\\partial y}{\\partial w} + \\mathbf{k} \\, \\frac{\\partial z}{\\partial w} \\right) \\, d w.}}\n\\end{array}\n\\]\n\nThen by (3.2)\n\n\\[\n\\mathbf{A} \\cdot (\\mathbf{B} \\times \\mathbf{C}) = \\left| \\frac{\\partial x}{\\partial u} \\quad \\frac{\\partial y}{\\partial u} \\quad \\frac{\\partial z}{\\partial u} \\right| \\, d u \\, d v \\, d w = J \\, d u \\, d v \\, d w\n\\]\n\nwhere \\(J\\) is the Jacobian of the transformation from \\(x\\), \\(y\\), \\(\\mathcal{Z}\\) to \\(u\\), \\(v\\), \\(w\\). Recall from the discussion of (3.2) that the triple scalar product may turn out to be positive or negative. Since we want a volume element to be positive, we use the absolute value of \\(J\\). Thus, the \\(u\\), \\(v\\), \\(w\\) volume element is \\(|J| \\, d u \\, d v \\, d w\\) as stated in Chapter 5, Section 4.\n\nApplications of the Triple Vector Product In Figure 3.8 (compare Figure 2.6), suppose the particle \\(_{T L}\\) is at rest on a rotating rigid body (for example, the earth). Then the angular momentum \\(\\mathbf{L}\\) of \\(_{f f t}\\) about point \\(O\\) is defined by the equation \\(\\mathbf{L} = \\mathbf{r} \\times (m \\mathbf{v}) = m \\mathbf{r} \\times \\mathbf{v}\\). In the discussion of Figure 2.6, we showed that \\(\\mathbf{v} = \\boldsymbol{\\omega} \\times \\mathbf{r}\\). Thus, \\(\\mathbf{L} = m \\mathbf{r} \\times (\\boldsymbol{\\omega} \\times \\mathbf{r})\\). See Problem 16 and also Chapter 10, Section 4.\n\nAs another example, it is shown in mechanics that the centripetal acceleration of \\(m\\) in Figure 3.8 is \\(\\mathbf{a} = \\boldsymbol{\\omega} \\times (\\boldsymbol{\\omega} \\times \\mathbf{r})\\). See Problem 17.\n\n![](images/f193a52234022a272488809d61a0ad5a333deefb4bce93f1bee538df9f2d9eee.jpg)\nFigure 3.8",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "\\(\\mathbf{a} = \boldsymbol{\\omega} \times (\boldsymbol{\\omega} \times \\mathbf{r})\\).",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Mathematical_Methods_in_the_Physical_Sciences-Third_Edition.pdf_301",
        "ID": "0f6f5893-5356-4138-b7f4-89744ff04925",
        "questions": "What is the expression for vector \\(\\mathbf{A}\\) in terms of partial derivatives with respect to \\(u\\) in the new coordinate system?",
        "answers": "\\(\\mathbf{A} = \frac{\\partial \\mathbf{r}}{\\partial u} \\, d u = \\left( \\mathbf{i} \\, \frac{\\partial x}{\\partial u} + \\mathbf{j} \\, \frac{\\partial y}{\\partial u} + \\mathbf{k} \\, \frac{\\partial z}{\\partial u} \right) \\, d u.\\)",
        "context": "Example 2. As another application of the triple scalar product, let's find the Jacobian we used in Chapter 5, Section 4 for changing variables in a multiple integral. As you know, in rectangular coordinates the volume element is a rectangular box of volume \\(d x \\, d y \\, d z\\). In other coordinate systems, the volume element may be approximately a parallelpiped as in Figure 3.1. We want a formula for the volume element in this case. (See, for example, the cylindrical and spherical coordinate volume elements in Chapter 5, Figures 4.4 and 4.5.)\n\nSuppose we are given formulas for \\(x\\), \\(y\\), \\(\\mathcal{L}\\) as functions of new variables \\(u\\), \\(v\\), \\(w\\). Then we want to find the vectors along the edges of the volume element in the \\(\\mathcal{U}\\), \\(v\\), \\(w\\) system. Suppose vector \\(\\mathbf{A}\\) in Figure 3.1 is along the direction in which \\(\\mathcal{U}\\) increases while \\(v\\) and \\(w\\) remain constant. Then if \\(d \\mathbf{r} = \\mathbf{i} \\, d x + \\mathbf{j} \\, d y + \\mathbf{k} \\, d z\\) is a vector in this direction, we have\n\n\\[\n\\mathbf{A} = \\frac{\\partial \\mathbf{r}}{\\partial u} \\, d u = \\left( \\mathbf{i} \\, \\frac{\\partial x}{\\partial u} + \\mathbf{j} \\, \\frac{\\partial y}{\\partial u} + \\mathbf{k} \\, \\frac{\\partial z}{\\partial u} \\right) \\, d u.\n\\]\n\nSimilarly, if \\(\\mathbf{B}\\) is along the increasing \\(v\\) edge of the volume element and \\(\\mathbf{C}\\) is along the increasing \\(w\\) edge, we have\n\n\\[\n\\begin{array}{l}\n{\\displaystyle{\\mathbf{B} = \\frac{\\partial \\mathbf{r}}{\\partial v} \\, d v = \\left( \\mathbf{i} \\, \\frac{\\partial x}{\\partial v} + \\mathbf{j} \\, \\frac{\\partial y}{\\partial v} + \\mathbf{k} \\, \\frac{\\partial z}{\\partial v} \\right) \\, d v,}} \\\\\n{\\displaystyle{\\mathbf{C} = \\frac{\\partial \\mathbf{r}}{\\partial w} \\, d w = \\left( \\mathbf{i} \\, \\frac{\\partial x}{\\partial w} + \\mathbf{j} \\, \\frac{\\partial y}{\\partial w} + \\mathbf{k} \\, \\frac{\\partial z}{\\partial w} \\right) \\, d w.}}\n\\end{array}\n\\]\n\nThen by (3.2)\n\n\\[\n\\mathbf{A} \\cdot (\\mathbf{B} \\times \\mathbf{C}) = \\left| \\frac{\\partial x}{\\partial u} \\quad \\frac{\\partial y}{\\partial u} \\quad \\frac{\\partial z}{\\partial u} \\right| \\, d u \\, d v \\, d w = J \\, d u \\, d v \\, d w\n\\]\n\nwhere \\(J\\) is the Jacobian of the transformation from \\(x\\), \\(y\\), \\(\\mathcal{Z}\\) to \\(u\\), \\(v\\), \\(w\\). Recall from the discussion of (3.2) that the triple scalar product may turn out to be positive or negative. Since we want a volume element to be positive, we use the absolute value of \\(J\\). Thus, the \\(u\\), \\(v\\), \\(w\\) volume element is \\(|J| \\, d u \\, d v \\, d w\\) as stated in Chapter 5, Section 4.\n\nApplications of the Triple Vector Product In Figure 3.8 (compare Figure 2.6), suppose the particle \\(_{T L}\\) is at rest on a rotating rigid body (for example, the earth). Then the angular momentum \\(\\mathbf{L}\\) of \\(_{f f t}\\) about point \\(O\\) is defined by the equation \\(\\mathbf{L} = \\mathbf{r} \\times (m \\mathbf{v}) = m \\mathbf{r} \\times \\mathbf{v}\\). In the discussion of Figure 2.6, we showed that \\(\\mathbf{v} = \\boldsymbol{\\omega} \\times \\mathbf{r}\\). Thus, \\(\\mathbf{L} = m \\mathbf{r} \\times (\\boldsymbol{\\omega} \\times \\mathbf{r})\\). See Problem 16 and also Chapter 10, Section 4.\n\nAs another example, it is shown in mechanics that the centripetal acceleration of \\(m\\) in Figure 3.8 is \\(\\mathbf{a} = \\boldsymbol{\\omega} \\times (\\boldsymbol{\\omega} \\times \\mathbf{r})\\). See Problem 17.\n\n![](images/f193a52234022a272488809d61a0ad5a333deefb4bce93f1bee538df9f2d9eee.jpg)\nFigure 3.8",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "\\(\\mathbf{A} = \frac{\\partial \\mathbf{r}}{\\partial u} \\, d u = \\left( \\mathbf{i} \\, \frac{\\partial x}{\\partial u} + \\mathbf{j} \\, \frac{\\partial y}{\\partial u} + \\mathbf{k} \\, \frac{\\partial z}{\\partial u} \right) \\, d u.\\)",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/Mathematical_Methods_in_the_Physical_Sciences-Third_Edition.pdf_301",
        "ID": "0f784eb0-c966-427b-a9af-9e179a979f42",
        "questions": "How is the Jacobian \\(J\\) related to the volume element transformation when moving from \\(x, y, \\mathcal{L}\\) to \\(u, v, w\\)?",
        "answers": "\\(\\mathbf{A} \\cdot (\\mathbf{B} \times \\mathbf{C}) = \\left| \frac{\\partial x}{\\partial u} \\quad \frac{\\partial y}{\\partial u} \\quad \frac{\\partial z}{\\partial u} \right| \\, d u \\, d v \\, d w = J \\, d u \\, d v \\, d w\\)",
        "context": "Example 2. As another application of the triple scalar product, let's find the Jacobian we used in Chapter 5, Section 4 for changing variables in a multiple integral. As you know, in rectangular coordinates the volume element is a rectangular box of volume \\(d x \\, d y \\, d z\\). In other coordinate systems, the volume element may be approximately a parallelpiped as in Figure 3.1. We want a formula for the volume element in this case. (See, for example, the cylindrical and spherical coordinate volume elements in Chapter 5, Figures 4.4 and 4.5.)\n\nSuppose we are given formulas for \\(x\\), \\(y\\), \\(\\mathcal{L}\\) as functions of new variables \\(u\\), \\(v\\), \\(w\\). Then we want to find the vectors along the edges of the volume element in the \\(\\mathcal{U}\\), \\(v\\), \\(w\\) system. Suppose vector \\(\\mathbf{A}\\) in Figure 3.1 is along the direction in which \\(\\mathcal{U}\\) increases while \\(v\\) and \\(w\\) remain constant. Then if \\(d \\mathbf{r} = \\mathbf{i} \\, d x + \\mathbf{j} \\, d y + \\mathbf{k} \\, d z\\) is a vector in this direction, we have\n\n\\[\n\\mathbf{A} = \\frac{\\partial \\mathbf{r}}{\\partial u} \\, d u = \\left( \\mathbf{i} \\, \\frac{\\partial x}{\\partial u} + \\mathbf{j} \\, \\frac{\\partial y}{\\partial u} + \\mathbf{k} \\, \\frac{\\partial z}{\\partial u} \\right) \\, d u.\n\\]\n\nSimilarly, if \\(\\mathbf{B}\\) is along the increasing \\(v\\) edge of the volume element and \\(\\mathbf{C}\\) is along the increasing \\(w\\) edge, we have\n\n\\[\n\\begin{array}{l}\n{\\displaystyle{\\mathbf{B} = \\frac{\\partial \\mathbf{r}}{\\partial v} \\, d v = \\left( \\mathbf{i} \\, \\frac{\\partial x}{\\partial v} + \\mathbf{j} \\, \\frac{\\partial y}{\\partial v} + \\mathbf{k} \\, \\frac{\\partial z}{\\partial v} \\right) \\, d v,}} \\\\\n{\\displaystyle{\\mathbf{C} = \\frac{\\partial \\mathbf{r}}{\\partial w} \\, d w = \\left( \\mathbf{i} \\, \\frac{\\partial x}{\\partial w} + \\mathbf{j} \\, \\frac{\\partial y}{\\partial w} + \\mathbf{k} \\, \\frac{\\partial z}{\\partial w} \\right) \\, d w.}}\n\\end{array}\n\\]\n\nThen by (3.2)\n\n\\[\n\\mathbf{A} \\cdot (\\mathbf{B} \\times \\mathbf{C}) = \\left| \\frac{\\partial x}{\\partial u} \\quad \\frac{\\partial y}{\\partial u} \\quad \\frac{\\partial z}{\\partial u} \\right| \\, d u \\, d v \\, d w = J \\, d u \\, d v \\, d w\n\\]\n\nwhere \\(J\\) is the Jacobian of the transformation from \\(x\\), \\(y\\), \\(\\mathcal{Z}\\) to \\(u\\), \\(v\\), \\(w\\). Recall from the discussion of (3.2) that the triple scalar product may turn out to be positive or negative. Since we want a volume element to be positive, we use the absolute value of \\(J\\). Thus, the \\(u\\), \\(v\\), \\(w\\) volume element is \\(|J| \\, d u \\, d v \\, d w\\) as stated in Chapter 5, Section 4.\n\nApplications of the Triple Vector Product In Figure 3.8 (compare Figure 2.6), suppose the particle \\(_{T L}\\) is at rest on a rotating rigid body (for example, the earth). Then the angular momentum \\(\\mathbf{L}\\) of \\(_{f f t}\\) about point \\(O\\) is defined by the equation \\(\\mathbf{L} = \\mathbf{r} \\times (m \\mathbf{v}) = m \\mathbf{r} \\times \\mathbf{v}\\). In the discussion of Figure 2.6, we showed that \\(\\mathbf{v} = \\boldsymbol{\\omega} \\times \\mathbf{r}\\). Thus, \\(\\mathbf{L} = m \\mathbf{r} \\times (\\boldsymbol{\\omega} \\times \\mathbf{r})\\). See Problem 16 and also Chapter 10, Section 4.\n\nAs another example, it is shown in mechanics that the centripetal acceleration of \\(m\\) in Figure 3.8 is \\(\\mathbf{a} = \\boldsymbol{\\omega} \\times (\\boldsymbol{\\omega} \\times \\mathbf{r})\\). See Problem 17.\n\n![](images/f193a52234022a272488809d61a0ad5a333deefb4bce93f1bee538df9f2d9eee.jpg)\nFigure 3.8",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "\\(\\mathbf{A} \\cdot (\\mathbf{B} \times \\mathbf{C}) = \\left| \frac{\\partial x}{\\partial u} \\quad \frac{\\partial y}{\\partial u} \\quad \frac{\\partial z}{\\partial u} \right| \\, d u \\, d v \\, d w = J \\, d u \\, d v \\, d w\\)",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/Mathematical_Methods_in_the_Physical_Sciences-Third_Edition.pdf_301",
        "ID": "0f7b2413-3e36-44ac-87bd-0b54b97eb522",
        "questions": "How is the angular momentum \\(\\mathbf{L}\\) of a particle of mass \\(m\\) at rest on a rotating rigid body about point \\(O\\) defined in terms of \\(\\mathbf{r}\\), \\(m\\), and \\(\\mathbf{v}\\)?",
        "answers": "\\(\\mathbf{L} = \\mathbf{r} \times (m \\mathbf{v}) = m \\mathbf{r} \times \\mathbf{v}\\)",
        "context": "Example 2. As another application of the triple scalar product, let's find the Jacobian we used in Chapter 5, Section 4 for changing variables in a multiple integral. As you know, in rectangular coordinates the volume element is a rectangular box of volume \\(d x \\, d y \\, d z\\). In other coordinate systems, the volume element may be approximately a parallelpiped as in Figure 3.1. We want a formula for the volume element in this case. (See, for example, the cylindrical and spherical coordinate volume elements in Chapter 5, Figures 4.4 and 4.5.)\n\nSuppose we are given formulas for \\(x\\), \\(y\\), \\(\\mathcal{L}\\) as functions of new variables \\(u\\), \\(v\\), \\(w\\). Then we want to find the vectors along the edges of the volume element in the \\(\\mathcal{U}\\), \\(v\\), \\(w\\) system. Suppose vector \\(\\mathbf{A}\\) in Figure 3.1 is along the direction in which \\(\\mathcal{U}\\) increases while \\(v\\) and \\(w\\) remain constant. Then if \\(d \\mathbf{r} = \\mathbf{i} \\, d x + \\mathbf{j} \\, d y + \\mathbf{k} \\, d z\\) is a vector in this direction, we have\n\n\\[\n\\mathbf{A} = \\frac{\\partial \\mathbf{r}}{\\partial u} \\, d u = \\left( \\mathbf{i} \\, \\frac{\\partial x}{\\partial u} + \\mathbf{j} \\, \\frac{\\partial y}{\\partial u} + \\mathbf{k} \\, \\frac{\\partial z}{\\partial u} \\right) \\, d u.\n\\]\n\nSimilarly, if \\(\\mathbf{B}\\) is along the increasing \\(v\\) edge of the volume element and \\(\\mathbf{C}\\) is along the increasing \\(w\\) edge, we have\n\n\\[\n\\begin{array}{l}\n{\\displaystyle{\\mathbf{B} = \\frac{\\partial \\mathbf{r}}{\\partial v} \\, d v = \\left( \\mathbf{i} \\, \\frac{\\partial x}{\\partial v} + \\mathbf{j} \\, \\frac{\\partial y}{\\partial v} + \\mathbf{k} \\, \\frac{\\partial z}{\\partial v} \\right) \\, d v,}} \\\\\n{\\displaystyle{\\mathbf{C} = \\frac{\\partial \\mathbf{r}}{\\partial w} \\, d w = \\left( \\mathbf{i} \\, \\frac{\\partial x}{\\partial w} + \\mathbf{j} \\, \\frac{\\partial y}{\\partial w} + \\mathbf{k} \\, \\frac{\\partial z}{\\partial w} \\right) \\, d w.}}\n\\end{array}\n\\]\n\nThen by (3.2)\n\n\\[\n\\mathbf{A} \\cdot (\\mathbf{B} \\times \\mathbf{C}) = \\left| \\frac{\\partial x}{\\partial u} \\quad \\frac{\\partial y}{\\partial u} \\quad \\frac{\\partial z}{\\partial u} \\right| \\, d u \\, d v \\, d w = J \\, d u \\, d v \\, d w\n\\]\n\nwhere \\(J\\) is the Jacobian of the transformation from \\(x\\), \\(y\\), \\(\\mathcal{Z}\\) to \\(u\\), \\(v\\), \\(w\\). Recall from the discussion of (3.2) that the triple scalar product may turn out to be positive or negative. Since we want a volume element to be positive, we use the absolute value of \\(J\\). Thus, the \\(u\\), \\(v\\), \\(w\\) volume element is \\(|J| \\, d u \\, d v \\, d w\\) as stated in Chapter 5, Section 4.\n\nApplications of the Triple Vector Product In Figure 3.8 (compare Figure 2.6), suppose the particle \\(_{T L}\\) is at rest on a rotating rigid body (for example, the earth). Then the angular momentum \\(\\mathbf{L}\\) of \\(_{f f t}\\) about point \\(O\\) is defined by the equation \\(\\mathbf{L} = \\mathbf{r} \\times (m \\mathbf{v}) = m \\mathbf{r} \\times \\mathbf{v}\\). In the discussion of Figure 2.6, we showed that \\(\\mathbf{v} = \\boldsymbol{\\omega} \\times \\mathbf{r}\\). Thus, \\(\\mathbf{L} = m \\mathbf{r} \\times (\\boldsymbol{\\omega} \\times \\mathbf{r})\\). See Problem 16 and also Chapter 10, Section 4.\n\nAs another example, it is shown in mechanics that the centripetal acceleration of \\(m\\) in Figure 3.8 is \\(\\mathbf{a} = \\boldsymbol{\\omega} \\times (\\boldsymbol{\\omega} \\times \\mathbf{r})\\). See Problem 17.\n\n![](images/f193a52234022a272488809d61a0ad5a333deefb4bce93f1bee538df9f2d9eee.jpg)\nFigure 3.8",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "\\(\\mathbf{L} = \\mathbf{r} \times (m \\mathbf{v}) = m \\mathbf{r} \times \\mathbf{v}\\)",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/3140.pdf_283",
        "ID": "0f8b4ec8-66ae-41bd-b3e5-7e85cd4aa89a",
        "questions": "What is the percentage of non-white composers programmed at the University of Wisconsin-Madison?",
        "answers": "13.28%",
        "context": "of Wisconsin-Madison, $11.72\\%$ of 128; University of Tennessee, $11.81\\%$ of 127. Even so the lowest percentage of male composes is a shockingly high number ($83.33\\%$)\n\n$\n\\caption{Table 15.3 The number and percentages of white vs non-white (Asian, Black, and Latin(a/o)) composers programmed at each university.}\n\\begin{tabular}{l|c|c|c|c|c|c|c}\n \nUniversity & Total No. Composers & No.White Composers & Percentage White Composers & No.Asian Composers & No.Black Composers & No. Latin(a/o) Composers & Percentage Non-White Composers \\\\  \nUniversity of Wisconsin-Madison & 128 & 111 & 86.72\\% & 4 & 6 & 7 & 13.28\\% \\\\  \nEastman School of Music & 153 & 137 & 89.54\\% & 4 & 4 & 8 & 10.46\\% \\\\  \nThe Ohio State University & 137 & 123 & 89.78\\% & 6 & 3 & 5 & 10.22\\% \\\\  \nUniversity of California, Los Angeles & 41 & 37 & 90.24\\% & 2 & 1 & 1 & 9.76\\% \\\\  \nWashington University at St. Louis & 72 & 66 & 91.67\\% & 0 & 2 & 4 & 8.33\\% \\\\  \nUniversity of Hawaii at Manoa & 48 & 44 & 91.67\\% & 3 & 1 & 0 & 8.33\\% \\\\  \nUniversity of South Carolina & 69 & 64 & 92.75\\% & 0 & 4 & 1 & 7.25\\% \\\\  \nUniversity of Tennessee & 127 & 118 & 92.91\\% & 2 & 5 & 2 & 7.09\\% \\\\  \nIndiana University & 176 & 164 & 93.18\\% & 6 & 5 & 1 & 6.82\\% \\\\  \nUniversity of North Texas & 252 & 236 & 93.65\\% & 4 & 9 & 3 & 6.35\\% \\\\  \nUniversity of Massachusetts at Amherst & 85 & 80 & 94.12\\% & 3 & 1 & 1 & 5.88\\% \\\\  \nUniversity of Texas at Austin & 149 & 141 & 94.63\\% & 4 & 3 & 1 & 5.37\\% \\\\  \nBoston University & 66 & 63 & 95.45\\% & 0 & 2 & 1 & 4.55\\% \\\\  \nAverages & & & 92.02\\% & & & & 7.98\\% \\\\  \n\\end{tabular}\n$\n\nThe data on white versus non-white composers shown in table 15.3 also reveals the bias of the musical canon. The percentage of non-white composers programmed ranges from $4.55\\%$ (Boston University) to $13.28\\%$ (University of Wisconsin-Madison) with an average of $7.98\\%$ non-white composers. Eight of the schools programmed pieces by fewer than ten non-white composers. Again, even the lowest percentage of white composers, $86.72\\%$, is still very high.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "table",
        "evidence_context": "University of Wisconsin-Madison & 128 & 111 & 86.72% & 4 & 6 & 7 & 13.28%",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/3140.pdf_283",
        "ID": "0f8f2ec6-64f6-4d04-ad7e-2d589d993a9b",
        "questions": "Which university has the highest percentage of white composers, and what is that percentage?",
        "answers": "Boston University, 95.45%",
        "context": "of Wisconsin-Madison, $11.72\\%$ of 128; University of Tennessee, $11.81\\%$ of 127. Even so the lowest percentage of male composes is a shockingly high number ($83.33\\%$)\n\n$\n\\caption{Table 15.3 The number and percentages of white vs non-white (Asian, Black, and Latin(a/o)) composers programmed at each university.}\n\\begin{tabular}{l|c|c|c|c|c|c|c}\n \nUniversity & Total No. Composers & No.White Composers & Percentage White Composers & No.Asian Composers & No.Black Composers & No. Latin(a/o) Composers & Percentage Non-White Composers \\\\  \nUniversity of Wisconsin-Madison & 128 & 111 & 86.72\\% & 4 & 6 & 7 & 13.28\\% \\\\  \nEastman School of Music & 153 & 137 & 89.54\\% & 4 & 4 & 8 & 10.46\\% \\\\  \nThe Ohio State University & 137 & 123 & 89.78\\% & 6 & 3 & 5 & 10.22\\% \\\\  \nUniversity of California, Los Angeles & 41 & 37 & 90.24\\% & 2 & 1 & 1 & 9.76\\% \\\\  \nWashington University at St. Louis & 72 & 66 & 91.67\\% & 0 & 2 & 4 & 8.33\\% \\\\  \nUniversity of Hawaii at Manoa & 48 & 44 & 91.67\\% & 3 & 1 & 0 & 8.33\\% \\\\  \nUniversity of South Carolina & 69 & 64 & 92.75\\% & 0 & 4 & 1 & 7.25\\% \\\\  \nUniversity of Tennessee & 127 & 118 & 92.91\\% & 2 & 5 & 2 & 7.09\\% \\\\  \nIndiana University & 176 & 164 & 93.18\\% & 6 & 5 & 1 & 6.82\\% \\\\  \nUniversity of North Texas & 252 & 236 & 93.65\\% & 4 & 9 & 3 & 6.35\\% \\\\  \nUniversity of Massachusetts at Amherst & 85 & 80 & 94.12\\% & 3 & 1 & 1 & 5.88\\% \\\\  \nUniversity of Texas at Austin & 149 & 141 & 94.63\\% & 4 & 3 & 1 & 5.37\\% \\\\  \nBoston University & 66 & 63 & 95.45\\% & 0 & 2 & 1 & 4.55\\% \\\\  \nAverages & & & 92.02\\% & & & & 7.98\\% \\\\  \n\\end{tabular}\n$\n\nThe data on white versus non-white composers shown in table 15.3 also reveals the bias of the musical canon. The percentage of non-white composers programmed ranges from $4.55\\%$ (Boston University) to $13.28\\%$ (University of Wisconsin-Madison) with an average of $7.98\\%$ non-white composers. Eight of the schools programmed pieces by fewer than ten non-white composers. Again, even the lowest percentage of white composers, $86.72\\%$, is still very high.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "table",
        "evidence_context": "Boston University & 66 & 63 & 95.45% & 0 & 2 & 1 & 4.55%",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/3140.pdf_283",
        "ID": "0f95b88a-8960-4a04-b6bb-de06429a8f86",
        "questions": "What is the average percentage of white composers programmed across all the schools listed in the table, and how does this reflect on the diversity in the musical canon?",
        "answers": "92.02%, it reveals the bias of the musical canon.",
        "context": "of Wisconsin-Madison, $11.72\\%$ of 128; University of Tennessee, $11.81\\%$ of 127. Even so the lowest percentage of male composes is a shockingly high number ($83.33\\%$)\n\n$\n\\caption{Table 15.3 The number and percentages of white vs non-white (Asian, Black, and Latin(a/o)) composers programmed at each university.}\n\\begin{tabular}{l|c|c|c|c|c|c|c}\n \nUniversity & Total No. Composers & No.White Composers & Percentage White Composers & No.Asian Composers & No.Black Composers & No. Latin(a/o) Composers & Percentage Non-White Composers \\\\  \nUniversity of Wisconsin-Madison & 128 & 111 & 86.72\\% & 4 & 6 & 7 & 13.28\\% \\\\  \nEastman School of Music & 153 & 137 & 89.54\\% & 4 & 4 & 8 & 10.46\\% \\\\  \nThe Ohio State University & 137 & 123 & 89.78\\% & 6 & 3 & 5 & 10.22\\% \\\\  \nUniversity of California, Los Angeles & 41 & 37 & 90.24\\% & 2 & 1 & 1 & 9.76\\% \\\\  \nWashington University at St. Louis & 72 & 66 & 91.67\\% & 0 & 2 & 4 & 8.33\\% \\\\  \nUniversity of Hawaii at Manoa & 48 & 44 & 91.67\\% & 3 & 1 & 0 & 8.33\\% \\\\  \nUniversity of South Carolina & 69 & 64 & 92.75\\% & 0 & 4 & 1 & 7.25\\% \\\\  \nUniversity of Tennessee & 127 & 118 & 92.91\\% & 2 & 5 & 2 & 7.09\\% \\\\  \nIndiana University & 176 & 164 & 93.18\\% & 6 & 5 & 1 & 6.82\\% \\\\  \nUniversity of North Texas & 252 & 236 & 93.65\\% & 4 & 9 & 3 & 6.35\\% \\\\  \nUniversity of Massachusetts at Amherst & 85 & 80 & 94.12\\% & 3 & 1 & 1 & 5.88\\% \\\\  \nUniversity of Texas at Austin & 149 & 141 & 94.63\\% & 4 & 3 & 1 & 5.37\\% \\\\  \nBoston University & 66 & 63 & 95.45\\% & 0 & 2 & 1 & 4.55\\% \\\\  \nAverages & & & 92.02\\% & & & & 7.98\\% \\\\  \n\\end{tabular}\n$\n\nThe data on white versus non-white composers shown in table 15.3 also reveals the bias of the musical canon. The percentage of non-white composers programmed ranges from $4.55\\%$ (Boston University) to $13.28\\%$ (University of Wisconsin-Madison) with an average of $7.98\\%$ non-white composers. Eight of the schools programmed pieces by fewer than ten non-white composers. Again, even the lowest percentage of white composers, $86.72\\%$, is still very high.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "The percentage of non-white composers programmed ranges from $4.55\\%$ (Boston University) to $13.28\\%$ (University of Wisconsin-Madison) with an average of $7.98\\%$ non-white composers. Again, even the lowest percentage of white composers, $86.72\\%$, is still very high.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/3140.pdf_283",
        "ID": "0f95e151-d3fd-4719-b4aa-1dca8f534838",
        "questions": "What is the percentage of non-white composers programmed at the Eastman School of Music?",
        "answers": "10.46%",
        "context": "of Wisconsin-Madison, $11.72\\%$ of 128; University of Tennessee, $11.81\\%$ of 127. Even so the lowest percentage of male composes is a shockingly high number ($83.33\\%$)\n\n$\n\\caption{Table 15.3 The number and percentages of white vs non-white (Asian, Black, and Latin(a/o)) composers programmed at each university.}\n\\begin{tabular}{l|c|c|c|c|c|c|c}\n \nUniversity & Total No. Composers & No.White Composers & Percentage White Composers & No.Asian Composers & No.Black Composers & No. Latin(a/o) Composers & Percentage Non-White Composers \\\\  \nUniversity of Wisconsin-Madison & 128 & 111 & 86.72\\% & 4 & 6 & 7 & 13.28\\% \\\\  \nEastman School of Music & 153 & 137 & 89.54\\% & 4 & 4 & 8 & 10.46\\% \\\\  \nThe Ohio State University & 137 & 123 & 89.78\\% & 6 & 3 & 5 & 10.22\\% \\\\  \nUniversity of California, Los Angeles & 41 & 37 & 90.24\\% & 2 & 1 & 1 & 9.76\\% \\\\  \nWashington University at St. Louis & 72 & 66 & 91.67\\% & 0 & 2 & 4 & 8.33\\% \\\\  \nUniversity of Hawaii at Manoa & 48 & 44 & 91.67\\% & 3 & 1 & 0 & 8.33\\% \\\\  \nUniversity of South Carolina & 69 & 64 & 92.75\\% & 0 & 4 & 1 & 7.25\\% \\\\  \nUniversity of Tennessee & 127 & 118 & 92.91\\% & 2 & 5 & 2 & 7.09\\% \\\\  \nIndiana University & 176 & 164 & 93.18\\% & 6 & 5 & 1 & 6.82\\% \\\\  \nUniversity of North Texas & 252 & 236 & 93.65\\% & 4 & 9 & 3 & 6.35\\% \\\\  \nUniversity of Massachusetts at Amherst & 85 & 80 & 94.12\\% & 3 & 1 & 1 & 5.88\\% \\\\  \nUniversity of Texas at Austin & 149 & 141 & 94.63\\% & 4 & 3 & 1 & 5.37\\% \\\\  \nBoston University & 66 & 63 & 95.45\\% & 0 & 2 & 1 & 4.55\\% \\\\  \nAverages & & & 92.02\\% & & & & 7.98\\% \\\\  \n\\end{tabular}\n$\n\nThe data on white versus non-white composers shown in table 15.3 also reveals the bias of the musical canon. The percentage of non-white composers programmed ranges from $4.55\\%$ (Boston University) to $13.28\\%$ (University of Wisconsin-Madison) with an average of $7.98\\%$ non-white composers. Eight of the schools programmed pieces by fewer than ten non-white composers. Again, even the lowest percentage of white composers, $86.72\\%$, is still very high.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Numeric",
        "evidence_source": "equation",
        "evidence_context": "\\begin{tabular}{l|c|c|c|c|c|c|c} \\hline \\textbf{University} & \\textbf{Total No. Composers} & \\textbf{No.White Composers} & \\textbf{Percentage White Composers} & \\textbf{No.Asian Composers} & \\textbf{No.Black Composers} & \\textbf{No. Latin(a/o) Composers} & \\textbf{Percentage Non-White Composers} \\\\ \\hline Eastman School of Music & 153 & 137 & 89.54\\% & 4 & 4 & 8 & 10.46\\% \\\\ \\hline",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/3140.pdf_283",
        "ID": "0fa07a3f-2e29-4065-afa2-31e959acdd98",
        "questions": "Which university has exactly 44 white composers, and what is their percentage of white composers?",
        "answers": "University of Hawaii at Manoa, 91.67%",
        "context": "of Wisconsin-Madison, $11.72\\%$ of 128; University of Tennessee, $11.81\\%$ of 127. Even so the lowest percentage of male composes is a shockingly high number ($83.33\\%$)\n\n$\n\\caption{Table 15.3 The number and percentages of white vs non-white (Asian, Black, and Latin(a/o)) composers programmed at each university.}\n\\begin{tabular}{l|c|c|c|c|c|c|c}\n \nUniversity & Total No. Composers & No.White Composers & Percentage White Composers & No.Asian Composers & No.Black Composers & No. Latin(a/o) Composers & Percentage Non-White Composers \\\\  \nUniversity of Wisconsin-Madison & 128 & 111 & 86.72\\% & 4 & 6 & 7 & 13.28\\% \\\\  \nEastman School of Music & 153 & 137 & 89.54\\% & 4 & 4 & 8 & 10.46\\% \\\\  \nThe Ohio State University & 137 & 123 & 89.78\\% & 6 & 3 & 5 & 10.22\\% \\\\  \nUniversity of California, Los Angeles & 41 & 37 & 90.24\\% & 2 & 1 & 1 & 9.76\\% \\\\  \nWashington University at St. Louis & 72 & 66 & 91.67\\% & 0 & 2 & 4 & 8.33\\% \\\\  \nUniversity of Hawaii at Manoa & 48 & 44 & 91.67\\% & 3 & 1 & 0 & 8.33\\% \\\\  \nUniversity of South Carolina & 69 & 64 & 92.75\\% & 0 & 4 & 1 & 7.25\\% \\\\  \nUniversity of Tennessee & 127 & 118 & 92.91\\% & 2 & 5 & 2 & 7.09\\% \\\\  \nIndiana University & 176 & 164 & 93.18\\% & 6 & 5 & 1 & 6.82\\% \\\\  \nUniversity of North Texas & 252 & 236 & 93.65\\% & 4 & 9 & 3 & 6.35\\% \\\\  \nUniversity of Massachusetts at Amherst & 85 & 80 & 94.12\\% & 3 & 1 & 1 & 5.88\\% \\\\  \nUniversity of Texas at Austin & 149 & 141 & 94.63\\% & 4 & 3 & 1 & 5.37\\% \\\\  \nBoston University & 66 & 63 & 95.45\\% & 0 & 2 & 1 & 4.55\\% \\\\  \nAverages & & & 92.02\\% & & & & 7.98\\% \\\\  \n\\end{tabular}\n$\n\nThe data on white versus non-white composers shown in table 15.3 also reveals the bias of the musical canon. The percentage of non-white composers programmed ranges from $4.55\\%$ (Boston University) to $13.28\\%$ (University of Wisconsin-Madison) with an average of $7.98\\%$ non-white composers. Eight of the schools programmed pieces by fewer than ten non-white composers. Again, even the lowest percentage of white composers, $86.72\\%$, is still very high.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "\\begin{tabular}{l|c|c|c|c|c|c|c} \\hline \\textbf{University} & \\textbf{Total No. Composers} & \\textbf{No.White Composers} & \\textbf{Percentage White Composers} & \\textbf{No.Asian Composers} & \\textbf{No.Black Composers} & \\textbf{No. Latin(a/o) Composers} & \\textbf{Percentage Non-White Composers} \\\\ \\hline University of Hawaii at Manoa & 48 & 44 & 91.67\\% & 3 & 1 & 0 & 8.33\\% \\\\ \\hline",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/3140.pdf_283",
        "ID": "0fa300b3-2f8b-477b-8897-82b2495f3505",
        "questions": "Given the universities listed with the percentage of non-white composers, which one has the highest percentage, and what is the exact value?",
        "answers": "University of Wisconsin-Madison, 13.28%",
        "context": "of Wisconsin-Madison, $11.72\\%$ of 128; University of Tennessee, $11.81\\%$ of 127. Even so the lowest percentage of male composes is a shockingly high number ($83.33\\%$)\n\n$\n\\caption{Table 15.3 The number and percentages of white vs non-white (Asian, Black, and Latin(a/o)) composers programmed at each university.}\n\\begin{tabular}{l|c|c|c|c|c|c|c}\n \nUniversity & Total No. Composers & No.White Composers & Percentage White Composers & No.Asian Composers & No.Black Composers & No. Latin(a/o) Composers & Percentage Non-White Composers \\\\  \nUniversity of Wisconsin-Madison & 128 & 111 & 86.72\\% & 4 & 6 & 7 & 13.28\\% \\\\  \nEastman School of Music & 153 & 137 & 89.54\\% & 4 & 4 & 8 & 10.46\\% \\\\  \nThe Ohio State University & 137 & 123 & 89.78\\% & 6 & 3 & 5 & 10.22\\% \\\\  \nUniversity of California, Los Angeles & 41 & 37 & 90.24\\% & 2 & 1 & 1 & 9.76\\% \\\\  \nWashington University at St. Louis & 72 & 66 & 91.67\\% & 0 & 2 & 4 & 8.33\\% \\\\  \nUniversity of Hawaii at Manoa & 48 & 44 & 91.67\\% & 3 & 1 & 0 & 8.33\\% \\\\  \nUniversity of South Carolina & 69 & 64 & 92.75\\% & 0 & 4 & 1 & 7.25\\% \\\\  \nUniversity of Tennessee & 127 & 118 & 92.91\\% & 2 & 5 & 2 & 7.09\\% \\\\  \nIndiana University & 176 & 164 & 93.18\\% & 6 & 5 & 1 & 6.82\\% \\\\  \nUniversity of North Texas & 252 & 236 & 93.65\\% & 4 & 9 & 3 & 6.35\\% \\\\  \nUniversity of Massachusetts at Amherst & 85 & 80 & 94.12\\% & 3 & 1 & 1 & 5.88\\% \\\\  \nUniversity of Texas at Austin & 149 & 141 & 94.63\\% & 4 & 3 & 1 & 5.37\\% \\\\  \nBoston University & 66 & 63 & 95.45\\% & 0 & 2 & 1 & 4.55\\% \\\\  \nAverages & & & 92.02\\% & & & & 7.98\\% \\\\  \n\\end{tabular}\n$\n\nThe data on white versus non-white composers shown in table 15.3 also reveals the bias of the musical canon. The percentage of non-white composers programmed ranges from $4.55\\%$ (Boston University) to $13.28\\%$ (University of Wisconsin-Madison) with an average of $7.98\\%$ non-white composers. Eight of the schools programmed pieces by fewer than ten non-white composers. Again, even the lowest percentage of white composers, $86.72\\%$, is still very high.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "\\begin{tabular}{l|c|c|c|c|c|c|c} \\hline \\textbf{University} & \\textbf{Total No. Composers} & \\textbf{No.White Composers} & \\textbf{Percentage White Composers} & \\textbf{No.Asian Composers} & \\textbf{No.Black Composers} & \\textbf{No. Latin(a/o) Composers} & \\textbf{Percentage Non-White Composers} \\\\ \\hline University of Wisconsin-Madison & 128 & 111 & 86.72\\% & 4 & 6 & 7 & 13.28\\% \\\\ \\hline",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/[Svetoslav_Savchev,_Titu_Andreescu]_Mathematical_M(z-lib.org).pdf_181",
        "ID": "0fa34543-b36c-417a-9162-3bd2cad60db8",
        "questions": "What is the sum of the first 1000 integers starting from 1 if at each step we remove one pebble from the same pile?",
        "answers": "500,500",
        "context": "# Solutions  \n\n1. This sum has just one possible value: 500,500. It is easy to guess the answer: If at each step we remove one pebble from the same pile, the sum will be  \n\n$$\n1000+999+998+\\cdots+2+1=500,500.\n$$  \n\nThere are different ways to prove that the same result will be obtained in all cases. Here is probably the shortest one. Imagine that initially each pebble is connected to each other pebble by a thread. When partitioning some pile into two smaller ones, assume that all the threads connecting pebbles that go to different piles are being cut. The number of these threads is exactly equal to the product of the number of pebbles in the smaller piles. Hence in all cases the sum in question will be equal to the total number of threads, that is, to  $1001\\cdot1000/2=500,500$.\n\n1. Project the discs onto the common line  $l$  of the two planes. We obtain two line segments with lengths equal to the corresponding diameters. But these line segments are obliged to coincide, since each of them may be regarded as the orthogonal projection of the set itself onto $l$.  \n\nThere are sets with the described property that are not spheres, for example, the common part of three right circular cylinders with pairwise perpendicular axes passing through a common point. It is another story that if any plane section of a three-dimensional point set is a circular disc, then the set is a ball.  \n\n3. Color the squares of the grid with n colors as shown in the left-hand figure below. Note that the main diagonal squares are exactly the ones colored with 1.  \n\n$\n \\begin{tabular}{|c|c|c|c|c|c|}  1 & 2 & 3 & & & $n$ \\  $n$ & 1 & 2 & 3 & & \\   & $n$ & 1 & 2 & 3 & \\   & & $n$ & 1 & 2 & 3 \\  3 & & & $n$ & 1 & 2 \\  2 & 3 & & & $n$ & 1 \\  \\end{tabular}\\quad\\begin{tabular}{|c|c|c|c|c|c|}  2 & 3 & & & $n$ & 1 \\  1 & 2 & 3 & & & $n$ \\  $n$ & 1 & 2 & 3 & & \\   & $n$ & 1 & 2 & 3 & \\   & & $n$ & 1 & 2 & 3 \\  \\end{tabular}\\quad\\begin{tabular}{|c|c|c|c|c|c|}  3 & & & $n$ & 1 & 2 \\  2 & 3 & & & $n$ & 1 \\  1 & 2 & 3 & & & $n$ \\  $n$ & 1 & 2 & 3 & & \\   & $n$ & 1 & 2 & 3 & \\   & & $n$ & 1 & 2 & 3 \\  \\end{tabular}\\end{table}\n$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Numeric",
        "evidence_source": "text",
        "evidence_context": "It is easy to guess the answer: If at each step we remove one pebble from the same pile, the sum will be $1000 + 999 + 998 + \\cdots + 2 + 1 = 500,500$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/[Svetoslav_Savchev,_Titu_Andreescu]_Mathematical_M(z-lib.org).pdf_181",
        "ID": "0fa66354-2fca-4ae3-aa97-673e35001aa9",
        "questions": "How is the number of threads connecting pebbles from different piles calculated when partitioning a pile into two smaller ones?",
        "answers": "The number of these threads is exactly equal to the product of the number of pebbles in the smaller piles.",
        "context": "# Solutions  \n\n1. This sum has just one possible value: 500,500. It is easy to guess the answer: If at each step we remove one pebble from the same pile, the sum will be  \n\n$$\n1000+999+998+\\cdots+2+1=500,500.\n$$  \n\nThere are different ways to prove that the same result will be obtained in all cases. Here is probably the shortest one. Imagine that initially each pebble is connected to each other pebble by a thread. When partitioning some pile into two smaller ones, assume that all the threads connecting pebbles that go to different piles are being cut. The number of these threads is exactly equal to the product of the number of pebbles in the smaller piles. Hence in all cases the sum in question will be equal to the total number of threads, that is, to  $1001\\cdot1000/2=500,500$.\n\n1. Project the discs onto the common line  $l$  of the two planes. We obtain two line segments with lengths equal to the corresponding diameters. But these line segments are obliged to coincide, since each of them may be regarded as the orthogonal projection of the set itself onto $l$.  \n\nThere are sets with the described property that are not spheres, for example, the common part of three right circular cylinders with pairwise perpendicular axes passing through a common point. It is another story that if any plane section of a three-dimensional point set is a circular disc, then the set is a ball.  \n\n3. Color the squares of the grid with n colors as shown in the left-hand figure below. Note that the main diagonal squares are exactly the ones colored with 1.  \n\n$\n \\begin{tabular}{|c|c|c|c|c|c|}  1 & 2 & 3 & & & $n$ \\  $n$ & 1 & 2 & 3 & & \\   & $n$ & 1 & 2 & 3 & \\   & & $n$ & 1 & 2 & 3 \\  3 & & & $n$ & 1 & 2 \\  2 & 3 & & & $n$ & 1 \\  \\end{tabular}\\quad\\begin{tabular}{|c|c|c|c|c|c|}  2 & 3 & & & $n$ & 1 \\  1 & 2 & 3 & & & $n$ \\  $n$ & 1 & 2 & 3 & & \\   & $n$ & 1 & 2 & 3 & \\   & & $n$ & 1 & 2 & 3 \\  \\end{tabular}\\quad\\begin{tabular}{|c|c|c|c|c|c|}  3 & & & $n$ & 1 & 2 \\  2 & 3 & & & $n$ & 1 \\  1 & 2 & 3 & & & $n$ \\  $n$ & 1 & 2 & 3 & & \\   & $n$ & 1 & 2 & 3 & \\   & & $n$ & 1 & 2 & 3 \\  \\end{tabular}\\end{table}\n$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Assume that all the threads connecting pebbles that go to different piles are being cut. The number of these threads is exactly equal to the product of the number of pebbles in the smaller piles.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/[Svetoslav_Savchev,_Titu_Andreescu]_Mathematical_M(z-lib.org).pdf_181",
        "ID": "0fa8aee9-1ba4-4eaf-84f4-d346d3016d9e",
        "questions": "What property proves that a three-dimensional point set is a ball if any plane section of the set is a circular disc?",
        "answers": "If any plane section of a three-dimensional point set is a circular disc, then the set is a ball.",
        "context": "# Solutions  \n\n1. This sum has just one possible value: 500,500. It is easy to guess the answer: If at each step we remove one pebble from the same pile, the sum will be  \n\n$$\n1000+999+998+\\cdots+2+1=500,500.\n$$  \n\nThere are different ways to prove that the same result will be obtained in all cases. Here is probably the shortest one. Imagine that initially each pebble is connected to each other pebble by a thread. When partitioning some pile into two smaller ones, assume that all the threads connecting pebbles that go to different piles are being cut. The number of these threads is exactly equal to the product of the number of pebbles in the smaller piles. Hence in all cases the sum in question will be equal to the total number of threads, that is, to  $1001\\cdot1000/2=500,500$.\n\n1. Project the discs onto the common line  $l$  of the two planes. We obtain two line segments with lengths equal to the corresponding diameters. But these line segments are obliged to coincide, since each of them may be regarded as the orthogonal projection of the set itself onto $l$.  \n\nThere are sets with the described property that are not spheres, for example, the common part of three right circular cylinders with pairwise perpendicular axes passing through a common point. It is another story that if any plane section of a three-dimensional point set is a circular disc, then the set is a ball.  \n\n3. Color the squares of the grid with n colors as shown in the left-hand figure below. Note that the main diagonal squares are exactly the ones colored with 1.  \n\n$\n \\begin{tabular}{|c|c|c|c|c|c|}  1 & 2 & 3 & & & $n$ \\  $n$ & 1 & 2 & 3 & & \\   & $n$ & 1 & 2 & 3 & \\   & & $n$ & 1 & 2 & 3 \\  3 & & & $n$ & 1 & 2 \\  2 & 3 & & & $n$ & 1 \\  \\end{tabular}\\quad\\begin{tabular}{|c|c|c|c|c|c|}  2 & 3 & & & $n$ & 1 \\  1 & 2 & 3 & & & $n$ \\  $n$ & 1 & 2 & 3 & & \\   & $n$ & 1 & 2 & 3 & \\   & & $n$ & 1 & 2 & 3 \\  \\end{tabular}\\quad\\begin{tabular}{|c|c|c|c|c|c|}  3 & & & $n$ & 1 & 2 \\  2 & 3 & & & $n$ & 1 \\  1 & 2 & 3 & & & $n$ \\  $n$ & 1 & 2 & 3 & & \\   & $n$ & 1 & 2 & 3 & \\   & & $n$ & 1 & 2 & 3 \\  \\end{tabular}\\end{table}\n$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "It is another story that if any plane section of a three-dimensional point set is a circular disc, then the set is a ball.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/[Svetoslav_Savchev,_Titu_Andreescu]_Mathematical_M(z-lib.org).pdf_181",
        "ID": "0fab2ba6-c8d7-4195-a8c3-bb899d3141ba",
        "questions": "What is the sum of the first 1000 natural numbers?",
        "answers": "500,500",
        "context": "# Solutions  \n\n1. This sum has just one possible value: 500,500. It is easy to guess the answer: If at each step we remove one pebble from the same pile, the sum will be  \n\n$$\n1000+999+998+\\cdots+2+1=500,500.\n$$  \n\nThere are different ways to prove that the same result will be obtained in all cases. Here is probably the shortest one. Imagine that initially each pebble is connected to each other pebble by a thread. When partitioning some pile into two smaller ones, assume that all the threads connecting pebbles that go to different piles are being cut. The number of these threads is exactly equal to the product of the number of pebbles in the smaller piles. Hence in all cases the sum in question will be equal to the total number of threads, that is, to  $1001\\cdot1000/2=500,500$.\n\n1. Project the discs onto the common line  $l$  of the two planes. We obtain two line segments with lengths equal to the corresponding diameters. But these line segments are obliged to coincide, since each of them may be regarded as the orthogonal projection of the set itself onto $l$.  \n\nThere are sets with the described property that are not spheres, for example, the common part of three right circular cylinders with pairwise perpendicular axes passing through a common point. It is another story that if any plane section of a three-dimensional point set is a circular disc, then the set is a ball.  \n\n3. Color the squares of the grid with n colors as shown in the left-hand figure below. Note that the main diagonal squares are exactly the ones colored with 1.  \n\n$\n \\begin{tabular}{|c|c|c|c|c|c|}  1 & 2 & 3 & & & $n$ \\  $n$ & 1 & 2 & 3 & & \\   & $n$ & 1 & 2 & 3 & \\   & & $n$ & 1 & 2 & 3 \\  3 & & & $n$ & 1 & 2 \\  2 & 3 & & & $n$ & 1 \\  \\end{tabular}\\quad\\begin{tabular}{|c|c|c|c|c|c|}  2 & 3 & & & $n$ & 1 \\  1 & 2 & 3 & & & $n$ \\  $n$ & 1 & 2 & 3 & & \\   & $n$ & 1 & 2 & 3 & \\   & & $n$ & 1 & 2 & 3 \\  \\end{tabular}\\quad\\begin{tabular}{|c|c|c|c|c|c|}  3 & & & $n$ & 1 & 2 \\  2 & 3 & & & $n$ & 1 \\  1 & 2 & 3 & & & $n$ \\  $n$ & 1 & 2 & 3 & & \\   & $n$ & 1 & 2 & 3 & \\   & & $n$ & 1 & 2 & 3 \\  \\end{tabular}\\end{table}\n$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Numeric",
        "evidence_source": "equation",
        "evidence_context": "$$ 1000+999+998+\\cdots+2+1=500,500.$$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/[Svetoslav_Savchev,_Titu_Andreescu]_Mathematical_M(z-lib.org).pdf_181",
        "ID": "0fbc0318-b6e4-416e-b066-8cc99e7f0271",
        "questions": "How is the total number of connections between pebbles initially represented when partitioning a pile into two smaller ones?",
        "answers": "$1001\\cdot1000/2=500,500$",
        "context": "# Solutions  \n\n1. This sum has just one possible value: 500,500. It is easy to guess the answer: If at each step we remove one pebble from the same pile, the sum will be  \n\n$$\n1000+999+998+\\cdots+2+1=500,500.\n$$  \n\nThere are different ways to prove that the same result will be obtained in all cases. Here is probably the shortest one. Imagine that initially each pebble is connected to each other pebble by a thread. When partitioning some pile into two smaller ones, assume that all the threads connecting pebbles that go to different piles are being cut. The number of these threads is exactly equal to the product of the number of pebbles in the smaller piles. Hence in all cases the sum in question will be equal to the total number of threads, that is, to  $1001\\cdot1000/2=500,500$.\n\n1. Project the discs onto the common line  $l$  of the two planes. We obtain two line segments with lengths equal to the corresponding diameters. But these line segments are obliged to coincide, since each of them may be regarded as the orthogonal projection of the set itself onto $l$.  \n\nThere are sets with the described property that are not spheres, for example, the common part of three right circular cylinders with pairwise perpendicular axes passing through a common point. It is another story that if any plane section of a three-dimensional point set is a circular disc, then the set is a ball.  \n\n3. Color the squares of the grid with n colors as shown in the left-hand figure below. Note that the main diagonal squares are exactly the ones colored with 1.  \n\n$\n \\begin{tabular}{|c|c|c|c|c|c|}  1 & 2 & 3 & & & $n$ \\  $n$ & 1 & 2 & 3 & & \\   & $n$ & 1 & 2 & 3 & \\   & & $n$ & 1 & 2 & 3 \\  3 & & & $n$ & 1 & 2 \\  2 & 3 & & & $n$ & 1 \\  \\end{tabular}\\quad\\begin{tabular}{|c|c|c|c|c|c|}  2 & 3 & & & $n$ & 1 \\  1 & 2 & 3 & & & $n$ \\  $n$ & 1 & 2 & 3 & & \\   & $n$ & 1 & 2 & 3 & \\   & & $n$ & 1 & 2 & 3 \\  \\end{tabular}\\quad\\begin{tabular}{|c|c|c|c|c|c|}  3 & & & $n$ & 1 & 2 \\  2 & 3 & & & $n$ & 1 \\  1 & 2 & 3 & & & $n$ \\  $n$ & 1 & 2 & 3 & & \\   & $n$ & 1 & 2 & 3 & \\   & & $n$ & 1 & 2 & 3 \\  \\end{tabular}\\end{table}\n$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "the sum in question will be equal to the total number of threads, that is, to  $1001\\cdot1000/2=500,500$.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/[Svetoslav_Savchev,_Titu_Andreescu]_Mathematical_M(z-lib.org).pdf_181",
        "ID": "0fc50523-3e8a-4ce6-8c52-4949c3248f55",
        "questions": "According to the text, what is the approach used to prove that the sum of removing pebbles is constant?",
        "answers": "When partitioning some pile into two smaller ones, assume that all the threads connecting pebbles that go to different piles are being cut. The number of these threads is exactly equal to the product of the number of pebbles in the smaller piles. Hence in all cases the sum in question will be equal to the total number of threads, that is, to  $1001\\cdot1000/2=500,500$.",
        "context": "# Solutions  \n\n1. This sum has just one possible value: 500,500. It is easy to guess the answer: If at each step we remove one pebble from the same pile, the sum will be  \n\n$$\n1000+999+998+\\cdots+2+1=500,500.\n$$  \n\nThere are different ways to prove that the same result will be obtained in all cases. Here is probably the shortest one. Imagine that initially each pebble is connected to each other pebble by a thread. When partitioning some pile into two smaller ones, assume that all the threads connecting pebbles that go to different piles are being cut. The number of these threads is exactly equal to the product of the number of pebbles in the smaller piles. Hence in all cases the sum in question will be equal to the total number of threads, that is, to  $1001\\cdot1000/2=500,500$.\n\n1. Project the discs onto the common line  $l$  of the two planes. We obtain two line segments with lengths equal to the corresponding diameters. But these line segments are obliged to coincide, since each of them may be regarded as the orthogonal projection of the set itself onto $l$.  \n\nThere are sets with the described property that are not spheres, for example, the common part of three right circular cylinders with pairwise perpendicular axes passing through a common point. It is another story that if any plane section of a three-dimensional point set is a circular disc, then the set is a ball.  \n\n3. Color the squares of the grid with n colors as shown in the left-hand figure below. Note that the main diagonal squares are exactly the ones colored with 1.  \n\n$\n \\begin{tabular}{|c|c|c|c|c|c|}  1 & 2 & 3 & & & $n$ \\  $n$ & 1 & 2 & 3 & & \\   & $n$ & 1 & 2 & 3 & \\   & & $n$ & 1 & 2 & 3 \\  3 & & & $n$ & 1 & 2 \\  2 & 3 & & & $n$ & 1 \\  \\end{tabular}\\quad\\begin{tabular}{|c|c|c|c|c|c|}  2 & 3 & & & $n$ & 1 \\  1 & 2 & 3 & & & $n$ \\  $n$ & 1 & 2 & 3 & & \\   & $n$ & 1 & 2 & 3 & \\   & & $n$ & 1 & 2 & 3 \\  \\end{tabular}\\quad\\begin{tabular}{|c|c|c|c|c|c|}  3 & & & $n$ & 1 & 2 \\  2 & 3 & & & $n$ & 1 \\  1 & 2 & 3 & & & $n$ \\  $n$ & 1 & 2 & 3 & & \\   & $n$ & 1 & 2 & 3 & \\   & & $n$ & 1 & 2 & 3 \\  \\end{tabular}\\end{table}\n$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Imagine that initially each pebble is connected to each other pebble by a thread. When partitioning some pile into two smaller ones, assume that all the threads connecting pebbles that go to different piles are being cut. The number of these threads is exactly equal to the product of the number of pebbles in the smaller piles. Hence in all cases the sum in question will be equal to the total number of threads, that is, to  $1001\\cdot1000/2=500,500$.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/UTM163-Differential_Geometry_of_Curves_and_Surfaces2016.pdf_142",
        "ID": "0fd29271-b440-44eb-83ed-8da8a35d9f4e",
        "questions": "What is a parametrized surface as defined in the given text?",
        "answers": "A parametrized surface is a smooth function \u03c3:U\u2192\u211d\u00b3 (where U is an open set in \u211d\u00b2) such that for all q\u2208U, d\u03c3_q has rank 2.",
        "context": "> **DEFINITION 3.28** <br>\nA parametrized surface is a smooth function $\\sigma:U\\to\\mathbb{R}^{3}$ (where $U$ is an open set in ${\\mathbb R}^{2}$) such that for all $q\\in U$, $d\\sigma_{q}$ has rank 2.  \n\nNotice that a regular surface is a set, while a parametrized surface is a function. Every surface patch for a regular surface is a parametrized surface. A parametrized surface need not be one-to-one. For example, the function $\\sigma:\\mathbb{R}^{2}\\to\\mathbb{R}^{3}$ defined as $\\sigma(u,v)\\,=\\,(\\cos u,\\sin u,v)$ is a parametrized surface that wraps the plane infinitely many times around the cylinder; the restriction of this function to a smaller domain was used in Example 3.23 as a surface patch for the cylinder. Exercise 3.27 in this section (illustrated in Fig. 3.17) shows a parametrized surface that fails to be one-to-one because of more complicated kinds of self-intersections. In studying only local properties, it doesn't matter whether one works with regular surfaces or parametrized surfaces, because of the following proposition:  \n\n> **PROPOSITION 3.29.**<br>\nIf $\\sigma:U\\to\\mathbb{R}^{3}$ is a parametrized surface, then for each $q_{0}\\in U$, there exists an open set $\\tilde{U}\\subset U$ containing $q_{0}$ such that the image $S=\\sigma(\\tilde{U})$ is a regular surface covered by a single surface patch (namely, the restriction of $\\sigma$ to $\\tilde{U}$).  \n\n**PROOF**. Let $q_{0}\\in U$. Choose any $N\\in\\mathbb{R}^{3}$ with $N\\not\\in\\operatorname{span}\\{\\sigma_{u}(q_{0}),\\sigma_{v}(q_{0})\\}$. Consider the smooth function $f:U\\times\\mathbb{R}\\to\\mathbb{R}^{3}$ defined as follows:  \n\n$$\nf(q,t)=\\sigma(q)+t N.\n$$  \n\nSet $p_{0}\\,=\\,\\sigma(q_{0})\\,=\\,f(q_{0},0)$. The derivative $d f_{(q_{0},0)}:\\mathbb{R}^{3}\\rightarrow\\mathbb{R}^{3}$ is invertible, because it sends the basis $\\{e_{1},e_{2},e_{3}\\}$ to the basis $\\{\\sigma_{u}(q_{0}),\\sigma_{v}(q_{0}),N\\}$. By the inverse function theorem (on page 120), $f$ restricts to a diffeomorphism from a neighborhood, $\\mathcal{A}$, of $(q_{0},0)$ in $U\\times\\mathbb{R}\\subset\\mathbb{R}^{2}\\times\\mathbb{R}=\\mathbb{R}^{3}$ to a neighborhood, $\\mathcal{B}$, of $p_{0}$ in ${\\mathbb{R}}^{3}$. We can assume (after possibly shrinking the neighborhoods) that $\\mathcal{A}$ has the form $\\mathcal{A}=\\tilde{U}\\times(-\\epsilon,\\epsilon)$, where $\\epsilon>0$ and $\\tilde{U}\\subset U$ is a neighborhood of $q_{0}$.  \n\nDefine $S=\\sigma(\\tilde{U})$. Since $f$ is injective on $\\mathcal{A}$, it follows that $\\boldsymbol{\\sigma}$ is injective on $\\tilde{U}$, so it has an inverse $\\sigma^{-1}:S\\to{\\tilde{U}}$. It remains to prove that $\\sigma^{-1}$ is smooth. For this, let $P:{\\mathcal{A}}\\to U$ denote the natural projection that maps $(q,t)\\mapsto q$. The function $P\\circ f^{-1}:{\\mathcal{B}}\\rightarrow{\\tilde{U}}$ is a smooth function that agrees with $\\sigma^{-1}$ on $B\\cap S$, which verifies that $\\sigma^{-1}$ is smooth. \n\nIn light of Proposition 3.29, you might guess that the image of every injective parametrized surface is a regular surface, but counterexamples to this guess will be given in Sect. 10.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "A parametrized surface is a smooth function $\u03c3:U\u2192\u211d\u00b3$ (where $U$ is an open set in ${\u211d}^{2}$) such that for all $q\u2208U$, $d\u03c3_q$ has rank 2.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTM163-Differential_Geometry_of_Curves_and_Surfaces2016.pdf_142",
        "ID": "0fdb691b-18d4-40f2-89f3-66b7b3d6ec5f",
        "questions": "What is the function used to define a parametrized surface that wraps the plane infinitely many times around the cylinder?",
        "answers": "\u03c3(u,v) = (cos u, sin u, v)",
        "context": "> **DEFINITION 3.28** <br>\nA parametrized surface is a smooth function $\\sigma:U\\to\\mathbb{R}^{3}$ (where $U$ is an open set in ${\\mathbb R}^{2}$) such that for all $q\\in U$, $d\\sigma_{q}$ has rank 2.  \n\nNotice that a regular surface is a set, while a parametrized surface is a function. Every surface patch for a regular surface is a parametrized surface. A parametrized surface need not be one-to-one. For example, the function $\\sigma:\\mathbb{R}^{2}\\to\\mathbb{R}^{3}$ defined as $\\sigma(u,v)\\,=\\,(\\cos u,\\sin u,v)$ is a parametrized surface that wraps the plane infinitely many times around the cylinder; the restriction of this function to a smaller domain was used in Example 3.23 as a surface patch for the cylinder. Exercise 3.27 in this section (illustrated in Fig. 3.17) shows a parametrized surface that fails to be one-to-one because of more complicated kinds of self-intersections. In studying only local properties, it doesn't matter whether one works with regular surfaces or parametrized surfaces, because of the following proposition:  \n\n> **PROPOSITION 3.29.**<br>\nIf $\\sigma:U\\to\\mathbb{R}^{3}$ is a parametrized surface, then for each $q_{0}\\in U$, there exists an open set $\\tilde{U}\\subset U$ containing $q_{0}$ such that the image $S=\\sigma(\\tilde{U})$ is a regular surface covered by a single surface patch (namely, the restriction of $\\sigma$ to $\\tilde{U}$).  \n\n**PROOF**. Let $q_{0}\\in U$. Choose any $N\\in\\mathbb{R}^{3}$ with $N\\not\\in\\operatorname{span}\\{\\sigma_{u}(q_{0}),\\sigma_{v}(q_{0})\\}$. Consider the smooth function $f:U\\times\\mathbb{R}\\to\\mathbb{R}^{3}$ defined as follows:  \n\n$$\nf(q,t)=\\sigma(q)+t N.\n$$  \n\nSet $p_{0}\\,=\\,\\sigma(q_{0})\\,=\\,f(q_{0},0)$. The derivative $d f_{(q_{0},0)}:\\mathbb{R}^{3}\\rightarrow\\mathbb{R}^{3}$ is invertible, because it sends the basis $\\{e_{1},e_{2},e_{3}\\}$ to the basis $\\{\\sigma_{u}(q_{0}),\\sigma_{v}(q_{0}),N\\}$. By the inverse function theorem (on page 120), $f$ restricts to a diffeomorphism from a neighborhood, $\\mathcal{A}$, of $(q_{0},0)$ in $U\\times\\mathbb{R}\\subset\\mathbb{R}^{2}\\times\\mathbb{R}=\\mathbb{R}^{3}$ to a neighborhood, $\\mathcal{B}$, of $p_{0}$ in ${\\mathbb{R}}^{3}$. We can assume (after possibly shrinking the neighborhoods) that $\\mathcal{A}$ has the form $\\mathcal{A}=\\tilde{U}\\times(-\\epsilon,\\epsilon)$, where $\\epsilon>0$ and $\\tilde{U}\\subset U$ is a neighborhood of $q_{0}$.  \n\nDefine $S=\\sigma(\\tilde{U})$. Since $f$ is injective on $\\mathcal{A}$, it follows that $\\boldsymbol{\\sigma}$ is injective on $\\tilde{U}$, so it has an inverse $\\sigma^{-1}:S\\to{\\tilde{U}}$. It remains to prove that $\\sigma^{-1}$ is smooth. For this, let $P:{\\mathcal{A}}\\to U$ denote the natural projection that maps $(q,t)\\mapsto q$. The function $P\\circ f^{-1}:{\\mathcal{B}}\\rightarrow{\\tilde{U}}$ is a smooth function that agrees with $\\sigma^{-1}$ on $B\\cap S$, which verifies that $\\sigma^{-1}$ is smooth. \n\nIn light of Proposition 3.29, you might guess that the image of every injective parametrized surface is a regular surface, but counterexamples to this guess will be given in Sect. 10.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "For example, the function $\u03c3:\u211d\u00b2\u2192\u211d\u00b3$ defined as $\u03c3(u,v) = (cos u, sin u, v)$ is a parametrized surface that wraps the plane infinitely many times around the cylinder;",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTM163-Differential_Geometry_of_Curves_and_Surfaces2016.pdf_142",
        "ID": "0fde45c5-ddf5-452d-9ad0-53de6fd6f23f",
        "questions": "What conditions must be met for the image \u03c3(tilde{U}) to be a regular surface covered by a single surface patch, according to Proposition 3.29?",
        "answers": "If \u03c3:U\u2192\u211d\u00b3 is a parametrized surface, then for each q\u2080\u2208U, there exists an open set \tilde{U} \u2282 U containing q\u2080 such that the image S = \u03c3(\tilde{U}) is a regular surface covered by a single surface patch (namely, the restriction of \u03c3 to \tilde{U}).",
        "context": "> **DEFINITION 3.28** <br>\nA parametrized surface is a smooth function $\\sigma:U\\to\\mathbb{R}^{3}$ (where $U$ is an open set in ${\\mathbb R}^{2}$) such that for all $q\\in U$, $d\\sigma_{q}$ has rank 2.  \n\nNotice that a regular surface is a set, while a parametrized surface is a function. Every surface patch for a regular surface is a parametrized surface. A parametrized surface need not be one-to-one. For example, the function $\\sigma:\\mathbb{R}^{2}\\to\\mathbb{R}^{3}$ defined as $\\sigma(u,v)\\,=\\,(\\cos u,\\sin u,v)$ is a parametrized surface that wraps the plane infinitely many times around the cylinder; the restriction of this function to a smaller domain was used in Example 3.23 as a surface patch for the cylinder. Exercise 3.27 in this section (illustrated in Fig. 3.17) shows a parametrized surface that fails to be one-to-one because of more complicated kinds of self-intersections. In studying only local properties, it doesn't matter whether one works with regular surfaces or parametrized surfaces, because of the following proposition:  \n\n> **PROPOSITION 3.29.**<br>\nIf $\\sigma:U\\to\\mathbb{R}^{3}$ is a parametrized surface, then for each $q_{0}\\in U$, there exists an open set $\\tilde{U}\\subset U$ containing $q_{0}$ such that the image $S=\\sigma(\\tilde{U})$ is a regular surface covered by a single surface patch (namely, the restriction of $\\sigma$ to $\\tilde{U}$).  \n\n**PROOF**. Let $q_{0}\\in U$. Choose any $N\\in\\mathbb{R}^{3}$ with $N\\not\\in\\operatorname{span}\\{\\sigma_{u}(q_{0}),\\sigma_{v}(q_{0})\\}$. Consider the smooth function $f:U\\times\\mathbb{R}\\to\\mathbb{R}^{3}$ defined as follows:  \n\n$$\nf(q,t)=\\sigma(q)+t N.\n$$  \n\nSet $p_{0}\\,=\\,\\sigma(q_{0})\\,=\\,f(q_{0},0)$. The derivative $d f_{(q_{0},0)}:\\mathbb{R}^{3}\\rightarrow\\mathbb{R}^{3}$ is invertible, because it sends the basis $\\{e_{1},e_{2},e_{3}\\}$ to the basis $\\{\\sigma_{u}(q_{0}),\\sigma_{v}(q_{0}),N\\}$. By the inverse function theorem (on page 120), $f$ restricts to a diffeomorphism from a neighborhood, $\\mathcal{A}$, of $(q_{0},0)$ in $U\\times\\mathbb{R}\\subset\\mathbb{R}^{2}\\times\\mathbb{R}=\\mathbb{R}^{3}$ to a neighborhood, $\\mathcal{B}$, of $p_{0}$ in ${\\mathbb{R}}^{3}$. We can assume (after possibly shrinking the neighborhoods) that $\\mathcal{A}$ has the form $\\mathcal{A}=\\tilde{U}\\times(-\\epsilon,\\epsilon)$, where $\\epsilon>0$ and $\\tilde{U}\\subset U$ is a neighborhood of $q_{0}$.  \n\nDefine $S=\\sigma(\\tilde{U})$. Since $f$ is injective on $\\mathcal{A}$, it follows that $\\boldsymbol{\\sigma}$ is injective on $\\tilde{U}$, so it has an inverse $\\sigma^{-1}:S\\to{\\tilde{U}}$. It remains to prove that $\\sigma^{-1}$ is smooth. For this, let $P:{\\mathcal{A}}\\to U$ denote the natural projection that maps $(q,t)\\mapsto q$. The function $P\\circ f^{-1}:{\\mathcal{B}}\\rightarrow{\\tilde{U}}$ is a smooth function that agrees with $\\sigma^{-1}$ on $B\\cap S$, which verifies that $\\sigma^{-1}$ is smooth. \n\nIn light of Proposition 3.29, you might guess that the image of every injective parametrized surface is a regular surface, but counterexamples to this guess will be given in Sect. 10.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "If \u03c3:U\u2192\u211d\u00b3 is a parametrized surface, then for each q\u2080\u2208U, there exists an open set \tilde{U} \u2282 U containing q\u2080 such that the image S = \u03c3(\tilde{U}) is a regular surface covered by a single surface patch (namely, the restriction of \u03c3 to \tilde{U}).",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTM163-Differential_Geometry_of_Curves_and_Surfaces2016.pdf_142",
        "ID": "0ff29be8-5075-42a5-ad0c-6ef6c3b0ab23",
        "questions": "What is the function representing a parametrized surface that wraps the plane infinitely many times around the cylinder? Provide the equation defining this function.",
        "answers": "$\\sigma(u,v) = (\\cos u, \\sin u, v)$",
        "context": "> **DEFINITION 3.28** <br>\nA parametrized surface is a smooth function $\\sigma:U\\to\\mathbb{R}^{3}$ (where $U$ is an open set in ${\\mathbb R}^{2}$) such that for all $q\\in U$, $d\\sigma_{q}$ has rank 2.  \n\nNotice that a regular surface is a set, while a parametrized surface is a function. Every surface patch for a regular surface is a parametrized surface. A parametrized surface need not be one-to-one. For example, the function $\\sigma:\\mathbb{R}^{2}\\to\\mathbb{R}^{3}$ defined as $\\sigma(u,v)\\,=\\,(\\cos u,\\sin u,v)$ is a parametrized surface that wraps the plane infinitely many times around the cylinder; the restriction of this function to a smaller domain was used in Example 3.23 as a surface patch for the cylinder. Exercise 3.27 in this section (illustrated in Fig. 3.17) shows a parametrized surface that fails to be one-to-one because of more complicated kinds of self-intersections. In studying only local properties, it doesn't matter whether one works with regular surfaces or parametrized surfaces, because of the following proposition:  \n\n> **PROPOSITION 3.29.**<br>\nIf $\\sigma:U\\to\\mathbb{R}^{3}$ is a parametrized surface, then for each $q_{0}\\in U$, there exists an open set $\\tilde{U}\\subset U$ containing $q_{0}$ such that the image $S=\\sigma(\\tilde{U})$ is a regular surface covered by a single surface patch (namely, the restriction of $\\sigma$ to $\\tilde{U}$).  \n\n**PROOF**. Let $q_{0}\\in U$. Choose any $N\\in\\mathbb{R}^{3}$ with $N\\not\\in\\operatorname{span}\\{\\sigma_{u}(q_{0}),\\sigma_{v}(q_{0})\\}$. Consider the smooth function $f:U\\times\\mathbb{R}\\to\\mathbb{R}^{3}$ defined as follows:  \n\n$$\nf(q,t)=\\sigma(q)+t N.\n$$  \n\nSet $p_{0}\\,=\\,\\sigma(q_{0})\\,=\\,f(q_{0},0)$. The derivative $d f_{(q_{0},0)}:\\mathbb{R}^{3}\\rightarrow\\mathbb{R}^{3}$ is invertible, because it sends the basis $\\{e_{1},e_{2},e_{3}\\}$ to the basis $\\{\\sigma_{u}(q_{0}),\\sigma_{v}(q_{0}),N\\}$. By the inverse function theorem (on page 120), $f$ restricts to a diffeomorphism from a neighborhood, $\\mathcal{A}$, of $(q_{0},0)$ in $U\\times\\mathbb{R}\\subset\\mathbb{R}^{2}\\times\\mathbb{R}=\\mathbb{R}^{3}$ to a neighborhood, $\\mathcal{B}$, of $p_{0}$ in ${\\mathbb{R}}^{3}$. We can assume (after possibly shrinking the neighborhoods) that $\\mathcal{A}$ has the form $\\mathcal{A}=\\tilde{U}\\times(-\\epsilon,\\epsilon)$, where $\\epsilon>0$ and $\\tilde{U}\\subset U$ is a neighborhood of $q_{0}$.  \n\nDefine $S=\\sigma(\\tilde{U})$. Since $f$ is injective on $\\mathcal{A}$, it follows that $\\boldsymbol{\\sigma}$ is injective on $\\tilde{U}$, so it has an inverse $\\sigma^{-1}:S\\to{\\tilde{U}}$. It remains to prove that $\\sigma^{-1}$ is smooth. For this, let $P:{\\mathcal{A}}\\to U$ denote the natural projection that maps $(q,t)\\mapsto q$. The function $P\\circ f^{-1}:{\\mathcal{B}}\\rightarrow{\\tilde{U}}$ is a smooth function that agrees with $\\sigma^{-1}$ on $B\\cap S$, which verifies that $\\sigma^{-1}$ is smooth. \n\nIn light of Proposition 3.29, you might guess that the image of every injective parametrized surface is a regular surface, but counterexamples to this guess will be given in Sect. 10.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "For example, the function $\\sigma:\\mathbb{R}^{2}\\to\\mathbb{R}^{3}$ defined as $\\sigma(u,v) = (\\cos u, \\sin u, v)$ is a parametrized surface that wraps the plane infinitely many times around the cylinder;",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/UTM163-Differential_Geometry_of_Curves_and_Surfaces2016.pdf_142",
        "ID": "0fffa6d4-005e-415d-9981-923a2fb2f8f2",
        "questions": "According to Proposition 3.29, if $\\sigma:U \\to \\mathbb{R}^{3}$ is a parametrized surface and $q_{0} \\in U$, what is the expression for defining the smooth function $f:U \\times \\mathbb{R} \\to \\mathbb{R}^{3}$?",
        "answers": "$f(q,t)=\\sigma(q)+t N$",
        "context": "> **DEFINITION 3.28** <br>\nA parametrized surface is a smooth function $\\sigma:U\\to\\mathbb{R}^{3}$ (where $U$ is an open set in ${\\mathbb R}^{2}$) such that for all $q\\in U$, $d\\sigma_{q}$ has rank 2.  \n\nNotice that a regular surface is a set, while a parametrized surface is a function. Every surface patch for a regular surface is a parametrized surface. A parametrized surface need not be one-to-one. For example, the function $\\sigma:\\mathbb{R}^{2}\\to\\mathbb{R}^{3}$ defined as $\\sigma(u,v)\\,=\\,(\\cos u,\\sin u,v)$ is a parametrized surface that wraps the plane infinitely many times around the cylinder; the restriction of this function to a smaller domain was used in Example 3.23 as a surface patch for the cylinder. Exercise 3.27 in this section (illustrated in Fig. 3.17) shows a parametrized surface that fails to be one-to-one because of more complicated kinds of self-intersections. In studying only local properties, it doesn't matter whether one works with regular surfaces or parametrized surfaces, because of the following proposition:  \n\n> **PROPOSITION 3.29.**<br>\nIf $\\sigma:U\\to\\mathbb{R}^{3}$ is a parametrized surface, then for each $q_{0}\\in U$, there exists an open set $\\tilde{U}\\subset U$ containing $q_{0}$ such that the image $S=\\sigma(\\tilde{U})$ is a regular surface covered by a single surface patch (namely, the restriction of $\\sigma$ to $\\tilde{U}$).  \n\n**PROOF**. Let $q_{0}\\in U$. Choose any $N\\in\\mathbb{R}^{3}$ with $N\\not\\in\\operatorname{span}\\{\\sigma_{u}(q_{0}),\\sigma_{v}(q_{0})\\}$. Consider the smooth function $f:U\\times\\mathbb{R}\\to\\mathbb{R}^{3}$ defined as follows:  \n\n$$\nf(q,t)=\\sigma(q)+t N.\n$$  \n\nSet $p_{0}\\,=\\,\\sigma(q_{0})\\,=\\,f(q_{0},0)$. The derivative $d f_{(q_{0},0)}:\\mathbb{R}^{3}\\rightarrow\\mathbb{R}^{3}$ is invertible, because it sends the basis $\\{e_{1},e_{2},e_{3}\\}$ to the basis $\\{\\sigma_{u}(q_{0}),\\sigma_{v}(q_{0}),N\\}$. By the inverse function theorem (on page 120), $f$ restricts to a diffeomorphism from a neighborhood, $\\mathcal{A}$, of $(q_{0},0)$ in $U\\times\\mathbb{R}\\subset\\mathbb{R}^{2}\\times\\mathbb{R}=\\mathbb{R}^{3}$ to a neighborhood, $\\mathcal{B}$, of $p_{0}$ in ${\\mathbb{R}}^{3}$. We can assume (after possibly shrinking the neighborhoods) that $\\mathcal{A}$ has the form $\\mathcal{A}=\\tilde{U}\\times(-\\epsilon,\\epsilon)$, where $\\epsilon>0$ and $\\tilde{U}\\subset U$ is a neighborhood of $q_{0}$.  \n\nDefine $S=\\sigma(\\tilde{U})$. Since $f$ is injective on $\\mathcal{A}$, it follows that $\\boldsymbol{\\sigma}$ is injective on $\\tilde{U}$, so it has an inverse $\\sigma^{-1}:S\\to{\\tilde{U}}$. It remains to prove that $\\sigma^{-1}$ is smooth. For this, let $P:{\\mathcal{A}}\\to U$ denote the natural projection that maps $(q,t)\\mapsto q$. The function $P\\circ f^{-1}:{\\mathcal{B}}\\rightarrow{\\tilde{U}}$ is a smooth function that agrees with $\\sigma^{-1}$ on $B\\cap S$, which verifies that $\\sigma^{-1}$ is smooth. \n\nIn light of Proposition 3.29, you might guess that the image of every injective parametrized surface is a regular surface, but counterexamples to this guess will be given in Sect. 10.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Consider the smooth function $f:U\\times\\mathbb{R}\\to\\mathbb{R}^{3}$ defined as follows: $f(q,t)=\\sigma(q)+t N$.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/UTM163-Differential_Geometry_of_Curves_and_Surfaces2016.pdf_142",
        "ID": "100aef24-0dd1-4beb-9d98-abc9eae9c546",
        "questions": "In Proposition 3.29, if $\\sigma(q_{0}) = p_{0}$ at $q_{0} \\in U$ and $f$ is defined as $f(q,t)=\\sigma(q)+t N$, what must the derivative $d f_{(q_{0},0)}:\\mathbb{R}^{3}\\rightarrow\\mathbb{R}^{3}$ send the basis to for it to be invertible?",
        "answers": "The basis $\\{e_{1},e_{2},e_{3}\\}$ to the basis $\\{\\sigma_{u}(q_{0}),\\sigma_{v}(q_{0}),N\\}$",
        "context": "> **DEFINITION 3.28** <br>\nA parametrized surface is a smooth function $\\sigma:U\\to\\mathbb{R}^{3}$ (where $U$ is an open set in ${\\mathbb R}^{2}$) such that for all $q\\in U$, $d\\sigma_{q}$ has rank 2.  \n\nNotice that a regular surface is a set, while a parametrized surface is a function. Every surface patch for a regular surface is a parametrized surface. A parametrized surface need not be one-to-one. For example, the function $\\sigma:\\mathbb{R}^{2}\\to\\mathbb{R}^{3}$ defined as $\\sigma(u,v)\\,=\\,(\\cos u,\\sin u,v)$ is a parametrized surface that wraps the plane infinitely many times around the cylinder; the restriction of this function to a smaller domain was used in Example 3.23 as a surface patch for the cylinder. Exercise 3.27 in this section (illustrated in Fig. 3.17) shows a parametrized surface that fails to be one-to-one because of more complicated kinds of self-intersections. In studying only local properties, it doesn't matter whether one works with regular surfaces or parametrized surfaces, because of the following proposition:  \n\n> **PROPOSITION 3.29.**<br>\nIf $\\sigma:U\\to\\mathbb{R}^{3}$ is a parametrized surface, then for each $q_{0}\\in U$, there exists an open set $\\tilde{U}\\subset U$ containing $q_{0}$ such that the image $S=\\sigma(\\tilde{U})$ is a regular surface covered by a single surface patch (namely, the restriction of $\\sigma$ to $\\tilde{U}$).  \n\n**PROOF**. Let $q_{0}\\in U$. Choose any $N\\in\\mathbb{R}^{3}$ with $N\\not\\in\\operatorname{span}\\{\\sigma_{u}(q_{0}),\\sigma_{v}(q_{0})\\}$. Consider the smooth function $f:U\\times\\mathbb{R}\\to\\mathbb{R}^{3}$ defined as follows:  \n\n$$\nf(q,t)=\\sigma(q)+t N.\n$$  \n\nSet $p_{0}\\,=\\,\\sigma(q_{0})\\,=\\,f(q_{0},0)$. The derivative $d f_{(q_{0},0)}:\\mathbb{R}^{3}\\rightarrow\\mathbb{R}^{3}$ is invertible, because it sends the basis $\\{e_{1},e_{2},e_{3}\\}$ to the basis $\\{\\sigma_{u}(q_{0}),\\sigma_{v}(q_{0}),N\\}$. By the inverse function theorem (on page 120), $f$ restricts to a diffeomorphism from a neighborhood, $\\mathcal{A}$, of $(q_{0},0)$ in $U\\times\\mathbb{R}\\subset\\mathbb{R}^{2}\\times\\mathbb{R}=\\mathbb{R}^{3}$ to a neighborhood, $\\mathcal{B}$, of $p_{0}$ in ${\\mathbb{R}}^{3}$. We can assume (after possibly shrinking the neighborhoods) that $\\mathcal{A}$ has the form $\\mathcal{A}=\\tilde{U}\\times(-\\epsilon,\\epsilon)$, where $\\epsilon>0$ and $\\tilde{U}\\subset U$ is a neighborhood of $q_{0}$.  \n\nDefine $S=\\sigma(\\tilde{U})$. Since $f$ is injective on $\\mathcal{A}$, it follows that $\\boldsymbol{\\sigma}$ is injective on $\\tilde{U}$, so it has an inverse $\\sigma^{-1}:S\\to{\\tilde{U}}$. It remains to prove that $\\sigma^{-1}$ is smooth. For this, let $P:{\\mathcal{A}}\\to U$ denote the natural projection that maps $(q,t)\\mapsto q$. The function $P\\circ f^{-1}:{\\mathcal{B}}\\rightarrow{\\tilde{U}}$ is a smooth function that agrees with $\\sigma^{-1}$ on $B\\cap S$, which verifies that $\\sigma^{-1}$ is smooth. \n\nIn light of Proposition 3.29, you might guess that the image of every injective parametrized surface is a regular surface, but counterexamples to this guess will be given in Sect. 10.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "The derivative $d f_{(q_{0},0)}:\\mathbb{R}^{3}\\rightarrow\\mathbb{R}^{3}$ is invertible, because it sends the basis $\\{e_{1},e_{2},e_{3}\\}$ to the basis $\\{\\sigma_{u}(q_{0}),\\sigma_{v}(q_{0}),N\\}$.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/GTM159-Functions_of_One_Complex_Variable_II_1995.pdf_367",
        "ID": "100dcfdb-c413-48e8-b19c-7b43aae0a764",
        "questions": "What is the term for the refinement of a negative subharmonic function often seen in the literature, and who originally introduced this concept?",
        "answers": "The term for the refinement of a negative subharmonic function most often seen in the literature is the French word 'balayage.' This concept was originally introduced by Poincar\u00e9.",
        "context": "that $\\delta_{n}^{c_{n}}=\\prod_{1\\leq j<k\\leq n}|z_{k}-z_{j}|$, Show that $z_{1},\\dots,z_{n}$ $\\partial\\hat{K}$ (the outer boundary of $K$\n\n# $\\boldsymbol{\\S}\\mathbf{12}$ The Refinement of a Subharmonic Function\n\nBecause of the intimate connection of subharmonic functions with so many of the properties of capacity and the solution of the Dirichlet problem, it is no surprise that the ability to manufacture these functions will extend the power of the theory and increase the depth of the results. In this section, a new technique is developed that increases our proficiency at constructing subharmonic functions. In the next two sections, this augmented skill will be put to good use as we prove Wiener's criterion for regularity.\n\nLet $G$ be a hyperbolic open subset of $\\mathbb{C}$ and suppose $E$ is an arbitrary subset of $G$ . For a negative subharmonic function $u$ on $G$ define\n\n$I_{E}^{u}(z)\\equiv\\sup\\{\\phi(z):\\phi$ is a negative subharmonic function on $G$ that is not identically $-\\infty$ on any component of $G$ and $\\phi\\leq u$ on $E\\}$\n\nThe function $I_{E}^{u}$ is called the increased function of $u$ relative to $E$ . Be aware that in the notation for the increased function, the role of $G$ is suppressed. Also note that $I_{E}^{u}$ may fail to be usc and thus may not be subharmonic. To correct for this, define\n\n$$\n\\hat{I}_{E}^{u}(z)=\\underset{w\\to z}{\\lim\\sup}I_{E}^{u}(w)\n$$\n\nfor all $z$ in $G$ . The function $\\hat{I}_{E}^{u}$ is called the refinement of $u$ relative to $E$ . The term for this function most often seen in the literature is the French word \"balayage.\" This word means \"sweeping\" or \"brushing.\" The term and concept go back to Poincar\u00e9, and the idea is that the subharmonic function $u$ is modified and polished (or brushed) to produce a better behaved function that still resembles $u$ on the set $E$. That the function $\\hat{I}_{E}^{u}$ accomplishes this will be seen shortly. We are avoiding the word \"sweep\" in this context as it was used in $\\S2$ in a different way.\n\nHere are some of the properties of the increased function and the refinement. Let $\\Phi_{E}^{u}$ be the set of negative subharmonic functions used to define $I_{E}^{u}$\n\n12.1 Proposition. If $G$ is a hyperbolic open set, $E$ and $F$ are subsets of $G$ , and $u$ and $v$ are negative subharmonic functions on $G$ , then:\n\n(a) $\\hat{I}_{E}^{u}$ is subharmonic on $G$\n\n(b) $u\\leq I_{E}^{u}\\leq\\hat{I}_{E}^{u}\\leq0$ on $G$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "The function $\\hat{I}_{E}^{u}$ is called the refinement of $u$ relative to $E$. The term for this function most often seen in the literature is the French word 'balayage.' This word means 'sweeping' or 'brushing.' The term and concept go back to Poincar\u00e9.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM159-Functions_of_One_Complex_Variable_II_1995.pdf_367",
        "ID": "100de114-0d19-48c8-861a-ac84883f0c01",
        "questions": "What property does the notation $I_{E}^{u}$ suppress, and under what condition may $I_{E}^{u}$ fail?",
        "answers": "The notation $I_{E}^{u}$ suppresses the role of $G$, and $I_{E}^{u}$ may fail to be upper semi-continuous (usc) and thus may not be subharmonic.",
        "context": "that $\\delta_{n}^{c_{n}}=\\prod_{1\\leq j<k\\leq n}|z_{k}-z_{j}|$, Show that $z_{1},\\dots,z_{n}$ $\\partial\\hat{K}$ (the outer boundary of $K$\n\n# $\\boldsymbol{\\S}\\mathbf{12}$ The Refinement of a Subharmonic Function\n\nBecause of the intimate connection of subharmonic functions with so many of the properties of capacity and the solution of the Dirichlet problem, it is no surprise that the ability to manufacture these functions will extend the power of the theory and increase the depth of the results. In this section, a new technique is developed that increases our proficiency at constructing subharmonic functions. In the next two sections, this augmented skill will be put to good use as we prove Wiener's criterion for regularity.\n\nLet $G$ be a hyperbolic open subset of $\\mathbb{C}$ and suppose $E$ is an arbitrary subset of $G$ . For a negative subharmonic function $u$ on $G$ define\n\n$I_{E}^{u}(z)\\equiv\\sup\\{\\phi(z):\\phi$ is a negative subharmonic function on $G$ that is not identically $-\\infty$ on any component of $G$ and $\\phi\\leq u$ on $E\\}$\n\nThe function $I_{E}^{u}$ is called the increased function of $u$ relative to $E$ . Be aware that in the notation for the increased function, the role of $G$ is suppressed. Also note that $I_{E}^{u}$ may fail to be usc and thus may not be subharmonic. To correct for this, define\n\n$$\n\\hat{I}_{E}^{u}(z)=\\underset{w\\to z}{\\lim\\sup}I_{E}^{u}(w)\n$$\n\nfor all $z$ in $G$ . The function $\\hat{I}_{E}^{u}$ is called the refinement of $u$ relative to $E$ . The term for this function most often seen in the literature is the French word \"balayage.\" This word means \"sweeping\" or \"brushing.\" The term and concept go back to Poincar\u00e9, and the idea is that the subharmonic function $u$ is modified and polished (or brushed) to produce a better behaved function that still resembles $u$ on the set $E$. That the function $\\hat{I}_{E}^{u}$ accomplishes this will be seen shortly. We are avoiding the word \"sweep\" in this context as it was used in $\\S2$ in a different way.\n\nHere are some of the properties of the increased function and the refinement. Let $\\Phi_{E}^{u}$ be the set of negative subharmonic functions used to define $I_{E}^{u}$\n\n12.1 Proposition. If $G$ is a hyperbolic open set, $E$ and $F$ are subsets of $G$ , and $u$ and $v$ are negative subharmonic functions on $G$ , then:\n\n(a) $\\hat{I}_{E}^{u}$ is subharmonic on $G$\n\n(b) $u\\leq I_{E}^{u}\\leq\\hat{I}_{E}^{u}\\leq0$ on $G$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Be aware that in the notation for the increased function, the role of $G$ is suppressed. Also note that $I_{E}^{u}$ may fail to be usc and thus may not be subharmonic.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM159-Functions_of_One_Complex_Variable_II_1995.pdf_367",
        "ID": "1016e2d7-00ee-4c67-aa72-dceff9f2f4ed",
        "questions": "According to the document, what is the definition of the increased function $I_E^u(z)$ for a negative subharmonic function $u$ on $G$?",
        "answers": "The increased function $I_{E}^{u}(z)$ for a negative subharmonic function $u$ on $G$ is defined as $I_{E}^{u}(z)\\equiv\\sup\\{\\phi(z):\\phi$ is a negative subharmonic function on $G$ that is not identically $-\\infty$ on any component of $G$ and $\\phi\\leq u$ on $E\\}$.",
        "context": "that $\\delta_{n}^{c_{n}}=\\prod_{1\\leq j<k\\leq n}|z_{k}-z_{j}|$, Show that $z_{1},\\dots,z_{n}$ $\\partial\\hat{K}$ (the outer boundary of $K$\n\n# $\\boldsymbol{\\S}\\mathbf{12}$ The Refinement of a Subharmonic Function\n\nBecause of the intimate connection of subharmonic functions with so many of the properties of capacity and the solution of the Dirichlet problem, it is no surprise that the ability to manufacture these functions will extend the power of the theory and increase the depth of the results. In this section, a new technique is developed that increases our proficiency at constructing subharmonic functions. In the next two sections, this augmented skill will be put to good use as we prove Wiener's criterion for regularity.\n\nLet $G$ be a hyperbolic open subset of $\\mathbb{C}$ and suppose $E$ is an arbitrary subset of $G$ . For a negative subharmonic function $u$ on $G$ define\n\n$I_{E}^{u}(z)\\equiv\\sup\\{\\phi(z):\\phi$ is a negative subharmonic function on $G$ that is not identically $-\\infty$ on any component of $G$ and $\\phi\\leq u$ on $E\\}$\n\nThe function $I_{E}^{u}$ is called the increased function of $u$ relative to $E$ . Be aware that in the notation for the increased function, the role of $G$ is suppressed. Also note that $I_{E}^{u}$ may fail to be usc and thus may not be subharmonic. To correct for this, define\n\n$$\n\\hat{I}_{E}^{u}(z)=\\underset{w\\to z}{\\lim\\sup}I_{E}^{u}(w)\n$$\n\nfor all $z$ in $G$ . The function $\\hat{I}_{E}^{u}$ is called the refinement of $u$ relative to $E$ . The term for this function most often seen in the literature is the French word \"balayage.\" This word means \"sweeping\" or \"brushing.\" The term and concept go back to Poincar\u00e9, and the idea is that the subharmonic function $u$ is modified and polished (or brushed) to produce a better behaved function that still resembles $u$ on the set $E$. That the function $\\hat{I}_{E}^{u}$ accomplishes this will be seen shortly. We are avoiding the word \"sweep\" in this context as it was used in $\\S2$ in a different way.\n\nHere are some of the properties of the increased function and the refinement. Let $\\Phi_{E}^{u}$ be the set of negative subharmonic functions used to define $I_{E}^{u}$\n\n12.1 Proposition. If $G$ is a hyperbolic open set, $E$ and $F$ are subsets of $G$ , and $u$ and $v$ are negative subharmonic functions on $G$ , then:\n\n(a) $\\hat{I}_{E}^{u}$ is subharmonic on $G$\n\n(b) $u\\leq I_{E}^{u}\\leq\\hat{I}_{E}^{u}\\leq0$ on $G$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "For a negative subharmonic function $u$ on $G$ define $I_{E}^{u}(z)\\equiv\\sup\\{\\phi(z):\\phi$ is a negative subharmonic function on $G$ that is not identically $-\\infty$ on any component of $G$ and $\\phi\\leq u$ on $E\\}$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM159-Functions_of_One_Complex_Variable_II_1995.pdf_367",
        "ID": "101fbccc-ded7-43e8-b421-eaeb534097ca",
        "questions": "What expression defines the initial increased function $I_{E}^{u}(z)$ for a negative subharmonic function $u$ on a hyperbolic open subset $G$?",
        "answers": "$I_{E}^{u}(z)\\equiv\\sup\\{\\phi(z):\\phi \\text{ is a negative subharmonic function on } G \\text{ that is not identically } -\\infty \\text{ on any component of } G \\text{ and } \\phi\\leq u \\text{ on } E\\}$",
        "context": "that $\\delta_{n}^{c_{n}}=\\prod_{1\\leq j<k\\leq n}|z_{k}-z_{j}|$, Show that $z_{1},\\dots,z_{n}$ $\\partial\\hat{K}$ (the outer boundary of $K$\n\n# $\\boldsymbol{\\S}\\mathbf{12}$ The Refinement of a Subharmonic Function\n\nBecause of the intimate connection of subharmonic functions with so many of the properties of capacity and the solution of the Dirichlet problem, it is no surprise that the ability to manufacture these functions will extend the power of the theory and increase the depth of the results. In this section, a new technique is developed that increases our proficiency at constructing subharmonic functions. In the next two sections, this augmented skill will be put to good use as we prove Wiener's criterion for regularity.\n\nLet $G$ be a hyperbolic open subset of $\\mathbb{C}$ and suppose $E$ is an arbitrary subset of $G$ . For a negative subharmonic function $u$ on $G$ define\n\n$I_{E}^{u}(z)\\equiv\\sup\\{\\phi(z):\\phi$ is a negative subharmonic function on $G$ that is not identically $-\\infty$ on any component of $G$ and $\\phi\\leq u$ on $E\\}$\n\nThe function $I_{E}^{u}$ is called the increased function of $u$ relative to $E$ . Be aware that in the notation for the increased function, the role of $G$ is suppressed. Also note that $I_{E}^{u}$ may fail to be usc and thus may not be subharmonic. To correct for this, define\n\n$$\n\\hat{I}_{E}^{u}(z)=\\underset{w\\to z}{\\lim\\sup}I_{E}^{u}(w)\n$$\n\nfor all $z$ in $G$ . The function $\\hat{I}_{E}^{u}$ is called the refinement of $u$ relative to $E$ . The term for this function most often seen in the literature is the French word \"balayage.\" This word means \"sweeping\" or \"brushing.\" The term and concept go back to Poincar\u00e9, and the idea is that the subharmonic function $u$ is modified and polished (or brushed) to produce a better behaved function that still resembles $u$ on the set $E$. That the function $\\hat{I}_{E}^{u}$ accomplishes this will be seen shortly. We are avoiding the word \"sweep\" in this context as it was used in $\\S2$ in a different way.\n\nHere are some of the properties of the increased function and the refinement. Let $\\Phi_{E}^{u}$ be the set of negative subharmonic functions used to define $I_{E}^{u}$\n\n12.1 Proposition. If $G$ is a hyperbolic open set, $E$ and $F$ are subsets of $G$ , and $u$ and $v$ are negative subharmonic functions on $G$ , then:\n\n(a) $\\hat{I}_{E}^{u}$ is subharmonic on $G$\n\n(b) $u\\leq I_{E}^{u}\\leq\\hat{I}_{E}^{u}\\leq0$ on $G$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$I_{E}^{u}(z)\\equiv\\sup\\{\\phi(z):\\phi \\text{ is a negative subharmonic function on } G \\text{ that is not identically } -\\infty \\text{ on any component of } G \\text{ and } \\phi\\leq u \\text{ on } E\\}$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/GTM159-Functions_of_One_Complex_Variable_II_1995.pdf_367",
        "ID": "1022f370-1d74-4571-9251-1980069c2773",
        "questions": "What is the definition of the refinement $\\hat{I}_{E}^{u}(z)$ for a negative subharmonic function $u$ on a set $G$?",
        "answers": "$\\hat{I}_{E}^{u}(z)=\\underset{w\\to z}{\\lim\\sup}I_{E}^{u}(w)$",
        "context": "that $\\delta_{n}^{c_{n}}=\\prod_{1\\leq j<k\\leq n}|z_{k}-z_{j}|$, Show that $z_{1},\\dots,z_{n}$ $\\partial\\hat{K}$ (the outer boundary of $K$\n\n# $\\boldsymbol{\\S}\\mathbf{12}$ The Refinement of a Subharmonic Function\n\nBecause of the intimate connection of subharmonic functions with so many of the properties of capacity and the solution of the Dirichlet problem, it is no surprise that the ability to manufacture these functions will extend the power of the theory and increase the depth of the results. In this section, a new technique is developed that increases our proficiency at constructing subharmonic functions. In the next two sections, this augmented skill will be put to good use as we prove Wiener's criterion for regularity.\n\nLet $G$ be a hyperbolic open subset of $\\mathbb{C}$ and suppose $E$ is an arbitrary subset of $G$ . For a negative subharmonic function $u$ on $G$ define\n\n$I_{E}^{u}(z)\\equiv\\sup\\{\\phi(z):\\phi$ is a negative subharmonic function on $G$ that is not identically $-\\infty$ on any component of $G$ and $\\phi\\leq u$ on $E\\}$\n\nThe function $I_{E}^{u}$ is called the increased function of $u$ relative to $E$ . Be aware that in the notation for the increased function, the role of $G$ is suppressed. Also note that $I_{E}^{u}$ may fail to be usc and thus may not be subharmonic. To correct for this, define\n\n$$\n\\hat{I}_{E}^{u}(z)=\\underset{w\\to z}{\\lim\\sup}I_{E}^{u}(w)\n$$\n\nfor all $z$ in $G$ . The function $\\hat{I}_{E}^{u}$ is called the refinement of $u$ relative to $E$ . The term for this function most often seen in the literature is the French word \"balayage.\" This word means \"sweeping\" or \"brushing.\" The term and concept go back to Poincar\u00e9, and the idea is that the subharmonic function $u$ is modified and polished (or brushed) to produce a better behaved function that still resembles $u$ on the set $E$. That the function $\\hat{I}_{E}^{u}$ accomplishes this will be seen shortly. We are avoiding the word \"sweep\" in this context as it was used in $\\S2$ in a different way.\n\nHere are some of the properties of the increased function and the refinement. Let $\\Phi_{E}^{u}$ be the set of negative subharmonic functions used to define $I_{E}^{u}$\n\n12.1 Proposition. If $G$ is a hyperbolic open set, $E$ and $F$ are subsets of $G$ , and $u$ and $v$ are negative subharmonic functions on $G$ , then:\n\n(a) $\\hat{I}_{E}^{u}$ is subharmonic on $G$\n\n(b) $u\\leq I_{E}^{u}\\leq\\hat{I}_{E}^{u}\\leq0$ on $G$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$\\hat{I}_{E}^{u}(z)=\\underset{w\\to z}{\\lim\\sup}I_{E}^{u}(w)$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/GTM159-Functions_of_One_Complex_Variable_II_1995.pdf_367",
        "ID": "1032223d-590e-41e1-a2a3-8a1062a68b1f",
        "questions": "In relation to the subharmonic functions $u$ and $v$, what inequalities are presented concerning $I_{E}^{u}$ and $\\hat{I}_{E}^{u}$ on a hyperbolic open set $G$?",
        "answers": "$u\\leq I_{E}^{u}\\leq\\hat{I}_{E}^{u}\\leq0$",
        "context": "that $\\delta_{n}^{c_{n}}=\\prod_{1\\leq j<k\\leq n}|z_{k}-z_{j}|$, Show that $z_{1},\\dots,z_{n}$ $\\partial\\hat{K}$ (the outer boundary of $K$\n\n# $\\boldsymbol{\\S}\\mathbf{12}$ The Refinement of a Subharmonic Function\n\nBecause of the intimate connection of subharmonic functions with so many of the properties of capacity and the solution of the Dirichlet problem, it is no surprise that the ability to manufacture these functions will extend the power of the theory and increase the depth of the results. In this section, a new technique is developed that increases our proficiency at constructing subharmonic functions. In the next two sections, this augmented skill will be put to good use as we prove Wiener's criterion for regularity.\n\nLet $G$ be a hyperbolic open subset of $\\mathbb{C}$ and suppose $E$ is an arbitrary subset of $G$ . For a negative subharmonic function $u$ on $G$ define\n\n$I_{E}^{u}(z)\\equiv\\sup\\{\\phi(z):\\phi$ is a negative subharmonic function on $G$ that is not identically $-\\infty$ on any component of $G$ and $\\phi\\leq u$ on $E\\}$\n\nThe function $I_{E}^{u}$ is called the increased function of $u$ relative to $E$ . Be aware that in the notation for the increased function, the role of $G$ is suppressed. Also note that $I_{E}^{u}$ may fail to be usc and thus may not be subharmonic. To correct for this, define\n\n$$\n\\hat{I}_{E}^{u}(z)=\\underset{w\\to z}{\\lim\\sup}I_{E}^{u}(w)\n$$\n\nfor all $z$ in $G$ . The function $\\hat{I}_{E}^{u}$ is called the refinement of $u$ relative to $E$ . The term for this function most often seen in the literature is the French word \"balayage.\" This word means \"sweeping\" or \"brushing.\" The term and concept go back to Poincar\u00e9, and the idea is that the subharmonic function $u$ is modified and polished (or brushed) to produce a better behaved function that still resembles $u$ on the set $E$. That the function $\\hat{I}_{E}^{u}$ accomplishes this will be seen shortly. We are avoiding the word \"sweep\" in this context as it was used in $\\S2$ in a different way.\n\nHere are some of the properties of the increased function and the refinement. Let $\\Phi_{E}^{u}$ be the set of negative subharmonic functions used to define $I_{E}^{u}$\n\n12.1 Proposition. If $G$ is a hyperbolic open set, $E$ and $F$ are subsets of $G$ , and $u$ and $v$ are negative subharmonic functions on $G$ , then:\n\n(a) $\\hat{I}_{E}^{u}$ is subharmonic on $G$\n\n(b) $u\\leq I_{E}^{u}\\leq\\hat{I}_{E}^{u}\\leq0$ on $G$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$u\\leq I_{E}^{u}\\leq\\hat{I}_{E}^{u}\\leq0$ on $G$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/human-20608.pdf_383",
        "ID": "1032fb80-f62c-4c39-accd-4523e11fe602",
        "questions": "What was the societal effect of many parents stopping the vaccination of their children due to the study linking autism to vaccine ingredients?",
        "answers": "An increase in childhood diseases, such as measles and whooping cough, that had almost been wiped out in the U.S. and elsewhere.",
        "context": "One very famous example of an on-credible secondary source was a paper, published in a very credible scientific journal, that linked autism to some of the ingredients in childhood vaccines. The result of this seemingly credible study was that many parents stopped vaccinating their children out of fear of autism. The result on society was an increase in childhood diseases, such as measles and whooping cough, that had almost been wiped out in the U.S. and elsewhere. Other scientists tried to replicate the results of the study, but they could not (validating results is also part of academic, especially scientific, inquiry). This failure to replicate the results called into question the validity of the original study. The original author and the journal recanted the study, so this relationship between vaccines and autism has now been debunked.\n\n# Tertiary Sources\n\nTertiary sources are those sources that have already been interpreted by two people. These sources are not nearly as reliable as primary and secondary sources because it is nearly impossible for a reader/listener to determine if the interpretation others have made is logical and accurate/appropriate. Common examples of tertiary sources are magazine articles in which an author uses a number of secondary sources or, lately, newspaper articles that cite other newspaper articles rather than an original source. Blogs are another common tertiary source, and they are rarely credible enough to include as a source for academic writing. (However, some academic researchers do have their own blogs, and if their work is generally considered credible, so are their blogs). Tertiary sources are like rumors\u2014you have to take them with \u201ca grain of salt.\u201d Many times, tertiary sources will also be filled with emotive language to get you to feel a certain way about the topic. This is a clue that your source may not be credible enough.\n\n# What Kind of Sources Should I Use?\n\nYour topic and purpose determine whether you must use both primary and secondary sources in your paper. Ask yourself which sources are most likely to provide the information that will answer your research questions. If you are writing a research paper about reality television shows, you will need to use some reality shows as a primary source, but secondary sources, such as a reviewer's critique, are also important. If you are writing about the health effects of nicotine, you will probably want to read the published results of scientific studies, but secondary sources, such as magazine articles discussing the outcome of a recent study, may also be helpful.\n\nOnce you have thought about what kinds of sources are most likely to help you answer your research questions, you may begin your search for print and electronic resources. The challenge here is to conduct your search efficiently. Writers use strategies to help them find the sources that are most relevant and reliable while steering clear of sources that will not be useful.\n\n# Print Resources versus Electronic Resources\n\nThese days, there really isn't much difference in how you find your resources, whether they are print or electronic. Either way, you will likely search for them digitally. The only difference is whether you read the resource online or hold it and read a print version. Keep in mind, however, that some potentially useful sources may be available only in print form. Others may be only available electronically. The following table lists different types of resources available at public, college, and university libraries.\n\n$\n\\begin{tabular}{|lll|}\n \nResource Type & Description & Example(s) \\\\\n \nReference works & Reference works provide a summary of information about a particular topic. Almanacs, encyclopedias, atlases, medical reference books, and scientific abstracts are examples of reference works. In some cases, reference books may not be checked out of a library; rather, they must be read there. Note that reference works are many steps removed from original primary sources and are often brief, so these should be used only & The World Almanac and Book of Facts 2010; Diagnostic and Statistical Manual published by the American Psychiatric Association\\\\\n \nNonfiction books & Nonfiction books provide in-depth coverage of a topic. Trade books, biographies, and how-to guides are usually written for a general audience. Scholarly books and scientific has specialized knowledge of a topic. & The Low-Carb solution: A Slimmer You in 30 Days; Carbohydrates, Fats and Proteins: Exploring the Relationship Between Macronutrient Ratios and Health Outcomes. \\\\\n \n\\end{tabular}\n$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "The result on society was an increase in childhood diseases, such as measles and whooping cough, that had almost been wiped out in the U.S. and elsewhere.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/human-20608.pdf_383",
        "ID": "10339310-2b7b-4e99-878f-40ed2c805ac7",
        "questions": "What are some examples of tertiary sources mentioned in the document, and why are they generally less reliable?",
        "answers": "Common examples of tertiary sources are magazine articles in which an author uses a number of secondary sources or, lately, newspaper articles that cite other newspaper articles rather than an original source. Blogs are another common tertiary source... Tertiary sources are not nearly as reliable as primary and secondary sources because it is nearly impossible for a reader/listener to determine if the interpretation others have made is logical and accurate/appropriate.",
        "context": "One very famous example of an on-credible secondary source was a paper, published in a very credible scientific journal, that linked autism to some of the ingredients in childhood vaccines. The result of this seemingly credible study was that many parents stopped vaccinating their children out of fear of autism. The result on society was an increase in childhood diseases, such as measles and whooping cough, that had almost been wiped out in the U.S. and elsewhere. Other scientists tried to replicate the results of the study, but they could not (validating results is also part of academic, especially scientific, inquiry). This failure to replicate the results called into question the validity of the original study. The original author and the journal recanted the study, so this relationship between vaccines and autism has now been debunked.\n\n# Tertiary Sources\n\nTertiary sources are those sources that have already been interpreted by two people. These sources are not nearly as reliable as primary and secondary sources because it is nearly impossible for a reader/listener to determine if the interpretation others have made is logical and accurate/appropriate. Common examples of tertiary sources are magazine articles in which an author uses a number of secondary sources or, lately, newspaper articles that cite other newspaper articles rather than an original source. Blogs are another common tertiary source, and they are rarely credible enough to include as a source for academic writing. (However, some academic researchers do have their own blogs, and if their work is generally considered credible, so are their blogs). Tertiary sources are like rumors\u2014you have to take them with \u201ca grain of salt.\u201d Many times, tertiary sources will also be filled with emotive language to get you to feel a certain way about the topic. This is a clue that your source may not be credible enough.\n\n# What Kind of Sources Should I Use?\n\nYour topic and purpose determine whether you must use both primary and secondary sources in your paper. Ask yourself which sources are most likely to provide the information that will answer your research questions. If you are writing a research paper about reality television shows, you will need to use some reality shows as a primary source, but secondary sources, such as a reviewer's critique, are also important. If you are writing about the health effects of nicotine, you will probably want to read the published results of scientific studies, but secondary sources, such as magazine articles discussing the outcome of a recent study, may also be helpful.\n\nOnce you have thought about what kinds of sources are most likely to help you answer your research questions, you may begin your search for print and electronic resources. The challenge here is to conduct your search efficiently. Writers use strategies to help them find the sources that are most relevant and reliable while steering clear of sources that will not be useful.\n\n# Print Resources versus Electronic Resources\n\nThese days, there really isn't much difference in how you find your resources, whether they are print or electronic. Either way, you will likely search for them digitally. The only difference is whether you read the resource online or hold it and read a print version. Keep in mind, however, that some potentially useful sources may be available only in print form. Others may be only available electronically. The following table lists different types of resources available at public, college, and university libraries.\n\n$\n\\begin{tabular}{|lll|}\n \nResource Type & Description & Example(s) \\\\\n \nReference works & Reference works provide a summary of information about a particular topic. Almanacs, encyclopedias, atlases, medical reference books, and scientific abstracts are examples of reference works. In some cases, reference books may not be checked out of a library; rather, they must be read there. Note that reference works are many steps removed from original primary sources and are often brief, so these should be used only & The World Almanac and Book of Facts 2010; Diagnostic and Statistical Manual published by the American Psychiatric Association\\\\\n \nNonfiction books & Nonfiction books provide in-depth coverage of a topic. Trade books, biographies, and how-to guides are usually written for a general audience. Scholarly books and scientific has specialized knowledge of a topic. & The Low-Carb solution: A Slimmer You in 30 Days; Carbohydrates, Fats and Proteins: Exploring the Relationship Between Macronutrient Ratios and Health Outcomes. \\\\\n \n\\end{tabular}\n$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Common examples of tertiary sources are magazine articles in which an author uses a number of secondary sources or, lately, newspaper articles that cite other newspaper articles rather than an original source. Blogs are another common tertiary source... Tertiary sources are not nearly as reliable as primary and secondary sources because it is nearly impossible for a reader/listener to determine if the interpretation others have made is logical and accurate/appropriate.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/human-20608.pdf_383",
        "ID": "10375004-14c8-414e-86e3-ac57ff1cfc80",
        "questions": "Which type of print resources may not be checked out of a library and must be read there, and what are some examples given?",
        "answers": "Reference works, Examples: The World Almanac and Book of Facts 2010; Diagnostic and Statistical Manual published by the American Psychiatric Association",
        "context": "One very famous example of an on-credible secondary source was a paper, published in a very credible scientific journal, that linked autism to some of the ingredients in childhood vaccines. The result of this seemingly credible study was that many parents stopped vaccinating their children out of fear of autism. The result on society was an increase in childhood diseases, such as measles and whooping cough, that had almost been wiped out in the U.S. and elsewhere. Other scientists tried to replicate the results of the study, but they could not (validating results is also part of academic, especially scientific, inquiry). This failure to replicate the results called into question the validity of the original study. The original author and the journal recanted the study, so this relationship between vaccines and autism has now been debunked.\n\n# Tertiary Sources\n\nTertiary sources are those sources that have already been interpreted by two people. These sources are not nearly as reliable as primary and secondary sources because it is nearly impossible for a reader/listener to determine if the interpretation others have made is logical and accurate/appropriate. Common examples of tertiary sources are magazine articles in which an author uses a number of secondary sources or, lately, newspaper articles that cite other newspaper articles rather than an original source. Blogs are another common tertiary source, and they are rarely credible enough to include as a source for academic writing. (However, some academic researchers do have their own blogs, and if their work is generally considered credible, so are their blogs). Tertiary sources are like rumors\u2014you have to take them with \u201ca grain of salt.\u201d Many times, tertiary sources will also be filled with emotive language to get you to feel a certain way about the topic. This is a clue that your source may not be credible enough.\n\n# What Kind of Sources Should I Use?\n\nYour topic and purpose determine whether you must use both primary and secondary sources in your paper. Ask yourself which sources are most likely to provide the information that will answer your research questions. If you are writing a research paper about reality television shows, you will need to use some reality shows as a primary source, but secondary sources, such as a reviewer's critique, are also important. If you are writing about the health effects of nicotine, you will probably want to read the published results of scientific studies, but secondary sources, such as magazine articles discussing the outcome of a recent study, may also be helpful.\n\nOnce you have thought about what kinds of sources are most likely to help you answer your research questions, you may begin your search for print and electronic resources. The challenge here is to conduct your search efficiently. Writers use strategies to help them find the sources that are most relevant and reliable while steering clear of sources that will not be useful.\n\n# Print Resources versus Electronic Resources\n\nThese days, there really isn't much difference in how you find your resources, whether they are print or electronic. Either way, you will likely search for them digitally. The only difference is whether you read the resource online or hold it and read a print version. Keep in mind, however, that some potentially useful sources may be available only in print form. Others may be only available electronically. The following table lists different types of resources available at public, college, and university libraries.\n\n$\n\\begin{tabular}{|lll|}\n \nResource Type & Description & Example(s) \\\\\n \nReference works & Reference works provide a summary of information about a particular topic. Almanacs, encyclopedias, atlases, medical reference books, and scientific abstracts are examples of reference works. In some cases, reference books may not be checked out of a library; rather, they must be read there. Note that reference works are many steps removed from original primary sources and are often brief, so these should be used only & The World Almanac and Book of Facts 2010; Diagnostic and Statistical Manual published by the American Psychiatric Association\\\\\n \nNonfiction books & Nonfiction books provide in-depth coverage of a topic. Trade books, biographies, and how-to guides are usually written for a general audience. Scholarly books and scientific has specialized knowledge of a topic. & The Low-Carb solution: A Slimmer You in 30 Days; Carbohydrates, Fats and Proteins: Exploring the Relationship Between Macronutrient Ratios and Health Outcomes. \\\\\n \n\\end{tabular}\n$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "table",
        "evidence_context": "In some cases, reference books may not be checked out of a library; rather, they must be read there. Note that reference works are many steps removed from original primary sources and are often brief, so these should be used only. Examples: The World Almanac and Book of Facts 2010; Diagnostic and Statistical Manual published by the American Psychiatric Association",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTX_-_Postmodern_Analysis,_Third_Edition.pdf_183",
        "ID": "103eaba1-de75-4cb9-b6c4-e48f436bd6b0",
        "questions": "What inequality is satisfied if function f is less than or equal to function g?",
        "answers": "\\int_{\\mathbb{R}^{d}}f(\\boldsymbol{x})d\\boldsymbol{x}\\le\\int_{\\mathbb{R}^{d}}g(\\boldsymbol{x})d\\boldsymbol{x}\\,.",
        "context": "$$\n\\begin{array}{l l}{\\displaystyle\\int(f(x)+g(x))d x=\\int_{\\mathbb R^{d}}f(x)d x+\\int_{\\mathbb R^{d}}g(x)d x,}\\\\ {\\displaystyle\\int_{\\mathbb R^{d}}\\alpha f(x)d x=\\alpha\\int_{\\mathbb R^{d}}f(x)d x\\ (l i n e a r i t y).}\\end{array}\n$$  \n\n(ii)  $If\\ f\\leq g$  then also  $\\begin{array}{r}{\\int_{\\mathbb{R}^{d}}f(\\boldsymbol{x})d\\boldsymbol{x}\\le\\int_{\\mathbb{R}^{d}}g(\\boldsymbol{x})d\\boldsymbol{x}\\,.}\\end{array}$  \n\n(iii)  $\\boldsymbol{I}f\\,\\boldsymbol{b}\\in\\mathbb{R}^{d},$   $A$  an orthogonal  $d\\times d{-m a t r i x}$  then  \n\n$$\n\\int_{\\mathbb{R}^{d}}f(A x+b)d x=\\int_{\\mathbb{R}^{d}}f(x)d x\\,.\n$$  \n\nProof. Parts (i) follows directly from the corresponding rules for the integral of elementary functions. The rule (iii) holds for elementary functions, because for an orthogonal matrix  $A$  and an elementary function  $t$  , the function  $t\\odot A$  is again elementary as  $A$  maps a cube on to a cube, and similarly for translation by a vector  $b$  . (ii) follows, as in case  $f\\leq g$  , we can approximate  $f$  and by  $g$  sequences  $(t_{n})$  and  $\\left(s_{n}\\right)$  , respectively, of elementary functions with  $t_{n}\\leq s_{n}$  \n\nFurthermore, we have  \n\nLemma 13.5 Let  $f\\in C_{c}(\\mathbb{R}^{d})$  with supp  $(f)$  in a cube of side length e. Then  \n\n$$\n|\\int_{\\mathbb{R}^{d}}f(x)d x|\\leq\\operatorname*{sup}|f(x)|\\cdot\\ell^{d}\\,.\n$$  \n\nThe proof again follows directly from the corresponding property for elementary functions.  \n\nLemmas 13.4 and 13.5 mean that the correspondence  \n\n$$\nf\\longmapsto\\int_{\\mathbb{R}^{d}}f(x)d x\n$$  \n\nis a linear, bounded (therefore continuous) real valued functional on each Banach space  $C_{c}(V)$   $W$  a cube in  $\\mathbb{R}^{d}$  ) that is invariant under isometries. One can show that a functional with these properties and the normalisation  \n\n$$\n\\intop_{I^{d}}1d x=1\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Equation",
        "evidence_source": "text",
        "evidence_context": "If\\ f\\leq g\\ then also  \\begin{array}{r}{\\int_{\\mathbb{R}^{d}}f(\\boldsymbol{x})d\\boldsymbol{x}\\le\\int_{\\mathbb{R}^{d}}g(\\boldsymbol{x})d\\boldsymbol{x}\\,.}\\end{array}",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTX_-_Postmodern_Analysis,_Third_Edition.pdf_183",
        "ID": "1046e73e-9da2-44fc-8b2a-5500f54d5acc",
        "questions": "How does an orthogonal matrix A and a vector b affect the integration of function f over \\mathbb{R}^{d}?",
        "answers": "\\int_{\\mathbb{R}^{d}}f(A x+b)d x=\\int_{\\mathbb{R}^{d}}f(x)d x\\,.",
        "context": "$$\n\\begin{array}{l l}{\\displaystyle\\int(f(x)+g(x))d x=\\int_{\\mathbb R^{d}}f(x)d x+\\int_{\\mathbb R^{d}}g(x)d x,}\\\\ {\\displaystyle\\int_{\\mathbb R^{d}}\\alpha f(x)d x=\\alpha\\int_{\\mathbb R^{d}}f(x)d x\\ (l i n e a r i t y).}\\end{array}\n$$  \n\n(ii)  $If\\ f\\leq g$  then also  $\\begin{array}{r}{\\int_{\\mathbb{R}^{d}}f(\\boldsymbol{x})d\\boldsymbol{x}\\le\\int_{\\mathbb{R}^{d}}g(\\boldsymbol{x})d\\boldsymbol{x}\\,.}\\end{array}$  \n\n(iii)  $\\boldsymbol{I}f\\,\\boldsymbol{b}\\in\\mathbb{R}^{d},$   $A$  an orthogonal  $d\\times d{-m a t r i x}$  then  \n\n$$\n\\int_{\\mathbb{R}^{d}}f(A x+b)d x=\\int_{\\mathbb{R}^{d}}f(x)d x\\,.\n$$  \n\nProof. Parts (i) follows directly from the corresponding rules for the integral of elementary functions. The rule (iii) holds for elementary functions, because for an orthogonal matrix  $A$  and an elementary function  $t$  , the function  $t\\odot A$  is again elementary as  $A$  maps a cube on to a cube, and similarly for translation by a vector  $b$  . (ii) follows, as in case  $f\\leq g$  , we can approximate  $f$  and by  $g$  sequences  $(t_{n})$  and  $\\left(s_{n}\\right)$  , respectively, of elementary functions with  $t_{n}\\leq s_{n}$  \n\nFurthermore, we have  \n\nLemma 13.5 Let  $f\\in C_{c}(\\mathbb{R}^{d})$  with supp  $(f)$  in a cube of side length e. Then  \n\n$$\n|\\int_{\\mathbb{R}^{d}}f(x)d x|\\leq\\operatorname*{sup}|f(x)|\\cdot\\ell^{d}\\,.\n$$  \n\nThe proof again follows directly from the corresponding property for elementary functions.  \n\nLemmas 13.4 and 13.5 mean that the correspondence  \n\n$$\nf\\longmapsto\\int_{\\mathbb{R}^{d}}f(x)d x\n$$  \n\nis a linear, bounded (therefore continuous) real valued functional on each Banach space  $C_{c}(V)$   $W$  a cube in  $\\mathbb{R}^{d}$  ) that is invariant under isometries. One can show that a functional with these properties and the normalisation  \n\n$$\n\\intop_{I^{d}}1d x=1\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Equation",
        "evidence_source": "text",
        "evidence_context": "If\\,\\boldsymbol{b}\\in\\mathbb{R}^{d},$   $A$  an orthogonal  $d\\times d{-m a t r i x}$  then  \\int_{\\mathbb{R}^{d}}f(A x+b)d x=\\int_{\\mathbb{R}^{d}}f(x)d x\\,.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTX_-_Postmodern_Analysis,_Third_Edition.pdf_183",
        "ID": "1047bcba-678c-40c3-b0fc-f3a02a143784",
        "questions": "What is the upper bound for the absolute value of the integral of function f over \\mathbb{R}^{d} if supp(f) is in a cube of side length e?",
        "answers": "|\\int_{\\mathbb{R}^{d}}f(x)d x|\\leq\\operatorname*{sup}|f(x)|\\cdot\\ell^{d}\\,.",
        "context": "$$\n\\begin{array}{l l}{\\displaystyle\\int(f(x)+g(x))d x=\\int_{\\mathbb R^{d}}f(x)d x+\\int_{\\mathbb R^{d}}g(x)d x,}\\\\ {\\displaystyle\\int_{\\mathbb R^{d}}\\alpha f(x)d x=\\alpha\\int_{\\mathbb R^{d}}f(x)d x\\ (l i n e a r i t y).}\\end{array}\n$$  \n\n(ii)  $If\\ f\\leq g$  then also  $\\begin{array}{r}{\\int_{\\mathbb{R}^{d}}f(\\boldsymbol{x})d\\boldsymbol{x}\\le\\int_{\\mathbb{R}^{d}}g(\\boldsymbol{x})d\\boldsymbol{x}\\,.}\\end{array}$  \n\n(iii)  $\\boldsymbol{I}f\\,\\boldsymbol{b}\\in\\mathbb{R}^{d},$   $A$  an orthogonal  $d\\times d{-m a t r i x}$  then  \n\n$$\n\\int_{\\mathbb{R}^{d}}f(A x+b)d x=\\int_{\\mathbb{R}^{d}}f(x)d x\\,.\n$$  \n\nProof. Parts (i) follows directly from the corresponding rules for the integral of elementary functions. The rule (iii) holds for elementary functions, because for an orthogonal matrix  $A$  and an elementary function  $t$  , the function  $t\\odot A$  is again elementary as  $A$  maps a cube on to a cube, and similarly for translation by a vector  $b$  . (ii) follows, as in case  $f\\leq g$  , we can approximate  $f$  and by  $g$  sequences  $(t_{n})$  and  $\\left(s_{n}\\right)$  , respectively, of elementary functions with  $t_{n}\\leq s_{n}$  \n\nFurthermore, we have  \n\nLemma 13.5 Let  $f\\in C_{c}(\\mathbb{R}^{d})$  with supp  $(f)$  in a cube of side length e. Then  \n\n$$\n|\\int_{\\mathbb{R}^{d}}f(x)d x|\\leq\\operatorname*{sup}|f(x)|\\cdot\\ell^{d}\\,.\n$$  \n\nThe proof again follows directly from the corresponding property for elementary functions.  \n\nLemmas 13.4 and 13.5 mean that the correspondence  \n\n$$\nf\\longmapsto\\int_{\\mathbb{R}^{d}}f(x)d x\n$$  \n\nis a linear, bounded (therefore continuous) real valued functional on each Banach space  $C_{c}(V)$   $W$  a cube in  $\\mathbb{R}^{d}$  ) that is invariant under isometries. One can show that a functional with these properties and the normalisation  \n\n$$\n\\intop_{I^{d}}1d x=1\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Equation",
        "evidence_source": "text",
        "evidence_context": "Let  $f\\in C_{c}(\\mathbb{R}^{d})$  with supp  $(f)$  in a cube of side length e. Then  $$ |\\int_{\\mathbb{R}^{d}}f(x)d x|\\leq\\operatorname*{sup}|f(x)|\\cdot\\ell^{d}\\,. $$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTX_-_Postmodern_Analysis,_Third_Edition.pdf_183",
        "ID": "104dff66-23f1-467e-81d3-4690a795ac54",
        "questions": "What is the integral property involving linearly combining functions f(x) and g(x)?",
        "answers": "\\int(f(x)+g(x))d x = \\int_{\\mathbb R^{d}}f(x)d x + \\int_{\\mathbb R^{d}}g(x)d x",
        "context": "$$\n\\begin{array}{l l}{\\displaystyle\\int(f(x)+g(x))d x=\\int_{\\mathbb R^{d}}f(x)d x+\\int_{\\mathbb R^{d}}g(x)d x,}\\\\ {\\displaystyle\\int_{\\mathbb R^{d}}\\alpha f(x)d x=\\alpha\\int_{\\mathbb R^{d}}f(x)d x\\ (l i n e a r i t y).}\\end{array}\n$$  \n\n(ii)  $If\\ f\\leq g$  then also  $\\begin{array}{r}{\\int_{\\mathbb{R}^{d}}f(\\boldsymbol{x})d\\boldsymbol{x}\\le\\int_{\\mathbb{R}^{d}}g(\\boldsymbol{x})d\\boldsymbol{x}\\,.}\\end{array}$  \n\n(iii)  $\\boldsymbol{I}f\\,\\boldsymbol{b}\\in\\mathbb{R}^{d},$   $A$  an orthogonal  $d\\times d{-m a t r i x}$  then  \n\n$$\n\\int_{\\mathbb{R}^{d}}f(A x+b)d x=\\int_{\\mathbb{R}^{d}}f(x)d x\\,.\n$$  \n\nProof. Parts (i) follows directly from the corresponding rules for the integral of elementary functions. The rule (iii) holds for elementary functions, because for an orthogonal matrix  $A$  and an elementary function  $t$  , the function  $t\\odot A$  is again elementary as  $A$  maps a cube on to a cube, and similarly for translation by a vector  $b$  . (ii) follows, as in case  $f\\leq g$  , we can approximate  $f$  and by  $g$  sequences  $(t_{n})$  and  $\\left(s_{n}\\right)$  , respectively, of elementary functions with  $t_{n}\\leq s_{n}$  \n\nFurthermore, we have  \n\nLemma 13.5 Let  $f\\in C_{c}(\\mathbb{R}^{d})$  with supp  $(f)$  in a cube of side length e. Then  \n\n$$\n|\\int_{\\mathbb{R}^{d}}f(x)d x|\\leq\\operatorname*{sup}|f(x)|\\cdot\\ell^{d}\\,.\n$$  \n\nThe proof again follows directly from the corresponding property for elementary functions.  \n\nLemmas 13.4 and 13.5 mean that the correspondence  \n\n$$\nf\\longmapsto\\int_{\\mathbb{R}^{d}}f(x)d x\n$$  \n\nis a linear, bounded (therefore continuous) real valued functional on each Banach space  $C_{c}(V)$   $W$  a cube in  $\\mathbb{R}^{d}$  ) that is invariant under isometries. One can show that a functional with these properties and the normalisation  \n\n$$\n\\intop_{I^{d}}1d x=1\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "{\\displaystyle\\int(f(x)+g(x))d x=\\int_{\\mathbb R^{d}}f(x)d x+\\int_{\\mathbb R^{d}}g(x)d x,}",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/UTX_-_Postmodern_Analysis,_Third_Edition.pdf_183",
        "ID": "106861d3-633d-4c54-b304-59cc30c42d61",
        "questions": "If f is less than or equal to g, what does the integral inequality state about integrating f(x) and g(x) over \\mathbb{R}^{d}?",
        "answers": "\\int_{\\mathbb{R}^{d}}f(\\boldsymbol{x})d\\boldsymbol{x}\\le\\int_{\\mathbb{R}^{d}}g(\\boldsymbol{x})d\\boldsymbol{x}",
        "context": "$$\n\\begin{array}{l l}{\\displaystyle\\int(f(x)+g(x))d x=\\int_{\\mathbb R^{d}}f(x)d x+\\int_{\\mathbb R^{d}}g(x)d x,}\\\\ {\\displaystyle\\int_{\\mathbb R^{d}}\\alpha f(x)d x=\\alpha\\int_{\\mathbb R^{d}}f(x)d x\\ (l i n e a r i t y).}\\end{array}\n$$  \n\n(ii)  $If\\ f\\leq g$  then also  $\\begin{array}{r}{\\int_{\\mathbb{R}^{d}}f(\\boldsymbol{x})d\\boldsymbol{x}\\le\\int_{\\mathbb{R}^{d}}g(\\boldsymbol{x})d\\boldsymbol{x}\\,.}\\end{array}$  \n\n(iii)  $\\boldsymbol{I}f\\,\\boldsymbol{b}\\in\\mathbb{R}^{d},$   $A$  an orthogonal  $d\\times d{-m a t r i x}$  then  \n\n$$\n\\int_{\\mathbb{R}^{d}}f(A x+b)d x=\\int_{\\mathbb{R}^{d}}f(x)d x\\,.\n$$  \n\nProof. Parts (i) follows directly from the corresponding rules for the integral of elementary functions. The rule (iii) holds for elementary functions, because for an orthogonal matrix  $A$  and an elementary function  $t$  , the function  $t\\odot A$  is again elementary as  $A$  maps a cube on to a cube, and similarly for translation by a vector  $b$  . (ii) follows, as in case  $f\\leq g$  , we can approximate  $f$  and by  $g$  sequences  $(t_{n})$  and  $\\left(s_{n}\\right)$  , respectively, of elementary functions with  $t_{n}\\leq s_{n}$  \n\nFurthermore, we have  \n\nLemma 13.5 Let  $f\\in C_{c}(\\mathbb{R}^{d})$  with supp  $(f)$  in a cube of side length e. Then  \n\n$$\n|\\int_{\\mathbb{R}^{d}}f(x)d x|\\leq\\operatorname*{sup}|f(x)|\\cdot\\ell^{d}\\,.\n$$  \n\nThe proof again follows directly from the corresponding property for elementary functions.  \n\nLemmas 13.4 and 13.5 mean that the correspondence  \n\n$$\nf\\longmapsto\\int_{\\mathbb{R}^{d}}f(x)d x\n$$  \n\nis a linear, bounded (therefore continuous) real valued functional on each Banach space  $C_{c}(V)$   $W$  a cube in  $\\mathbb{R}^{d}$  ) that is invariant under isometries. One can show that a functional with these properties and the normalisation  \n\n$$\n\\intop_{I^{d}}1d x=1\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Inequality Expression",
        "evidence_source": "equation",
        "evidence_context": "If\\ f\\leq g\\ then\\ also\\ {\\int_{\\mathbb{R}^{d}}f(\\boldsymbol{x})d\\boldsymbol{x}\\le\\int_{\\mathbb{R}^{d}}g(\\boldsymbol{x})d\\boldsymbol{x}\\,.}",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/UTX_-_Postmodern_Analysis,_Third_Edition.pdf_183",
        "ID": "106cb112-d7a7-40e8-bb38-d6d08870582a",
        "questions": "What condition must an orthogonal matrix A and vector b meet for the integral of f(Ax+b) over \\mathbb{R}^{d} to equal the integral of f(x) over \\mathbb{R}^{d}?",
        "answers": "\\int_{\\mathbb{R}^{d}}f(A x+b)d x=\\int_{\\mathbb{R}^{d}}f(x)d x",
        "context": "$$\n\\begin{array}{l l}{\\displaystyle\\int(f(x)+g(x))d x=\\int_{\\mathbb R^{d}}f(x)d x+\\int_{\\mathbb R^{d}}g(x)d x,}\\\\ {\\displaystyle\\int_{\\mathbb R^{d}}\\alpha f(x)d x=\\alpha\\int_{\\mathbb R^{d}}f(x)d x\\ (l i n e a r i t y).}\\end{array}\n$$  \n\n(ii)  $If\\ f\\leq g$  then also  $\\begin{array}{r}{\\int_{\\mathbb{R}^{d}}f(\\boldsymbol{x})d\\boldsymbol{x}\\le\\int_{\\mathbb{R}^{d}}g(\\boldsymbol{x})d\\boldsymbol{x}\\,.}\\end{array}$  \n\n(iii)  $\\boldsymbol{I}f\\,\\boldsymbol{b}\\in\\mathbb{R}^{d},$   $A$  an orthogonal  $d\\times d{-m a t r i x}$  then  \n\n$$\n\\int_{\\mathbb{R}^{d}}f(A x+b)d x=\\int_{\\mathbb{R}^{d}}f(x)d x\\,.\n$$  \n\nProof. Parts (i) follows directly from the corresponding rules for the integral of elementary functions. The rule (iii) holds for elementary functions, because for an orthogonal matrix  $A$  and an elementary function  $t$  , the function  $t\\odot A$  is again elementary as  $A$  maps a cube on to a cube, and similarly for translation by a vector  $b$  . (ii) follows, as in case  $f\\leq g$  , we can approximate  $f$  and by  $g$  sequences  $(t_{n})$  and  $\\left(s_{n}\\right)$  , respectively, of elementary functions with  $t_{n}\\leq s_{n}$  \n\nFurthermore, we have  \n\nLemma 13.5 Let  $f\\in C_{c}(\\mathbb{R}^{d})$  with supp  $(f)$  in a cube of side length e. Then  \n\n$$\n|\\int_{\\mathbb{R}^{d}}f(x)d x|\\leq\\operatorname*{sup}|f(x)|\\cdot\\ell^{d}\\,.\n$$  \n\nThe proof again follows directly from the corresponding property for elementary functions.  \n\nLemmas 13.4 and 13.5 mean that the correspondence  \n\n$$\nf\\longmapsto\\int_{\\mathbb{R}^{d}}f(x)d x\n$$  \n\nis a linear, bounded (therefore continuous) real valued functional on each Banach space  $C_{c}(V)$   $W$  a cube in  $\\mathbb{R}^{d}$  ) that is invariant under isometries. One can show that a functional with these properties and the normalisation  \n\n$$\n\\intop_{I^{d}}1d x=1\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Integral Equality",
        "evidence_source": "equation",
        "evidence_context": "\\int_{\\mathbb{R}^{d}}f(A x+b)d x=\\int_{\\mathbb{R}^{d}}f(x)d x\\,.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/[Ivan_Morton_Niven]_Numbers__Rational_and_Irration(z-lib.org).pdf_103",
        "ID": "10710096-cf60-4ea3-9d37-a7eb07323bec",
        "questions": "What is the inequality that any rational number \\(m/n\\) in lowest terms must satisfy given any irrational number \\(\\lambda\\), according to Theorem 6.5?",
        "answers": "$-\\frac{1}{n^{2}} < \\lambda - \\frac{m}{n} < \\frac{1}{n^{2}}$",
        "context": "Theorem 6.3, we moved to approximation to within $1/k n$ for some $n \\leq k$ in Theorem 6.4. Now we obtain approximations to within $1/n^{2}$.\n\nTHEOREM 6.5. Given any irrational number $\\lambda$, there are infinitely many rational numbers $m/n$ in lowest terms such that\n\n$$\n-\\frac{1}{n^{2}}<\\lambda-\\frac{m}{n}<\\frac{1}{n^{2}}.\n$$\n\nProoF. First, we observe that any rational number $m/n$ satisfying the inequality of Theorem 6.4 automatically satisfies that of Theorem 6.5. The reason for this is that since $n$ does not exceed $k$, from $k \\geq n$ we may deduce, using Theorem 6.1, parts (d), (e), and (g), that\n\n$$\n{\\frac{1}{k}}\\leq{\\frac{1}{n}}\\qquad{\\mathrm{and}}\\qquad{\\frac{1}{k n}}\\leq{\\frac{1}{n^{2}}}.\n$$\n\nHence, any number which lies between $-1/k n$ and $1/k n$ must certainly lie in the range between $-1/n^{2}$ and $1/n^{2}$.\n\nNext, we show that if any rational number $m/n$, not in lowest terms, satisfies the inequalities of the theorem, then the same rational number, in lowest terms, must also satisfy the appropriate inequalities. Let us write $M/N$ as the form of $m/n$ in lowest terms. We may presume that both $\\pmb{n}$ and $N$ are positive, any negative sign being absorbed into the numerator. Hence, we have\n\n$$\n{\\frac{m}{n}}={\\frac{M}{N}},\\qquad0<\\,N<\\,n,\n$$\n\nbecause the reduction to lowest terms does not alter the value of the fraction but does reduce the size of the denominator. It follows from Theorem 6.1 that\n\n$$\n{\\frac{1}{n}}<{\\frac{1}{N}}\\quad\\quad{\\mathrm{and}}\\quad\\quad{\\frac{1}{n^{2}}}<{\\frac{1}{N^{2}}},\n$$\n\nand so if $\\lambda$ satisfies\n\n$$\n-\\frac{1}{n^{2}}<\\lambda-\\frac{m}{n}<\\frac{1}{n^{2}},\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "THEOREM 6.5. Given any irrational number $\\lambda$, there are infinitely many rational numbers $m/n$ in lowest terms such that $$-\frac{1}{n^{2}}<\\lambda-\frac{m}{n}<\frac{1}{n^{2}}.$$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/[Ivan_Morton_Niven]_Numbers__Rational_and_Irration(z-lib.org).pdf_103",
        "ID": "1088a81b-85b1-4cd4-aea0-026b9cbbb38e",
        "questions": "In the proof of Theorem 6.5, what relationship between \\(k\\) and \\(n\\) is used to show that any number lying between \\(-1/kn\\) and \\(1/kn\\) must lie between \\(-1/n^2\\) and \\(1/n^2\\)?",
        "answers": "$k \\geq n$",
        "context": "Theorem 6.3, we moved to approximation to within $1/k n$ for some $n \\leq k$ in Theorem 6.4. Now we obtain approximations to within $1/n^{2}$.\n\nTHEOREM 6.5. Given any irrational number $\\lambda$, there are infinitely many rational numbers $m/n$ in lowest terms such that\n\n$$\n-\\frac{1}{n^{2}}<\\lambda-\\frac{m}{n}<\\frac{1}{n^{2}}.\n$$\n\nProoF. First, we observe that any rational number $m/n$ satisfying the inequality of Theorem 6.4 automatically satisfies that of Theorem 6.5. The reason for this is that since $n$ does not exceed $k$, from $k \\geq n$ we may deduce, using Theorem 6.1, parts (d), (e), and (g), that\n\n$$\n{\\frac{1}{k}}\\leq{\\frac{1}{n}}\\qquad{\\mathrm{and}}\\qquad{\\frac{1}{k n}}\\leq{\\frac{1}{n^{2}}}.\n$$\n\nHence, any number which lies between $-1/k n$ and $1/k n$ must certainly lie in the range between $-1/n^{2}$ and $1/n^{2}$.\n\nNext, we show that if any rational number $m/n$, not in lowest terms, satisfies the inequalities of the theorem, then the same rational number, in lowest terms, must also satisfy the appropriate inequalities. Let us write $M/N$ as the form of $m/n$ in lowest terms. We may presume that both $\\pmb{n}$ and $N$ are positive, any negative sign being absorbed into the numerator. Hence, we have\n\n$$\n{\\frac{m}{n}}={\\frac{M}{N}},\\qquad0<\\,N<\\,n,\n$$\n\nbecause the reduction to lowest terms does not alter the value of the fraction but does reduce the size of the denominator. It follows from Theorem 6.1 that\n\n$$\n{\\frac{1}{n}}<{\\frac{1}{N}}\\quad\\quad{\\mathrm{and}}\\quad\\quad{\\frac{1}{n^{2}}}<{\\frac{1}{N^{2}}},\n$$\n\nand so if $\\lambda$ satisfies\n\n$$\n-\\frac{1}{n^{2}}<\\lambda-\\frac{m}{n}<\\frac{1}{n^{2}},\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "The reason for this is that since $n$ does not exceed $k$, from $k \\geq n$ we may deduce, using Theorem 6.1, parts (d), (e), and (g), that $$\frac{1}{k}\\leq\frac{1}{n}\\qquad\\mathrm{and}\\qquad\frac{1}{kn}\\leq\frac{1}{n^{2}}.$$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/[Ivan_Morton_Niven]_Numbers__Rational_and_Irration(z-lib.org).pdf_103",
        "ID": "108956c0-6a54-4593-b68f-80528f38b308",
        "questions": "According to Theorem 6.5's proof, how does reducing a fraction \\(m/n\\) to its lowest terms \\(M/N\\) affect the inequality if \\(M/N\\) also satisfies the inequalities of the theorem?",
        "answers": "0<N<n",
        "context": "Theorem 6.3, we moved to approximation to within $1/k n$ for some $n \\leq k$ in Theorem 6.4. Now we obtain approximations to within $1/n^{2}$.\n\nTHEOREM 6.5. Given any irrational number $\\lambda$, there are infinitely many rational numbers $m/n$ in lowest terms such that\n\n$$\n-\\frac{1}{n^{2}}<\\lambda-\\frac{m}{n}<\\frac{1}{n^{2}}.\n$$\n\nProoF. First, we observe that any rational number $m/n$ satisfying the inequality of Theorem 6.4 automatically satisfies that of Theorem 6.5. The reason for this is that since $n$ does not exceed $k$, from $k \\geq n$ we may deduce, using Theorem 6.1, parts (d), (e), and (g), that\n\n$$\n{\\frac{1}{k}}\\leq{\\frac{1}{n}}\\qquad{\\mathrm{and}}\\qquad{\\frac{1}{k n}}\\leq{\\frac{1}{n^{2}}}.\n$$\n\nHence, any number which lies between $-1/k n$ and $1/k n$ must certainly lie in the range between $-1/n^{2}$ and $1/n^{2}$.\n\nNext, we show that if any rational number $m/n$, not in lowest terms, satisfies the inequalities of the theorem, then the same rational number, in lowest terms, must also satisfy the appropriate inequalities. Let us write $M/N$ as the form of $m/n$ in lowest terms. We may presume that both $\\pmb{n}$ and $N$ are positive, any negative sign being absorbed into the numerator. Hence, we have\n\n$$\n{\\frac{m}{n}}={\\frac{M}{N}},\\qquad0<\\,N<\\,n,\n$$\n\nbecause the reduction to lowest terms does not alter the value of the fraction but does reduce the size of the denominator. It follows from Theorem 6.1 that\n\n$$\n{\\frac{1}{n}}<{\\frac{1}{N}}\\quad\\quad{\\mathrm{and}}\\quad\\quad{\\frac{1}{n^{2}}}<{\\frac{1}{N^{2}}},\n$$\n\nand so if $\\lambda$ satisfies\n\n$$\n-\\frac{1}{n^{2}}<\\lambda-\\frac{m}{n}<\\frac{1}{n^{2}},\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Next, we show that if any rational number $m/n$, not in lowest terms, satisfies the inequalities of the theorem, then the same rational number, in lowest terms, must also satisfy the appropriate inequalities. Let us write $M/N$ as the form of $m/n$ in lowest terms. We may presume that both $n$ and $N$ are positive, any negative sign being absorbed into the numerator. Hence, we have $$\frac{m}{n}=\frac{M}{N},\\qquad0<\\,N<\\,n,$$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/[Ivan_Morton_Niven]_Numbers__Rational_and_Irration(z-lib.org).pdf_103",
        "ID": "108e0777-95b7-4925-a86c-deaf9dc701aa",
        "questions": "What inequality does Theorem 6.5 define for any irrational number $\\lambda$ in relation to the rational number $m/n$ in lowest terms?",
        "answers": "-\\frac{1}{n^{2}}<\\lambda-\\frac{m}{n}<\\frac{1}{n^{2}}.",
        "context": "Theorem 6.3, we moved to approximation to within $1/k n$ for some $n \\leq k$ in Theorem 6.4. Now we obtain approximations to within $1/n^{2}$.\n\nTHEOREM 6.5. Given any irrational number $\\lambda$, there are infinitely many rational numbers $m/n$ in lowest terms such that\n\n$$\n-\\frac{1}{n^{2}}<\\lambda-\\frac{m}{n}<\\frac{1}{n^{2}}.\n$$\n\nProoF. First, we observe that any rational number $m/n$ satisfying the inequality of Theorem 6.4 automatically satisfies that of Theorem 6.5. The reason for this is that since $n$ does not exceed $k$, from $k \\geq n$ we may deduce, using Theorem 6.1, parts (d), (e), and (g), that\n\n$$\n{\\frac{1}{k}}\\leq{\\frac{1}{n}}\\qquad{\\mathrm{and}}\\qquad{\\frac{1}{k n}}\\leq{\\frac{1}{n^{2}}}.\n$$\n\nHence, any number which lies between $-1/k n$ and $1/k n$ must certainly lie in the range between $-1/n^{2}$ and $1/n^{2}$.\n\nNext, we show that if any rational number $m/n$, not in lowest terms, satisfies the inequalities of the theorem, then the same rational number, in lowest terms, must also satisfy the appropriate inequalities. Let us write $M/N$ as the form of $m/n$ in lowest terms. We may presume that both $\\pmb{n}$ and $N$ are positive, any negative sign being absorbed into the numerator. Hence, we have\n\n$$\n{\\frac{m}{n}}={\\frac{M}{N}},\\qquad0<\\,N<\\,n,\n$$\n\nbecause the reduction to lowest terms does not alter the value of the fraction but does reduce the size of the denominator. It follows from Theorem 6.1 that\n\n$$\n{\\frac{1}{n}}<{\\frac{1}{N}}\\quad\\quad{\\mathrm{and}}\\quad\\quad{\\frac{1}{n^{2}}}<{\\frac{1}{N^{2}}},\n$$\n\nand so if $\\lambda$ satisfies\n\n$$\n-\\frac{1}{n^{2}}<\\lambda-\\frac{m}{n}<\\frac{1}{n^{2}},\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Given any irrational number \\(\\lambda\\), there are infinitely many rational numbers $m/n$ in lowest terms such that $$-\\frac{1}{n^{2}}<\\lambda-\\frac{m}{n}<\\frac{1}{n^{2}}.$$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/[Ivan_Morton_Niven]_Numbers__Rational_and_Irration(z-lib.org).pdf_103",
        "ID": "1094625b-f102-40d0-859c-5fe3ad031c4d",
        "questions": "According to Theorem 6.5, if $n$ does not exceed $k$, what can be deduced from $k \\geq n$ using Theorem 6.1?",
        "answers": "\\frac{1}{k}\\leq\\frac{1}{n}\\qquad\\mathrm{and}\\qquad\\frac{1}{k n}\\leq\\frac{1}{n^{2}}.",
        "context": "Theorem 6.3, we moved to approximation to within $1/k n$ for some $n \\leq k$ in Theorem 6.4. Now we obtain approximations to within $1/n^{2}$.\n\nTHEOREM 6.5. Given any irrational number $\\lambda$, there are infinitely many rational numbers $m/n$ in lowest terms such that\n\n$$\n-\\frac{1}{n^{2}}<\\lambda-\\frac{m}{n}<\\frac{1}{n^{2}}.\n$$\n\nProoF. First, we observe that any rational number $m/n$ satisfying the inequality of Theorem 6.4 automatically satisfies that of Theorem 6.5. The reason for this is that since $n$ does not exceed $k$, from $k \\geq n$ we may deduce, using Theorem 6.1, parts (d), (e), and (g), that\n\n$$\n{\\frac{1}{k}}\\leq{\\frac{1}{n}}\\qquad{\\mathrm{and}}\\qquad{\\frac{1}{k n}}\\leq{\\frac{1}{n^{2}}}.\n$$\n\nHence, any number which lies between $-1/k n$ and $1/k n$ must certainly lie in the range between $-1/n^{2}$ and $1/n^{2}$.\n\nNext, we show that if any rational number $m/n$, not in lowest terms, satisfies the inequalities of the theorem, then the same rational number, in lowest terms, must also satisfy the appropriate inequalities. Let us write $M/N$ as the form of $m/n$ in lowest terms. We may presume that both $\\pmb{n}$ and $N$ are positive, any negative sign being absorbed into the numerator. Hence, we have\n\n$$\n{\\frac{m}{n}}={\\frac{M}{N}},\\qquad0<\\,N<\\,n,\n$$\n\nbecause the reduction to lowest terms does not alter the value of the fraction but does reduce the size of the denominator. It follows from Theorem 6.1 that\n\n$$\n{\\frac{1}{n}}<{\\frac{1}{N}}\\quad\\quad{\\mathrm{and}}\\quad\\quad{\\frac{1}{n^{2}}}<{\\frac{1}{N^{2}}},\n$$\n\nand so if $\\lambda$ satisfies\n\n$$\n-\\frac{1}{n^{2}}<\\lambda-\\frac{m}{n}<\\frac{1}{n^{2}},\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "The reason for this is that since $n$ does not exceed $k$, from $k \\geq n$ we may deduce, using Theorem 6.1, parts (d), (e), and (g), that $$ \\frac{1}{k}\\leq\\frac{1}{n}\\qquad\\mathrm{and}\\qquad\\frac{1}{k n}\\leq\\frac{1}{n^{2}}.$$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/[Ivan_Morton_Niven]_Numbers__Rational_and_Irration(z-lib.org).pdf_103",
        "ID": "109d5c8d-4562-4aff-96b2-64357bb8be94",
        "questions": "For any rational number $m/n$ satisfying the inequality $\n{-1/k n < \\lambda - m/n < 1/k n}$, is it true that it also satisfies the inequality of Theorem 6.5?",
        "answers": "Yes",
        "context": "Theorem 6.3, we moved to approximation to within $1/k n$ for some $n \\leq k$ in Theorem 6.4. Now we obtain approximations to within $1/n^{2}$.\n\nTHEOREM 6.5. Given any irrational number $\\lambda$, there are infinitely many rational numbers $m/n$ in lowest terms such that\n\n$$\n-\\frac{1}{n^{2}}<\\lambda-\\frac{m}{n}<\\frac{1}{n^{2}}.\n$$\n\nProoF. First, we observe that any rational number $m/n$ satisfying the inequality of Theorem 6.4 automatically satisfies that of Theorem 6.5. The reason for this is that since $n$ does not exceed $k$, from $k \\geq n$ we may deduce, using Theorem 6.1, parts (d), (e), and (g), that\n\n$$\n{\\frac{1}{k}}\\leq{\\frac{1}{n}}\\qquad{\\mathrm{and}}\\qquad{\\frac{1}{k n}}\\leq{\\frac{1}{n^{2}}}.\n$$\n\nHence, any number which lies between $-1/k n$ and $1/k n$ must certainly lie in the range between $-1/n^{2}$ and $1/n^{2}$.\n\nNext, we show that if any rational number $m/n$, not in lowest terms, satisfies the inequalities of the theorem, then the same rational number, in lowest terms, must also satisfy the appropriate inequalities. Let us write $M/N$ as the form of $m/n$ in lowest terms. We may presume that both $\\pmb{n}$ and $N$ are positive, any negative sign being absorbed into the numerator. Hence, we have\n\n$$\n{\\frac{m}{n}}={\\frac{M}{N}},\\qquad0<\\,N<\\,n,\n$$\n\nbecause the reduction to lowest terms does not alter the value of the fraction but does reduce the size of the denominator. It follows from Theorem 6.1 that\n\n$$\n{\\frac{1}{n}}<{\\frac{1}{N}}\\quad\\quad{\\mathrm{and}}\\quad\\quad{\\frac{1}{n^{2}}}<{\\frac{1}{N^{2}}},\n$$\n\nand so if $\\lambda$ satisfies\n\n$$\n-\\frac{1}{n^{2}}<\\lambda-\\frac{m}{n}<\\frac{1}{n^{2}},\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Yes/No",
        "evidence_source": "equation",
        "evidence_context": "Hence, any number which lies between $-1/k n$ and $1/k n$ must certainly lie in the range between $-1/n^{2}$ and $1/n^{2}$.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/UTX_-_Mathematical_Methods_in_Biology_and_Neurobiology.pdf_81",
        "ID": "10a74c94-af37-48b6-b981-069c0886aa83",
        "questions": "What is the simplest branching process mentioned in the document?",
        "answers": "the Galton-Watson process",
        "context": "Exist, and we shall introduce and investigate below the basic one, the Hodgkin Huxley model. Notwithstanding its lack of bio-physical realism, however, Poisson type models are very important in neuroscience because, on one hand, they relate well to the experimental practice of recording spikes, and on the other hand, they can be the basis for models of information transmission in neural systems.\n\n# 3.4 Branching Processes  \n\nReferences for this section are [80, 56]  \n\nWe start with the simplest branching process, the Galton-Watson process. Here, each individual lives in a fixed generation $n$ and independently of all other individuals produces a random number of offspring that become members of generation $n+1$. This random variable, the number of offspring, is the same for all individuals in all generations. Thus, the numbers of offspring for the individuals are independent and identically distributed random variables. We denote their common generating function by $G(s)$. We also assume that there is a positive probability for having more than one offspring. If the probability of having $m$ offspring is $p(m)$, this means that $p(0) + p(1) < 1$.\n\nLet the random variable $Z_{n}$ denote the size of generation $n$. One usually assumes that the process starts with a single individual in generation 0, that is, $Z_{0} = 1$.\n\nLet $G_{n}(s) = E(s^{Z_{n}})$ be the generating function of $Z_{n}$.\n\nLemma 3.4.1. $G_{n}$ is the $n$-th fold iterate of $G$.\n\n$$\nG_{n}(s) = G \\circ \\cdots \\circ G(s),\n$$\n\nand thus also for $m, n \\in \\mathbb{N}$,\n\n$$\nG_{m+n}(s) = G_{m}(G_{n}(s)).\n$$\n\nProof. We shall show (3.4.2) which easily implies (3.4.1) by iteration. Let the random variable $Y_{i}$ denote the number of members of the $(m+n)$th generation that derive from member $i$ of the $m$th one. We then have\n\n$$\nZ_{m+n} = Y_{1} + \\cdot\\cdot\\cdot + Y_{Z_{m}}.\n$$\n\nBy our assumptions, the $Y_{i}$ are independent and identically distributed, in fact identical to $Z_{n}$, the number of offspring deriving from an individual $n$ generations ago. Lemma 3.1.3c) then yields the claim.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "We start with the simplest branching process, the Galton-Watson process.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTX_-_Mathematical_Methods_in_Biology_and_Neurobiology.pdf_81",
        "ID": "10ab5ce4-f9a9-449a-8958-45edd65e5de6",
        "questions": "What is denoted by the random variable $Z_{n}$ in relation to the branching process described?",
        "answers": "the size of generation $n$",
        "context": "Exist, and we shall introduce and investigate below the basic one, the Hodgkin Huxley model. Notwithstanding its lack of bio-physical realism, however, Poisson type models are very important in neuroscience because, on one hand, they relate well to the experimental practice of recording spikes, and on the other hand, they can be the basis for models of information transmission in neural systems.\n\n# 3.4 Branching Processes  \n\nReferences for this section are [80, 56]  \n\nWe start with the simplest branching process, the Galton-Watson process. Here, each individual lives in a fixed generation $n$ and independently of all other individuals produces a random number of offspring that become members of generation $n+1$. This random variable, the number of offspring, is the same for all individuals in all generations. Thus, the numbers of offspring for the individuals are independent and identically distributed random variables. We denote their common generating function by $G(s)$. We also assume that there is a positive probability for having more than one offspring. If the probability of having $m$ offspring is $p(m)$, this means that $p(0) + p(1) < 1$.\n\nLet the random variable $Z_{n}$ denote the size of generation $n$. One usually assumes that the process starts with a single individual in generation 0, that is, $Z_{0} = 1$.\n\nLet $G_{n}(s) = E(s^{Z_{n}})$ be the generating function of $Z_{n}$.\n\nLemma 3.4.1. $G_{n}$ is the $n$-th fold iterate of $G$.\n\n$$\nG_{n}(s) = G \\circ \\cdots \\circ G(s),\n$$\n\nand thus also for $m, n \\in \\mathbb{N}$,\n\n$$\nG_{m+n}(s) = G_{m}(G_{n}(s)).\n$$\n\nProof. We shall show (3.4.2) which easily implies (3.4.1) by iteration. Let the random variable $Y_{i}$ denote the number of members of the $(m+n)$th generation that derive from member $i$ of the $m$th one. We then have\n\n$$\nZ_{m+n} = Y_{1} + \\cdot\\cdot\\cdot + Y_{Z_{m}}.\n$$\n\nBy our assumptions, the $Y_{i}$ are independent and identically distributed, in fact identical to $Z_{n}$, the number of offspring deriving from an individual $n$ generations ago. Lemma 3.1.3c) then yields the claim.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Let the random variable $Z_{n}$ denote the size of generation $n$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTX_-_Mathematical_Methods_in_Biology_and_Neurobiology.pdf_81",
        "ID": "10b94515-0727-41ba-a43c-f05a62e973d6",
        "questions": "If $Z_{0} = 1$ and the generating function of $Z_{n}$ is $G_{n}(s)$, what is the fold iteration relation given for $G_{n}$ and $G$?",
        "answers": "$G_{n}(s) = G \\circ \\cdots \\circ G(s)$",
        "context": "Exist, and we shall introduce and investigate below the basic one, the Hodgkin Huxley model. Notwithstanding its lack of bio-physical realism, however, Poisson type models are very important in neuroscience because, on one hand, they relate well to the experimental practice of recording spikes, and on the other hand, they can be the basis for models of information transmission in neural systems.\n\n# 3.4 Branching Processes  \n\nReferences for this section are [80, 56]  \n\nWe start with the simplest branching process, the Galton-Watson process. Here, each individual lives in a fixed generation $n$ and independently of all other individuals produces a random number of offspring that become members of generation $n+1$. This random variable, the number of offspring, is the same for all individuals in all generations. Thus, the numbers of offspring for the individuals are independent and identically distributed random variables. We denote their common generating function by $G(s)$. We also assume that there is a positive probability for having more than one offspring. If the probability of having $m$ offspring is $p(m)$, this means that $p(0) + p(1) < 1$.\n\nLet the random variable $Z_{n}$ denote the size of generation $n$. One usually assumes that the process starts with a single individual in generation 0, that is, $Z_{0} = 1$.\n\nLet $G_{n}(s) = E(s^{Z_{n}})$ be the generating function of $Z_{n}$.\n\nLemma 3.4.1. $G_{n}$ is the $n$-th fold iterate of $G$.\n\n$$\nG_{n}(s) = G \\circ \\cdots \\circ G(s),\n$$\n\nand thus also for $m, n \\in \\mathbb{N}$,\n\n$$\nG_{m+n}(s) = G_{m}(G_{n}(s)).\n$$\n\nProof. We shall show (3.4.2) which easily implies (3.4.1) by iteration. Let the random variable $Y_{i}$ denote the number of members of the $(m+n)$th generation that derive from member $i$ of the $m$th one. We then have\n\n$$\nZ_{m+n} = Y_{1} + \\cdot\\cdot\\cdot + Y_{Z_{m}}.\n$$\n\nBy our assumptions, the $Y_{i}$ are independent and identically distributed, in fact identical to $Z_{n}$, the number of offspring deriving from an individual $n$ generations ago. Lemma 3.1.3c) then yields the claim.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Equation",
        "evidence_source": "equation",
        "evidence_context": "Lemma 3.4.1. $G_{n}$ is the $n$-th fold iterate of $G$. $G_{n}(s) = G \\circ \\cdots \\circ G(s)$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTX_-_Mathematical_Methods_in_Biology_and_Neurobiology.pdf_81",
        "ID": "10c23883-2a16-4138-b5cf-b04b087a49f5",
        "questions": "What is the generating function of the size of generation $n$, denoted as $Z_{n}$, in the Galton-Watson process?",
        "answers": "$G_{n}(s) = G \\circ \\cdots \\circ G(s)$",
        "context": "Exist, and we shall introduce and investigate below the basic one, the Hodgkin Huxley model. Notwithstanding its lack of bio-physical realism, however, Poisson type models are very important in neuroscience because, on one hand, they relate well to the experimental practice of recording spikes, and on the other hand, they can be the basis for models of information transmission in neural systems.\n\n# 3.4 Branching Processes  \n\nReferences for this section are [80, 56]  \n\nWe start with the simplest branching process, the Galton-Watson process. Here, each individual lives in a fixed generation $n$ and independently of all other individuals produces a random number of offspring that become members of generation $n+1$. This random variable, the number of offspring, is the same for all individuals in all generations. Thus, the numbers of offspring for the individuals are independent and identically distributed random variables. We denote their common generating function by $G(s)$. We also assume that there is a positive probability for having more than one offspring. If the probability of having $m$ offspring is $p(m)$, this means that $p(0) + p(1) < 1$.\n\nLet the random variable $Z_{n}$ denote the size of generation $n$. One usually assumes that the process starts with a single individual in generation 0, that is, $Z_{0} = 1$.\n\nLet $G_{n}(s) = E(s^{Z_{n}})$ be the generating function of $Z_{n}$.\n\nLemma 3.4.1. $G_{n}$ is the $n$-th fold iterate of $G$.\n\n$$\nG_{n}(s) = G \\circ \\cdots \\circ G(s),\n$$\n\nand thus also for $m, n \\in \\mathbb{N}$,\n\n$$\nG_{m+n}(s) = G_{m}(G_{n}(s)).\n$$\n\nProof. We shall show (3.4.2) which easily implies (3.4.1) by iteration. Let the random variable $Y_{i}$ denote the number of members of the $(m+n)$th generation that derive from member $i$ of the $m$th one. We then have\n\n$$\nZ_{m+n} = Y_{1} + \\cdot\\cdot\\cdot + Y_{Z_{m}}.\n$$\n\nBy our assumptions, the $Y_{i}$ are independent and identically distributed, in fact identical to $Z_{n}$, the number of offspring deriving from an individual $n$ generations ago. Lemma 3.1.3c) then yields the claim.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Lemma 3.4.1. $G_{n}$ is the $n$-th fold iterate of $G$. $$ G_{n}(s) = G \\circ \\cdots \\circ G(s), $$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/UTX_-_Mathematical_Methods_in_Biology_and_Neurobiology.pdf_81",
        "ID": "10c565d5-5405-4bed-9fb8-61a396d53ecf",
        "questions": "In the Galton-Watson process, how is the generating function for $m+n$ generations expressed in terms of the generating functions for $m$ and $n$ generations?",
        "answers": "$G_{m+n}(s) = G_{m}(G_{n}(s))$",
        "context": "Exist, and we shall introduce and investigate below the basic one, the Hodgkin Huxley model. Notwithstanding its lack of bio-physical realism, however, Poisson type models are very important in neuroscience because, on one hand, they relate well to the experimental practice of recording spikes, and on the other hand, they can be the basis for models of information transmission in neural systems.\n\n# 3.4 Branching Processes  \n\nReferences for this section are [80, 56]  \n\nWe start with the simplest branching process, the Galton-Watson process. Here, each individual lives in a fixed generation $n$ and independently of all other individuals produces a random number of offspring that become members of generation $n+1$. This random variable, the number of offspring, is the same for all individuals in all generations. Thus, the numbers of offspring for the individuals are independent and identically distributed random variables. We denote their common generating function by $G(s)$. We also assume that there is a positive probability for having more than one offspring. If the probability of having $m$ offspring is $p(m)$, this means that $p(0) + p(1) < 1$.\n\nLet the random variable $Z_{n}$ denote the size of generation $n$. One usually assumes that the process starts with a single individual in generation 0, that is, $Z_{0} = 1$.\n\nLet $G_{n}(s) = E(s^{Z_{n}})$ be the generating function of $Z_{n}$.\n\nLemma 3.4.1. $G_{n}$ is the $n$-th fold iterate of $G$.\n\n$$\nG_{n}(s) = G \\circ \\cdots \\circ G(s),\n$$\n\nand thus also for $m, n \\in \\mathbb{N}$,\n\n$$\nG_{m+n}(s) = G_{m}(G_{n}(s)).\n$$\n\nProof. We shall show (3.4.2) which easily implies (3.4.1) by iteration. Let the random variable $Y_{i}$ denote the number of members of the $(m+n)$th generation that derive from member $i$ of the $m$th one. We then have\n\n$$\nZ_{m+n} = Y_{1} + \\cdot\\cdot\\cdot + Y_{Z_{m}}.\n$$\n\nBy our assumptions, the $Y_{i}$ are independent and identically distributed, in fact identical to $Z_{n}$, the number of offspring deriving from an individual $n$ generations ago. Lemma 3.1.3c) then yields the claim.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "and thus also for $m, n \\in \\mathbb{N}$, $$ G_{m+n}(s) = G_{m}(G_{n}(s)). $$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/UTX_-_Mathematical_Methods_in_Biology_and_Neurobiology.pdf_81",
        "ID": "10c8cc63-2c98-4a95-8122-dbb0d671ac8e",
        "questions": "How is the size of generation $m+n$ expressed in terms of the random variables related to generation $m$ in the Galton-Watson process?",
        "answers": "$Z_{m+n} = Y_{1} + \\cdot\\cdot\\cdot + Y_{Z_{m}}$",
        "context": "Exist, and we shall introduce and investigate below the basic one, the Hodgkin Huxley model. Notwithstanding its lack of bio-physical realism, however, Poisson type models are very important in neuroscience because, on one hand, they relate well to the experimental practice of recording spikes, and on the other hand, they can be the basis for models of information transmission in neural systems.\n\n# 3.4 Branching Processes  \n\nReferences for this section are [80, 56]  \n\nWe start with the simplest branching process, the Galton-Watson process. Here, each individual lives in a fixed generation $n$ and independently of all other individuals produces a random number of offspring that become members of generation $n+1$. This random variable, the number of offspring, is the same for all individuals in all generations. Thus, the numbers of offspring for the individuals are independent and identically distributed random variables. We denote their common generating function by $G(s)$. We also assume that there is a positive probability for having more than one offspring. If the probability of having $m$ offspring is $p(m)$, this means that $p(0) + p(1) < 1$.\n\nLet the random variable $Z_{n}$ denote the size of generation $n$. One usually assumes that the process starts with a single individual in generation 0, that is, $Z_{0} = 1$.\n\nLet $G_{n}(s) = E(s^{Z_{n}})$ be the generating function of $Z_{n}$.\n\nLemma 3.4.1. $G_{n}$ is the $n$-th fold iterate of $G$.\n\n$$\nG_{n}(s) = G \\circ \\cdots \\circ G(s),\n$$\n\nand thus also for $m, n \\in \\mathbb{N}$,\n\n$$\nG_{m+n}(s) = G_{m}(G_{n}(s)).\n$$\n\nProof. We shall show (3.4.2) which easily implies (3.4.1) by iteration. Let the random variable $Y_{i}$ denote the number of members of the $(m+n)$th generation that derive from member $i$ of the $m$th one. We then have\n\n$$\nZ_{m+n} = Y_{1} + \\cdot\\cdot\\cdot + Y_{Z_{m}}.\n$$\n\nBy our assumptions, the $Y_{i}$ are independent and identically distributed, in fact identical to $Z_{n}$, the number of offspring deriving from an individual $n$ generations ago. Lemma 3.1.3c) then yields the claim.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "We then have $$ Z_{m+n} = Y_{1} + \\cdot\\cdot\\cdot + Y_{Z_{m}}. $$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/med-76735.pdf_625",
        "ID": "10d41a34-2ce2-48dc-931c-617d97a922a2",
        "questions": "What are some defining characteristics of the NANDA-I diagnosis 'Readiness for Enhanced Spiritual Well-Being'?",
        "answers": "[\"Connections to Self\",\"Connections with Others\",\"Connections with Art, Music, Literature, and Nature\",\"Connections with Power Greater than Self\"]",
        "context": "# Diagnoses  \n\n\\begin{table}[h!]\n\\centering\n\\caption{Common NANDA-I Nursing Diagnoses Related to Spiritual Health}\n\\begin{tabular}{|p{4cm}|p{6cm}|p{7cm}|}\n \nNANDA-I Diagnosis & Definition & Defining Characteristics \\\\  \n\nReadiness for Enhanced Spiritual Well-Being \n& A pattern of experiencing and integrating meaning and purpose in life through connectedness with self, others, art, music, literature, nature, and/or a power greater than oneself, which can be strengthened\n& \n    \\item Connections to Self\n    \\item Connections with Others\n    \\item Connections with Art, Music, Literature, and Nature\n    \\item Connections with Power Greater than Self\n    \\begin{itemize}\n        \\item Expresses desire to enhance participation in religious activity\n        \\item Expresses desire to enhance prayerfulness\n    \n\\end{itemize} \\\\  \n\nImpaired Religiosity \n& Impaired ability to exercise reliance on beliefs and/or participate in rituals of a particular faith tradition \n& \n    \\item Desires to reconnect with previous belief pattern\n    \\item Has difficulty adhering to prescribed religious beliefs and/or rituals\n    \\item Distresses about separation from the faith community\n \\\\  \n\nSpiritual Distress \n& A state of suffering related to the impaired ability to experience meaning in life through connections with self, others, the world, or a superior being\n& \n    \\item Anxiety\n    \\item Crying\n    \\item Fatigue\n    \\item Fear\n    \\item Insomnia\n    \\item Questioning identity\n    \\item Questioning meaning of life\n    \\item Questioning meaning of suffering\n \\\\  \n\n\\end{tabular}\n\\end{table}\n\n\n# Sample Nursing Diagnosis Statements  \n\n# Readiness for Enhanced Spiritual Well-Being  \n\nMany people experienced feelings of isolation as they sheltered at home during the COVID-19 pandemic. A sample PES statement for this shared experience is, \"Readiness for Enhanced Spiritual Well-Being as evidenced by expressed desire to enhance time outdoors.\" The nurse could encourage patients to visit local parks and walk outdoors while wearing a mask and maintaining social distancing.  \n\n> ![](images/752479bdb28ccbc0397fc551d39c43031a5ab65440a571bf24202c440ce91f03.jpg)  \nRecall that when a PES statement is created for a health promotion diagnosis, the defining characteristics are provided as evidence of the desire of the patient to improve their current health status.  \n\n# Impaired Religiosity  \n\nHospitalized patients may be unable to attend religious services they are accustomed to attending. A sample PES statement is, \"Impaired Religiosity related to environmental barriers to practicing religion as evidenced by difficulty adhering to prescribed religious beliefs.\" The nurse could contact the patient's pastor to arrange a visitor or determine if services can be viewed online.  \n\n# Spiritual Distress  \n\nEvents that place patient populations at risk for developing spiritual distress include birth of a child, death of a significant other, exposure to death, a significant life transition, severe illness or injury, exposure to natural disaster, racial conflict, or an unexpected event.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "table",
        "evidence_context": "Readiness for Enhanced Spiritual Well-Being & A pattern of experiencing and integrating meaning and purpose in life through connectedness with self, others, art, music, literature, nature, and/or a power greater than oneself, which can be strengthened & \n     Connections to Self\n     Connections with Others\n     Connections with Art, Music, Literature, and Nature\n     Connections with Power Greater than Self",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/med-76735.pdf_625",
        "ID": "10f0cb05-dcf8-4eb1-a478-33785d531aa7",
        "questions": "Which NANDA-I diagnosis includes characteristics such as anxiety, questioning the meaning of life, and insomnia?",
        "answers": "Spiritual Distress",
        "context": "# Diagnoses  \n\n\\begin{table}[h!]\n\\centering\n\\caption{Common NANDA-I Nursing Diagnoses Related to Spiritual Health}\n\\begin{tabular}{|p{4cm}|p{6cm}|p{7cm}|}\n \nNANDA-I Diagnosis & Definition & Defining Characteristics \\\\  \n\nReadiness for Enhanced Spiritual Well-Being \n& A pattern of experiencing and integrating meaning and purpose in life through connectedness with self, others, art, music, literature, nature, and/or a power greater than oneself, which can be strengthened\n& \n    \\item Connections to Self\n    \\item Connections with Others\n    \\item Connections with Art, Music, Literature, and Nature\n    \\item Connections with Power Greater than Self\n    \\begin{itemize}\n        \\item Expresses desire to enhance participation in religious activity\n        \\item Expresses desire to enhance prayerfulness\n    \n\\end{itemize} \\\\  \n\nImpaired Religiosity \n& Impaired ability to exercise reliance on beliefs and/or participate in rituals of a particular faith tradition \n& \n    \\item Desires to reconnect with previous belief pattern\n    \\item Has difficulty adhering to prescribed religious beliefs and/or rituals\n    \\item Distresses about separation from the faith community\n \\\\  \n\nSpiritual Distress \n& A state of suffering related to the impaired ability to experience meaning in life through connections with self, others, the world, or a superior being\n& \n    \\item Anxiety\n    \\item Crying\n    \\item Fatigue\n    \\item Fear\n    \\item Insomnia\n    \\item Questioning identity\n    \\item Questioning meaning of life\n    \\item Questioning meaning of suffering\n \\\\  \n\n\\end{tabular}\n\\end{table}\n\n\n# Sample Nursing Diagnosis Statements  \n\n# Readiness for Enhanced Spiritual Well-Being  \n\nMany people experienced feelings of isolation as they sheltered at home during the COVID-19 pandemic. A sample PES statement for this shared experience is, \"Readiness for Enhanced Spiritual Well-Being as evidenced by expressed desire to enhance time outdoors.\" The nurse could encourage patients to visit local parks and walk outdoors while wearing a mask and maintaining social distancing.  \n\n> ![](images/752479bdb28ccbc0397fc551d39c43031a5ab65440a571bf24202c440ce91f03.jpg)  \nRecall that when a PES statement is created for a health promotion diagnosis, the defining characteristics are provided as evidence of the desire of the patient to improve their current health status.  \n\n# Impaired Religiosity  \n\nHospitalized patients may be unable to attend religious services they are accustomed to attending. A sample PES statement is, \"Impaired Religiosity related to environmental barriers to practicing religion as evidenced by difficulty adhering to prescribed religious beliefs.\" The nurse could contact the patient's pastor to arrange a visitor or determine if services can be viewed online.  \n\n# Spiritual Distress  \n\nEvents that place patient populations at risk for developing spiritual distress include birth of a child, death of a significant other, exposure to death, a significant life transition, severe illness or injury, exposure to natural disaster, racial conflict, or an unexpected event.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "table",
        "evidence_context": "Spiritual Distress & A state of suffering related to the impaired ability to experience meaning in life through connections with self, others, the world, or a superior being & \n     Anxiety\n     Crying\n     Fatigue\n     Fear\n     Insomnia\n     Questioning identity\n     Questioning meaning of life\n     Questioning meaning of suffering",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/med-76735.pdf_625",
        "ID": "10f143e2-1abc-418e-8785-b14453158ee1",
        "questions": "What are some events that can place patient populations at risk for developing spiritual distress according to the document?",
        "answers": "[\"birth of a child\",\"death of a significant other\",\"exposure to death\",\"a significant life transition\",\"severe illness or injury\",\"exposure to natural disaster\",\"racial conflict\",\"an unexpected event\"]",
        "context": "# Diagnoses  \n\n\\begin{table}[h!]\n\\centering\n\\caption{Common NANDA-I Nursing Diagnoses Related to Spiritual Health}\n\\begin{tabular}{|p{4cm}|p{6cm}|p{7cm}|}\n \nNANDA-I Diagnosis & Definition & Defining Characteristics \\\\  \n\nReadiness for Enhanced Spiritual Well-Being \n& A pattern of experiencing and integrating meaning and purpose in life through connectedness with self, others, art, music, literature, nature, and/or a power greater than oneself, which can be strengthened\n& \n    \\item Connections to Self\n    \\item Connections with Others\n    \\item Connections with Art, Music, Literature, and Nature\n    \\item Connections with Power Greater than Self\n    \\begin{itemize}\n        \\item Expresses desire to enhance participation in religious activity\n        \\item Expresses desire to enhance prayerfulness\n    \n\\end{itemize} \\\\  \n\nImpaired Religiosity \n& Impaired ability to exercise reliance on beliefs and/or participate in rituals of a particular faith tradition \n& \n    \\item Desires to reconnect with previous belief pattern\n    \\item Has difficulty adhering to prescribed religious beliefs and/or rituals\n    \\item Distresses about separation from the faith community\n \\\\  \n\nSpiritual Distress \n& A state of suffering related to the impaired ability to experience meaning in life through connections with self, others, the world, or a superior being\n& \n    \\item Anxiety\n    \\item Crying\n    \\item Fatigue\n    \\item Fear\n    \\item Insomnia\n    \\item Questioning identity\n    \\item Questioning meaning of life\n    \\item Questioning meaning of suffering\n \\\\  \n\n\\end{tabular}\n\\end{table}\n\n\n# Sample Nursing Diagnosis Statements  \n\n# Readiness for Enhanced Spiritual Well-Being  \n\nMany people experienced feelings of isolation as they sheltered at home during the COVID-19 pandemic. A sample PES statement for this shared experience is, \"Readiness for Enhanced Spiritual Well-Being as evidenced by expressed desire to enhance time outdoors.\" The nurse could encourage patients to visit local parks and walk outdoors while wearing a mask and maintaining social distancing.  \n\n> ![](images/752479bdb28ccbc0397fc551d39c43031a5ab65440a571bf24202c440ce91f03.jpg)  \nRecall that when a PES statement is created for a health promotion diagnosis, the defining characteristics are provided as evidence of the desire of the patient to improve their current health status.  \n\n# Impaired Religiosity  \n\nHospitalized patients may be unable to attend religious services they are accustomed to attending. A sample PES statement is, \"Impaired Religiosity related to environmental barriers to practicing religion as evidenced by difficulty adhering to prescribed religious beliefs.\" The nurse could contact the patient's pastor to arrange a visitor or determine if services can be viewed online.  \n\n# Spiritual Distress  \n\nEvents that place patient populations at risk for developing spiritual distress include birth of a child, death of a significant other, exposure to death, a significant life transition, severe illness or injury, exposure to natural disaster, racial conflict, or an unexpected event.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Events that place patient populations at risk for developing spiritual distress include birth of a child, death of a significant other, exposure to death, a significant life transition, severe illness or injury, exposure to natural disaster, racial conflict, or an unexpected event.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Triangulated_Categories_of_Mixed_Motives_(Denis-Charles_Cisinski_,_Fre\u0301de\u0301ric_De\u0301glise)_(Z-Library).pdf_145",
        "ID": "10fc9eee-0a17-47f7-aa5f-24b6de6fec4b",
        "questions": "What is the left adjoint functor to the functor $u^*$ in the context of any functor between small categories $u:I\\longrightarrow J$?",
        "answers": "$\\mathbf{L}u_{\\sharp}$",
        "context": "(induced by the composition with $u$), and for any morphism of functors\n\n![](images/1.png)\n\none has a morphism of functors.\n\n![](images/2.png)\n\nMoreover, the prederivator $\\mathbf{Ho}(\\mathcal{V})$ is then a Grothendieck derivator; see [Ciso3 Thm.6.i1]. This means in particular that, for any functor between small categories $u:I\\longrightarrow J$, the functor $u^{*}$ has a left adjoint\n\n$$\n\\mathbf{L}u_{\\sharp}:\\mathbf{H o}(\\mathcal{V})(I)\\longrightarrow\\mathbf{H o}(\\mathcal{V})(J)\n$$  \n\nas well as a right adjoint\n\n$$\n\\mathbf{R}u_{*}:\\mathbf{Hom}(\\mathcal{V})(I)\\longrightarrow\\mathbf{Hom}(\\mathcal{V})(J)\n$$  \n\n(in the case where $J\\,=\\,e$ is the terminal category, $\\mathbf{L}\\boldsymbol{u}_{\\sharp}$ is the homotopy colimit functor, while $\\mathbf{R}u_{*}$ is the homotopy limit functor).\n\nIf $\\mathcal{V}$ and $\\mathcal{V}^{\\prime}$ are two model categories, a morphism of derivators\n\n$$\n\\Phi:\\mathbf{H o}(\\mathcal{V})\\longrightarrow\\mathbf{H o}(\\mathcal{V}^{\\prime})\n$$  \n\nis simply a morphism of 2-functors, that is, the data of functors\n\n$$\n\\Phi_{I}:\\mathbf{H o}(\\mathcal{V})(I)\\longrightarrow\\mathbf{H o}(\\mathcal{V}^{\\prime})(I)\n$$  \n\ntogether with coherent isomorphisms\n\n$$\nu^{*}(\\Phi_{J}(F))\\simeq\\Phi_{I}(u^{*}(F))\n$$  \n\nfor any functor $u:I\\longrightarrow J$ and any presheaf $F$ on $J$ with values in $\\mathcal{V}$ (see [Ciso3 p.2io] for a precise definition).\n\nSuch a morphism $\\Phi$ is said to be continuous if, for any functor $u:I\\longrightarrow J$ and any object $F$ of $\\mathbf{No}(\\mathcal{V})(I)$, the canonical map\n\n$$\n\\Phi_{J}\\,{\\bf R}u_{*}(F)\\longrightarrow{\\bf R}u_{*}\\,\\Phi_{I}(F)\n$$  \n\nis an isomorphism. One can check that a morphism of derivators $\\Phi$ is continuous if and only if it commutes with homotopy limits (i.e., if and only if the maps (3.2.13.4) are isomorphisms in the case where $J=e$ is the terminal category); see [Ciso8].",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "the functor $u^{*}$ has a left adjoint $$\\mathbf{L}u_{\\sharp}:\\mathbf{H o}(\\mathcal{V})(I)\\longrightarrow\\mathbf{H o}(\\mathcal{V})(J)$$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Triangulated_Categories_of_Mixed_Motives_(Denis-Charles_Cisinski_,_Fre\u0301de\u0301ric_De\u0301glise)_(Z-Library).pdf_145",
        "ID": "10fcbacf-84bf-4051-8aff-0f904cecbd32",
        "questions": "What term is used to describe a morphism of derivators that commutes with homotopy limits?",
        "answers": "continuous",
        "context": "(induced by the composition with $u$), and for any morphism of functors\n\n![](images/1.png)\n\none has a morphism of functors.\n\n![](images/2.png)\n\nMoreover, the prederivator $\\mathbf{Ho}(\\mathcal{V})$ is then a Grothendieck derivator; see [Ciso3 Thm.6.i1]. This means in particular that, for any functor between small categories $u:I\\longrightarrow J$, the functor $u^{*}$ has a left adjoint\n\n$$\n\\mathbf{L}u_{\\sharp}:\\mathbf{H o}(\\mathcal{V})(I)\\longrightarrow\\mathbf{H o}(\\mathcal{V})(J)\n$$  \n\nas well as a right adjoint\n\n$$\n\\mathbf{R}u_{*}:\\mathbf{Hom}(\\mathcal{V})(I)\\longrightarrow\\mathbf{Hom}(\\mathcal{V})(J)\n$$  \n\n(in the case where $J\\,=\\,e$ is the terminal category, $\\mathbf{L}\\boldsymbol{u}_{\\sharp}$ is the homotopy colimit functor, while $\\mathbf{R}u_{*}$ is the homotopy limit functor).\n\nIf $\\mathcal{V}$ and $\\mathcal{V}^{\\prime}$ are two model categories, a morphism of derivators\n\n$$\n\\Phi:\\mathbf{H o}(\\mathcal{V})\\longrightarrow\\mathbf{H o}(\\mathcal{V}^{\\prime})\n$$  \n\nis simply a morphism of 2-functors, that is, the data of functors\n\n$$\n\\Phi_{I}:\\mathbf{H o}(\\mathcal{V})(I)\\longrightarrow\\mathbf{H o}(\\mathcal{V}^{\\prime})(I)\n$$  \n\ntogether with coherent isomorphisms\n\n$$\nu^{*}(\\Phi_{J}(F))\\simeq\\Phi_{I}(u^{*}(F))\n$$  \n\nfor any functor $u:I\\longrightarrow J$ and any presheaf $F$ on $J$ with values in $\\mathcal{V}$ (see [Ciso3 p.2io] for a precise definition).\n\nSuch a morphism $\\Phi$ is said to be continuous if, for any functor $u:I\\longrightarrow J$ and any object $F$ of $\\mathbf{No}(\\mathcal{V})(I)$, the canonical map\n\n$$\n\\Phi_{J}\\,{\\bf R}u_{*}(F)\\longrightarrow{\\bf R}u_{*}\\,\\Phi_{I}(F)\n$$  \n\nis an isomorphism. One can check that a morphism of derivators $\\Phi$ is continuous if and only if it commutes with homotopy limits (i.e., if and only if the maps (3.2.13.4) are isomorphisms in the case where $J=e$ is the terminal category); see [Ciso8].",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "One can check that a morphism of derivators $\\Phi$ is continuous if and only if it commutes with homotopy limits",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Triangulated_Categories_of_Mixed_Motives_(Denis-Charles_Cisinski_,_Fre\u0301de\u0301ric_De\u0301glise)_(Z-Library).pdf_145",
        "ID": "10fe6843-9f0f-47a7-a424-24067c637708",
        "questions": "For the derivator $\\mathbf{Ho}(\\mathcal{V})$, what does the functor $\\mathbf{R}u_{*}$ represent when $J$ is the terminal category?",
        "answers": "homotopy limit functor",
        "context": "(induced by the composition with $u$), and for any morphism of functors\n\n![](images/1.png)\n\none has a morphism of functors.\n\n![](images/2.png)\n\nMoreover, the prederivator $\\mathbf{Ho}(\\mathcal{V})$ is then a Grothendieck derivator; see [Ciso3 Thm.6.i1]. This means in particular that, for any functor between small categories $u:I\\longrightarrow J$, the functor $u^{*}$ has a left adjoint\n\n$$\n\\mathbf{L}u_{\\sharp}:\\mathbf{H o}(\\mathcal{V})(I)\\longrightarrow\\mathbf{H o}(\\mathcal{V})(J)\n$$  \n\nas well as a right adjoint\n\n$$\n\\mathbf{R}u_{*}:\\mathbf{Hom}(\\mathcal{V})(I)\\longrightarrow\\mathbf{Hom}(\\mathcal{V})(J)\n$$  \n\n(in the case where $J\\,=\\,e$ is the terminal category, $\\mathbf{L}\\boldsymbol{u}_{\\sharp}$ is the homotopy colimit functor, while $\\mathbf{R}u_{*}$ is the homotopy limit functor).\n\nIf $\\mathcal{V}$ and $\\mathcal{V}^{\\prime}$ are two model categories, a morphism of derivators\n\n$$\n\\Phi:\\mathbf{H o}(\\mathcal{V})\\longrightarrow\\mathbf{H o}(\\mathcal{V}^{\\prime})\n$$  \n\nis simply a morphism of 2-functors, that is, the data of functors\n\n$$\n\\Phi_{I}:\\mathbf{H o}(\\mathcal{V})(I)\\longrightarrow\\mathbf{H o}(\\mathcal{V}^{\\prime})(I)\n$$  \n\ntogether with coherent isomorphisms\n\n$$\nu^{*}(\\Phi_{J}(F))\\simeq\\Phi_{I}(u^{*}(F))\n$$  \n\nfor any functor $u:I\\longrightarrow J$ and any presheaf $F$ on $J$ with values in $\\mathcal{V}$ (see [Ciso3 p.2io] for a precise definition).\n\nSuch a morphism $\\Phi$ is said to be continuous if, for any functor $u:I\\longrightarrow J$ and any object $F$ of $\\mathbf{No}(\\mathcal{V})(I)$, the canonical map\n\n$$\n\\Phi_{J}\\,{\\bf R}u_{*}(F)\\longrightarrow{\\bf R}u_{*}\\,\\Phi_{I}(F)\n$$  \n\nis an isomorphism. One can check that a morphism of derivators $\\Phi$ is continuous if and only if it commutes with homotopy limits (i.e., if and only if the maps (3.2.13.4) are isomorphisms in the case where $J=e$ is the terminal category); see [Ciso8].",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "$\\mathbf{R}u_{*}$ is the homotopy limit functor",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Triangulated_Categories_of_Mixed_Motives_(Denis-Charles_Cisinski_,_Fre\u0301de\u0301ric_De\u0301glise)_(Z-Library).pdf_145",
        "ID": "10ff4de8-e6ff-43b5-b36c-ddb8beabdee5",
        "questions": "What is the definition equation for the left adjoint of the functor $u^{*}$?",
        "answers": "$\\mathbf{L}u_{\\sharp}:\\mathbf{H o}(\\mathcal{V})(I)\\longrightarrow\\mathbf{H o}(\\mathcal{V})(J)$",
        "context": "(induced by the composition with $u$), and for any morphism of functors\n\n![](images/1.png)\n\none has a morphism of functors.\n\n![](images/2.png)\n\nMoreover, the prederivator $\\mathbf{Ho}(\\mathcal{V})$ is then a Grothendieck derivator; see [Ciso3 Thm.6.i1]. This means in particular that, for any functor between small categories $u:I\\longrightarrow J$, the functor $u^{*}$ has a left adjoint\n\n$$\n\\mathbf{L}u_{\\sharp}:\\mathbf{H o}(\\mathcal{V})(I)\\longrightarrow\\mathbf{H o}(\\mathcal{V})(J)\n$$  \n\nas well as a right adjoint\n\n$$\n\\mathbf{R}u_{*}:\\mathbf{Hom}(\\mathcal{V})(I)\\longrightarrow\\mathbf{Hom}(\\mathcal{V})(J)\n$$  \n\n(in the case where $J\\,=\\,e$ is the terminal category, $\\mathbf{L}\\boldsymbol{u}_{\\sharp}$ is the homotopy colimit functor, while $\\mathbf{R}u_{*}$ is the homotopy limit functor).\n\nIf $\\mathcal{V}$ and $\\mathcal{V}^{\\prime}$ are two model categories, a morphism of derivators\n\n$$\n\\Phi:\\mathbf{H o}(\\mathcal{V})\\longrightarrow\\mathbf{H o}(\\mathcal{V}^{\\prime})\n$$  \n\nis simply a morphism of 2-functors, that is, the data of functors\n\n$$\n\\Phi_{I}:\\mathbf{H o}(\\mathcal{V})(I)\\longrightarrow\\mathbf{H o}(\\mathcal{V}^{\\prime})(I)\n$$  \n\ntogether with coherent isomorphisms\n\n$$\nu^{*}(\\Phi_{J}(F))\\simeq\\Phi_{I}(u^{*}(F))\n$$  \n\nfor any functor $u:I\\longrightarrow J$ and any presheaf $F$ on $J$ with values in $\\mathcal{V}$ (see [Ciso3 p.2io] for a precise definition).\n\nSuch a morphism $\\Phi$ is said to be continuous if, for any functor $u:I\\longrightarrow J$ and any object $F$ of $\\mathbf{No}(\\mathcal{V})(I)$, the canonical map\n\n$$\n\\Phi_{J}\\,{\\bf R}u_{*}(F)\\longrightarrow{\\bf R}u_{*}\\,\\Phi_{I}(F)\n$$  \n\nis an isomorphism. One can check that a morphism of derivators $\\Phi$ is continuous if and only if it commutes with homotopy limits (i.e., if and only if the maps (3.2.13.4) are isomorphisms in the case where $J=e$ is the terminal category); see [Ciso8].",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "the functor $u^{*}$ has a left adjoint $\\mathbf{L}u_{\\sharp}:\\mathbf{H o}(\\mathcal{V})(I)\\longrightarrow\\mathbf{H o}(\\mathcal{V})(J)$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/Triangulated_Categories_of_Mixed_Motives_(Denis-Charles_Cisinski_,_Fre\u0301de\u0301ric_De\u0301glise)_(Z-Library).pdf_145",
        "ID": "1100e837-af2d-418f-a993-58c828e47422",
        "questions": "What is the right adjoint of $u^{*}$ in the case where $J$ is a terminal category?",
        "answers": "$\\mathbf{R}u_{*}:\\mathbf{Hom}(\\mathcal{V})(I)\\longrightarrow\\mathbf{Hom}(\\mathcal{V})(J)$",
        "context": "(induced by the composition with $u$), and for any morphism of functors\n\n![](images/1.png)\n\none has a morphism of functors.\n\n![](images/2.png)\n\nMoreover, the prederivator $\\mathbf{Ho}(\\mathcal{V})$ is then a Grothendieck derivator; see [Ciso3 Thm.6.i1]. This means in particular that, for any functor between small categories $u:I\\longrightarrow J$, the functor $u^{*}$ has a left adjoint\n\n$$\n\\mathbf{L}u_{\\sharp}:\\mathbf{H o}(\\mathcal{V})(I)\\longrightarrow\\mathbf{H o}(\\mathcal{V})(J)\n$$  \n\nas well as a right adjoint\n\n$$\n\\mathbf{R}u_{*}:\\mathbf{Hom}(\\mathcal{V})(I)\\longrightarrow\\mathbf{Hom}(\\mathcal{V})(J)\n$$  \n\n(in the case where $J\\,=\\,e$ is the terminal category, $\\mathbf{L}\\boldsymbol{u}_{\\sharp}$ is the homotopy colimit functor, while $\\mathbf{R}u_{*}$ is the homotopy limit functor).\n\nIf $\\mathcal{V}$ and $\\mathcal{V}^{\\prime}$ are two model categories, a morphism of derivators\n\n$$\n\\Phi:\\mathbf{H o}(\\mathcal{V})\\longrightarrow\\mathbf{H o}(\\mathcal{V}^{\\prime})\n$$  \n\nis simply a morphism of 2-functors, that is, the data of functors\n\n$$\n\\Phi_{I}:\\mathbf{H o}(\\mathcal{V})(I)\\longrightarrow\\mathbf{H o}(\\mathcal{V}^{\\prime})(I)\n$$  \n\ntogether with coherent isomorphisms\n\n$$\nu^{*}(\\Phi_{J}(F))\\simeq\\Phi_{I}(u^{*}(F))\n$$  \n\nfor any functor $u:I\\longrightarrow J$ and any presheaf $F$ on $J$ with values in $\\mathcal{V}$ (see [Ciso3 p.2io] for a precise definition).\n\nSuch a morphism $\\Phi$ is said to be continuous if, for any functor $u:I\\longrightarrow J$ and any object $F$ of $\\mathbf{No}(\\mathcal{V})(I)$, the canonical map\n\n$$\n\\Phi_{J}\\,{\\bf R}u_{*}(F)\\longrightarrow{\\bf R}u_{*}\\,\\Phi_{I}(F)\n$$  \n\nis an isomorphism. One can check that a morphism of derivators $\\Phi$ is continuous if and only if it commutes with homotopy limits (i.e., if and only if the maps (3.2.13.4) are isomorphisms in the case where $J=e$ is the terminal category); see [Ciso8].",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$\\mathbf{R}u_{*}:\\mathbf{Hom}(\\mathcal{V})(I)\\longrightarrow\\mathbf{Hom}(\\mathcal{V})(J)$ (in the case where $J\\,=\\,e$ is the terminal category, $\\mathbf{L}\\boldsymbol{u}_{\\sharp}$ is the homotopy colimit functor, while $\\mathbf{R}u_{*}$ is the homotopy limit functor).",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/Triangulated_Categories_of_Mixed_Motives_(Denis-Charles_Cisinski_,_Fre\u0301de\u0301ric_De\u0301glise)_(Z-Library).pdf_145",
        "ID": "11029ff4-9930-436a-b2ad-9dfb1f24f379",
        "questions": "Under what condition is a morphism of derivators $\\Phi$ said to be continuous?",
        "answers": "if and only if the maps (3.2.13.4) are isomorphisms in the case where $J=e$ is the terminal category",
        "context": "(induced by the composition with $u$), and for any morphism of functors\n\n![](images/1.png)\n\none has a morphism of functors.\n\n![](images/2.png)\n\nMoreover, the prederivator $\\mathbf{Ho}(\\mathcal{V})$ is then a Grothendieck derivator; see [Ciso3 Thm.6.i1]. This means in particular that, for any functor between small categories $u:I\\longrightarrow J$, the functor $u^{*}$ has a left adjoint\n\n$$\n\\mathbf{L}u_{\\sharp}:\\mathbf{H o}(\\mathcal{V})(I)\\longrightarrow\\mathbf{H o}(\\mathcal{V})(J)\n$$  \n\nas well as a right adjoint\n\n$$\n\\mathbf{R}u_{*}:\\mathbf{Hom}(\\mathcal{V})(I)\\longrightarrow\\mathbf{Hom}(\\mathcal{V})(J)\n$$  \n\n(in the case where $J\\,=\\,e$ is the terminal category, $\\mathbf{L}\\boldsymbol{u}_{\\sharp}$ is the homotopy colimit functor, while $\\mathbf{R}u_{*}$ is the homotopy limit functor).\n\nIf $\\mathcal{V}$ and $\\mathcal{V}^{\\prime}$ are two model categories, a morphism of derivators\n\n$$\n\\Phi:\\mathbf{H o}(\\mathcal{V})\\longrightarrow\\mathbf{H o}(\\mathcal{V}^{\\prime})\n$$  \n\nis simply a morphism of 2-functors, that is, the data of functors\n\n$$\n\\Phi_{I}:\\mathbf{H o}(\\mathcal{V})(I)\\longrightarrow\\mathbf{H o}(\\mathcal{V}^{\\prime})(I)\n$$  \n\ntogether with coherent isomorphisms\n\n$$\nu^{*}(\\Phi_{J}(F))\\simeq\\Phi_{I}(u^{*}(F))\n$$  \n\nfor any functor $u:I\\longrightarrow J$ and any presheaf $F$ on $J$ with values in $\\mathcal{V}$ (see [Ciso3 p.2io] for a precise definition).\n\nSuch a morphism $\\Phi$ is said to be continuous if, for any functor $u:I\\longrightarrow J$ and any object $F$ of $\\mathbf{No}(\\mathcal{V})(I)$, the canonical map\n\n$$\n\\Phi_{J}\\,{\\bf R}u_{*}(F)\\longrightarrow{\\bf R}u_{*}\\,\\Phi_{I}(F)\n$$  \n\nis an isomorphism. One can check that a morphism of derivators $\\Phi$ is continuous if and only if it commutes with homotopy limits (i.e., if and only if the maps (3.2.13.4) are isomorphisms in the case where $J=e$ is the terminal category); see [Ciso8].",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "One can check that a morphism of derivators $\\Phi$ is continuous if and only if it commutes with homotopy limits (i.e., if and only if the maps (3.2.13.4) are isomorphisms in the case where $J=e$ is the terminal category); see [Ciso8].",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/(Graduate_Studies_in_Mathematics,181)_Leoni,_Giovanni_-_A_first_course_in_Sobolev_spaces_(2017,_American_Mathematical_Society).pdf_509",
        "ID": "111004d0-3dd0-463c-bbbd-cd207c9814b7",
        "questions": "What theorem implies the isoperimetric inequality according to the document?",
        "answers": "The Sobolev-Gagliardo-Nirenberg embedding theorem in $BV$",
        "context": "and so\n\n$$\n\\begin{array}{r l r}{{\\int_{B_{R}}|u-u_{B_{R}}|^{1*}\\,d x=\\Big(1-\\frac{\\mathcal{L}^{N}(B_{R}\\cap E)}{\\mathcal{L}^{N}(B_{R})}\\Big)^{1*}\\mathcal{L}^{N}(B_{R}\\cap E)}}\\\\ &{}&{\\quad\\quad+\\left(\\frac{\\mathcal{L}^{N}(B_{R}\\cap E)}{\\mathcal{L}^{N}(B_{R})}\\right)^{1*}\\mathcal{L}^{N}(B_{R}\\setminus E).}\\end{array}\n$$\n\nIf ${\\mathcal{L}}^{N}(B_{R}\\cap E)\\leq{\\mathcal{L}}^{N}(B_{R}\\setminus E)$ , then\n\n$$\n\\begin{array}{r l}{{\\left(\\int_{B_{R}}|u-u_{B_{R}}|^{1*}\\,d x\\right)^{1/1^{*}}\\ge\\cfrac{\\mathcal{L}^{N}(B_{R}\\setminus E)}{\\mathcal{L}^{N}(B_{R})}(\\mathcal{L}^{N}(B_{R}\\cap E))^{1/1^{*}}}}\\\\ &{\\ge\\frac{1}{2}(\\mathcal{L}^{N}(B_{R}\\cap E))^{1/1^{*}}}\\\\ &{=\\frac{1}{2}\\operatorname*{min}\\{\\mathcal{L}^{N}(B_{R}\\cap E),\\mathcal{L}^{N}(B_{R}\\setminus E)\\}^{1/1^{*}}.}\\end{array}\n$$\n\nThe other case is analogous.\n\nBy applying Poincare's inequality for balls (see the previous exercise), we get that the left-hand side of the previous inequality is bounded from above by $c\\|D(\\chi_{E})\\|(B_{R})$ and so\n\n$$\n\\begin{array}{r l}{\\frac12\\operatorname*{min}\\{\\mathcal{L}^{N}(B_{R}\\cap E),\\mathcal{L}^{N}(B_{R}\\setminus E)\\}^{1/1^{*}}\\leq c\\|D(\\chi_{E})\\|(B_{R})}&{}\\\\ {\\leq c\\|D(\\chi_{E})\\|(\\mathbb{R}^{N}).}\\end{array}\n$$\n\nHence, the claim is proved.\n\nBy letting $R\\to\\infty$ in the previous inequality and using Proposition B.9, it follows that either $E$ or $\\mathbb{R}^{N}\\setminus E$ has finite Lebesgue measure.\n\nThus, we have shown that the Sobolev-Gagliardo-Nirenberg embedding theorem in $BV$ implies the isoperimetric inequality. Next, we show that the opposite is also true.\n\nTheorem 14.45. Assume that the isoperimetric inequality (14.45) holds for all sets with finite perimeter. Then there exists a constant $c=c(N)>0$ such that\n\n$$\n\\|u\\|_{L^{1^{*}}({\\mathbb R}^{N})}\\leq c\\|D u\\|({\\mathbb R}^{N})\n$$\n\nfor all $u\\in BV(\\mathbb{R}^{N})$.\n\nProof. Assume first that $u\\geq0$ and that $u\\in C^{\\infty}(\\mathbb{R}^{N})\\cap W^{1,1}(\\mathbb{R}^{N})$. For $t\\in\\mathbb{R}$ , define $A_{t}:=\\{x\\in\\mathbb{R}^{N}:u(x)>t\\}$. Then by the coarea formula (14.42) and the isoperimetric inequality (14.45),\n\n$$\n\\int_{\\mathbb{R}^{N}}\\|\\nabla u\\|\\,d x=\\int_{0}^{\\infty}\\operatorname{P}(A_{t})\\,d t\\geq{\\frac{1}{c}}\\int_{0}^{\\infty}({\\mathcal{L}}^{N}(A_{t}))^{1/1^{*}}\\,d t.\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Thus, we have shown that the Sobolev-Gagliardo-Nirenberg embedding theorem in $BV$ implies the isoperimetric inequality.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/(Graduate_Studies_in_Mathematics,181)_Leoni,_Giovanni_-_A_first_course_in_Sobolev_spaces_(2017,_American_Mathematical_Society).pdf_509",
        "ID": "11168820-a76d-4b32-a121-78c70ce131dc",
        "questions": "What inequality does Theorem 14.45 guarantee for all functions in the space $BV(\\mathbb{R}^{N})$?",
        "answers": "\\|u\\|_{L^{1^{*}}({\\mathbb R}^{N})}\\leq c\\|D u\\|({\\mathbb R}^{N})",
        "context": "and so\n\n$$\n\\begin{array}{r l r}{{\\int_{B_{R}}|u-u_{B_{R}}|^{1*}\\,d x=\\Big(1-\\frac{\\mathcal{L}^{N}(B_{R}\\cap E)}{\\mathcal{L}^{N}(B_{R})}\\Big)^{1*}\\mathcal{L}^{N}(B_{R}\\cap E)}}\\\\ &{}&{\\quad\\quad+\\left(\\frac{\\mathcal{L}^{N}(B_{R}\\cap E)}{\\mathcal{L}^{N}(B_{R})}\\right)^{1*}\\mathcal{L}^{N}(B_{R}\\setminus E).}\\end{array}\n$$\n\nIf ${\\mathcal{L}}^{N}(B_{R}\\cap E)\\leq{\\mathcal{L}}^{N}(B_{R}\\setminus E)$ , then\n\n$$\n\\begin{array}{r l}{{\\left(\\int_{B_{R}}|u-u_{B_{R}}|^{1*}\\,d x\\right)^{1/1^{*}}\\ge\\cfrac{\\mathcal{L}^{N}(B_{R}\\setminus E)}{\\mathcal{L}^{N}(B_{R})}(\\mathcal{L}^{N}(B_{R}\\cap E))^{1/1^{*}}}}\\\\ &{\\ge\\frac{1}{2}(\\mathcal{L}^{N}(B_{R}\\cap E))^{1/1^{*}}}\\\\ &{=\\frac{1}{2}\\operatorname*{min}\\{\\mathcal{L}^{N}(B_{R}\\cap E),\\mathcal{L}^{N}(B_{R}\\setminus E)\\}^{1/1^{*}}.}\\end{array}\n$$\n\nThe other case is analogous.\n\nBy applying Poincare's inequality for balls (see the previous exercise), we get that the left-hand side of the previous inequality is bounded from above by $c\\|D(\\chi_{E})\\|(B_{R})$ and so\n\n$$\n\\begin{array}{r l}{\\frac12\\operatorname*{min}\\{\\mathcal{L}^{N}(B_{R}\\cap E),\\mathcal{L}^{N}(B_{R}\\setminus E)\\}^{1/1^{*}}\\leq c\\|D(\\chi_{E})\\|(B_{R})}&{}\\\\ {\\leq c\\|D(\\chi_{E})\\|(\\mathbb{R}^{N}).}\\end{array}\n$$\n\nHence, the claim is proved.\n\nBy letting $R\\to\\infty$ in the previous inequality and using Proposition B.9, it follows that either $E$ or $\\mathbb{R}^{N}\\setminus E$ has finite Lebesgue measure.\n\nThus, we have shown that the Sobolev-Gagliardo-Nirenberg embedding theorem in $BV$ implies the isoperimetric inequality. Next, we show that the opposite is also true.\n\nTheorem 14.45. Assume that the isoperimetric inequality (14.45) holds for all sets with finite perimeter. Then there exists a constant $c=c(N)>0$ such that\n\n$$\n\\|u\\|_{L^{1^{*}}({\\mathbb R}^{N})}\\leq c\\|D u\\|({\\mathbb R}^{N})\n$$\n\nfor all $u\\in BV(\\mathbb{R}^{N})$.\n\nProof. Assume first that $u\\geq0$ and that $u\\in C^{\\infty}(\\mathbb{R}^{N})\\cap W^{1,1}(\\mathbb{R}^{N})$. For $t\\in\\mathbb{R}$ , define $A_{t}:=\\{x\\in\\mathbb{R}^{N}:u(x)>t\\}$. Then by the coarea formula (14.42) and the isoperimetric inequality (14.45),\n\n$$\n\\int_{\\mathbb{R}^{N}}\\|\\nabla u\\|\\,d x=\\int_{0}^{\\infty}\\operatorname{P}(A_{t})\\,d t\\geq{\\frac{1}{c}}\\int_{0}^{\\infty}({\\mathcal{L}}^{N}(A_{t}))^{1/1^{*}}\\,d t.\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Equation",
        "evidence_source": "equation",
        "evidence_context": "Then there exists a constant $c=c(N)>0$ such that \\|u\\|_{L^{1^{*}}({\\mathbb R}^{N})}\\leq c\\|D u\\|({\\mathbb R}^{N}) for all $u\\in BV(\\mathbb{R}^{N})$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/(Graduate_Studies_in_Mathematics,181)_Leoni,_Giovanni_-_A_first_course_in_Sobolev_spaces_(2017,_American_Mathematical_Society).pdf_509",
        "ID": "1117bacb-6e88-418c-a99e-12fe095c2be6",
        "questions": "In the context of the document, when ${\\mathcal{L}}^{N}(B_{R}\\cap E) \\leq {\\mathcal{L}}^{N}(B_{R}\\setminus E)$, what can be deduced about the Lebesgue measure of sets $E$ or $\\mathbb{R}^{N}\\setminus E$ as $R\\to\\infty$?",
        "answers": "Either $E$ or $\\mathbb{R}^{N}\\setminus E$ has finite Lebesgue measure.",
        "context": "and so\n\n$$\n\\begin{array}{r l r}{{\\int_{B_{R}}|u-u_{B_{R}}|^{1*}\\,d x=\\Big(1-\\frac{\\mathcal{L}^{N}(B_{R}\\cap E)}{\\mathcal{L}^{N}(B_{R})}\\Big)^{1*}\\mathcal{L}^{N}(B_{R}\\cap E)}}\\\\ &{}&{\\quad\\quad+\\left(\\frac{\\mathcal{L}^{N}(B_{R}\\cap E)}{\\mathcal{L}^{N}(B_{R})}\\right)^{1*}\\mathcal{L}^{N}(B_{R}\\setminus E).}\\end{array}\n$$\n\nIf ${\\mathcal{L}}^{N}(B_{R}\\cap E)\\leq{\\mathcal{L}}^{N}(B_{R}\\setminus E)$ , then\n\n$$\n\\begin{array}{r l}{{\\left(\\int_{B_{R}}|u-u_{B_{R}}|^{1*}\\,d x\\right)^{1/1^{*}}\\ge\\cfrac{\\mathcal{L}^{N}(B_{R}\\setminus E)}{\\mathcal{L}^{N}(B_{R})}(\\mathcal{L}^{N}(B_{R}\\cap E))^{1/1^{*}}}}\\\\ &{\\ge\\frac{1}{2}(\\mathcal{L}^{N}(B_{R}\\cap E))^{1/1^{*}}}\\\\ &{=\\frac{1}{2}\\operatorname*{min}\\{\\mathcal{L}^{N}(B_{R}\\cap E),\\mathcal{L}^{N}(B_{R}\\setminus E)\\}^{1/1^{*}}.}\\end{array}\n$$\n\nThe other case is analogous.\n\nBy applying Poincare's inequality for balls (see the previous exercise), we get that the left-hand side of the previous inequality is bounded from above by $c\\|D(\\chi_{E})\\|(B_{R})$ and so\n\n$$\n\\begin{array}{r l}{\\frac12\\operatorname*{min}\\{\\mathcal{L}^{N}(B_{R}\\cap E),\\mathcal{L}^{N}(B_{R}\\setminus E)\\}^{1/1^{*}}\\leq c\\|D(\\chi_{E})\\|(B_{R})}&{}\\\\ {\\leq c\\|D(\\chi_{E})\\|(\\mathbb{R}^{N}).}\\end{array}\n$$\n\nHence, the claim is proved.\n\nBy letting $R\\to\\infty$ in the previous inequality and using Proposition B.9, it follows that either $E$ or $\\mathbb{R}^{N}\\setminus E$ has finite Lebesgue measure.\n\nThus, we have shown that the Sobolev-Gagliardo-Nirenberg embedding theorem in $BV$ implies the isoperimetric inequality. Next, we show that the opposite is also true.\n\nTheorem 14.45. Assume that the isoperimetric inequality (14.45) holds for all sets with finite perimeter. Then there exists a constant $c=c(N)>0$ such that\n\n$$\n\\|u\\|_{L^{1^{*}}({\\mathbb R}^{N})}\\leq c\\|D u\\|({\\mathbb R}^{N})\n$$\n\nfor all $u\\in BV(\\mathbb{R}^{N})$.\n\nProof. Assume first that $u\\geq0$ and that $u\\in C^{\\infty}(\\mathbb{R}^{N})\\cap W^{1,1}(\\mathbb{R}^{N})$. For $t\\in\\mathbb{R}$ , define $A_{t}:=\\{x\\in\\mathbb{R}^{N}:u(x)>t\\}$. Then by the coarea formula (14.42) and the isoperimetric inequality (14.45),\n\n$$\n\\int_{\\mathbb{R}^{N}}\\|\\nabla u\\|\\,d x=\\int_{0}^{\\infty}\\operatorname{P}(A_{t})\\,d t\\geq{\\frac{1}{c}}\\int_{0}^{\\infty}({\\mathcal{L}}^{N}(A_{t}))^{1/1^{*}}\\,d t.\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "By letting $R\\to\\infty$ in the previous inequality and using Proposition B.9, it follows that either $E$ or $\\mathbb{R}^{N}\\setminus E$ has finite Lebesgue measure.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/(Graduate_Studies_in_Mathematics,181)_Leoni,_Giovanni_-_A_first_course_in_Sobolev_spaces_(2017,_American_Mathematical_Society).pdf_509",
        "ID": "11192c5a-7120-478e-9a45-d8b8ea8605a6",
        "questions": "When ${\\mathcal{L}}^{N}(B_{R}\\cap E)\\leq{\\mathcal{L}}^{N}(B_{R}\\setminus E)$, what is the lower bound for the integral raised to the power of $1/1^{*}$ involving $u-u_{B_{R}}$ over $B_{R}$, based on Lebesgue measure properties?",
        "answers": "$\\cfrac{\\mathcal{L}^{N}(B_{R}\\setminus E)}{\\mathcal{L}^{N}(B_{R})}(\\mathcal{L}^{N}(B_{R}\\cap E))^{1/1^{*}}$",
        "context": "and so\n\n$$\n\\begin{array}{r l r}{{\\int_{B_{R}}|u-u_{B_{R}}|^{1*}\\,d x=\\Big(1-\\frac{\\mathcal{L}^{N}(B_{R}\\cap E)}{\\mathcal{L}^{N}(B_{R})}\\Big)^{1*}\\mathcal{L}^{N}(B_{R}\\cap E)}}\\\\ &{}&{\\quad\\quad+\\left(\\frac{\\mathcal{L}^{N}(B_{R}\\cap E)}{\\mathcal{L}^{N}(B_{R})}\\right)^{1*}\\mathcal{L}^{N}(B_{R}\\setminus E).}\\end{array}\n$$\n\nIf ${\\mathcal{L}}^{N}(B_{R}\\cap E)\\leq{\\mathcal{L}}^{N}(B_{R}\\setminus E)$ , then\n\n$$\n\\begin{array}{r l}{{\\left(\\int_{B_{R}}|u-u_{B_{R}}|^{1*}\\,d x\\right)^{1/1^{*}}\\ge\\cfrac{\\mathcal{L}^{N}(B_{R}\\setminus E)}{\\mathcal{L}^{N}(B_{R})}(\\mathcal{L}^{N}(B_{R}\\cap E))^{1/1^{*}}}}\\\\ &{\\ge\\frac{1}{2}(\\mathcal{L}^{N}(B_{R}\\cap E))^{1/1^{*}}}\\\\ &{=\\frac{1}{2}\\operatorname*{min}\\{\\mathcal{L}^{N}(B_{R}\\cap E),\\mathcal{L}^{N}(B_{R}\\setminus E)\\}^{1/1^{*}}.}\\end{array}\n$$\n\nThe other case is analogous.\n\nBy applying Poincare's inequality for balls (see the previous exercise), we get that the left-hand side of the previous inequality is bounded from above by $c\\|D(\\chi_{E})\\|(B_{R})$ and so\n\n$$\n\\begin{array}{r l}{\\frac12\\operatorname*{min}\\{\\mathcal{L}^{N}(B_{R}\\cap E),\\mathcal{L}^{N}(B_{R}\\setminus E)\\}^{1/1^{*}}\\leq c\\|D(\\chi_{E})\\|(B_{R})}&{}\\\\ {\\leq c\\|D(\\chi_{E})\\|(\\mathbb{R}^{N}).}\\end{array}\n$$\n\nHence, the claim is proved.\n\nBy letting $R\\to\\infty$ in the previous inequality and using Proposition B.9, it follows that either $E$ or $\\mathbb{R}^{N}\\setminus E$ has finite Lebesgue measure.\n\nThus, we have shown that the Sobolev-Gagliardo-Nirenberg embedding theorem in $BV$ implies the isoperimetric inequality. Next, we show that the opposite is also true.\n\nTheorem 14.45. Assume that the isoperimetric inequality (14.45) holds for all sets with finite perimeter. Then there exists a constant $c=c(N)>0$ such that\n\n$$\n\\|u\\|_{L^{1^{*}}({\\mathbb R}^{N})}\\leq c\\|D u\\|({\\mathbb R}^{N})\n$$\n\nfor all $u\\in BV(\\mathbb{R}^{N})$.\n\nProof. Assume first that $u\\geq0$ and that $u\\in C^{\\infty}(\\mathbb{R}^{N})\\cap W^{1,1}(\\mathbb{R}^{N})$. For $t\\in\\mathbb{R}$ , define $A_{t}:=\\{x\\in\\mathbb{R}^{N}:u(x)>t\\}$. Then by the coarea formula (14.42) and the isoperimetric inequality (14.45),\n\n$$\n\\int_{\\mathbb{R}^{N}}\\|\\nabla u\\|\\,d x=\\int_{0}^{\\infty}\\operatorname{P}(A_{t})\\,d t\\geq{\\frac{1}{c}}\\int_{0}^{\\infty}({\\mathcal{L}}^{N}(A_{t}))^{1/1^{*}}\\,d t.\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "${\\left(\\int_{B_{R}}|u-u_{B_{R}}|^{1*}\\,d x\right)^{1/1^{*}}\\ge\\cfrac{\\mathcal{L}^{N}(B_{R}\\setminus E)}{\\mathcal{L}^{N}(B_{R})}(\\mathcal{L}^{N}(B_{R}\\cap E))^{1/1^{*}}}}",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/(Graduate_Studies_in_Mathematics,181)_Leoni,_Giovanni_-_A_first_course_in_Sobolev_spaces_(2017,_American_Mathematical_Society).pdf_509",
        "ID": "111f8adc-ef95-4b05-a507-509e35805023",
        "questions": "What inequality does Poincare's inequality imply for the minimum of the Lebesgue measures of $B_{R}\\cap E$ and $B_{R}\\setminus E$ in relation to $c||D(\\chi_{E})||(B_{R})$?",
        "answers": "$\\frac12\\operatorname*{min}\\{\\mathcal{L}^{N}(B_{R}\\cap E),\\mathcal{L}^{N}(B_{R}\\setminus E)\\}^{1/1^{*}}\\leq c\\|D(\\chi_{E})\\|(B_{R})$",
        "context": "and so\n\n$$\n\\begin{array}{r l r}{{\\int_{B_{R}}|u-u_{B_{R}}|^{1*}\\,d x=\\Big(1-\\frac{\\mathcal{L}^{N}(B_{R}\\cap E)}{\\mathcal{L}^{N}(B_{R})}\\Big)^{1*}\\mathcal{L}^{N}(B_{R}\\cap E)}}\\\\ &{}&{\\quad\\quad+\\left(\\frac{\\mathcal{L}^{N}(B_{R}\\cap E)}{\\mathcal{L}^{N}(B_{R})}\\right)^{1*}\\mathcal{L}^{N}(B_{R}\\setminus E).}\\end{array}\n$$\n\nIf ${\\mathcal{L}}^{N}(B_{R}\\cap E)\\leq{\\mathcal{L}}^{N}(B_{R}\\setminus E)$ , then\n\n$$\n\\begin{array}{r l}{{\\left(\\int_{B_{R}}|u-u_{B_{R}}|^{1*}\\,d x\\right)^{1/1^{*}}\\ge\\cfrac{\\mathcal{L}^{N}(B_{R}\\setminus E)}{\\mathcal{L}^{N}(B_{R})}(\\mathcal{L}^{N}(B_{R}\\cap E))^{1/1^{*}}}}\\\\ &{\\ge\\frac{1}{2}(\\mathcal{L}^{N}(B_{R}\\cap E))^{1/1^{*}}}\\\\ &{=\\frac{1}{2}\\operatorname*{min}\\{\\mathcal{L}^{N}(B_{R}\\cap E),\\mathcal{L}^{N}(B_{R}\\setminus E)\\}^{1/1^{*}}.}\\end{array}\n$$\n\nThe other case is analogous.\n\nBy applying Poincare's inequality for balls (see the previous exercise), we get that the left-hand side of the previous inequality is bounded from above by $c\\|D(\\chi_{E})\\|(B_{R})$ and so\n\n$$\n\\begin{array}{r l}{\\frac12\\operatorname*{min}\\{\\mathcal{L}^{N}(B_{R}\\cap E),\\mathcal{L}^{N}(B_{R}\\setminus E)\\}^{1/1^{*}}\\leq c\\|D(\\chi_{E})\\|(B_{R})}&{}\\\\ {\\leq c\\|D(\\chi_{E})\\|(\\mathbb{R}^{N}).}\\end{array}\n$$\n\nHence, the claim is proved.\n\nBy letting $R\\to\\infty$ in the previous inequality and using Proposition B.9, it follows that either $E$ or $\\mathbb{R}^{N}\\setminus E$ has finite Lebesgue measure.\n\nThus, we have shown that the Sobolev-Gagliardo-Nirenberg embedding theorem in $BV$ implies the isoperimetric inequality. Next, we show that the opposite is also true.\n\nTheorem 14.45. Assume that the isoperimetric inequality (14.45) holds for all sets with finite perimeter. Then there exists a constant $c=c(N)>0$ such that\n\n$$\n\\|u\\|_{L^{1^{*}}({\\mathbb R}^{N})}\\leq c\\|D u\\|({\\mathbb R}^{N})\n$$\n\nfor all $u\\in BV(\\mathbb{R}^{N})$.\n\nProof. Assume first that $u\\geq0$ and that $u\\in C^{\\infty}(\\mathbb{R}^{N})\\cap W^{1,1}(\\mathbb{R}^{N})$. For $t\\in\\mathbb{R}$ , define $A_{t}:=\\{x\\in\\mathbb{R}^{N}:u(x)>t\\}$. Then by the coarea formula (14.42) and the isoperimetric inequality (14.45),\n\n$$\n\\int_{\\mathbb{R}^{N}}\\|\\nabla u\\|\\,d x=\\int_{0}^{\\infty}\\operatorname{P}(A_{t})\\,d t\\geq{\\frac{1}{c}}\\int_{0}^{\\infty}({\\mathcal{L}}^{N}(A_{t}))^{1/1^{*}}\\,d t.\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$\\frac12\\operatorname*{min}\\{\\mathcal{L}^{N}(B_{R}\\cap E),\\mathcal{L}^{N}(B_{R}\\setminus E)\\}^{1/1^{*}}\\leq c\\|D(\\chi_{E})\\|(B_{R})$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/(Graduate_Studies_in_Mathematics,181)_Leoni,_Giovanni_-_A_first_course_in_Sobolev_spaces_(2017,_American_Mathematical_Society).pdf_509",
        "ID": "1122da51-f90c-41ce-9c4c-cadbf2f1553b",
        "questions": "According to Theorem 14.45, what condition involving the $L^{1^{*}}$ norm and a constant $c>0$ is true for all functions in $BV(\\mathbb{R}^{N})$?",
        "answers": "$\\|u\\|_{L^{1^{*}}({\\mathbb R}^{N})}\\leq c\\|D u\\|({\\mathbb R}^{N})$",
        "context": "and so\n\n$$\n\\begin{array}{r l r}{{\\int_{B_{R}}|u-u_{B_{R}}|^{1*}\\,d x=\\Big(1-\\frac{\\mathcal{L}^{N}(B_{R}\\cap E)}{\\mathcal{L}^{N}(B_{R})}\\Big)^{1*}\\mathcal{L}^{N}(B_{R}\\cap E)}}\\\\ &{}&{\\quad\\quad+\\left(\\frac{\\mathcal{L}^{N}(B_{R}\\cap E)}{\\mathcal{L}^{N}(B_{R})}\\right)^{1*}\\mathcal{L}^{N}(B_{R}\\setminus E).}\\end{array}\n$$\n\nIf ${\\mathcal{L}}^{N}(B_{R}\\cap E)\\leq{\\mathcal{L}}^{N}(B_{R}\\setminus E)$ , then\n\n$$\n\\begin{array}{r l}{{\\left(\\int_{B_{R}}|u-u_{B_{R}}|^{1*}\\,d x\\right)^{1/1^{*}}\\ge\\cfrac{\\mathcal{L}^{N}(B_{R}\\setminus E)}{\\mathcal{L}^{N}(B_{R})}(\\mathcal{L}^{N}(B_{R}\\cap E))^{1/1^{*}}}}\\\\ &{\\ge\\frac{1}{2}(\\mathcal{L}^{N}(B_{R}\\cap E))^{1/1^{*}}}\\\\ &{=\\frac{1}{2}\\operatorname*{min}\\{\\mathcal{L}^{N}(B_{R}\\cap E),\\mathcal{L}^{N}(B_{R}\\setminus E)\\}^{1/1^{*}}.}\\end{array}\n$$\n\nThe other case is analogous.\n\nBy applying Poincare's inequality for balls (see the previous exercise), we get that the left-hand side of the previous inequality is bounded from above by $c\\|D(\\chi_{E})\\|(B_{R})$ and so\n\n$$\n\\begin{array}{r l}{\\frac12\\operatorname*{min}\\{\\mathcal{L}^{N}(B_{R}\\cap E),\\mathcal{L}^{N}(B_{R}\\setminus E)\\}^{1/1^{*}}\\leq c\\|D(\\chi_{E})\\|(B_{R})}&{}\\\\ {\\leq c\\|D(\\chi_{E})\\|(\\mathbb{R}^{N}).}\\end{array}\n$$\n\nHence, the claim is proved.\n\nBy letting $R\\to\\infty$ in the previous inequality and using Proposition B.9, it follows that either $E$ or $\\mathbb{R}^{N}\\setminus E$ has finite Lebesgue measure.\n\nThus, we have shown that the Sobolev-Gagliardo-Nirenberg embedding theorem in $BV$ implies the isoperimetric inequality. Next, we show that the opposite is also true.\n\nTheorem 14.45. Assume that the isoperimetric inequality (14.45) holds for all sets with finite perimeter. Then there exists a constant $c=c(N)>0$ such that\n\n$$\n\\|u\\|_{L^{1^{*}}({\\mathbb R}^{N})}\\leq c\\|D u\\|({\\mathbb R}^{N})\n$$\n\nfor all $u\\in BV(\\mathbb{R}^{N})$.\n\nProof. Assume first that $u\\geq0$ and that $u\\in C^{\\infty}(\\mathbb{R}^{N})\\cap W^{1,1}(\\mathbb{R}^{N})$. For $t\\in\\mathbb{R}$ , define $A_{t}:=\\{x\\in\\mathbb{R}^{N}:u(x)>t\\}$. Then by the coarea formula (14.42) and the isoperimetric inequality (14.45),\n\n$$\n\\int_{\\mathbb{R}^{N}}\\|\\nabla u\\|\\,d x=\\int_{0}^{\\infty}\\operatorname{P}(A_{t})\\,d t\\geq{\\frac{1}{c}}\\int_{0}^{\\infty}({\\mathcal{L}}^{N}(A_{t}))^{1/1^{*}}\\,d t.\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$\\|u\\|_{L^{1^{*}}({\\mathbb R}^{N})}\\leq c\\|D u\\|({\\mathbb R}^{N})$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/textbook_needrop_en_1514",
        "ID": "11235205-3b9f-4f0d-9c01-75d8c3d199f2",
        "questions": "What is the formula for the symplectic pairing e(x,y) in terms of the sign function and the area ratios?",
        "answers": "e(x,y)=\\operatorname{sgn}(x,y)\\cdot{\\frac{a(\\mathbb{Z}x+\\mathbb{Z}y)}{a(L)}}",
        "context": "Observe that  $e:L\\times L\\times\\mathbb{Z}$   defines by reduction modulo  $m$  a symplectic pairing  $e_{m}:L/m L\\times L/m L\\to\\mathbb{Z}/m$  , and for  $m$  dividing  $n$  , we have a commutative diagram  \n\n$$\n\\begin{array}{rcl}\nL/nL \\times L/nL & \\xrightarrow{e_n} & \\mathbb{Z}/n \\\\\n\\Big\\downarrow & & \\Big\\downarrow \\\\\nL/mL \\times L/mL & \\xrightarrow{e_m} & \\mathbb{Z}/m\n\\end{array}\n$$  \n\n(2.2) Remark. The symplectic pairings  $e$   and  $e_{m}$   are nondegenerate. This means, for example, that for any linear map  $u\\,:\\,L\\,\\rightarrow\\,\\mathbb{Z}$   there exists a unique  $y$  in  $L$  with  $u(x)=e(x,y)$   for all  $x$  in  $L$  \n\nUsing the definitions going into the formula for the dual isogeny in (1.2), we can obtain a useful formula for  $e(x,y)$  . First, let  $\\operatorname{sgn}(x,y)$  equal  $+1,\\,0,\\,-1$  when\n\n  $\\mathbf{Im}(x/y)\\;\\mathrm{is}>0,=0$  , and  $<0$  , respectively. Then it is easy to check that  \n\n$$\ne(x,y)=\\operatorname{sgn}(x,y)\\cdot{\\frac{a(\\mathbb{Z}x+\\mathbb{Z}y)}{a(L)}}.\n$$  \n\n(2.3) Remark. With this formula for  $e$  , we show that for any  isogeny $\\lambda : E = \\mathbb{C}/L \\rightarrow E' = \\mathbb{C}/L'$ with $\\lambda L \\subset L'$ and dual isogeny $\\hat{\\lambda} : E' \\xrightarrow{} E$, the relation $ e_{L'}(\\lambda x, x') = e_{L}(x, \\hat{\\lambda}x') $  holds for $x$ in $L$ and $x'$ in $L'$. We have the following inclusions between lattices:\n\n\\[\n\\begin{array}{rcl}\n\\lambda L & \\subset & L' \\\\\n\\cup & & \\cup \\\\\n\\mathbb{Z}\\lambda x + \\mathbb{Z}n x' & \\subset & \\mathbb{Z}\\lambda x + \\mathbb{Z}x'.\n\\end{array}\n\\]\n\nNow calculate  \n\n$$\n\\begin{array}{r l}&{e_{L^{\\prime}}(x,\\hat{\\lambda}x^{\\prime})=\\mathrm{sgn}(x,\\hat{\\lambda}x^{\\prime})\\cdot\\frac{a(\\mathbb{Z}x+\\mathbb{Z}(n/\\lambda)x^{\\prime})}{a(L)}}\\\\ &{\\qquad\\qquad=\\mathrm{sgn}(\\lambda x,x^{\\prime})\\cdot\\frac{a(\\mathbb{Z}\\lambda x+\\mathbb{Z}n x^{\\prime})}{a(\\lambda L)}}\\\\ &{\\qquad\\qquad=\\mathrm{sgn}(\\lambda x,x^{\\prime})[\\lambda L:\\mathbb{Z}\\lambda x+\\mathbb{Z}n x^{\\prime}]}\\\\ &{\\qquad\\qquad=\\mathrm{sgn}(\\lambda x,x^{\\prime})[L^{\\prime}:\\mathbb{Z}\\lambda x+\\mathbb{Z}x^{\\prime}]}\\\\ &{\\qquad\\qquad=e_{L^{\\prime}}(\\lambda x,x^{\\prime}).}\\end{array}\n$$  \n\nThis verifies the formula.  \n\nThe above discussion takes place on lattices. Now we reinterpret the pairing on the division points  $_{N}E(\\mathbb{C})=(I/N)L/L\\subset E(\\mathbb{C})$   contained in the complex points of the curve. This will lead later to the algebraic definition of the symplectic pairing, which is due to A. Weil. The results over the complex numbers are summarized in the following proposition.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "e(x,y)=\\operatorname{sgn}(x,y)\\cdot{\\frac{a(\\mathbb{Z}x+\\mathbb{Z}y)}{a(L)}}.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/textbook_needrop_en_1514",
        "ID": "112a2174-9d27-4596-b945-2195d03ce606",
        "questions": "According to the document, what type of pairing do e and e_m define, and what property do they share?",
        "answers": "The symplectic pairings e and e_m are nondegenerate.",
        "context": "Observe that  $e:L\\times L\\times\\mathbb{Z}$   defines by reduction modulo  $m$  a symplectic pairing  $e_{m}:L/m L\\times L/m L\\to\\mathbb{Z}/m$  , and for  $m$  dividing  $n$  , we have a commutative diagram  \n\n$$\n\\begin{array}{rcl}\nL/nL \\times L/nL & \\xrightarrow{e_n} & \\mathbb{Z}/n \\\\\n\\Big\\downarrow & & \\Big\\downarrow \\\\\nL/mL \\times L/mL & \\xrightarrow{e_m} & \\mathbb{Z}/m\n\\end{array}\n$$  \n\n(2.2) Remark. The symplectic pairings  $e$   and  $e_{m}$   are nondegenerate. This means, for example, that for any linear map  $u\\,:\\,L\\,\\rightarrow\\,\\mathbb{Z}$   there exists a unique  $y$  in  $L$  with  $u(x)=e(x,y)$   for all  $x$  in  $L$  \n\nUsing the definitions going into the formula for the dual isogeny in (1.2), we can obtain a useful formula for  $e(x,y)$  . First, let  $\\operatorname{sgn}(x,y)$  equal  $+1,\\,0,\\,-1$  when\n\n  $\\mathbf{Im}(x/y)\\;\\mathrm{is}>0,=0$  , and  $<0$  , respectively. Then it is easy to check that  \n\n$$\ne(x,y)=\\operatorname{sgn}(x,y)\\cdot{\\frac{a(\\mathbb{Z}x+\\mathbb{Z}y)}{a(L)}}.\n$$  \n\n(2.3) Remark. With this formula for  $e$  , we show that for any  isogeny $\\lambda : E = \\mathbb{C}/L \\rightarrow E' = \\mathbb{C}/L'$ with $\\lambda L \\subset L'$ and dual isogeny $\\hat{\\lambda} : E' \\xrightarrow{} E$, the relation $ e_{L'}(\\lambda x, x') = e_{L}(x, \\hat{\\lambda}x') $  holds for $x$ in $L$ and $x'$ in $L'$. We have the following inclusions between lattices:\n\n\\[\n\\begin{array}{rcl}\n\\lambda L & \\subset & L' \\\\\n\\cup & & \\cup \\\\\n\\mathbb{Z}\\lambda x + \\mathbb{Z}n x' & \\subset & \\mathbb{Z}\\lambda x + \\mathbb{Z}x'.\n\\end{array}\n\\]\n\nNow calculate  \n\n$$\n\\begin{array}{r l}&{e_{L^{\\prime}}(x,\\hat{\\lambda}x^{\\prime})=\\mathrm{sgn}(x,\\hat{\\lambda}x^{\\prime})\\cdot\\frac{a(\\mathbb{Z}x+\\mathbb{Z}(n/\\lambda)x^{\\prime})}{a(L)}}\\\\ &{\\qquad\\qquad=\\mathrm{sgn}(\\lambda x,x^{\\prime})\\cdot\\frac{a(\\mathbb{Z}\\lambda x+\\mathbb{Z}n x^{\\prime})}{a(\\lambda L)}}\\\\ &{\\qquad\\qquad=\\mathrm{sgn}(\\lambda x,x^{\\prime})[\\lambda L:\\mathbb{Z}\\lambda x+\\mathbb{Z}n x^{\\prime}]}\\\\ &{\\qquad\\qquad=\\mathrm{sgn}(\\lambda x,x^{\\prime})[L^{\\prime}:\\mathbb{Z}\\lambda x+\\mathbb{Z}x^{\\prime}]}\\\\ &{\\qquad\\qquad=e_{L^{\\prime}}(\\lambda x,x^{\\prime}).}\\end{array}\n$$  \n\nThis verifies the formula.  \n\nThe above discussion takes place on lattices. Now we reinterpret the pairing on the division points  $_{N}E(\\mathbb{C})=(I/N)L/L\\subset E(\\mathbb{C})$   contained in the complex points of the curve. This will lead later to the algebraic definition of the symplectic pairing, which is due to A. Weil. The results over the complex numbers are summarized in the following proposition.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "The symplectic pairings e and e_{m} are nondegenerate.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/textbook_needrop_en_1514",
        "ID": "1133add6-90a9-4e49-88e8-0b6993c198e1",
        "questions": "What relation is shown to hold for the symplectic pairings involving an isogeny lambda and its dual isogeny hat{lambda}, in terms of lattices L and L'?",
        "answers": "e_{L'}(\\lambda x, x') = e_{L}(x, \\hat{\\lambda}x')",
        "context": "Observe that  $e:L\\times L\\times\\mathbb{Z}$   defines by reduction modulo  $m$  a symplectic pairing  $e_{m}:L/m L\\times L/m L\\to\\mathbb{Z}/m$  , and for  $m$  dividing  $n$  , we have a commutative diagram  \n\n$$\n\\begin{array}{rcl}\nL/nL \\times L/nL & \\xrightarrow{e_n} & \\mathbb{Z}/n \\\\\n\\Big\\downarrow & & \\Big\\downarrow \\\\\nL/mL \\times L/mL & \\xrightarrow{e_m} & \\mathbb{Z}/m\n\\end{array}\n$$  \n\n(2.2) Remark. The symplectic pairings  $e$   and  $e_{m}$   are nondegenerate. This means, for example, that for any linear map  $u\\,:\\,L\\,\\rightarrow\\,\\mathbb{Z}$   there exists a unique  $y$  in  $L$  with  $u(x)=e(x,y)$   for all  $x$  in  $L$  \n\nUsing the definitions going into the formula for the dual isogeny in (1.2), we can obtain a useful formula for  $e(x,y)$  . First, let  $\\operatorname{sgn}(x,y)$  equal  $+1,\\,0,\\,-1$  when\n\n  $\\mathbf{Im}(x/y)\\;\\mathrm{is}>0,=0$  , and  $<0$  , respectively. Then it is easy to check that  \n\n$$\ne(x,y)=\\operatorname{sgn}(x,y)\\cdot{\\frac{a(\\mathbb{Z}x+\\mathbb{Z}y)}{a(L)}}.\n$$  \n\n(2.3) Remark. With this formula for  $e$  , we show that for any  isogeny $\\lambda : E = \\mathbb{C}/L \\rightarrow E' = \\mathbb{C}/L'$ with $\\lambda L \\subset L'$ and dual isogeny $\\hat{\\lambda} : E' \\xrightarrow{} E$, the relation $ e_{L'}(\\lambda x, x') = e_{L}(x, \\hat{\\lambda}x') $  holds for $x$ in $L$ and $x'$ in $L'$. We have the following inclusions between lattices:\n\n\\[\n\\begin{array}{rcl}\n\\lambda L & \\subset & L' \\\\\n\\cup & & \\cup \\\\\n\\mathbb{Z}\\lambda x + \\mathbb{Z}n x' & \\subset & \\mathbb{Z}\\lambda x + \\mathbb{Z}x'.\n\\end{array}\n\\]\n\nNow calculate  \n\n$$\n\\begin{array}{r l}&{e_{L^{\\prime}}(x,\\hat{\\lambda}x^{\\prime})=\\mathrm{sgn}(x,\\hat{\\lambda}x^{\\prime})\\cdot\\frac{a(\\mathbb{Z}x+\\mathbb{Z}(n/\\lambda)x^{\\prime})}{a(L)}}\\\\ &{\\qquad\\qquad=\\mathrm{sgn}(\\lambda x,x^{\\prime})\\cdot\\frac{a(\\mathbb{Z}\\lambda x+\\mathbb{Z}n x^{\\prime})}{a(\\lambda L)}}\\\\ &{\\qquad\\qquad=\\mathrm{sgn}(\\lambda x,x^{\\prime})[\\lambda L:\\mathbb{Z}\\lambda x+\\mathbb{Z}n x^{\\prime}]}\\\\ &{\\qquad\\qquad=\\mathrm{sgn}(\\lambda x,x^{\\prime})[L^{\\prime}:\\mathbb{Z}\\lambda x+\\mathbb{Z}x^{\\prime}]}\\\\ &{\\qquad\\qquad=e_{L^{\\prime}}(\\lambda x,x^{\\prime}).}\\end{array}\n$$  \n\nThis verifies the formula.  \n\nThe above discussion takes place on lattices. Now we reinterpret the pairing on the division points  $_{N}E(\\mathbb{C})=(I/N)L/L\\subset E(\\mathbb{C})$   contained in the complex points of the curve. This will lead later to the algebraic definition of the symplectic pairing, which is due to A. Weil. The results over the complex numbers are summarized in the following proposition.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "With this formula for  e  , we show that for any  isogeny \\lambda : E = \\mathbb{C}/L \\rightarrow E' = \\mathbb{C}/L' with \\lambda L \\subset L' and dual isogeny \\hat{\\lambda} : E' \\xrightarrow{} E, the relation e_{L'}(\\lambda x, x') = e_{L}(x, \\hat{\\lambda}x') holds for  x  in  L  and  x'  in  L'.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/textbook_needrop_en_1514",
        "ID": "1138b1e2-488d-4d7a-a312-810215328479",
        "questions": "What is the formula for the symplectic pairing function $e(x,y)$ used to check when $\\mathbf{Im}(x/y)$ is positive, zero, or negative?",
        "answers": "$e(x,y)=\\operatorname{sgn}(x,y)\\cdot{\\frac{a(\\mathbb{Z}x+\\mathbb{Z}y)}{a(L)}}$",
        "context": "Observe that  $e:L\\times L\\times\\mathbb{Z}$   defines by reduction modulo  $m$  a symplectic pairing  $e_{m}:L/m L\\times L/m L\\to\\mathbb{Z}/m$  , and for  $m$  dividing  $n$  , we have a commutative diagram  \n\n$$\n\\begin{array}{rcl}\nL/nL \\times L/nL & \\xrightarrow{e_n} & \\mathbb{Z}/n \\\\\n\\Big\\downarrow & & \\Big\\downarrow \\\\\nL/mL \\times L/mL & \\xrightarrow{e_m} & \\mathbb{Z}/m\n\\end{array}\n$$  \n\n(2.2) Remark. The symplectic pairings  $e$   and  $e_{m}$   are nondegenerate. This means, for example, that for any linear map  $u\\,:\\,L\\,\\rightarrow\\,\\mathbb{Z}$   there exists a unique  $y$  in  $L$  with  $u(x)=e(x,y)$   for all  $x$  in  $L$  \n\nUsing the definitions going into the formula for the dual isogeny in (1.2), we can obtain a useful formula for  $e(x,y)$  . First, let  $\\operatorname{sgn}(x,y)$  equal  $+1,\\,0,\\,-1$  when\n\n  $\\mathbf{Im}(x/y)\\;\\mathrm{is}>0,=0$  , and  $<0$  , respectively. Then it is easy to check that  \n\n$$\ne(x,y)=\\operatorname{sgn}(x,y)\\cdot{\\frac{a(\\mathbb{Z}x+\\mathbb{Z}y)}{a(L)}}.\n$$  \n\n(2.3) Remark. With this formula for  $e$  , we show that for any  isogeny $\\lambda : E = \\mathbb{C}/L \\rightarrow E' = \\mathbb{C}/L'$ with $\\lambda L \\subset L'$ and dual isogeny $\\hat{\\lambda} : E' \\xrightarrow{} E$, the relation $ e_{L'}(\\lambda x, x') = e_{L}(x, \\hat{\\lambda}x') $  holds for $x$ in $L$ and $x'$ in $L'$. We have the following inclusions between lattices:\n\n\\[\n\\begin{array}{rcl}\n\\lambda L & \\subset & L' \\\\\n\\cup & & \\cup \\\\\n\\mathbb{Z}\\lambda x + \\mathbb{Z}n x' & \\subset & \\mathbb{Z}\\lambda x + \\mathbb{Z}x'.\n\\end{array}\n\\]\n\nNow calculate  \n\n$$\n\\begin{array}{r l}&{e_{L^{\\prime}}(x,\\hat{\\lambda}x^{\\prime})=\\mathrm{sgn}(x,\\hat{\\lambda}x^{\\prime})\\cdot\\frac{a(\\mathbb{Z}x+\\mathbb{Z}(n/\\lambda)x^{\\prime})}{a(L)}}\\\\ &{\\qquad\\qquad=\\mathrm{sgn}(\\lambda x,x^{\\prime})\\cdot\\frac{a(\\mathbb{Z}\\lambda x+\\mathbb{Z}n x^{\\prime})}{a(\\lambda L)}}\\\\ &{\\qquad\\qquad=\\mathrm{sgn}(\\lambda x,x^{\\prime})[\\lambda L:\\mathbb{Z}\\lambda x+\\mathbb{Z}n x^{\\prime}]}\\\\ &{\\qquad\\qquad=\\mathrm{sgn}(\\lambda x,x^{\\prime})[L^{\\prime}:\\mathbb{Z}\\lambda x+\\mathbb{Z}x^{\\prime}]}\\\\ &{\\qquad\\qquad=e_{L^{\\prime}}(\\lambda x,x^{\\prime}).}\\end{array}\n$$  \n\nThis verifies the formula.  \n\nThe above discussion takes place on lattices. Now we reinterpret the pairing on the division points  $_{N}E(\\mathbb{C})=(I/N)L/L\\subset E(\\mathbb{C})$   contained in the complex points of the curve. This will lead later to the algebraic definition of the symplectic pairing, which is due to A. Weil. The results over the complex numbers are summarized in the following proposition.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$$e(x,y)=\\operatorname{sgn}(x,y)\\cdot{\\frac{a(\\mathbb{Z}x+\\mathbb{Z}y)}{a(L)}}.$$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/textbook_needrop_en_1514",
        "ID": "113c1836-77f4-431b-bde9-d47dd89331ac",
        "questions": "What relation holds for the symplectic pairings $e_{L'}(\\lambda x, x')$ and $e_{L}(x, \\hat{\\lambda}x')$ for an isogeny $\\lambda: E \\rightarrow E'$ and its dual $\\hat{\\lambda}: E' \\xrightarrow{} E$?",
        "answers": "$e_{L^{\\prime}}(\\lambda x, x^{\\prime})=e_{L}(x, \\hat{\\lambda}x^{\\prime})$",
        "context": "Observe that  $e:L\\times L\\times\\mathbb{Z}$   defines by reduction modulo  $m$  a symplectic pairing  $e_{m}:L/m L\\times L/m L\\to\\mathbb{Z}/m$  , and for  $m$  dividing  $n$  , we have a commutative diagram  \n\n$$\n\\begin{array}{rcl}\nL/nL \\times L/nL & \\xrightarrow{e_n} & \\mathbb{Z}/n \\\\\n\\Big\\downarrow & & \\Big\\downarrow \\\\\nL/mL \\times L/mL & \\xrightarrow{e_m} & \\mathbb{Z}/m\n\\end{array}\n$$  \n\n(2.2) Remark. The symplectic pairings  $e$   and  $e_{m}$   are nondegenerate. This means, for example, that for any linear map  $u\\,:\\,L\\,\\rightarrow\\,\\mathbb{Z}$   there exists a unique  $y$  in  $L$  with  $u(x)=e(x,y)$   for all  $x$  in  $L$  \n\nUsing the definitions going into the formula for the dual isogeny in (1.2), we can obtain a useful formula for  $e(x,y)$  . First, let  $\\operatorname{sgn}(x,y)$  equal  $+1,\\,0,\\,-1$  when\n\n  $\\mathbf{Im}(x/y)\\;\\mathrm{is}>0,=0$  , and  $<0$  , respectively. Then it is easy to check that  \n\n$$\ne(x,y)=\\operatorname{sgn}(x,y)\\cdot{\\frac{a(\\mathbb{Z}x+\\mathbb{Z}y)}{a(L)}}.\n$$  \n\n(2.3) Remark. With this formula for  $e$  , we show that for any  isogeny $\\lambda : E = \\mathbb{C}/L \\rightarrow E' = \\mathbb{C}/L'$ with $\\lambda L \\subset L'$ and dual isogeny $\\hat{\\lambda} : E' \\xrightarrow{} E$, the relation $ e_{L'}(\\lambda x, x') = e_{L}(x, \\hat{\\lambda}x') $  holds for $x$ in $L$ and $x'$ in $L'$. We have the following inclusions between lattices:\n\n\\[\n\\begin{array}{rcl}\n\\lambda L & \\subset & L' \\\\\n\\cup & & \\cup \\\\\n\\mathbb{Z}\\lambda x + \\mathbb{Z}n x' & \\subset & \\mathbb{Z}\\lambda x + \\mathbb{Z}x'.\n\\end{array}\n\\]\n\nNow calculate  \n\n$$\n\\begin{array}{r l}&{e_{L^{\\prime}}(x,\\hat{\\lambda}x^{\\prime})=\\mathrm{sgn}(x,\\hat{\\lambda}x^{\\prime})\\cdot\\frac{a(\\mathbb{Z}x+\\mathbb{Z}(n/\\lambda)x^{\\prime})}{a(L)}}\\\\ &{\\qquad\\qquad=\\mathrm{sgn}(\\lambda x,x^{\\prime})\\cdot\\frac{a(\\mathbb{Z}\\lambda x+\\mathbb{Z}n x^{\\prime})}{a(\\lambda L)}}\\\\ &{\\qquad\\qquad=\\mathrm{sgn}(\\lambda x,x^{\\prime})[\\lambda L:\\mathbb{Z}\\lambda x+\\mathbb{Z}n x^{\\prime}]}\\\\ &{\\qquad\\qquad=\\mathrm{sgn}(\\lambda x,x^{\\prime})[L^{\\prime}:\\mathbb{Z}\\lambda x+\\mathbb{Z}x^{\\prime}]}\\\\ &{\\qquad\\qquad=e_{L^{\\prime}}(\\lambda x,x^{\\prime}).}\\end{array}\n$$  \n\nThis verifies the formula.  \n\nThe above discussion takes place on lattices. Now we reinterpret the pairing on the division points  $_{N}E(\\mathbb{C})=(I/N)L/L\\subset E(\\mathbb{C})$   contained in the complex points of the curve. This will lead later to the algebraic definition of the symplectic pairing, which is due to A. Weil. The results over the complex numbers are summarized in the following proposition.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "the relation $ e_{L'}(\\lambda x, x') = e_{L}(x, \\hat{\\lambda}x') $  holds for $x$ in $L$ and $x'$ in $L'$.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/textbook_needrop_en_1514",
        "ID": "113c88f4-d3ca-4477-8fa2-d2731240c5fa",
        "questions": "How is the calculation of $e_{L^{\\prime}}(x,\\hat{\\lambda}x^{\\prime})$ verified using the subdivisions within the lattices?",
        "answers": "$\\begin{array}{r l}&{e_{L^{\\prime}}(x,\\hat{\\lambda}x^{\\prime})=\\mathrm{sgn}(x,\\hat{\\lambda}x^{\\prime})\\cdot\\frac{a(\\mathbb{Z}x+\\mathbb{Z}(n/\\lambda)x^{\\prime})}{a(L)}}\\\\ &{\\qquad\\qquad=\\mathrm{sgn}(\\lambda x,x^{\\prime})\\cdot\\frac{a(\\mathbb{Z}\\lambda x+\\mathbb{Z}n x^{\\prime})}{a(\\lambda L)}}\\\\ &{\\qquad\\qquad=\\mathrm{sgn}(\\lambda x,x^{\\prime})[\\lambda L:\\mathbb{Z}\\lambda x+\\mathbb{Z}n x^{\\prime}]}\\\\ &{\\qquad\\qquad=\\mathrm{sgn}(\\lambda x,x^{\\prime})[L^{\\prime}:\\mathbb{Z}\\lambda x+\\mathbb{Z}x^{\\prime}]}\\\\ &{\\qquad\\qquad=e_{L^{\\prime}}(\\lambda x,x^{\\prime}).}\\end{array}$",
        "context": "Observe that  $e:L\\times L\\times\\mathbb{Z}$   defines by reduction modulo  $m$  a symplectic pairing  $e_{m}:L/m L\\times L/m L\\to\\mathbb{Z}/m$  , and for  $m$  dividing  $n$  , we have a commutative diagram  \n\n$$\n\\begin{array}{rcl}\nL/nL \\times L/nL & \\xrightarrow{e_n} & \\mathbb{Z}/n \\\\\n\\Big\\downarrow & & \\Big\\downarrow \\\\\nL/mL \\times L/mL & \\xrightarrow{e_m} & \\mathbb{Z}/m\n\\end{array}\n$$  \n\n(2.2) Remark. The symplectic pairings  $e$   and  $e_{m}$   are nondegenerate. This means, for example, that for any linear map  $u\\,:\\,L\\,\\rightarrow\\,\\mathbb{Z}$   there exists a unique  $y$  in  $L$  with  $u(x)=e(x,y)$   for all  $x$  in  $L$  \n\nUsing the definitions going into the formula for the dual isogeny in (1.2), we can obtain a useful formula for  $e(x,y)$  . First, let  $\\operatorname{sgn}(x,y)$  equal  $+1,\\,0,\\,-1$  when\n\n  $\\mathbf{Im}(x/y)\\;\\mathrm{is}>0,=0$  , and  $<0$  , respectively. Then it is easy to check that  \n\n$$\ne(x,y)=\\operatorname{sgn}(x,y)\\cdot{\\frac{a(\\mathbb{Z}x+\\mathbb{Z}y)}{a(L)}}.\n$$  \n\n(2.3) Remark. With this formula for  $e$  , we show that for any  isogeny $\\lambda : E = \\mathbb{C}/L \\rightarrow E' = \\mathbb{C}/L'$ with $\\lambda L \\subset L'$ and dual isogeny $\\hat{\\lambda} : E' \\xrightarrow{} E$, the relation $ e_{L'}(\\lambda x, x') = e_{L}(x, \\hat{\\lambda}x') $  holds for $x$ in $L$ and $x'$ in $L'$. We have the following inclusions between lattices:\n\n\\[\n\\begin{array}{rcl}\n\\lambda L & \\subset & L' \\\\\n\\cup & & \\cup \\\\\n\\mathbb{Z}\\lambda x + \\mathbb{Z}n x' & \\subset & \\mathbb{Z}\\lambda x + \\mathbb{Z}x'.\n\\end{array}\n\\]\n\nNow calculate  \n\n$$\n\\begin{array}{r l}&{e_{L^{\\prime}}(x,\\hat{\\lambda}x^{\\prime})=\\mathrm{sgn}(x,\\hat{\\lambda}x^{\\prime})\\cdot\\frac{a(\\mathbb{Z}x+\\mathbb{Z}(n/\\lambda)x^{\\prime})}{a(L)}}\\\\ &{\\qquad\\qquad=\\mathrm{sgn}(\\lambda x,x^{\\prime})\\cdot\\frac{a(\\mathbb{Z}\\lambda x+\\mathbb{Z}n x^{\\prime})}{a(\\lambda L)}}\\\\ &{\\qquad\\qquad=\\mathrm{sgn}(\\lambda x,x^{\\prime})[\\lambda L:\\mathbb{Z}\\lambda x+\\mathbb{Z}n x^{\\prime}]}\\\\ &{\\qquad\\qquad=\\mathrm{sgn}(\\lambda x,x^{\\prime})[L^{\\prime}:\\mathbb{Z}\\lambda x+\\mathbb{Z}x^{\\prime}]}\\\\ &{\\qquad\\qquad=e_{L^{\\prime}}(\\lambda x,x^{\\prime}).}\\end{array}\n$$  \n\nThis verifies the formula.  \n\nThe above discussion takes place on lattices. Now we reinterpret the pairing on the division points  $_{N}E(\\mathbb{C})=(I/N)L/L\\subset E(\\mathbb{C})$   contained in the complex points of the curve. This will lead later to the algebraic definition of the symplectic pairing, which is due to A. Weil. The results over the complex numbers are summarized in the following proposition.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$\\begin{array}{r l}&{e_{L^{\\prime}}(x,\\hat{\\lambda}x^{\\prime})=\\mathrm{sgn}(x,\\hat{\\lambda}x^{\\prime})\\cdot\\frac{a(\\mathbb{Z}x+\\mathbb{Z}(n/\\lambda)x^{\\prime})}{a(L)}}\\\\ &{\\qquad\\qquad=\\mathrm{sgn}(\\lambda x,x^{\\prime})\\cdot\\frac{a(\\mathbb{Z}\\lambda x+\\mathbb{Z}n x^{\\prime})}{a(\\lambda L)}}\\\\ &{\\qquad\\qquad=\\mathrm{sgn}(\\lambda x,x^{\\prime})[\\lambda L:\\mathbb{Z}\\lambda x+\\mathbb{Z}n x^{\\prime}]}\\\\ &{\\qquad\\qquad=\\mathrm{sgn}(\\lambda x,x^{\\prime})[L^{\\prime}:\\mathbb{Z}\\lambda x+\\mathbb{Z}x^{\\prime}]}\\\\ &{\\qquad\\qquad=e_{L^{\\prime}}(\\lambda x,x^{\\prime}).}\\end{array}$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/phys-31192.pdf_56",
        "ID": "1140b40c-0fa1-43f1-9171-649d930d25ab",
        "questions": "What are the values of the Cayley-Klein parameters $\\xi_{0}$ and $\\xi_{1}$ in the representation of the unitary matrix in terms of Euler angles $\\alpha$, $\\beta$, and $\\gamma$?",
        "answers": "$\\xi_{0}=e^{-i\\\\alpha/2}\\\\cos(\\\\beta/2)e^{-i\\\\gamma/2}$, $\\\\xi_{1}=e^{i\\\\alpha/2}\\\\sin(\\\\beta/2)e^{-i\\\\gamma/2}$",
        "context": "$$\n{\\begin{array}{r l}&{V(\\alpha,\\beta,\\gamma)=U\\left({\\hat{x}}_{3},{\\frac{\\alpha}{2}}\\right)U\\left({\\hat{x}}_{2},{\\frac{\\beta}{2}}\\right)U\\left({\\hat{x}}_{3},{\\frac{\\gamma}{2}}\\right)}\\\\ &{\\quad\\quad\\quad=\\left(\\begin{array}{c c}{e^{-i\\alpha/2}}&{0}\\\\ {0}&{e^{i\\alpha/2}}\\end{array}\\right)\\left(\\begin{array}{c c}{\\cos(\\beta/2)}&{-\\sin(\\beta/2)}\\\\ {\\sin(\\beta/2)}&{\\cos(\\beta/2)}\\end{array}\\right)\\left(\\begin{array}{c c}{e^{-i\\gamma/2}}&{0}\\\\ {0}&{e^{i\\gamma/2}}\\end{array}\\right)}\\\\ &{\\quad\\quad=\\left(\\begin{array}{c c}{e^{-i\\alpha/2}\\cos(\\beta/2)e^{-i\\gamma/2}}&{-e^{-i\\alpha/2}\\sin(\\beta/2)e^{i\\gamma/2}}\\\\ {e^{i\\alpha/2}\\sin(\\beta/2)e^{-i\\gamma/2}}&{e^{i\\alpha/2}\\cos(\\beta/2)e^{i\\gamma/2}}\\end{array}\\right)}\\\\ &{\\quad\\quad=\\left(\\begin{array}{c c}{\\xi_{0}}&{-\\xi_{1}^{*}}\\\\ {\\xi_{1}}&{\\xi_{0}^{*}}\\end{array}\\right)}\\end{array}}\n$$  \n\nwith  \n\n$$\n\\begin{array}{l}{{\\xi_{0}=e^{-i\\alpha/2}\\cos(\\beta/2)e^{-i\\gamma/2}}}\\\\ {{\\xi_{1}=e^{i\\alpha/2}\\sin(\\beta/2)e^{-i\\gamma/2}}}\\end{array}\n$$  \n\nThe four matrix elements appearing in this relation are the so-called Cayley-Klein parameters. (See Equation 3.4.43 in Section 3.4.2.)  \n\nIt is a general property of the matrices of the algebra  $\\mathcal{A}_{2}$  , that they can be represented either in terms of components or in terms of matrix elements. We have arrived at the conclusion that the representation of a unitary matrix in terms of elements is suitable for the parametrization of orientation al configuration, while the rotation operator is represented in terms of components (axis-angle variables).  \n\nThere is one more step left to express this result most efficiently. We introduce the two-component complex vectors (spinors) of  $\\mathcal{V}(2,C)$  already mentioned at the beginning of the chapter. In particular, we define two conjugate column vectors, or ket spinors:  \n\n$$\n|\\xi\\rangle=\\left({\\xi_{0}\\atop\\xi_{1}}\\right),\\quad|\\bar{\\xi}\\,\\rangle=\\left(\\begin{array}{c}{{-\\xi_{1}^{\\ast}\\nonumber}}\\\\ {{\\xi_{0}^{\\ast}}}\\end{array}\\right)\n$$  \n\nand write the unitary V matrix symbolically as  \n\n$$\nV=(\\langle\\xi||\\mathbf{\\theta}|\\bar{\\xi}\\rangle)\n$$  \n\nWe define the corresponding bra vectors by splitting the Hermitian conjugate  $\\mathrm{V}$  horizontally into row vectors:  \n\n$$\nV^{\\dagger}=\\left(\\begin{array}{l l}{{\\xi_{0}^{*}}}&{{\\xi_{1}^{*}}}\\\\ {{-\\xi_{1}}}&{{\\xi_{0}}}\\end{array}\\right)=\\left(\\begin{array}{l}{{\\langle\\xi|}}\\\\ {{\\langle\\bar{\\xi}|}}\\end{array}\\right)\n$$  \n\nor  \n\n$$\n\\langle{\\pmb\\xi}|=\\left(\\xi_{0}^{*},\\xi_{1}^{*}\\right);\\quad\\langle\\bar{\\pmb\\xi}|=(-\\xi_{1},\\xi_{0})\n$$  \n\nThe condition of unit ari ty of  $\\mathrm{v}$  can be expressed as  \n\n$$\nV^{\\dagger}V=\\left(\\begin{array}{c c c}{{\\langle\\xi|}}\\\\ {{\\langle\\bar{\\xi}|}}\\end{array}\\right)(|\\xi\\rangle,|\\bar{\\xi}\\rangle)\n$$  \n\n$$\n={\\left(\\begin{array}{l l}{\\langle\\xi\\mid\\xi\\rangle}&{\\langle\\xi\\mid{\\bar{\\xi}}\\rangle}\\\\ {\\langle{\\bar{\\xi}}\\mid\\xi\\rangle}&{\\langle{\\bar{\\xi}}\\mid{\\bar{\\xi}}\\rangle}\\end{array}\\right)}={\\left(\\begin{array}{l l}{1}&{0}\\\\ {0}&{1}\\end{array}\\right)}\n$$  \n\nyielding at once the conditions of ortho normality  \n\n$$\n\\begin{array}{c c c}{{\\langle\\xi\\mid\\xi\\rangle=\\langle\\bar{\\xi}\\mid\\bar{\\xi}\\rangle=1}}\\\\ {{\\langle\\xi\\mid\\bar{\\xi}\\rangle=\\langle\\bar{\\xi}\\mid\\xi\\rangle=0}}\\end{array}\n$$  \n\nThese can be, of course, verified by direct calculation. The orthogonal spinors are also called conjugate spinors. We see from these relations that our definition of spin conjugation is, indeed, a sensible one. However, the meaning of this concept is richer than the analogy with the ortho-normality relation in the real domain might suggest.  \n\nFirst of all, we express spin conjugation in terms of a matrix operation. The relation is nonlinear, as it involves the operation of complex conjugation  $\\kappa$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "${\\\\xi_{0}=e^{-i\\\\alpha/2}\\\\cos(\\\\beta/2)e^{-i\\\\gamma/2}}, {\\\\xi_{1}=e^{i\\\\alpha/2}\\\\sin(\\\\beta/2)e^{-i\\\\gamma/2}}",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/phys-31192.pdf_56",
        "ID": "1140e8ae-8923-44d6-bffd-d31f91c73e1d",
        "questions": "What is the orthonormality condition for the conjugate spinors $|\\xi\\\\rangle$ and $|\\\\bar{\\\\xi}\\\\rangle$?",
        "answers": "${\\\\langle\\\\xi\\\\mid\\\\xi\\\\rangle=\\\\langle\\\\bar{\\\\xi}\\\\mid\\\\bar{\\\\xi}\\\\rangle=1}, {\\\\langle\\\\xi\\\\mid\\\\bar{\\\\xi}\\\\rangle=\\\\langle\\\\bar{\\\\xi}\\\\mid\\\\xi\\\\rangle=0}$",
        "context": "$$\n{\\begin{array}{r l}&{V(\\alpha,\\beta,\\gamma)=U\\left({\\hat{x}}_{3},{\\frac{\\alpha}{2}}\\right)U\\left({\\hat{x}}_{2},{\\frac{\\beta}{2}}\\right)U\\left({\\hat{x}}_{3},{\\frac{\\gamma}{2}}\\right)}\\\\ &{\\quad\\quad\\quad=\\left(\\begin{array}{c c}{e^{-i\\alpha/2}}&{0}\\\\ {0}&{e^{i\\alpha/2}}\\end{array}\\right)\\left(\\begin{array}{c c}{\\cos(\\beta/2)}&{-\\sin(\\beta/2)}\\\\ {\\sin(\\beta/2)}&{\\cos(\\beta/2)}\\end{array}\\right)\\left(\\begin{array}{c c}{e^{-i\\gamma/2}}&{0}\\\\ {0}&{e^{i\\gamma/2}}\\end{array}\\right)}\\\\ &{\\quad\\quad=\\left(\\begin{array}{c c}{e^{-i\\alpha/2}\\cos(\\beta/2)e^{-i\\gamma/2}}&{-e^{-i\\alpha/2}\\sin(\\beta/2)e^{i\\gamma/2}}\\\\ {e^{i\\alpha/2}\\sin(\\beta/2)e^{-i\\gamma/2}}&{e^{i\\alpha/2}\\cos(\\beta/2)e^{i\\gamma/2}}\\end{array}\\right)}\\\\ &{\\quad\\quad=\\left(\\begin{array}{c c}{\\xi_{0}}&{-\\xi_{1}^{*}}\\\\ {\\xi_{1}}&{\\xi_{0}^{*}}\\end{array}\\right)}\\end{array}}\n$$  \n\nwith  \n\n$$\n\\begin{array}{l}{{\\xi_{0}=e^{-i\\alpha/2}\\cos(\\beta/2)e^{-i\\gamma/2}}}\\\\ {{\\xi_{1}=e^{i\\alpha/2}\\sin(\\beta/2)e^{-i\\gamma/2}}}\\end{array}\n$$  \n\nThe four matrix elements appearing in this relation are the so-called Cayley-Klein parameters. (See Equation 3.4.43 in Section 3.4.2.)  \n\nIt is a general property of the matrices of the algebra  $\\mathcal{A}_{2}$  , that they can be represented either in terms of components or in terms of matrix elements. We have arrived at the conclusion that the representation of a unitary matrix in terms of elements is suitable for the parametrization of orientation al configuration, while the rotation operator is represented in terms of components (axis-angle variables).  \n\nThere is one more step left to express this result most efficiently. We introduce the two-component complex vectors (spinors) of  $\\mathcal{V}(2,C)$  already mentioned at the beginning of the chapter. In particular, we define two conjugate column vectors, or ket spinors:  \n\n$$\n|\\xi\\rangle=\\left({\\xi_{0}\\atop\\xi_{1}}\\right),\\quad|\\bar{\\xi}\\,\\rangle=\\left(\\begin{array}{c}{{-\\xi_{1}^{\\ast}\\nonumber}}\\\\ {{\\xi_{0}^{\\ast}}}\\end{array}\\right)\n$$  \n\nand write the unitary V matrix symbolically as  \n\n$$\nV=(\\langle\\xi||\\mathbf{\\theta}|\\bar{\\xi}\\rangle)\n$$  \n\nWe define the corresponding bra vectors by splitting the Hermitian conjugate  $\\mathrm{V}$  horizontally into row vectors:  \n\n$$\nV^{\\dagger}=\\left(\\begin{array}{l l}{{\\xi_{0}^{*}}}&{{\\xi_{1}^{*}}}\\\\ {{-\\xi_{1}}}&{{\\xi_{0}}}\\end{array}\\right)=\\left(\\begin{array}{l}{{\\langle\\xi|}}\\\\ {{\\langle\\bar{\\xi}|}}\\end{array}\\right)\n$$  \n\nor  \n\n$$\n\\langle{\\pmb\\xi}|=\\left(\\xi_{0}^{*},\\xi_{1}^{*}\\right);\\quad\\langle\\bar{\\pmb\\xi}|=(-\\xi_{1},\\xi_{0})\n$$  \n\nThe condition of unit ari ty of  $\\mathrm{v}$  can be expressed as  \n\n$$\nV^{\\dagger}V=\\left(\\begin{array}{c c c}{{\\langle\\xi|}}\\\\ {{\\langle\\bar{\\xi}|}}\\end{array}\\right)(|\\xi\\rangle,|\\bar{\\xi}\\rangle)\n$$  \n\n$$\n={\\left(\\begin{array}{l l}{\\langle\\xi\\mid\\xi\\rangle}&{\\langle\\xi\\mid{\\bar{\\xi}}\\rangle}\\\\ {\\langle{\\bar{\\xi}}\\mid\\xi\\rangle}&{\\langle{\\bar{\\xi}}\\mid{\\bar{\\xi}}\\rangle}\\end{array}\\right)}={\\left(\\begin{array}{l l}{1}&{0}\\\\ {0}&{1}\\end{array}\\right)}\n$$  \n\nyielding at once the conditions of ortho normality  \n\n$$\n\\begin{array}{c c c}{{\\langle\\xi\\mid\\xi\\rangle=\\langle\\bar{\\xi}\\mid\\bar{\\xi}\\rangle=1}}\\\\ {{\\langle\\xi\\mid\\bar{\\xi}\\rangle=\\langle\\bar{\\xi}\\mid\\xi\\rangle=0}}\\end{array}\n$$  \n\nThese can be, of course, verified by direct calculation. The orthogonal spinors are also called conjugate spinors. We see from these relations that our definition of spin conjugation is, indeed, a sensible one. However, the meaning of this concept is richer than the analogy with the ortho-normality relation in the real domain might suggest.  \n\nFirst of all, we express spin conjugation in terms of a matrix operation. The relation is nonlinear, as it involves the operation of complex conjugation  $\\kappa$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "${\\\\langle\\\\xi\\\\mid\\\\xi\\\\rangle=\\\\langle\\\\bar{\\\\xi}\\\\mid\\\\bar{\\\\xi}\\\\rangle=1}\\\\, {\\\\langle\\\\xi\\\\mid\\\\bar{\\\\xi}\\\\rangle=\\\\langle\\\\bar{\\\\xi}\\\\mid\\\\xi\\\\rangle=0}$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/phys-31192.pdf_56",
        "ID": "1146749b-beff-45eb-a0cf-822975201d7f",
        "questions": "Is the condition of unitarity of the V matrix verified by direct calculation from the spinor bra vectors?",
        "answers": "Yes",
        "context": "$$\n{\\begin{array}{r l}&{V(\\alpha,\\beta,\\gamma)=U\\left({\\hat{x}}_{3},{\\frac{\\alpha}{2}}\\right)U\\left({\\hat{x}}_{2},{\\frac{\\beta}{2}}\\right)U\\left({\\hat{x}}_{3},{\\frac{\\gamma}{2}}\\right)}\\\\ &{\\quad\\quad\\quad=\\left(\\begin{array}{c c}{e^{-i\\alpha/2}}&{0}\\\\ {0}&{e^{i\\alpha/2}}\\end{array}\\right)\\left(\\begin{array}{c c}{\\cos(\\beta/2)}&{-\\sin(\\beta/2)}\\\\ {\\sin(\\beta/2)}&{\\cos(\\beta/2)}\\end{array}\\right)\\left(\\begin{array}{c c}{e^{-i\\gamma/2}}&{0}\\\\ {0}&{e^{i\\gamma/2}}\\end{array}\\right)}\\\\ &{\\quad\\quad=\\left(\\begin{array}{c c}{e^{-i\\alpha/2}\\cos(\\beta/2)e^{-i\\gamma/2}}&{-e^{-i\\alpha/2}\\sin(\\beta/2)e^{i\\gamma/2}}\\\\ {e^{i\\alpha/2}\\sin(\\beta/2)e^{-i\\gamma/2}}&{e^{i\\alpha/2}\\cos(\\beta/2)e^{i\\gamma/2}}\\end{array}\\right)}\\\\ &{\\quad\\quad=\\left(\\begin{array}{c c}{\\xi_{0}}&{-\\xi_{1}^{*}}\\\\ {\\xi_{1}}&{\\xi_{0}^{*}}\\end{array}\\right)}\\end{array}}\n$$  \n\nwith  \n\n$$\n\\begin{array}{l}{{\\xi_{0}=e^{-i\\alpha/2}\\cos(\\beta/2)e^{-i\\gamma/2}}}\\\\ {{\\xi_{1}=e^{i\\alpha/2}\\sin(\\beta/2)e^{-i\\gamma/2}}}\\end{array}\n$$  \n\nThe four matrix elements appearing in this relation are the so-called Cayley-Klein parameters. (See Equation 3.4.43 in Section 3.4.2.)  \n\nIt is a general property of the matrices of the algebra  $\\mathcal{A}_{2}$  , that they can be represented either in terms of components or in terms of matrix elements. We have arrived at the conclusion that the representation of a unitary matrix in terms of elements is suitable for the parametrization of orientation al configuration, while the rotation operator is represented in terms of components (axis-angle variables).  \n\nThere is one more step left to express this result most efficiently. We introduce the two-component complex vectors (spinors) of  $\\mathcal{V}(2,C)$  already mentioned at the beginning of the chapter. In particular, we define two conjugate column vectors, or ket spinors:  \n\n$$\n|\\xi\\rangle=\\left({\\xi_{0}\\atop\\xi_{1}}\\right),\\quad|\\bar{\\xi}\\,\\rangle=\\left(\\begin{array}{c}{{-\\xi_{1}^{\\ast}\\nonumber}}\\\\ {{\\xi_{0}^{\\ast}}}\\end{array}\\right)\n$$  \n\nand write the unitary V matrix symbolically as  \n\n$$\nV=(\\langle\\xi||\\mathbf{\\theta}|\\bar{\\xi}\\rangle)\n$$  \n\nWe define the corresponding bra vectors by splitting the Hermitian conjugate  $\\mathrm{V}$  horizontally into row vectors:  \n\n$$\nV^{\\dagger}=\\left(\\begin{array}{l l}{{\\xi_{0}^{*}}}&{{\\xi_{1}^{*}}}\\\\ {{-\\xi_{1}}}&{{\\xi_{0}}}\\end{array}\\right)=\\left(\\begin{array}{l}{{\\langle\\xi|}}\\\\ {{\\langle\\bar{\\xi}|}}\\end{array}\\right)\n$$  \n\nor  \n\n$$\n\\langle{\\pmb\\xi}|=\\left(\\xi_{0}^{*},\\xi_{1}^{*}\\right);\\quad\\langle\\bar{\\pmb\\xi}|=(-\\xi_{1},\\xi_{0})\n$$  \n\nThe condition of unit ari ty of  $\\mathrm{v}$  can be expressed as  \n\n$$\nV^{\\dagger}V=\\left(\\begin{array}{c c c}{{\\langle\\xi|}}\\\\ {{\\langle\\bar{\\xi}|}}\\end{array}\\right)(|\\xi\\rangle,|\\bar{\\xi}\\rangle)\n$$  \n\n$$\n={\\left(\\begin{array}{l l}{\\langle\\xi\\mid\\xi\\rangle}&{\\langle\\xi\\mid{\\bar{\\xi}}\\rangle}\\\\ {\\langle{\\bar{\\xi}}\\mid\\xi\\rangle}&{\\langle{\\bar{\\xi}}\\mid{\\bar{\\xi}}\\rangle}\\end{array}\\right)}={\\left(\\begin{array}{l l}{1}&{0}\\\\ {0}&{1}\\end{array}\\right)}\n$$  \n\nyielding at once the conditions of ortho normality  \n\n$$\n\\begin{array}{c c c}{{\\langle\\xi\\mid\\xi\\rangle=\\langle\\bar{\\xi}\\mid\\bar{\\xi}\\rangle=1}}\\\\ {{\\langle\\xi\\mid\\bar{\\xi}\\rangle=\\langle\\bar{\\xi}\\mid\\xi\\rangle=0}}\\end{array}\n$$  \n\nThese can be, of course, verified by direct calculation. The orthogonal spinors are also called conjugate spinors. We see from these relations that our definition of spin conjugation is, indeed, a sensible one. However, the meaning of this concept is richer than the analogy with the ortho-normality relation in the real domain might suggest.  \n\nFirst of all, we express spin conjugation in terms of a matrix operation. The relation is nonlinear, as it involves the operation of complex conjugation  $\\kappa$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Yes/No",
        "evidence_source": "text",
        "evidence_context": "These can be, of course, verified by direct calculation.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/phys-31192.pdf_56",
        "ID": "114acf8e-89b5-4d29-b44d-732592a90fd2",
        "questions": "What is the expression for the matrix element \\( V(\\alpha, \\beta, \\gamma) \\) in terms of \\(\\alpha\\), \\(\\beta\\), and \\(\\gamma\\)?",
        "answers": "\\( V(\\alpha, \\beta, \\gamma) = U\\left({\\hat{x}}_{3},{\\frac{\\alpha}{2}}\\right)U\\left({\\hat{x}}_{2},{\\frac{\\beta}{2}}\\right)U\\left({\\hat{x}}_{3},{\\frac{\\gamma}{2}}\\right) \\)",
        "context": "$$\n{\\begin{array}{r l}&{V(\\alpha,\\beta,\\gamma)=U\\left({\\hat{x}}_{3},{\\frac{\\alpha}{2}}\\right)U\\left({\\hat{x}}_{2},{\\frac{\\beta}{2}}\\right)U\\left({\\hat{x}}_{3},{\\frac{\\gamma}{2}}\\right)}\\\\ &{\\quad\\quad\\quad=\\left(\\begin{array}{c c}{e^{-i\\alpha/2}}&{0}\\\\ {0}&{e^{i\\alpha/2}}\\end{array}\\right)\\left(\\begin{array}{c c}{\\cos(\\beta/2)}&{-\\sin(\\beta/2)}\\\\ {\\sin(\\beta/2)}&{\\cos(\\beta/2)}\\end{array}\\right)\\left(\\begin{array}{c c}{e^{-i\\gamma/2}}&{0}\\\\ {0}&{e^{i\\gamma/2}}\\end{array}\\right)}\\\\ &{\\quad\\quad=\\left(\\begin{array}{c c}{e^{-i\\alpha/2}\\cos(\\beta/2)e^{-i\\gamma/2}}&{-e^{-i\\alpha/2}\\sin(\\beta/2)e^{i\\gamma/2}}\\\\ {e^{i\\alpha/2}\\sin(\\beta/2)e^{-i\\gamma/2}}&{e^{i\\alpha/2}\\cos(\\beta/2)e^{i\\gamma/2}}\\end{array}\\right)}\\\\ &{\\quad\\quad=\\left(\\begin{array}{c c}{\\xi_{0}}&{-\\xi_{1}^{*}}\\\\ {\\xi_{1}}&{\\xi_{0}^{*}}\\end{array}\\right)}\\end{array}}\n$$  \n\nwith  \n\n$$\n\\begin{array}{l}{{\\xi_{0}=e^{-i\\alpha/2}\\cos(\\beta/2)e^{-i\\gamma/2}}}\\\\ {{\\xi_{1}=e^{i\\alpha/2}\\sin(\\beta/2)e^{-i\\gamma/2}}}\\end{array}\n$$  \n\nThe four matrix elements appearing in this relation are the so-called Cayley-Klein parameters. (See Equation 3.4.43 in Section 3.4.2.)  \n\nIt is a general property of the matrices of the algebra  $\\mathcal{A}_{2}$  , that they can be represented either in terms of components or in terms of matrix elements. We have arrived at the conclusion that the representation of a unitary matrix in terms of elements is suitable for the parametrization of orientation al configuration, while the rotation operator is represented in terms of components (axis-angle variables).  \n\nThere is one more step left to express this result most efficiently. We introduce the two-component complex vectors (spinors) of  $\\mathcal{V}(2,C)$  already mentioned at the beginning of the chapter. In particular, we define two conjugate column vectors, or ket spinors:  \n\n$$\n|\\xi\\rangle=\\left({\\xi_{0}\\atop\\xi_{1}}\\right),\\quad|\\bar{\\xi}\\,\\rangle=\\left(\\begin{array}{c}{{-\\xi_{1}^{\\ast}\\nonumber}}\\\\ {{\\xi_{0}^{\\ast}}}\\end{array}\\right)\n$$  \n\nand write the unitary V matrix symbolically as  \n\n$$\nV=(\\langle\\xi||\\mathbf{\\theta}|\\bar{\\xi}\\rangle)\n$$  \n\nWe define the corresponding bra vectors by splitting the Hermitian conjugate  $\\mathrm{V}$  horizontally into row vectors:  \n\n$$\nV^{\\dagger}=\\left(\\begin{array}{l l}{{\\xi_{0}^{*}}}&{{\\xi_{1}^{*}}}\\\\ {{-\\xi_{1}}}&{{\\xi_{0}}}\\end{array}\\right)=\\left(\\begin{array}{l}{{\\langle\\xi|}}\\\\ {{\\langle\\bar{\\xi}|}}\\end{array}\\right)\n$$  \n\nor  \n\n$$\n\\langle{\\pmb\\xi}|=\\left(\\xi_{0}^{*},\\xi_{1}^{*}\\right);\\quad\\langle\\bar{\\pmb\\xi}|=(-\\xi_{1},\\xi_{0})\n$$  \n\nThe condition of unit ari ty of  $\\mathrm{v}$  can be expressed as  \n\n$$\nV^{\\dagger}V=\\left(\\begin{array}{c c c}{{\\langle\\xi|}}\\\\ {{\\langle\\bar{\\xi}|}}\\end{array}\\right)(|\\xi\\rangle,|\\bar{\\xi}\\rangle)\n$$  \n\n$$\n={\\left(\\begin{array}{l l}{\\langle\\xi\\mid\\xi\\rangle}&{\\langle\\xi\\mid{\\bar{\\xi}}\\rangle}\\\\ {\\langle{\\bar{\\xi}}\\mid\\xi\\rangle}&{\\langle{\\bar{\\xi}}\\mid{\\bar{\\xi}}\\rangle}\\end{array}\\right)}={\\left(\\begin{array}{l l}{1}&{0}\\\\ {0}&{1}\\end{array}\\right)}\n$$  \n\nyielding at once the conditions of ortho normality  \n\n$$\n\\begin{array}{c c c}{{\\langle\\xi\\mid\\xi\\rangle=\\langle\\bar{\\xi}\\mid\\bar{\\xi}\\rangle=1}}\\\\ {{\\langle\\xi\\mid\\bar{\\xi}\\rangle=\\langle\\bar{\\xi}\\mid\\xi\\rangle=0}}\\end{array}\n$$  \n\nThese can be, of course, verified by direct calculation. The orthogonal spinors are also called conjugate spinors. We see from these relations that our definition of spin conjugation is, indeed, a sensible one. However, the meaning of this concept is richer than the analogy with the ortho-normality relation in the real domain might suggest.  \n\nFirst of all, we express spin conjugation in terms of a matrix operation. The relation is nonlinear, as it involves the operation of complex conjugation  $\\kappa$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$V(\\\\alpha, \\\\beta, \\\\gamma) = U\\\\left({\\\\hat{x}}_{3},{\\\\frac{\\\\alpha}{2}}\\\\right)U\\\\left({\\\\hat{x}}_{2},{\\\\frac{\\\\beta}{2}}\\\\right)U\\\\left({\\\\hat{x}}_{3},{\\\\frac{\\\\gamma}{2}}\\\\right)$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/phys-31192.pdf_56",
        "ID": "1157c073-b3e1-4908-93f0-e4b4387138d4",
        "questions": "How are \\(\\xi_0\\) and \\(\\xi_1\\) defined in terms of \\(\\alpha\\), \\(\\beta\\), and \\(\\gamma\\)?",
        "answers": "\\(\\xi_0 = e^{-i\\alpha/2}\\cos(\\beta/2)e^{-i\\gamma/2}\\) and \\(\\xi_1 = e^{i\\alpha/2}\\sin(\\beta/2)e^{-i\\gamma/2}\\)",
        "context": "$$\n{\\begin{array}{r l}&{V(\\alpha,\\beta,\\gamma)=U\\left({\\hat{x}}_{3},{\\frac{\\alpha}{2}}\\right)U\\left({\\hat{x}}_{2},{\\frac{\\beta}{2}}\\right)U\\left({\\hat{x}}_{3},{\\frac{\\gamma}{2}}\\right)}\\\\ &{\\quad\\quad\\quad=\\left(\\begin{array}{c c}{e^{-i\\alpha/2}}&{0}\\\\ {0}&{e^{i\\alpha/2}}\\end{array}\\right)\\left(\\begin{array}{c c}{\\cos(\\beta/2)}&{-\\sin(\\beta/2)}\\\\ {\\sin(\\beta/2)}&{\\cos(\\beta/2)}\\end{array}\\right)\\left(\\begin{array}{c c}{e^{-i\\gamma/2}}&{0}\\\\ {0}&{e^{i\\gamma/2}}\\end{array}\\right)}\\\\ &{\\quad\\quad=\\left(\\begin{array}{c c}{e^{-i\\alpha/2}\\cos(\\beta/2)e^{-i\\gamma/2}}&{-e^{-i\\alpha/2}\\sin(\\beta/2)e^{i\\gamma/2}}\\\\ {e^{i\\alpha/2}\\sin(\\beta/2)e^{-i\\gamma/2}}&{e^{i\\alpha/2}\\cos(\\beta/2)e^{i\\gamma/2}}\\end{array}\\right)}\\\\ &{\\quad\\quad=\\left(\\begin{array}{c c}{\\xi_{0}}&{-\\xi_{1}^{*}}\\\\ {\\xi_{1}}&{\\xi_{0}^{*}}\\end{array}\\right)}\\end{array}}\n$$  \n\nwith  \n\n$$\n\\begin{array}{l}{{\\xi_{0}=e^{-i\\alpha/2}\\cos(\\beta/2)e^{-i\\gamma/2}}}\\\\ {{\\xi_{1}=e^{i\\alpha/2}\\sin(\\beta/2)e^{-i\\gamma/2}}}\\end{array}\n$$  \n\nThe four matrix elements appearing in this relation are the so-called Cayley-Klein parameters. (See Equation 3.4.43 in Section 3.4.2.)  \n\nIt is a general property of the matrices of the algebra  $\\mathcal{A}_{2}$  , that they can be represented either in terms of components or in terms of matrix elements. We have arrived at the conclusion that the representation of a unitary matrix in terms of elements is suitable for the parametrization of orientation al configuration, while the rotation operator is represented in terms of components (axis-angle variables).  \n\nThere is one more step left to express this result most efficiently. We introduce the two-component complex vectors (spinors) of  $\\mathcal{V}(2,C)$  already mentioned at the beginning of the chapter. In particular, we define two conjugate column vectors, or ket spinors:  \n\n$$\n|\\xi\\rangle=\\left({\\xi_{0}\\atop\\xi_{1}}\\right),\\quad|\\bar{\\xi}\\,\\rangle=\\left(\\begin{array}{c}{{-\\xi_{1}^{\\ast}\\nonumber}}\\\\ {{\\xi_{0}^{\\ast}}}\\end{array}\\right)\n$$  \n\nand write the unitary V matrix symbolically as  \n\n$$\nV=(\\langle\\xi||\\mathbf{\\theta}|\\bar{\\xi}\\rangle)\n$$  \n\nWe define the corresponding bra vectors by splitting the Hermitian conjugate  $\\mathrm{V}$  horizontally into row vectors:  \n\n$$\nV^{\\dagger}=\\left(\\begin{array}{l l}{{\\xi_{0}^{*}}}&{{\\xi_{1}^{*}}}\\\\ {{-\\xi_{1}}}&{{\\xi_{0}}}\\end{array}\\right)=\\left(\\begin{array}{l}{{\\langle\\xi|}}\\\\ {{\\langle\\bar{\\xi}|}}\\end{array}\\right)\n$$  \n\nor  \n\n$$\n\\langle{\\pmb\\xi}|=\\left(\\xi_{0}^{*},\\xi_{1}^{*}\\right);\\quad\\langle\\bar{\\pmb\\xi}|=(-\\xi_{1},\\xi_{0})\n$$  \n\nThe condition of unit ari ty of  $\\mathrm{v}$  can be expressed as  \n\n$$\nV^{\\dagger}V=\\left(\\begin{array}{c c c}{{\\langle\\xi|}}\\\\ {{\\langle\\bar{\\xi}|}}\\end{array}\\right)(|\\xi\\rangle,|\\bar{\\xi}\\rangle)\n$$  \n\n$$\n={\\left(\\begin{array}{l l}{\\langle\\xi\\mid\\xi\\rangle}&{\\langle\\xi\\mid{\\bar{\\xi}}\\rangle}\\\\ {\\langle{\\bar{\\xi}}\\mid\\xi\\rangle}&{\\langle{\\bar{\\xi}}\\mid{\\bar{\\xi}}\\rangle}\\end{array}\\right)}={\\left(\\begin{array}{l l}{1}&{0}\\\\ {0}&{1}\\end{array}\\right)}\n$$  \n\nyielding at once the conditions of ortho normality  \n\n$$\n\\begin{array}{c c c}{{\\langle\\xi\\mid\\xi\\rangle=\\langle\\bar{\\xi}\\mid\\bar{\\xi}\\rangle=1}}\\\\ {{\\langle\\xi\\mid\\bar{\\xi}\\rangle=\\langle\\bar{\\xi}\\mid\\xi\\rangle=0}}\\end{array}\n$$  \n\nThese can be, of course, verified by direct calculation. The orthogonal spinors are also called conjugate spinors. We see from these relations that our definition of spin conjugation is, indeed, a sensible one. However, the meaning of this concept is richer than the analogy with the ortho-normality relation in the real domain might suggest.  \n\nFirst of all, we express spin conjugation in terms of a matrix operation. The relation is nonlinear, as it involves the operation of complex conjugation  $\\kappa$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "\\\\begin{array}{l}{{\\\\xi_{0}=e^{-i\\\\alpha/2}\\\\cos(\\\\beta/2)e^{-i\\\\gamma/2}}}\\\\\\\\ {{\\\\xi_{1}=e^{i\\\\alpha/2}\\\\sin(\\\\beta/2)e^{-i\\\\gamma/2}}}\\\\end{array}",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/phys-31192.pdf_56",
        "ID": "115d3e44-3adf-4a11-862d-d64a97fb334b",
        "questions": "What are the conditions for the orthonormality of the spinors \\(\\xi\\) and \\(\\bar{\\xi}\\)?",
        "answers": "\\(\\langle\\xi\\mid\\xi\\rangle = \\langle\\bar{\\xi}\\mid\\bar{\\xi}\\rangle = 1\\) and \\(\\langle\\xi\\mid\\bar{\\xi}\\rangle = \\langle\\bar{\\xi}\\mid\\xi\\rangle = 0\\)",
        "context": "$$\n{\\begin{array}{r l}&{V(\\alpha,\\beta,\\gamma)=U\\left({\\hat{x}}_{3},{\\frac{\\alpha}{2}}\\right)U\\left({\\hat{x}}_{2},{\\frac{\\beta}{2}}\\right)U\\left({\\hat{x}}_{3},{\\frac{\\gamma}{2}}\\right)}\\\\ &{\\quad\\quad\\quad=\\left(\\begin{array}{c c}{e^{-i\\alpha/2}}&{0}\\\\ {0}&{e^{i\\alpha/2}}\\end{array}\\right)\\left(\\begin{array}{c c}{\\cos(\\beta/2)}&{-\\sin(\\beta/2)}\\\\ {\\sin(\\beta/2)}&{\\cos(\\beta/2)}\\end{array}\\right)\\left(\\begin{array}{c c}{e^{-i\\gamma/2}}&{0}\\\\ {0}&{e^{i\\gamma/2}}\\end{array}\\right)}\\\\ &{\\quad\\quad=\\left(\\begin{array}{c c}{e^{-i\\alpha/2}\\cos(\\beta/2)e^{-i\\gamma/2}}&{-e^{-i\\alpha/2}\\sin(\\beta/2)e^{i\\gamma/2}}\\\\ {e^{i\\alpha/2}\\sin(\\beta/2)e^{-i\\gamma/2}}&{e^{i\\alpha/2}\\cos(\\beta/2)e^{i\\gamma/2}}\\end{array}\\right)}\\\\ &{\\quad\\quad=\\left(\\begin{array}{c c}{\\xi_{0}}&{-\\xi_{1}^{*}}\\\\ {\\xi_{1}}&{\\xi_{0}^{*}}\\end{array}\\right)}\\end{array}}\n$$  \n\nwith  \n\n$$\n\\begin{array}{l}{{\\xi_{0}=e^{-i\\alpha/2}\\cos(\\beta/2)e^{-i\\gamma/2}}}\\\\ {{\\xi_{1}=e^{i\\alpha/2}\\sin(\\beta/2)e^{-i\\gamma/2}}}\\end{array}\n$$  \n\nThe four matrix elements appearing in this relation are the so-called Cayley-Klein parameters. (See Equation 3.4.43 in Section 3.4.2.)  \n\nIt is a general property of the matrices of the algebra  $\\mathcal{A}_{2}$  , that they can be represented either in terms of components or in terms of matrix elements. We have arrived at the conclusion that the representation of a unitary matrix in terms of elements is suitable for the parametrization of orientation al configuration, while the rotation operator is represented in terms of components (axis-angle variables).  \n\nThere is one more step left to express this result most efficiently. We introduce the two-component complex vectors (spinors) of  $\\mathcal{V}(2,C)$  already mentioned at the beginning of the chapter. In particular, we define two conjugate column vectors, or ket spinors:  \n\n$$\n|\\xi\\rangle=\\left({\\xi_{0}\\atop\\xi_{1}}\\right),\\quad|\\bar{\\xi}\\,\\rangle=\\left(\\begin{array}{c}{{-\\xi_{1}^{\\ast}\\nonumber}}\\\\ {{\\xi_{0}^{\\ast}}}\\end{array}\\right)\n$$  \n\nand write the unitary V matrix symbolically as  \n\n$$\nV=(\\langle\\xi||\\mathbf{\\theta}|\\bar{\\xi}\\rangle)\n$$  \n\nWe define the corresponding bra vectors by splitting the Hermitian conjugate  $\\mathrm{V}$  horizontally into row vectors:  \n\n$$\nV^{\\dagger}=\\left(\\begin{array}{l l}{{\\xi_{0}^{*}}}&{{\\xi_{1}^{*}}}\\\\ {{-\\xi_{1}}}&{{\\xi_{0}}}\\end{array}\\right)=\\left(\\begin{array}{l}{{\\langle\\xi|}}\\\\ {{\\langle\\bar{\\xi}|}}\\end{array}\\right)\n$$  \n\nor  \n\n$$\n\\langle{\\pmb\\xi}|=\\left(\\xi_{0}^{*},\\xi_{1}^{*}\\right);\\quad\\langle\\bar{\\pmb\\xi}|=(-\\xi_{1},\\xi_{0})\n$$  \n\nThe condition of unit ari ty of  $\\mathrm{v}$  can be expressed as  \n\n$$\nV^{\\dagger}V=\\left(\\begin{array}{c c c}{{\\langle\\xi|}}\\\\ {{\\langle\\bar{\\xi}|}}\\end{array}\\right)(|\\xi\\rangle,|\\bar{\\xi}\\rangle)\n$$  \n\n$$\n={\\left(\\begin{array}{l l}{\\langle\\xi\\mid\\xi\\rangle}&{\\langle\\xi\\mid{\\bar{\\xi}}\\rangle}\\\\ {\\langle{\\bar{\\xi}}\\mid\\xi\\rangle}&{\\langle{\\bar{\\xi}}\\mid{\\bar{\\xi}}\\rangle}\\end{array}\\right)}={\\left(\\begin{array}{l l}{1}&{0}\\\\ {0}&{1}\\end{array}\\right)}\n$$  \n\nyielding at once the conditions of ortho normality  \n\n$$\n\\begin{array}{c c c}{{\\langle\\xi\\mid\\xi\\rangle=\\langle\\bar{\\xi}\\mid\\bar{\\xi}\\rangle=1}}\\\\ {{\\langle\\xi\\mid\\bar{\\xi}\\rangle=\\langle\\bar{\\xi}\\mid\\xi\\rangle=0}}\\end{array}\n$$  \n\nThese can be, of course, verified by direct calculation. The orthogonal spinors are also called conjugate spinors. We see from these relations that our definition of spin conjugation is, indeed, a sensible one. However, the meaning of this concept is richer than the analogy with the ortho-normality relation in the real domain might suggest.  \n\nFirst of all, we express spin conjugation in terms of a matrix operation. The relation is nonlinear, as it involves the operation of complex conjugation  $\\kappa$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "\\\\begin{array}{c c c}{{\\\\langle\\\\xi\\\\mid\\\\xi\\\\rangle=\\\\langle\\\\bar{\\\\xi}\\\\mid\\\\bar{\\\\xi}\\\\rangle=1}}\\\\\\\\ {{\\\\langle\\\\xi\\\\mid\\\\bar{\\\\xi}\\\\rangle=\\\\langle\\\\bar{\\\\xi}\\\\mid\\\\xi\\\\rangle=0}}\\\\end{array}",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/(Graduate_Studies_in_Mathematics,070)_Sean_Dineen_-_Probability_Theory_in_Finance-American_Mathematical_Society_(2013).pdf_186",
        "ID": "11625ccc-c0b9-489a-b3bf-052d24d210fb",
        "questions": "What condition must be met for the probability of each set $G_n$ in a countable partition to be considered in Proposition 8.4?",
        "answers": "$P(G_{n})\\,>\\,0$ for all $n$",
        "context": "by (8.15), $\\begin{array}{r}{|\\mathbb{E}[X|\\mathcal{G}](\\omega_{n})|\\le\\int_{G_{n}}|X|d P/P(G_{n})}\\end{array}$ and\n\n$$\n\\begin{array}{r l r}{\\displaystyle\\int_{\\Omega}|{\\mathbb E}[X|\\mathcal{G}]|d P=\\sum_{n=1}^{\\infty}\\int_{G_{n}}|{\\mathbb E}[X|\\mathcal{G}]|d P}&{=}&{\\displaystyle\\sum_{n=1}^{\\infty}|{\\mathbb E}[X|\\mathcal{G}](\\omega_{n})|\\cdot P(G_{n})}\\\\ {\\displaystyle\\leq\\sum_{n=1}^{\\infty}\\int_{G_{n}}|X|d P}&{=}&{\\displaystyle\\int_{\\Omega}|X|d P={\\mathbb E}[|X|].~~~}\\end{array}\n$$\n\nHence $\\mathbb{E}[X|\\mathcal{G}]$ is integrable and $\\mathbb{E}[\\left\\lvert\\mathbb{E}[X|\\mathcal{G}]\\right\\rvert]\\leq\\mathbb{E}[\\left\\lvert X\\right\\rvert]$\n\nThe trivial $\\sigma$ -field $\\mathcal{F}_{\\varnothing}$ is countably generated and, since $P(\\Omega)=1$ , it follows that $\\mathbb{E}[X|\\mathcal{F}_{\\varnothing}](\\omega)=\\mathbb{E}[X]$ for all $\\omega\\in\\Omega$ . Hence we may identify $\\mathbb{E}[X]$ and the constant random variable $\\mathbb{E}[X|{\\mathcal{F}}_{\\varnothing}]$ and regard the expectation defined in the previous chapter as a special case of conditional expectation.\n\nOur next result characterizes conditional expectations in the countably generated case and extends, although we do not prove it, with a slightly weaker form of uniqueness to arbitrary conditional expectations.\n\nProposition 8.4. Let $(\\Omega,{\\mathcal{F}},P)$ denote a probability space and let $\\mathcal{G}$ denote a $\\sigma$ -field on $\\Omega$ generated by a countable partition $(G_{n})_{n=1}^{\\infty}$ of $\\Omega$ . We suppose ${\\mathcal{G}}\\subset{\\mathcal{F}}$ and $P(G_{n})\\,>\\,0$ for all $n$. If $X$ is an integrable random variable on $(\\Omega,{\\mathcal{F}},P)$, then $\\mathbb{E}[X|\\mathcal{G}]$ is the unique $\\mathcal{G}$ measurable integrable random variable on $(\\Omega,{\\mathcal{F}},P)$ satisfying\n\n$$\n\\int_{A}\\mathbb{E}[X|G]d P=\\int_{A}X d P\n$$\n\nfor all $A\\in{\\mathcal{G}}$\n\nProof. Let $n$ be arbitrary and let $\\omega\\in G_{n}$ . Since $\\mathbb{E}[X|\\mathcal{G}]$ is constant on each $G_{n}$ , it is $\\mathcal{G}$ measurable and\n\n$$\n\\begin{array}{r c l}{{\\displaystyle\\int_{G_{n}}\\mathbb{E}[X|\\mathcal{G}]d P}}&{{=}}&{{\\mathbb{E}[X|\\mathcal{G}](\\omega)\\cdot\\displaystyle\\int_{G_{n}}d P=\\left(\\frac{1}{P(G_{n})}\\int_{G_{n}}X d P\\right)\\cdot P(G_{n})}}\\\\ {{}}&{{}}&{{}}\\\\ {{}}&{{=}}&{{\\displaystyle\\int_{G_{n}}X d P.}}\\end{array}\n$$\n\nIf $A\\in{\\mathcal{G}}$ , then $A=\\textstyle\\bigcup_{n\\in M}G_{n}$ for some $M\\subset\\mathbf{N}$ . Hence\n\n$$\n\\begin{array}{r c l}{{\\displaystyle\\int_{A}\\mathbb{E}[X|\\mathcal{G}]d P}}&{{=}}&{{\\displaystyle\\int_{\\cup_{n\\in M}G_{n}}\\mathbb{E}[X|\\mathcal{G}]d P=\\sum_{n\\in M}\\int_{G_{n}}\\mathbb{E}[X|\\mathcal{G}]d P}}\\\\ {{}}&{{=}}&{{\\displaystyle\\sum_{n\\in M}\\int_{G_{n}}X d P=\\int_{\\cup_{n\\in M}G_{n}}X d P}}\\\\ {{}}&{{=}}&{{\\displaystyle\\int_{A}X d P.}}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "We suppose ${\\mathcal{G}}\\subset{\\mathcal{F}}$ and $P(G_{n})\\,>\\,0$ for all $n$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/(Graduate_Studies_in_Mathematics,070)_Sean_Dineen_-_Probability_Theory_in_Finance-American_Mathematical_Society_(2013).pdf_186",
        "ID": "1167d3f5-dfa6-4abe-9fe8-80c09e7f4775",
        "questions": "In the context of conditional expectations, how is $\\mathbb{E}[X|\\mathcal{F}_{\u000barnothing}]$ related to $\\mathbb{E}[X]$ for all $\\omega$ in $\\Omega$?",
        "answers": "$\\mathbb{E}[X|\\mathcal{F}_{\u000barnothing}](\\omega)=\\mathbb{E}[X]$ for all $\\omega\\in\\Omega$",
        "context": "by (8.15), $\\begin{array}{r}{|\\mathbb{E}[X|\\mathcal{G}](\\omega_{n})|\\le\\int_{G_{n}}|X|d P/P(G_{n})}\\end{array}$ and\n\n$$\n\\begin{array}{r l r}{\\displaystyle\\int_{\\Omega}|{\\mathbb E}[X|\\mathcal{G}]|d P=\\sum_{n=1}^{\\infty}\\int_{G_{n}}|{\\mathbb E}[X|\\mathcal{G}]|d P}&{=}&{\\displaystyle\\sum_{n=1}^{\\infty}|{\\mathbb E}[X|\\mathcal{G}](\\omega_{n})|\\cdot P(G_{n})}\\\\ {\\displaystyle\\leq\\sum_{n=1}^{\\infty}\\int_{G_{n}}|X|d P}&{=}&{\\displaystyle\\int_{\\Omega}|X|d P={\\mathbb E}[|X|].~~~}\\end{array}\n$$\n\nHence $\\mathbb{E}[X|\\mathcal{G}]$ is integrable and $\\mathbb{E}[\\left\\lvert\\mathbb{E}[X|\\mathcal{G}]\\right\\rvert]\\leq\\mathbb{E}[\\left\\lvert X\\right\\rvert]$\n\nThe trivial $\\sigma$ -field $\\mathcal{F}_{\\varnothing}$ is countably generated and, since $P(\\Omega)=1$ , it follows that $\\mathbb{E}[X|\\mathcal{F}_{\\varnothing}](\\omega)=\\mathbb{E}[X]$ for all $\\omega\\in\\Omega$ . Hence we may identify $\\mathbb{E}[X]$ and the constant random variable $\\mathbb{E}[X|{\\mathcal{F}}_{\\varnothing}]$ and regard the expectation defined in the previous chapter as a special case of conditional expectation.\n\nOur next result characterizes conditional expectations in the countably generated case and extends, although we do not prove it, with a slightly weaker form of uniqueness to arbitrary conditional expectations.\n\nProposition 8.4. Let $(\\Omega,{\\mathcal{F}},P)$ denote a probability space and let $\\mathcal{G}$ denote a $\\sigma$ -field on $\\Omega$ generated by a countable partition $(G_{n})_{n=1}^{\\infty}$ of $\\Omega$ . We suppose ${\\mathcal{G}}\\subset{\\mathcal{F}}$ and $P(G_{n})\\,>\\,0$ for all $n$. If $X$ is an integrable random variable on $(\\Omega,{\\mathcal{F}},P)$, then $\\mathbb{E}[X|\\mathcal{G}]$ is the unique $\\mathcal{G}$ measurable integrable random variable on $(\\Omega,{\\mathcal{F}},P)$ satisfying\n\n$$\n\\int_{A}\\mathbb{E}[X|G]d P=\\int_{A}X d P\n$$\n\nfor all $A\\in{\\mathcal{G}}$\n\nProof. Let $n$ be arbitrary and let $\\omega\\in G_{n}$ . Since $\\mathbb{E}[X|\\mathcal{G}]$ is constant on each $G_{n}$ , it is $\\mathcal{G}$ measurable and\n\n$$\n\\begin{array}{r c l}{{\\displaystyle\\int_{G_{n}}\\mathbb{E}[X|\\mathcal{G}]d P}}&{{=}}&{{\\mathbb{E}[X|\\mathcal{G}](\\omega)\\cdot\\displaystyle\\int_{G_{n}}d P=\\left(\\frac{1}{P(G_{n})}\\int_{G_{n}}X d P\\right)\\cdot P(G_{n})}}\\\\ {{}}&{{}}&{{}}\\\\ {{}}&{{=}}&{{\\displaystyle\\int_{G_{n}}X d P.}}\\end{array}\n$$\n\nIf $A\\in{\\mathcal{G}}$ , then $A=\\textstyle\\bigcup_{n\\in M}G_{n}$ for some $M\\subset\\mathbf{N}$ . Hence\n\n$$\n\\begin{array}{r c l}{{\\displaystyle\\int_{A}\\mathbb{E}[X|\\mathcal{G}]d P}}&{{=}}&{{\\displaystyle\\int_{\\cup_{n\\in M}G_{n}}\\mathbb{E}[X|\\mathcal{G}]d P=\\sum_{n\\in M}\\int_{G_{n}}\\mathbb{E}[X|\\mathcal{G}]d P}}\\\\ {{}}&{{=}}&{{\\displaystyle\\sum_{n\\in M}\\int_{G_{n}}X d P=\\int_{\\cup_{n\\in M}G_{n}}X d P}}\\\\ {{}}&{{=}}&{{\\displaystyle\\int_{A}X d P.}}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "it follows that $\\mathbb{E}[X|\\mathcal{F}_{\u000barnothing}](\\omega)=\\mathbb{E}[X]$ for all $\\omega\\in\\Omega$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/(Graduate_Studies_in_Mathematics,070)_Sean_Dineen_-_Probability_Theory_in_Finance-American_Mathematical_Society_(2013).pdf_186",
        "ID": "116b47e2-e046-4545-a0ab-75bf34b2a7da",
        "questions": "Does the document claim that $\\mathbb{E}[X|\\mathcal{G}]$ is integrable and satisfies the inequality with respect to $\\mathbb{E}[|X|]$?",
        "answers": "Yes",
        "context": "by (8.15), $\\begin{array}{r}{|\\mathbb{E}[X|\\mathcal{G}](\\omega_{n})|\\le\\int_{G_{n}}|X|d P/P(G_{n})}\\end{array}$ and\n\n$$\n\\begin{array}{r l r}{\\displaystyle\\int_{\\Omega}|{\\mathbb E}[X|\\mathcal{G}]|d P=\\sum_{n=1}^{\\infty}\\int_{G_{n}}|{\\mathbb E}[X|\\mathcal{G}]|d P}&{=}&{\\displaystyle\\sum_{n=1}^{\\infty}|{\\mathbb E}[X|\\mathcal{G}](\\omega_{n})|\\cdot P(G_{n})}\\\\ {\\displaystyle\\leq\\sum_{n=1}^{\\infty}\\int_{G_{n}}|X|d P}&{=}&{\\displaystyle\\int_{\\Omega}|X|d P={\\mathbb E}[|X|].~~~}\\end{array}\n$$\n\nHence $\\mathbb{E}[X|\\mathcal{G}]$ is integrable and $\\mathbb{E}[\\left\\lvert\\mathbb{E}[X|\\mathcal{G}]\\right\\rvert]\\leq\\mathbb{E}[\\left\\lvert X\\right\\rvert]$\n\nThe trivial $\\sigma$ -field $\\mathcal{F}_{\\varnothing}$ is countably generated and, since $P(\\Omega)=1$ , it follows that $\\mathbb{E}[X|\\mathcal{F}_{\\varnothing}](\\omega)=\\mathbb{E}[X]$ for all $\\omega\\in\\Omega$ . Hence we may identify $\\mathbb{E}[X]$ and the constant random variable $\\mathbb{E}[X|{\\mathcal{F}}_{\\varnothing}]$ and regard the expectation defined in the previous chapter as a special case of conditional expectation.\n\nOur next result characterizes conditional expectations in the countably generated case and extends, although we do not prove it, with a slightly weaker form of uniqueness to arbitrary conditional expectations.\n\nProposition 8.4. Let $(\\Omega,{\\mathcal{F}},P)$ denote a probability space and let $\\mathcal{G}$ denote a $\\sigma$ -field on $\\Omega$ generated by a countable partition $(G_{n})_{n=1}^{\\infty}$ of $\\Omega$ . We suppose ${\\mathcal{G}}\\subset{\\mathcal{F}}$ and $P(G_{n})\\,>\\,0$ for all $n$. If $X$ is an integrable random variable on $(\\Omega,{\\mathcal{F}},P)$, then $\\mathbb{E}[X|\\mathcal{G}]$ is the unique $\\mathcal{G}$ measurable integrable random variable on $(\\Omega,{\\mathcal{F}},P)$ satisfying\n\n$$\n\\int_{A}\\mathbb{E}[X|G]d P=\\int_{A}X d P\n$$\n\nfor all $A\\in{\\mathcal{G}}$\n\nProof. Let $n$ be arbitrary and let $\\omega\\in G_{n}$ . Since $\\mathbb{E}[X|\\mathcal{G}]$ is constant on each $G_{n}$ , it is $\\mathcal{G}$ measurable and\n\n$$\n\\begin{array}{r c l}{{\\displaystyle\\int_{G_{n}}\\mathbb{E}[X|\\mathcal{G}]d P}}&{{=}}&{{\\mathbb{E}[X|\\mathcal{G}](\\omega)\\cdot\\displaystyle\\int_{G_{n}}d P=\\left(\\frac{1}{P(G_{n})}\\int_{G_{n}}X d P\\right)\\cdot P(G_{n})}}\\\\ {{}}&{{}}&{{}}\\\\ {{}}&{{=}}&{{\\displaystyle\\int_{G_{n}}X d P.}}\\end{array}\n$$\n\nIf $A\\in{\\mathcal{G}}$ , then $A=\\textstyle\\bigcup_{n\\in M}G_{n}$ for some $M\\subset\\mathbf{N}$ . Hence\n\n$$\n\\begin{array}{r c l}{{\\displaystyle\\int_{A}\\mathbb{E}[X|\\mathcal{G}]d P}}&{{=}}&{{\\displaystyle\\int_{\\cup_{n\\in M}G_{n}}\\mathbb{E}[X|\\mathcal{G}]d P=\\sum_{n\\in M}\\int_{G_{n}}\\mathbb{E}[X|\\mathcal{G}]d P}}\\\\ {{}}&{{=}}&{{\\displaystyle\\sum_{n\\in M}\\int_{G_{n}}X d P=\\int_{\\cup_{n\\in M}G_{n}}X d P}}\\\\ {{}}&{{=}}&{{\\displaystyle\\int_{A}X d P.}}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Yes/No",
        "evidence_source": "text",
        "evidence_context": "Hence $\\mathbb{E}[X|\\mathcal{G}]$ is integrable and $\\mathbb{E}[\\left\\lvert\\mathbb{E}[X|\\mathcal{G}]\right\rvert]\\leq\\mathbb{E}[\\left\\lvert X\right\rvert]$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/(Graduate_Studies_in_Mathematics,070)_Sean_Dineen_-_Probability_Theory_in_Finance-American_Mathematical_Society_(2013).pdf_186",
        "ID": "116c00eb-243f-42b4-ab25-68c03c82b15f",
        "questions": "What condition must the probability of each partition $G_n$ in the countable partition of $\\Omega$ satisfy in the context of conditional expectation in Proposition 8.4?",
        "answers": "$P(G_{n})\\,>\\,0$ for all $n$",
        "context": "by (8.15), $\\begin{array}{r}{|\\mathbb{E}[X|\\mathcal{G}](\\omega_{n})|\\le\\int_{G_{n}}|X|d P/P(G_{n})}\\end{array}$ and\n\n$$\n\\begin{array}{r l r}{\\displaystyle\\int_{\\Omega}|{\\mathbb E}[X|\\mathcal{G}]|d P=\\sum_{n=1}^{\\infty}\\int_{G_{n}}|{\\mathbb E}[X|\\mathcal{G}]|d P}&{=}&{\\displaystyle\\sum_{n=1}^{\\infty}|{\\mathbb E}[X|\\mathcal{G}](\\omega_{n})|\\cdot P(G_{n})}\\\\ {\\displaystyle\\leq\\sum_{n=1}^{\\infty}\\int_{G_{n}}|X|d P}&{=}&{\\displaystyle\\int_{\\Omega}|X|d P={\\mathbb E}[|X|].~~~}\\end{array}\n$$\n\nHence $\\mathbb{E}[X|\\mathcal{G}]$ is integrable and $\\mathbb{E}[\\left\\lvert\\mathbb{E}[X|\\mathcal{G}]\\right\\rvert]\\leq\\mathbb{E}[\\left\\lvert X\\right\\rvert]$\n\nThe trivial $\\sigma$ -field $\\mathcal{F}_{\\varnothing}$ is countably generated and, since $P(\\Omega)=1$ , it follows that $\\mathbb{E}[X|\\mathcal{F}_{\\varnothing}](\\omega)=\\mathbb{E}[X]$ for all $\\omega\\in\\Omega$ . Hence we may identify $\\mathbb{E}[X]$ and the constant random variable $\\mathbb{E}[X|{\\mathcal{F}}_{\\varnothing}]$ and regard the expectation defined in the previous chapter as a special case of conditional expectation.\n\nOur next result characterizes conditional expectations in the countably generated case and extends, although we do not prove it, with a slightly weaker form of uniqueness to arbitrary conditional expectations.\n\nProposition 8.4. Let $(\\Omega,{\\mathcal{F}},P)$ denote a probability space and let $\\mathcal{G}$ denote a $\\sigma$ -field on $\\Omega$ generated by a countable partition $(G_{n})_{n=1}^{\\infty}$ of $\\Omega$ . We suppose ${\\mathcal{G}}\\subset{\\mathcal{F}}$ and $P(G_{n})\\,>\\,0$ for all $n$. If $X$ is an integrable random variable on $(\\Omega,{\\mathcal{F}},P)$, then $\\mathbb{E}[X|\\mathcal{G}]$ is the unique $\\mathcal{G}$ measurable integrable random variable on $(\\Omega,{\\mathcal{F}},P)$ satisfying\n\n$$\n\\int_{A}\\mathbb{E}[X|G]d P=\\int_{A}X d P\n$$\n\nfor all $A\\in{\\mathcal{G}}$\n\nProof. Let $n$ be arbitrary and let $\\omega\\in G_{n}$ . Since $\\mathbb{E}[X|\\mathcal{G}]$ is constant on each $G_{n}$ , it is $\\mathcal{G}$ measurable and\n\n$$\n\\begin{array}{r c l}{{\\displaystyle\\int_{G_{n}}\\mathbb{E}[X|\\mathcal{G}]d P}}&{{=}}&{{\\mathbb{E}[X|\\mathcal{G}](\\omega)\\cdot\\displaystyle\\int_{G_{n}}d P=\\left(\\frac{1}{P(G_{n})}\\int_{G_{n}}X d P\\right)\\cdot P(G_{n})}}\\\\ {{}}&{{}}&{{}}\\\\ {{}}&{{=}}&{{\\displaystyle\\int_{G_{n}}X d P.}}\\end{array}\n$$\n\nIf $A\\in{\\mathcal{G}}$ , then $A=\\textstyle\\bigcup_{n\\in M}G_{n}$ for some $M\\subset\\mathbf{N}$ . Hence\n\n$$\n\\begin{array}{r c l}{{\\displaystyle\\int_{A}\\mathbb{E}[X|\\mathcal{G}]d P}}&{{=}}&{{\\displaystyle\\int_{\\cup_{n\\in M}G_{n}}\\mathbb{E}[X|\\mathcal{G}]d P=\\sum_{n\\in M}\\int_{G_{n}}\\mathbb{E}[X|\\mathcal{G}]d P}}\\\\ {{}}&{{=}}&{{\\displaystyle\\sum_{n\\in M}\\int_{G_{n}}X d P=\\int_{\\cup_{n\\in M}G_{n}}X d P}}\\\\ {{}}&{{=}}&{{\\displaystyle\\int_{A}X d P.}}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "We suppose ${\\mathcal{G}}\\subset{\\mathcal{F}}$ and $P(G_{n})\\,>\\,0$ for all $n$.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/(Graduate_Studies_in_Mathematics,070)_Sean_Dineen_-_Probability_Theory_in_Finance-American_Mathematical_Society_(2013).pdf_186",
        "ID": "116d5d35-e4a8-4e2b-9286-3cd3658df18f",
        "questions": "How is the integral of the conditional expectation $\\mathbb{E}[X|\\mathcal{G}]$ over a set $A$ in $\\mathcal{G}$ expressed in terms of integrals over the countable partition $G_n$?",
        "answers": "$\\int_{A}\\mathbb{E}[X|\\mathcal{G}]d P=\\sum_{n\\in M}\\int_{G_{n}}\\mathbb{E}[X|\\mathcal{G}]d P=\\sum_{n\\in M}\\int_{G_{n}}X d P=\\int_{A}X d P.$",
        "context": "by (8.15), $\\begin{array}{r}{|\\mathbb{E}[X|\\mathcal{G}](\\omega_{n})|\\le\\int_{G_{n}}|X|d P/P(G_{n})}\\end{array}$ and\n\n$$\n\\begin{array}{r l r}{\\displaystyle\\int_{\\Omega}|{\\mathbb E}[X|\\mathcal{G}]|d P=\\sum_{n=1}^{\\infty}\\int_{G_{n}}|{\\mathbb E}[X|\\mathcal{G}]|d P}&{=}&{\\displaystyle\\sum_{n=1}^{\\infty}|{\\mathbb E}[X|\\mathcal{G}](\\omega_{n})|\\cdot P(G_{n})}\\\\ {\\displaystyle\\leq\\sum_{n=1}^{\\infty}\\int_{G_{n}}|X|d P}&{=}&{\\displaystyle\\int_{\\Omega}|X|d P={\\mathbb E}[|X|].~~~}\\end{array}\n$$\n\nHence $\\mathbb{E}[X|\\mathcal{G}]$ is integrable and $\\mathbb{E}[\\left\\lvert\\mathbb{E}[X|\\mathcal{G}]\\right\\rvert]\\leq\\mathbb{E}[\\left\\lvert X\\right\\rvert]$\n\nThe trivial $\\sigma$ -field $\\mathcal{F}_{\\varnothing}$ is countably generated and, since $P(\\Omega)=1$ , it follows that $\\mathbb{E}[X|\\mathcal{F}_{\\varnothing}](\\omega)=\\mathbb{E}[X]$ for all $\\omega\\in\\Omega$ . Hence we may identify $\\mathbb{E}[X]$ and the constant random variable $\\mathbb{E}[X|{\\mathcal{F}}_{\\varnothing}]$ and regard the expectation defined in the previous chapter as a special case of conditional expectation.\n\nOur next result characterizes conditional expectations in the countably generated case and extends, although we do not prove it, with a slightly weaker form of uniqueness to arbitrary conditional expectations.\n\nProposition 8.4. Let $(\\Omega,{\\mathcal{F}},P)$ denote a probability space and let $\\mathcal{G}$ denote a $\\sigma$ -field on $\\Omega$ generated by a countable partition $(G_{n})_{n=1}^{\\infty}$ of $\\Omega$ . We suppose ${\\mathcal{G}}\\subset{\\mathcal{F}}$ and $P(G_{n})\\,>\\,0$ for all $n$. If $X$ is an integrable random variable on $(\\Omega,{\\mathcal{F}},P)$, then $\\mathbb{E}[X|\\mathcal{G}]$ is the unique $\\mathcal{G}$ measurable integrable random variable on $(\\Omega,{\\mathcal{F}},P)$ satisfying\n\n$$\n\\int_{A}\\mathbb{E}[X|G]d P=\\int_{A}X d P\n$$\n\nfor all $A\\in{\\mathcal{G}}$\n\nProof. Let $n$ be arbitrary and let $\\omega\\in G_{n}$ . Since $\\mathbb{E}[X|\\mathcal{G}]$ is constant on each $G_{n}$ , it is $\\mathcal{G}$ measurable and\n\n$$\n\\begin{array}{r c l}{{\\displaystyle\\int_{G_{n}}\\mathbb{E}[X|\\mathcal{G}]d P}}&{{=}}&{{\\mathbb{E}[X|\\mathcal{G}](\\omega)\\cdot\\displaystyle\\int_{G_{n}}d P=\\left(\\frac{1}{P(G_{n})}\\int_{G_{n}}X d P\\right)\\cdot P(G_{n})}}\\\\ {{}}&{{}}&{{}}\\\\ {{}}&{{=}}&{{\\displaystyle\\int_{G_{n}}X d P.}}\\end{array}\n$$\n\nIf $A\\in{\\mathcal{G}}$ , then $A=\\textstyle\\bigcup_{n\\in M}G_{n}$ for some $M\\subset\\mathbf{N}$ . Hence\n\n$$\n\\begin{array}{r c l}{{\\displaystyle\\int_{A}\\mathbb{E}[X|\\mathcal{G}]d P}}&{{=}}&{{\\displaystyle\\int_{\\cup_{n\\in M}G_{n}}\\mathbb{E}[X|\\mathcal{G}]d P=\\sum_{n\\in M}\\int_{G_{n}}\\mathbb{E}[X|\\mathcal{G}]d P}}\\\\ {{}}&{{=}}&{{\\displaystyle\\sum_{n\\in M}\\int_{G_{n}}X d P=\\int_{\\cup_{n\\in M}G_{n}}X d P}}\\\\ {{}}&{{=}}&{{\\displaystyle\\int_{A}X d P.}}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$\\int_{A}\\mathbb{E}[X|\\mathcal{G}]d P=\\sum_{n\\in M}\\int_{G_{n}}\\mathbb{E}[X|\\mathcal{G}]d P=\\sum_{n\\in M}\\int_{G_{n}}X d P=\\int_{A}X d P.$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/(Graduate_Studies_in_Mathematics,070)_Sean_Dineen_-_Probability_Theory_in_Finance-American_Mathematical_Society_(2013).pdf_186",
        "ID": "116febe7-aa0c-4327-9daa-42fc90b15e3d",
        "questions": "What mathematical operation characterizes the conditional expectation $\\mathbb{E}[X | \\mathcal{G}]$ over a partition set $G_n$ in terms of the integral of $X$ over $G_n$?",
        "answers": "$\\int_{G_{n}}\\mathbb{E}[X|\\mathcal{G}]d P = \\mathbb{E}[X|\\mathcal{G}](\\omega)\\cdot\\int_{G_{n}}d P=\\left(\frac{1}{P(G_{n})}\\int_{G_{n}}X d P\right)\\cdot P(G_{n})=\\int_{G_{n}}X d P.$",
        "context": "by (8.15), $\\begin{array}{r}{|\\mathbb{E}[X|\\mathcal{G}](\\omega_{n})|\\le\\int_{G_{n}}|X|d P/P(G_{n})}\\end{array}$ and\n\n$$\n\\begin{array}{r l r}{\\displaystyle\\int_{\\Omega}|{\\mathbb E}[X|\\mathcal{G}]|d P=\\sum_{n=1}^{\\infty}\\int_{G_{n}}|{\\mathbb E}[X|\\mathcal{G}]|d P}&{=}&{\\displaystyle\\sum_{n=1}^{\\infty}|{\\mathbb E}[X|\\mathcal{G}](\\omega_{n})|\\cdot P(G_{n})}\\\\ {\\displaystyle\\leq\\sum_{n=1}^{\\infty}\\int_{G_{n}}|X|d P}&{=}&{\\displaystyle\\int_{\\Omega}|X|d P={\\mathbb E}[|X|].~~~}\\end{array}\n$$\n\nHence $\\mathbb{E}[X|\\mathcal{G}]$ is integrable and $\\mathbb{E}[\\left\\lvert\\mathbb{E}[X|\\mathcal{G}]\\right\\rvert]\\leq\\mathbb{E}[\\left\\lvert X\\right\\rvert]$\n\nThe trivial $\\sigma$ -field $\\mathcal{F}_{\\varnothing}$ is countably generated and, since $P(\\Omega)=1$ , it follows that $\\mathbb{E}[X|\\mathcal{F}_{\\varnothing}](\\omega)=\\mathbb{E}[X]$ for all $\\omega\\in\\Omega$ . Hence we may identify $\\mathbb{E}[X]$ and the constant random variable $\\mathbb{E}[X|{\\mathcal{F}}_{\\varnothing}]$ and regard the expectation defined in the previous chapter as a special case of conditional expectation.\n\nOur next result characterizes conditional expectations in the countably generated case and extends, although we do not prove it, with a slightly weaker form of uniqueness to arbitrary conditional expectations.\n\nProposition 8.4. Let $(\\Omega,{\\mathcal{F}},P)$ denote a probability space and let $\\mathcal{G}$ denote a $\\sigma$ -field on $\\Omega$ generated by a countable partition $(G_{n})_{n=1}^{\\infty}$ of $\\Omega$ . We suppose ${\\mathcal{G}}\\subset{\\mathcal{F}}$ and $P(G_{n})\\,>\\,0$ for all $n$. If $X$ is an integrable random variable on $(\\Omega,{\\mathcal{F}},P)$, then $\\mathbb{E}[X|\\mathcal{G}]$ is the unique $\\mathcal{G}$ measurable integrable random variable on $(\\Omega,{\\mathcal{F}},P)$ satisfying\n\n$$\n\\int_{A}\\mathbb{E}[X|G]d P=\\int_{A}X d P\n$$\n\nfor all $A\\in{\\mathcal{G}}$\n\nProof. Let $n$ be arbitrary and let $\\omega\\in G_{n}$ . Since $\\mathbb{E}[X|\\mathcal{G}]$ is constant on each $G_{n}$ , it is $\\mathcal{G}$ measurable and\n\n$$\n\\begin{array}{r c l}{{\\displaystyle\\int_{G_{n}}\\mathbb{E}[X|\\mathcal{G}]d P}}&{{=}}&{{\\mathbb{E}[X|\\mathcal{G}](\\omega)\\cdot\\displaystyle\\int_{G_{n}}d P=\\left(\\frac{1}{P(G_{n})}\\int_{G_{n}}X d P\\right)\\cdot P(G_{n})}}\\\\ {{}}&{{}}&{{}}\\\\ {{}}&{{=}}&{{\\displaystyle\\int_{G_{n}}X d P.}}\\end{array}\n$$\n\nIf $A\\in{\\mathcal{G}}$ , then $A=\\textstyle\\bigcup_{n\\in M}G_{n}$ for some $M\\subset\\mathbf{N}$ . Hence\n\n$$\n\\begin{array}{r c l}{{\\displaystyle\\int_{A}\\mathbb{E}[X|\\mathcal{G}]d P}}&{{=}}&{{\\displaystyle\\int_{\\cup_{n\\in M}G_{n}}\\mathbb{E}[X|\\mathcal{G}]d P=\\sum_{n\\in M}\\int_{G_{n}}\\mathbb{E}[X|\\mathcal{G}]d P}}\\\\ {{}}&{{=}}&{{\\displaystyle\\sum_{n\\in M}\\int_{G_{n}}X d P=\\int_{\\cup_{n\\in M}G_{n}}X d P}}\\\\ {{}}&{{=}}&{{\\displaystyle\\int_{A}X d P.}}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$\\int_{G_{n}}\\mathbb{E}[X|\\mathcal{G}]d P = \\mathbb{E}[X|\\mathcal{G}](\\omega)\\cdot\\int_{G_{n}}d P=\\left(\frac{1}{P(G_{n})}\\int_{G_{n}}X d P\right)\\cdot P(G_{n})=\\int_{G_{n}}X d P.$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/[Sin-Itiro_Tomonaga]_Quantum_Mechanics_Vol.2(BookZZ.org).pdf_220",
        "ID": "117d0b17-70f4-48cd-acb0-08dcb00c1552",
        "questions": "What is the width of the domain around $p^0$ within which the values of $p$ are essentially contained according to the given probability density formula for momentum?",
        "answers": "$h/2\\pi\\delta$",
        "context": "The probability density that the momentum assumes a value in the vicinity of $p$ is, then, given by  \n\n$$\nP(p)=\\frac{2\\pi^{\\frac{1}{2}}\\delta}{h}\\exp\\Big\\{-\\,\\left(\\frac{2\\pi}{h}\\right)^{2}\\,\\delta^{2}(p\\!-\\!p^{0})^{2}\\Big\\},\n$$  \n\nwhich implies that the values of $p$ are essentially within the domain of width $h/2\\pi\\delta$ around $p^{0}$.  \n\nThe probability density of the coordinate $q$ for $\\psi$ of Eq. (59.12), by the way, is given by  \n\n$$\nP(q)=\\frac{1}{\\bar{\\pi}^{\\frac{1}{2}}\\delta}\\exp\\Big\\{-\\frac{1}{\\delta^{2}}\\,(q\\!-\\!q^{0})^{2}\\Big\\}.\n$$  \n\n(iv) The Uncertainty Relation  \n\nThe two uncertainties $(\\varDelta q$ and $\\varDelta p)$ obtained in the last subsection seem to show a reciprocal relation. Namely, according to Eqs. (59.14) and (59.17), respectively,  \n\n$$\n\\begin{array}{l}{{\\varDelta q=\\frac{1}{\\sqrt{2}}\\,\\delta}}\\\\ {{\\varDelta p=\\left(\\frac{h}{2\\pi}\\right)\\frac{1}{\\delta\\sqrt{2}}\\,.}}\\end{array}\n$$  \n\nThat is, $\\varDelta q$ is proportional to $\\delta$ while $\\varDelta p$ is to $1/\\delta$. Therefore, an effort to reduce $\\varDelta q$ inevitably causes an increase in $\\varDelta p$ and vice versa.  \n\nFrom Eq. (59.20) we find that  \n\n$$\n\\varDelta p\\cdot\\varDelta q={\\textstyle{\\frac{1}{2}}}{\\frac{h}{2\\pi}}\\,.\n$$  \n\nIt says, for instance, that $\\varDelta\\phi$ approaches infinity if $\\varDelta q$ tends to 0, and $\\varDelta q$ approaches infinity if $\\varDelta p$ tends to 0. In other words, in a state in which the coordinate has a definite value, the value of momentum is completely indefinite, and in a state in which the momentum has a definite value, the value of coordinate is completely indefinite.  \n\nThe relation (59.21) has been derived from the consideration of a specific wave packet of the form of Eq. (59.12). The question is then, what happens if we take a state other than that chosen here? We give the answer first. For a general $\\psi_{i}$, the relation given in Eq. (59.21) does not necessarily hold, but the product $\\varDelta p \\varDelta q$ never becomes smaller than the value given by Eq. (59.21). We have namely",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "which implies that the values of $p$ are essentially within the domain of width $h/2\\pi\\delta$ around $p^{0}$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/[Sin-Itiro_Tomonaga]_Quantum_Mechanics_Vol.2(BookZZ.org).pdf_220",
        "ID": "11870fe4-41b4-49bd-aa80-c8090af84578",
        "questions": "What happens to $\u000barDelta q$ and $\u000barDelta p$ in a state where the coordinate has a definite value?",
        "answers": "the value of momentum is completely indefinite",
        "context": "The probability density that the momentum assumes a value in the vicinity of $p$ is, then, given by  \n\n$$\nP(p)=\\frac{2\\pi^{\\frac{1}{2}}\\delta}{h}\\exp\\Big\\{-\\,\\left(\\frac{2\\pi}{h}\\right)^{2}\\,\\delta^{2}(p\\!-\\!p^{0})^{2}\\Big\\},\n$$  \n\nwhich implies that the values of $p$ are essentially within the domain of width $h/2\\pi\\delta$ around $p^{0}$.  \n\nThe probability density of the coordinate $q$ for $\\psi$ of Eq. (59.12), by the way, is given by  \n\n$$\nP(q)=\\frac{1}{\\bar{\\pi}^{\\frac{1}{2}}\\delta}\\exp\\Big\\{-\\frac{1}{\\delta^{2}}\\,(q\\!-\\!q^{0})^{2}\\Big\\}.\n$$  \n\n(iv) The Uncertainty Relation  \n\nThe two uncertainties $(\\varDelta q$ and $\\varDelta p)$ obtained in the last subsection seem to show a reciprocal relation. Namely, according to Eqs. (59.14) and (59.17), respectively,  \n\n$$\n\\begin{array}{l}{{\\varDelta q=\\frac{1}{\\sqrt{2}}\\,\\delta}}\\\\ {{\\varDelta p=\\left(\\frac{h}{2\\pi}\\right)\\frac{1}{\\delta\\sqrt{2}}\\,.}}\\end{array}\n$$  \n\nThat is, $\\varDelta q$ is proportional to $\\delta$ while $\\varDelta p$ is to $1/\\delta$. Therefore, an effort to reduce $\\varDelta q$ inevitably causes an increase in $\\varDelta p$ and vice versa.  \n\nFrom Eq. (59.20) we find that  \n\n$$\n\\varDelta p\\cdot\\varDelta q={\\textstyle{\\frac{1}{2}}}{\\frac{h}{2\\pi}}\\,.\n$$  \n\nIt says, for instance, that $\\varDelta\\phi$ approaches infinity if $\\varDelta q$ tends to 0, and $\\varDelta q$ approaches infinity if $\\varDelta p$ tends to 0. In other words, in a state in which the coordinate has a definite value, the value of momentum is completely indefinite, and in a state in which the momentum has a definite value, the value of coordinate is completely indefinite.  \n\nThe relation (59.21) has been derived from the consideration of a specific wave packet of the form of Eq. (59.12). The question is then, what happens if we take a state other than that chosen here? We give the answer first. For a general $\\psi_{i}$, the relation given in Eq. (59.21) does not necessarily hold, but the product $\\varDelta p \\varDelta q$ never becomes smaller than the value given by Eq. (59.21). We have namely",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "In other words, in a state in which the coordinate has a definite value, the value of momentum is completely indefinite, and in a state in which the momentum has a definite value, the value of coordinate is completely indefinite.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/[Sin-Itiro_Tomonaga]_Quantum_Mechanics_Vol.2(BookZZ.org).pdf_220",
        "ID": "1197a1ae-a4ad-4b24-90ae-180f7af5613d",
        "questions": "Does the product $\u000barDelta p \u000barDelta q$ ever become smaller than ${\textstyle{\frac{1}{2}}}{\frac{h}{2\\pi}}$ for a general $\\psi_{i}$?",
        "answers": "No",
        "context": "The probability density that the momentum assumes a value in the vicinity of $p$ is, then, given by  \n\n$$\nP(p)=\\frac{2\\pi^{\\frac{1}{2}}\\delta}{h}\\exp\\Big\\{-\\,\\left(\\frac{2\\pi}{h}\\right)^{2}\\,\\delta^{2}(p\\!-\\!p^{0})^{2}\\Big\\},\n$$  \n\nwhich implies that the values of $p$ are essentially within the domain of width $h/2\\pi\\delta$ around $p^{0}$.  \n\nThe probability density of the coordinate $q$ for $\\psi$ of Eq. (59.12), by the way, is given by  \n\n$$\nP(q)=\\frac{1}{\\bar{\\pi}^{\\frac{1}{2}}\\delta}\\exp\\Big\\{-\\frac{1}{\\delta^{2}}\\,(q\\!-\\!q^{0})^{2}\\Big\\}.\n$$  \n\n(iv) The Uncertainty Relation  \n\nThe two uncertainties $(\\varDelta q$ and $\\varDelta p)$ obtained in the last subsection seem to show a reciprocal relation. Namely, according to Eqs. (59.14) and (59.17), respectively,  \n\n$$\n\\begin{array}{l}{{\\varDelta q=\\frac{1}{\\sqrt{2}}\\,\\delta}}\\\\ {{\\varDelta p=\\left(\\frac{h}{2\\pi}\\right)\\frac{1}{\\delta\\sqrt{2}}\\,.}}\\end{array}\n$$  \n\nThat is, $\\varDelta q$ is proportional to $\\delta$ while $\\varDelta p$ is to $1/\\delta$. Therefore, an effort to reduce $\\varDelta q$ inevitably causes an increase in $\\varDelta p$ and vice versa.  \n\nFrom Eq. (59.20) we find that  \n\n$$\n\\varDelta p\\cdot\\varDelta q={\\textstyle{\\frac{1}{2}}}{\\frac{h}{2\\pi}}\\,.\n$$  \n\nIt says, for instance, that $\\varDelta\\phi$ approaches infinity if $\\varDelta q$ tends to 0, and $\\varDelta q$ approaches infinity if $\\varDelta p$ tends to 0. In other words, in a state in which the coordinate has a definite value, the value of momentum is completely indefinite, and in a state in which the momentum has a definite value, the value of coordinate is completely indefinite.  \n\nThe relation (59.21) has been derived from the consideration of a specific wave packet of the form of Eq. (59.12). The question is then, what happens if we take a state other than that chosen here? We give the answer first. For a general $\\psi_{i}$, the relation given in Eq. (59.21) does not necessarily hold, but the product $\\varDelta p \\varDelta q$ never becomes smaller than the value given by Eq. (59.21). We have namely",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Yes/No",
        "evidence_source": "text",
        "evidence_context": "For a general $\\psi_{i}$, the relation given in Eq. (59.21) does not necessarily hold, but the product $\u000barDelta p \u000barDelta q$ never becomes smaller than the value given by Eq. (59.21).",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/[Sin-Itiro_Tomonaga]_Quantum_Mechanics_Vol.2(BookZZ.org).pdf_220",
        "ID": "119a7034-8817-446b-b100-a5ca6589a70b",
        "questions": "What is the probability density function of momentum $p$ is near $p^0$ given the parameters $h$ and $\\delta$?",
        "answers": "$P(p)=\\frac{2\\pi^{\\frac{1}{2}}\\delta}{h}\\exp\\Big\\{-\\,\\left(\\frac{2\\pi}{h}\\right)^{2}\\,\\delta^{2}(p\\!\\-\\!p^{0})^{2}\\Big\\}$",
        "context": "The probability density that the momentum assumes a value in the vicinity of $p$ is, then, given by  \n\n$$\nP(p)=\\frac{2\\pi^{\\frac{1}{2}}\\delta}{h}\\exp\\Big\\{-\\,\\left(\\frac{2\\pi}{h}\\right)^{2}\\,\\delta^{2}(p\\!-\\!p^{0})^{2}\\Big\\},\n$$  \n\nwhich implies that the values of $p$ are essentially within the domain of width $h/2\\pi\\delta$ around $p^{0}$.  \n\nThe probability density of the coordinate $q$ for $\\psi$ of Eq. (59.12), by the way, is given by  \n\n$$\nP(q)=\\frac{1}{\\bar{\\pi}^{\\frac{1}{2}}\\delta}\\exp\\Big\\{-\\frac{1}{\\delta^{2}}\\,(q\\!-\\!q^{0})^{2}\\Big\\}.\n$$  \n\n(iv) The Uncertainty Relation  \n\nThe two uncertainties $(\\varDelta q$ and $\\varDelta p)$ obtained in the last subsection seem to show a reciprocal relation. Namely, according to Eqs. (59.14) and (59.17), respectively,  \n\n$$\n\\begin{array}{l}{{\\varDelta q=\\frac{1}{\\sqrt{2}}\\,\\delta}}\\\\ {{\\varDelta p=\\left(\\frac{h}{2\\pi}\\right)\\frac{1}{\\delta\\sqrt{2}}\\,.}}\\end{array}\n$$  \n\nThat is, $\\varDelta q$ is proportional to $\\delta$ while $\\varDelta p$ is to $1/\\delta$. Therefore, an effort to reduce $\\varDelta q$ inevitably causes an increase in $\\varDelta p$ and vice versa.  \n\nFrom Eq. (59.20) we find that  \n\n$$\n\\varDelta p\\cdot\\varDelta q={\\textstyle{\\frac{1}{2}}}{\\frac{h}{2\\pi}}\\,.\n$$  \n\nIt says, for instance, that $\\varDelta\\phi$ approaches infinity if $\\varDelta q$ tends to 0, and $\\varDelta q$ approaches infinity if $\\varDelta p$ tends to 0. In other words, in a state in which the coordinate has a definite value, the value of momentum is completely indefinite, and in a state in which the momentum has a definite value, the value of coordinate is completely indefinite.  \n\nThe relation (59.21) has been derived from the consideration of a specific wave packet of the form of Eq. (59.12). The question is then, what happens if we take a state other than that chosen here? We give the answer first. For a general $\\psi_{i}$, the relation given in Eq. (59.21) does not necessarily hold, but the product $\\varDelta p \\varDelta q$ never becomes smaller than the value given by Eq. (59.21). We have namely",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$P(p)=\\frac{2\\pi^{\\frac{1}{2}}\\delta}{h}\\exp\\Big\\{-\\,\\left(\\frac{2\\pi}{h}\\right)^{2}\\,\\delta^{2}(p\\!\\-\\!p^{0})^{2}\\Big\\},$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/[Sin-Itiro_Tomonaga]_Quantum_Mechanics_Vol.2(BookZZ.org).pdf_220",
        "ID": "119aa71b-f6bf-47b5-9f46-fe0222087f22",
        "questions": "Calculate the product of uncertainties $\u000barDelta p$ and $\u000barDelta q$ using $h$ and $\\pi$.",
        "answers": "$\\varDelta p\\cdot\\varDelta q={\\textstyle{\\frac{1}{2}}}{\\frac{h}{2\\pi}}\\,$",
        "context": "The probability density that the momentum assumes a value in the vicinity of $p$ is, then, given by  \n\n$$\nP(p)=\\frac{2\\pi^{\\frac{1}{2}}\\delta}{h}\\exp\\Big\\{-\\,\\left(\\frac{2\\pi}{h}\\right)^{2}\\,\\delta^{2}(p\\!-\\!p^{0})^{2}\\Big\\},\n$$  \n\nwhich implies that the values of $p$ are essentially within the domain of width $h/2\\pi\\delta$ around $p^{0}$.  \n\nThe probability density of the coordinate $q$ for $\\psi$ of Eq. (59.12), by the way, is given by  \n\n$$\nP(q)=\\frac{1}{\\bar{\\pi}^{\\frac{1}{2}}\\delta}\\exp\\Big\\{-\\frac{1}{\\delta^{2}}\\,(q\\!-\\!q^{0})^{2}\\Big\\}.\n$$  \n\n(iv) The Uncertainty Relation  \n\nThe two uncertainties $(\\varDelta q$ and $\\varDelta p)$ obtained in the last subsection seem to show a reciprocal relation. Namely, according to Eqs. (59.14) and (59.17), respectively,  \n\n$$\n\\begin{array}{l}{{\\varDelta q=\\frac{1}{\\sqrt{2}}\\,\\delta}}\\\\ {{\\varDelta p=\\left(\\frac{h}{2\\pi}\\right)\\frac{1}{\\delta\\sqrt{2}}\\,.}}\\end{array}\n$$  \n\nThat is, $\\varDelta q$ is proportional to $\\delta$ while $\\varDelta p$ is to $1/\\delta$. Therefore, an effort to reduce $\\varDelta q$ inevitably causes an increase in $\\varDelta p$ and vice versa.  \n\nFrom Eq. (59.20) we find that  \n\n$$\n\\varDelta p\\cdot\\varDelta q={\\textstyle{\\frac{1}{2}}}{\\frac{h}{2\\pi}}\\,.\n$$  \n\nIt says, for instance, that $\\varDelta\\phi$ approaches infinity if $\\varDelta q$ tends to 0, and $\\varDelta q$ approaches infinity if $\\varDelta p$ tends to 0. In other words, in a state in which the coordinate has a definite value, the value of momentum is completely indefinite, and in a state in which the momentum has a definite value, the value of coordinate is completely indefinite.  \n\nThe relation (59.21) has been derived from the consideration of a specific wave packet of the form of Eq. (59.12). The question is then, what happens if we take a state other than that chosen here? We give the answer first. For a general $\\psi_{i}$, the relation given in Eq. (59.21) does not necessarily hold, but the product $\\varDelta p \\varDelta q$ never becomes smaller than the value given by Eq. (59.21). We have namely",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Numeric",
        "evidence_source": "equation",
        "evidence_context": "$\\varDelta p\\cdot\\varDelta q={\\textstyle{\\frac{1}{2}}}{\\frac{h}{2\\pi}}\\,$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/[Sin-Itiro_Tomonaga]_Quantum_Mechanics_Vol.2(BookZZ.org).pdf_220",
        "ID": "11a4e0a9-f52a-4dbe-8279-1be8bbee3ce8",
        "questions": "What is the expression for $\u000barDelta p$ if $\\delta$ is a factor in the uncertainty relation involving $h$ and $\\pi$?",
        "answers": "$\\varDelta p=\\left(\\frac{h}{2\\pi}\\right)\\frac{1}{\\delta\\sqrt{2}}\\,.$",
        "context": "The probability density that the momentum assumes a value in the vicinity of $p$ is, then, given by  \n\n$$\nP(p)=\\frac{2\\pi^{\\frac{1}{2}}\\delta}{h}\\exp\\Big\\{-\\,\\left(\\frac{2\\pi}{h}\\right)^{2}\\,\\delta^{2}(p\\!-\\!p^{0})^{2}\\Big\\},\n$$  \n\nwhich implies that the values of $p$ are essentially within the domain of width $h/2\\pi\\delta$ around $p^{0}$.  \n\nThe probability density of the coordinate $q$ for $\\psi$ of Eq. (59.12), by the way, is given by  \n\n$$\nP(q)=\\frac{1}{\\bar{\\pi}^{\\frac{1}{2}}\\delta}\\exp\\Big\\{-\\frac{1}{\\delta^{2}}\\,(q\\!-\\!q^{0})^{2}\\Big\\}.\n$$  \n\n(iv) The Uncertainty Relation  \n\nThe two uncertainties $(\\varDelta q$ and $\\varDelta p)$ obtained in the last subsection seem to show a reciprocal relation. Namely, according to Eqs. (59.14) and (59.17), respectively,  \n\n$$\n\\begin{array}{l}{{\\varDelta q=\\frac{1}{\\sqrt{2}}\\,\\delta}}\\\\ {{\\varDelta p=\\left(\\frac{h}{2\\pi}\\right)\\frac{1}{\\delta\\sqrt{2}}\\,.}}\\end{array}\n$$  \n\nThat is, $\\varDelta q$ is proportional to $\\delta$ while $\\varDelta p$ is to $1/\\delta$. Therefore, an effort to reduce $\\varDelta q$ inevitably causes an increase in $\\varDelta p$ and vice versa.  \n\nFrom Eq. (59.20) we find that  \n\n$$\n\\varDelta p\\cdot\\varDelta q={\\textstyle{\\frac{1}{2}}}{\\frac{h}{2\\pi}}\\,.\n$$  \n\nIt says, for instance, that $\\varDelta\\phi$ approaches infinity if $\\varDelta q$ tends to 0, and $\\varDelta q$ approaches infinity if $\\varDelta p$ tends to 0. In other words, in a state in which the coordinate has a definite value, the value of momentum is completely indefinite, and in a state in which the momentum has a definite value, the value of coordinate is completely indefinite.  \n\nThe relation (59.21) has been derived from the consideration of a specific wave packet of the form of Eq. (59.12). The question is then, what happens if we take a state other than that chosen here? We give the answer first. For a general $\\psi_{i}$, the relation given in Eq. (59.21) does not necessarily hold, but the product $\\varDelta p \\varDelta q$ never becomes smaller than the value given by Eq. (59.21). We have namely",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "${{\\varDelta p=\\left(\\frac{h}{2\\pi}\\right)\\frac{1}{\\delta\\sqrt{2}}\\,.}}",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/math-134115.pdf_670",
        "ID": "11aa387b-f313-4a72-aafe-38ae9ac6a4d6",
        "questions": "What year did Thomas Austin release 24 rabbits into the wild in Australia, leading to the rabbit population explosion?",
        "answers": "1859",
        "context": "# 3.7: Exponential and Logarithmic Equations  \n\n# Learning Objectives  \n\nUse like bases to solve exponential equations. Use logarithms to solve exponential equations. Use the definition of a logarithm to solve logarithmic equations. Use the one-to-one property of logarithms to solve logarithmic equations. Solve applied problems involving exponential and logarithmic equations.  \n\nIn 1859, an Australian landowner named Thomas Austin released 24 rabbits into the wild for hunting. Because Australia had few predators and ample food, the rabbit population exploded. In fewer than ten years, the rabbit population numbered in the millions.  \n\n![](images/7d585de337a9c3dda9a2a11222f09233daf5ae1754f571734cdf59b560ed98dc.jpg)  \nFigure 3.7.1: Wild rabbits in Australia. The rabbit population grew so quickly in Australia that the event became known as the \"rabbit plague.\" (credit: Richard Taylor, Flickr)  \n\nUncontrolled population growth, as in the wild rabbits in Australia, can be modeled with exponential functions. Equations resulting from those exponential functions can be solved to analyze and make predictions about exponential growth. In this section, we will learn techniques for solving exponential functions.  \n\n# Using Like Bases to Solve Exponential Equations  \n\nThe first technique involves two functions with like bases. Recall that the one-to-one property of exponential functions tells us that, for any real numbers $b, S,$ and $T_{i}$ where $b > 0, b \\neq 1, b^{S} = b^{T}$ if and only if $S = T$.  \n\nIn other words, when an exponential equation has the same base on each side, the exponents must be equal. This also applies when the exponents are algebraic expressions. Therefore, we can solve many exponential equations by using the rules of exponents to rewrite each side as a power with the same base. Then, we use the fact that exponential functions are one-to-one to set the exponents equal to one another, and solve for the unknown.  \n\n$3^{4x-7} = \\frac{3^{2x}}{3}$  \n$\\boldsymbol{x}$ side so that both sides have the common base, 3. Then we apply the one-to-one property of exponents by setting the exponents equal to one another and solving for $\\em x$.  \n\n${\\begin{array}{r l} & 3^{4x-7} = \\cfrac{3^{2x}}{3} \\\\ & 3^{4x-7} = \\cfrac{3^{2x}}{3^{1}} \\\\ & 3^{4x-7} = 3^{2x-1} \\\\ & 4x-7 = 2x-1 \\\\ & 2x = 6 \\\\ & x = 3 \\end{array}}$  \nRewrite 3 as $3^{1}$. Use the division property of exponents. Apply the one-to-one property of exponents. Subtract $2\\mathbf{x}$ and add 7 to both sides. Divide by 3.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Numeric",
        "evidence_source": "text",
        "evidence_context": "In 1859, an Australian landowner named Thomas Austin released 24 rabbits into the wild for hunting.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/math-134115.pdf_670",
        "ID": "11aeb9d2-1be1-49e1-8f4a-3366f66aad2e",
        "questions": "Which property of exponential functions is used to set the exponents equal to one another in solving exponential equations?",
        "answers": "one-to-one property",
        "context": "# 3.7: Exponential and Logarithmic Equations  \n\n# Learning Objectives  \n\nUse like bases to solve exponential equations. Use logarithms to solve exponential equations. Use the definition of a logarithm to solve logarithmic equations. Use the one-to-one property of logarithms to solve logarithmic equations. Solve applied problems involving exponential and logarithmic equations.  \n\nIn 1859, an Australian landowner named Thomas Austin released 24 rabbits into the wild for hunting. Because Australia had few predators and ample food, the rabbit population exploded. In fewer than ten years, the rabbit population numbered in the millions.  \n\n![](images/7d585de337a9c3dda9a2a11222f09233daf5ae1754f571734cdf59b560ed98dc.jpg)  \nFigure 3.7.1: Wild rabbits in Australia. The rabbit population grew so quickly in Australia that the event became known as the \"rabbit plague.\" (credit: Richard Taylor, Flickr)  \n\nUncontrolled population growth, as in the wild rabbits in Australia, can be modeled with exponential functions. Equations resulting from those exponential functions can be solved to analyze and make predictions about exponential growth. In this section, we will learn techniques for solving exponential functions.  \n\n# Using Like Bases to Solve Exponential Equations  \n\nThe first technique involves two functions with like bases. Recall that the one-to-one property of exponential functions tells us that, for any real numbers $b, S,$ and $T_{i}$ where $b > 0, b \\neq 1, b^{S} = b^{T}$ if and only if $S = T$.  \n\nIn other words, when an exponential equation has the same base on each side, the exponents must be equal. This also applies when the exponents are algebraic expressions. Therefore, we can solve many exponential equations by using the rules of exponents to rewrite each side as a power with the same base. Then, we use the fact that exponential functions are one-to-one to set the exponents equal to one another, and solve for the unknown.  \n\n$3^{4x-7} = \\frac{3^{2x}}{3}$  \n$\\boldsymbol{x}$ side so that both sides have the common base, 3. Then we apply the one-to-one property of exponents by setting the exponents equal to one another and solving for $\\em x$.  \n\n${\\begin{array}{r l} & 3^{4x-7} = \\cfrac{3^{2x}}{3} \\\\ & 3^{4x-7} = \\cfrac{3^{2x}}{3^{1}} \\\\ & 3^{4x-7} = 3^{2x-1} \\\\ & 4x-7 = 2x-1 \\\\ & 2x = 6 \\\\ & x = 3 \\end{array}}$  \nRewrite 3 as $3^{1}$. Use the division property of exponents. Apply the one-to-one property of exponents. Subtract $2\\mathbf{x}$ and add 7 to both sides. Divide by 3.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Recall that the one-to-one property of exponential functions tells us that, for any real numbers $b, S,$ and $T_{i}$ where $b > 0, b \neq 1, b^{S} = b^{T}$ if and only if $S = T$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/math-134115.pdf_670",
        "ID": "11cbb930-94d0-4262-a965-2ff98a2e8edf",
        "questions": "Using the base 3 and the division property of exponents, what is the value of \\( x \\) in the equation \\( 3^{4x-7} = \frac{3^{2x}}{3} \\)?",
        "answers": "3",
        "context": "# 3.7: Exponential and Logarithmic Equations  \n\n# Learning Objectives  \n\nUse like bases to solve exponential equations. Use logarithms to solve exponential equations. Use the definition of a logarithm to solve logarithmic equations. Use the one-to-one property of logarithms to solve logarithmic equations. Solve applied problems involving exponential and logarithmic equations.  \n\nIn 1859, an Australian landowner named Thomas Austin released 24 rabbits into the wild for hunting. Because Australia had few predators and ample food, the rabbit population exploded. In fewer than ten years, the rabbit population numbered in the millions.  \n\n![](images/7d585de337a9c3dda9a2a11222f09233daf5ae1754f571734cdf59b560ed98dc.jpg)  \nFigure 3.7.1: Wild rabbits in Australia. The rabbit population grew so quickly in Australia that the event became known as the \"rabbit plague.\" (credit: Richard Taylor, Flickr)  \n\nUncontrolled population growth, as in the wild rabbits in Australia, can be modeled with exponential functions. Equations resulting from those exponential functions can be solved to analyze and make predictions about exponential growth. In this section, we will learn techniques for solving exponential functions.  \n\n# Using Like Bases to Solve Exponential Equations  \n\nThe first technique involves two functions with like bases. Recall that the one-to-one property of exponential functions tells us that, for any real numbers $b, S,$ and $T_{i}$ where $b > 0, b \\neq 1, b^{S} = b^{T}$ if and only if $S = T$.  \n\nIn other words, when an exponential equation has the same base on each side, the exponents must be equal. This also applies when the exponents are algebraic expressions. Therefore, we can solve many exponential equations by using the rules of exponents to rewrite each side as a power with the same base. Then, we use the fact that exponential functions are one-to-one to set the exponents equal to one another, and solve for the unknown.  \n\n$3^{4x-7} = \\frac{3^{2x}}{3}$  \n$\\boldsymbol{x}$ side so that both sides have the common base, 3. Then we apply the one-to-one property of exponents by setting the exponents equal to one another and solving for $\\em x$.  \n\n${\\begin{array}{r l} & 3^{4x-7} = \\cfrac{3^{2x}}{3} \\\\ & 3^{4x-7} = \\cfrac{3^{2x}}{3^{1}} \\\\ & 3^{4x-7} = 3^{2x-1} \\\\ & 4x-7 = 2x-1 \\\\ & 2x = 6 \\\\ & x = 3 \\end{array}}$  \nRewrite 3 as $3^{1}$. Use the division property of exponents. Apply the one-to-one property of exponents. Subtract $2\\mathbf{x}$ and add 7 to both sides. Divide by 3.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Numeric",
        "evidence_source": "equation",
        "evidence_context": "${\begin{array}{r l} & 3^{4x-7} = \\cfrac{3^{2x}}{3} \\ & 3^{4x-7} = \\cfrac{3^{2x}}{3^{1}} \\ & 3^{4x-7} = 3^{2x-1} \\ & 4x-7 = 2x-1 \\ & 2x = 6 \\ & x = 3 \\end{array}}",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/math-134115.pdf_670",
        "ID": "11d56acf-680f-45e2-a0c3-6cdd9937f592",
        "questions": "What is the value of $x$ when solving the exponential equation $3^{4x-7} = \frac{3^{2x}}{3}$?",
        "answers": "The value of $x$ is 3.",
        "context": "# 3.7: Exponential and Logarithmic Equations  \n\n# Learning Objectives  \n\nUse like bases to solve exponential equations. Use logarithms to solve exponential equations. Use the definition of a logarithm to solve logarithmic equations. Use the one-to-one property of logarithms to solve logarithmic equations. Solve applied problems involving exponential and logarithmic equations.  \n\nIn 1859, an Australian landowner named Thomas Austin released 24 rabbits into the wild for hunting. Because Australia had few predators and ample food, the rabbit population exploded. In fewer than ten years, the rabbit population numbered in the millions.  \n\n![](images/7d585de337a9c3dda9a2a11222f09233daf5ae1754f571734cdf59b560ed98dc.jpg)  \nFigure 3.7.1: Wild rabbits in Australia. The rabbit population grew so quickly in Australia that the event became known as the \"rabbit plague.\" (credit: Richard Taylor, Flickr)  \n\nUncontrolled population growth, as in the wild rabbits in Australia, can be modeled with exponential functions. Equations resulting from those exponential functions can be solved to analyze and make predictions about exponential growth. In this section, we will learn techniques for solving exponential functions.  \n\n# Using Like Bases to Solve Exponential Equations  \n\nThe first technique involves two functions with like bases. Recall that the one-to-one property of exponential functions tells us that, for any real numbers $b, S,$ and $T_{i}$ where $b > 0, b \\neq 1, b^{S} = b^{T}$ if and only if $S = T$.  \n\nIn other words, when an exponential equation has the same base on each side, the exponents must be equal. This also applies when the exponents are algebraic expressions. Therefore, we can solve many exponential equations by using the rules of exponents to rewrite each side as a power with the same base. Then, we use the fact that exponential functions are one-to-one to set the exponents equal to one another, and solve for the unknown.  \n\n$3^{4x-7} = \\frac{3^{2x}}{3}$  \n$\\boldsymbol{x}$ side so that both sides have the common base, 3. Then we apply the one-to-one property of exponents by setting the exponents equal to one another and solving for $\\em x$.  \n\n${\\begin{array}{r l} & 3^{4x-7} = \\cfrac{3^{2x}}{3} \\\\ & 3^{4x-7} = \\cfrac{3^{2x}}{3^{1}} \\\\ & 3^{4x-7} = 3^{2x-1} \\\\ & 4x-7 = 2x-1 \\\\ & 2x = 6 \\\\ & x = 3 \\end{array}}$  \nRewrite 3 as $3^{1}$. Use the division property of exponents. Apply the one-to-one property of exponents. Subtract $2\\mathbf{x}$ and add 7 to both sides. Divide by 3.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Numeric",
        "evidence_source": "equation",
        "evidence_context": "${\\begin{array}{r l} & 3^{4x-7} = \\cfrac{3^{2x}}{3} \\ & 3^{4x-7} = \\cfrac{3^{2x}}{3^{1}} \\ & 3^{4x-7} = 3^{2x-1} \\ & 4x-7 = 2x-1 \\ & 2x = 6 \\ & x = 3 \\end{array}}$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/math-134115.pdf_670",
        "ID": "11d7ad85-6e2d-4604-9ac0-407b8f06d1a1",
        "questions": "Explain the method used to solve the exponential equation $3^{4x-7} = \frac{3^{2x}}{3}$, mentioning both the property used and the operations applied.",
        "answers": "The method involves using the like bases property and the division property of exponents. Each side is rewritten with a common base, and then the one-to-one property of exponents is applied by setting the exponents equal to one another.",
        "context": "# 3.7: Exponential and Logarithmic Equations  \n\n# Learning Objectives  \n\nUse like bases to solve exponential equations. Use logarithms to solve exponential equations. Use the definition of a logarithm to solve logarithmic equations. Use the one-to-one property of logarithms to solve logarithmic equations. Solve applied problems involving exponential and logarithmic equations.  \n\nIn 1859, an Australian landowner named Thomas Austin released 24 rabbits into the wild for hunting. Because Australia had few predators and ample food, the rabbit population exploded. In fewer than ten years, the rabbit population numbered in the millions.  \n\n![](images/7d585de337a9c3dda9a2a11222f09233daf5ae1754f571734cdf59b560ed98dc.jpg)  \nFigure 3.7.1: Wild rabbits in Australia. The rabbit population grew so quickly in Australia that the event became known as the \"rabbit plague.\" (credit: Richard Taylor, Flickr)  \n\nUncontrolled population growth, as in the wild rabbits in Australia, can be modeled with exponential functions. Equations resulting from those exponential functions can be solved to analyze and make predictions about exponential growth. In this section, we will learn techniques for solving exponential functions.  \n\n# Using Like Bases to Solve Exponential Equations  \n\nThe first technique involves two functions with like bases. Recall that the one-to-one property of exponential functions tells us that, for any real numbers $b, S,$ and $T_{i}$ where $b > 0, b \\neq 1, b^{S} = b^{T}$ if and only if $S = T$.  \n\nIn other words, when an exponential equation has the same base on each side, the exponents must be equal. This also applies when the exponents are algebraic expressions. Therefore, we can solve many exponential equations by using the rules of exponents to rewrite each side as a power with the same base. Then, we use the fact that exponential functions are one-to-one to set the exponents equal to one another, and solve for the unknown.  \n\n$3^{4x-7} = \\frac{3^{2x}}{3}$  \n$\\boldsymbol{x}$ side so that both sides have the common base, 3. Then we apply the one-to-one property of exponents by setting the exponents equal to one another and solving for $\\em x$.  \n\n${\\begin{array}{r l} & 3^{4x-7} = \\cfrac{3^{2x}}{3} \\\\ & 3^{4x-7} = \\cfrac{3^{2x}}{3^{1}} \\\\ & 3^{4x-7} = 3^{2x-1} \\\\ & 4x-7 = 2x-1 \\\\ & 2x = 6 \\\\ & x = 3 \\end{array}}$  \nRewrite 3 as $3^{1}$. Use the division property of exponents. Apply the one-to-one property of exponents. Subtract $2\\mathbf{x}$ and add 7 to both sides. Divide by 3.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "${\\begin{array}{r l} & 3^{4x-7} = \\cfrac{3^{2x}}{3} \\ & 3^{4x-7} = \\cfrac{3^{2x}}{3^{1}} \\ & 3^{4x-7} = 3^{2x-1} \\ & 4x-7 = 2x-1 \\ & 2x = 6 \\ & x = 3 \\end{array}}$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/math-134115.pdf_670",
        "ID": "11df13ab-c687-4c27-a89c-ae081512ae13",
        "questions": "What logarithmic techniques can be used to solve exponential equations if the bases are not the same?",
        "answers": "Logarithmic functions and the definition of a logarithm, such as using the natural logarithm or common logarithm, can be used to solve exponential equations when the bases are not the same.",
        "context": "# 3.7: Exponential and Logarithmic Equations  \n\n# Learning Objectives  \n\nUse like bases to solve exponential equations. Use logarithms to solve exponential equations. Use the definition of a logarithm to solve logarithmic equations. Use the one-to-one property of logarithms to solve logarithmic equations. Solve applied problems involving exponential and logarithmic equations.  \n\nIn 1859, an Australian landowner named Thomas Austin released 24 rabbits into the wild for hunting. Because Australia had few predators and ample food, the rabbit population exploded. In fewer than ten years, the rabbit population numbered in the millions.  \n\n![](images/7d585de337a9c3dda9a2a11222f09233daf5ae1754f571734cdf59b560ed98dc.jpg)  \nFigure 3.7.1: Wild rabbits in Australia. The rabbit population grew so quickly in Australia that the event became known as the \"rabbit plague.\" (credit: Richard Taylor, Flickr)  \n\nUncontrolled population growth, as in the wild rabbits in Australia, can be modeled with exponential functions. Equations resulting from those exponential functions can be solved to analyze and make predictions about exponential growth. In this section, we will learn techniques for solving exponential functions.  \n\n# Using Like Bases to Solve Exponential Equations  \n\nThe first technique involves two functions with like bases. Recall that the one-to-one property of exponential functions tells us that, for any real numbers $b, S,$ and $T_{i}$ where $b > 0, b \\neq 1, b^{S} = b^{T}$ if and only if $S = T$.  \n\nIn other words, when an exponential equation has the same base on each side, the exponents must be equal. This also applies when the exponents are algebraic expressions. Therefore, we can solve many exponential equations by using the rules of exponents to rewrite each side as a power with the same base. Then, we use the fact that exponential functions are one-to-one to set the exponents equal to one another, and solve for the unknown.  \n\n$3^{4x-7} = \\frac{3^{2x}}{3}$  \n$\\boldsymbol{x}$ side so that both sides have the common base, 3. Then we apply the one-to-one property of exponents by setting the exponents equal to one another and solving for $\\em x$.  \n\n${\\begin{array}{r l} & 3^{4x-7} = \\cfrac{3^{2x}}{3} \\\\ & 3^{4x-7} = \\cfrac{3^{2x}}{3^{1}} \\\\ & 3^{4x-7} = 3^{2x-1} \\\\ & 4x-7 = 2x-1 \\\\ & 2x = 6 \\\\ & x = 3 \\end{array}}$  \nRewrite 3 as $3^{1}$. Use the division property of exponents. Apply the one-to-one property of exponents. Subtract $2\\mathbf{x}$ and add 7 to both sides. Divide by 3.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Use like bases to solve exponential equations. Use logarithms to solve exponential equations. Use the definition of a logarithm to solve logarithmic equations. Use the one-to-one property of logarithms to solve logarithmic equations.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/textbook_needrop_en_3204",
        "ID": "11e4a4de-bcd4-423a-adc5-4265f82e4074",
        "questions": "For commutative rings $R$ and $S$, where $R \\subseteq S$, and an element $g \\in S$ is such that $g^2, g^3 \\in R$, what are the generators of the $R$-submodule $P_r$ for any $r \\in R$?",
        "answers": "(1 + r g, g^{2})",
        "context": "(2.15) Example. Let $R\\subseteq S$ be commutative rings, and let $g \\in S$ be such that $g^{2}, g^{3} \\in R$. This implies (easily) that $g^{n} \\in R$ for all $n \\geq 2$, but $g$ itself may or may not be in $R$. For $r \\in R$, let $P_{r} = (1 + r g, g^{2})$ be the $R$-submodule of $S$ generated by the indicated elements. $^{7}\\mathrm{For} \\; r, s \\in R$\n\n$ P_{r}P_{s} = (1 + r g, g^{2})(1 + s g, g^{2}) = (1 + (r + s)g + r s g^{2}, g^{2} + r g^{3}, g^{2} + s g^{3}, g^4) $   contains $ g^{2}(1 + (r + s)g + r s g^{2}) - r s g^{4} = g^{2} + (r + s)g^{3} $, so it also contains $r g^{3}, s g^{3}$ and $g^{2}$, $1 + (r + s)g $. Therefore,\n\n$$\nP_{r} P_{s} = (1 + (r + s)g, g^{2}, r g^{3}, s g^{3}).\n$$\n\nFrom $g^{3}(1 + (r + s)g) - (r + s)g^{2}g^{2} = g^{3}$, we see further that\n\n$$\nP_{r}P_{s} = (1 + (r + s)g, g^{2}) = P_{r+s}.\n$$\n\nIn particular, $P_{r}P_{-r} = P_{0} = (1, g^{2}) = R$, so $\\{P_{r} : r \\in R\\}$ is a family of invertible (hence projective) $R$-submodules of $S$, with $P_{r}^{*} = P_{r}^{-1} = P_{-r}$. The criterion for $P_{r}$ to be free turns out to be the following:\n\n(2.15B) $P_{r} \\;\\;\\mathrm{is}\\;\\; R\\mathrm{-free\\;iff}\\;\\; u(1 + r g) \\in R$ for some $u \\in \\mathrm{U}(R[g])$\n\nIn fact, if $P_{r}$ is $R$-free, by (2.14)(4) we have $P_{-r} = u R$ for some $u \\in \\mathrm{U}(S)$. Since\n\n$$\nu \\in P_{-r} = (1 - r g, g^{2}) \\subseteq R[g] \\quad \\mathrm{and} \\quad u^{-1} \\in P_{r} = (1 + r g, g^{2}) \\subseteq R[g],\n$$\n\nwe have $u \\in \\mathrm{U}(R[g])$ and $u(1 + r g) \\in u P_{r} = R$. Conversely, suppose $u(1 + r g) \\in R$ for some $u \\in \\mathrm{U}(R[g])$. Since $u g^{2} \\in R[g]g^{2} \\subseteq R$, we have $u P_{r} = (u(1 + r g), u g^{2}) \\subseteq R$ so $P_{r} \\subseteq u^{-1}R$. We finish by showing that $P_{r} = u^{-1}R$. Let $J = \\{c \\in R : c g \\in R\\}$. This is an ideal of $R[g]$ (called the \u201cconductor\u201d of the pair $R \\subseteq R[g]$). Clearly, $R g^{2} \\subseteq J$. Also, for any $c \\in J$ \uff1a\n\n$$\nc = c(1 - r^{2}g^{2} + r^{2}g^{2}) = [c(1 - r g)](1 + r g) + [c r^{2}]g^{2} \\in P_{r},\n$$\n\nso $J \\subseteq P_{r}$. Let $t = u(1 + r g) \\in R$. Since $(1 + r g)(1 - r g) \\in 1 + J$, we have $\\overline{1 + r g} \\in \\mathrm{U}(R[g]/J)$, and hence $\\bar{t} \\in \\mathrm{U}(R[g]/J)$. Using the fact that $R \\subseteq R[g]$ is an integral extension, we see that $\\bar{t} \\in \\mathrm{U}(R/J)$. Therefore,\n\n$$\nP_{r}/J = (1 + r g) \\cdot (R/J) = u^{-1}t \\cdot (R/J) = u^{-1} \\cdot (R/J).\n$$\n\nThis implies that $u^{-1}R \\subseteq P_{r}$, as desired.\n\nTo further simplify the criterion for $P_{r}$ to be free, we can impose an additional hypothesis.\n\n(2.15C) Proposition. In the preceding example, assume that\n\n(2.15D) $For\\ u \\in \\mathrm{U}(R[g]), u(1 + r g) \\in R \\implies u \\in R$.\n\nsupplement: The construction of $P_1 = (1 + g, g^2)$ was first given by S. Schanuel. It is, therefore, reasonable to call the $P_r$'s Schanuel modules. The direct calculation checking $P_r P_s = P_{r+s}$ in (2.15A) appears to be new.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "For $r \\in R, let P_{r} = (1 + r g, g^{2}) be the $R$-submodule of $S$ generated by the indicated elements.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/textbook_needrop_en_3204",
        "ID": "11ebcd49-428a-4c22-95fd-b76a19fbeb1d",
        "questions": "What is the criterion for the $R$-submodule $P_{r}$ to be free, given that $P_{r}$ is defined as $(1 + r g, g^{2})$ for some $r \\in R$ and $g \\in S$?",
        "answers": "$P_{r} \\;\\;\\mathrm{is}\\;\\; R\\mathrm{-free\\;iff}\\;\\; u(1 + r g) \\in R$ for some $u \\in \\mathrm{U}(R[g])$",
        "context": "(2.15) Example. Let $R\\subseteq S$ be commutative rings, and let $g \\in S$ be such that $g^{2}, g^{3} \\in R$. This implies (easily) that $g^{n} \\in R$ for all $n \\geq 2$, but $g$ itself may or may not be in $R$. For $r \\in R$, let $P_{r} = (1 + r g, g^{2})$ be the $R$-submodule of $S$ generated by the indicated elements. $^{7}\\mathrm{For} \\; r, s \\in R$\n\n$ P_{r}P_{s} = (1 + r g, g^{2})(1 + s g, g^{2}) = (1 + (r + s)g + r s g^{2}, g^{2} + r g^{3}, g^{2} + s g^{3}, g^4) $   contains $ g^{2}(1 + (r + s)g + r s g^{2}) - r s g^{4} = g^{2} + (r + s)g^{3} $, so it also contains $r g^{3}, s g^{3}$ and $g^{2}$, $1 + (r + s)g $. Therefore,\n\n$$\nP_{r} P_{s} = (1 + (r + s)g, g^{2}, r g^{3}, s g^{3}).\n$$\n\nFrom $g^{3}(1 + (r + s)g) - (r + s)g^{2}g^{2} = g^{3}$, we see further that\n\n$$\nP_{r}P_{s} = (1 + (r + s)g, g^{2}) = P_{r+s}.\n$$\n\nIn particular, $P_{r}P_{-r} = P_{0} = (1, g^{2}) = R$, so $\\{P_{r} : r \\in R\\}$ is a family of invertible (hence projective) $R$-submodules of $S$, with $P_{r}^{*} = P_{r}^{-1} = P_{-r}$. The criterion for $P_{r}$ to be free turns out to be the following:\n\n(2.15B) $P_{r} \\;\\;\\mathrm{is}\\;\\; R\\mathrm{-free\\;iff}\\;\\; u(1 + r g) \\in R$ for some $u \\in \\mathrm{U}(R[g])$\n\nIn fact, if $P_{r}$ is $R$-free, by (2.14)(4) we have $P_{-r} = u R$ for some $u \\in \\mathrm{U}(S)$. Since\n\n$$\nu \\in P_{-r} = (1 - r g, g^{2}) \\subseteq R[g] \\quad \\mathrm{and} \\quad u^{-1} \\in P_{r} = (1 + r g, g^{2}) \\subseteq R[g],\n$$\n\nwe have $u \\in \\mathrm{U}(R[g])$ and $u(1 + r g) \\in u P_{r} = R$. Conversely, suppose $u(1 + r g) \\in R$ for some $u \\in \\mathrm{U}(R[g])$. Since $u g^{2} \\in R[g]g^{2} \\subseteq R$, we have $u P_{r} = (u(1 + r g), u g^{2}) \\subseteq R$ so $P_{r} \\subseteq u^{-1}R$. We finish by showing that $P_{r} = u^{-1}R$. Let $J = \\{c \\in R : c g \\in R\\}$. This is an ideal of $R[g]$ (called the \u201cconductor\u201d of the pair $R \\subseteq R[g]$). Clearly, $R g^{2} \\subseteq J$. Also, for any $c \\in J$ \uff1a\n\n$$\nc = c(1 - r^{2}g^{2} + r^{2}g^{2}) = [c(1 - r g)](1 + r g) + [c r^{2}]g^{2} \\in P_{r},\n$$\n\nso $J \\subseteq P_{r}$. Let $t = u(1 + r g) \\in R$. Since $(1 + r g)(1 - r g) \\in 1 + J$, we have $\\overline{1 + r g} \\in \\mathrm{U}(R[g]/J)$, and hence $\\bar{t} \\in \\mathrm{U}(R[g]/J)$. Using the fact that $R \\subseteq R[g]$ is an integral extension, we see that $\\bar{t} \\in \\mathrm{U}(R/J)$. Therefore,\n\n$$\nP_{r}/J = (1 + r g) \\cdot (R/J) = u^{-1}t \\cdot (R/J) = u^{-1} \\cdot (R/J).\n$$\n\nThis implies that $u^{-1}R \\subseteq P_{r}$, as desired.\n\nTo further simplify the criterion for $P_{r}$ to be free, we can impose an additional hypothesis.\n\n(2.15C) Proposition. In the preceding example, assume that\n\n(2.15D) $For\\ u \\in \\mathrm{U}(R[g]), u(1 + r g) \\in R \\implies u \\in R$.\n\nsupplement: The construction of $P_1 = (1 + g, g^2)$ was first given by S. Schanuel. It is, therefore, reasonable to call the $P_r$'s Schanuel modules. The direct calculation checking $P_r P_s = P_{r+s}$ in (2.15A) appears to be new.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "$P_{r} \\;\\;\\mathrm{is}\\;\\; R\\mathrm{-free\\;iff}\\;\\; u(1 + r g) \\in R$ for some $u \\in \\mathrm{U}(R[g])$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/textbook_needrop_en_3204",
        "ID": "11ecdee5-6f5f-4b4f-b305-23a06ac27493",
        "questions": "In the context of commutative rings $R \\subseteq S$ with an element $g \\in S$, and $P_r = (1 + r g, g^{2})$ for $r \\in R$, how is the conductor ideal $J$ of the pair $R \\subseteq R[g]$ defined, and what is its relevance to proving $P_{r} = u^{-1}R$?",
        "answers": "$J = \\{c \\in R : c g \\in R\\}$ is an ideal of $R[g]$ (called the \u201cconductor\u201d of the pair $R \\subseteq R[g]$). Clearly, $R g^{2} \\subseteq J$.",
        "context": "(2.15) Example. Let $R\\subseteq S$ be commutative rings, and let $g \\in S$ be such that $g^{2}, g^{3} \\in R$. This implies (easily) that $g^{n} \\in R$ for all $n \\geq 2$, but $g$ itself may or may not be in $R$. For $r \\in R$, let $P_{r} = (1 + r g, g^{2})$ be the $R$-submodule of $S$ generated by the indicated elements. $^{7}\\mathrm{For} \\; r, s \\in R$\n\n$ P_{r}P_{s} = (1 + r g, g^{2})(1 + s g, g^{2}) = (1 + (r + s)g + r s g^{2}, g^{2} + r g^{3}, g^{2} + s g^{3}, g^4) $   contains $ g^{2}(1 + (r + s)g + r s g^{2}) - r s g^{4} = g^{2} + (r + s)g^{3} $, so it also contains $r g^{3}, s g^{3}$ and $g^{2}$, $1 + (r + s)g $. Therefore,\n\n$$\nP_{r} P_{s} = (1 + (r + s)g, g^{2}, r g^{3}, s g^{3}).\n$$\n\nFrom $g^{3}(1 + (r + s)g) - (r + s)g^{2}g^{2} = g^{3}$, we see further that\n\n$$\nP_{r}P_{s} = (1 + (r + s)g, g^{2}) = P_{r+s}.\n$$\n\nIn particular, $P_{r}P_{-r} = P_{0} = (1, g^{2}) = R$, so $\\{P_{r} : r \\in R\\}$ is a family of invertible (hence projective) $R$-submodules of $S$, with $P_{r}^{*} = P_{r}^{-1} = P_{-r}$. The criterion for $P_{r}$ to be free turns out to be the following:\n\n(2.15B) $P_{r} \\;\\;\\mathrm{is}\\;\\; R\\mathrm{-free\\;iff}\\;\\; u(1 + r g) \\in R$ for some $u \\in \\mathrm{U}(R[g])$\n\nIn fact, if $P_{r}$ is $R$-free, by (2.14)(4) we have $P_{-r} = u R$ for some $u \\in \\mathrm{U}(S)$. Since\n\n$$\nu \\in P_{-r} = (1 - r g, g^{2}) \\subseteq R[g] \\quad \\mathrm{and} \\quad u^{-1} \\in P_{r} = (1 + r g, g^{2}) \\subseteq R[g],\n$$\n\nwe have $u \\in \\mathrm{U}(R[g])$ and $u(1 + r g) \\in u P_{r} = R$. Conversely, suppose $u(1 + r g) \\in R$ for some $u \\in \\mathrm{U}(R[g])$. Since $u g^{2} \\in R[g]g^{2} \\subseteq R$, we have $u P_{r} = (u(1 + r g), u g^{2}) \\subseteq R$ so $P_{r} \\subseteq u^{-1}R$. We finish by showing that $P_{r} = u^{-1}R$. Let $J = \\{c \\in R : c g \\in R\\}$. This is an ideal of $R[g]$ (called the \u201cconductor\u201d of the pair $R \\subseteq R[g]$). Clearly, $R g^{2} \\subseteq J$. Also, for any $c \\in J$ \uff1a\n\n$$\nc = c(1 - r^{2}g^{2} + r^{2}g^{2}) = [c(1 - r g)](1 + r g) + [c r^{2}]g^{2} \\in P_{r},\n$$\n\nso $J \\subseteq P_{r}$. Let $t = u(1 + r g) \\in R$. Since $(1 + r g)(1 - r g) \\in 1 + J$, we have $\\overline{1 + r g} \\in \\mathrm{U}(R[g]/J)$, and hence $\\bar{t} \\in \\mathrm{U}(R[g]/J)$. Using the fact that $R \\subseteq R[g]$ is an integral extension, we see that $\\bar{t} \\in \\mathrm{U}(R/J)$. Therefore,\n\n$$\nP_{r}/J = (1 + r g) \\cdot (R/J) = u^{-1}t \\cdot (R/J) = u^{-1} \\cdot (R/J).\n$$\n\nThis implies that $u^{-1}R \\subseteq P_{r}$, as desired.\n\nTo further simplify the criterion for $P_{r}$ to be free, we can impose an additional hypothesis.\n\n(2.15C) Proposition. In the preceding example, assume that\n\n(2.15D) $For\\ u \\in \\mathrm{U}(R[g]), u(1 + r g) \\in R \\implies u \\in R$.\n\nsupplement: The construction of $P_1 = (1 + g, g^2)$ was first given by S. Schanuel. It is, therefore, reasonable to call the $P_r$'s Schanuel modules. The direct calculation checking $P_r P_s = P_{r+s}$ in (2.15A) appears to be new.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Let $J = \\{c \\in R : c g \\in R\\}. This is an ideal of $R[g]$ (called the \u201cconductor\u201d of the pair $R \\subseteq R[g]$). Clearly, R g^{2} \\subseteq J.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/textbook_needrop_en_3204",
        "ID": "11f0458c-f767-4ead-aa00-246fa6034d21",
        "questions": "Given that for commutative rings $R \\subseteq S$, $g \\in S$ such that $g^2, g^3 \\in R$, what is the simplified form of $P_r P_s$ in terms of $r$ and $s$?",
        "answers": "P_r P_s = (1 + (r + s)g, g^2)",
        "context": "(2.15) Example. Let $R\\subseteq S$ be commutative rings, and let $g \\in S$ be such that $g^{2}, g^{3} \\in R$. This implies (easily) that $g^{n} \\in R$ for all $n \\geq 2$, but $g$ itself may or may not be in $R$. For $r \\in R$, let $P_{r} = (1 + r g, g^{2})$ be the $R$-submodule of $S$ generated by the indicated elements. $^{7}\\mathrm{For} \\; r, s \\in R$\n\n$ P_{r}P_{s} = (1 + r g, g^{2})(1 + s g, g^{2}) = (1 + (r + s)g + r s g^{2}, g^{2} + r g^{3}, g^{2} + s g^{3}, g^4) $   contains $ g^{2}(1 + (r + s)g + r s g^{2}) - r s g^{4} = g^{2} + (r + s)g^{3} $, so it also contains $r g^{3}, s g^{3}$ and $g^{2}$, $1 + (r + s)g $. Therefore,\n\n$$\nP_{r} P_{s} = (1 + (r + s)g, g^{2}, r g^{3}, s g^{3}).\n$$\n\nFrom $g^{3}(1 + (r + s)g) - (r + s)g^{2}g^{2} = g^{3}$, we see further that\n\n$$\nP_{r}P_{s} = (1 + (r + s)g, g^{2}) = P_{r+s}.\n$$\n\nIn particular, $P_{r}P_{-r} = P_{0} = (1, g^{2}) = R$, so $\\{P_{r} : r \\in R\\}$ is a family of invertible (hence projective) $R$-submodules of $S$, with $P_{r}^{*} = P_{r}^{-1} = P_{-r}$. The criterion for $P_{r}$ to be free turns out to be the following:\n\n(2.15B) $P_{r} \\;\\;\\mathrm{is}\\;\\; R\\mathrm{-free\\;iff}\\;\\; u(1 + r g) \\in R$ for some $u \\in \\mathrm{U}(R[g])$\n\nIn fact, if $P_{r}$ is $R$-free, by (2.14)(4) we have $P_{-r} = u R$ for some $u \\in \\mathrm{U}(S)$. Since\n\n$$\nu \\in P_{-r} = (1 - r g, g^{2}) \\subseteq R[g] \\quad \\mathrm{and} \\quad u^{-1} \\in P_{r} = (1 + r g, g^{2}) \\subseteq R[g],\n$$\n\nwe have $u \\in \\mathrm{U}(R[g])$ and $u(1 + r g) \\in u P_{r} = R$. Conversely, suppose $u(1 + r g) \\in R$ for some $u \\in \\mathrm{U}(R[g])$. Since $u g^{2} \\in R[g]g^{2} \\subseteq R$, we have $u P_{r} = (u(1 + r g), u g^{2}) \\subseteq R$ so $P_{r} \\subseteq u^{-1}R$. We finish by showing that $P_{r} = u^{-1}R$. Let $J = \\{c \\in R : c g \\in R\\}$. This is an ideal of $R[g]$ (called the \u201cconductor\u201d of the pair $R \\subseteq R[g]$). Clearly, $R g^{2} \\subseteq J$. Also, for any $c \\in J$ \uff1a\n\n$$\nc = c(1 - r^{2}g^{2} + r^{2}g^{2}) = [c(1 - r g)](1 + r g) + [c r^{2}]g^{2} \\in P_{r},\n$$\n\nso $J \\subseteq P_{r}$. Let $t = u(1 + r g) \\in R$. Since $(1 + r g)(1 - r g) \\in 1 + J$, we have $\\overline{1 + r g} \\in \\mathrm{U}(R[g]/J)$, and hence $\\bar{t} \\in \\mathrm{U}(R[g]/J)$. Using the fact that $R \\subseteq R[g]$ is an integral extension, we see that $\\bar{t} \\in \\mathrm{U}(R/J)$. Therefore,\n\n$$\nP_{r}/J = (1 + r g) \\cdot (R/J) = u^{-1}t \\cdot (R/J) = u^{-1} \\cdot (R/J).\n$$\n\nThis implies that $u^{-1}R \\subseteq P_{r}$, as desired.\n\nTo further simplify the criterion for $P_{r}$ to be free, we can impose an additional hypothesis.\n\n(2.15C) Proposition. In the preceding example, assume that\n\n(2.15D) $For\\ u \\in \\mathrm{U}(R[g]), u(1 + r g) \\in R \\implies u \\in R$.\n\nsupplement: The construction of $P_1 = (1 + g, g^2)$ was first given by S. Schanuel. It is, therefore, reasonable to call the $P_r$'s Schanuel modules. The direct calculation checking $P_r P_s = P_{r+s}$ in (2.15A) appears to be new.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Therefore, $$P_{r} P_{s} = (1 + (r + s)g, g^{2}, r g^{3}, s g^{3}).$$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/textbook_needrop_en_3204",
        "ID": "11fc637a-2d7e-4291-a19f-c948095d4879",
        "questions": "For rings $R \\subseteq S$ with $g \\in S$ and $g^2, g^3 \\in R$, under what condition is the $R$-submodule $P_r$ free?",
        "answers": "P_r is R-free iff u(1 + r g) \\in R for some u \\in \\mathrm{U}(R[g])",
        "context": "(2.15) Example. Let $R\\subseteq S$ be commutative rings, and let $g \\in S$ be such that $g^{2}, g^{3} \\in R$. This implies (easily) that $g^{n} \\in R$ for all $n \\geq 2$, but $g$ itself may or may not be in $R$. For $r \\in R$, let $P_{r} = (1 + r g, g^{2})$ be the $R$-submodule of $S$ generated by the indicated elements. $^{7}\\mathrm{For} \\; r, s \\in R$\n\n$ P_{r}P_{s} = (1 + r g, g^{2})(1 + s g, g^{2}) = (1 + (r + s)g + r s g^{2}, g^{2} + r g^{3}, g^{2} + s g^{3}, g^4) $   contains $ g^{2}(1 + (r + s)g + r s g^{2}) - r s g^{4} = g^{2} + (r + s)g^{3} $, so it also contains $r g^{3}, s g^{3}$ and $g^{2}$, $1 + (r + s)g $. Therefore,\n\n$$\nP_{r} P_{s} = (1 + (r + s)g, g^{2}, r g^{3}, s g^{3}).\n$$\n\nFrom $g^{3}(1 + (r + s)g) - (r + s)g^{2}g^{2} = g^{3}$, we see further that\n\n$$\nP_{r}P_{s} = (1 + (r + s)g, g^{2}) = P_{r+s}.\n$$\n\nIn particular, $P_{r}P_{-r} = P_{0} = (1, g^{2}) = R$, so $\\{P_{r} : r \\in R\\}$ is a family of invertible (hence projective) $R$-submodules of $S$, with $P_{r}^{*} = P_{r}^{-1} = P_{-r}$. The criterion for $P_{r}$ to be free turns out to be the following:\n\n(2.15B) $P_{r} \\;\\;\\mathrm{is}\\;\\; R\\mathrm{-free\\;iff}\\;\\; u(1 + r g) \\in R$ for some $u \\in \\mathrm{U}(R[g])$\n\nIn fact, if $P_{r}$ is $R$-free, by (2.14)(4) we have $P_{-r} = u R$ for some $u \\in \\mathrm{U}(S)$. Since\n\n$$\nu \\in P_{-r} = (1 - r g, g^{2}) \\subseteq R[g] \\quad \\mathrm{and} \\quad u^{-1} \\in P_{r} = (1 + r g, g^{2}) \\subseteq R[g],\n$$\n\nwe have $u \\in \\mathrm{U}(R[g])$ and $u(1 + r g) \\in u P_{r} = R$. Conversely, suppose $u(1 + r g) \\in R$ for some $u \\in \\mathrm{U}(R[g])$. Since $u g^{2} \\in R[g]g^{2} \\subseteq R$, we have $u P_{r} = (u(1 + r g), u g^{2}) \\subseteq R$ so $P_{r} \\subseteq u^{-1}R$. We finish by showing that $P_{r} = u^{-1}R$. Let $J = \\{c \\in R : c g \\in R\\}$. This is an ideal of $R[g]$ (called the \u201cconductor\u201d of the pair $R \\subseteq R[g]$). Clearly, $R g^{2} \\subseteq J$. Also, for any $c \\in J$ \uff1a\n\n$$\nc = c(1 - r^{2}g^{2} + r^{2}g^{2}) = [c(1 - r g)](1 + r g) + [c r^{2}]g^{2} \\in P_{r},\n$$\n\nso $J \\subseteq P_{r}$. Let $t = u(1 + r g) \\in R$. Since $(1 + r g)(1 - r g) \\in 1 + J$, we have $\\overline{1 + r g} \\in \\mathrm{U}(R[g]/J)$, and hence $\\bar{t} \\in \\mathrm{U}(R[g]/J)$. Using the fact that $R \\subseteq R[g]$ is an integral extension, we see that $\\bar{t} \\in \\mathrm{U}(R/J)$. Therefore,\n\n$$\nP_{r}/J = (1 + r g) \\cdot (R/J) = u^{-1}t \\cdot (R/J) = u^{-1} \\cdot (R/J).\n$$\n\nThis implies that $u^{-1}R \\subseteq P_{r}$, as desired.\n\nTo further simplify the criterion for $P_{r}$ to be free, we can impose an additional hypothesis.\n\n(2.15C) Proposition. In the preceding example, assume that\n\n(2.15D) $For\\ u \\in \\mathrm{U}(R[g]), u(1 + r g) \\in R \\implies u \\in R$.\n\nsupplement: The construction of $P_1 = (1 + g, g^2)$ was first given by S. Schanuel. It is, therefore, reasonable to call the $P_r$'s Schanuel modules. The direct calculation checking $P_r P_s = P_{r+s}$ in (2.15A) appears to be new.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "(2.15B) $P_{r} \\;\\;\\mathrm{is}\\;\\; R\\mathrm{-free\\;iff}\\;\\; u(1 + r g) \\in R$ for some $u \\in \\mathrm{U}(R[g])$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/textbook_needrop_en_3204",
        "ID": "12053b52-97ac-4637-a8fa-4de926f975cd",
        "questions": "In the context of $P_r$ being $R$-free, which element must belong to the set $\\mathrm{U}(R[g])$ if $u(1 + r g) \\in R$ for some $u \\in \\mathrm{U}(R[g])$?",
        "answers": "u",
        "context": "(2.15) Example. Let $R\\subseteq S$ be commutative rings, and let $g \\in S$ be such that $g^{2}, g^{3} \\in R$. This implies (easily) that $g^{n} \\in R$ for all $n \\geq 2$, but $g$ itself may or may not be in $R$. For $r \\in R$, let $P_{r} = (1 + r g, g^{2})$ be the $R$-submodule of $S$ generated by the indicated elements. $^{7}\\mathrm{For} \\; r, s \\in R$\n\n$ P_{r}P_{s} = (1 + r g, g^{2})(1 + s g, g^{2}) = (1 + (r + s)g + r s g^{2}, g^{2} + r g^{3}, g^{2} + s g^{3}, g^4) $   contains $ g^{2}(1 + (r + s)g + r s g^{2}) - r s g^{4} = g^{2} + (r + s)g^{3} $, so it also contains $r g^{3}, s g^{3}$ and $g^{2}$, $1 + (r + s)g $. Therefore,\n\n$$\nP_{r} P_{s} = (1 + (r + s)g, g^{2}, r g^{3}, s g^{3}).\n$$\n\nFrom $g^{3}(1 + (r + s)g) - (r + s)g^{2}g^{2} = g^{3}$, we see further that\n\n$$\nP_{r}P_{s} = (1 + (r + s)g, g^{2}) = P_{r+s}.\n$$\n\nIn particular, $P_{r}P_{-r} = P_{0} = (1, g^{2}) = R$, so $\\{P_{r} : r \\in R\\}$ is a family of invertible (hence projective) $R$-submodules of $S$, with $P_{r}^{*} = P_{r}^{-1} = P_{-r}$. The criterion for $P_{r}$ to be free turns out to be the following:\n\n(2.15B) $P_{r} \\;\\;\\mathrm{is}\\;\\; R\\mathrm{-free\\;iff}\\;\\; u(1 + r g) \\in R$ for some $u \\in \\mathrm{U}(R[g])$\n\nIn fact, if $P_{r}$ is $R$-free, by (2.14)(4) we have $P_{-r} = u R$ for some $u \\in \\mathrm{U}(S)$. Since\n\n$$\nu \\in P_{-r} = (1 - r g, g^{2}) \\subseteq R[g] \\quad \\mathrm{and} \\quad u^{-1} \\in P_{r} = (1 + r g, g^{2}) \\subseteq R[g],\n$$\n\nwe have $u \\in \\mathrm{U}(R[g])$ and $u(1 + r g) \\in u P_{r} = R$. Conversely, suppose $u(1 + r g) \\in R$ for some $u \\in \\mathrm{U}(R[g])$. Since $u g^{2} \\in R[g]g^{2} \\subseteq R$, we have $u P_{r} = (u(1 + r g), u g^{2}) \\subseteq R$ so $P_{r} \\subseteq u^{-1}R$. We finish by showing that $P_{r} = u^{-1}R$. Let $J = \\{c \\in R : c g \\in R\\}$. This is an ideal of $R[g]$ (called the \u201cconductor\u201d of the pair $R \\subseteq R[g]$). Clearly, $R g^{2} \\subseteq J$. Also, for any $c \\in J$ \uff1a\n\n$$\nc = c(1 - r^{2}g^{2} + r^{2}g^{2}) = [c(1 - r g)](1 + r g) + [c r^{2}]g^{2} \\in P_{r},\n$$\n\nso $J \\subseteq P_{r}$. Let $t = u(1 + r g) \\in R$. Since $(1 + r g)(1 - r g) \\in 1 + J$, we have $\\overline{1 + r g} \\in \\mathrm{U}(R[g]/J)$, and hence $\\bar{t} \\in \\mathrm{U}(R[g]/J)$. Using the fact that $R \\subseteq R[g]$ is an integral extension, we see that $\\bar{t} \\in \\mathrm{U}(R/J)$. Therefore,\n\n$$\nP_{r}/J = (1 + r g) \\cdot (R/J) = u^{-1}t \\cdot (R/J) = u^{-1} \\cdot (R/J).\n$$\n\nThis implies that $u^{-1}R \\subseteq P_{r}$, as desired.\n\nTo further simplify the criterion for $P_{r}$ to be free, we can impose an additional hypothesis.\n\n(2.15C) Proposition. In the preceding example, assume that\n\n(2.15D) $For\\ u \\in \\mathrm{U}(R[g]), u(1 + r g) \\in R \\implies u \\in R$.\n\nsupplement: The construction of $P_1 = (1 + g, g^2)$ was first given by S. Schanuel. It is, therefore, reasonable to call the $P_r$'s Schanuel modules. The direct calculation checking $P_r P_s = P_{r+s}$ in (2.15A) appears to be new.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Conversely, suppose $u(1 + r g) \\in R$ for some $u \\in \\mathrm{U}(R[g])$. Since $u g^{2} \\in R[g]g^{2} \\subseteq R$.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/Riemannian_Geometry_And_Geometric_Analysis(Jo.pdf_69",
        "ID": "120961ea-0913-4087-95d3-8ca9986cc8d5",
        "questions": "What is the dimension of the Clifford algebra Cl(V) as a vector space?",
        "answers": "2^n",
        "context": "Necessarily nondegenerate quadratic form on $V$ would suffice, but here we have no need to investigate the most general possible construction. On the contrary, for our purposes it suffices to take $\\mathbb{R}^{n}$ with its standard Euclidean scalar product. An orthonormal basis will be denoted by $e_{1},\\ldots,e_{n}$.\n\nDefinition 1.8.1 The Clifford algebra $\\operatorname{Cl}(V)$, also denoted $\\mathrm{Cl}(n)$, is the quotient of the tensor algebra $\\bigoplus_{k\\geq0}V\\otimes\\ldots\\otimes V$ generated by $V$ by the two-sided ideal generated by all elements of the form $v\\otimes v+\\|v\\|^{2}$ for $v\\in V$.\n\nThus, the multiplication rule for the Clifford algebra $\\operatorname{Cl}(V)$ is  \n\n$$\nv w+w v=-2\\langle v,w\\rangle\n$$  \n\nIn particular, in terms of our orthonormal basis $e_{1},\\ldots,e_{n}$, we have  \n\n$$\ne_{i}{}^{2}=-1{\\mathrm{~and~}}e_{i}e_{j}=-e_{i}e_{j}{\\mathrm{~for~}}i\\neq j.\n$$  \n\nFrom this, one easily sees that a basis of $\\operatorname{Cl}(V)$ as a real vector space is given by  \n\n$$\ne_{0}:=1,\\quad e_{\\alpha}:=e_{\\alpha_{1}}e_{\\alpha_{2}}\\ldots e_{\\alpha_{k}}\n$$  \n\nwith $\\alpha=\\{\\alpha_{1},\\ldots,\\alpha_{k}\\}\\subset\\{1,\\ldots,n\\}$ and $\\alpha_{1}<\\alpha_{2}\\ldots<\\alpha_{k}$. For such an $\\alpha$, we shall put $|\\alpha|:=k$ in the sequel. Thus, as a vector space, $\\operatorname{Cl}(V)$ is isomorphic to $A^{*}(V)$ (as algebras, these two spaces are of course different). In particular, the dimension of $\\operatorname{Cl}(V)$ as a vector space is $2^{n}$. Also, declaring this basis as being orthonormal, we obtain a scalar product on $\\operatorname{Cl}(V)$ extending the one on $V$.\n\nWe define the degree of as being $|\\alpha|$. The of degree $k$ generate the $\\epsilon_{\\alpha}$ $e_{\\alpha}$ subset $\\operatorname{Cl}^{k}(V)$ of elements of degree $k$. We have  \n\n$$\n\\begin{array}{r}{\\mathrm{Cl}^{0}=\\mathbb{R}}\\\\ {\\mathrm{Cl}^{1}=V.}\\end{array}\n$$  \n\nFinally, we let $\\operatorname{Cl}^{e v}(V)$ and $\\mathrm{Cl}^{o d d}(V)$ be the subspaces of elements of even resp. odd degree. The former is a subalgebra of $\\operatorname{Cl}(V)$, but not the latter.\n\nLemma 1.8.1 The center of $\\operatorname{Cl}(V)$ consists of those elements that commute with all $v\\in\\operatorname{Cl}^{1}(V)=V$. For $n$ even, the center is $\\mathrm{Cl}^{0}(V)$, while for $n$ odd it is $\\mathrm{Cl}^{0}(V)\\oplus\\mathrm{Cl}^{n}(V)$.\n\nProof. It suffices to consider basis vectors $e_{\\alpha} = e_{\\alpha_{1}}\\ldots,e_{\\alpha_{k}}$ as above. For $j\\not\\in\\alpha$, we have  \n\n$$\ne_{\\alpha}e_{j}=(-1)^{|\\alpha|}e_{j}e_{\\alpha},\n$$  \n\nand thus $|\\alpha|$ has to be even for $\\epsilon_{\\alpha}$ to commute with $e_{j}$, while  \n\n$$\ne_{\\alpha}e_{\\alpha_{j}}=(-1)^{|\\alpha|-1}e_{\\alpha_{j}}e_{\\alpha},\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "In particular, the dimension of \\operatorname{Cl}(V) as a vector space is 2^{n}.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Riemannian_Geometry_And_Geometric_Analysis(Jo.pdf_69",
        "ID": "12180934-6156-40f3-8fa7-a4386f3f49f4",
        "questions": "According to Lemma 1.8.1, what elements make up the center of the Clifford algebra Cl(V) when n is odd?",
        "answers": "Cl^0(V) \\oplus Cl^n(V)",
        "context": "Necessarily nondegenerate quadratic form on $V$ would suffice, but here we have no need to investigate the most general possible construction. On the contrary, for our purposes it suffices to take $\\mathbb{R}^{n}$ with its standard Euclidean scalar product. An orthonormal basis will be denoted by $e_{1},\\ldots,e_{n}$.\n\nDefinition 1.8.1 The Clifford algebra $\\operatorname{Cl}(V)$, also denoted $\\mathrm{Cl}(n)$, is the quotient of the tensor algebra $\\bigoplus_{k\\geq0}V\\otimes\\ldots\\otimes V$ generated by $V$ by the two-sided ideal generated by all elements of the form $v\\otimes v+\\|v\\|^{2}$ for $v\\in V$.\n\nThus, the multiplication rule for the Clifford algebra $\\operatorname{Cl}(V)$ is  \n\n$$\nv w+w v=-2\\langle v,w\\rangle\n$$  \n\nIn particular, in terms of our orthonormal basis $e_{1},\\ldots,e_{n}$, we have  \n\n$$\ne_{i}{}^{2}=-1{\\mathrm{~and~}}e_{i}e_{j}=-e_{i}e_{j}{\\mathrm{~for~}}i\\neq j.\n$$  \n\nFrom this, one easily sees that a basis of $\\operatorname{Cl}(V)$ as a real vector space is given by  \n\n$$\ne_{0}:=1,\\quad e_{\\alpha}:=e_{\\alpha_{1}}e_{\\alpha_{2}}\\ldots e_{\\alpha_{k}}\n$$  \n\nwith $\\alpha=\\{\\alpha_{1},\\ldots,\\alpha_{k}\\}\\subset\\{1,\\ldots,n\\}$ and $\\alpha_{1}<\\alpha_{2}\\ldots<\\alpha_{k}$. For such an $\\alpha$, we shall put $|\\alpha|:=k$ in the sequel. Thus, as a vector space, $\\operatorname{Cl}(V)$ is isomorphic to $A^{*}(V)$ (as algebras, these two spaces are of course different). In particular, the dimension of $\\operatorname{Cl}(V)$ as a vector space is $2^{n}$. Also, declaring this basis as being orthonormal, we obtain a scalar product on $\\operatorname{Cl}(V)$ extending the one on $V$.\n\nWe define the degree of as being $|\\alpha|$. The of degree $k$ generate the $\\epsilon_{\\alpha}$ $e_{\\alpha}$ subset $\\operatorname{Cl}^{k}(V)$ of elements of degree $k$. We have  \n\n$$\n\\begin{array}{r}{\\mathrm{Cl}^{0}=\\mathbb{R}}\\\\ {\\mathrm{Cl}^{1}=V.}\\end{array}\n$$  \n\nFinally, we let $\\operatorname{Cl}^{e v}(V)$ and $\\mathrm{Cl}^{o d d}(V)$ be the subspaces of elements of even resp. odd degree. The former is a subalgebra of $\\operatorname{Cl}(V)$, but not the latter.\n\nLemma 1.8.1 The center of $\\operatorname{Cl}(V)$ consists of those elements that commute with all $v\\in\\operatorname{Cl}^{1}(V)=V$. For $n$ even, the center is $\\mathrm{Cl}^{0}(V)$, while for $n$ odd it is $\\mathrm{Cl}^{0}(V)\\oplus\\mathrm{Cl}^{n}(V)$.\n\nProof. It suffices to consider basis vectors $e_{\\alpha} = e_{\\alpha_{1}}\\ldots,e_{\\alpha_{k}}$ as above. For $j\\not\\in\\alpha$, we have  \n\n$$\ne_{\\alpha}e_{j}=(-1)^{|\\alpha|}e_{j}e_{\\alpha},\n$$  \n\nand thus $|\\alpha|$ has to be even for $\\epsilon_{\\alpha}$ to commute with $e_{j}$, while  \n\n$$\ne_{\\alpha}e_{\\alpha_{j}}=(-1)^{|\\alpha|-1}e_{\\alpha_{j}}e_{\\alpha},\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "For n odd, the center is \\mathrm{Cl}^{0}(V)\\oplus\\mathrm{Cl}^{n}(V).",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Riemannian_Geometry_And_Geometric_Analysis(Jo.pdf_69",
        "ID": "121e980d-8983-4c29-965a-01871a64c95a",
        "questions": "In the Clifford algebra defined in the document, what are the multiplication rules for the basis elements e_i and e_j for i \u2260 j?",
        "answers": "e_i e_j = -e_j e_i",
        "context": "Necessarily nondegenerate quadratic form on $V$ would suffice, but here we have no need to investigate the most general possible construction. On the contrary, for our purposes it suffices to take $\\mathbb{R}^{n}$ with its standard Euclidean scalar product. An orthonormal basis will be denoted by $e_{1},\\ldots,e_{n}$.\n\nDefinition 1.8.1 The Clifford algebra $\\operatorname{Cl}(V)$, also denoted $\\mathrm{Cl}(n)$, is the quotient of the tensor algebra $\\bigoplus_{k\\geq0}V\\otimes\\ldots\\otimes V$ generated by $V$ by the two-sided ideal generated by all elements of the form $v\\otimes v+\\|v\\|^{2}$ for $v\\in V$.\n\nThus, the multiplication rule for the Clifford algebra $\\operatorname{Cl}(V)$ is  \n\n$$\nv w+w v=-2\\langle v,w\\rangle\n$$  \n\nIn particular, in terms of our orthonormal basis $e_{1},\\ldots,e_{n}$, we have  \n\n$$\ne_{i}{}^{2}=-1{\\mathrm{~and~}}e_{i}e_{j}=-e_{i}e_{j}{\\mathrm{~for~}}i\\neq j.\n$$  \n\nFrom this, one easily sees that a basis of $\\operatorname{Cl}(V)$ as a real vector space is given by  \n\n$$\ne_{0}:=1,\\quad e_{\\alpha}:=e_{\\alpha_{1}}e_{\\alpha_{2}}\\ldots e_{\\alpha_{k}}\n$$  \n\nwith $\\alpha=\\{\\alpha_{1},\\ldots,\\alpha_{k}\\}\\subset\\{1,\\ldots,n\\}$ and $\\alpha_{1}<\\alpha_{2}\\ldots<\\alpha_{k}$. For such an $\\alpha$, we shall put $|\\alpha|:=k$ in the sequel. Thus, as a vector space, $\\operatorname{Cl}(V)$ is isomorphic to $A^{*}(V)$ (as algebras, these two spaces are of course different). In particular, the dimension of $\\operatorname{Cl}(V)$ as a vector space is $2^{n}$. Also, declaring this basis as being orthonormal, we obtain a scalar product on $\\operatorname{Cl}(V)$ extending the one on $V$.\n\nWe define the degree of as being $|\\alpha|$. The of degree $k$ generate the $\\epsilon_{\\alpha}$ $e_{\\alpha}$ subset $\\operatorname{Cl}^{k}(V)$ of elements of degree $k$. We have  \n\n$$\n\\begin{array}{r}{\\mathrm{Cl}^{0}=\\mathbb{R}}\\\\ {\\mathrm{Cl}^{1}=V.}\\end{array}\n$$  \n\nFinally, we let $\\operatorname{Cl}^{e v}(V)$ and $\\mathrm{Cl}^{o d d}(V)$ be the subspaces of elements of even resp. odd degree. The former is a subalgebra of $\\operatorname{Cl}(V)$, but not the latter.\n\nLemma 1.8.1 The center of $\\operatorname{Cl}(V)$ consists of those elements that commute with all $v\\in\\operatorname{Cl}^{1}(V)=V$. For $n$ even, the center is $\\mathrm{Cl}^{0}(V)$, while for $n$ odd it is $\\mathrm{Cl}^{0}(V)\\oplus\\mathrm{Cl}^{n}(V)$.\n\nProof. It suffices to consider basis vectors $e_{\\alpha} = e_{\\alpha_{1}}\\ldots,e_{\\alpha_{k}}$ as above. For $j\\not\\in\\alpha$, we have  \n\n$$\ne_{\\alpha}e_{j}=(-1)^{|\\alpha|}e_{j}e_{\\alpha},\n$$  \n\nand thus $|\\alpha|$ has to be even for $\\epsilon_{\\alpha}$ to commute with $e_{j}$, while  \n\n$$\ne_{\\alpha}e_{\\alpha_{j}}=(-1)^{|\\alpha|-1}e_{\\alpha_{j}}e_{\\alpha},\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "In particular, in terms of our orthonormal basis e_1, \\ldots, e_n, we have e_i e_j = -e_j e_i for i \u2260 j.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/Riemannian_Geometry_And_Geometric_Analysis(Jo.pdf_69",
        "ID": "1222512c-05f4-4847-8e02-ddeafdc9dcb2",
        "questions": "What is the multiplication rule for the Clifford algebra Cl(V) in terms of the vectors v and w from the vector space V?",
        "answers": "$v w + w v = -2\\langle v, w\\rangle$",
        "context": "Necessarily nondegenerate quadratic form on $V$ would suffice, but here we have no need to investigate the most general possible construction. On the contrary, for our purposes it suffices to take $\\mathbb{R}^{n}$ with its standard Euclidean scalar product. An orthonormal basis will be denoted by $e_{1},\\ldots,e_{n}$.\n\nDefinition 1.8.1 The Clifford algebra $\\operatorname{Cl}(V)$, also denoted $\\mathrm{Cl}(n)$, is the quotient of the tensor algebra $\\bigoplus_{k\\geq0}V\\otimes\\ldots\\otimes V$ generated by $V$ by the two-sided ideal generated by all elements of the form $v\\otimes v+\\|v\\|^{2}$ for $v\\in V$.\n\nThus, the multiplication rule for the Clifford algebra $\\operatorname{Cl}(V)$ is  \n\n$$\nv w+w v=-2\\langle v,w\\rangle\n$$  \n\nIn particular, in terms of our orthonormal basis $e_{1},\\ldots,e_{n}$, we have  \n\n$$\ne_{i}{}^{2}=-1{\\mathrm{~and~}}e_{i}e_{j}=-e_{i}e_{j}{\\mathrm{~for~}}i\\neq j.\n$$  \n\nFrom this, one easily sees that a basis of $\\operatorname{Cl}(V)$ as a real vector space is given by  \n\n$$\ne_{0}:=1,\\quad e_{\\alpha}:=e_{\\alpha_{1}}e_{\\alpha_{2}}\\ldots e_{\\alpha_{k}}\n$$  \n\nwith $\\alpha=\\{\\alpha_{1},\\ldots,\\alpha_{k}\\}\\subset\\{1,\\ldots,n\\}$ and $\\alpha_{1}<\\alpha_{2}\\ldots<\\alpha_{k}$. For such an $\\alpha$, we shall put $|\\alpha|:=k$ in the sequel. Thus, as a vector space, $\\operatorname{Cl}(V)$ is isomorphic to $A^{*}(V)$ (as algebras, these two spaces are of course different). In particular, the dimension of $\\operatorname{Cl}(V)$ as a vector space is $2^{n}$. Also, declaring this basis as being orthonormal, we obtain a scalar product on $\\operatorname{Cl}(V)$ extending the one on $V$.\n\nWe define the degree of as being $|\\alpha|$. The of degree $k$ generate the $\\epsilon_{\\alpha}$ $e_{\\alpha}$ subset $\\operatorname{Cl}^{k}(V)$ of elements of degree $k$. We have  \n\n$$\n\\begin{array}{r}{\\mathrm{Cl}^{0}=\\mathbb{R}}\\\\ {\\mathrm{Cl}^{1}=V.}\\end{array}\n$$  \n\nFinally, we let $\\operatorname{Cl}^{e v}(V)$ and $\\mathrm{Cl}^{o d d}(V)$ be the subspaces of elements of even resp. odd degree. The former is a subalgebra of $\\operatorname{Cl}(V)$, but not the latter.\n\nLemma 1.8.1 The center of $\\operatorname{Cl}(V)$ consists of those elements that commute with all $v\\in\\operatorname{Cl}^{1}(V)=V$. For $n$ even, the center is $\\mathrm{Cl}^{0}(V)$, while for $n$ odd it is $\\mathrm{Cl}^{0}(V)\\oplus\\mathrm{Cl}^{n}(V)$.\n\nProof. It suffices to consider basis vectors $e_{\\alpha} = e_{\\alpha_{1}}\\ldots,e_{\\alpha_{k}}$ as above. For $j\\not\\in\\alpha$, we have  \n\n$$\ne_{\\alpha}e_{j}=(-1)^{|\\alpha|}e_{j}e_{\\alpha},\n$$  \n\nand thus $|\\alpha|$ has to be even for $\\epsilon_{\\alpha}$ to commute with $e_{j}$, while  \n\n$$\ne_{\\alpha}e_{\\alpha_{j}}=(-1)^{|\\alpha|-1}e_{\\alpha_{j}}e_{\\alpha},\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Thus, the multiplication rule for the Clifford algebra \\operatorname{Cl}(V) is $$ v w+w v=-2\\langle v,w\\rangle $$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/Riemannian_Geometry_And_Geometric_Analysis(Jo.pdf_69",
        "ID": "124a4251-9ba9-4899-b5cd-ad78c1c449eb",
        "questions": "What is the dimension of the Clifford algebra Cl(V) as a vector space when it has a basis with n elements?",
        "answers": "$2^{n}$",
        "context": "Necessarily nondegenerate quadratic form on $V$ would suffice, but here we have no need to investigate the most general possible construction. On the contrary, for our purposes it suffices to take $\\mathbb{R}^{n}$ with its standard Euclidean scalar product. An orthonormal basis will be denoted by $e_{1},\\ldots,e_{n}$.\n\nDefinition 1.8.1 The Clifford algebra $\\operatorname{Cl}(V)$, also denoted $\\mathrm{Cl}(n)$, is the quotient of the tensor algebra $\\bigoplus_{k\\geq0}V\\otimes\\ldots\\otimes V$ generated by $V$ by the two-sided ideal generated by all elements of the form $v\\otimes v+\\|v\\|^{2}$ for $v\\in V$.\n\nThus, the multiplication rule for the Clifford algebra $\\operatorname{Cl}(V)$ is  \n\n$$\nv w+w v=-2\\langle v,w\\rangle\n$$  \n\nIn particular, in terms of our orthonormal basis $e_{1},\\ldots,e_{n}$, we have  \n\n$$\ne_{i}{}^{2}=-1{\\mathrm{~and~}}e_{i}e_{j}=-e_{i}e_{j}{\\mathrm{~for~}}i\\neq j.\n$$  \n\nFrom this, one easily sees that a basis of $\\operatorname{Cl}(V)$ as a real vector space is given by  \n\n$$\ne_{0}:=1,\\quad e_{\\alpha}:=e_{\\alpha_{1}}e_{\\alpha_{2}}\\ldots e_{\\alpha_{k}}\n$$  \n\nwith $\\alpha=\\{\\alpha_{1},\\ldots,\\alpha_{k}\\}\\subset\\{1,\\ldots,n\\}$ and $\\alpha_{1}<\\alpha_{2}\\ldots<\\alpha_{k}$. For such an $\\alpha$, we shall put $|\\alpha|:=k$ in the sequel. Thus, as a vector space, $\\operatorname{Cl}(V)$ is isomorphic to $A^{*}(V)$ (as algebras, these two spaces are of course different). In particular, the dimension of $\\operatorname{Cl}(V)$ as a vector space is $2^{n}$. Also, declaring this basis as being orthonormal, we obtain a scalar product on $\\operatorname{Cl}(V)$ extending the one on $V$.\n\nWe define the degree of as being $|\\alpha|$. The of degree $k$ generate the $\\epsilon_{\\alpha}$ $e_{\\alpha}$ subset $\\operatorname{Cl}^{k}(V)$ of elements of degree $k$. We have  \n\n$$\n\\begin{array}{r}{\\mathrm{Cl}^{0}=\\mathbb{R}}\\\\ {\\mathrm{Cl}^{1}=V.}\\end{array}\n$$  \n\nFinally, we let $\\operatorname{Cl}^{e v}(V)$ and $\\mathrm{Cl}^{o d d}(V)$ be the subspaces of elements of even resp. odd degree. The former is a subalgebra of $\\operatorname{Cl}(V)$, but not the latter.\n\nLemma 1.8.1 The center of $\\operatorname{Cl}(V)$ consists of those elements that commute with all $v\\in\\operatorname{Cl}^{1}(V)=V$. For $n$ even, the center is $\\mathrm{Cl}^{0}(V)$, while for $n$ odd it is $\\mathrm{Cl}^{0}(V)\\oplus\\mathrm{Cl}^{n}(V)$.\n\nProof. It suffices to consider basis vectors $e_{\\alpha} = e_{\\alpha_{1}}\\ldots,e_{\\alpha_{k}}$ as above. For $j\\not\\in\\alpha$, we have  \n\n$$\ne_{\\alpha}e_{j}=(-1)^{|\\alpha|}e_{j}e_{\\alpha},\n$$  \n\nand thus $|\\alpha|$ has to be even for $\\epsilon_{\\alpha}$ to commute with $e_{j}$, while  \n\n$$\ne_{\\alpha}e_{\\alpha_{j}}=(-1)^{|\\alpha|-1}e_{\\alpha_{j}}e_{\\alpha},\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Numeric",
        "evidence_source": "equation",
        "evidence_context": "In particular, the dimension of \\operatorname{Cl}(V) as a vector space is $2^{n}$.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/Riemannian_Geometry_And_Geometric_Analysis(Jo.pdf_69",
        "ID": "124f4f60-8d03-4eec-af5a-0b3bee191416",
        "questions": "What is the condition on the degree |\u03b1| of an element e_\u03b1 from Cl(V) for it to commute with all basis vectors e_j not in \u03b1?",
        "answers": "k has to be even",
        "context": "Necessarily nondegenerate quadratic form on $V$ would suffice, but here we have no need to investigate the most general possible construction. On the contrary, for our purposes it suffices to take $\\mathbb{R}^{n}$ with its standard Euclidean scalar product. An orthonormal basis will be denoted by $e_{1},\\ldots,e_{n}$.\n\nDefinition 1.8.1 The Clifford algebra $\\operatorname{Cl}(V)$, also denoted $\\mathrm{Cl}(n)$, is the quotient of the tensor algebra $\\bigoplus_{k\\geq0}V\\otimes\\ldots\\otimes V$ generated by $V$ by the two-sided ideal generated by all elements of the form $v\\otimes v+\\|v\\|^{2}$ for $v\\in V$.\n\nThus, the multiplication rule for the Clifford algebra $\\operatorname{Cl}(V)$ is  \n\n$$\nv w+w v=-2\\langle v,w\\rangle\n$$  \n\nIn particular, in terms of our orthonormal basis $e_{1},\\ldots,e_{n}$, we have  \n\n$$\ne_{i}{}^{2}=-1{\\mathrm{~and~}}e_{i}e_{j}=-e_{i}e_{j}{\\mathrm{~for~}}i\\neq j.\n$$  \n\nFrom this, one easily sees that a basis of $\\operatorname{Cl}(V)$ as a real vector space is given by  \n\n$$\ne_{0}:=1,\\quad e_{\\alpha}:=e_{\\alpha_{1}}e_{\\alpha_{2}}\\ldots e_{\\alpha_{k}}\n$$  \n\nwith $\\alpha=\\{\\alpha_{1},\\ldots,\\alpha_{k}\\}\\subset\\{1,\\ldots,n\\}$ and $\\alpha_{1}<\\alpha_{2}\\ldots<\\alpha_{k}$. For such an $\\alpha$, we shall put $|\\alpha|:=k$ in the sequel. Thus, as a vector space, $\\operatorname{Cl}(V)$ is isomorphic to $A^{*}(V)$ (as algebras, these two spaces are of course different). In particular, the dimension of $\\operatorname{Cl}(V)$ as a vector space is $2^{n}$. Also, declaring this basis as being orthonormal, we obtain a scalar product on $\\operatorname{Cl}(V)$ extending the one on $V$.\n\nWe define the degree of as being $|\\alpha|$. The of degree $k$ generate the $\\epsilon_{\\alpha}$ $e_{\\alpha}$ subset $\\operatorname{Cl}^{k}(V)$ of elements of degree $k$. We have  \n\n$$\n\\begin{array}{r}{\\mathrm{Cl}^{0}=\\mathbb{R}}\\\\ {\\mathrm{Cl}^{1}=V.}\\end{array}\n$$  \n\nFinally, we let $\\operatorname{Cl}^{e v}(V)$ and $\\mathrm{Cl}^{o d d}(V)$ be the subspaces of elements of even resp. odd degree. The former is a subalgebra of $\\operatorname{Cl}(V)$, but not the latter.\n\nLemma 1.8.1 The center of $\\operatorname{Cl}(V)$ consists of those elements that commute with all $v\\in\\operatorname{Cl}^{1}(V)=V$. For $n$ even, the center is $\\mathrm{Cl}^{0}(V)$, while for $n$ odd it is $\\mathrm{Cl}^{0}(V)\\oplus\\mathrm{Cl}^{n}(V)$.\n\nProof. It suffices to consider basis vectors $e_{\\alpha} = e_{\\alpha_{1}}\\ldots,e_{\\alpha_{k}}$ as above. For $j\\not\\in\\alpha$, we have  \n\n$$\ne_{\\alpha}e_{j}=(-1)^{|\\alpha|}e_{j}e_{\\alpha},\n$$  \n\nand thus $|\\alpha|$ has to be even for $\\epsilon_{\\alpha}$ to commute with $e_{j}$, while  \n\n$$\ne_{\\alpha}e_{\\alpha_{j}}=(-1)^{|\\alpha|-1}e_{\\alpha_{j}}e_{\\alpha},\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "e_{\\alpha}e_{j}=(-1)^{|\\alpha|}e_{j}e_{\\alpha}, and thus |\\alpha| has to be even for \\epsilon_{\\alpha} to commute with e_{j},",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/eng-88486.pdf_102",
        "ID": "12564ae3-d11d-4dcc-a7be-1b754868f62d",
        "questions": "What is the formula for the diffusion coefficient as a function of temperature in terms of $D_{o}$, $E_{A}$, and $kT$ in a semiconductor?",
        "answers": "$D(T)=D_{o}e^{-\\frac{E_{a}}{k T}}$",
        "context": "# 4.4: Fick's First Law  \n\nWe talked about diffusion in the context of diodes, and described Fick's First Law of Diffusion for some particle concentration  $N(x,\\,t)$  \n\n$$\n\\operatorname{Flux}=(-D){\\frac{\\mathrm{d}N(x,t)}{\\mathrm{d}x}}\\qquad\\operatorname{Fick's}\\operatorname{First}\\operatorname{Law}\\,\\operatorname{of}\\operatorname{Diffusion}\n$$  \n\n$D$  is the diffusion coefficient and has units of cm/sec  \n\nIn a semiconductor, impurities move about either interstitially, which means they travel around in-between the lattice sites (Figure 4.4.1), or they move by substitutional diffusion, which means they hop from lattice site to lattice site (Figure 4.4.2). Substitutional diffusion is only possible if the lattice has a number of vacancies, or empty lattice sites, scattered throughout the crystal, so that there are places into which the impurity can move. Moving interstitially requires energy to get over the potential barrier of the regions between the lattice sites. Energy is required to form the vacancies for substitutional diffusion. Thus, for either form of diffusion, the diffusion coefficient  $D$  , is a strong function of temperature.  \n\n![](images/dcf6db58e4708c5881f50cd2cbdfc27785f1326083807aed06250968b7597625.jpg)  \nFigure 4.4.1: Interstitial diffusion  \n\n![](images/5a79dd51d7b7ae3def1e1b838728f46e3aed59dc3a8166f894e99d27295e1dc8.jpg)  \nFigure 4.4.2: Substitutional diffusion  \n\nTo a very good degree of accuracy, one can describe the temperature dependence of the diffusion coefficient with an activation energy  $E_{A}$  such that:  \n\n$$\nD(T)=D_{o}e^{-\\frac{E_{a}}{k T}}\n$$  \n\nThe activation energy  $E_{A}$   and coefficient  $D_{o}$   are obtained from a plot of the natural log of  $D$  vs.  $\\frac{1}{k T}$  (Figure 4.4.3). The slope gives  $E_{A}$   and the projection to infinite  $T$   $\\left(\\frac{1}{T}\\rightarrow0\\right)$  gives  $\\ln(D_{o})$  \n\n![](images/277098daccfb7310c0a4d4705cfa0638c9fff14ba6ab18da525c889ef8d939d8.jpg)  \nFigure 4.4.3: Arrhenius plot of diffusion constant  \n\nThe continuity equation holds for motion of impurities just like it does for anything else, so the divergence of the flux, $\\operatorname{div}(F)$  must equal the negative of the time rate of change of the concentration of the impurities, or, in one dimension:",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "To a very good degree of accuracy, one can describe the temperature dependence of the diffusion coefficient with an activation energy  $E_{A}$  such that:  $$D(T)=D_{o}e^{-\\frac{E_{a}}{k T}}$$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/eng-88486.pdf_102",
        "ID": "12665bdc-a55f-4546-a6ce-196954f78e89",
        "questions": "Is the diffusion coefficient $D$ in semiconductors affected by temperature?",
        "answers": "Yes",
        "context": "# 4.4: Fick's First Law  \n\nWe talked about diffusion in the context of diodes, and described Fick's First Law of Diffusion for some particle concentration  $N(x,\\,t)$  \n\n$$\n\\operatorname{Flux}=(-D){\\frac{\\mathrm{d}N(x,t)}{\\mathrm{d}x}}\\qquad\\operatorname{Fick's}\\operatorname{First}\\operatorname{Law}\\,\\operatorname{of}\\operatorname{Diffusion}\n$$  \n\n$D$  is the diffusion coefficient and has units of cm/sec  \n\nIn a semiconductor, impurities move about either interstitially, which means they travel around in-between the lattice sites (Figure 4.4.1), or they move by substitutional diffusion, which means they hop from lattice site to lattice site (Figure 4.4.2). Substitutional diffusion is only possible if the lattice has a number of vacancies, or empty lattice sites, scattered throughout the crystal, so that there are places into which the impurity can move. Moving interstitially requires energy to get over the potential barrier of the regions between the lattice sites. Energy is required to form the vacancies for substitutional diffusion. Thus, for either form of diffusion, the diffusion coefficient  $D$  , is a strong function of temperature.  \n\n![](images/dcf6db58e4708c5881f50cd2cbdfc27785f1326083807aed06250968b7597625.jpg)  \nFigure 4.4.1: Interstitial diffusion  \n\n![](images/5a79dd51d7b7ae3def1e1b838728f46e3aed59dc3a8166f894e99d27295e1dc8.jpg)  \nFigure 4.4.2: Substitutional diffusion  \n\nTo a very good degree of accuracy, one can describe the temperature dependence of the diffusion coefficient with an activation energy  $E_{A}$  such that:  \n\n$$\nD(T)=D_{o}e^{-\\frac{E_{a}}{k T}}\n$$  \n\nThe activation energy  $E_{A}$   and coefficient  $D_{o}$   are obtained from a plot of the natural log of  $D$  vs.  $\\frac{1}{k T}$  (Figure 4.4.3). The slope gives  $E_{A}$   and the projection to infinite  $T$   $\\left(\\frac{1}{T}\\rightarrow0\\right)$  gives  $\\ln(D_{o})$  \n\n![](images/277098daccfb7310c0a4d4705cfa0638c9fff14ba6ab18da525c889ef8d939d8.jpg)  \nFigure 4.4.3: Arrhenius plot of diffusion constant  \n\nThe continuity equation holds for motion of impurities just like it does for anything else, so the divergence of the flux, $\\operatorname{div}(F)$  must equal the negative of the time rate of change of the concentration of the impurities, or, in one dimension:",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Yes/No",
        "evidence_source": "text",
        "evidence_context": "Thus, for either form of diffusion, the diffusion coefficient  $D$, is a strong function of temperature.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/eng-88486.pdf_102",
        "ID": "126bbdd7-f8d1-4d15-a017-68c509c0fbd4",
        "questions": "What kind of plot is used to obtain the activation energy $E_{A}$ and coefficient $D_{o}$ for the diffusion coefficient in semiconductors?",
        "answers": "A plot of the natural log of $D$ vs. $\\frac{1}{k T}$",
        "context": "# 4.4: Fick's First Law  \n\nWe talked about diffusion in the context of diodes, and described Fick's First Law of Diffusion for some particle concentration  $N(x,\\,t)$  \n\n$$\n\\operatorname{Flux}=(-D){\\frac{\\mathrm{d}N(x,t)}{\\mathrm{d}x}}\\qquad\\operatorname{Fick's}\\operatorname{First}\\operatorname{Law}\\,\\operatorname{of}\\operatorname{Diffusion}\n$$  \n\n$D$  is the diffusion coefficient and has units of cm/sec  \n\nIn a semiconductor, impurities move about either interstitially, which means they travel around in-between the lattice sites (Figure 4.4.1), or they move by substitutional diffusion, which means they hop from lattice site to lattice site (Figure 4.4.2). Substitutional diffusion is only possible if the lattice has a number of vacancies, or empty lattice sites, scattered throughout the crystal, so that there are places into which the impurity can move. Moving interstitially requires energy to get over the potential barrier of the regions between the lattice sites. Energy is required to form the vacancies for substitutional diffusion. Thus, for either form of diffusion, the diffusion coefficient  $D$  , is a strong function of temperature.  \n\n![](images/dcf6db58e4708c5881f50cd2cbdfc27785f1326083807aed06250968b7597625.jpg)  \nFigure 4.4.1: Interstitial diffusion  \n\n![](images/5a79dd51d7b7ae3def1e1b838728f46e3aed59dc3a8166f894e99d27295e1dc8.jpg)  \nFigure 4.4.2: Substitutional diffusion  \n\nTo a very good degree of accuracy, one can describe the temperature dependence of the diffusion coefficient with an activation energy  $E_{A}$  such that:  \n\n$$\nD(T)=D_{o}e^{-\\frac{E_{a}}{k T}}\n$$  \n\nThe activation energy  $E_{A}$   and coefficient  $D_{o}$   are obtained from a plot of the natural log of  $D$  vs.  $\\frac{1}{k T}$  (Figure 4.4.3). The slope gives  $E_{A}$   and the projection to infinite  $T$   $\\left(\\frac{1}{T}\\rightarrow0\\right)$  gives  $\\ln(D_{o})$  \n\n![](images/277098daccfb7310c0a4d4705cfa0638c9fff14ba6ab18da525c889ef8d939d8.jpg)  \nFigure 4.4.3: Arrhenius plot of diffusion constant  \n\nThe continuity equation holds for motion of impurities just like it does for anything else, so the divergence of the flux, $\\operatorname{div}(F)$  must equal the negative of the time rate of change of the concentration of the impurities, or, in one dimension:",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "The activation energy  $E_{A}$  and coefficient  $D_{o}$   are obtained from a plot of the natural log of  $D$  vs.  $\\frac{1}{k T}$  (Figure 4.4.3).",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/eng-88486.pdf_102",
        "ID": "126c8333-0452-4960-b406-05b0dd8b7681",
        "questions": "What is the formula that represents the flux of particles according to Fick's First Law of Diffusion in terms of the diffusion coefficient $D$ and particle concentration gradient $\\frac{dN(x,t)}{dx}$?",
        "answers": "(-D)\\frac{\\mathrm{d}N(x,t)}{\\mathrm{d}x}",
        "context": "# 4.4: Fick's First Law  \n\nWe talked about diffusion in the context of diodes, and described Fick's First Law of Diffusion for some particle concentration  $N(x,\\,t)$  \n\n$$\n\\operatorname{Flux}=(-D){\\frac{\\mathrm{d}N(x,t)}{\\mathrm{d}x}}\\qquad\\operatorname{Fick's}\\operatorname{First}\\operatorname{Law}\\,\\operatorname{of}\\operatorname{Diffusion}\n$$  \n\n$D$  is the diffusion coefficient and has units of cm/sec  \n\nIn a semiconductor, impurities move about either interstitially, which means they travel around in-between the lattice sites (Figure 4.4.1), or they move by substitutional diffusion, which means they hop from lattice site to lattice site (Figure 4.4.2). Substitutional diffusion is only possible if the lattice has a number of vacancies, or empty lattice sites, scattered throughout the crystal, so that there are places into which the impurity can move. Moving interstitially requires energy to get over the potential barrier of the regions between the lattice sites. Energy is required to form the vacancies for substitutional diffusion. Thus, for either form of diffusion, the diffusion coefficient  $D$  , is a strong function of temperature.  \n\n![](images/dcf6db58e4708c5881f50cd2cbdfc27785f1326083807aed06250968b7597625.jpg)  \nFigure 4.4.1: Interstitial diffusion  \n\n![](images/5a79dd51d7b7ae3def1e1b838728f46e3aed59dc3a8166f894e99d27295e1dc8.jpg)  \nFigure 4.4.2: Substitutional diffusion  \n\nTo a very good degree of accuracy, one can describe the temperature dependence of the diffusion coefficient with an activation energy  $E_{A}$  such that:  \n\n$$\nD(T)=D_{o}e^{-\\frac{E_{a}}{k T}}\n$$  \n\nThe activation energy  $E_{A}$   and coefficient  $D_{o}$   are obtained from a plot of the natural log of  $D$  vs.  $\\frac{1}{k T}$  (Figure 4.4.3). The slope gives  $E_{A}$   and the projection to infinite  $T$   $\\left(\\frac{1}{T}\\rightarrow0\\right)$  gives  $\\ln(D_{o})$  \n\n![](images/277098daccfb7310c0a4d4705cfa0638c9fff14ba6ab18da525c889ef8d939d8.jpg)  \nFigure 4.4.3: Arrhenius plot of diffusion constant  \n\nThe continuity equation holds for motion of impurities just like it does for anything else, so the divergence of the flux, $\\operatorname{div}(F)$  must equal the negative of the time rate of change of the concentration of the impurities, or, in one dimension:",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$\\operatorname{Flux}=(-D){\\frac{\\mathrm{d}N(x,t)}{\\mathrm{d}x}}\\qquad\\operatorname{Fick's}\\operatorname{First}\\operatorname{Law}\\,\\operatorname{of}\\operatorname{Diffusion}$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/eng-88486.pdf_102",
        "ID": "126f34dc-5e78-427a-b069-6899755e60a8",
        "questions": "How is the diffusion coefficient $D(T)$ expressed as a function of temperature given the activation energy $E_A$, pre-exponential factor $D_o$, and Boltzmann constant $k$?",
        "answers": "D(T)=D_{o}e^{-\frac{E_{a}}{k T}}",
        "context": "# 4.4: Fick's First Law  \n\nWe talked about diffusion in the context of diodes, and described Fick's First Law of Diffusion for some particle concentration  $N(x,\\,t)$  \n\n$$\n\\operatorname{Flux}=(-D){\\frac{\\mathrm{d}N(x,t)}{\\mathrm{d}x}}\\qquad\\operatorname{Fick's}\\operatorname{First}\\operatorname{Law}\\,\\operatorname{of}\\operatorname{Diffusion}\n$$  \n\n$D$  is the diffusion coefficient and has units of cm/sec  \n\nIn a semiconductor, impurities move about either interstitially, which means they travel around in-between the lattice sites (Figure 4.4.1), or they move by substitutional diffusion, which means they hop from lattice site to lattice site (Figure 4.4.2). Substitutional diffusion is only possible if the lattice has a number of vacancies, or empty lattice sites, scattered throughout the crystal, so that there are places into which the impurity can move. Moving interstitially requires energy to get over the potential barrier of the regions between the lattice sites. Energy is required to form the vacancies for substitutional diffusion. Thus, for either form of diffusion, the diffusion coefficient  $D$  , is a strong function of temperature.  \n\n![](images/dcf6db58e4708c5881f50cd2cbdfc27785f1326083807aed06250968b7597625.jpg)  \nFigure 4.4.1: Interstitial diffusion  \n\n![](images/5a79dd51d7b7ae3def1e1b838728f46e3aed59dc3a8166f894e99d27295e1dc8.jpg)  \nFigure 4.4.2: Substitutional diffusion  \n\nTo a very good degree of accuracy, one can describe the temperature dependence of the diffusion coefficient with an activation energy  $E_{A}$  such that:  \n\n$$\nD(T)=D_{o}e^{-\\frac{E_{a}}{k T}}\n$$  \n\nThe activation energy  $E_{A}$   and coefficient  $D_{o}$   are obtained from a plot of the natural log of  $D$  vs.  $\\frac{1}{k T}$  (Figure 4.4.3). The slope gives  $E_{A}$   and the projection to infinite  $T$   $\\left(\\frac{1}{T}\\rightarrow0\\right)$  gives  $\\ln(D_{o})$  \n\n![](images/277098daccfb7310c0a4d4705cfa0638c9fff14ba6ab18da525c889ef8d939d8.jpg)  \nFigure 4.4.3: Arrhenius plot of diffusion constant  \n\nThe continuity equation holds for motion of impurities just like it does for anything else, so the divergence of the flux, $\\operatorname{div}(F)$  must equal the negative of the time rate of change of the concentration of the impurities, or, in one dimension:",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$$ D(T)=D_{o}e^{-\\frac{E_{a}}{k T}} $$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/eng-88486.pdf_102",
        "ID": "1276bb2e-185f-4658-98ed-21757ebada36",
        "questions": "If the slope of the plot of the natural log of the diffusion coefficient $D$ versus $\\frac{1}{k T}$ gives $E_A$, what does the projection to infinite temperature $\\left(\\frac{1}{T}\\rightarrow0\\right)$ give?",
        "answers": "ln(D_o)",
        "context": "# 4.4: Fick's First Law  \n\nWe talked about diffusion in the context of diodes, and described Fick's First Law of Diffusion for some particle concentration  $N(x,\\,t)$  \n\n$$\n\\operatorname{Flux}=(-D){\\frac{\\mathrm{d}N(x,t)}{\\mathrm{d}x}}\\qquad\\operatorname{Fick's}\\operatorname{First}\\operatorname{Law}\\,\\operatorname{of}\\operatorname{Diffusion}\n$$  \n\n$D$  is the diffusion coefficient and has units of cm/sec  \n\nIn a semiconductor, impurities move about either interstitially, which means they travel around in-between the lattice sites (Figure 4.4.1), or they move by substitutional diffusion, which means they hop from lattice site to lattice site (Figure 4.4.2). Substitutional diffusion is only possible if the lattice has a number of vacancies, or empty lattice sites, scattered throughout the crystal, so that there are places into which the impurity can move. Moving interstitially requires energy to get over the potential barrier of the regions between the lattice sites. Energy is required to form the vacancies for substitutional diffusion. Thus, for either form of diffusion, the diffusion coefficient  $D$  , is a strong function of temperature.  \n\n![](images/dcf6db58e4708c5881f50cd2cbdfc27785f1326083807aed06250968b7597625.jpg)  \nFigure 4.4.1: Interstitial diffusion  \n\n![](images/5a79dd51d7b7ae3def1e1b838728f46e3aed59dc3a8166f894e99d27295e1dc8.jpg)  \nFigure 4.4.2: Substitutional diffusion  \n\nTo a very good degree of accuracy, one can describe the temperature dependence of the diffusion coefficient with an activation energy  $E_{A}$  such that:  \n\n$$\nD(T)=D_{o}e^{-\\frac{E_{a}}{k T}}\n$$  \n\nThe activation energy  $E_{A}$   and coefficient  $D_{o}$   are obtained from a plot of the natural log of  $D$  vs.  $\\frac{1}{k T}$  (Figure 4.4.3). The slope gives  $E_{A}$   and the projection to infinite  $T$   $\\left(\\frac{1}{T}\\rightarrow0\\right)$  gives  $\\ln(D_{o})$  \n\n![](images/277098daccfb7310c0a4d4705cfa0638c9fff14ba6ab18da525c889ef8d939d8.jpg)  \nFigure 4.4.3: Arrhenius plot of diffusion constant  \n\nThe continuity equation holds for motion of impurities just like it does for anything else, so the divergence of the flux, $\\operatorname{div}(F)$  must equal the negative of the time rate of change of the concentration of the impurities, or, in one dimension:",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "The slope gives $E_{A}$ and the projection to infinite $T$ $\\left(\\frac{1}{T}\\rightarrow0\\right)$ gives $\\ln(D_{o})$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/biz-26010.pdf_127",
        "ID": "1291b3fc-32b3-4a9c-ba43-e1e46bb35fd3",
        "questions": "What is the sales total for Product 1 according to the example for Wonderfood?",
        "answers": "60,000",
        "context": "# 5.8: Break Even Point for Multiple Products  \n\nAlthough you are likely to use cost-volume-profit analysis for a single product, you will more frequently use it in multi-product situations. The easiest way to use cost-volume-profit analysis for a multi-product company is to use dollars of sales as the volume measure. For CVP purposes, a multi-product company must assume a given product mix or sales mix. Product (or sales) mix refers to the proportion of the company's total sales for each type of product sold.  \n\nTo illustrate the computation of the break-even point for Wonderfood, a multi-product company that makes three types of cereal, assume the following historical data (percent is a percentage of sale, for each product, take the amount/sales and multiply by 100 to get the percentage):  \n\n$\n\\begin{tabular}{|l|c|c|c|c|c|c|c|c|}\n \n & \\multicolumn{2}{c|}{Product 1} & \\multicolumn{2}{c|}{Product 2} & \\multicolumn{2}{c|}{Product 3} & \\multicolumn{2}{c|}{Total} \\\\\n \n & Amount & Percent & Amount & Percent & Amount & Percent & Amount & Percent \\\\\n \nSales & 60,000 & 100\\% & 30,000 & 100\\% & 10,000 & 100\\% & 100,000 & 100\\% \\\\\n \nLess: variable costs & 40,000 & 67\\% & 16,000 & 53\\% & 4,000 & 40\\% & 60,000 & 60\\% \\\\\n \nContribution margin & 20,000 & 33\\% & 14,000 & 47\\% & 6,000 & 60\\% & 40,000 & 40\\% \\\\\n \n\\end{tabular}\n$\n\nWe use the data in the total columns to compute the break-even point. The contribution margin ratio is $40\\%$ (total contribution margin $\\S40{,}000,$ / total sales $\\mathbb{S}\\;100{,}000)$ . Assuming the product mix remains constant and fixed costs for the company are $\\S50{,}000$ break-even sales are $\\S125,\\!000$ computed as follows:  \n\n$\n\\begin{tabular}{|l|c|c|l|}\n \n\\multirow{2}{*}{BE in Sales Doloars=} & Fixed Costs & \\$50,000 & \\multirow{2}{*}{=\\$125,000} \\\\\n \n & Contribution Margin RATIO & 0.40 & \\\\\n \n\\end{tabular}\n$ \n\n[To check our answer: (\\$125,000 break even sales $\\times$ 0.40 contribution margin ratio) $-$ \\$50,000 fixed costs \\$0 net income.]  \n\nHere is a video example:  \n\n![](images/3a8a9398b403efdc917ae74f2f8161b64986424a766d47cc470282886f85d8e0.jpg)  \n\nA YouTube element has been excluded from this version of the text. You can view it online here:pb.libretexts.org/llmanagerialaccounting/?p=122  \n\nSince what we found in our example for Wonderfood is a total, we need to determine how much sales would be needed by each product to break even. To find the three product sales totals, we multiply total sales dollars by the percent of product (or sales) mix for each of the three products. The product mix for products 1, 2, and 3 is 60:30:10, respectively. That is, out of the \\$100,000 total",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Numeric",
        "evidence_source": "table",
        "evidence_context": "Sales & 60,000 & 100\\% & 30,000 & 100\\% & 10,000 & 100\\% & 100,000 & 100\\%",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/biz-26010.pdf_127",
        "ID": "12a1ae41-2f27-4e32-9589-6e6cd5708e7b",
        "questions": "What is the variable cost as a percentage of sales for Product 2 in the example provided for Wonderfood?",
        "answers": "53%",
        "context": "# 5.8: Break Even Point for Multiple Products  \n\nAlthough you are likely to use cost-volume-profit analysis for a single product, you will more frequently use it in multi-product situations. The easiest way to use cost-volume-profit analysis for a multi-product company is to use dollars of sales as the volume measure. For CVP purposes, a multi-product company must assume a given product mix or sales mix. Product (or sales) mix refers to the proportion of the company's total sales for each type of product sold.  \n\nTo illustrate the computation of the break-even point for Wonderfood, a multi-product company that makes three types of cereal, assume the following historical data (percent is a percentage of sale, for each product, take the amount/sales and multiply by 100 to get the percentage):  \n\n$\n\\begin{tabular}{|l|c|c|c|c|c|c|c|c|}\n \n & \\multicolumn{2}{c|}{Product 1} & \\multicolumn{2}{c|}{Product 2} & \\multicolumn{2}{c|}{Product 3} & \\multicolumn{2}{c|}{Total} \\\\\n \n & Amount & Percent & Amount & Percent & Amount & Percent & Amount & Percent \\\\\n \nSales & 60,000 & 100\\% & 30,000 & 100\\% & 10,000 & 100\\% & 100,000 & 100\\% \\\\\n \nLess: variable costs & 40,000 & 67\\% & 16,000 & 53\\% & 4,000 & 40\\% & 60,000 & 60\\% \\\\\n \nContribution margin & 20,000 & 33\\% & 14,000 & 47\\% & 6,000 & 60\\% & 40,000 & 40\\% \\\\\n \n\\end{tabular}\n$\n\nWe use the data in the total columns to compute the break-even point. The contribution margin ratio is $40\\%$ (total contribution margin $\\S40{,}000,$ / total sales $\\mathbb{S}\\;100{,}000)$ . Assuming the product mix remains constant and fixed costs for the company are $\\S50{,}000$ break-even sales are $\\S125,\\!000$ computed as follows:  \n\n$\n\\begin{tabular}{|l|c|c|l|}\n \n\\multirow{2}{*}{BE in Sales Doloars=} & Fixed Costs & \\$50,000 & \\multirow{2}{*}{=\\$125,000} \\\\\n \n & Contribution Margin RATIO & 0.40 & \\\\\n \n\\end{tabular}\n$ \n\n[To check our answer: (\\$125,000 break even sales $\\times$ 0.40 contribution margin ratio) $-$ \\$50,000 fixed costs \\$0 net income.]  \n\nHere is a video example:  \n\n![](images/3a8a9398b403efdc917ae74f2f8161b64986424a766d47cc470282886f85d8e0.jpg)  \n\nA YouTube element has been excluded from this version of the text. You can view it online here:pb.libretexts.org/llmanagerialaccounting/?p=122  \n\nSince what we found in our example for Wonderfood is a total, we need to determine how much sales would be needed by each product to break even. To find the three product sales totals, we multiply total sales dollars by the percent of product (or sales) mix for each of the three products. The product mix for products 1, 2, and 3 is 60:30:10, respectively. That is, out of the \\$100,000 total",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "table",
        "evidence_context": "Less: variable costs & 40,000 & 67\\% & 16,000 & 53\\% & 4,000 & 40\\% & 60,000 & 60\\%",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/biz-26010.pdf_127",
        "ID": "12ae37a8-49d1-4424-9429-6b689ce2b312",
        "questions": "If the fixed costs for Wonderfood are $50,000 and the contribution margin ratio is 40%, what are the break-even sales in dollars?",
        "answers": "125,000",
        "context": "# 5.8: Break Even Point for Multiple Products  \n\nAlthough you are likely to use cost-volume-profit analysis for a single product, you will more frequently use it in multi-product situations. The easiest way to use cost-volume-profit analysis for a multi-product company is to use dollars of sales as the volume measure. For CVP purposes, a multi-product company must assume a given product mix or sales mix. Product (or sales) mix refers to the proportion of the company's total sales for each type of product sold.  \n\nTo illustrate the computation of the break-even point for Wonderfood, a multi-product company that makes three types of cereal, assume the following historical data (percent is a percentage of sale, for each product, take the amount/sales and multiply by 100 to get the percentage):  \n\n$\n\\begin{tabular}{|l|c|c|c|c|c|c|c|c|}\n \n & \\multicolumn{2}{c|}{Product 1} & \\multicolumn{2}{c|}{Product 2} & \\multicolumn{2}{c|}{Product 3} & \\multicolumn{2}{c|}{Total} \\\\\n \n & Amount & Percent & Amount & Percent & Amount & Percent & Amount & Percent \\\\\n \nSales & 60,000 & 100\\% & 30,000 & 100\\% & 10,000 & 100\\% & 100,000 & 100\\% \\\\\n \nLess: variable costs & 40,000 & 67\\% & 16,000 & 53\\% & 4,000 & 40\\% & 60,000 & 60\\% \\\\\n \nContribution margin & 20,000 & 33\\% & 14,000 & 47\\% & 6,000 & 60\\% & 40,000 & 40\\% \\\\\n \n\\end{tabular}\n$\n\nWe use the data in the total columns to compute the break-even point. The contribution margin ratio is $40\\%$ (total contribution margin $\\S40{,}000,$ / total sales $\\mathbb{S}\\;100{,}000)$ . Assuming the product mix remains constant and fixed costs for the company are $\\S50{,}000$ break-even sales are $\\S125,\\!000$ computed as follows:  \n\n$\n\\begin{tabular}{|l|c|c|l|}\n \n\\multirow{2}{*}{BE in Sales Doloars=} & Fixed Costs & \\$50,000 & \\multirow{2}{*}{=\\$125,000} \\\\\n \n & Contribution Margin RATIO & 0.40 & \\\\\n \n\\end{tabular}\n$ \n\n[To check our answer: (\\$125,000 break even sales $\\times$ 0.40 contribution margin ratio) $-$ \\$50,000 fixed costs \\$0 net income.]  \n\nHere is a video example:  \n\n![](images/3a8a9398b403efdc917ae74f2f8161b64986424a766d47cc470282886f85d8e0.jpg)  \n\nA YouTube element has been excluded from this version of the text. You can view it online here:pb.libretexts.org/llmanagerialaccounting/?p=122  \n\nSince what we found in our example for Wonderfood is a total, we need to determine how much sales would be needed by each product to break even. To find the three product sales totals, we multiply total sales dollars by the percent of product (or sales) mix for each of the three products. The product mix for products 1, 2, and 3 is 60:30:10, respectively. That is, out of the \\$100,000 total",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Numeric",
        "evidence_source": "text",
        "evidence_context": "Assuming the product mix remains constant and fixed costs for the company are \\S50{,}000 break-even sales are \\S125,\\!000 computed as follows:",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/biz-26010.pdf_127",
        "ID": "12ccfc6b-afd4-4b68-aa8e-892e93b29e24",
        "questions": "What is the total sales amount for Product 1?",
        "answers": "60,000",
        "context": "# 5.8: Break Even Point for Multiple Products  \n\nAlthough you are likely to use cost-volume-profit analysis for a single product, you will more frequently use it in multi-product situations. The easiest way to use cost-volume-profit analysis for a multi-product company is to use dollars of sales as the volume measure. For CVP purposes, a multi-product company must assume a given product mix or sales mix. Product (or sales) mix refers to the proportion of the company's total sales for each type of product sold.  \n\nTo illustrate the computation of the break-even point for Wonderfood, a multi-product company that makes three types of cereal, assume the following historical data (percent is a percentage of sale, for each product, take the amount/sales and multiply by 100 to get the percentage):  \n\n$\n\\begin{tabular}{|l|c|c|c|c|c|c|c|c|}\n \n & \\multicolumn{2}{c|}{Product 1} & \\multicolumn{2}{c|}{Product 2} & \\multicolumn{2}{c|}{Product 3} & \\multicolumn{2}{c|}{Total} \\\\\n \n & Amount & Percent & Amount & Percent & Amount & Percent & Amount & Percent \\\\\n \nSales & 60,000 & 100\\% & 30,000 & 100\\% & 10,000 & 100\\% & 100,000 & 100\\% \\\\\n \nLess: variable costs & 40,000 & 67\\% & 16,000 & 53\\% & 4,000 & 40\\% & 60,000 & 60\\% \\\\\n \nContribution margin & 20,000 & 33\\% & 14,000 & 47\\% & 6,000 & 60\\% & 40,000 & 40\\% \\\\\n \n\\end{tabular}\n$\n\nWe use the data in the total columns to compute the break-even point. The contribution margin ratio is $40\\%$ (total contribution margin $\\S40{,}000,$ / total sales $\\mathbb{S}\\;100{,}000)$ . Assuming the product mix remains constant and fixed costs for the company are $\\S50{,}000$ break-even sales are $\\S125,\\!000$ computed as follows:  \n\n$\n\\begin{tabular}{|l|c|c|l|}\n \n\\multirow{2}{*}{BE in Sales Doloars=} & Fixed Costs & \\$50,000 & \\multirow{2}{*}{=\\$125,000} \\\\\n \n & Contribution Margin RATIO & 0.40 & \\\\\n \n\\end{tabular}\n$ \n\n[To check our answer: (\\$125,000 break even sales $\\times$ 0.40 contribution margin ratio) $-$ \\$50,000 fixed costs \\$0 net income.]  \n\nHere is a video example:  \n\n![](images/3a8a9398b403efdc917ae74f2f8161b64986424a766d47cc470282886f85d8e0.jpg)  \n\nA YouTube element has been excluded from this version of the text. You can view it online here:pb.libretexts.org/llmanagerialaccounting/?p=122  \n\nSince what we found in our example for Wonderfood is a total, we need to determine how much sales would be needed by each product to break even. To find the three product sales totals, we multiply total sales dollars by the percent of product (or sales) mix for each of the three products. The product mix for products 1, 2, and 3 is 60:30:10, respectively. That is, out of the \\$100,000 total",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Numeric",
        "evidence_source": "equation",
        "evidence_context": "Sales & 60,000 & 100\\% & 30,000 & 100\\% & 10,000 & 100\\% & 100,000 & 100\\%",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/biz-26010.pdf_127",
        "ID": "12ce3ed7-1c9b-4dc9-9bfa-25a0f2992e2e",
        "questions": "How is the break-even point in sales dollars calculated for Wonderfood, assuming a constant product mix and fixed costs of $50,000?",
        "answers": "BE in Sales Doloars= Fixed Costs / Contribution Margin RATIO = $125,000",
        "context": "# 5.8: Break Even Point for Multiple Products  \n\nAlthough you are likely to use cost-volume-profit analysis for a single product, you will more frequently use it in multi-product situations. The easiest way to use cost-volume-profit analysis for a multi-product company is to use dollars of sales as the volume measure. For CVP purposes, a multi-product company must assume a given product mix or sales mix. Product (or sales) mix refers to the proportion of the company's total sales for each type of product sold.  \n\nTo illustrate the computation of the break-even point for Wonderfood, a multi-product company that makes three types of cereal, assume the following historical data (percent is a percentage of sale, for each product, take the amount/sales and multiply by 100 to get the percentage):  \n\n$\n\\begin{tabular}{|l|c|c|c|c|c|c|c|c|}\n \n & \\multicolumn{2}{c|}{Product 1} & \\multicolumn{2}{c|}{Product 2} & \\multicolumn{2}{c|}{Product 3} & \\multicolumn{2}{c|}{Total} \\\\\n \n & Amount & Percent & Amount & Percent & Amount & Percent & Amount & Percent \\\\\n \nSales & 60,000 & 100\\% & 30,000 & 100\\% & 10,000 & 100\\% & 100,000 & 100\\% \\\\\n \nLess: variable costs & 40,000 & 67\\% & 16,000 & 53\\% & 4,000 & 40\\% & 60,000 & 60\\% \\\\\n \nContribution margin & 20,000 & 33\\% & 14,000 & 47\\% & 6,000 & 60\\% & 40,000 & 40\\% \\\\\n \n\\end{tabular}\n$\n\nWe use the data in the total columns to compute the break-even point. The contribution margin ratio is $40\\%$ (total contribution margin $\\S40{,}000,$ / total sales $\\mathbb{S}\\;100{,}000)$ . Assuming the product mix remains constant and fixed costs for the company are $\\S50{,}000$ break-even sales are $\\S125,\\!000$ computed as follows:  \n\n$\n\\begin{tabular}{|l|c|c|l|}\n \n\\multirow{2}{*}{BE in Sales Doloars=} & Fixed Costs & \\$50,000 & \\multirow{2}{*}{=\\$125,000} \\\\\n \n & Contribution Margin RATIO & 0.40 & \\\\\n \n\\end{tabular}\n$ \n\n[To check our answer: (\\$125,000 break even sales $\\times$ 0.40 contribution margin ratio) $-$ \\$50,000 fixed costs \\$0 net income.]  \n\nHere is a video example:  \n\n![](images/3a8a9398b403efdc917ae74f2f8161b64986424a766d47cc470282886f85d8e0.jpg)  \n\nA YouTube element has been excluded from this version of the text. You can view it online here:pb.libretexts.org/llmanagerialaccounting/?p=122  \n\nSince what we found in our example for Wonderfood is a total, we need to determine how much sales would be needed by each product to break even. To find the three product sales totals, we multiply total sales dollars by the percent of product (or sales) mix for each of the three products. The product mix for products 1, 2, and 3 is 60:30:10, respectively. That is, out of the \\$100,000 total",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "\\multirow{2}{*}{BE in Sales Doloars=} & Fixed Costs & \\$50,000 & \\multirow{2}{*}{=\\$125,000} \\",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/biz-26010.pdf_127",
        "ID": "12d2d972-0dbe-4e15-8be7-3c9903b57080",
        "questions": "What is the contribution margin percentage for Product 3?",
        "answers": "60\\%",
        "context": "# 5.8: Break Even Point for Multiple Products  \n\nAlthough you are likely to use cost-volume-profit analysis for a single product, you will more frequently use it in multi-product situations. The easiest way to use cost-volume-profit analysis for a multi-product company is to use dollars of sales as the volume measure. For CVP purposes, a multi-product company must assume a given product mix or sales mix. Product (or sales) mix refers to the proportion of the company's total sales for each type of product sold.  \n\nTo illustrate the computation of the break-even point for Wonderfood, a multi-product company that makes three types of cereal, assume the following historical data (percent is a percentage of sale, for each product, take the amount/sales and multiply by 100 to get the percentage):  \n\n$\n\\begin{tabular}{|l|c|c|c|c|c|c|c|c|}\n \n & \\multicolumn{2}{c|}{Product 1} & \\multicolumn{2}{c|}{Product 2} & \\multicolumn{2}{c|}{Product 3} & \\multicolumn{2}{c|}{Total} \\\\\n \n & Amount & Percent & Amount & Percent & Amount & Percent & Amount & Percent \\\\\n \nSales & 60,000 & 100\\% & 30,000 & 100\\% & 10,000 & 100\\% & 100,000 & 100\\% \\\\\n \nLess: variable costs & 40,000 & 67\\% & 16,000 & 53\\% & 4,000 & 40\\% & 60,000 & 60\\% \\\\\n \nContribution margin & 20,000 & 33\\% & 14,000 & 47\\% & 6,000 & 60\\% & 40,000 & 40\\% \\\\\n \n\\end{tabular}\n$\n\nWe use the data in the total columns to compute the break-even point. The contribution margin ratio is $40\\%$ (total contribution margin $\\S40{,}000,$ / total sales $\\mathbb{S}\\;100{,}000)$ . Assuming the product mix remains constant and fixed costs for the company are $\\S50{,}000$ break-even sales are $\\S125,\\!000$ computed as follows:  \n\n$\n\\begin{tabular}{|l|c|c|l|}\n \n\\multirow{2}{*}{BE in Sales Doloars=} & Fixed Costs & \\$50,000 & \\multirow{2}{*}{=\\$125,000} \\\\\n \n & Contribution Margin RATIO & 0.40 & \\\\\n \n\\end{tabular}\n$ \n\n[To check our answer: (\\$125,000 break even sales $\\times$ 0.40 contribution margin ratio) $-$ \\$50,000 fixed costs \\$0 net income.]  \n\nHere is a video example:  \n\n![](images/3a8a9398b403efdc917ae74f2f8161b64986424a766d47cc470282886f85d8e0.jpg)  \n\nA YouTube element has been excluded from this version of the text. You can view it online here:pb.libretexts.org/llmanagerialaccounting/?p=122  \n\nSince what we found in our example for Wonderfood is a total, we need to determine how much sales would be needed by each product to break even. To find the three product sales totals, we multiply total sales dollars by the percent of product (or sales) mix for each of the three products. The product mix for products 1, 2, and 3 is 60:30:10, respectively. That is, out of the \\$100,000 total",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Contribution margin & 20,000 & 33\\% & 14,000 & 47\\% & 6,000 & 60\\% & 40,000 & 40\\%",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/The_Mathematics_Of_Diffusion(Ni).pdf_56",
        "ID": "12e00905-d492-4f25-aedb-c324bdff359f",
        "questions": "For the Neumann problem in the annulus case with a domain given by $\\Omega=\\{x \\in \\mathbb{R}^{n} \\mid 0<a<|x|<b\\}$, where does the solution concentrate for small $\u000barepsilon$?",
        "answers": "near the outer boundary $|x|=b$",
        "context": "which can be achieved if $M^{\\prime}(1)>0$ (since $\\varepsilon\\rho\\to1$ and $\\begin{array}{r}{\\frac{1}{\\varepsilon}-\\rho\\sim|\\log\\varepsilon|)}\\end{array}$  \n\nFor the Dirichlet case, (3.30) and (3.32), we define similarly the functionals $\\widetilde{J}_{\\varepsilon,D}$ and $\\Psi_{\\varepsilon,D}$ and the expansion corresponding to (3.34) now reads as follows:  \n\n$$\n\\varepsilon^{n-1}\\Psi_{\\varepsilon,D}(\\rho)=M(\\varepsilon\\rho)\\left(\\alpha+\\beta e^{-2\\lambda(\\frac{1}{\\varepsilon}-\\rho)}\\right)+\\mathrm{higher-order\\;terms}.\n$$  \n\n$\\beta e^{-2\\lambda(\\frac{1}{\\varepsilon}-\\rho)}$ which reflects the different, or opposite, effects of Dirichlet and Neumann boundary conditions. Heuristically, when $V\\equiv1$, the first term in (3.34) and (3.35) is due to the volume energy which always has a tendency to \u201cshrink\u201d (in order to minimize), while the second $\\pm\\beta e^{-2\\lambda(\\frac{1}{\\varepsilon}-\\rho)}$ the boundary \u201cpushes\u201d the mass of the solution away from the boundary (therefore only single-peak solutions are possible), but in the Neumann case the boundary \u201cpulls\u201d the mass of the solution and thereby reaches a balance at $\\varepsilon\\rho=r_{\\varepsilon}\\sim1-\\varepsilon|\\log\\varepsilon|$ creating an extra solution.  \n\nWe remark that the method described above also applies to the annulus case and yields the following interesting results for $V\\equiv1$, which illustrate the opposite effects between Dirichlet and Neumann boundary conditions most vividly.  \n\n# Theorem 3.11 (see [AMN3]).  \n\n(i) For every $p>1$ and $\\varepsilon$ small, the Neumann problem (3.1) with $\\Omega=\\{x\\in\\mathbb{R}^{n}\\mid0<a<$   $|x|<b\\}$ possesses a solution concentrating at $|x|=r_{\\varepsilon}$, where $b-r_{\\varepsilon}\\sim\\varepsilon|\\log\\varepsilon|$, near the outer boundary $|x|=b$.  \n\n(ii) For every $p>1$ and $\\varepsilon$ small, the Dirichlet problem (3.2) with $\\Omega=\\{x\\in\\mathbb{R}^{n}\\,\\vert\\,0<a<$   $|x|<b\\}$ possesses a solution concentrating at $|x|=r_{\\varepsilon}$, where $r_{\\varepsilon}-a\\sim\\varepsilon|\\log\\varepsilon|$, near the inner boundary $|x|=a$.  \n\nObserve that from the \u201cmoving plane\u201d method [GNN1] it follows easily that the Dirichlet problem (3.2) does not have a solution concentrating on a sphere near the outer boundary $|x|=b$.  \n\nIn conclusion, we mention that the method of Theorem 3.10 can be extended to produce solutions with $k$-dimensional concentration sets, but again, some symmetry assumptions are needed. Other interesting progress in this direction includes a one-dimensional concentration set in the interior of a two-dimensional domain due to [WY]. The conjecture stated at the beginning of this section remains largely a major open problem.  \n\n# 3.1.4 Remarks  \n\nIn Section 3.1, we have considered the various concentration phenomena for essentially just one equation, namely,  \n\n$$\n\\varepsilon^{2}\\Delta u-u+u^{p}=0\n$$  \n\nin a bounded domain $\\Omega$ under either Dirichlet or Neumann boundary conditions in (3.2) or (3.1), respectively. However, since (3.36) is quite basic, similar phenomena could be",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "For every $p>1$ and $\u000barepsilon$ small, the Neumann problem (3.1) with $\\Omega=\\{x \\in \\mathbb{R}^{n} \\mid 0<a<|x|<b\\}$ possesses a solution concentrating at $|x|=r_{\u000barepsilon}$, where $b-r_{\u000barepsilon}\\sim\u000barepsilon|\\log\u000barepsilon|$, near the outer boundary $|x|=b$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/The_Mathematics_Of_Diffusion(Ni).pdf_56",
        "ID": "12e0c8b2-bad6-40fb-9948-8dec4f65d4d9",
        "questions": "According to the given functionals, under what conditions are single-peak solutions possible?",
        "answers": "only single-peak solutions are possible",
        "context": "which can be achieved if $M^{\\prime}(1)>0$ (since $\\varepsilon\\rho\\to1$ and $\\begin{array}{r}{\\frac{1}{\\varepsilon}-\\rho\\sim|\\log\\varepsilon|)}\\end{array}$  \n\nFor the Dirichlet case, (3.30) and (3.32), we define similarly the functionals $\\widetilde{J}_{\\varepsilon,D}$ and $\\Psi_{\\varepsilon,D}$ and the expansion corresponding to (3.34) now reads as follows:  \n\n$$\n\\varepsilon^{n-1}\\Psi_{\\varepsilon,D}(\\rho)=M(\\varepsilon\\rho)\\left(\\alpha+\\beta e^{-2\\lambda(\\frac{1}{\\varepsilon}-\\rho)}\\right)+\\mathrm{higher-order\\;terms}.\n$$  \n\n$\\beta e^{-2\\lambda(\\frac{1}{\\varepsilon}-\\rho)}$ which reflects the different, or opposite, effects of Dirichlet and Neumann boundary conditions. Heuristically, when $V\\equiv1$, the first term in (3.34) and (3.35) is due to the volume energy which always has a tendency to \u201cshrink\u201d (in order to minimize), while the second $\\pm\\beta e^{-2\\lambda(\\frac{1}{\\varepsilon}-\\rho)}$ the boundary \u201cpushes\u201d the mass of the solution away from the boundary (therefore only single-peak solutions are possible), but in the Neumann case the boundary \u201cpulls\u201d the mass of the solution and thereby reaches a balance at $\\varepsilon\\rho=r_{\\varepsilon}\\sim1-\\varepsilon|\\log\\varepsilon|$ creating an extra solution.  \n\nWe remark that the method described above also applies to the annulus case and yields the following interesting results for $V\\equiv1$, which illustrate the opposite effects between Dirichlet and Neumann boundary conditions most vividly.  \n\n# Theorem 3.11 (see [AMN3]).  \n\n(i) For every $p>1$ and $\\varepsilon$ small, the Neumann problem (3.1) with $\\Omega=\\{x\\in\\mathbb{R}^{n}\\mid0<a<$   $|x|<b\\}$ possesses a solution concentrating at $|x|=r_{\\varepsilon}$, where $b-r_{\\varepsilon}\\sim\\varepsilon|\\log\\varepsilon|$, near the outer boundary $|x|=b$.  \n\n(ii) For every $p>1$ and $\\varepsilon$ small, the Dirichlet problem (3.2) with $\\Omega=\\{x\\in\\mathbb{R}^{n}\\,\\vert\\,0<a<$   $|x|<b\\}$ possesses a solution concentrating at $|x|=r_{\\varepsilon}$, where $r_{\\varepsilon}-a\\sim\\varepsilon|\\log\\varepsilon|$, near the inner boundary $|x|=a$.  \n\nObserve that from the \u201cmoving plane\u201d method [GNN1] it follows easily that the Dirichlet problem (3.2) does not have a solution concentrating on a sphere near the outer boundary $|x|=b$.  \n\nIn conclusion, we mention that the method of Theorem 3.10 can be extended to produce solutions with $k$-dimensional concentration sets, but again, some symmetry assumptions are needed. Other interesting progress in this direction includes a one-dimensional concentration set in the interior of a two-dimensional domain due to [WY]. The conjecture stated at the beginning of this section remains largely a major open problem.  \n\n# 3.1.4 Remarks  \n\nIn Section 3.1, we have considered the various concentration phenomena for essentially just one equation, namely,  \n\n$$\n\\varepsilon^{2}\\Delta u-u+u^{p}=0\n$$  \n\nin a bounded domain $\\Omega$ under either Dirichlet or Neumann boundary conditions in (3.2) or (3.1), respectively. However, since (3.36) is quite basic, similar phenomena could be",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "...while the second $\\pm \\beta e^{-2\\lambda(\\frac{1}{\u000barepsilon}-\\rho)}$ the boundary \u201cpushes\u201d the mass of the solution away from the boundary (therefore only single-peak solutions are possible)...",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/The_Mathematics_Of_Diffusion(Ni).pdf_56",
        "ID": "12f671b0-2f22-40b6-89fc-7de9d7e7d52f",
        "questions": "Does the Dirichlet problem with domain $\\Omega=\\{x \\in \\mathbb{R}^{n} \\mid 0<a<|x|<b\\}$ have a solution concentrating near the outer boundary $|x|=b$?",
        "answers": "No",
        "context": "which can be achieved if $M^{\\prime}(1)>0$ (since $\\varepsilon\\rho\\to1$ and $\\begin{array}{r}{\\frac{1}{\\varepsilon}-\\rho\\sim|\\log\\varepsilon|)}\\end{array}$  \n\nFor the Dirichlet case, (3.30) and (3.32), we define similarly the functionals $\\widetilde{J}_{\\varepsilon,D}$ and $\\Psi_{\\varepsilon,D}$ and the expansion corresponding to (3.34) now reads as follows:  \n\n$$\n\\varepsilon^{n-1}\\Psi_{\\varepsilon,D}(\\rho)=M(\\varepsilon\\rho)\\left(\\alpha+\\beta e^{-2\\lambda(\\frac{1}{\\varepsilon}-\\rho)}\\right)+\\mathrm{higher-order\\;terms}.\n$$  \n\n$\\beta e^{-2\\lambda(\\frac{1}{\\varepsilon}-\\rho)}$ which reflects the different, or opposite, effects of Dirichlet and Neumann boundary conditions. Heuristically, when $V\\equiv1$, the first term in (3.34) and (3.35) is due to the volume energy which always has a tendency to \u201cshrink\u201d (in order to minimize), while the second $\\pm\\beta e^{-2\\lambda(\\frac{1}{\\varepsilon}-\\rho)}$ the boundary \u201cpushes\u201d the mass of the solution away from the boundary (therefore only single-peak solutions are possible), but in the Neumann case the boundary \u201cpulls\u201d the mass of the solution and thereby reaches a balance at $\\varepsilon\\rho=r_{\\varepsilon}\\sim1-\\varepsilon|\\log\\varepsilon|$ creating an extra solution.  \n\nWe remark that the method described above also applies to the annulus case and yields the following interesting results for $V\\equiv1$, which illustrate the opposite effects between Dirichlet and Neumann boundary conditions most vividly.  \n\n# Theorem 3.11 (see [AMN3]).  \n\n(i) For every $p>1$ and $\\varepsilon$ small, the Neumann problem (3.1) with $\\Omega=\\{x\\in\\mathbb{R}^{n}\\mid0<a<$   $|x|<b\\}$ possesses a solution concentrating at $|x|=r_{\\varepsilon}$, where $b-r_{\\varepsilon}\\sim\\varepsilon|\\log\\varepsilon|$, near the outer boundary $|x|=b$.  \n\n(ii) For every $p>1$ and $\\varepsilon$ small, the Dirichlet problem (3.2) with $\\Omega=\\{x\\in\\mathbb{R}^{n}\\,\\vert\\,0<a<$   $|x|<b\\}$ possesses a solution concentrating at $|x|=r_{\\varepsilon}$, where $r_{\\varepsilon}-a\\sim\\varepsilon|\\log\\varepsilon|$, near the inner boundary $|x|=a$.  \n\nObserve that from the \u201cmoving plane\u201d method [GNN1] it follows easily that the Dirichlet problem (3.2) does not have a solution concentrating on a sphere near the outer boundary $|x|=b$.  \n\nIn conclusion, we mention that the method of Theorem 3.10 can be extended to produce solutions with $k$-dimensional concentration sets, but again, some symmetry assumptions are needed. Other interesting progress in this direction includes a one-dimensional concentration set in the interior of a two-dimensional domain due to [WY]. The conjecture stated at the beginning of this section remains largely a major open problem.  \n\n# 3.1.4 Remarks  \n\nIn Section 3.1, we have considered the various concentration phenomena for essentially just one equation, namely,  \n\n$$\n\\varepsilon^{2}\\Delta u-u+u^{p}=0\n$$  \n\nin a bounded domain $\\Omega$ under either Dirichlet or Neumann boundary conditions in (3.2) or (3.1), respectively. However, since (3.36) is quite basic, similar phenomena could be",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Yes/No",
        "evidence_source": "text",
        "evidence_context": "Observe that from the \u201cmoving plane\u201d method [GNN1] it follows easily that the Dirichlet problem (3.2) does not have a solution concentrating on a sphere near the outer boundary $|x|=b$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/The_Mathematics_Of_Diffusion(Ni).pdf_56",
        "ID": "12f6c3db-462f-49e0-ac37-d027e4443472",
        "questions": "What is the relationship between $b-r_{\u000barepsilon}$ and $\u000barepsilon|\\log\u000barepsilon|$ in the Neumann problem for $\\Omega=\\{x\\in\\mathbb{R}^{n}\\mid 0<a<|x|<b\\}$ when $p>1$ and $\u000barepsilon$ is small?",
        "answers": "$b-r_{\u000barepsilon}\\sim\\varepsilon|\\log\\varepsilon|$",
        "context": "which can be achieved if $M^{\\prime}(1)>0$ (since $\\varepsilon\\rho\\to1$ and $\\begin{array}{r}{\\frac{1}{\\varepsilon}-\\rho\\sim|\\log\\varepsilon|)}\\end{array}$  \n\nFor the Dirichlet case, (3.30) and (3.32), we define similarly the functionals $\\widetilde{J}_{\\varepsilon,D}$ and $\\Psi_{\\varepsilon,D}$ and the expansion corresponding to (3.34) now reads as follows:  \n\n$$\n\\varepsilon^{n-1}\\Psi_{\\varepsilon,D}(\\rho)=M(\\varepsilon\\rho)\\left(\\alpha+\\beta e^{-2\\lambda(\\frac{1}{\\varepsilon}-\\rho)}\\right)+\\mathrm{higher-order\\;terms}.\n$$  \n\n$\\beta e^{-2\\lambda(\\frac{1}{\\varepsilon}-\\rho)}$ which reflects the different, or opposite, effects of Dirichlet and Neumann boundary conditions. Heuristically, when $V\\equiv1$, the first term in (3.34) and (3.35) is due to the volume energy which always has a tendency to \u201cshrink\u201d (in order to minimize), while the second $\\pm\\beta e^{-2\\lambda(\\frac{1}{\\varepsilon}-\\rho)}$ the boundary \u201cpushes\u201d the mass of the solution away from the boundary (therefore only single-peak solutions are possible), but in the Neumann case the boundary \u201cpulls\u201d the mass of the solution and thereby reaches a balance at $\\varepsilon\\rho=r_{\\varepsilon}\\sim1-\\varepsilon|\\log\\varepsilon|$ creating an extra solution.  \n\nWe remark that the method described above also applies to the annulus case and yields the following interesting results for $V\\equiv1$, which illustrate the opposite effects between Dirichlet and Neumann boundary conditions most vividly.  \n\n# Theorem 3.11 (see [AMN3]).  \n\n(i) For every $p>1$ and $\\varepsilon$ small, the Neumann problem (3.1) with $\\Omega=\\{x\\in\\mathbb{R}^{n}\\mid0<a<$   $|x|<b\\}$ possesses a solution concentrating at $|x|=r_{\\varepsilon}$, where $b-r_{\\varepsilon}\\sim\\varepsilon|\\log\\varepsilon|$, near the outer boundary $|x|=b$.  \n\n(ii) For every $p>1$ and $\\varepsilon$ small, the Dirichlet problem (3.2) with $\\Omega=\\{x\\in\\mathbb{R}^{n}\\,\\vert\\,0<a<$   $|x|<b\\}$ possesses a solution concentrating at $|x|=r_{\\varepsilon}$, where $r_{\\varepsilon}-a\\sim\\varepsilon|\\log\\varepsilon|$, near the inner boundary $|x|=a$.  \n\nObserve that from the \u201cmoving plane\u201d method [GNN1] it follows easily that the Dirichlet problem (3.2) does not have a solution concentrating on a sphere near the outer boundary $|x|=b$.  \n\nIn conclusion, we mention that the method of Theorem 3.10 can be extended to produce solutions with $k$-dimensional concentration sets, but again, some symmetry assumptions are needed. Other interesting progress in this direction includes a one-dimensional concentration set in the interior of a two-dimensional domain due to [WY]. The conjecture stated at the beginning of this section remains largely a major open problem.  \n\n# 3.1.4 Remarks  \n\nIn Section 3.1, we have considered the various concentration phenomena for essentially just one equation, namely,  \n\n$$\n\\varepsilon^{2}\\Delta u-u+u^{p}=0\n$$  \n\nin a bounded domain $\\Omega$ under either Dirichlet or Neumann boundary conditions in (3.2) or (3.1), respectively. However, since (3.36) is quite basic, similar phenomena could be",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "(i) For every $p>1$ and $\\varepsilon$ small, the Neumann problem (3.1) with $\\Omega=\\{x\\in\\mathbb{R}^{n}\\mid0<a<$ $|x|<b\\}$ possesses a solution concentrating at $|x|=r_{\\varepsilon}$, where $b-r_{\\varepsilon}\\sim\\varepsilon|\\log\\varepsilon|$, near the outer boundary $|x|=b$.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/The_Mathematics_Of_Diffusion(Ni).pdf_56",
        "ID": "12f7d8e7-76f3-4a3d-9cec-afd1fd360bf4",
        "questions": "How does $r_{\u000barepsilon}$ relate to $a$ under the Dirichlet problem when $p>1$ and $\u000barepsilon$ is small?",
        "answers": "$r_{\\varepsilon}-a\\sim\\varepsilon|\\log\\varepsilon|$",
        "context": "which can be achieved if $M^{\\prime}(1)>0$ (since $\\varepsilon\\rho\\to1$ and $\\begin{array}{r}{\\frac{1}{\\varepsilon}-\\rho\\sim|\\log\\varepsilon|)}\\end{array}$  \n\nFor the Dirichlet case, (3.30) and (3.32), we define similarly the functionals $\\widetilde{J}_{\\varepsilon,D}$ and $\\Psi_{\\varepsilon,D}$ and the expansion corresponding to (3.34) now reads as follows:  \n\n$$\n\\varepsilon^{n-1}\\Psi_{\\varepsilon,D}(\\rho)=M(\\varepsilon\\rho)\\left(\\alpha+\\beta e^{-2\\lambda(\\frac{1}{\\varepsilon}-\\rho)}\\right)+\\mathrm{higher-order\\;terms}.\n$$  \n\n$\\beta e^{-2\\lambda(\\frac{1}{\\varepsilon}-\\rho)}$ which reflects the different, or opposite, effects of Dirichlet and Neumann boundary conditions. Heuristically, when $V\\equiv1$, the first term in (3.34) and (3.35) is due to the volume energy which always has a tendency to \u201cshrink\u201d (in order to minimize), while the second $\\pm\\beta e^{-2\\lambda(\\frac{1}{\\varepsilon}-\\rho)}$ the boundary \u201cpushes\u201d the mass of the solution away from the boundary (therefore only single-peak solutions are possible), but in the Neumann case the boundary \u201cpulls\u201d the mass of the solution and thereby reaches a balance at $\\varepsilon\\rho=r_{\\varepsilon}\\sim1-\\varepsilon|\\log\\varepsilon|$ creating an extra solution.  \n\nWe remark that the method described above also applies to the annulus case and yields the following interesting results for $V\\equiv1$, which illustrate the opposite effects between Dirichlet and Neumann boundary conditions most vividly.  \n\n# Theorem 3.11 (see [AMN3]).  \n\n(i) For every $p>1$ and $\\varepsilon$ small, the Neumann problem (3.1) with $\\Omega=\\{x\\in\\mathbb{R}^{n}\\mid0<a<$   $|x|<b\\}$ possesses a solution concentrating at $|x|=r_{\\varepsilon}$, where $b-r_{\\varepsilon}\\sim\\varepsilon|\\log\\varepsilon|$, near the outer boundary $|x|=b$.  \n\n(ii) For every $p>1$ and $\\varepsilon$ small, the Dirichlet problem (3.2) with $\\Omega=\\{x\\in\\mathbb{R}^{n}\\,\\vert\\,0<a<$   $|x|<b\\}$ possesses a solution concentrating at $|x|=r_{\\varepsilon}$, where $r_{\\varepsilon}-a\\sim\\varepsilon|\\log\\varepsilon|$, near the inner boundary $|x|=a$.  \n\nObserve that from the \u201cmoving plane\u201d method [GNN1] it follows easily that the Dirichlet problem (3.2) does not have a solution concentrating on a sphere near the outer boundary $|x|=b$.  \n\nIn conclusion, we mention that the method of Theorem 3.10 can be extended to produce solutions with $k$-dimensional concentration sets, but again, some symmetry assumptions are needed. Other interesting progress in this direction includes a one-dimensional concentration set in the interior of a two-dimensional domain due to [WY]. The conjecture stated at the beginning of this section remains largely a major open problem.  \n\n# 3.1.4 Remarks  \n\nIn Section 3.1, we have considered the various concentration phenomena for essentially just one equation, namely,  \n\n$$\n\\varepsilon^{2}\\Delta u-u+u^{p}=0\n$$  \n\nin a bounded domain $\\Omega$ under either Dirichlet or Neumann boundary conditions in (3.2) or (3.1), respectively. However, since (3.36) is quite basic, similar phenomena could be",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "(ii) For every $p>1$ and $\\varepsilon$ small, the Dirichlet problem (3.2) with $\\Omega=\\{x\\in\\mathbb{R}^{n}\\,\\vert\\,0<a<$ $|x|<b\\}$ possesses a solution concentrating at $|x|=r_{\\varepsilon}$, where $r_{\\varepsilon}-a\\sim\\varepsilon|\\log\\varepsilon|$, near the inner boundary $|x|=a$.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/The_Mathematics_Of_Diffusion(Ni).pdf_56",
        "ID": "12f84c3f-7fa8-4d64-a7e0-1b2e2ae8cb9f",
        "questions": "What is the equation considered for concentration phenomena in a bounded domain under Dirichlet or Neumann boundary conditions?",
        "answers": "$\\varepsilon^{2}\\Delta u-u+u^{p}=0$",
        "context": "which can be achieved if $M^{\\prime}(1)>0$ (since $\\varepsilon\\rho\\to1$ and $\\begin{array}{r}{\\frac{1}{\\varepsilon}-\\rho\\sim|\\log\\varepsilon|)}\\end{array}$  \n\nFor the Dirichlet case, (3.30) and (3.32), we define similarly the functionals $\\widetilde{J}_{\\varepsilon,D}$ and $\\Psi_{\\varepsilon,D}$ and the expansion corresponding to (3.34) now reads as follows:  \n\n$$\n\\varepsilon^{n-1}\\Psi_{\\varepsilon,D}(\\rho)=M(\\varepsilon\\rho)\\left(\\alpha+\\beta e^{-2\\lambda(\\frac{1}{\\varepsilon}-\\rho)}\\right)+\\mathrm{higher-order\\;terms}.\n$$  \n\n$\\beta e^{-2\\lambda(\\frac{1}{\\varepsilon}-\\rho)}$ which reflects the different, or opposite, effects of Dirichlet and Neumann boundary conditions. Heuristically, when $V\\equiv1$, the first term in (3.34) and (3.35) is due to the volume energy which always has a tendency to \u201cshrink\u201d (in order to minimize), while the second $\\pm\\beta e^{-2\\lambda(\\frac{1}{\\varepsilon}-\\rho)}$ the boundary \u201cpushes\u201d the mass of the solution away from the boundary (therefore only single-peak solutions are possible), but in the Neumann case the boundary \u201cpulls\u201d the mass of the solution and thereby reaches a balance at $\\varepsilon\\rho=r_{\\varepsilon}\\sim1-\\varepsilon|\\log\\varepsilon|$ creating an extra solution.  \n\nWe remark that the method described above also applies to the annulus case and yields the following interesting results for $V\\equiv1$, which illustrate the opposite effects between Dirichlet and Neumann boundary conditions most vividly.  \n\n# Theorem 3.11 (see [AMN3]).  \n\n(i) For every $p>1$ and $\\varepsilon$ small, the Neumann problem (3.1) with $\\Omega=\\{x\\in\\mathbb{R}^{n}\\mid0<a<$   $|x|<b\\}$ possesses a solution concentrating at $|x|=r_{\\varepsilon}$, where $b-r_{\\varepsilon}\\sim\\varepsilon|\\log\\varepsilon|$, near the outer boundary $|x|=b$.  \n\n(ii) For every $p>1$ and $\\varepsilon$ small, the Dirichlet problem (3.2) with $\\Omega=\\{x\\in\\mathbb{R}^{n}\\,\\vert\\,0<a<$   $|x|<b\\}$ possesses a solution concentrating at $|x|=r_{\\varepsilon}$, where $r_{\\varepsilon}-a\\sim\\varepsilon|\\log\\varepsilon|$, near the inner boundary $|x|=a$.  \n\nObserve that from the \u201cmoving plane\u201d method [GNN1] it follows easily that the Dirichlet problem (3.2) does not have a solution concentrating on a sphere near the outer boundary $|x|=b$.  \n\nIn conclusion, we mention that the method of Theorem 3.10 can be extended to produce solutions with $k$-dimensional concentration sets, but again, some symmetry assumptions are needed. Other interesting progress in this direction includes a one-dimensional concentration set in the interior of a two-dimensional domain due to [WY]. The conjecture stated at the beginning of this section remains largely a major open problem.  \n\n# 3.1.4 Remarks  \n\nIn Section 3.1, we have considered the various concentration phenomena for essentially just one equation, namely,  \n\n$$\n\\varepsilon^{2}\\Delta u-u+u^{p}=0\n$$  \n\nin a bounded domain $\\Omega$ under either Dirichlet or Neumann boundary conditions in (3.2) or (3.1), respectively. However, since (3.36) is quite basic, similar phenomena could be",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "In Section 3.1, we have considered the various concentration phenomena for essentially just one equation, namely, $$\\varepsilon^{2}\\Delta u-u+u^{p}=0$$ in a bounded domain $\\Omega$ under either Dirichlet or Neumann boundary conditions in (3.2) or (3.1), respectively.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/06Numerical_Optimization2006.pdf_555",
        "ID": "12f943e8-688d-4d04-b1aa-2f9383ab80c7",
        "questions": "What condition must \\( s_k \\) and \\( y_k \\) satisfy for the standard BFGS update formula to be applicable?",
        "answers": "$s_{k}^{T}y_{k} \\geq \theta s_{k}^{T} B_{k} s_{k}$",
        "context": "of approximating it with a positive definite matrix may be problematic. BFGS updating requires that  $s_{k}$  and  $y_{k}$  satisfy the curvature condition  $s_{k}^{T}y_{k}>0$  , which may not hold when  $s_{k}$  and  $y_{k}$  are defined by (18.13), even when the iterates are close to the solution.  \n\nTo overcome this difficulty, we could skip the BFGS update if the condition  \n\n$$\ns_{k}^{T}y_{k}\\geq\\theta s_{k}^{T}B_{k}s_{k}\n$$  \n\nis not satisfied, where  $\\theta$  is a positive parameter  $(10^{-2},\\,\\mathrm{say})$  . This strategy may, on occasion, yield poor performance or even failure, so it cannot be regarded as adequate for general purpose algorithms.  \n\nA more effective modification ensures that the update is always well defined by modifying the definition of  $y_{k}$.\n\nProcedure 18.2 (Damped BFGS Updating)  \n\nGiven: symmetric and positive definite matrix  $B_{k}$  Define  $s_{k}$  and  $y_{k}$  as in (18.13) and set  \n\n$$\nr_{k}=\\theta_{k}y_{k}+(1-\\theta_{k})B_{k}s_{k},\n$$  \n\nwhere the scalar  $\\theta_{k}$  is defined as  \n\n$$\n\\theta_{k}=\\left\\{\\begin{array}{l l}{1}&{\\mathrm{~if}\\,s_{k}^{T}y_{k}\\geq0.2s_{k}^{T}B_{k}s_{k},}\\\\ {(0.8s_{k}^{T}B_{k}s_{k})/(s_{k}^{T}B_{k}s_{k}-s_{k}^{T}y_{k})}&{\\mathrm{~if}\\,s_{k}^{T}y_{k}<0.2s_{k}^{T}B_{k}s_{k};}\\end{array}\\right.\n$$  \n\nUpdate  $B_{k}$  as follows:  \n\n$$\nB_{k+1}=B_{k}-\\frac{B_{k}s_{k}s_{k}^{T}B_{k}}{s_{k}^{T}B_{k}s_{k}}+\\frac{r_{k}r_{k}^{T}}{s_{k}^{T}r_{k}}.\n$$  \n\nThe formula (18.16) is simply the standard BFGS update formula, with  $y_{k}$  replaced by  $r_{k}$  . It guarantees that  $B_{k+1}$  is positive definite, since it is easy to show that when  $\\theta_{k}\\neq1$  we have  \n\n$$\ns_{k}^{T}r_{k}=0.2s_{k}^{T}B_{k}s_{k}>0.\n$$  \n\nTo gain more insight into this strategy, note that the choice  $\\theta_{k}=0$  gives  $B_{k+1}=B_{k}$  , while  $\\theta_{k}=1$  gives the (possibly indefinite) matrix produced by the unmodified BFGS update. A value  $\\theta_{k}\\,\\in\\,(0,1)$  thus produces a matrix that interpolates the current approximation  $B_{k}$  and the one produced by the unmodified BFGS formula. The choice of  $\\theta_{k}$  ensures that the new approximation stays close enough to the current approximation  $B_{k}$  to ensure positive definiteness.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "To overcome this difficulty, we could skip the BFGS update if the condition \\( s_{k}^{T}y_{k} \\geq \theta s_{k}^{T}B_{k}s_{k} \\) is not satisfied, where \\( \theta \\) is a positive parameter \\( (10^{-2}, \\, \\mathrm{say}) \\) .",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/06Numerical_Optimization2006.pdf_555",
        "ID": "12fc925c-7a66-4233-9394-98a79e686423",
        "questions": "What is the value of \\( \theta_k \\) when \\( s_k^T y_k \\geq 0.2 s_k^T B_k s_k \\) in Procedure 18.2?",
        "answers": "1",
        "context": "of approximating it with a positive definite matrix may be problematic. BFGS updating requires that  $s_{k}$  and  $y_{k}$  satisfy the curvature condition  $s_{k}^{T}y_{k}>0$  , which may not hold when  $s_{k}$  and  $y_{k}$  are defined by (18.13), even when the iterates are close to the solution.  \n\nTo overcome this difficulty, we could skip the BFGS update if the condition  \n\n$$\ns_{k}^{T}y_{k}\\geq\\theta s_{k}^{T}B_{k}s_{k}\n$$  \n\nis not satisfied, where  $\\theta$  is a positive parameter  $(10^{-2},\\,\\mathrm{say})$  . This strategy may, on occasion, yield poor performance or even failure, so it cannot be regarded as adequate for general purpose algorithms.  \n\nA more effective modification ensures that the update is always well defined by modifying the definition of  $y_{k}$.\n\nProcedure 18.2 (Damped BFGS Updating)  \n\nGiven: symmetric and positive definite matrix  $B_{k}$  Define  $s_{k}$  and  $y_{k}$  as in (18.13) and set  \n\n$$\nr_{k}=\\theta_{k}y_{k}+(1-\\theta_{k})B_{k}s_{k},\n$$  \n\nwhere the scalar  $\\theta_{k}$  is defined as  \n\n$$\n\\theta_{k}=\\left\\{\\begin{array}{l l}{1}&{\\mathrm{~if}\\,s_{k}^{T}y_{k}\\geq0.2s_{k}^{T}B_{k}s_{k},}\\\\ {(0.8s_{k}^{T}B_{k}s_{k})/(s_{k}^{T}B_{k}s_{k}-s_{k}^{T}y_{k})}&{\\mathrm{~if}\\,s_{k}^{T}y_{k}<0.2s_{k}^{T}B_{k}s_{k};}\\end{array}\\right.\n$$  \n\nUpdate  $B_{k}$  as follows:  \n\n$$\nB_{k+1}=B_{k}-\\frac{B_{k}s_{k}s_{k}^{T}B_{k}}{s_{k}^{T}B_{k}s_{k}}+\\frac{r_{k}r_{k}^{T}}{s_{k}^{T}r_{k}}.\n$$  \n\nThe formula (18.16) is simply the standard BFGS update formula, with  $y_{k}$  replaced by  $r_{k}$  . It guarantees that  $B_{k+1}$  is positive definite, since it is easy to show that when  $\\theta_{k}\\neq1$  we have  \n\n$$\ns_{k}^{T}r_{k}=0.2s_{k}^{T}B_{k}s_{k}>0.\n$$  \n\nTo gain more insight into this strategy, note that the choice  $\\theta_{k}=0$  gives  $B_{k+1}=B_{k}$  , while  $\\theta_{k}=1$  gives the (possibly indefinite) matrix produced by the unmodified BFGS update. A value  $\\theta_{k}\\,\\in\\,(0,1)$  thus produces a matrix that interpolates the current approximation  $B_{k}$  and the one produced by the unmodified BFGS formula. The choice of  $\\theta_{k}$  ensures that the new approximation stays close enough to the current approximation  $B_{k}$  to ensure positive definiteness.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Numeric",
        "evidence_source": "equation",
        "evidence_context": "the scalar \\( \theta_{k} \\) is defined as \\( \theta_{k}=\\left\\{\begin{array}{l l}{1}&{\\mathrm{~if}\\,s_{k}^{T}y_{k}\\geq0.2s_{k}^{T}B_{k}s_{k},}\\end{array}\right. \\)",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/06Numerical_Optimization2006.pdf_555",
        "ID": "12fd3550-ff88-43ce-a49c-c66396cd2a09",
        "questions": "Does the damped BFGS update formula ensure that the new matrix \\( B_{k+1} \\) is positive definite when \\( \theta_k \neq 1 \\)?",
        "answers": "Yes",
        "context": "of approximating it with a positive definite matrix may be problematic. BFGS updating requires that  $s_{k}$  and  $y_{k}$  satisfy the curvature condition  $s_{k}^{T}y_{k}>0$  , which may not hold when  $s_{k}$  and  $y_{k}$  are defined by (18.13), even when the iterates are close to the solution.  \n\nTo overcome this difficulty, we could skip the BFGS update if the condition  \n\n$$\ns_{k}^{T}y_{k}\\geq\\theta s_{k}^{T}B_{k}s_{k}\n$$  \n\nis not satisfied, where  $\\theta$  is a positive parameter  $(10^{-2},\\,\\mathrm{say})$  . This strategy may, on occasion, yield poor performance or even failure, so it cannot be regarded as adequate for general purpose algorithms.  \n\nA more effective modification ensures that the update is always well defined by modifying the definition of  $y_{k}$.\n\nProcedure 18.2 (Damped BFGS Updating)  \n\nGiven: symmetric and positive definite matrix  $B_{k}$  Define  $s_{k}$  and  $y_{k}$  as in (18.13) and set  \n\n$$\nr_{k}=\\theta_{k}y_{k}+(1-\\theta_{k})B_{k}s_{k},\n$$  \n\nwhere the scalar  $\\theta_{k}$  is defined as  \n\n$$\n\\theta_{k}=\\left\\{\\begin{array}{l l}{1}&{\\mathrm{~if}\\,s_{k}^{T}y_{k}\\geq0.2s_{k}^{T}B_{k}s_{k},}\\\\ {(0.8s_{k}^{T}B_{k}s_{k})/(s_{k}^{T}B_{k}s_{k}-s_{k}^{T}y_{k})}&{\\mathrm{~if}\\,s_{k}^{T}y_{k}<0.2s_{k}^{T}B_{k}s_{k};}\\end{array}\\right.\n$$  \n\nUpdate  $B_{k}$  as follows:  \n\n$$\nB_{k+1}=B_{k}-\\frac{B_{k}s_{k}s_{k}^{T}B_{k}}{s_{k}^{T}B_{k}s_{k}}+\\frac{r_{k}r_{k}^{T}}{s_{k}^{T}r_{k}}.\n$$  \n\nThe formula (18.16) is simply the standard BFGS update formula, with  $y_{k}$  replaced by  $r_{k}$  . It guarantees that  $B_{k+1}$  is positive definite, since it is easy to show that when  $\\theta_{k}\\neq1$  we have  \n\n$$\ns_{k}^{T}r_{k}=0.2s_{k}^{T}B_{k}s_{k}>0.\n$$  \n\nTo gain more insight into this strategy, note that the choice  $\\theta_{k}=0$  gives  $B_{k+1}=B_{k}$  , while  $\\theta_{k}=1$  gives the (possibly indefinite) matrix produced by the unmodified BFGS update. A value  $\\theta_{k}\\,\\in\\,(0,1)$  thus produces a matrix that interpolates the current approximation  $B_{k}$  and the one produced by the unmodified BFGS formula. The choice of  $\\theta_{k}$  ensures that the new approximation stays close enough to the current approximation  $B_{k}$  to ensure positive definiteness.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Yes/No",
        "evidence_source": "text",
        "evidence_context": "It guarantees that \\( B_{k+1} \\) is positive definite, since it is easy to show that when \\( \theta_{k} \neq 1 \\) we have \\( s_{k}^{T}r_{k} = 0.2s_{k}^{T}B_{k}s_{k} > 0 \\).",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/06Numerical_Optimization2006.pdf_555",
        "ID": "12fefd05-2eb2-45cf-84f1-411ec296d339",
        "questions": "What condition must be met for the curvature in the BFGS method to hold when $s_k$ and $y_k$ are defined by the damped BFGS update?",
        "answers": "$s_{k}^{T}y_{k}\\geq\theta s_{k}^{T}B_{k}s_{k}$",
        "context": "of approximating it with a positive definite matrix may be problematic. BFGS updating requires that  $s_{k}$  and  $y_{k}$  satisfy the curvature condition  $s_{k}^{T}y_{k}>0$  , which may not hold when  $s_{k}$  and  $y_{k}$  are defined by (18.13), even when the iterates are close to the solution.  \n\nTo overcome this difficulty, we could skip the BFGS update if the condition  \n\n$$\ns_{k}^{T}y_{k}\\geq\\theta s_{k}^{T}B_{k}s_{k}\n$$  \n\nis not satisfied, where  $\\theta$  is a positive parameter  $(10^{-2},\\,\\mathrm{say})$  . This strategy may, on occasion, yield poor performance or even failure, so it cannot be regarded as adequate for general purpose algorithms.  \n\nA more effective modification ensures that the update is always well defined by modifying the definition of  $y_{k}$.\n\nProcedure 18.2 (Damped BFGS Updating)  \n\nGiven: symmetric and positive definite matrix  $B_{k}$  Define  $s_{k}$  and  $y_{k}$  as in (18.13) and set  \n\n$$\nr_{k}=\\theta_{k}y_{k}+(1-\\theta_{k})B_{k}s_{k},\n$$  \n\nwhere the scalar  $\\theta_{k}$  is defined as  \n\n$$\n\\theta_{k}=\\left\\{\\begin{array}{l l}{1}&{\\mathrm{~if}\\,s_{k}^{T}y_{k}\\geq0.2s_{k}^{T}B_{k}s_{k},}\\\\ {(0.8s_{k}^{T}B_{k}s_{k})/(s_{k}^{T}B_{k}s_{k}-s_{k}^{T}y_{k})}&{\\mathrm{~if}\\,s_{k}^{T}y_{k}<0.2s_{k}^{T}B_{k}s_{k};}\\end{array}\\right.\n$$  \n\nUpdate  $B_{k}$  as follows:  \n\n$$\nB_{k+1}=B_{k}-\\frac{B_{k}s_{k}s_{k}^{T}B_{k}}{s_{k}^{T}B_{k}s_{k}}+\\frac{r_{k}r_{k}^{T}}{s_{k}^{T}r_{k}}.\n$$  \n\nThe formula (18.16) is simply the standard BFGS update formula, with  $y_{k}$  replaced by  $r_{k}$  . It guarantees that  $B_{k+1}$  is positive definite, since it is easy to show that when  $\\theta_{k}\\neq1$  we have  \n\n$$\ns_{k}^{T}r_{k}=0.2s_{k}^{T}B_{k}s_{k}>0.\n$$  \n\nTo gain more insight into this strategy, note that the choice  $\\theta_{k}=0$  gives  $B_{k+1}=B_{k}$  , while  $\\theta_{k}=1$  gives the (possibly indefinite) matrix produced by the unmodified BFGS update. A value  $\\theta_{k}\\,\\in\\,(0,1)$  thus produces a matrix that interpolates the current approximation  $B_{k}$  and the one produced by the unmodified BFGS formula. The choice of  $\\theta_{k}$  ensures that the new approximation stays close enough to the current approximation  $B_{k}$  to ensure positive definiteness.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "To overcome this difficulty, we could skip the BFGS update if the condition  $$ s_{k}^{T}y_{k}\\geq\theta s_{k}^{T}B_{k}s_{k} $$  is not satisfied, where  $\\theta$  is a positive parameter  $(10^{-2},\\,\\mathrm{say})$  .",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/06Numerical_Optimization2006.pdf_555",
        "ID": "130e7fb3-30dd-493e-8ea0-e0ffe80249a1",
        "questions": "How is the scalar $\\theta_k$ defined in the damped BFGS method when $s_k^T y_k < 0.2 s_k^T B_k s_k$?",
        "answers": "$(0.8s_{k}^{T}B_{k}s_{k})/(s_{k}^{T}B_{k}s_{k}-s_{k}^{T}y_{k})",
        "context": "of approximating it with a positive definite matrix may be problematic. BFGS updating requires that  $s_{k}$  and  $y_{k}$  satisfy the curvature condition  $s_{k}^{T}y_{k}>0$  , which may not hold when  $s_{k}$  and  $y_{k}$  are defined by (18.13), even when the iterates are close to the solution.  \n\nTo overcome this difficulty, we could skip the BFGS update if the condition  \n\n$$\ns_{k}^{T}y_{k}\\geq\\theta s_{k}^{T}B_{k}s_{k}\n$$  \n\nis not satisfied, where  $\\theta$  is a positive parameter  $(10^{-2},\\,\\mathrm{say})$  . This strategy may, on occasion, yield poor performance or even failure, so it cannot be regarded as adequate for general purpose algorithms.  \n\nA more effective modification ensures that the update is always well defined by modifying the definition of  $y_{k}$.\n\nProcedure 18.2 (Damped BFGS Updating)  \n\nGiven: symmetric and positive definite matrix  $B_{k}$  Define  $s_{k}$  and  $y_{k}$  as in (18.13) and set  \n\n$$\nr_{k}=\\theta_{k}y_{k}+(1-\\theta_{k})B_{k}s_{k},\n$$  \n\nwhere the scalar  $\\theta_{k}$  is defined as  \n\n$$\n\\theta_{k}=\\left\\{\\begin{array}{l l}{1}&{\\mathrm{~if}\\,s_{k}^{T}y_{k}\\geq0.2s_{k}^{T}B_{k}s_{k},}\\\\ {(0.8s_{k}^{T}B_{k}s_{k})/(s_{k}^{T}B_{k}s_{k}-s_{k}^{T}y_{k})}&{\\mathrm{~if}\\,s_{k}^{T}y_{k}<0.2s_{k}^{T}B_{k}s_{k};}\\end{array}\\right.\n$$  \n\nUpdate  $B_{k}$  as follows:  \n\n$$\nB_{k+1}=B_{k}-\\frac{B_{k}s_{k}s_{k}^{T}B_{k}}{s_{k}^{T}B_{k}s_{k}}+\\frac{r_{k}r_{k}^{T}}{s_{k}^{T}r_{k}}.\n$$  \n\nThe formula (18.16) is simply the standard BFGS update formula, with  $y_{k}$  replaced by  $r_{k}$  . It guarantees that  $B_{k+1}$  is positive definite, since it is easy to show that when  $\\theta_{k}\\neq1$  we have  \n\n$$\ns_{k}^{T}r_{k}=0.2s_{k}^{T}B_{k}s_{k}>0.\n$$  \n\nTo gain more insight into this strategy, note that the choice  $\\theta_{k}=0$  gives  $B_{k+1}=B_{k}$  , while  $\\theta_{k}=1$  gives the (possibly indefinite) matrix produced by the unmodified BFGS update. A value  $\\theta_{k}\\,\\in\\,(0,1)$  thus produces a matrix that interpolates the current approximation  $B_{k}$  and the one produced by the unmodified BFGS formula. The choice of  $\\theta_{k}$  ensures that the new approximation stays close enough to the current approximation  $B_{k}$  to ensure positive definiteness.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "where the scalar  $\\theta_{k}$  is defined as  $$ \\theta_{k}=\\left\\{\\begin{array}{l l}{1}&{\\mathrm{~if}\\,s_{k}^{T}y_{k}\\geq0.2s_{k}^{T}B_{k}s_{k},}\\\\ {(0.8s_{k}^{T}B_{k}s_{k})/(s_{k}^{T}B_{k}s_{k}-s_{k}^{T}y_{k})}&{\\mathrm{~if}\\,s_{k}^{T}y_{k}<0.2s_{k}^{T}B_{k}s_{k};}\\end{array}\\right.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/06Numerical_Optimization2006.pdf_555",
        "ID": "13169396-7edd-45ba-a901-cb3a82132bfe",
        "questions": "In the damped BFGS update, what is the modified $B_{k+1}$ when $s_k^T r_k = 0.2 s_k^T B_k s_k > 0$?",
        "answers": "$B_{k+1}=B_{k}-\\frac{B_{k}s_{k}s_{k}^{T}B_{k}}{s_{k}^{T}B_{k}s_{k}}+\\frac{r_{k}r_{k}^{T}}{s_{k}^{T}r_{k}}$",
        "context": "of approximating it with a positive definite matrix may be problematic. BFGS updating requires that  $s_{k}$  and  $y_{k}$  satisfy the curvature condition  $s_{k}^{T}y_{k}>0$  , which may not hold when  $s_{k}$  and  $y_{k}$  are defined by (18.13), even when the iterates are close to the solution.  \n\nTo overcome this difficulty, we could skip the BFGS update if the condition  \n\n$$\ns_{k}^{T}y_{k}\\geq\\theta s_{k}^{T}B_{k}s_{k}\n$$  \n\nis not satisfied, where  $\\theta$  is a positive parameter  $(10^{-2},\\,\\mathrm{say})$  . This strategy may, on occasion, yield poor performance or even failure, so it cannot be regarded as adequate for general purpose algorithms.  \n\nA more effective modification ensures that the update is always well defined by modifying the definition of  $y_{k}$.\n\nProcedure 18.2 (Damped BFGS Updating)  \n\nGiven: symmetric and positive definite matrix  $B_{k}$  Define  $s_{k}$  and  $y_{k}$  as in (18.13) and set  \n\n$$\nr_{k}=\\theta_{k}y_{k}+(1-\\theta_{k})B_{k}s_{k},\n$$  \n\nwhere the scalar  $\\theta_{k}$  is defined as  \n\n$$\n\\theta_{k}=\\left\\{\\begin{array}{l l}{1}&{\\mathrm{~if}\\,s_{k}^{T}y_{k}\\geq0.2s_{k}^{T}B_{k}s_{k},}\\\\ {(0.8s_{k}^{T}B_{k}s_{k})/(s_{k}^{T}B_{k}s_{k}-s_{k}^{T}y_{k})}&{\\mathrm{~if}\\,s_{k}^{T}y_{k}<0.2s_{k}^{T}B_{k}s_{k};}\\end{array}\\right.\n$$  \n\nUpdate  $B_{k}$  as follows:  \n\n$$\nB_{k+1}=B_{k}-\\frac{B_{k}s_{k}s_{k}^{T}B_{k}}{s_{k}^{T}B_{k}s_{k}}+\\frac{r_{k}r_{k}^{T}}{s_{k}^{T}r_{k}}.\n$$  \n\nThe formula (18.16) is simply the standard BFGS update formula, with  $y_{k}$  replaced by  $r_{k}$  . It guarantees that  $B_{k+1}$  is positive definite, since it is easy to show that when  $\\theta_{k}\\neq1$  we have  \n\n$$\ns_{k}^{T}r_{k}=0.2s_{k}^{T}B_{k}s_{k}>0.\n$$  \n\nTo gain more insight into this strategy, note that the choice  $\\theta_{k}=0$  gives  $B_{k+1}=B_{k}$  , while  $\\theta_{k}=1$  gives the (possibly indefinite) matrix produced by the unmodified BFGS update. A value  $\\theta_{k}\\,\\in\\,(0,1)$  thus produces a matrix that interpolates the current approximation  $B_{k}$  and the one produced by the unmodified BFGS formula. The choice of  $\\theta_{k}$  ensures that the new approximation stays close enough to the current approximation  $B_{k}$  to ensure positive definiteness.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Update  $B_{k}$  as follows:  $$ B_{k+1}=B_{k}-\\frac{B_{k}s_{k}s_{k}^{T}B_{k}}{s_{k}^{T}B_{k}s_{k}}+\\frac{r_{k}r_{k}^{T}}{s_{k}^{T}r_{k}}. $$  The formula (18.16) is simply the standard BFGS update formula, with  $y_{k}$  replaced by  $r_{k}$  .",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/1c00e16c0db1f129d7b8b87fad27646fdfc393600d20182fa7eb94682601b913.pdf_9",
        "ID": "13195c25-e1f6-42de-b339-ddd036bfeb63",
        "questions": "What percentage of people surveyed indicated they would reduce their contributions if their household income dropped?",
        "answers": "45%",
        "context": "# Individual Giving  \n\nIf household income drops, 45% would reduce their contribution.  \n\n# WHAT COULD REDUCE GIVING  \n\nAlthough most citizens plan to support nonprofits in the next 12 months as generously as they have in the past year, it is important to anticipate what factors might reduce donations. For example, $45\\%$ reported that their contributions would be reduced if their incomes dropped. However, $73\\%$ appeared to be optimistic about their job security in the coming year.  \n\nFactors that could impinge on future giving include: \n- hearing that nonprofits have high overhead, salary, and administrative costs $(65\\%)$.\n- too many requests for contributions $(65\\%)$.\n- lack of sufficient information about how contributions will be spent $(61\\%)$.\n- being financially unable to give $(52\\%)$.\n- having other spending priorities $(41\\%)$.\n- not being personally asked to give $(34\\%)$.\n- losing a job $(27\\%)$.\n\n![](images/d83bb93f2cb5ae148ad27edc47884895ead5b60393c0acbacb51aacee5999e79.jpg)\n\n# EMPLOYER SUPPORT  \n\nThe workplace plays an important role by encouraging giving and providing systems that simplify giving, such as payroll deduction. Many of those surveyed gave through programs offered by their employers, and were also able to increase the level of giving by using matching gift programs. Among the key findings about employer support in Kent County are:  \n\n- Payroll deduction of contributions by employers was available for $49\\%$ of workers surveyed, and almost half of this group used the payroll deduction process. Both the existence and use of payroll deduction plans increase with income.  \n\n![](images/c9d3e843d155d13d71db1a1f600fb37edbbdd73e101cf5a53bc1c744cf09ecdf.jpg)",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Numeric",
        "evidence_source": "text",
        "evidence_context": "If household income drops, 45% would reduce their contribution.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/1c00e16c0db1f129d7b8b87fad27646fdfc393600d20182fa7eb94682601b913.pdf_9",
        "ID": "131bf956-c72a-4ac1-b0c9-7d347ae624a6",
        "questions": "What is one specific factor listed that could reduce future giving due to financial inability?",
        "answers": "being financially unable to give",
        "context": "# Individual Giving  \n\nIf household income drops, 45% would reduce their contribution.  \n\n# WHAT COULD REDUCE GIVING  \n\nAlthough most citizens plan to support nonprofits in the next 12 months as generously as they have in the past year, it is important to anticipate what factors might reduce donations. For example, $45\\%$ reported that their contributions would be reduced if their incomes dropped. However, $73\\%$ appeared to be optimistic about their job security in the coming year.  \n\nFactors that could impinge on future giving include: \n- hearing that nonprofits have high overhead, salary, and administrative costs $(65\\%)$.\n- too many requests for contributions $(65\\%)$.\n- lack of sufficient information about how contributions will be spent $(61\\%)$.\n- being financially unable to give $(52\\%)$.\n- having other spending priorities $(41\\%)$.\n- not being personally asked to give $(34\\%)$.\n- losing a job $(27\\%)$.\n\n![](images/d83bb93f2cb5ae148ad27edc47884895ead5b60393c0acbacb51aacee5999e79.jpg)\n\n# EMPLOYER SUPPORT  \n\nThe workplace plays an important role by encouraging giving and providing systems that simplify giving, such as payroll deduction. Many of those surveyed gave through programs offered by their employers, and were also able to increase the level of giving by using matching gift programs. Among the key findings about employer support in Kent County are:  \n\n- Payroll deduction of contributions by employers was available for $49\\%$ of workers surveyed, and almost half of this group used the payroll deduction process. Both the existence and use of payroll deduction plans increase with income.  \n\n![](images/c9d3e843d155d13d71db1a1f600fb37edbbdd73e101cf5a53bc1c744cf09ecdf.jpg)",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Factors that could impinge on future giving include: [...] - being financially unable to give (52%).",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/1c00e16c0db1f129d7b8b87fad27646fdfc393600d20182fa7eb94682601b913.pdf_9",
        "ID": "1320cceb-0100-4f9b-a3e5-7d420711f067",
        "questions": "What percentage of workers surveyed reported that payroll deduction of contributions by employers was available in Kent County?",
        "answers": "49%",
        "context": "# Individual Giving  \n\nIf household income drops, 45% would reduce their contribution.  \n\n# WHAT COULD REDUCE GIVING  \n\nAlthough most citizens plan to support nonprofits in the next 12 months as generously as they have in the past year, it is important to anticipate what factors might reduce donations. For example, $45\\%$ reported that their contributions would be reduced if their incomes dropped. However, $73\\%$ appeared to be optimistic about their job security in the coming year.  \n\nFactors that could impinge on future giving include: \n- hearing that nonprofits have high overhead, salary, and administrative costs $(65\\%)$.\n- too many requests for contributions $(65\\%)$.\n- lack of sufficient information about how contributions will be spent $(61\\%)$.\n- being financially unable to give $(52\\%)$.\n- having other spending priorities $(41\\%)$.\n- not being personally asked to give $(34\\%)$.\n- losing a job $(27\\%)$.\n\n![](images/d83bb93f2cb5ae148ad27edc47884895ead5b60393c0acbacb51aacee5999e79.jpg)\n\n# EMPLOYER SUPPORT  \n\nThe workplace plays an important role by encouraging giving and providing systems that simplify giving, such as payroll deduction. Many of those surveyed gave through programs offered by their employers, and were also able to increase the level of giving by using matching gift programs. Among the key findings about employer support in Kent County are:  \n\n- Payroll deduction of contributions by employers was available for $49\\%$ of workers surveyed, and almost half of this group used the payroll deduction process. Both the existence and use of payroll deduction plans increase with income.  \n\n![](images/c9d3e843d155d13d71db1a1f600fb37edbbdd73e101cf5a53bc1c744cf09ecdf.jpg)",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Numeric",
        "evidence_source": "text",
        "evidence_context": "Payroll deduction of contributions by employers was available for 49% of workers surveyed, and almost half of this group used the payroll deduction process.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/chem-323236.pdf_183",
        "ID": "13337bb7-168c-4202-85d3-3f0978dfcadf",
        "questions": "What is the prefix used to specify a molecule with four atoms of an element according to Table 5.8.1?",
        "answers": "tetra-",
        "context": "# 5.8: Naming Molecular (Covalent) Compounds\n\n# Learning Objectives  \n\nDetermine the name of a simple molecular compound from its chemical formula.  \n\n# Molecular Compounds  \n\nMolecular compounds are inorganic compounds that take the form of discrete molecules. Examples include such familiar substances as water $\\mathrm{(H_{2}O)}$ and carbon dioxide $(\\mathrm{CO_{2}})$. These compounds are very different from ionic compounds like sodium chloride $\\mathrm{(NaCl)}$. Ionic compounds are formed when metal atoms lose one or more of their electrons to nonmetal atoms. The resulting cations and anions are electrostatically attracted to each other.  \n\nSo, what holds the atoms of a molecule together? Rather than forming ions, the atoms of a molecule share their electrons in such a way that a bond forms between a pair of atoms. In a carbon dioxide molecule, there are two of these bonds, each occurring between the carbon atom and one of the two oxygen atoms.  \n\n![](images/a24696198d68a156bedf2a87c6be7ce7afe720474c7e017a1512f98799f4f1c0.jpg)  \nFigure 5.8.1: Carbon dioxide molecules consist of a central carbon atom bonded to 2 oxygen atoms.  \n\nLarger molecules can have many, many bonds that serve to keep the molecule together. In a large sample of a given molecular compound, all of the individual molecules are identical.  \n\n# Naming Binary Molecular Compounds  \n\nRecall that a molecular formula shows the number of atoms of each element that a molecule contains. A molecule of water contains two hydrogen atoms and one oxygen atom, so its formula is $\\mathrm{H}_{2}\\mathrm{O}$. A molecule of octane, which is a component of gasoline, $\\mathrm{C_{8}H_{18}}$.  \n\n![](images/df60c3fe2a34711580adf46795c6bb91ef1bb1710a2a303a697377c71e301182.jpg)  \nFigure 5.8.2: Nitrogen dioxide $\\mathrm{(NO_{2})}$ is a reddish-brown toxic gas that is a prominent air pollutant produced by internal combustion engines.  \n\nNaming binary (two-element) molecular compounds is similar to naming simple ionic compounds. The first element in the formula is simply listed using the name of the element. The second element is named by taking the stem of the element name and adding the suffix -ide. A system of numerical prefixes is used to specify the number of atoms in a molecule. Table 5.8.1 lists these numerical prefixes.  \n\n$\n\\begin{tabular}{|c|c|}\n \nNumber of Atoms in Compound & Prefix on the Name of the Element \\\\\n \n1 & mono-\\* \\\\\n \n2 & di- \\\\\n \n3 & tri- \\\\\n \n4 & tetra- \\\\\n \n5 & penta- \\\\\n \n6 & hexa- \\\\\n \n\\end{tabular}\n$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "table",
        "evidence_context": "4 & tetra-",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/chem-323236.pdf_183",
        "ID": "133f10a2-163c-4e1d-b72f-3bde631453f4",
        "questions": "How many hydrogen atoms are contained in a molecule of octane, which is a component of gasoline?",
        "answers": "18",
        "context": "# 5.8: Naming Molecular (Covalent) Compounds\n\n# Learning Objectives  \n\nDetermine the name of a simple molecular compound from its chemical formula.  \n\n# Molecular Compounds  \n\nMolecular compounds are inorganic compounds that take the form of discrete molecules. Examples include such familiar substances as water $\\mathrm{(H_{2}O)}$ and carbon dioxide $(\\mathrm{CO_{2}})$. These compounds are very different from ionic compounds like sodium chloride $\\mathrm{(NaCl)}$. Ionic compounds are formed when metal atoms lose one or more of their electrons to nonmetal atoms. The resulting cations and anions are electrostatically attracted to each other.  \n\nSo, what holds the atoms of a molecule together? Rather than forming ions, the atoms of a molecule share their electrons in such a way that a bond forms between a pair of atoms. In a carbon dioxide molecule, there are two of these bonds, each occurring between the carbon atom and one of the two oxygen atoms.  \n\n![](images/a24696198d68a156bedf2a87c6be7ce7afe720474c7e017a1512f98799f4f1c0.jpg)  \nFigure 5.8.1: Carbon dioxide molecules consist of a central carbon atom bonded to 2 oxygen atoms.  \n\nLarger molecules can have many, many bonds that serve to keep the molecule together. In a large sample of a given molecular compound, all of the individual molecules are identical.  \n\n# Naming Binary Molecular Compounds  \n\nRecall that a molecular formula shows the number of atoms of each element that a molecule contains. A molecule of water contains two hydrogen atoms and one oxygen atom, so its formula is $\\mathrm{H}_{2}\\mathrm{O}$. A molecule of octane, which is a component of gasoline, $\\mathrm{C_{8}H_{18}}$.  \n\n![](images/df60c3fe2a34711580adf46795c6bb91ef1bb1710a2a303a697377c71e301182.jpg)  \nFigure 5.8.2: Nitrogen dioxide $\\mathrm{(NO_{2})}$ is a reddish-brown toxic gas that is a prominent air pollutant produced by internal combustion engines.  \n\nNaming binary (two-element) molecular compounds is similar to naming simple ionic compounds. The first element in the formula is simply listed using the name of the element. The second element is named by taking the stem of the element name and adding the suffix -ide. A system of numerical prefixes is used to specify the number of atoms in a molecule. Table 5.8.1 lists these numerical prefixes.  \n\n$\n\\begin{tabular}{|c|c|}\n \nNumber of Atoms in Compound & Prefix on the Name of the Element \\\\\n \n1 & mono-\\* \\\\\n \n2 & di- \\\\\n \n3 & tri- \\\\\n \n4 & tetra- \\\\\n \n5 & penta- \\\\\n \n6 & hexa- \\\\\n \n\\end{tabular}\n$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Numeric",
        "evidence_source": "text",
        "evidence_context": "A molecule of octane, which is a component of gasoline, $\\mathrm{C_{8}H_{18}}$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/chem-323236.pdf_183",
        "ID": "13493ec4-fa5e-499e-a3ff-34b7c2ce6c9b",
        "questions": "What type of bond forms between atoms in a molecular compound as opposed to an ionic compound?",
        "answers": "The atoms of a molecule share their electrons in such a way that a bond forms between a pair of atoms.",
        "context": "# 5.8: Naming Molecular (Covalent) Compounds\n\n# Learning Objectives  \n\nDetermine the name of a simple molecular compound from its chemical formula.  \n\n# Molecular Compounds  \n\nMolecular compounds are inorganic compounds that take the form of discrete molecules. Examples include such familiar substances as water $\\mathrm{(H_{2}O)}$ and carbon dioxide $(\\mathrm{CO_{2}})$. These compounds are very different from ionic compounds like sodium chloride $\\mathrm{(NaCl)}$. Ionic compounds are formed when metal atoms lose one or more of their electrons to nonmetal atoms. The resulting cations and anions are electrostatically attracted to each other.  \n\nSo, what holds the atoms of a molecule together? Rather than forming ions, the atoms of a molecule share their electrons in such a way that a bond forms between a pair of atoms. In a carbon dioxide molecule, there are two of these bonds, each occurring between the carbon atom and one of the two oxygen atoms.  \n\n![](images/a24696198d68a156bedf2a87c6be7ce7afe720474c7e017a1512f98799f4f1c0.jpg)  \nFigure 5.8.1: Carbon dioxide molecules consist of a central carbon atom bonded to 2 oxygen atoms.  \n\nLarger molecules can have many, many bonds that serve to keep the molecule together. In a large sample of a given molecular compound, all of the individual molecules are identical.  \n\n# Naming Binary Molecular Compounds  \n\nRecall that a molecular formula shows the number of atoms of each element that a molecule contains. A molecule of water contains two hydrogen atoms and one oxygen atom, so its formula is $\\mathrm{H}_{2}\\mathrm{O}$. A molecule of octane, which is a component of gasoline, $\\mathrm{C_{8}H_{18}}$.  \n\n![](images/df60c3fe2a34711580adf46795c6bb91ef1bb1710a2a303a697377c71e301182.jpg)  \nFigure 5.8.2: Nitrogen dioxide $\\mathrm{(NO_{2})}$ is a reddish-brown toxic gas that is a prominent air pollutant produced by internal combustion engines.  \n\nNaming binary (two-element) molecular compounds is similar to naming simple ionic compounds. The first element in the formula is simply listed using the name of the element. The second element is named by taking the stem of the element name and adding the suffix -ide. A system of numerical prefixes is used to specify the number of atoms in a molecule. Table 5.8.1 lists these numerical prefixes.  \n\n$\n\\begin{tabular}{|c|c|}\n \nNumber of Atoms in Compound & Prefix on the Name of the Element \\\\\n \n1 & mono-\\* \\\\\n \n2 & di- \\\\\n \n3 & tri- \\\\\n \n4 & tetra- \\\\\n \n5 & penta- \\\\\n \n6 & hexa- \\\\\n \n\\end{tabular}\n$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Rather than forming ions, the atoms of a molecule share their electrons in such a way that a bond forms between a pair of atoms.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/socialsci-65263.pdf_113",
        "ID": "13495931-f4bf-40fa-8b6b-bb82acea0c22",
        "questions": "What percentage of ADHD cases is attributed to genetic variations according to twin studies mentioned in the document?",
        "answers": "75%",
        "context": "of the family. The psychologist found that in the morning, Jake would complete one or two steps of his routine before he became distracted and switched activities, despite his mother's constant reminders. During dinner time, Jake would leave his seat between 10 and 15 times over the course of the meal. Jake's teachers were worried because Jake was only able to complete 50% of his homework. Further, his classmates would not pick Jake for team sports during recess because he often became distracted and wandered off during the game.\n\nIn this case, Jake's symptoms would not be considered developmentally appropriate for a 10-year-old child. Further, his symptoms caused him to experience impairment at home and school. Unlike Michael, Jake probably would be diagnosed with ADHD.\n\n# Why Do Some Children Develop Behavior Disorders?\n\nThe reasons that some children develop ADHD are complex, and it is generally recognized that a single cause is insufficient to explain why an individual child does or does not have the disorder. Researchers have attempted to identify risk factors that predispose a child to develop ADHD. These risk factors range in scope from genetic (e.g., specific gene polymorphisms) to familial (e.g., poor parenting) to cultural (e.g., low socioeconomic status). This section will identify some of the risk factors that are thought to contribute to ADHD. It will conclude by reviewing some of the more controversial ideas about the causes of ADHD, such as poor parenting and children's diets, and review some of the evidence pertaining to these causes.\n\n![](images/f625ff72e43fe00b54ad95554f13c5041f337dc097e0b49ccb508af75dfd24d9.jpg)  \nStudies of twins have shown that genetics are primarily responsible for ADHD. [Image: donnierayjones, https://goo.gl/dgPvFx, CC BY 2.0, https://goo.gl/9uSnqN]\n\nMost experts believe that genetic and neurophysiological factors cause the majority of ADHD cases. Indeed, ADHD is primarily a genetic disorder\u2014twin studies find that whether or not a child develops ADHD is due in large part (75%) to genetic variations (Faraone et al., 2005). Further, children with a family history of ADHD are more likely to develop ADHD themselves (Faraone & Biederman, 1994). Specific genes that have been associated with ADHD are linked to neurotransmitters such as dopamine and serotonin. In addition, neuroimaging studies have found that children with ADHD show reduced brain volume in some regions of the brain, such as the prefrontal cortex, the corpus callosum, the anterior cingulate cortex, the basal ganglia, and the cerebellum (Seidman, Valera, & Makris, 2005). Among their other functions, these regions of the brain are implicated in organization, impulse control, and motor activity, so the reduced volume of these structures in children with ADHD may cause some of their symptoms.\n\nAlthough genetics appear to be a main cause of ADHD, recent studies have shown that environmental risk factors may cause a minority of ADHD cases. Many of these environmental risk factors increase the risk for ADHD by disrupting early development and compromising the integrity of the central nervous system. Environmental influences such as low birth weight, malnutrition, and maternal alcohol and nicotine use during pregnancy can increase the likelihood that a child will develop ADHD (Mick, Biederman, Faraone, Sayer, & Kleinman, 2002). Additionally, recent studies have shown that exposure to environmental toxins, such as lead and pesticides, early in a child's life may also increase risk of developing ADHD (Nigg, 2006).\n\n# Controversies on Causes of ADHD\n\nControversial explanations for the development of ADHD have risen and fallen in popularity since the 1960s. Some of these ideas arise from cultural folklore, others can be traced to \"specialists\" trying to market an easy fix for ADHD based on their proposed cause. Some other ideas contain a kernel of truth but have been falsely cast as causing the majority of ADHD cases.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Numeric",
        "evidence_source": "text",
        "evidence_context": "Indeed, ADHD is primarily a genetic disorder\u2014twin studies find that whether or not a child develops ADHD is due in large part (75%) to genetic variations (Faraone et al., 2005).",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/socialsci-65263.pdf_113",
        "ID": "13520473-55bf-45d5-8a72-e1230f006727",
        "questions": "Which neurotransmitters are associated with specific genes linked to ADHD according to the document?",
        "answers": "Dopamine and serotonin",
        "context": "of the family. The psychologist found that in the morning, Jake would complete one or two steps of his routine before he became distracted and switched activities, despite his mother's constant reminders. During dinner time, Jake would leave his seat between 10 and 15 times over the course of the meal. Jake's teachers were worried because Jake was only able to complete 50% of his homework. Further, his classmates would not pick Jake for team sports during recess because he often became distracted and wandered off during the game.\n\nIn this case, Jake's symptoms would not be considered developmentally appropriate for a 10-year-old child. Further, his symptoms caused him to experience impairment at home and school. Unlike Michael, Jake probably would be diagnosed with ADHD.\n\n# Why Do Some Children Develop Behavior Disorders?\n\nThe reasons that some children develop ADHD are complex, and it is generally recognized that a single cause is insufficient to explain why an individual child does or does not have the disorder. Researchers have attempted to identify risk factors that predispose a child to develop ADHD. These risk factors range in scope from genetic (e.g., specific gene polymorphisms) to familial (e.g., poor parenting) to cultural (e.g., low socioeconomic status). This section will identify some of the risk factors that are thought to contribute to ADHD. It will conclude by reviewing some of the more controversial ideas about the causes of ADHD, such as poor parenting and children's diets, and review some of the evidence pertaining to these causes.\n\n![](images/f625ff72e43fe00b54ad95554f13c5041f337dc097e0b49ccb508af75dfd24d9.jpg)  \nStudies of twins have shown that genetics are primarily responsible for ADHD. [Image: donnierayjones, https://goo.gl/dgPvFx, CC BY 2.0, https://goo.gl/9uSnqN]\n\nMost experts believe that genetic and neurophysiological factors cause the majority of ADHD cases. Indeed, ADHD is primarily a genetic disorder\u2014twin studies find that whether or not a child develops ADHD is due in large part (75%) to genetic variations (Faraone et al., 2005). Further, children with a family history of ADHD are more likely to develop ADHD themselves (Faraone & Biederman, 1994). Specific genes that have been associated with ADHD are linked to neurotransmitters such as dopamine and serotonin. In addition, neuroimaging studies have found that children with ADHD show reduced brain volume in some regions of the brain, such as the prefrontal cortex, the corpus callosum, the anterior cingulate cortex, the basal ganglia, and the cerebellum (Seidman, Valera, & Makris, 2005). Among their other functions, these regions of the brain are implicated in organization, impulse control, and motor activity, so the reduced volume of these structures in children with ADHD may cause some of their symptoms.\n\nAlthough genetics appear to be a main cause of ADHD, recent studies have shown that environmental risk factors may cause a minority of ADHD cases. Many of these environmental risk factors increase the risk for ADHD by disrupting early development and compromising the integrity of the central nervous system. Environmental influences such as low birth weight, malnutrition, and maternal alcohol and nicotine use during pregnancy can increase the likelihood that a child will develop ADHD (Mick, Biederman, Faraone, Sayer, & Kleinman, 2002). Additionally, recent studies have shown that exposure to environmental toxins, such as lead and pesticides, early in a child's life may also increase risk of developing ADHD (Nigg, 2006).\n\n# Controversies on Causes of ADHD\n\nControversial explanations for the development of ADHD have risen and fallen in popularity since the 1960s. Some of these ideas arise from cultural folklore, others can be traced to \"specialists\" trying to market an easy fix for ADHD based on their proposed cause. Some other ideas contain a kernel of truth but have been falsely cast as causing the majority of ADHD cases.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Specific genes that have been associated with ADHD are linked to neurotransmitters such as dopamine and serotonin.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/socialsci-65263.pdf_113",
        "ID": "135981c7-b984-4be3-aef8-2d2e51f83e44",
        "questions": "According to Mick, Biederman, Faraone, Sayer, & Kleinman (2002), name one environmental factor that can increase the likelihood of developing ADHD?",
        "answers": "Maternal alcohol and nicotine use during pregnancy",
        "context": "of the family. The psychologist found that in the morning, Jake would complete one or two steps of his routine before he became distracted and switched activities, despite his mother's constant reminders. During dinner time, Jake would leave his seat between 10 and 15 times over the course of the meal. Jake's teachers were worried because Jake was only able to complete 50% of his homework. Further, his classmates would not pick Jake for team sports during recess because he often became distracted and wandered off during the game.\n\nIn this case, Jake's symptoms would not be considered developmentally appropriate for a 10-year-old child. Further, his symptoms caused him to experience impairment at home and school. Unlike Michael, Jake probably would be diagnosed with ADHD.\n\n# Why Do Some Children Develop Behavior Disorders?\n\nThe reasons that some children develop ADHD are complex, and it is generally recognized that a single cause is insufficient to explain why an individual child does or does not have the disorder. Researchers have attempted to identify risk factors that predispose a child to develop ADHD. These risk factors range in scope from genetic (e.g., specific gene polymorphisms) to familial (e.g., poor parenting) to cultural (e.g., low socioeconomic status). This section will identify some of the risk factors that are thought to contribute to ADHD. It will conclude by reviewing some of the more controversial ideas about the causes of ADHD, such as poor parenting and children's diets, and review some of the evidence pertaining to these causes.\n\n![](images/f625ff72e43fe00b54ad95554f13c5041f337dc097e0b49ccb508af75dfd24d9.jpg)  \nStudies of twins have shown that genetics are primarily responsible for ADHD. [Image: donnierayjones, https://goo.gl/dgPvFx, CC BY 2.0, https://goo.gl/9uSnqN]\n\nMost experts believe that genetic and neurophysiological factors cause the majority of ADHD cases. Indeed, ADHD is primarily a genetic disorder\u2014twin studies find that whether or not a child develops ADHD is due in large part (75%) to genetic variations (Faraone et al., 2005). Further, children with a family history of ADHD are more likely to develop ADHD themselves (Faraone & Biederman, 1994). Specific genes that have been associated with ADHD are linked to neurotransmitters such as dopamine and serotonin. In addition, neuroimaging studies have found that children with ADHD show reduced brain volume in some regions of the brain, such as the prefrontal cortex, the corpus callosum, the anterior cingulate cortex, the basal ganglia, and the cerebellum (Seidman, Valera, & Makris, 2005). Among their other functions, these regions of the brain are implicated in organization, impulse control, and motor activity, so the reduced volume of these structures in children with ADHD may cause some of their symptoms.\n\nAlthough genetics appear to be a main cause of ADHD, recent studies have shown that environmental risk factors may cause a minority of ADHD cases. Many of these environmental risk factors increase the risk for ADHD by disrupting early development and compromising the integrity of the central nervous system. Environmental influences such as low birth weight, malnutrition, and maternal alcohol and nicotine use during pregnancy can increase the likelihood that a child will develop ADHD (Mick, Biederman, Faraone, Sayer, & Kleinman, 2002). Additionally, recent studies have shown that exposure to environmental toxins, such as lead and pesticides, early in a child's life may also increase risk of developing ADHD (Nigg, 2006).\n\n# Controversies on Causes of ADHD\n\nControversial explanations for the development of ADHD have risen and fallen in popularity since the 1960s. Some of these ideas arise from cultural folklore, others can be traced to \"specialists\" trying to market an easy fix for ADHD based on their proposed cause. Some other ideas contain a kernel of truth but have been falsely cast as causing the majority of ADHD cases.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Environmental influences such as low birth weight, malnutrition, and maternal alcohol and nicotine use during pregnancy can increase the likelihood that a child will develop ADHD (Mick, Biederman, Faraone, Sayer, & Kleinman, 2002).",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/socialsci-84769.pdf_42",
        "ID": "13626040-3458-496e-b872-e12155e0637c",
        "questions": "What is a characteristic of a semantic differential scale in measuring opinions or feelings?",
        "answers": "the statement remains constant, while the anchors (adjective pairs) change across items",
        "context": "statements vary in different items or indicators, the anchors (\"strongly disagree\" to \"strongly agree\") remain the same. Likert scales are ordinal scales because the anchors are not necessarily equidistant, even though sometimes we treat them like interval scales.  \nHow would you rate your opinions on national health insurance?\n\n\\usepackage[table]{xcolor} % \u5bfc\u5165 colortbl \u5b8f\u5305\u4ee5\u652f\u6301 rowcolor\n\n\\begin{table}[h]\n    \\centering\n    \\caption{Table 6.4. A semantic differential scale for measuring attitude toward national health insurance}\n    \\begin{tabular}{|p{0.11\\textwidth}|p{0.11\\textwidth}|p{0.11\\textwidth}|p{0.11\\textwidth}|p{0.11\\textwidth}|p{0.11\\textwidth}|p{0.11\\textwidth}|}\n         \n        \\rowcolor[HTML]{FFFFFF} \n        & Very much & Somewhat & Neither & Somewhat & Very much &  \\\\\n         \n        Good & & & & & & Bad \\\\\n         \n        \\rowcolor[HTML]{E9E9E9} \n        Useful & & & & & & Useless \\\\\n         \n        Caring & & & & & & Uncaring \\\\\n         \n        \\rowcolor[HTML]{E9E9E9} \n        Interesting & & & & & & Boring \\\\\n         \n    \\end{tabular}\n\\end{table}\n\n\nSemantic differential scale. This is a composite (multi-item) scale where respondents are asked to indicate their opinions or feelings toward a single statement using different pairs of adjectives framed as polar opposites. For instance, the construct \"attitude toward national health insurance\" can be measured using four items shown in Table 6.4. As in the Likert scale, the overall scale score may be a summation of individual item scores. Notice that in Likert scales, the statement changes but the anchors remain the same across items. However, in semantic differential scales, the statement remains constant, while the anchors (adjective pairs) change across items. Semantic differential is believed to be an excellent technique for measuring people's attitude or feelings toward objects, events, or behaviors.  \n\nGuttman scale. Designed by Louis Guttman, this composite scale uses a series of items arranged in increasing order of intensity of the construct of interest, from least intense to most intense. As an example, the construct \"attitude toward immigrants\" can be measured using five items shown in Table 6.5. Each item in the above Guttman scale has a weight (not indicated above) which varies with the intensity of that item, and the weighted combination of each response is used as an aggregate measure of an observation.  \n\nHow will you rate your opinions on the following statements about immigrants?  \n\n\\begin{table}\n\\centering\n\\caption{Table6.5. A five-item Guttman scale for measuring attitude toward immigrants}\n\\begin{tabular}{|>{\\columncolor[gray]{0.95}}m{0.5\\linewidth}|l|l|}\n \n Question & Yes & No \\\\\n \nDo you mind immigrants being citizens of your country? & Yes & No \\\\\n \n Do you mind immigrants living in your own neighborhood? & Yes & No \\\\\n \nWould you mind living next door to an immigrant? & Yes & No \\\\\n \nWould you mind having an immigrant as your close friend? & Yes & No \\\\\n \nWould you mind if someone in your family married an immigrant? & Yes & No \\\\\n \n\\end{tabular}\n\\end{table}\n\n# Scaling  \n\nThe previous section discussed how to measure respondents\u2019 responses to predesigned items or indicators belonging to an underlying construct. But how do we create the indicators themselves? The process of creating the indicators is called scaling. More formally, scaling is a branch of measurement that involves the construction of measures by associating qualitative judgments about unobservable constructs with quantitative, measurable metric units. Stevens (1946) said, \"Scaling is the assignment of objects to numbers according to a rule.\" This process of measuring abstract concepts in concrete terms remains one of the most difficult tasks in empirical social science research.  \n\nThe outcome of a scaling process is a scale, which is an empirical structure for measuring items or indicators of a given construct. Understand that \"scales\", as discussed in this section, are a little different from \"rating scales\" discussed in the previous section. A rating scale is used to capture the respondents\u2019 reactions to a given item, for instance, such as a nominal scaled item captures a yes/no reaction and an interval scaled item captures a value between \"strongly disagree\" to \"strongly agree.\" Attaching a rating",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "However, in semantic differential scales, the statement remains constant, while the anchors (adjective pairs) change across items.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/socialsci-84769.pdf_42",
        "ID": "1372c380-c140-441c-b635-8066e5d151bc",
        "questions": "In which year did Stevens define the concept of scaling?",
        "answers": "1946",
        "context": "statements vary in different items or indicators, the anchors (\"strongly disagree\" to \"strongly agree\") remain the same. Likert scales are ordinal scales because the anchors are not necessarily equidistant, even though sometimes we treat them like interval scales.  \nHow would you rate your opinions on national health insurance?\n\n\\usepackage[table]{xcolor} % \u5bfc\u5165 colortbl \u5b8f\u5305\u4ee5\u652f\u6301 rowcolor\n\n\\begin{table}[h]\n    \\centering\n    \\caption{Table 6.4. A semantic differential scale for measuring attitude toward national health insurance}\n    \\begin{tabular}{|p{0.11\\textwidth}|p{0.11\\textwidth}|p{0.11\\textwidth}|p{0.11\\textwidth}|p{0.11\\textwidth}|p{0.11\\textwidth}|p{0.11\\textwidth}|}\n         \n        \\rowcolor[HTML]{FFFFFF} \n        & Very much & Somewhat & Neither & Somewhat & Very much &  \\\\\n         \n        Good & & & & & & Bad \\\\\n         \n        \\rowcolor[HTML]{E9E9E9} \n        Useful & & & & & & Useless \\\\\n         \n        Caring & & & & & & Uncaring \\\\\n         \n        \\rowcolor[HTML]{E9E9E9} \n        Interesting & & & & & & Boring \\\\\n         \n    \\end{tabular}\n\\end{table}\n\n\nSemantic differential scale. This is a composite (multi-item) scale where respondents are asked to indicate their opinions or feelings toward a single statement using different pairs of adjectives framed as polar opposites. For instance, the construct \"attitude toward national health insurance\" can be measured using four items shown in Table 6.4. As in the Likert scale, the overall scale score may be a summation of individual item scores. Notice that in Likert scales, the statement changes but the anchors remain the same across items. However, in semantic differential scales, the statement remains constant, while the anchors (adjective pairs) change across items. Semantic differential is believed to be an excellent technique for measuring people's attitude or feelings toward objects, events, or behaviors.  \n\nGuttman scale. Designed by Louis Guttman, this composite scale uses a series of items arranged in increasing order of intensity of the construct of interest, from least intense to most intense. As an example, the construct \"attitude toward immigrants\" can be measured using five items shown in Table 6.5. Each item in the above Guttman scale has a weight (not indicated above) which varies with the intensity of that item, and the weighted combination of each response is used as an aggregate measure of an observation.  \n\nHow will you rate your opinions on the following statements about immigrants?  \n\n\\begin{table}\n\\centering\n\\caption{Table6.5. A five-item Guttman scale for measuring attitude toward immigrants}\n\\begin{tabular}{|>{\\columncolor[gray]{0.95}}m{0.5\\linewidth}|l|l|}\n \n Question & Yes & No \\\\\n \nDo you mind immigrants being citizens of your country? & Yes & No \\\\\n \n Do you mind immigrants living in your own neighborhood? & Yes & No \\\\\n \nWould you mind living next door to an immigrant? & Yes & No \\\\\n \nWould you mind having an immigrant as your close friend? & Yes & No \\\\\n \nWould you mind if someone in your family married an immigrant? & Yes & No \\\\\n \n\\end{tabular}\n\\end{table}\n\n# Scaling  \n\nThe previous section discussed how to measure respondents\u2019 responses to predesigned items or indicators belonging to an underlying construct. But how do we create the indicators themselves? The process of creating the indicators is called scaling. More formally, scaling is a branch of measurement that involves the construction of measures by associating qualitative judgments about unobservable constructs with quantitative, measurable metric units. Stevens (1946) said, \"Scaling is the assignment of objects to numbers according to a rule.\" This process of measuring abstract concepts in concrete terms remains one of the most difficult tasks in empirical social science research.  \n\nThe outcome of a scaling process is a scale, which is an empirical structure for measuring items or indicators of a given construct. Understand that \"scales\", as discussed in this section, are a little different from \"rating scales\" discussed in the previous section. A rating scale is used to capture the respondents\u2019 reactions to a given item, for instance, such as a nominal scaled item captures a yes/no reaction and an interval scaled item captures a value between \"strongly disagree\" to \"strongly agree.\" Attaching a rating",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Numeric",
        "evidence_source": "text",
        "evidence_context": "Stevens (1946) said, 'Scaling is the assignment of objects to numbers according to a rule.'",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/socialsci-84769.pdf_42",
        "ID": "13732886-4ad6-4644-a684-2175f54b092a",
        "questions": "What kind of questions are used in the example Guttman scale for measuring attitudes toward immigrants?",
        "answers": "[Yes/No]",
        "context": "statements vary in different items or indicators, the anchors (\"strongly disagree\" to \"strongly agree\") remain the same. Likert scales are ordinal scales because the anchors are not necessarily equidistant, even though sometimes we treat them like interval scales.  \nHow would you rate your opinions on national health insurance?\n\n\\usepackage[table]{xcolor} % \u5bfc\u5165 colortbl \u5b8f\u5305\u4ee5\u652f\u6301 rowcolor\n\n\\begin{table}[h]\n    \\centering\n    \\caption{Table 6.4. A semantic differential scale for measuring attitude toward national health insurance}\n    \\begin{tabular}{|p{0.11\\textwidth}|p{0.11\\textwidth}|p{0.11\\textwidth}|p{0.11\\textwidth}|p{0.11\\textwidth}|p{0.11\\textwidth}|p{0.11\\textwidth}|}\n         \n        \\rowcolor[HTML]{FFFFFF} \n        & Very much & Somewhat & Neither & Somewhat & Very much &  \\\\\n         \n        Good & & & & & & Bad \\\\\n         \n        \\rowcolor[HTML]{E9E9E9} \n        Useful & & & & & & Useless \\\\\n         \n        Caring & & & & & & Uncaring \\\\\n         \n        \\rowcolor[HTML]{E9E9E9} \n        Interesting & & & & & & Boring \\\\\n         \n    \\end{tabular}\n\\end{table}\n\n\nSemantic differential scale. This is a composite (multi-item) scale where respondents are asked to indicate their opinions or feelings toward a single statement using different pairs of adjectives framed as polar opposites. For instance, the construct \"attitude toward national health insurance\" can be measured using four items shown in Table 6.4. As in the Likert scale, the overall scale score may be a summation of individual item scores. Notice that in Likert scales, the statement changes but the anchors remain the same across items. However, in semantic differential scales, the statement remains constant, while the anchors (adjective pairs) change across items. Semantic differential is believed to be an excellent technique for measuring people's attitude or feelings toward objects, events, or behaviors.  \n\nGuttman scale. Designed by Louis Guttman, this composite scale uses a series of items arranged in increasing order of intensity of the construct of interest, from least intense to most intense. As an example, the construct \"attitude toward immigrants\" can be measured using five items shown in Table 6.5. Each item in the above Guttman scale has a weight (not indicated above) which varies with the intensity of that item, and the weighted combination of each response is used as an aggregate measure of an observation.  \n\nHow will you rate your opinions on the following statements about immigrants?  \n\n\\begin{table}\n\\centering\n\\caption{Table6.5. A five-item Guttman scale for measuring attitude toward immigrants}\n\\begin{tabular}{|>{\\columncolor[gray]{0.95}}m{0.5\\linewidth}|l|l|}\n \n Question & Yes & No \\\\\n \nDo you mind immigrants being citizens of your country? & Yes & No \\\\\n \n Do you mind immigrants living in your own neighborhood? & Yes & No \\\\\n \nWould you mind living next door to an immigrant? & Yes & No \\\\\n \nWould you mind having an immigrant as your close friend? & Yes & No \\\\\n \nWould you mind if someone in your family married an immigrant? & Yes & No \\\\\n \n\\end{tabular}\n\\end{table}\n\n# Scaling  \n\nThe previous section discussed how to measure respondents\u2019 responses to predesigned items or indicators belonging to an underlying construct. But how do we create the indicators themselves? The process of creating the indicators is called scaling. More formally, scaling is a branch of measurement that involves the construction of measures by associating qualitative judgments about unobservable constructs with quantitative, measurable metric units. Stevens (1946) said, \"Scaling is the assignment of objects to numbers according to a rule.\" This process of measuring abstract concepts in concrete terms remains one of the most difficult tasks in empirical social science research.  \n\nThe outcome of a scaling process is a scale, which is an empirical structure for measuring items or indicators of a given construct. Understand that \"scales\", as discussed in this section, are a little different from \"rating scales\" discussed in the previous section. A rating scale is used to capture the respondents\u2019 reactions to a given item, for instance, such as a nominal scaled item captures a yes/no reaction and an interval scaled item captures a value between \"strongly disagree\" to \"strongly agree.\" Attaching a rating",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Yes/No",
        "evidence_source": "table",
        "evidence_context": "Would you mind if someone in your family married an immigrant? & Yes & No",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM_090_-_ISBN978-1-4612-1148-8_-_Arne_Br\u00f8ndsted_-_An_Introduction_to_Convex_Polytopes.pdf_42",
        "ID": "1377dc4a-4aea-465b-acb0-4a442c040f51",
        "questions": "What is the maximum number of extreme points needed to express any point in a compact convex set C in R^d with dimension n as a convex combination according to Corollary 5.11?",
        "answers": "n+1",
        "context": "To prove $(b)\\Rightarrow(a)$, it suffices to show that  \n\n$$\nC\\in\\operatorname{conv}(\\operatorname{ext}\\,C).\n$$\n\n(In fact, suppose that (4) holds. Since the opposite inclusion of (4) is obvious, it then follows that $C={\\mathrm{conv}}({\\mathrm{ext}}\\ C)$. But then we also have $C={\\mathrm{conv}}\\ M$ for any subset $M$ of $C$ containing ext $C$.) We shall prove (4) by induction on the dimension of $C$. For dim $C=-1,0$, there is nothing to prove. For dim $C=1$, the statement is clearly valid. Suppose that the statement is valid for all compact convex sets of dimension $<e$, where $e\\geq2$, and let $C$ be a compact convex set of dimension $e$. Let $x$ be any point in $C$; we shall prove that $x$ is a convex combination of extreme points of $C$, cf. Theorem 2.2. If $x$ itself is an extreme point, there is nothing to prove. If $x$ is not an extreme point, then there is a segment in $C$ having $x$ in its relative interior. Extending the segment, if necessary, we see that there are in fact points $y_{0},y_{1}\\in\\mathrm{rb}\\;C$ such that $x\\in\\;]y_{0},y_{1}[$. Let $F_{0}$ and $F_{1}$ be the smallest faces of $C$ containing $y_{0}$ and $y_{1}$, respectively. Then $F_{0}$ and $F_{1}$ are proper faces of $C$, cf. Corollary 5.7. They are, in particular, compact convex sets, cf. Theorem 5.1, and they both have dimension $<e$, cf. Corollary 5.5. Then, by the induction hypothesis, there are points $x_{0\\,1},\\dots,x_{0\\,p}\\in\\,\\mathrm{ext}\\,F_{0}$ and $x_{11},\\dots,x_{1q}\\in\\,\\mathrm{ext}\\,F_{\\mathrm{1}}$ such that $y_{0}$ is a convex combination of the $x_{0i}$'s and $y_{1}$ is a convex combination of the $x_{1j}$'s. Since $x$ is a convex combination of $y_{0}$ and $y_{1}$, it follows that $x$ is a convex combination of the $x_{0i}$'s and $x_{1j}$'s. To complete the proof, we note that the $x_{0i}$'s and $x_{1j}$'s are in fact extreme points of $C$; this follows from Theorem 5.2.\n\nCorollary 5.11. Let $C$ be a compact convex set in $\\mathbb{R}^{d}$ with $\\mathrm{dim}\\;C=n$. Then each point of $C$ is a convex combination of at most $n+1$ extreme points of $C$.\n\nProof. Combine Theorem 5.10(c) and Corollary 2.4.  \n\n# EXERCISES  \n\n5.1. Show that ext $C$ is closed when $C$ is a 2-dimensional compact convex set.\n\n5.2. Let $C$ be the convex hull of the set of points $(\\alpha_{1},\\alpha_{2},\\alpha_{3})\\in\\mathbb{R}^{3}$ such that\n\n$$\n\\begin{array}{r}{\\alpha_{1}=\\alpha_{2}=0,\\qquad\\alpha_{3}\\in[-1,1],}\\end{array}\n$$  \n\nor  \n\n$$\n\\alpha_{3}=0,\\qquad(\\alpha_{1}-1)^{2}+\\alpha_{2}^{2}=1.\n$$  \n\nShow that $\\mathrm{ext}\\,C$ is non-closed.  \n\n5.3. Let $C$ be a closed convex set in $\\mathbb{R}^{d}$. Show that if a convex subset $F$ of $C$ is a face of $C$, then $C\\backslash F$ is convex. Show that the converse does not hold in general.  \n\n5.4. Let $C$ be a non-empty closed convex set in $\\mathbb{R}^{d}$. An affine subspace $A$ of $\\mathbb{R}^{d}$ is said to support $C$ if $A\\cap C\\neq\\emptyset$ and $C\\backslash A$ is convex. Show that the supporting hyperplanes of $C$ in the sense of Section 4 are the hyperplanes that support $C$ in the sense just mentioned.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Corollary 5.11. Let $C$ be a compact convex set in $\\mathbb{R}^{d}$ with $\\mathrm{dim}\\;C=n$. Then each point of $C$ is a convex combination of at most $n+1$ extreme points of $C$.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM_090_-_ISBN978-1-4612-1148-8_-_Arne_Br\u00f8ndsted_-_An_Introduction_to_Convex_Polytopes.pdf_42",
        "ID": "13843901-b020-48d4-929b-eb354fa09d36",
        "questions": "In the proof that involves induction on the dimension of a compact convex set C, what happens if a point x in C is not an extreme point?",
        "answers": "There is a segment in C having x in its relative interior.",
        "context": "To prove $(b)\\Rightarrow(a)$, it suffices to show that  \n\n$$\nC\\in\\operatorname{conv}(\\operatorname{ext}\\,C).\n$$\n\n(In fact, suppose that (4) holds. Since the opposite inclusion of (4) is obvious, it then follows that $C={\\mathrm{conv}}({\\mathrm{ext}}\\ C)$. But then we also have $C={\\mathrm{conv}}\\ M$ for any subset $M$ of $C$ containing ext $C$.) We shall prove (4) by induction on the dimension of $C$. For dim $C=-1,0$, there is nothing to prove. For dim $C=1$, the statement is clearly valid. Suppose that the statement is valid for all compact convex sets of dimension $<e$, where $e\\geq2$, and let $C$ be a compact convex set of dimension $e$. Let $x$ be any point in $C$; we shall prove that $x$ is a convex combination of extreme points of $C$, cf. Theorem 2.2. If $x$ itself is an extreme point, there is nothing to prove. If $x$ is not an extreme point, then there is a segment in $C$ having $x$ in its relative interior. Extending the segment, if necessary, we see that there are in fact points $y_{0},y_{1}\\in\\mathrm{rb}\\;C$ such that $x\\in\\;]y_{0},y_{1}[$. Let $F_{0}$ and $F_{1}$ be the smallest faces of $C$ containing $y_{0}$ and $y_{1}$, respectively. Then $F_{0}$ and $F_{1}$ are proper faces of $C$, cf. Corollary 5.7. They are, in particular, compact convex sets, cf. Theorem 5.1, and they both have dimension $<e$, cf. Corollary 5.5. Then, by the induction hypothesis, there are points $x_{0\\,1},\\dots,x_{0\\,p}\\in\\,\\mathrm{ext}\\,F_{0}$ and $x_{11},\\dots,x_{1q}\\in\\,\\mathrm{ext}\\,F_{\\mathrm{1}}$ such that $y_{0}$ is a convex combination of the $x_{0i}$'s and $y_{1}$ is a convex combination of the $x_{1j}$'s. Since $x$ is a convex combination of $y_{0}$ and $y_{1}$, it follows that $x$ is a convex combination of the $x_{0i}$'s and $x_{1j}$'s. To complete the proof, we note that the $x_{0i}$'s and $x_{1j}$'s are in fact extreme points of $C$; this follows from Theorem 5.2.\n\nCorollary 5.11. Let $C$ be a compact convex set in $\\mathbb{R}^{d}$ with $\\mathrm{dim}\\;C=n$. Then each point of $C$ is a convex combination of at most $n+1$ extreme points of $C$.\n\nProof. Combine Theorem 5.10(c) and Corollary 2.4.  \n\n# EXERCISES  \n\n5.1. Show that ext $C$ is closed when $C$ is a 2-dimensional compact convex set.\n\n5.2. Let $C$ be the convex hull of the set of points $(\\alpha_{1},\\alpha_{2},\\alpha_{3})\\in\\mathbb{R}^{3}$ such that\n\n$$\n\\begin{array}{r}{\\alpha_{1}=\\alpha_{2}=0,\\qquad\\alpha_{3}\\in[-1,1],}\\end{array}\n$$  \n\nor  \n\n$$\n\\alpha_{3}=0,\\qquad(\\alpha_{1}-1)^{2}+\\alpha_{2}^{2}=1.\n$$  \n\nShow that $\\mathrm{ext}\\,C$ is non-closed.  \n\n5.3. Let $C$ be a closed convex set in $\\mathbb{R}^{d}$. Show that if a convex subset $F$ of $C$ is a face of $C$, then $C\\backslash F$ is convex. Show that the converse does not hold in general.  \n\n5.4. Let $C$ be a non-empty closed convex set in $\\mathbb{R}^{d}$. An affine subspace $A$ of $\\mathbb{R}^{d}$ is said to support $C$ if $A\\cap C\\neq\\emptyset$ and $C\\backslash A$ is convex. Show that the supporting hyperplanes of $C$ in the sense of Section 4 are the hyperplanes that support $C$ in the sense just mentioned.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "If $x$ is not an extreme point, then there is a segment in $C$ having $x$ in its relative interior.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM_090_-_ISBN978-1-4612-1148-8_-_Arne_Br\u00f8ndsted_-_An_Introduction_to_Convex_Polytopes.pdf_42",
        "ID": "13896d5f-e051-4913-957e-71ee8d05f9d4",
        "questions": "Is the set of extreme points ext C guaranteed to be closed when C is a 2-dimensional compact convex set?",
        "answers": "Yes",
        "context": "To prove $(b)\\Rightarrow(a)$, it suffices to show that  \n\n$$\nC\\in\\operatorname{conv}(\\operatorname{ext}\\,C).\n$$\n\n(In fact, suppose that (4) holds. Since the opposite inclusion of (4) is obvious, it then follows that $C={\\mathrm{conv}}({\\mathrm{ext}}\\ C)$. But then we also have $C={\\mathrm{conv}}\\ M$ for any subset $M$ of $C$ containing ext $C$.) We shall prove (4) by induction on the dimension of $C$. For dim $C=-1,0$, there is nothing to prove. For dim $C=1$, the statement is clearly valid. Suppose that the statement is valid for all compact convex sets of dimension $<e$, where $e\\geq2$, and let $C$ be a compact convex set of dimension $e$. Let $x$ be any point in $C$; we shall prove that $x$ is a convex combination of extreme points of $C$, cf. Theorem 2.2. If $x$ itself is an extreme point, there is nothing to prove. If $x$ is not an extreme point, then there is a segment in $C$ having $x$ in its relative interior. Extending the segment, if necessary, we see that there are in fact points $y_{0},y_{1}\\in\\mathrm{rb}\\;C$ such that $x\\in\\;]y_{0},y_{1}[$. Let $F_{0}$ and $F_{1}$ be the smallest faces of $C$ containing $y_{0}$ and $y_{1}$, respectively. Then $F_{0}$ and $F_{1}$ are proper faces of $C$, cf. Corollary 5.7. They are, in particular, compact convex sets, cf. Theorem 5.1, and they both have dimension $<e$, cf. Corollary 5.5. Then, by the induction hypothesis, there are points $x_{0\\,1},\\dots,x_{0\\,p}\\in\\,\\mathrm{ext}\\,F_{0}$ and $x_{11},\\dots,x_{1q}\\in\\,\\mathrm{ext}\\,F_{\\mathrm{1}}$ such that $y_{0}$ is a convex combination of the $x_{0i}$'s and $y_{1}$ is a convex combination of the $x_{1j}$'s. Since $x$ is a convex combination of $y_{0}$ and $y_{1}$, it follows that $x$ is a convex combination of the $x_{0i}$'s and $x_{1j}$'s. To complete the proof, we note that the $x_{0i}$'s and $x_{1j}$'s are in fact extreme points of $C$; this follows from Theorem 5.2.\n\nCorollary 5.11. Let $C$ be a compact convex set in $\\mathbb{R}^{d}$ with $\\mathrm{dim}\\;C=n$. Then each point of $C$ is a convex combination of at most $n+1$ extreme points of $C$.\n\nProof. Combine Theorem 5.10(c) and Corollary 2.4.  \n\n# EXERCISES  \n\n5.1. Show that ext $C$ is closed when $C$ is a 2-dimensional compact convex set.\n\n5.2. Let $C$ be the convex hull of the set of points $(\\alpha_{1},\\alpha_{2},\\alpha_{3})\\in\\mathbb{R}^{3}$ such that\n\n$$\n\\begin{array}{r}{\\alpha_{1}=\\alpha_{2}=0,\\qquad\\alpha_{3}\\in[-1,1],}\\end{array}\n$$  \n\nor  \n\n$$\n\\alpha_{3}=0,\\qquad(\\alpha_{1}-1)^{2}+\\alpha_{2}^{2}=1.\n$$  \n\nShow that $\\mathrm{ext}\\,C$ is non-closed.  \n\n5.3. Let $C$ be a closed convex set in $\\mathbb{R}^{d}$. Show that if a convex subset $F$ of $C$ is a face of $C$, then $C\\backslash F$ is convex. Show that the converse does not hold in general.  \n\n5.4. Let $C$ be a non-empty closed convex set in $\\mathbb{R}^{d}$. An affine subspace $A$ of $\\mathbb{R}^{d}$ is said to support $C$ if $A\\cap C\\neq\\emptyset$ and $C\\backslash A$ is convex. Show that the supporting hyperplanes of $C$ in the sense of Section 4 are the hyperplanes that support $C$ in the sense just mentioned.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Yes/No",
        "evidence_source": "text",
        "evidence_context": "5.1. Show that ext $C$ is closed when $C$ is a 2-dimensional compact convex set.",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/GTM_090_-_ISBN978-1-4612-1148-8_-_Arne_Br\u00f8ndsted_-_An_Introduction_to_Convex_Polytopes.pdf_42",
        "ID": "138eadb6-e460-4675-8278-b8db900caefd",
        "questions": "What is required to show for the implication $(b) \\Rightarrow (a)$ to hold?",
        "answers": "$C \\in \\operatorname{conv}(\\operatorname{ext}\\,C)$",
        "context": "To prove $(b)\\Rightarrow(a)$, it suffices to show that  \n\n$$\nC\\in\\operatorname{conv}(\\operatorname{ext}\\,C).\n$$\n\n(In fact, suppose that (4) holds. Since the opposite inclusion of (4) is obvious, it then follows that $C={\\mathrm{conv}}({\\mathrm{ext}}\\ C)$. But then we also have $C={\\mathrm{conv}}\\ M$ for any subset $M$ of $C$ containing ext $C$.) We shall prove (4) by induction on the dimension of $C$. For dim $C=-1,0$, there is nothing to prove. For dim $C=1$, the statement is clearly valid. Suppose that the statement is valid for all compact convex sets of dimension $<e$, where $e\\geq2$, and let $C$ be a compact convex set of dimension $e$. Let $x$ be any point in $C$; we shall prove that $x$ is a convex combination of extreme points of $C$, cf. Theorem 2.2. If $x$ itself is an extreme point, there is nothing to prove. If $x$ is not an extreme point, then there is a segment in $C$ having $x$ in its relative interior. Extending the segment, if necessary, we see that there are in fact points $y_{0},y_{1}\\in\\mathrm{rb}\\;C$ such that $x\\in\\;]y_{0},y_{1}[$. Let $F_{0}$ and $F_{1}$ be the smallest faces of $C$ containing $y_{0}$ and $y_{1}$, respectively. Then $F_{0}$ and $F_{1}$ are proper faces of $C$, cf. Corollary 5.7. They are, in particular, compact convex sets, cf. Theorem 5.1, and they both have dimension $<e$, cf. Corollary 5.5. Then, by the induction hypothesis, there are points $x_{0\\,1},\\dots,x_{0\\,p}\\in\\,\\mathrm{ext}\\,F_{0}$ and $x_{11},\\dots,x_{1q}\\in\\,\\mathrm{ext}\\,F_{\\mathrm{1}}$ such that $y_{0}$ is a convex combination of the $x_{0i}$'s and $y_{1}$ is a convex combination of the $x_{1j}$'s. Since $x$ is a convex combination of $y_{0}$ and $y_{1}$, it follows that $x$ is a convex combination of the $x_{0i}$'s and $x_{1j}$'s. To complete the proof, we note that the $x_{0i}$'s and $x_{1j}$'s are in fact extreme points of $C$; this follows from Theorem 5.2.\n\nCorollary 5.11. Let $C$ be a compact convex set in $\\mathbb{R}^{d}$ with $\\mathrm{dim}\\;C=n$. Then each point of $C$ is a convex combination of at most $n+1$ extreme points of $C$.\n\nProof. Combine Theorem 5.10(c) and Corollary 2.4.  \n\n# EXERCISES  \n\n5.1. Show that ext $C$ is closed when $C$ is a 2-dimensional compact convex set.\n\n5.2. Let $C$ be the convex hull of the set of points $(\\alpha_{1},\\alpha_{2},\\alpha_{3})\\in\\mathbb{R}^{3}$ such that\n\n$$\n\\begin{array}{r}{\\alpha_{1}=\\alpha_{2}=0,\\qquad\\alpha_{3}\\in[-1,1],}\\end{array}\n$$  \n\nor  \n\n$$\n\\alpha_{3}=0,\\qquad(\\alpha_{1}-1)^{2}+\\alpha_{2}^{2}=1.\n$$  \n\nShow that $\\mathrm{ext}\\,C$ is non-closed.  \n\n5.3. Let $C$ be a closed convex set in $\\mathbb{R}^{d}$. Show that if a convex subset $F$ of $C$ is a face of $C$, then $C\\backslash F$ is convex. Show that the converse does not hold in general.  \n\n5.4. Let $C$ be a non-empty closed convex set in $\\mathbb{R}^{d}$. An affine subspace $A$ of $\\mathbb{R}^{d}$ is said to support $C$ if $A\\cap C\\neq\\emptyset$ and $C\\backslash A$ is convex. Show that the supporting hyperplanes of $C$ in the sense of Section 4 are the hyperplanes that support $C$ in the sense just mentioned.",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "To prove $(b)\\Rightarrow(a)$, it suffices to show that  $$ C\\in\\operatorname{conv}(\\operatorname{ext}\\,C).$$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/GTM_090_-_ISBN978-1-4612-1148-8_-_Arne_Br\u00f8ndsted_-_An_Introduction_to_Convex_Polytopes.pdf_42",
        "ID": "1397f163-59ec-4ac9-9b81-f356e88031d0",
        "questions": "What convex combinations are needed to show the validity of Corollary 5.11?",
        "answers": "There are points $x_{0\\,1},\\dots,x_{0\\,p}\\in\\,\\mathrm{ext}\\,F_{0}$ and $x_{11},\\dots,x_{1q}\\in\\,\\mathrm{ext}\\,F_{\\mathrm{1}}$ such that $y_{0}$ is a convex combination of the $x_{0i}$'s and $y_{1}$ is a convex combination of the $x_{1j}$'s.",
        "context": "To prove $(b)\\Rightarrow(a)$, it suffices to show that  \n\n$$\nC\\in\\operatorname{conv}(\\operatorname{ext}\\,C).\n$$\n\n(In fact, suppose that (4) holds. Since the opposite inclusion of (4) is obvious, it then follows that $C={\\mathrm{conv}}({\\mathrm{ext}}\\ C)$. But then we also have $C={\\mathrm{conv}}\\ M$ for any subset $M$ of $C$ containing ext $C$.) We shall prove (4) by induction on the dimension of $C$. For dim $C=-1,0$, there is nothing to prove. For dim $C=1$, the statement is clearly valid. Suppose that the statement is valid for all compact convex sets of dimension $<e$, where $e\\geq2$, and let $C$ be a compact convex set of dimension $e$. Let $x$ be any point in $C$; we shall prove that $x$ is a convex combination of extreme points of $C$, cf. Theorem 2.2. If $x$ itself is an extreme point, there is nothing to prove. If $x$ is not an extreme point, then there is a segment in $C$ having $x$ in its relative interior. Extending the segment, if necessary, we see that there are in fact points $y_{0},y_{1}\\in\\mathrm{rb}\\;C$ such that $x\\in\\;]y_{0},y_{1}[$. Let $F_{0}$ and $F_{1}$ be the smallest faces of $C$ containing $y_{0}$ and $y_{1}$, respectively. Then $F_{0}$ and $F_{1}$ are proper faces of $C$, cf. Corollary 5.7. They are, in particular, compact convex sets, cf. Theorem 5.1, and they both have dimension $<e$, cf. Corollary 5.5. Then, by the induction hypothesis, there are points $x_{0\\,1},\\dots,x_{0\\,p}\\in\\,\\mathrm{ext}\\,F_{0}$ and $x_{11},\\dots,x_{1q}\\in\\,\\mathrm{ext}\\,F_{\\mathrm{1}}$ such that $y_{0}$ is a convex combination of the $x_{0i}$'s and $y_{1}$ is a convex combination of the $x_{1j}$'s. Since $x$ is a convex combination of $y_{0}$ and $y_{1}$, it follows that $x$ is a convex combination of the $x_{0i}$'s and $x_{1j}$'s. To complete the proof, we note that the $x_{0i}$'s and $x_{1j}$'s are in fact extreme points of $C$; this follows from Theorem 5.2.\n\nCorollary 5.11. Let $C$ be a compact convex set in $\\mathbb{R}^{d}$ with $\\mathrm{dim}\\;C=n$. Then each point of $C$ is a convex combination of at most $n+1$ extreme points of $C$.\n\nProof. Combine Theorem 5.10(c) and Corollary 2.4.  \n\n# EXERCISES  \n\n5.1. Show that ext $C$ is closed when $C$ is a 2-dimensional compact convex set.\n\n5.2. Let $C$ be the convex hull of the set of points $(\\alpha_{1},\\alpha_{2},\\alpha_{3})\\in\\mathbb{R}^{3}$ such that\n\n$$\n\\begin{array}{r}{\\alpha_{1}=\\alpha_{2}=0,\\qquad\\alpha_{3}\\in[-1,1],}\\end{array}\n$$  \n\nor  \n\n$$\n\\alpha_{3}=0,\\qquad(\\alpha_{1}-1)^{2}+\\alpha_{2}^{2}=1.\n$$  \n\nShow that $\\mathrm{ext}\\,C$ is non-closed.  \n\n5.3. Let $C$ be a closed convex set in $\\mathbb{R}^{d}$. Show that if a convex subset $F$ of $C$ is a face of $C$, then $C\\backslash F$ is convex. Show that the converse does not hold in general.  \n\n5.4. Let $C$ be a non-empty closed convex set in $\\mathbb{R}^{d}$. An affine subspace $A$ of $\\mathbb{R}^{d}$ is said to support $C$ if $A\\cap C\\neq\\emptyset$ and $C\\backslash A$ is convex. Show that the supporting hyperplanes of $C$ in the sense of Section 4 are the hyperplanes that support $C$ in the sense just mentioned.",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Then, by the induction hypothesis, there are points $x_{0\\,1},\\dots,x_{0\\,p}\\in\\,\\mathrm{ext}\\,F_{0}$ and $x_{11},\\dots,x_{1q}\\in\\,\\mathrm{ext}\\,F_{\\mathrm{1}}$ such that $y_{0}$ is a convex combination of the $x_{0i}$'s and $y_{1}$ is a convex combination of the $x_{1j}$'s.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/GTM_090_-_ISBN978-1-4612-1148-8_-_Arne_Br\u00f8ndsted_-_An_Introduction_to_Convex_Polytopes.pdf_42",
        "ID": "139a9a4b-1cb4-4b91-b718-d0bdd7db31c9",
        "questions": "If $C$ is a compact convex set in $\\mathbb{R}^{3}$, what is $\\operatorname{dim}\\,C$ and how would a point in $C$ be expressed in terms of extreme points according to Corollary 5.11?",
        "answers": "$n = 3$; each point of $C$ is a convex combination of at most $3+1=4$ extreme points of $C$.",
        "context": "To prove $(b)\\Rightarrow(a)$, it suffices to show that  \n\n$$\nC\\in\\operatorname{conv}(\\operatorname{ext}\\,C).\n$$\n\n(In fact, suppose that (4) holds. Since the opposite inclusion of (4) is obvious, it then follows that $C={\\mathrm{conv}}({\\mathrm{ext}}\\ C)$. But then we also have $C={\\mathrm{conv}}\\ M$ for any subset $M$ of $C$ containing ext $C$.) We shall prove (4) by induction on the dimension of $C$. For dim $C=-1,0$, there is nothing to prove. For dim $C=1$, the statement is clearly valid. Suppose that the statement is valid for all compact convex sets of dimension $<e$, where $e\\geq2$, and let $C$ be a compact convex set of dimension $e$. Let $x$ be any point in $C$; we shall prove that $x$ is a convex combination of extreme points of $C$, cf. Theorem 2.2. If $x$ itself is an extreme point, there is nothing to prove. If $x$ is not an extreme point, then there is a segment in $C$ having $x$ in its relative interior. Extending the segment, if necessary, we see that there are in fact points $y_{0},y_{1}\\in\\mathrm{rb}\\;C$ such that $x\\in\\;]y_{0},y_{1}[$. Let $F_{0}$ and $F_{1}$ be the smallest faces of $C$ containing $y_{0}$ and $y_{1}$, respectively. Then $F_{0}$ and $F_{1}$ are proper faces of $C$, cf. Corollary 5.7. They are, in particular, compact convex sets, cf. Theorem 5.1, and they both have dimension $<e$, cf. Corollary 5.5. Then, by the induction hypothesis, there are points $x_{0\\,1},\\dots,x_{0\\,p}\\in\\,\\mathrm{ext}\\,F_{0}$ and $x_{11},\\dots,x_{1q}\\in\\,\\mathrm{ext}\\,F_{\\mathrm{1}}$ such that $y_{0}$ is a convex combination of the $x_{0i}$'s and $y_{1}$ is a convex combination of the $x_{1j}$'s. Since $x$ is a convex combination of $y_{0}$ and $y_{1}$, it follows that $x$ is a convex combination of the $x_{0i}$'s and $x_{1j}$'s. To complete the proof, we note that the $x_{0i}$'s and $x_{1j}$'s are in fact extreme points of $C$; this follows from Theorem 5.2.\n\nCorollary 5.11. Let $C$ be a compact convex set in $\\mathbb{R}^{d}$ with $\\mathrm{dim}\\;C=n$. Then each point of $C$ is a convex combination of at most $n+1$ extreme points of $C$.\n\nProof. Combine Theorem 5.10(c) and Corollary 2.4.  \n\n# EXERCISES  \n\n5.1. Show that ext $C$ is closed when $C$ is a 2-dimensional compact convex set.\n\n5.2. Let $C$ be the convex hull of the set of points $(\\alpha_{1},\\alpha_{2},\\alpha_{3})\\in\\mathbb{R}^{3}$ such that\n\n$$\n\\begin{array}{r}{\\alpha_{1}=\\alpha_{2}=0,\\qquad\\alpha_{3}\\in[-1,1],}\\end{array}\n$$  \n\nor  \n\n$$\n\\alpha_{3}=0,\\qquad(\\alpha_{1}-1)^{2}+\\alpha_{2}^{2}=1.\n$$  \n\nShow that $\\mathrm{ext}\\,C$ is non-closed.  \n\n5.3. Let $C$ be a closed convex set in $\\mathbb{R}^{d}$. Show that if a convex subset $F$ of $C$ is a face of $C$, then $C\\backslash F$ is convex. Show that the converse does not hold in general.  \n\n5.4. Let $C$ be a non-empty closed convex set in $\\mathbb{R}^{d}$. An affine subspace $A$ of $\\mathbb{R}^{d}$ is said to support $C$ if $A\\cap C\\neq\\emptyset$ and $C\\backslash A$ is convex. Show that the supporting hyperplanes of $C$ in the sense of Section 4 are the hyperplanes that support $C$ in the sense just mentioned.",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Numeric",
        "evidence_source": "equation",
        "evidence_context": "Corollary 5.11. Let $C$ be a compact convex set in $\\mathbb{R}^{d}$ with $\\mathrm{dim}\\;C=n$. Then each point of $C$ is a convex combination of at most $n+1$ extreme points of $C$.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/(Graduate_Studies_in_Mathematics,034)_Sigurdur_Helgason_-_Differential_Geometry,_Lie_Groups,_and_Symmetric_Spaces_(2001,_American_Mathematical_Society).pdf_143",
        "ID": "139c77c9-91bf-4715-bebe-8ad07714d461",
        "questions": "What relation in terms of wedge products is derived from multiplying by X^{-1} in the context of the general linear group GL(n,R)?",
        "answers": "d\u03a9 + \u03a9\u2227\u03a9 = 0",
        "context": "Proposition 7.2. Let $X_{1},\\,...,\\,X_{n}$ be a basis of $\\mathfrak{g}$ and $\\omega_{1},\\,...,\\,\\omega_{n}$ the 1-forms on $G$ determined by $\\omega_{i}(\\tilde{X}_{j})=\\delta_{i j},$ Then\n\n$$\nd\\omega_{i}=-\\textstyle{\\frac{1}{2}}\\sum_{j,k=1}^{n}c^{i}{}_{j k}\\omega_{j}\\ \\wedge\\ \\omega_{k}\n$$\n\n$c_{\\ j k}^{i}$ are the structural constants given by\n\n$$\n[X_{j},X_{k}]=\\sum_{i=1}^{n}c^{i}{}_{j k}X_{i}.\n$$\n\nEquations (3) are known as the Maurer-Cartan equations. They follow immediately from (1). They also follow from Theorem 8.1, Chapter I if we give $G$ the left invariant affine connection for which $\\alpha$ in Prop. 1.4 is identically 0. Note that the Jacobi identity for $\\mathfrak{g}$ is reflected in the relation $d^{2}=0$\n\nExample. Consider as in $\\S1$ the general linear group $G L(n,\\,R)$ with the usual coordinates $\\sigma\\to(x_{i j}(\\sigma))$ . Writing $X=(x_{i j})$ $d X=(d x_{i j})$ \uff0cthe matrix\n\n$$\n\\varOmega=X^{-1}\\,d X,\n$$\n\nwhose entries are 1-forms on $G$ is invariant under left translations $X\\to\\sigma X$ on $G$ . Writing\n\n$$\nd X=X\\Omega,\n$$\n\nwe can derive\n\n$$\n0=(d X)\\wedge\\Omega+X\\wedge\\,d\\Omega,\n$$\n\nwhere $\\wedge$ denote the obvious wedge product of matrices. Multiplying by $X^{-1}$ , we obtain\n\n$$\nd\\Omega+\\Omega\\wedge\\Omega=0,\n$$\n\nwhich is an equivalent form of (3)\n\nMore generally, consider for each $\\pmb{x}$ in the Lie group $G$ the mapping\n\n$$\nd L(x^{-1})_{x}:G_{x}\\to\\mathfrak{g}\n$$\n\nand let $\\pmb{\\Omega}$ denote the family of these maps. In other words,\n\n$$\n\\varOmega_{x}(v)=d L(x^{-1})(v)\\qquad\\quad\\mathrm{if}\\quad v\\in G_{x}.\n$$\n\nThen $\\Omega$ is a 1-form on $G$ with values in $\\mathfrak{g}$ . Moreover, if $x,\\,y\\in G,$ then\n\n$$\n\\mathcal{Q}_{x y}\\circ d L(x)_{y}=\\mathcal{Q}_{y},\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "Multiplying by $X^{-1}$ , we obtain $$ d\\Omega+\\Omega\\wedge\\Omega=0, $$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/(Graduate_Studies_in_Mathematics,034)_Sigurdur_Helgason_-_Differential_Geometry,_Lie_Groups,_and_Symmetric_Spaces_(2001,_American_Mathematical_Society).pdf_143",
        "ID": "139dfab3-82ea-4e3a-90e6-8f8ca77ff11f",
        "questions": "For a basis X\u2081,...,X\u2099 of \ud835\udd24, what are the 1-forms on G that satisfy the Kronecker delta condition \u03c9\u1d62(\u1e6aild{X}\u2c7c) = \u03b4\u1d62\u2c7c?",
        "answers": "\u03c9\u2081, ..., \u03c9\u2099",
        "context": "Proposition 7.2. Let $X_{1},\\,...,\\,X_{n}$ be a basis of $\\mathfrak{g}$ and $\\omega_{1},\\,...,\\,\\omega_{n}$ the 1-forms on $G$ determined by $\\omega_{i}(\\tilde{X}_{j})=\\delta_{i j},$ Then\n\n$$\nd\\omega_{i}=-\\textstyle{\\frac{1}{2}}\\sum_{j,k=1}^{n}c^{i}{}_{j k}\\omega_{j}\\ \\wedge\\ \\omega_{k}\n$$\n\n$c_{\\ j k}^{i}$ are the structural constants given by\n\n$$\n[X_{j},X_{k}]=\\sum_{i=1}^{n}c^{i}{}_{j k}X_{i}.\n$$\n\nEquations (3) are known as the Maurer-Cartan equations. They follow immediately from (1). They also follow from Theorem 8.1, Chapter I if we give $G$ the left invariant affine connection for which $\\alpha$ in Prop. 1.4 is identically 0. Note that the Jacobi identity for $\\mathfrak{g}$ is reflected in the relation $d^{2}=0$\n\nExample. Consider as in $\\S1$ the general linear group $G L(n,\\,R)$ with the usual coordinates $\\sigma\\to(x_{i j}(\\sigma))$ . Writing $X=(x_{i j})$ $d X=(d x_{i j})$ \uff0cthe matrix\n\n$$\n\\varOmega=X^{-1}\\,d X,\n$$\n\nwhose entries are 1-forms on $G$ is invariant under left translations $X\\to\\sigma X$ on $G$ . Writing\n\n$$\nd X=X\\Omega,\n$$\n\nwe can derive\n\n$$\n0=(d X)\\wedge\\Omega+X\\wedge\\,d\\Omega,\n$$\n\nwhere $\\wedge$ denote the obvious wedge product of matrices. Multiplying by $X^{-1}$ , we obtain\n\n$$\nd\\Omega+\\Omega\\wedge\\Omega=0,\n$$\n\nwhich is an equivalent form of (3)\n\nMore generally, consider for each $\\pmb{x}$ in the Lie group $G$ the mapping\n\n$$\nd L(x^{-1})_{x}:G_{x}\\to\\mathfrak{g}\n$$\n\nand let $\\pmb{\\Omega}$ denote the family of these maps. In other words,\n\n$$\n\\varOmega_{x}(v)=d L(x^{-1})(v)\\qquad\\quad\\mathrm{if}\\quad v\\in G_{x}.\n$$\n\nThen $\\Omega$ is a 1-form on $G$ with values in $\\mathfrak{g}$ . Moreover, if $x,\\,y\\in G,$ then\n\n$$\n\\mathcal{Q}_{x y}\\circ d L(x)_{y}=\\mathcal{Q}_{y},\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "Let $X_{1},\\,...,\\,X_{n}$ be a basis of $\\mathfrak{g}$ and $\\omega_{1},\\,...,\\,\\omega_{n}$ the 1-forms on $G$ determined by $\\omega_{i}(\tilde{X}_{j})=\\delta_{i j},$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/(Graduate_Studies_in_Mathematics,034)_Sigurdur_Helgason_-_Differential_Geometry,_Lie_Groups,_and_Symmetric_Spaces_(2001,_American_Mathematical_Society).pdf_143",
        "ID": "139e5ca2-b9e7-4780-821c-f26265739938",
        "questions": "What is the differential form equation that follows from the Maurer-Cartan equations for the basis X\u2081,...,X\u2099 of \ud835\udd24 and the 1-forms \u03c9\u2081,...,\u03c9\u2099?",
        "answers": "d\u03c9\u1d62 = -1/2 \u2211(j,k=1)^n c\u1d62\u208d\u2c7c\u2096\u2c7c\u2c7c\u2c7c\u2096}\u03c9\u2c7c \u2227 \u03c9\u2096",
        "context": "Proposition 7.2. Let $X_{1},\\,...,\\,X_{n}$ be a basis of $\\mathfrak{g}$ and $\\omega_{1},\\,...,\\,\\omega_{n}$ the 1-forms on $G$ determined by $\\omega_{i}(\\tilde{X}_{j})=\\delta_{i j},$ Then\n\n$$\nd\\omega_{i}=-\\textstyle{\\frac{1}{2}}\\sum_{j,k=1}^{n}c^{i}{}_{j k}\\omega_{j}\\ \\wedge\\ \\omega_{k}\n$$\n\n$c_{\\ j k}^{i}$ are the structural constants given by\n\n$$\n[X_{j},X_{k}]=\\sum_{i=1}^{n}c^{i}{}_{j k}X_{i}.\n$$\n\nEquations (3) are known as the Maurer-Cartan equations. They follow immediately from (1). They also follow from Theorem 8.1, Chapter I if we give $G$ the left invariant affine connection for which $\\alpha$ in Prop. 1.4 is identically 0. Note that the Jacobi identity for $\\mathfrak{g}$ is reflected in the relation $d^{2}=0$\n\nExample. Consider as in $\\S1$ the general linear group $G L(n,\\,R)$ with the usual coordinates $\\sigma\\to(x_{i j}(\\sigma))$ . Writing $X=(x_{i j})$ $d X=(d x_{i j})$ \uff0cthe matrix\n\n$$\n\\varOmega=X^{-1}\\,d X,\n$$\n\nwhose entries are 1-forms on $G$ is invariant under left translations $X\\to\\sigma X$ on $G$ . Writing\n\n$$\nd X=X\\Omega,\n$$\n\nwe can derive\n\n$$\n0=(d X)\\wedge\\Omega+X\\wedge\\,d\\Omega,\n$$\n\nwhere $\\wedge$ denote the obvious wedge product of matrices. Multiplying by $X^{-1}$ , we obtain\n\n$$\nd\\Omega+\\Omega\\wedge\\Omega=0,\n$$\n\nwhich is an equivalent form of (3)\n\nMore generally, consider for each $\\pmb{x}$ in the Lie group $G$ the mapping\n\n$$\nd L(x^{-1})_{x}:G_{x}\\to\\mathfrak{g}\n$$\n\nand let $\\pmb{\\Omega}$ denote the family of these maps. In other words,\n\n$$\n\\varOmega_{x}(v)=d L(x^{-1})(v)\\qquad\\quad\\mathrm{if}\\quad v\\in G_{x}.\n$$\n\nThen $\\Omega$ is a 1-form on $G$ with values in $\\mathfrak{g}$ . Moreover, if $x,\\,y\\in G,$ then\n\n$$\n\\mathcal{Q}_{x y}\\circ d L(x)_{y}=\\mathcal{Q}_{y},\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$$ d\\omega_{i}=-\\textstyle{\\frac{1}{2}}\\sum_{j,k=1}^{n}c^{i}{}_{j k}\\omega_{j}\\ \\wedge\\ \\omega_{k} $$",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/(Graduate_Studies_in_Mathematics,034)_Sigurdur_Helgason_-_Differential_Geometry,_Lie_Groups,_and_Symmetric_Spaces_(2001,_American_Mathematical_Society).pdf_143",
        "ID": "13a534c8-db93-4206-bfdb-1798b850d5e0",
        "questions": "What is the expression for $d\\Omega$ in terms of $\\Omega$ in the context of the general linear group $GL(n,\\,R)$ in the mathematical document?",
        "answers": "$d\\Omega + \\Omega\\wedge\\Omega = 0$",
        "context": "Proposition 7.2. Let $X_{1},\\,...,\\,X_{n}$ be a basis of $\\mathfrak{g}$ and $\\omega_{1},\\,...,\\,\\omega_{n}$ the 1-forms on $G$ determined by $\\omega_{i}(\\tilde{X}_{j})=\\delta_{i j},$ Then\n\n$$\nd\\omega_{i}=-\\textstyle{\\frac{1}{2}}\\sum_{j,k=1}^{n}c^{i}{}_{j k}\\omega_{j}\\ \\wedge\\ \\omega_{k}\n$$\n\n$c_{\\ j k}^{i}$ are the structural constants given by\n\n$$\n[X_{j},X_{k}]=\\sum_{i=1}^{n}c^{i}{}_{j k}X_{i}.\n$$\n\nEquations (3) are known as the Maurer-Cartan equations. They follow immediately from (1). They also follow from Theorem 8.1, Chapter I if we give $G$ the left invariant affine connection for which $\\alpha$ in Prop. 1.4 is identically 0. Note that the Jacobi identity for $\\mathfrak{g}$ is reflected in the relation $d^{2}=0$\n\nExample. Consider as in $\\S1$ the general linear group $G L(n,\\,R)$ with the usual coordinates $\\sigma\\to(x_{i j}(\\sigma))$ . Writing $X=(x_{i j})$ $d X=(d x_{i j})$ \uff0cthe matrix\n\n$$\n\\varOmega=X^{-1}\\,d X,\n$$\n\nwhose entries are 1-forms on $G$ is invariant under left translations $X\\to\\sigma X$ on $G$ . Writing\n\n$$\nd X=X\\Omega,\n$$\n\nwe can derive\n\n$$\n0=(d X)\\wedge\\Omega+X\\wedge\\,d\\Omega,\n$$\n\nwhere $\\wedge$ denote the obvious wedge product of matrices. Multiplying by $X^{-1}$ , we obtain\n\n$$\nd\\Omega+\\Omega\\wedge\\Omega=0,\n$$\n\nwhich is an equivalent form of (3)\n\nMore generally, consider for each $\\pmb{x}$ in the Lie group $G$ the mapping\n\n$$\nd L(x^{-1})_{x}:G_{x}\\to\\mathfrak{g}\n$$\n\nand let $\\pmb{\\Omega}$ denote the family of these maps. In other words,\n\n$$\n\\varOmega_{x}(v)=d L(x^{-1})(v)\\qquad\\quad\\mathrm{if}\\quad v\\in G_{x}.\n$$\n\nThen $\\Omega$ is a 1-form on $G$ with values in $\\mathfrak{g}$ . Moreover, if $x,\\,y\\in G,$ then\n\n$$\n\\mathcal{Q}_{x y}\\circ d L(x)_{y}=\\mathcal{Q}_{y},\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$d\\Omega + \\Omega\\wedge\\Omega=0$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/(Graduate_Studies_in_Mathematics,034)_Sigurdur_Helgason_-_Differential_Geometry,_Lie_Groups,_and_Symmetric_Spaces_(2001,_American_Mathematical_Society).pdf_143",
        "ID": "13ae4690-af3c-4650-a6fb-b698d951dd59",
        "questions": "In Proposition 7.2, how are the differential of the 1-forms $\\omega_{i}$ expressed in terms of the wedge product of the 1-forms $\\omega_{j}$ and $\\omega_{k}$?",
        "answers": "$d\\omega_{i}=-\\frac{1}{2}\\sum_{j,k=1}^{n}c^{i}{}_{j k}\\omega_{j}\\wedge\\omega_{k}$",
        "context": "Proposition 7.2. Let $X_{1},\\,...,\\,X_{n}$ be a basis of $\\mathfrak{g}$ and $\\omega_{1},\\,...,\\,\\omega_{n}$ the 1-forms on $G$ determined by $\\omega_{i}(\\tilde{X}_{j})=\\delta_{i j},$ Then\n\n$$\nd\\omega_{i}=-\\textstyle{\\frac{1}{2}}\\sum_{j,k=1}^{n}c^{i}{}_{j k}\\omega_{j}\\ \\wedge\\ \\omega_{k}\n$$\n\n$c_{\\ j k}^{i}$ are the structural constants given by\n\n$$\n[X_{j},X_{k}]=\\sum_{i=1}^{n}c^{i}{}_{j k}X_{i}.\n$$\n\nEquations (3) are known as the Maurer-Cartan equations. They follow immediately from (1). They also follow from Theorem 8.1, Chapter I if we give $G$ the left invariant affine connection for which $\\alpha$ in Prop. 1.4 is identically 0. Note that the Jacobi identity for $\\mathfrak{g}$ is reflected in the relation $d^{2}=0$\n\nExample. Consider as in $\\S1$ the general linear group $G L(n,\\,R)$ with the usual coordinates $\\sigma\\to(x_{i j}(\\sigma))$ . Writing $X=(x_{i j})$ $d X=(d x_{i j})$ \uff0cthe matrix\n\n$$\n\\varOmega=X^{-1}\\,d X,\n$$\n\nwhose entries are 1-forms on $G$ is invariant under left translations $X\\to\\sigma X$ on $G$ . Writing\n\n$$\nd X=X\\Omega,\n$$\n\nwe can derive\n\n$$\n0=(d X)\\wedge\\Omega+X\\wedge\\,d\\Omega,\n$$\n\nwhere $\\wedge$ denote the obvious wedge product of matrices. Multiplying by $X^{-1}$ , we obtain\n\n$$\nd\\Omega+\\Omega\\wedge\\Omega=0,\n$$\n\nwhich is an equivalent form of (3)\n\nMore generally, consider for each $\\pmb{x}$ in the Lie group $G$ the mapping\n\n$$\nd L(x^{-1})_{x}:G_{x}\\to\\mathfrak{g}\n$$\n\nand let $\\pmb{\\Omega}$ denote the family of these maps. In other words,\n\n$$\n\\varOmega_{x}(v)=d L(x^{-1})(v)\\qquad\\quad\\mathrm{if}\\quad v\\in G_{x}.\n$$\n\nThen $\\Omega$ is a 1-form on $G$ with values in $\\mathfrak{g}$ . Moreover, if $x,\\,y\\in G,$ then\n\n$$\n\\mathcal{Q}_{x y}\\circ d L(x)_{y}=\\mathcal{Q}_{y},\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$d\\omega_{i}=-\\frac{1}{2}\\sum_{j,k=1}^{n}c^{i}{}_{j k}\\omega_{j}\\wedge\\omega_{k}$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/(Graduate_Studies_in_Mathematics,034)_Sigurdur_Helgason_-_Differential_Geometry,_Lie_Groups,_and_Symmetric_Spaces_(2001,_American_Mathematical_Society).pdf_143",
        "ID": "13b3e713-0c9a-42ec-a404-3f363fb32271",
        "questions": "According to the document, how is the structure constant $c_{j k}^{i}$ related to the basis elements $X_j$ and $X_k$ in a Lie algebra $\\mathfrak{g}$?",
        "answers": "$[X_{j},X_{k}]=\\sum_{i=1}^{n}c^{i}{}_{j k}X_{i}$",
        "context": "Proposition 7.2. Let $X_{1},\\,...,\\,X_{n}$ be a basis of $\\mathfrak{g}$ and $\\omega_{1},\\,...,\\,\\omega_{n}$ the 1-forms on $G$ determined by $\\omega_{i}(\\tilde{X}_{j})=\\delta_{i j},$ Then\n\n$$\nd\\omega_{i}=-\\textstyle{\\frac{1}{2}}\\sum_{j,k=1}^{n}c^{i}{}_{j k}\\omega_{j}\\ \\wedge\\ \\omega_{k}\n$$\n\n$c_{\\ j k}^{i}$ are the structural constants given by\n\n$$\n[X_{j},X_{k}]=\\sum_{i=1}^{n}c^{i}{}_{j k}X_{i}.\n$$\n\nEquations (3) are known as the Maurer-Cartan equations. They follow immediately from (1). They also follow from Theorem 8.1, Chapter I if we give $G$ the left invariant affine connection for which $\\alpha$ in Prop. 1.4 is identically 0. Note that the Jacobi identity for $\\mathfrak{g}$ is reflected in the relation $d^{2}=0$\n\nExample. Consider as in $\\S1$ the general linear group $G L(n,\\,R)$ with the usual coordinates $\\sigma\\to(x_{i j}(\\sigma))$ . Writing $X=(x_{i j})$ $d X=(d x_{i j})$ \uff0cthe matrix\n\n$$\n\\varOmega=X^{-1}\\,d X,\n$$\n\nwhose entries are 1-forms on $G$ is invariant under left translations $X\\to\\sigma X$ on $G$ . Writing\n\n$$\nd X=X\\Omega,\n$$\n\nwe can derive\n\n$$\n0=(d X)\\wedge\\Omega+X\\wedge\\,d\\Omega,\n$$\n\nwhere $\\wedge$ denote the obvious wedge product of matrices. Multiplying by $X^{-1}$ , we obtain\n\n$$\nd\\Omega+\\Omega\\wedge\\Omega=0,\n$$\n\nwhich is an equivalent form of (3)\n\nMore generally, consider for each $\\pmb{x}$ in the Lie group $G$ the mapping\n\n$$\nd L(x^{-1})_{x}:G_{x}\\to\\mathfrak{g}\n$$\n\nand let $\\pmb{\\Omega}$ denote the family of these maps. In other words,\n\n$$\n\\varOmega_{x}(v)=d L(x^{-1})(v)\\qquad\\quad\\mathrm{if}\\quad v\\in G_{x}.\n$$\n\nThen $\\Omega$ is a 1-form on $G$ with values in $\\mathfrak{g}$ . Moreover, if $x,\\,y\\in G,$ then\n\n$$\n\\mathcal{Q}_{x y}\\circ d L(x)_{y}=\\mathcal{Q}_{y},\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "$[X_{j},X_{k}]=\\sum_{i=1}^{n}c^{i}{}_{j k}X_{i}$",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/UTX_-_Riemannian_Geometry_and_Geometric_Analysis,_Fourth_Edition.pdf_485",
        "ID": "13b44e7e-0eeb-4794-b9e7-63d92cd078c2",
        "questions": "What does the second variation of energy depend on if \\( f_{00} \\) satisfies \\( \nabla_{\frac{\\partial}{\\partial t}} \frac{\\partial f}{\\partial s} \\equiv 0 \\) for \\( s = t = 0 \\)?",
        "answers": "The second variation depends only on \\( V \\) and \\( W \\), but not on higher derivatives of \\( f \\) with respect to \\( s \\) and \\( t \\).",
        "context": "We want to examine the third term in (8.7.1) more closely.\n\n$$\n\\int_M \\left\\langle \\nabla_{\\frac{\\partial}{\\partial x^\\alpha}} \\frac{\\partial}{\\partial t} \\nabla_{\\frac{\\partial}{\\partial s}} \\frac{\\partial f}{\\partial x^\\alpha} dx^\\alpha, \\frac{\\partial f}{\\partial x^\\beta} dx^\\beta \\right\\rangle_{T^*M \\otimes f^{-1} TN}\n$$\n\n$$\n= - \\int_M \\left\\langle \\nabla_{\\frac{\\partial}{\\partial t}} \\frac{\\partial f}{\\partial s} dx^\\alpha, \\nabla_{\\frac{\\partial}{\\partial x^\\alpha}} \\frac{\\partial f}{\\partial x^\\beta} dx^\\beta \\right\\rangle_{T^*M \\otimes f^{-1} TN}\n$$\n\nsince \\(\\nabla\\) is metric and integrating by parts\n\n$$\n= - \\int_M \\left\\langle \\nabla_{\\frac{\\partial}{\\partial t}} \\frac{\\partial f}{\\partial s}, \\text{trace}_M \\nabla df \\right\\rangle_{f^{-1} TN}.\n$$\n\nTheorem 8.7.1: For a smooth family $f_{s t}\\,:\\,M\\,\\rightarrow\\,N$ of finite energy maps between Riemannian manifolds, with $f_{s t}(x)\\;=\\;f_{00}(x)$ for all $x\\,\\in\\,\\partial M$ (in case $\\partial M\\ne\\emptyset$) and all $s,t$, we have for the second variation of energy, with $\\begin{array}{r}{V=\\frac{\\partial f}{\\partial s}_{\\mid s=0},W=\\frac{\\partial f}{\\partial t}_{\\mid t=0}}\\end{array}$\n\n$$\n\\begin{array}{r l}&{\\frac{\\partial^{2}E(f_{s t})}{\\partial s\\partial t}_{|s=t=0}}\\\\ &{=\\displaystyle\\int_{M}\\left\\langle\\nabla V,\\nabla W\\right\\rangle_{f^{-1}T N}-\\displaystyle\\int_{M}\\mathrm{trace}_{M}\\langle R^{N}(d f,V)W,d f\\rangle_{f^{-1}T N}}\\\\ &{\\quad+\\displaystyle\\int_{M}\\left\\langle\\nabla_{\\frac{\\partial}{\\partial t}}\\frac{\\partial f}{\\partial s},\\ \\mathrm{trace}_{M}\\nabla d f\\right\\rangle_{f^{-1}T N}.}\\end{array}\n$$\n\nIf $f_{\\mathrm{00}}$ $\\begin{array}{r}{\\nabla_{\\frac{\\partial}{\\partial t}}\\frac{\\partial f}{\\partial s}\\equiv0}\\end{array}$ for $s=t=0$, then the second variation depends only on $V$ and $W$, but not on higher derivatives of $f$ w.r.t. $s,t$, and\n\n$$\n\\begin{array}{l}{\\displaystyle I_{f}(V,W):=\\frac{\\partial^{2}E(f_{s t})}{\\partial s\\partial t}=\\int_{M}\\left\\langle\\nabla V,\\nabla W\\right\\rangle_{f^{-1}T N}}\\\\ {\\displaystyle\\qquad\\qquad-\\int_{M}\\mathrm{trace}_{M}\\langle R^{N}(d f,V)W,d f\\rangle_{f^{-1}T N}\\,.}\\end{array}\n$$\n\n$\\begin{array}{r}{\\nabla_{\\frac{\\partial}{\\partial t}}\\frac{\\partial f}{\\partial s}\\equiv0}\\end{array}$ Or $\\mathrm{trace}_{M}\\nabla d f\\equiv0$, and the latter is the harmonic map equation (cf. (8.1.14)).\n\nWe look at the special case where we only have one parameter:\n\n$$\n\\begin{array}{r l}&{f(x,t)=f_{t}(x),f:M\\times(-\\varepsilon,\\varepsilon)\\to N,}\\\\ &{\\quad\\quad W:=\\displaystyle\\frac{\\partial f}{\\partial t}_{|t=0}}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "text",
        "evidence_context": "If \\( f_{\\mathrm{00}} \\) \\( \begin{array}{r}{\nabla_{\frac{\\partial}{\\partial t}} \frac{\\partial f}{\\partial s} \\equiv 0 }\\end{array} \\) for \\( s=t=0 \\), then the second variation depends only on \\( V \\) and \\( W \\), but not on higher derivatives of \\( f \\) w.r.t. \\( s,t \\), and",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTX_-_Riemannian_Geometry_and_Geometric_Analysis,_Fourth_Edition.pdf_485",
        "ID": "13b76328-4251-48a2-a753-9cad456b0866",
        "questions": "What integral expression is used to represent the second variation of energy for a smooth family \\( f_{st} \\) if \\( \nabla_{\frac{\\partial}{\\partial t}} \frac{\\partial f}{\\partial s} \\equiv 0 \\)?",
        "answers": "\\[ \\begin{array}{l}{I_{f}(V,W):=\frac{\\partial^{2}E(f_{s t})}{\\partial s\\partial t}=\\int_{M}\\left\\langle\nabla V,\nabla W\right\rangle_{f^{-1}T N}}\\{\\qquad\\qquad-\\int_{M}\\mathrm{trace}_{M}\\langle R^{N}(d f,V)W,d f\rangle_{f^{-1}T N}\\,.}\\end{array}\\]",
        "context": "We want to examine the third term in (8.7.1) more closely.\n\n$$\n\\int_M \\left\\langle \\nabla_{\\frac{\\partial}{\\partial x^\\alpha}} \\frac{\\partial}{\\partial t} \\nabla_{\\frac{\\partial}{\\partial s}} \\frac{\\partial f}{\\partial x^\\alpha} dx^\\alpha, \\frac{\\partial f}{\\partial x^\\beta} dx^\\beta \\right\\rangle_{T^*M \\otimes f^{-1} TN}\n$$\n\n$$\n= - \\int_M \\left\\langle \\nabla_{\\frac{\\partial}{\\partial t}} \\frac{\\partial f}{\\partial s} dx^\\alpha, \\nabla_{\\frac{\\partial}{\\partial x^\\alpha}} \\frac{\\partial f}{\\partial x^\\beta} dx^\\beta \\right\\rangle_{T^*M \\otimes f^{-1} TN}\n$$\n\nsince \\(\\nabla\\) is metric and integrating by parts\n\n$$\n= - \\int_M \\left\\langle \\nabla_{\\frac{\\partial}{\\partial t}} \\frac{\\partial f}{\\partial s}, \\text{trace}_M \\nabla df \\right\\rangle_{f^{-1} TN}.\n$$\n\nTheorem 8.7.1: For a smooth family $f_{s t}\\,:\\,M\\,\\rightarrow\\,N$ of finite energy maps between Riemannian manifolds, with $f_{s t}(x)\\;=\\;f_{00}(x)$ for all $x\\,\\in\\,\\partial M$ (in case $\\partial M\\ne\\emptyset$) and all $s,t$, we have for the second variation of energy, with $\\begin{array}{r}{V=\\frac{\\partial f}{\\partial s}_{\\mid s=0},W=\\frac{\\partial f}{\\partial t}_{\\mid t=0}}\\end{array}$\n\n$$\n\\begin{array}{r l}&{\\frac{\\partial^{2}E(f_{s t})}{\\partial s\\partial t}_{|s=t=0}}\\\\ &{=\\displaystyle\\int_{M}\\left\\langle\\nabla V,\\nabla W\\right\\rangle_{f^{-1}T N}-\\displaystyle\\int_{M}\\mathrm{trace}_{M}\\langle R^{N}(d f,V)W,d f\\rangle_{f^{-1}T N}}\\\\ &{\\quad+\\displaystyle\\int_{M}\\left\\langle\\nabla_{\\frac{\\partial}{\\partial t}}\\frac{\\partial f}{\\partial s},\\ \\mathrm{trace}_{M}\\nabla d f\\right\\rangle_{f^{-1}T N}.}\\end{array}\n$$\n\nIf $f_{\\mathrm{00}}$ $\\begin{array}{r}{\\nabla_{\\frac{\\partial}{\\partial t}}\\frac{\\partial f}{\\partial s}\\equiv0}\\end{array}$ for $s=t=0$, then the second variation depends only on $V$ and $W$, but not on higher derivatives of $f$ w.r.t. $s,t$, and\n\n$$\n\\begin{array}{l}{\\displaystyle I_{f}(V,W):=\\frac{\\partial^{2}E(f_{s t})}{\\partial s\\partial t}=\\int_{M}\\left\\langle\\nabla V,\\nabla W\\right\\rangle_{f^{-1}T N}}\\\\ {\\displaystyle\\qquad\\qquad-\\int_{M}\\mathrm{trace}_{M}\\langle R^{N}(d f,V)W,d f\\rangle_{f^{-1}T N}\\,.}\\end{array}\n$$\n\n$\\begin{array}{r}{\\nabla_{\\frac{\\partial}{\\partial t}}\\frac{\\partial f}{\\partial s}\\equiv0}\\end{array}$ Or $\\mathrm{trace}_{M}\\nabla d f\\equiv0$, and the latter is the harmonic map equation (cf. (8.1.14)).\n\nWe look at the special case where we only have one parameter:\n\n$$\n\\begin{array}{r l}&{f(x,t)=f_{t}(x),f:M\\times(-\\varepsilon,\\varepsilon)\\to N,}\\\\ &{\\quad\\quad W:=\\displaystyle\\frac{\\partial f}{\\partial t}_{|t=0}}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Equation",
        "evidence_source": "equation",
        "evidence_context": "\\[ \\begin{array}{l}{\\displaystyle I_{f}(V,W):=\frac{\\partial^{2}E(f_{s t})}{\\partial s\\partial t}=\\int_{M}\\left\\langle\nabla V,\nabla W\\right\\rangle_{f^{-1}T N}}\\ {\\displaystyle\\qquad\\qquad-\\int_{M}\\mathrm{trace}_{M}\\langle R^{N}(d f,V)W,d f\\rangle_{f^{-1}T N}\\,.}\\end{array}\\]",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTX_-_Riemannian_Geometry_and_Geometric_Analysis,_Fourth_Edition.pdf_485",
        "ID": "13bb05c5-3220-44a8-b610-cb2461020a09",
        "questions": "For a smooth family of finite energy maps \\( f_{st}: M \rightarrow N \\) with boundary conditions \\( f_{st}(x) = f_{00}(x) \\) for all \\( x \\in \\partial M \\) where \\( \\partial M \neq \\emptyset \\), what is the general form of the second variation of energy?",
        "answers": "\\[ \\frac{\\partial^{2}E(f_{st})}{\\partial s\\partial t}_{|s=t=0} = \\int_{M} \\left\\langle \\nabla V, \\nabla W \\right\\rangle_{f^{-1}TN} - \\int_{M} \\mathrm{trace}_{M} \\langle R^{N}(df, V)W, df \\rangle_{f^{-1}TN} + \\int_{M} \\left\\langle \\nabla_{\\frac{\\partial}{\\partial t}} \\frac{\\partial f}{\\partial s}, \\mathrm{trace}_{M} \\nabla df \\right\\rangle_{f^{-1}TN}\\]",
        "context": "We want to examine the third term in (8.7.1) more closely.\n\n$$\n\\int_M \\left\\langle \\nabla_{\\frac{\\partial}{\\partial x^\\alpha}} \\frac{\\partial}{\\partial t} \\nabla_{\\frac{\\partial}{\\partial s}} \\frac{\\partial f}{\\partial x^\\alpha} dx^\\alpha, \\frac{\\partial f}{\\partial x^\\beta} dx^\\beta \\right\\rangle_{T^*M \\otimes f^{-1} TN}\n$$\n\n$$\n= - \\int_M \\left\\langle \\nabla_{\\frac{\\partial}{\\partial t}} \\frac{\\partial f}{\\partial s} dx^\\alpha, \\nabla_{\\frac{\\partial}{\\partial x^\\alpha}} \\frac{\\partial f}{\\partial x^\\beta} dx^\\beta \\right\\rangle_{T^*M \\otimes f^{-1} TN}\n$$\n\nsince \\(\\nabla\\) is metric and integrating by parts\n\n$$\n= - \\int_M \\left\\langle \\nabla_{\\frac{\\partial}{\\partial t}} \\frac{\\partial f}{\\partial s}, \\text{trace}_M \\nabla df \\right\\rangle_{f^{-1} TN}.\n$$\n\nTheorem 8.7.1: For a smooth family $f_{s t}\\,:\\,M\\,\\rightarrow\\,N$ of finite energy maps between Riemannian manifolds, with $f_{s t}(x)\\;=\\;f_{00}(x)$ for all $x\\,\\in\\,\\partial M$ (in case $\\partial M\\ne\\emptyset$) and all $s,t$, we have for the second variation of energy, with $\\begin{array}{r}{V=\\frac{\\partial f}{\\partial s}_{\\mid s=0},W=\\frac{\\partial f}{\\partial t}_{\\mid t=0}}\\end{array}$\n\n$$\n\\begin{array}{r l}&{\\frac{\\partial^{2}E(f_{s t})}{\\partial s\\partial t}_{|s=t=0}}\\\\ &{=\\displaystyle\\int_{M}\\left\\langle\\nabla V,\\nabla W\\right\\rangle_{f^{-1}T N}-\\displaystyle\\int_{M}\\mathrm{trace}_{M}\\langle R^{N}(d f,V)W,d f\\rangle_{f^{-1}T N}}\\\\ &{\\quad+\\displaystyle\\int_{M}\\left\\langle\\nabla_{\\frac{\\partial}{\\partial t}}\\frac{\\partial f}{\\partial s},\\ \\mathrm{trace}_{M}\\nabla d f\\right\\rangle_{f^{-1}T N}.}\\end{array}\n$$\n\nIf $f_{\\mathrm{00}}$ $\\begin{array}{r}{\\nabla_{\\frac{\\partial}{\\partial t}}\\frac{\\partial f}{\\partial s}\\equiv0}\\end{array}$ for $s=t=0$, then the second variation depends only on $V$ and $W$, but not on higher derivatives of $f$ w.r.t. $s,t$, and\n\n$$\n\\begin{array}{l}{\\displaystyle I_{f}(V,W):=\\frac{\\partial^{2}E(f_{s t})}{\\partial s\\partial t}=\\int_{M}\\left\\langle\\nabla V,\\nabla W\\right\\rangle_{f^{-1}T N}}\\\\ {\\displaystyle\\qquad\\qquad-\\int_{M}\\mathrm{trace}_{M}\\langle R^{N}(d f,V)W,d f\\rangle_{f^{-1}T N}\\,.}\\end{array}\n$$\n\n$\\begin{array}{r}{\\nabla_{\\frac{\\partial}{\\partial t}}\\frac{\\partial f}{\\partial s}\\equiv0}\\end{array}$ Or $\\mathrm{trace}_{M}\\nabla d f\\equiv0$, and the latter is the harmonic map equation (cf. (8.1.14)).\n\nWe look at the special case where we only have one parameter:\n\n$$\n\\begin{array}{r l}&{f(x,t)=f_{t}(x),f:M\\times(-\\varepsilon,\\varepsilon)\\to N,}\\\\ &{\\quad\\quad W:=\\displaystyle\\frac{\\partial f}{\\partial t}_{|t=0}}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Equation",
        "evidence_source": "equation",
        "evidence_context": "Theorem 8.7.1: For a smooth family $f_{s t}\\,:\\,M\\,\rightarrow\\,N$ of finite energy maps between Riemannian manifolds, with $f_{s t}(x)\\;=\\;f_{00}(x)$ for all $x\\,\\in\\,\\partial M$ (in case $\\partial M\ne\\emptyset$) and all $s,t$, we have for the second variation of energy,...",
        "evidence_page_no": 0,
        "is_extra_qa": false
    },
    {
        "doc_name": "textbook/UTX_-_Riemannian_Geometry_and_Geometric_Analysis,_Fourth_Edition.pdf_485",
        "ID": "13bd01ae-70dd-4704-a489-88cf091523be",
        "questions": "What is the term representing the trace of the product of the Riemannian curvature and the differential map in the second variation of energy for a smooth family \\( f_{s t} \\) of finite energy maps?",
        "answers": "-\\displaystyle\\int_{M}\\mathrm{trace}_{M}\\langle R^{N}(d f,V)W,d f\\rangle_{f^{-1}T N}",
        "context": "We want to examine the third term in (8.7.1) more closely.\n\n$$\n\\int_M \\left\\langle \\nabla_{\\frac{\\partial}{\\partial x^\\alpha}} \\frac{\\partial}{\\partial t} \\nabla_{\\frac{\\partial}{\\partial s}} \\frac{\\partial f}{\\partial x^\\alpha} dx^\\alpha, \\frac{\\partial f}{\\partial x^\\beta} dx^\\beta \\right\\rangle_{T^*M \\otimes f^{-1} TN}\n$$\n\n$$\n= - \\int_M \\left\\langle \\nabla_{\\frac{\\partial}{\\partial t}} \\frac{\\partial f}{\\partial s} dx^\\alpha, \\nabla_{\\frac{\\partial}{\\partial x^\\alpha}} \\frac{\\partial f}{\\partial x^\\beta} dx^\\beta \\right\\rangle_{T^*M \\otimes f^{-1} TN}\n$$\n\nsince \\(\\nabla\\) is metric and integrating by parts\n\n$$\n= - \\int_M \\left\\langle \\nabla_{\\frac{\\partial}{\\partial t}} \\frac{\\partial f}{\\partial s}, \\text{trace}_M \\nabla df \\right\\rangle_{f^{-1} TN}.\n$$\n\nTheorem 8.7.1: For a smooth family $f_{s t}\\,:\\,M\\,\\rightarrow\\,N$ of finite energy maps between Riemannian manifolds, with $f_{s t}(x)\\;=\\;f_{00}(x)$ for all $x\\,\\in\\,\\partial M$ (in case $\\partial M\\ne\\emptyset$) and all $s,t$, we have for the second variation of energy, with $\\begin{array}{r}{V=\\frac{\\partial f}{\\partial s}_{\\mid s=0},W=\\frac{\\partial f}{\\partial t}_{\\mid t=0}}\\end{array}$\n\n$$\n\\begin{array}{r l}&{\\frac{\\partial^{2}E(f_{s t})}{\\partial s\\partial t}_{|s=t=0}}\\\\ &{=\\displaystyle\\int_{M}\\left\\langle\\nabla V,\\nabla W\\right\\rangle_{f^{-1}T N}-\\displaystyle\\int_{M}\\mathrm{trace}_{M}\\langle R^{N}(d f,V)W,d f\\rangle_{f^{-1}T N}}\\\\ &{\\quad+\\displaystyle\\int_{M}\\left\\langle\\nabla_{\\frac{\\partial}{\\partial t}}\\frac{\\partial f}{\\partial s},\\ \\mathrm{trace}_{M}\\nabla d f\\right\\rangle_{f^{-1}T N}.}\\end{array}\n$$\n\nIf $f_{\\mathrm{00}}$ $\\begin{array}{r}{\\nabla_{\\frac{\\partial}{\\partial t}}\\frac{\\partial f}{\\partial s}\\equiv0}\\end{array}$ for $s=t=0$, then the second variation depends only on $V$ and $W$, but not on higher derivatives of $f$ w.r.t. $s,t$, and\n\n$$\n\\begin{array}{l}{\\displaystyle I_{f}(V,W):=\\frac{\\partial^{2}E(f_{s t})}{\\partial s\\partial t}=\\int_{M}\\left\\langle\\nabla V,\\nabla W\\right\\rangle_{f^{-1}T N}}\\\\ {\\displaystyle\\qquad\\qquad-\\int_{M}\\mathrm{trace}_{M}\\langle R^{N}(d f,V)W,d f\\rangle_{f^{-1}T N}\\,.}\\end{array}\n$$\n\n$\\begin{array}{r}{\\nabla_{\\frac{\\partial}{\\partial t}}\\frac{\\partial f}{\\partial s}\\equiv0}\\end{array}$ Or $\\mathrm{trace}_{M}\\nabla d f\\equiv0$, and the latter is the harmonic map equation (cf. (8.1.14)).\n\nWe look at the special case where we only have one parameter:\n\n$$\n\\begin{array}{r l}&{f(x,t)=f_{t}(x),f:M\\times(-\\varepsilon,\\varepsilon)\\to N,}\\\\ &{\\quad\\quad W:=\\displaystyle\\frac{\\partial f}{\\partial t}_{|t=0}}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Medium",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "=-\\displaystyle\\int_{M}\\mathrm{trace}_{M}\\langle R^{N}(d f,V)W,d f\\rangle_{f^{-1}T N}",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/UTX_-_Riemannian_Geometry_and_Geometric_Analysis,_Fourth_Edition.pdf_485",
        "ID": "13bea224-32cc-49b1-a883-93f7f8a22794",
        "questions": "How is the third term in (8.7.1) transformed after integrating by parts and utilizing the metric properties of \\(\nabla\\)?",
        "answers": "- \\int_M \\left\\langle \\nabla_{\\frac{\\partial}{\\partial t}} \\frac{\\partial f}{\\partial s}, \\text{trace}_M \\nabla df \\right\\rangle_{f^{-1} TN}.",
        "context": "We want to examine the third term in (8.7.1) more closely.\n\n$$\n\\int_M \\left\\langle \\nabla_{\\frac{\\partial}{\\partial x^\\alpha}} \\frac{\\partial}{\\partial t} \\nabla_{\\frac{\\partial}{\\partial s}} \\frac{\\partial f}{\\partial x^\\alpha} dx^\\alpha, \\frac{\\partial f}{\\partial x^\\beta} dx^\\beta \\right\\rangle_{T^*M \\otimes f^{-1} TN}\n$$\n\n$$\n= - \\int_M \\left\\langle \\nabla_{\\frac{\\partial}{\\partial t}} \\frac{\\partial f}{\\partial s} dx^\\alpha, \\nabla_{\\frac{\\partial}{\\partial x^\\alpha}} \\frac{\\partial f}{\\partial x^\\beta} dx^\\beta \\right\\rangle_{T^*M \\otimes f^{-1} TN}\n$$\n\nsince \\(\\nabla\\) is metric and integrating by parts\n\n$$\n= - \\int_M \\left\\langle \\nabla_{\\frac{\\partial}{\\partial t}} \\frac{\\partial f}{\\partial s}, \\text{trace}_M \\nabla df \\right\\rangle_{f^{-1} TN}.\n$$\n\nTheorem 8.7.1: For a smooth family $f_{s t}\\,:\\,M\\,\\rightarrow\\,N$ of finite energy maps between Riemannian manifolds, with $f_{s t}(x)\\;=\\;f_{00}(x)$ for all $x\\,\\in\\,\\partial M$ (in case $\\partial M\\ne\\emptyset$) and all $s,t$, we have for the second variation of energy, with $\\begin{array}{r}{V=\\frac{\\partial f}{\\partial s}_{\\mid s=0},W=\\frac{\\partial f}{\\partial t}_{\\mid t=0}}\\end{array}$\n\n$$\n\\begin{array}{r l}&{\\frac{\\partial^{2}E(f_{s t})}{\\partial s\\partial t}_{|s=t=0}}\\\\ &{=\\displaystyle\\int_{M}\\left\\langle\\nabla V,\\nabla W\\right\\rangle_{f^{-1}T N}-\\displaystyle\\int_{M}\\mathrm{trace}_{M}\\langle R^{N}(d f,V)W,d f\\rangle_{f^{-1}T N}}\\\\ &{\\quad+\\displaystyle\\int_{M}\\left\\langle\\nabla_{\\frac{\\partial}{\\partial t}}\\frac{\\partial f}{\\partial s},\\ \\mathrm{trace}_{M}\\nabla d f\\right\\rangle_{f^{-1}T N}.}\\end{array}\n$$\n\nIf $f_{\\mathrm{00}}$ $\\begin{array}{r}{\\nabla_{\\frac{\\partial}{\\partial t}}\\frac{\\partial f}{\\partial s}\\equiv0}\\end{array}$ for $s=t=0$, then the second variation depends only on $V$ and $W$, but not on higher derivatives of $f$ w.r.t. $s,t$, and\n\n$$\n\\begin{array}{l}{\\displaystyle I_{f}(V,W):=\\frac{\\partial^{2}E(f_{s t})}{\\partial s\\partial t}=\\int_{M}\\left\\langle\\nabla V,\\nabla W\\right\\rangle_{f^{-1}T N}}\\\\ {\\displaystyle\\qquad\\qquad-\\int_{M}\\mathrm{trace}_{M}\\langle R^{N}(d f,V)W,d f\\rangle_{f^{-1}T N}\\,.}\\end{array}\n$$\n\n$\\begin{array}{r}{\\nabla_{\\frac{\\partial}{\\partial t}}\\frac{\\partial f}{\\partial s}\\equiv0}\\end{array}$ Or $\\mathrm{trace}_{M}\\nabla d f\\equiv0$, and the latter is the harmonic map equation (cf. (8.1.14)).\n\nWe look at the special case where we only have one parameter:\n\n$$\n\\begin{array}{r l}&{f(x,t)=f_{t}(x),f:M\\times(-\\varepsilon,\\varepsilon)\\to N,}\\\\ &{\\quad\\quad W:=\\displaystyle\\frac{\\partial f}{\\partial t}_{|t=0}}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Hard",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "= - \\int_M \\left\\langle \\nabla_{\\frac{\\partial}{\\partial t}} \\frac{\\partial f}{\\partial s}, \\text{trace}_M \\nabla df \\right\\rangle_{f^{-1} TN}.",
        "evidence_page_no": 0,
        "is_extra_qa": true
    },
    {
        "doc_name": "textbook/UTX_-_Riemannian_Geometry_and_Geometric_Analysis,_Fourth_Edition.pdf_485",
        "ID": "13bfa947-97ff-46e7-b877-b7373cc61e47",
        "questions": "What is the definition of the second variation of energy \\( I_f(V, W) \\) when \\( \\nabla_{\\frac{\\partial}{\\partial t}} \\frac{\\partial f}{\\partial s} \\equiv 0 \\)?",
        "answers": "I_f(V, W):= \\frac{\\partial^{2}E(f_{s t})}{\\partial s\\partial t}= \\int_{M}\\left\\langle\\nabla V,\\nabla W\\right\\rangle_{f^{-1}T N} -\\int_{M}\\mathrm{trace}_{M}\\langle R^{N}(d f,V)W,d f\\rangle_{f^{-1}T N}\\.",
        "context": "We want to examine the third term in (8.7.1) more closely.\n\n$$\n\\int_M \\left\\langle \\nabla_{\\frac{\\partial}{\\partial x^\\alpha}} \\frac{\\partial}{\\partial t} \\nabla_{\\frac{\\partial}{\\partial s}} \\frac{\\partial f}{\\partial x^\\alpha} dx^\\alpha, \\frac{\\partial f}{\\partial x^\\beta} dx^\\beta \\right\\rangle_{T^*M \\otimes f^{-1} TN}\n$$\n\n$$\n= - \\int_M \\left\\langle \\nabla_{\\frac{\\partial}{\\partial t}} \\frac{\\partial f}{\\partial s} dx^\\alpha, \\nabla_{\\frac{\\partial}{\\partial x^\\alpha}} \\frac{\\partial f}{\\partial x^\\beta} dx^\\beta \\right\\rangle_{T^*M \\otimes f^{-1} TN}\n$$\n\nsince \\(\\nabla\\) is metric and integrating by parts\n\n$$\n= - \\int_M \\left\\langle \\nabla_{\\frac{\\partial}{\\partial t}} \\frac{\\partial f}{\\partial s}, \\text{trace}_M \\nabla df \\right\\rangle_{f^{-1} TN}.\n$$\n\nTheorem 8.7.1: For a smooth family $f_{s t}\\,:\\,M\\,\\rightarrow\\,N$ of finite energy maps between Riemannian manifolds, with $f_{s t}(x)\\;=\\;f_{00}(x)$ for all $x\\,\\in\\,\\partial M$ (in case $\\partial M\\ne\\emptyset$) and all $s,t$, we have for the second variation of energy, with $\\begin{array}{r}{V=\\frac{\\partial f}{\\partial s}_{\\mid s=0},W=\\frac{\\partial f}{\\partial t}_{\\mid t=0}}\\end{array}$\n\n$$\n\\begin{array}{r l}&{\\frac{\\partial^{2}E(f_{s t})}{\\partial s\\partial t}_{|s=t=0}}\\\\ &{=\\displaystyle\\int_{M}\\left\\langle\\nabla V,\\nabla W\\right\\rangle_{f^{-1}T N}-\\displaystyle\\int_{M}\\mathrm{trace}_{M}\\langle R^{N}(d f,V)W,d f\\rangle_{f^{-1}T N}}\\\\ &{\\quad+\\displaystyle\\int_{M}\\left\\langle\\nabla_{\\frac{\\partial}{\\partial t}}\\frac{\\partial f}{\\partial s},\\ \\mathrm{trace}_{M}\\nabla d f\\right\\rangle_{f^{-1}T N}.}\\end{array}\n$$\n\nIf $f_{\\mathrm{00}}$ $\\begin{array}{r}{\\nabla_{\\frac{\\partial}{\\partial t}}\\frac{\\partial f}{\\partial s}\\equiv0}\\end{array}$ for $s=t=0$, then the second variation depends only on $V$ and $W$, but not on higher derivatives of $f$ w.r.t. $s,t$, and\n\n$$\n\\begin{array}{l}{\\displaystyle I_{f}(V,W):=\\frac{\\partial^{2}E(f_{s t})}{\\partial s\\partial t}=\\int_{M}\\left\\langle\\nabla V,\\nabla W\\right\\rangle_{f^{-1}T N}}\\\\ {\\displaystyle\\qquad\\qquad-\\int_{M}\\mathrm{trace}_{M}\\langle R^{N}(d f,V)W,d f\\rangle_{f^{-1}T N}\\,.}\\end{array}\n$$\n\n$\\begin{array}{r}{\\nabla_{\\frac{\\partial}{\\partial t}}\\frac{\\partial f}{\\partial s}\\equiv0}\\end{array}$ Or $\\mathrm{trace}_{M}\\nabla d f\\equiv0$, and the latter is the harmonic map equation (cf. (8.1.14)).\n\nWe look at the special case where we only have one parameter:\n\n$$\n\\begin{array}{r l}&{f(x,t)=f_{t}(x),f:M\\times(-\\varepsilon,\\varepsilon)\\to N,}\\\\ &{\\quad\\quad W:=\\displaystyle\\frac{\\partial f}{\\partial t}_{|t=0}}\\end{array}\n$$",
        "doc_type": "textbook",
        "difficulty_level": "Easy",
        "answer_form": "Short Answer",
        "evidence_source": "equation",
        "evidence_context": "I_f(V, W):= \\frac{\\partial^{2}E(f_{s t})}{\\partial s\\partial t}= \\int_{M}\\left\\langle\\nabla V,\\nabla W\\right\\rangle_{f^{-1}T N} -\\int_{M}\\mathrm{trace}_{M}\\langle R^{N}(d f,V)W,d f\\rangle_{f^{-1}T N}",
        "evidence_page_no": 0,
        "is_extra_qa": true
    }
]